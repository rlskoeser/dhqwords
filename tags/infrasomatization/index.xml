<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>infrasomatization on DHQwords</title><link>https://rlskoeser.github.io/dhqwords/tags/infrasomatization/</link><description>Recent content in infrasomatization on DHQwords</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>cdh-info@princeton.edu</managingEditor><webMaster>cdh-info@princeton.edu</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License.</copyright><lastBuildDate>Fri, 07 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://rlskoeser.github.io/dhqwords/tags/infrasomatization/index.xml" rel="self" type="application/rss+xml"/><item><title>The Explainability Turn</title><link>https://rlskoeser.github.io/dhqwords/vol/17/2/000685/</link><pubDate>Fri, 07 Jul 2023 00:00:00 +0000</pubDate><author>David M. Berry</author><guid>https://rlskoeser.github.io/dhqwords/vol/17/2/000685/</guid><description>Introduction How can we know what our computational infrastructures are doing to us? More to the point, how can we trust that algorithms and related technologies do not have a detrimental effect? As technologies make up more of our digital environment, they not only provide tools for thought, but they also shape and direct the very way we think. The move from relying on books to understand a topic to using the internet to research a topic is profoundly different, not only in terms of the acceleration in access to information, but also in the reliance on surfing and searching for information.</description></item></channel></rss>