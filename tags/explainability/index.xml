<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Explainability on DHQwords</title><link>https://rlskoeser.github.io/dhqwords/tags/explainability/</link><description>Recent content in Explainability on DHQwords</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>cdh-info@princeton.edu</managingEditor><webMaster>cdh-info@princeton.edu</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License.</copyright><lastBuildDate>Thu, 20 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://rlskoeser.github.io/dhqwords/tags/explainability/index.xml" rel="self" type="application/rss+xml"/><item><title>Tracing Toxicity Through Code: Towards a Method of Explainability and Interpretability in Software</title><link>https://rlskoeser.github.io/dhqwords/vol/17/2/000706/</link><pubDate>Thu, 20 Jul 2023 00:00:00 +0000</pubDate><author>David M. Berry</author><guid>https://rlskoeser.github.io/dhqwords/vol/17/2/000706/</guid><description>Introduction In the past decade, due to the perceived lack of accountability of algorithmic systems, particularly automated decision systems, a new explanatory demand has crystallized in an important critique of computational opaqueness and new forms of technical transparency calledÂ explainability. We see this, for example, in challenges to facial recognition technologies, public unease with algorithmic judicial systems and other automated decision systems. There have been new regulatory attempts to capture some of the ideas that stem from explainability such as the Algorithmic Accountability Act 2022 in the US, and the General Data Protection Regulation 2016/679 (GDPR) in the European Union.</description></item><item><title>The Explainability Turn</title><link>https://rlskoeser.github.io/dhqwords/vol/17/2/000685/</link><pubDate>Fri, 07 Jul 2023 00:00:00 +0000</pubDate><author>David M. Berry</author><guid>https://rlskoeser.github.io/dhqwords/vol/17/2/000685/</guid><description>Introduction How can we know what our computational infrastructures are doing to us? More to the point, how can we trust that algorithms and related technologies do not have a detrimental effect? As technologies make up more of our digital environment, they not only provide tools for thought, but they also shape and direct the very way we think. The move from relying on books to understand a topic to using the internet to research a topic is profoundly different, not only in terms of the acceleration in access to information, but also in the reliance on surfing and searching for information.</description></item></channel></rss>