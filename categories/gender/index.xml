<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>gender on DHQwords</title><link>https://rlskoeser.github.io/dhqwords/categories/gender/</link><description>Recent content in gender on DHQwords</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>cdh-info@princeton.edu</managingEditor><webMaster>cdh-info@princeton.edu</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License.</copyright><lastBuildDate>Thu, 20 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://rlskoeser.github.io/dhqwords/categories/gender/index.xml" rel="self" type="application/rss+xml"/><item><title>Reverse Engineering the Gendered Design of Amazon’s Alexa: Methods in Testing Closed-Source Code in Grey and Black Box Systems</title><link>https://rlskoeser.github.io/dhqwords/vol/17/2/000700/</link><pubDate>Thu, 20 Jul 2023 00:00:00 +0000</pubDate><author>Lai-Tze Fan</author><guid>https://rlskoeser.github.io/dhqwords/vol/17/2/000700/</guid><description>30 years ago these sayings were cliché, today they are offenisve [sic]. Demeaning, limiting, or belittling a woman’s contribution to a household is not quaint or cute. Prolonging or promoting sexists tropes is wrong. Maybe write a skill called Sexist Spouse. Please do better humans.
—customer review for the Amazon Alexa skill “Happy Wife”
This article examines the gendered design of Amazon Alexa’s voice-driven capabilities, or, skills, in order to better understand how Alexa, as an AI assistant, mirrors traditionally feminized labour and sociocultural expectations.</description></item></channel></rss>