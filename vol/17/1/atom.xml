<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://gohugo.io/" version="0.116.0">Hugo</generator><link href="https://startwords.cdh.princeton.edu/vol/17/1/" rel="alternate" type="text/html" title="html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/index.xml" rel="alternate" type="application/rss+xml" title="rss"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/atom.xml" rel="self" type="application/atom+xml" title="Atom"/><updated>2023-08-04T17:16:51+00:00</updated><rights>This work is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License.</rights><id>https://startwords.cdh.princeton.edu/vol/17/1/</id><entry><title type="html">Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="related" type="text/html" title="Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="related" type="text/html" title="Follow the Money?: Funding and Digital Sustainability"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="related" type="text/html" title="From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction to Special Issue: Project Resiliency in the Digital Humanities"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000660/?utm_source=atom_feed" rel="related" type="text/html" title="No Boutique or Fashionable Technologies: Project Development, Mentorship, and Sustainability in an Innovation-First World"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000669/</id><author><name>James Cummings</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>This article looks back at the technical development of two projects, The <em>CURSUS</em> project (2000-2003) and the <em>William Godwin’s Diary</em> project (2007-2010), as case studies in which outside events or internal decisions negatively impacted the project.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> The <em>CURSUS</em> project is a collection of XML editions of medieval liturgical texts, and The William Godwin’s Diary project makes available 32 volumes of Godwin’s diaries covering 1788 to 1836. Although both websites are still available, they have had difficult histories and both should be considered at risk of disappearing from the web at any moment. The <em>CURSUS</em> project faced challenges partly because the principal investigator passed away. The <em>William Godwin’s Diary</em> project suffered because the people maintaining the project were not given the resources to do so, and because all stakeholders left the institution. As the main technical developer for both of these projects, I have direct insight into the technical background and general lessons learned, which are useful to examine as case studies for each project before contrasting them with the <em>Endings Principles for Digital Longevity</em> (<a class="footnote-ref" href="#endings2021"> [endings2021] </a>; hereafter <em>Endings Principles</em> ). Although the projects pre-date these <em>Principles</em> , they are worth comparing to each other given that both of these projects are TEI-based editions and relate directly to the issues the <em>Principles</em> tackle. It is easy, of course, to criticize the technical decisions of a project decades afterwards; seeing in hindsight how the digital landscape has evolved in the meantime gives us an immediate sense that we would certainly have done things differently and definitely have made different choices. In these cases, since I was the developer and technical consultant on these projects, I do not need to guess. While I would like to think I would make better decisions now, I know that I would not unless I were time-traveling back with my current knowledge and experience. These two projects are useful proxies for examining many issues of the longevity of our research outputs.</p>
<p>Part of the overall argument I am making through these case studies is that we should always plan for events that affect the sustainability of digital research projects. Some of these events are obviously unpredictable, while others are of our own making. While we pay lip service to doing so in funding applications, once a project is under way, unexpected challenges present themselves and our solutions to them should adhere to an underlying set of principles. We need to plan for failure, plan for the project being cut short, plan for staff disappearing, and plan for all kinds of threats to the project by adopting and following principles such as those recommended by the Endings Project in the <em>Endings Principles</em> .</p>
<h2 id="_cursus_--an-online-resource-of-medieval-liturgical-texts"><em>CURSUS</em> : An Online Resource of Medieval Liturgical Texts</h2>
<p>From 2000-2003 I was fortunate enough to be employed by the AHRB-funded <em>CURSUS</em> project as a postdoctoral research associate. This project was the brainchild of Professor David Chadd of the School of Music at University of East Anglia (UEA) and sought to produce editions of medieval Benedictine Latin liturgical texts online, and experimentally to explore the use of XML publication for such materials. The main purpose was to enable investigation of the order of antiphons, responds, and prayers in these liturgical manuscripts. The project proposed that this order of service in many ways gives a fingerprint of the liturgy in different places in England. We edited these liturgical items with the utmost care, but for other aspects such as the biblical readings transcribed only the first few and last few words, since the point of the project was not to spend time making a critical edition of the Latin Vulgate Bible.</p>
<p>In the end, the project produced editions of twelve main texts and a number of ancillary works. These included an XML conversion of the Latin Vulgate Bible, derived lists of individual incipits, and a repository of liturgical items (antiphons, responds, and prayers) based on the <em>Corpus Antiphonalium Officii</em> (CAO). The approach the project used was not merely to edit a liturgical item in its context in the edition of a particular manuscript, but also to create a textual-critical apparatus in a repository with all the other textual variants from CAO and any other manuscripts edited by the project. In this way each liturgical item in the edition of a manuscript, instead of existing in the source file for that manuscript edition, is in reality a pointer to a specific antiphon, respond, or prayer in the project’s CAO repository file. Pointers are not a URI-based system in TEI P4, so extraction involves looking up the correct reading for that manuscript to display and importing it to this point through an XSLT stylesheet. This makes for a dense CAO repository file but for very light editions where most of the file is filled with pointers.</p>
<h2 id="cursus-technical-background">CURSUS Technical Background</h2>
<p>A worked example, looking at one antiphon to which the <em>CURSUS</em> project gave the ID ‘c5111’ and how this and references to it are encoded, will help to explain some of the technical details of the project.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> The c5111 antiphon appears, among other places, in the Peterborough Antiphoner<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> during the<a href="http://cursus.org.uk/ms/peterborough#Pet.07065000">Vespers service for Maunday Thursday</a>. Most manuscripts have a different date for this antiphon; all the other manuscripts edited on the project, for whatever reason, use it on the Tuesday or Wednesday of the medieval Christian Holy Week. In the underlying XML of the manuscript the pointer to this specific antiphon is encoded as in Figure 1 below.</p>




























<figure ><img loading="lazy" alt="Screenshot of a xptr XML tag with href equal to Antiphons and type equal to abody" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>An xpointer to the <em>CURSUS</em> project antiphon c5111.
        </p>
    </figcaption>
</figure>
<p>What becomes instantly obvious (to those familiar with XML markup standards at least) is that this does not follow the current TEI P5 Guidelines. Indeed, the <em>CURSUS</em> project predates TEI P5, which was not released until 2007, and uses a project-specific extension of TEI P4 XML for its markup.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> In Figure 1 a TEI P4 <code>&lt;xptr/&gt;</code> element points to the ID ‘c5111’ in the CAO repository of antiphons, responds, and prayers, and the markup instructs the processing to retrieve the content of the <code>&lt;aBody&gt;</code> element there (denoted by the value of the type attribute). A mere examination of the form of this <code>&lt;xptr/&gt;</code> in isolation does not explain much, but looking at it in progressively greater context shows more of the liturgy-specific elements that the project had added to its use of the TEI. The (custom) <code>&lt;antiphon&gt;</code> element that surrounds it is seen in Figure 2.</p>




























<figure ><img loading="lazy" alt="screenshot of XML code with antiphon and rubric tags" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>An <code>&lt;antiphon&gt;</code> element from the <em>CURSUS</em> project.
        </p>
    </figcaption>
</figure>
<p>In Figure 2 the mixture of TEI P4 elements (such asadd,hi,supplied,andxptr) and the project’s own additions (such asantiphonandrubric) are evident. Once the project’s principal investigator learned of the extensibility of the TEI as a system, he preferred discipline-specific terminology for important aspects of the text. Although there are differences between this markup and what one might see today in TEI P5, the general intentions and interpretations of the markup are still relatively clear.</p>




























<figure ><img loading="lazy" alt="screenshot of xml code with tags such as antiphon, incipit, and rubric" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The entire <em>CURSUS</em> project encoding of the Vespers service that contains antiphon c5111.
        </p>
    </figcaption>
</figure>
<p>Even in the full context (Figure 3) of the entire Vespers service that contains antiphon c5111, there are only a few additional non-TEI P4 elements (such asDay,service,andincipit). What starts to become evident through these examples, at least to those familiar with TEI P4 markup, is that this project took full advantage of a TEI DTD-based feature allowing the creation of custom DTD entities for repeated formulaic text, punctuation, and markup that are very common in the highly repetitive liturgical documents. This means that the encoders did not need to include repetitive portions of markup, and merely used a smallerentityto stand in for that markup. Even in the context shown through the markup in Figure 2, the use of the entity <code>&amp;AE;</code> at the beginning of the <code>&lt;antiphon&gt;</code> element demonstrates this exploitation of a technical method of providing formulaic text and markup. The cursus.ent file listing the project’s DTD entities expands this as seen in Figure 4.</p>




























<figure ><img loading="lazy" alt="screenshot of XML with the A and AE elements" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The <em>CURSUS</em> project DTD entities file showing theAandAEentities.
        </p>
    </figcaption>
</figure>
<p>In this file theAEentity is shown to be expanded to a string of textual markup showing the rubricated textIn Evangelio.Moreover, this formulaic text itself recursively includes an additional custom entityAwhich is replaced with the rubricated labelAnt.While there are a number of drawbacks to such a system that mean it would not be recommended today, it was an imaginative exploitation of the ability of DTD-linked documents to provide re-used bits of text and markup.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> However, this approach does introduce a significant fragility based on all files’ dependence on the DTD and entities file being present and accessible at the time of processing. If the files were to be normalized to TEI P5 XML, then a conversion process would have to begin with a basic identity transform which would expand all of these entities into their non-entity form.</p>
<p>This discussion explains what the encoding of the xpointer only for antiphon c5111 looks like solely in the context of one of the manuscript edition files, but the content of the antiphon is stored with all its textual variants in the CAO repository file. Figure 5 gives an example of this file.</p>




























<figure ><img loading="lazy" alt="screenshot of an encoded repo with many app tags" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The <em>CURSUS</em> CAO repository file antiphon entry for c5111
        </p>
    </figcaption>
</figure>
<p>New elements that the project introduced here (including ant, header, usage, and aBody), like most of the additions made by the project, could have been modeled in other ways with TEI elements. For example, the <code>&lt;ant&gt;</code> element could have used a TEI <code>&lt;ab&gt;</code> (anonymous block) element. However, in customizing the TEI, the project used element names that made sense for its encoding needs. The bespoke markup and TEI P4 XML of this project could, should there ever be a need, be converted to TEI P5 XML to be used in a modern production environment. Indeed, it is because of the adoption of the open international standard of the TEI that the markup would be straightforward to convert, even in the case of this extensive customization. The entries in the header are given as standardized numerical codes for all days of the medieval liturgical calendar created by the <em>CANTUS</em> project and are used to generate the links into the manuscript editions.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Similarly, the website generated version of the files automatically adds in the IDs of the previous and next liturgical items to the enriched form of the antiphon during the process of extraction by XSLT stylesheets into individual files. These are pieces of convenience data to enable easier processing of the underlying XML for online browsing.</p>
<p>Figure 6 shows the HTML view of this CAO repository entry – the entries are all browseable online and are dynamically transformed to HTML pages on the fly. The textual variants are laid out in parallel boxes showing their mutual differences with the witness sigils discreetly present, mimicking the underlying TEI parallel segmentation markup. In modern websites, these variants would likely be presented in a very different manner – the interface certainly shows its age, having been created in 2002.</p>




























<figure ><img loading="lazy" alt="screenshot of the critical edition of antiphon webpage. The title of the page is at the top in green and the repo form figure five is displayed below" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>A <em>CURSUS</em> antiphon web page for antiphon c5111.
        </p>
    </figcaption>
</figure>
<p>This form of interlinking between manuscript edition and repository entries, which then link through to all the other places this antiphon is used, promotes a circular and generally beneficial form of user experience in the navigation. While the XML files store most of the intellectual output of the project, preserving only the XML files would mean that we would lose the argument presented by the interface for how we should interact with such editions. The aspects of interface as edition might be lost if we look only at the underlying files; the edition itself is a publication that includes not only the underlying data but the manner in which it was presented. The output of projects is not only the data they produce but the way in which those products are presented to the end user — when research is published in print, the book is the product, not the research notes or data that underlie it; in other words, the interface is the means of preservation. However, as with many digital resources, perhaps in a demonstration of an appreciation of the much vaunted but seldom realized re-use of materials, we concentrate on the underlying data as the primary output to the detriment of other aspects of the outputs. As a historical artifact representing digital editions from this period of our development in thinking about how to present such editions online, the CURSUS interface deserves preservation or conservation, in the same way one might argue the primary source documents do.</p>
<h2 id="_cursus_-project-afterlife"><em>CURSUS</em> Project Afterlife</h2>
<p>By 2003 the main <em>CURSUS</em> project was completed. Professor David Chadd and I had edited more manuscripts and produced more additional outputs than promised in the AHRB funding bid — but my contract came to an end, so I left UEA for a post at the Oxford Text Archive, University of Oxford. However, Professor Chadd continued work and did not really consider the project concluded, only its funded portion. He occasionally continued to update the website, and, in order to simplify some of the underlying publication technology and assist with technical aspects generally, he later employed Dr Richard Lewis (then a departmental postgrad).<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> This ongoing work meant that the project never reached a point at which Professor Chadd felt that working files could be canonicalized in their final form.</p>
<p>Sadly, in late 2006 Professor Chadd died after a short illness. Although his passing did not immediately affect the website, it did truly bring the project to a close. Professor Chadd had continued to edit manuscripts as and when he could up until his death, but, because he was not using a version control system or frequently uploading these to the website, his final work has been lost.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> But even death was not the most impactful event in the <em>CURSUS</em> project afterlife.</p>
<p>More dramatically, an event totally unrelated to the <em>CURSUS</em> project in November 2009 had a severe detrimental impact upon it: a hacker illegally obtained over 1,000 emails spanning 13 years, along with 3,000 other documents, from the Climate Research Unit at UEA. A combination of ignorance and willful misunderstanding meant that even any unprofessional or confusing comments in them were used by climate change deniers to spread misinformation. This event became known asClimateGateand as a result UEA temporarily closed all off-campus access to its servers.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup></p>
<p>Originally, we had “set up one of the project’s desktop machines as a Debian Linux server” <a class="footnote-ref" href="#cummings2006"> [cummings2006] </a>but shortly before leaving I suggested it might be best to make it more official, and in my mind more stable, on a departmental server. Throughout all the tumultuous events above, even though the PI of the project had passed away, the <em>CURSUS</em> website continued to run unproblematically on the School of Music departmental server. The site had begun to be cited in journal articles, and not just by those directly concerned with musicology or digital publishing<a class="footnote-ref" href="#licence2006"> [licence2006] </a>.</p>
<p>However, sometime in 2010 a software upgrade on that server caused the website to go down, and it needed a configuration change and a restart. With the continuing ban on off-campus access and the fact that neither Dr Lewis nor I were in Norwich or had worked for the university for a few years, we had no easy way to restart the server. By this point the School of Music had little IT support, and UEA’s central IT had no ability to take on these extra duties. Indeed, later in 2010 the School also replaced their departmental server with a new one – having no local champions or even people who knew much about this legacy site, the <em>CURSUS</em> website at the University of East Anglia finally disappeared.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>
<p>We had backed up the latest version of the data on the server shortly after Professor Chadd’s death, of course, and it was around this time that I first contacted UEA to discuss getting the rights to put the website up again or hosting it elsewhere. Starting with the School of Music, who disavowed any responsibility for the site, I was eventually put in touch with UEA’s Commercialisation Manager from Research and Enterprise Services. A slow process of back-and-forth explanations resulted in 2016 in a Creative Commons Attribution Non-Commercial license for the intellectual property – after six years of negotiation – for a project that always had intended its data to be open but hadn’t explicitly licensed it as such.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> Indeed, UEA had eventually closed its School of Music in 2014, after hard-fought campaigns to keep it, so even the academic department that had created and hosted this project was now gone<a class="footnote-ref" href="#cunnane2011"> [cunnane2011] </a><a class="footnote-ref" href="#bbc2011"> [bbc2011] </a>. The closure of the department caused additional confusion as it was unclear to the university who in authority might give permission to license this data. But perhaps we did not even need permission: UEA as an institution did not even know it owned this data and the project’s intention was always to release it openly. An alternative, more assertive approach, would have been to put the site up while simultaneously pursuing the permission to do so.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> While the website is still up, the problems noted above concerning sustainability of such resources indicate that even to preserve the project as a working resource has an inherent fragility. If it is not practical or feasible to preserve such resources, recording a screencast video using the website might be one solution at the very least to document the ephemerality of user experience and interaction for the future.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup></p>
<p>Since 2016, the site has been hosted on a small personal VPS run by Dr Lewis and the<a href="http://cursus.org.uk/">cursus.org.uk</a>domain name (paid for by me), and the underlying data and code stored in GitHub.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> This arrangement is contingent and precarious; Dr Lewis might decide to stop hosting the site or I might not continue to pay the domain name registration fee. Although people still do use the site and the data, it raises the question of when and how to retire websites and merely preserve the data in case someone wishes to re-use it at a later date. Part of our reason for hosting it is a feeling that the main constituency of users would find the data hard to use in its underlying format. A compromise would be to undertake a project to flatten the website, removing any need for server-side processing and make this available online in a variety of forms. As the website was mostly static (only the XML to HTML transformations being dynamic), it would be easy to flatten it. The XSLT stylesheets and an HTML copy of the website as currently served (with relative links) was added to maintain a coherent version in the zip archive uploaded to Zenodo.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> Updating the data to be more usable, for example converting to TEI P5 XML, is not a large project but would take a bit more work to rationalize the bespoke elements (only lightly documented in the DTD — these days we would document these extensions fully with a TEI ODD).<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup></p>
<h2 id="lessons-from-the-_cursus_-project">Lessons from the <em>CURSUS</em> Project</h2>
<p>Numerous red flags and warning signs indicated that the <em>CURSUS</em> project was at-risk and not properly preserved. Two decades on, it would be gratifying to be able to say that digital humanities projects no longer do such things. Alas, we cannot. However, there have been significant changes that make the preservation of project outputs more likely. For example, instead of keeping the master copy of data on the PI’s laptop, digital humanities projects now use GitHub routinely to store both versioned code and data while enabling collaboration.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> Instead of using departmental servers stored under someone’s desk to host funded research projects, we now use institutional or virtual machines hosted in the cloud. Major institutional and international data repositories now exist for depositing copies of research outputs but did not at the time.</p>
<p>The majority of problems in the project’s afterlife are those that we did not reflect upon at all while the project was running. For example, we never considered the so-calledBus Factor– the minimum number of people who have to vanish from a project before it completely stalls due to the lack of necessary knowledge to sustain it. In this case it was Professor Chadd’s sudden death and the fact that legacy planning for the project site had not been undertaken. Since no other project staff were still employed by UEA, the intellectual content of the project could easily have slipped away. It is only because Dr Lewis and I wanted to preserve it, partly as a tribute to Professor Chadd’s legacy, that it survives at all. We should also recognize the <em>CURSUS</em> project’s strengths – in being fairly simple TEI-based XML with XSLT 1.0 conversion to HTML (albeit dynamic) without any JavaScript or additional libraries, it could easily be migrated and preserved. It is, I would argue, the relative simplicity of the site that has enabled its preservation. Just as a physical object in good condition might be preserved by benign neglect, this website’s minimal footprint, structured text-only content, and generally uncomplicated needs, enabled it to survive relatively well despite being subject to benign digital neglect. More active interventions and conservation might have resulted in the use of more advanced frameworks, features, or libraries, as these became popular, causing more long-term harm for its sustainability than otherwise (see Holmes and Takeda in this issue).</p>
<p>One of the reasons for describing the technical background of this project, and giving the detailed explanation of their use of the TEI Guidelines, is that it demonstrates the kind of complexity that could be achieved within the <em>Endings Principles</em> . To be clear, the <em>CURSUS</em> project does not meet those requirements since, in its current form, it still requires bespoke dynamic pipelined conversion of the underlying XML to HTML. While the experimental DTD-based markup entities were interesting, the fragility they introduce means such an approach should have been used only for the development of materials, not the publication copies. It would have been better to expand all the custom entities in all the files (as well as normalize the markup vocabulary) for a publication version, but with the ongoing nature of the project as Professor Chadd worked towards his (sadly unachieved) retirement, the curse of the perpetual beta meant that it never quite seemedfinished.It would have been better if regular fixed releases were made, where the production system files (as opposed to the development version) were always in their final canonicalized forms. The server-side dynamic transformation does not add much that, with hindsight, could not have been accomplished with pre-generated flat files. The project was experimenting with various methods of digital publication of TEI-based XML and relished the idea of being “able to have virtual URLs, allowing our users to create dynamically-assembled pages from a variety of XML source files” <a class="footnote-ref" href="#cummings2006"> [cummings2006] </a>. It would have been better to pre-generate output files with massive redundancy of every possible view as the <em>Endings Principles</em> suggest.</p>
<p>A lesson for encoding and technical expectation management might be drawn from the number of new custom entities and bespoke elements the project created. Once Professor Chadd discovered the ease with which we could create new bespoke elements, his default approach when a new textual phenomenon or encoding problem was encountered was to create a bespoke element. Taking the easiest approach in any digital project always results in trade-offs and compromises for longevity. This approach sometimes meant that we were encoding things with new project-specific elements rather than looking slightly harder in the community for standardized approaches and solutions. While the <em>CURSUS</em> project was groundbreaking in some of its experiments in the publication of digital medieval resources, hindsight reveals some problems which should have been foreseen at the time.</p>
<h2 id="william-godwins-diary">William Godwin’s Diary</h2>
<p>A similar story is that of the <em>William Godwin’s Diary</em> project at the University of Oxford, which ran several years after the <em>CURSUS</em> project. Funded by the Leverhulme Trust from 2007-2010, this project coincided with the Bodleian Libraries’ receipt of funding from the National Heritage Memorial Fund and various donations to buy the Abinger Collection which, among many other things, includes William Godwin’s diary. Godwin “was the founding father of philosophical anarchism and was also a major novelist, although he is perhaps better known today as the husband of Mary Wollstonecraft and the father of Mary Shelley” <a class="footnote-ref" href="#philp2021"> [philp2021] </a>. His diary contains 48 years of records in 32 octavo notebooks, written in often highly abbreviated entries that the project had to decipher and disambiguate. People’s names are often given only as initials and there is little detail concerning the substance of any meetings and the meaning thereof can be hard to decipher.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> Initial transcriptions provided as MS Word documents were converted to TEI P5 XML.</p>




























<figure ><img loading="lazy" alt="Image of a manuscript page from the eighteenth century. The page includes life events like births." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>William Godwin’s diary entries including that of 30 August 1797 where he, concisely, notes the birth of his daughter Mary (later Mary Shelley) at 11:20pm.
        </p>
    </figcaption>
</figure>
<p>The project was interested in highlighting relationships between Godwin and other people and extracting datasets of information from the diaries. To do this, I trained a team consisting of the PI (Professor Mark Philp), a postdoctoral research associate (Dr David O’Shaughnessy), and two DPhil students (Kathryn Barush and James Grande) in a project-specific TEI P5 customisation that was very reduced and used renamed elements to make encoding these entries easier.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> The XML they were hand-encoding in successive passes consisted of fewer than 20 separate elements in total but was automatically expanded to full TEI on the website each evening. So while the project might encode using a non-TEI <code>&lt;dMeal&gt;</code> (diary meal) element, the renamed element was converted to a pure TEI <code>&lt;seg type=&quot;dMeal&quot;&gt;</code> element in the production XML<a class="footnote-ref" href="#cummings2008"> [cummings2008] </a>. Similarly, the project workflow meant checking work into an institutional Subversion version control system; unlike the <em>CURSUS</em> project, the real risk of data loss, while never zero, was minimal. The overall training took just over a day, but the project benefited by having me as their on-call technical support when they needed it.</p>
<h2 id="_william-godwins-diary_-technical-background"><em>William Godwin’s Diary</em> Technical Background</h2>
<p>The website was built on top of an early version of eXist-db (a native XML database) that at the time used Apache Cocoon for URL-based pipelined conversions, with which I was familiar from the <em>CURSUS</em> project. I had experimented with eXist-db during the <em>CURSUS</em> project; an XML database was desired because of the nature of the queries to be done — again on the fly — against a fairly complicated XML dataset. At the time, the popular idea that it “may not be possible to achieve one input — <em>all</em> outputs, but surely one input — many outputs is an entirely practical goal” <a class="footnote-ref" href="#walsh2002"> [walsh2002] </a>was brought from the <em>CURSUS</em> project and taken to heart. The project leads viewed it as not only feasible but also desirable to generate many of the project outputs from a single or at least small number of input datasets. Indeed, the project tried to create a network of interlinked inputs that generated a network of intertwined outputs that would decentralize any starting point and thus be open to exploration. The <em>William Godwin’s Diary</em> site, a “finely engineered architecture of XML tagging[,] allows the user to trace acquaintances across the decades, books through his library catalogues, and the author himself through the streets of the metropolis” <a class="footnote-ref" href="#bullard2013"> [bullard2013] </a>.</p>
<p>The project methodology of working in phases (first adding structural markup, then adding markup recording meetings, then recording and eventually identifying people, places, and events) meant the encoders always moved on to a new year of the diary they had not seen before. This iterative but distributed process meant that fresh eyes saw each entry several times, thus acting as additional proofreaders to reduce human error. From the point of view of the <em>Endings Principles</em> , this methodology ensured that after each phase the content was coherent and complete (as far as it went).<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> This methodological approach is something that many DH projects use to ensure a phased production of output work. The encoders also had diagnostics using a local XSLT stylesheet to transform their work into a debuggingproofreader’sview that allowed them to spot mistakes through formatting realized in a manner that could never be acceptable in a user-oriented front end. This view highlighted any elements that should have had content but didn’t, and coloured things in a way to emphasize aspects that had not yet been completed.</p>
<p>The website infrastructure was fed directly from the Subversion repository and automatically produced a number of views on the website when updated each evening. The nightly jobs would transform any updated (but well-formed and valid) files into pure TEI P5 XML, load these into the eXist-db database and regenerate a wide variety of tables of information. These included not only lists of plays Godwin went to or books he was reading/writing, but also detailed tables of meals he had (and whether he was dining with the person or the person was dining with him), and other forms of meetings. These were displayed using the external jQuery library DataTables plug-in to provide a filterable, pageable, sortable view of the data that would certainly be against the <em>Endings Principles</em> if they had existed at the time.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> The level of detail of the encoding and cross-references throughout are what enable the site to provide detail to researchers using it. As one reviewer wrote,</p>
<blockquote>
<p>What makes the site an amazing research tool is the level to which Godwin’s meticulous (but brief) notes are cross-referenced against one another, creating a vast web of information that not only fleshes out the skeleton of the author’s life, but also provides a wealth of information about Romantic-era social networks and day-to-day life in the London of the period.<a class="footnote-ref" href="#thomas2018"> [thomas2018] </a></p>
</blockquote>




























<figure ><img loading="lazy" alt="Image of the _William Godwin’s Diary_ project web page. The page includes a table of meetings with dates and diary entries" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>DataTable of meetings where Godwin was calling on a person
        </p>
    </figcaption>
</figure>
<p>As one might expect, the diary data itself is organized chronologically. Each diary day is represented by a TEI <code>&lt;ab&gt;</code> element with a @type attribute ofdDayand is required to have an @xml:id attribute based on the date. Each diary entry is required to have a <code>&lt;date&gt;</code> element with a @when attribute provided in W3C format, but the element will have transcribed text content here only if it existed in the diary. The production server markup uses only standard TEI elements, with arbitrary segments denoting meals, meetings, or similar concerns of the project using the <code>&lt;seg&gt;</code> element.</p>




























<figure ><img loading="lazy" alt="Screenshot of encoding for the _William Godwin’s Diary_ project. Some of the tags includes are persName and placeName" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The <em>William Godwin’s Diary</em> XML entry for 1 August 1797.
        </p>
    </figcaption>
</figure>
<p>One of the major intellectual contributions of this encoding work — and a significant demonstration that good text encoding really is research in itself — is the identification and deduplication of 50,000 of the 64,413 instances of names in the diary.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> In Figure 9, they are mostly given as their surnames, but evenA Ais identified and points directly to the website’s ALD02.html file where information about Amelia (Opie) Alderson and her 119 appearances in the diary is provided. Arguably, the data should have pointed to the underlying XML file (ALD02.xml) but this file URI was provided as part of the transformation to pure TEI for the website as a processing convenience. Similarly, the decision was taken early on that when a person’s name was mentioned as a venue where a meeting took place, the encoders would denote this distinction for various project needs, by embedding a <code>&lt;placeName&gt;</code> of <code>@type</code> venueinside the <code>&lt;persName&gt;</code> content. While this might have made more sense the other way around (a place name which had a personal name as its content rather than a personal name that had a place name as its content), this method was chosen for consistency with other decisions on the project.</p>




























<figure ><img loading="lazy" alt="Screenshot of the _William Godwin’s Diary_ project website. The page includes diary entries for the month of August" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The <em>William Godwin’s Diary</em> website showing the beginning of August 1797.
        </p>
    </figcaption>
</figure>
<p>The display of the diary entries themselves is as running text based on calendar entries. One can view a single day, a particular month (as in Figure 10), or a whole year at a time, all extracted dynamically from the underlying XML year file. Clicking on the year, month, or day in the accompanying calendar provides an easy form of date-based navigation for users. All of the transformations are done dynamically, converting underlying XML with XSLT to HTML for display. However, in some cases the query to discover, extract, and then convert the XML took so long that pre-cached static copies of the XML were created.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> As one can tell from Figure 10, almost all the content of the diary entries links to more information. Any mention of people, places, meals, meetings, texts Godwin was reading or writing, topics discussed, or events links to more information about that named entity. In the display of the website, jQuery is used to toggle on/off highlighting of these to enable people to discover them more easily. If one toggles on highlighting of people, for example, then all the names of people are highlighted with a light pink box.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> If one clicks on a name — for example, in Figure 10, the nameJohnson’sin theDine at Johnson’sin the entry for the 1 August 1797 — the name links to a page assembling not only the project-provided biographical details, editorial notes, and bibliography concerning the identified Joseph Johnson, but also an automatically-generated chart and details of all of his appearances in the diary that can be used to navigate back through the diary (Figure 11). This page includes some basic statistics, here that he was mentioned 413 times, not at home when Godwin called in 23 times, and listed as a venue 324 times. The statistics clearly indicate that Godwin called on Johnson much more than the reverse and that he also liked to host gatherings of all sorts that many attended – the data providing rich views of their interactions over the course of Godwin‘s life. Through such techniques, the site navigation still creates a richly encoded endless loop of exploration for researchers over a decade later, as noted by Thomas:</p>
<blockquote>
<p>Part of the intent behind the site’s extensive interlinking is to allow readers to navigate the diary in any order that they choose, permitting a type of exploration that facilitates serendipitous insights (and, for enthusiasts, affords the simple amusement of searching for whatever the author was doing on any given day).<a class="footnote-ref" href="#thomas2018"> [thomas2018] </a></p>
</blockquote>




























<figure ><img loading="lazy" alt="screenshot from the _William Godwin’s Diary_ project showing entries mentioning Joseph Johnson" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The <em>William Godwin’s Diary</em> person page for Joseph Johnson.
        </p>
    </figcaption>
</figure>
<p>Another direction of travel from the diary pages is to click on the thumbnail for that week’s page image. As part of the agreement in receiving funding to purchase the Abinger Collection, the Bodleian Library imaged all of Godwin’s diary. The project PI decided strongly against the facing-page Text/Image that is common in many digital scholarly editions. Instead, he wished to privilege the edited text, only providing links to the images as thumbnail images that are placed alongside each page of text as a way of making these linked resources available. However, linking through to these images has proved very useful to those undertaking Godwin studies who now routinely include snippets of them in their slides and articles.</p>




























<figure ><img loading="lazy" alt="Screenshot of _William Godwin’s Diary_ website with a manuscript page in the middle zoomed in to show only a few letters." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The <em>William Godwin’s Diary</em> pan/zoom Google Maps-driven image viewer.
        </p>
    </figcaption>
</figure>
<p>The images were taken and tiled, and a pan/zoom image viewer was built using the Google Maps API, long before collaborations such as IIIF were available (Figure 12). Today, a project would simply embed a IIIF viewer for the digitized images that the Bodleian makes available on its Digital Bodleian website, even though doing so introduces a dependence on an external service. Indeed, one of the reasons the images proved so popular with researchers was not the easy interface, but the fact that we provided a link to the full high-resolution image and had (after much effort) convinced the Bodleian to license the images with a Creative Commons Attribution license. With this full image, researchers could crop the portions they were discussing and use them in their conference presentation slides. However, the necessity of having both the full high-resolution image and pre-generated tiles for each of the page images at each level of magnification added significantly to the size of the virtual machine to be requested, which in turn may be partly why it was only reluctantly hosted by the Bodleian Library. For a project following the <em>Endings Principles,</em> there is a calculation to be done concerning any additional storage costs for hosting its images locally versus the fragility of pointing to an external institutional image server.</p>
<h2 id="project-afterlife">Project Afterlife</h2>
<p>The project ran successfully and completed on time and budget in 2010, and in 2012 won an award for Digital Resources from the British Society for Eighteenth-Century Studies.<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> Shortly afterwards, the DPhil student assistants completed their theses, and the postdoctoral research associate moved on to another university, and within a few years the PI of the project moved on to the University of Warwick. The project Twitter account continued to tweet out diary entries every few hours (until a Twitter authentication change meant the script started to fail). Nevertheless, although the project was over, the website continued to function, relatively unproblematically. And yet, one of the aspects of hosting that was problematic with the <em>William Godwin’s Diary</em> project was the question of where institutionally the website was to be hosted. As the Bodleian Libraries did not yet have a centralized media server (now<a href="https://digital.bodleian.ox.ac.uk/">https://digital.bodleian.ox.ac.uk/</a>), and the images were hosted locally on the virtual machine (VM) that housed the website, the VM would need to survive with all it needed, but this need meant a fairly large (for the time) VM. The availability of resources always affects projects’ afterlives.</p>
<p>One of the reasons for mentioning (above) the sources of funding for the Bodleian’s purchase of the rest of these (and other) materials of the Abinger Collection was that as part of the purchase agreement the library had promised that web hosting for this project, like the imaging, would be provided pro bono. At the beginning I brought together representatives of the project with those from Bodleian Digital Library Systems and Services, who agreed to provide a suitable VM inside the Bodleian Libraries’ infrastructure. When it came to it, however, since I was the sole technical developer on the website and happened to work for the Oxford University Computing Services (OUCS), the Bodleian decided that I should just set up a VM in Computing Services, and that they would transfer it over to their infrastructure at the end of the project. At the conclusion of the project, the Bodleian then made the argument that the OUCS VM was working well, and so even though it had a Bodleian URL there was no pressing reason to move the underlying VM to their infrastructure. It was only several years later, when the Computing Services (by then IT Services) and Bodleian Library were both having major upgrades to their VM infrastructure, that I finally convinced them that the VM should be moved under the Bodleian Library’s care. The operating system itself was updated to the latest long-term support version, but as I had only limited time to donate to the project, the version of eXist-db (now quite ancient) was not upgraded and just copied across. Even so, the VM remains one of those VMs on an older infrastructure on the outskirts of the purview of Bodleian’s overworked infrastructure team.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> As it is, the website occasionally needs a restart; when the VM is rebooted, the website does not automatically start, and occasionally a small partition fills up with log files.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> Both of these are problems that would have been addressable while I had access to the server, but in an immediately post-project setting, it never seemed important enough to ensure such access. While I would restart the website maybe once or twice a year while working there, I have had no local access to the server since I left the University of Oxford in 2017; as there is no one connected to the original project left at the institution, restarting falls to the busy infrastructure team of the Bodleian Library. This need to care for legacy websites and their compounding maintenance burden will become only more pressing as we continue to produce digital projects that are deemed too important to justturn offafter a discrete period.</p>
<h2 id="lessons-learned-from-_william-godwins-diary_">Lessons Learned from <em>William Godwin’s Diary</em></h2>
<p>It may sound as though I am faulting the Bodleian Libraries, and especially the Bodleian Digital Library Systems and Services section, for not providing a VM at the beginning of the project as they had promised to do. And while they should have done so and enabled development or at the very least a production server to be hosted on their infrastructure, I certainly have sympathy for their point of view. Before the start of the project, the upper levels of the library administration committed them to providing support from system administrators but without providing any extra resources to the staff to enable this additional work. The necessary imaging of materials was provided, pro bono, and they promised to host the website but, when the development of the website had finished, hosting was understandably not a priority task for them. If I had been working directly for the Department of Politics and International Relations (where the project originated) and had not had sophisticated local IT resources at the time, then there would have been no question that the Bodleian would have provided the necessary infrastructure — the project would have been impossible without it. However, I happened to work for the Oxford University Computing Services, and so I had easy access to VMs and it seemed natural to them that I should provide these at no extra cost or immediate effort from them. This kind of approach is dangerous, and projects should be sure to get formal agreements of in-kind support where feasible.</p>
<p>This project relied on a single developer (me) to provide some degree of unpaid support long after the project had finished. This is why the <em>Endings Principles</em> are so important – they encourage discussion of the project afterlife. In the case of the <em>William Godwin’s Diary</em> project, the project team gave little consideration to what would happen to the site after it was handed over to the Bodleian. Much like a physical output such as a book, everyone seemed to think it would be handed over and that would be that. But digital research outputs are not like books; they demand care and attention, however fleeting, irregular, and inconsistent. This remains true, though to a much lesser degree, of static websites as well which at very least need servers to run on. While of course I had backups of the <em>William Godwin’s Diary</em> data, and it was deposited in the institutional repository, after my departure in 2017 I no longer had access to the server or Subversion repository. I only got around to uploading the underlying data and code to an open GitHub repository in November 2019.<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> I had also previously provided a full copy of the data to the <em>Shelley-Godwin Archive</em> at the Maryland Institute for Technology in the Humanities, who have had their own ongoing maintenance burden for the sites they create<a class="footnote-ref" href="#munoz2015"> [munoz2015] </a>.</p>




























<figure ><img loading="lazy" alt="Screenshot of a Google Maps errors informing the viewer that the map cannot load" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Google Maps API error on <em>William Godwin’s Diary</em> website.
        </p>
    </figcaption>
</figure>
<p>Using freely-available but proprietary systems like the Google Maps API to build a pan/zoom image browser was always going to be a compromise.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> The API has had major backwards-incompatible updates at least twice since the project adopted it. Indeed, I am amazed that it still works at all. There is an error message notifying the user that it cannot load Google Maps, but the message can be easily dismissed and the viewer functions as before, since all of the image tiles needed are on the local server. As I mentioned earlier, if built today the project would certainly have used the IIIF media server that the Bodleian has set up in the meantime. With archival digital image resources there is an open question on how best to interact with them and still adhere to the <em>Endings Principles</em> . In discussing these issues as part of the <em>Endings Project</em> Symposium, Martin Holmes pointed out that the use of IIIF might imply a viewer (such as Mirador) with server-side requirements and the consequent longevity problems inherent in any such software. This is true if the IIIF is hosted as part of the project website, but one could design the site so that only the remote media server’s viewer were used (embedding or merely linking to it) and if one day the images disappeared, the site could degrade gracefully, presenting only the text view. For some projects, a fine balance must be struck between treating whole remote collections of images as research objects and hosting these resources locally<a class="footnote-ref" href="#fenlon2019"> [fenlon2019] </a>. A centralized institutional image store may make sense, especially where the same set of images may be used for multiple projects, but it needs to be carefully incorporated into the site in a manner that prepares for graceful degradation of any linked resources.<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup></p>
<h2 id="comparison-with-the-_endings-principles_">Comparison with the <em>Endings Principles</em></h2>
<p>There are certainly a number of commonalities between the <em>CURSUS</em> and <em>William Godwin’s Diary</em> projects (other than my involvement) from which we might learn. The latter project, having been developed some years later, benefited from some of the lessons learned from CURSUS.</p>
<p>Technology is bound to change — some of what now seems impossible will become plausible and eventually a reality and developing the resources of the future will inevitably be different. Indeed, in archive-based research projects digitizing and exploiting textual sources the development and significant improvements made to handwritten text recognition (a machine-learning-based technique for transcribing handwritten documents, though also applicable to print) promises the glimmering hope of an age where whole archives (or those materials in similar scripts at least) will be able to be transcribed (c.f.<a class="footnote-ref" href="#terras2021"> [terras2021] </a><a class="footnote-ref" href="#muehlberger2019"> [muehlberger2019] </a>. With a wealth of text available, some will exploit these corpora through programmatic analysis, but others will want to edit and up-convert the material to provide interpretation and make it more accessible to readers. As expected, the <em>Endings Principles</em> for most projects do a good job in suggesting some ground rules that will always result in easily archivable outputs.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup> Looking at these Principles in comparison to the projects above will highlight some of their many flaws but looking at these points of failure gives us a method by which we can improve.</p>
<p>In the creation of the data, the <em>CURSUS</em> project did not conform to open standards. While based on TEI P4, the encoding diverged from P4 significantly and did not put the effort into canonicalizing the data before release.<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> Similarly, the files were not really subject to version control.<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> The <em>William Godwin’s Diary</em> project was better in sustaining itself these areas, by using standard TEI P5 and a Subversion repository. Both did employ validation and diagnostic analysis of a sort.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup></p>
<p>Neither site truly meets the principles for documentation, in that while they provided some high-level project documentation about the content, neither documented the technical infrastructure very well.<sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> Although the <em>CURSUS</em> project had a commented DTD, it merely noted the element that was being added; it didn’t explain any rationale or give a description of it. With full hindsight, CURSUS should have followed the <em>Endings Principles</em> on licensing; although the original web page stated that the outputs were releasedopenly, establishing the rights after the fact was a major hurdle.<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup> This lesson had truly been learnt by the time of the <em>William Godwin’s Diary</em> project, which licensed all of its materials with a Creative Commons Attribution Non-Commercial 3.0 license.</p>
<p>In the websites’ processing, there were also good and bad aspects. As they were XML-based systems, the source files were always valid against a defined schema, though therelentless validationdid not always extend to the HTML and CSS.<sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup> While these were both validated at one point, the validation requirements have also changed in the intervening decades, as guidelines for web accessibility have improved. Neither site had true continuous integration, but both had some degree of automation for the generation and testing of the sites.<sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup> TheGodwinroject had a variety of behind-the-scenes automated testing, proofreading, and checking before any file was copied into the database. The processing code was treated similarly, though should have been recognized as being more contingent.<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> The benefit of a static site for some projects in conforming to the <em>Endings Principles</em> (long after these two projects) is the reduction in the burden of server-side processing, that is, making sites “untethered from the processing that created them” (Holmes and Takeda in this issue). Both of these projects have benefits resulting from those aspects that are static, but fragility still exists.</p>
<p>The main fragilities of the two projects lie in their production of outputs/products. Both were dependent on server-side software, <em>CURSUS</em> merely for searching and pipelining dynamic transformations to HTML, but <em>Godwin</em> for its entire XML database-backed infrastructure.<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup> The <em>Godwin</em> project, in using jQuery for a number of aspects, fails at the <em>Endings Principles’</em> caution against fashionable technologies and external libraries or services.<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup> CURSUS is better here, as many of these technologies either did not yet exist or were too complex to use, but suffers the opposite problem in having later created bespoke server-side software (e.g. PyCoon). I suspect that these will be some of the hardest Principles to convince developers to follow since they often love fashionable external libraries and services that appear to make their urgent tasks easier in the short-term.<sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup></p>
<p>Neither site has URLs that contain query strings and both have straightforward URLs for all individual entities on the site.<sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup> The two sites also provide all the underlying data for download, though both could do better at documenting it.<sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup> While both sites do provide all the necessary data in order to function in the page, they do not truly meet the ‘massive redundancy’ that the <em>Endings Principles</em> suggest.<sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup> In both projects, while an individual page might have all the text necessary for its own functions, it might link to a shared liturgical item as a source that can take users to other pages, or provide additional prosopographical information never intended to be embedded in that individual page.</p>
<p>Both sites meet the principles of graceful degradation reasonably well. As primarily text-based sites, they function fairly well, though in an even uglier way, with JavaScript and CSS turned off.<sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup> With <em>CURSUS</em> this functionality is partly because it predates the mass adoption of JavaScript and uses only fairly simple CSS. With <em>Godwin,</em> conscious attempts were made to enable graceful degradation; in reality, this approach only means mitigations such as a system whereby clicking on the main menu item with JavaScript disabled leads to a page containing the menu sub-items as a nested list. Happily, this choice is also beneficial for user navigation with touch interfaces, whose popularity was only beginning at that point, and is something that is still sometimes neglected even in responsive mobile sites.</p>
<p>Two concessions in the <em>Endings Principles</em> <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup> (that good static websites generated from data may be enhanced with server-side tools like eXist-db or external libraries) might justify some aspects of the <em>Godwin</em> website, but not convincingly, since these tools were the foundation of the site rather than an added extra. This concession might have justified adding a Swish-E index to the <em>CURSUS</em> site, although Swish-E has since been removed because it failed when the site was rehosted.</p>
<p>Neither site fully met the principles for release management. In both cases the website was updated as and when particular data was available or software improvements were complete, with no news items, warnings, or even public version numbering.<sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup> While all files are valid, the project release could not be said to be both coherent and complete, or have an edition/version number.<sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup> Neither site gives unambiguous information on how to cite any specific page of the resource, although providing this information would have been easy.<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup> Similarly, changes made to the site during the lifetime of the project meant, to our shame, that resources at particular URLs were not persistent.<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup> Although neither site fully meets the ideals of the <em>Endings Principles</em> , it is surprising how little might need to be done to upgrade, flatten, and prepare these projects for a more archival afterlife.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In the funding bids for academic projects, Data Management Plans often extol the standards used and the long-term preservation benefits resulting from the way their data and websites will be constructed. But, as with the agreements for in-kind support or partnerships with external partners, projects should also plan their afterlife with more than just funding bid fictions. However good a digital research project’s sustainability plan is, it is still very rare for the lifespan of most digital projects to outlast their creators for very long. Just as humans should not leave it up to the grief-ridden survivors to guess at what should be done with their effects after they pass away, neither should digital humanities research projects leave it to librarians or technical teams to decide what should be done with their outputs. Instead, we should all be clear in advance what the plan is for the eventual sunsetting of projects, having already archived our well-documented data long in advance, and not rely on the best efforts of those left to interpret what should be done with them. Some websites will be rejuvenated and preserved as the front-facing access to their data is seen as too important (or costly) to merely archive, while others will become nothing more than a ZIP archive downloaded by those who really want to explore the data. But we should plan for failure, and we should plan for the project being cut short for any reason with no notice. To realize these plans, we should make the data we produce as transportable and transparent as possible. We should simultaneously recognise that all aspects of an archival research project’s website may be important, not only the underlying data but the choices made in presenting it. Some may be inconsequential, as with both of these two websites, but we should be mindful that the interface through which the data is presented also forms a part of the editorial argument and needs to be preserved if possible. Limiting oneself to minimal technologies may facilitate this.<sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup></p>
<p>Many of the project flaws identified in this article are partly down to inexperience (as many of the technologies were only just emerging), and the eternal problem of busy people having too much to do and relying on shortcuts. Indeed, there were so many moments along the way when these websites could have been destroyed through policy change or simply vanished through neglect. It is easy to see now in hindsight what should have been done — and by and large what should have been done was to follow the then not-yet-created <em>Endings Principles</em> .</p>
<ul>
<li id="bbc2011">BBC. (2011) “University of East Anglia closes school of music” , _BBC Website_ , 28 November 2011. Available at:<a href="https://www.bbc.co.uk/news/uk-england-norfolk-15919759">https://www.bbc.co.uk/news/uk-england-norfolk-15919759</a>.
</li>
<li id="bullard2013">Bullard, P. (2013) “Digital Humanities and Electronic Resources in the Long Eighteenth Century” , _Literature Compass_ , 10, pp. 748–760. Available at:<a href="https://doi.org/10.1111/lic3.12085">https://doi.org/10.1111/lic3.12085</a>.
</li>
<li id="cummings2006">Cummings, J. (2006) “Liturgy, Drama and the Archive: Three Conversions from Legacy Formats to TEI XML” , _Digital Medievalist_ , 2(1). Available at:<a href="http://doi.org/10.16995/dm.11">http://doi.org/10.16995/dm.11</a>.
</li>
<li id="cummings2008">Cummings, J. (2008) “The William Godwin’s Diaries Project” , _Jahrbuch für Computerphilologie_ 10, pp. 1–19. Available at:<a href="http://computerphilologie.de/jg08/cummings.pdf">http://computerphilologie.de/jg08/cummings.pdf</a>.
</li>
<li id="cummings2019">Cummings, J. (2019) “Opening the Book: Data Models and Distractions in Digital Scholarly Editing” . _International Journal of Digital Humanities_ , 1(2), pp. 179–193. Available at:<a href="https://doi.org/10.1007/s42803-019-00016-6">https://doi.org/10.1007/s42803-019-00016-6</a>.
</li>
<li id="cunnane2011">Cunnane, S. (2011) “Campaigners Battle Plans to Close UEA’s School of Music” , _Times Higher Education_ . Available at:<a href="https://www.timeshighereducation.com/news/campaigners-battle-plans-to-close-ueas-school-of-music/418013.article">https://www.timeshighereducation.com/news/campaigners-battle-plans-to-close-ueas-school-of-music/418013.article</a>.
</li>
<li id="endings2021">Endings Project. (2021) _Endings Principles for Digital Longevity_ , Version 2.1. Available at:<a href="https://endings.uvic.ca/principles.html">https://endings.uvic.ca/principles.html</a>.
</li>
<li id="fenlon2019">Fenlon, K. (2019) “Modeling Digital Humanities Collections as Research Objects” , _2019 ACM/IEEE Joint Conference on Digital Libraries (JCDL)_ , pp. 138–147. Available at:<a href="https://doi.org/10.1109/JCDL.2019.00029">https://doi.org/10.1109/JCDL.2019.00029</a>.
</li>
<li id="holmes2023">Holmes, M., and Takeda, J. (2023) “From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles” , _Digital Humanities Quarterly_ .
</li>
<li id="licence2006">Licence, T. (2006) “Goscelin of St Bertin and the Life of St. Eadwold of Cerne” , _The Journal of Medieval Latin_ , 16, pp. 182–207. Available at:<a href="https://doi.org/10.1484/J.JML.2.303234">https://doi.org/10.1484/J.JML.2.303234</a>.
</li>
<li id="muehlberger2019">Muehlberger, G. (2019) et al. “Transforming Scholarship in the Archives through Handwritten Text Recognition: Transkribus as a Case Study” , _Journal of Documentation_ , 75(5), pp. 954–976. Available at:<a href="https://doi.org/10.1108/JD-07-2018-0114">https://doi.org/10.1108/JD-07-2018-0114</a>.
</li>
<li id="munoz2015">Muñoz, T., and Viglianti, R. (2015) “Texts and Documents: New Challenges for TEI Interchange and Lessons from the Shelley-Godwin Archive” , _Journal of the Text Encoding Initiative_ , 8.<a href="https://doi.org/10.4000/jtei.1270">https://doi.org/10.4000/jtei.1270</a>.
</li>
<p>Philp 2021</p>
<li id="philp2021">Philp, M. (2021) “William Godwin (and his diary)”  _The Digital Encyclopedia of British Sociability in the Long Eighteenth Century_ . Available at:<a href="https://www.digitens.org/en/notices/william-godwin-and-his-diary.html">https://www.digitens.org/en/notices/william-godwin-and-his-diary.html</a>.
</li>
<li id="raman2020">Raman, S., and Pearce, W. (2020) “Learning the lessons of Climategate: A Cosmopolitan Moment in the Public Life of Climate Science” . _WIREs Clim Change_ . 11:e672. Available at:<a href="https://doi.org/10.1002/wcc.672">https://doi.org/10.1002/wcc.672</a>.
</li>
<li id="sperbergmcqueen2002">Sperberg-McQueen, C. M., and Burnard, L. (eds.) (2002) _TEI P4: Guidelines for Electronic Text Encoding and Interchange_ . Oxford, Providence, Charlottesville, Bergen: Text Encoding Initiative Consortium. Available at:<a href="https://tei-c.org/Vault/P4/doc/html/index.html">https://tei-c.org/Vault/P4/doc/html/index.html</a>.
</li>
<li id="terras2021">Terras, M. (2021) “The Role of the Library when Computers can Read: Critically Adopting Handwritten Text Recognition (HTR) Technologies to Support Research” in Wheatley, A., and Hervieux, S. (eds.), _The Rise of AI: Implications and Applications of Artificial Intelligence in Academic Libraries_ ACRL - Association of College & Research Libraries, pp. 137–148.
</li>
<li id="thomas2018">Thomas, R. G. (2018) “Review of The Shelley-Godwin Archive (S-GA), New York Public Library and the Maryland Institute for Technology in the Humanities, gen. ed. Neil Fraistat, Elizabeth Denlinger, and Raffaele Viglianti; William Godwin’s Diary, dir. Victoria Myers, David O’Shaughnessy, and Mark Philp” , _Eighteenth-Century Fiction_ 30(4), pp. 601–603. Available at:<a href="https://doi.org/10.3138/ecf.30.4.601">https://doi.org/10.3138/ecf.30.4.601</a>.
</li>
<li id="walsh2002">Walsh, N. (2002) “XML: One Input — Many Outputs: A Response to Hillesund” , _Journal of Digital Information_ , 3(1). Available at:<a href="https://journals.tdl.org/jodi/index.php/jodi/article/view/jodi-64">https://journals.tdl.org/jodi/index.php/jodi/article/view/jodi-64</a>.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The article started as a brief video and then symposium talk for<a href="https://endings.uvic.ca/symposium.html">The Endings Project Symposium</a>and the slides initially used are available at<a href="https://slides.com/jamescummings/endingsproject2021/">https://slides.com/jamescummings/endingsproject2021/</a>. Although there is substantial discussion of TEI Markup that is useful in recording for posterity the nature of the projects, in the end it is this portable markup that helps in their preservation. I hope those unfamiliar with TEI markup will bear with those parts in reading this article. While it is necessary to give the detailed background for those readers who are interested in these TEI aspects, the lessons learnt are also equally applicable to non-TEI projects.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>For additional material on the <em>CURSUS</em> project technical decisions see Cummings, 2006.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><em>The Peterborough Antiphoner</em> . Cambridge, Magdalene College Ms F.4.10. An Antiphoner of the fourteenth century from the Benedictine Abbey of St Peter, St Paul and St Andrew, Peterborough, Northamptonshire.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>For the now deprecated TEI P4 Guidelines see<a href="https://tei-c.org/Vault/P4/doc/html/index.html">https://tei-c.org/Vault/P4/doc/html/index.html</a><a class="footnote-ref" href="#sperbergmcqueen2002"> [sperbergmcqueen2002] </a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>The amount the <em>CURSUS</em> project used this feature of DTD-based document processing to include any repetitive portions of text should not be underestimated. Not only rubricated labels such as ‘Ant.’ but accents, unusual punctuation, character abbreviation markers, books of the Bible, portions of the <code>&lt;teiHeader&gt;</code> , and manuscript witness information were also included. The use is more akin to how one might use XInclude or similar these days. For the full horror see<a href="https://github.com/jamescummings/cursus/blob/master/dtd/cursus.ent">https://github.com/jamescummings/cursus/blob/master/dtd/cursus.ent</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>See<a href="http://cantusindex.org/">http://cantusindex.org/</a>for more information about <em>CANTUS</em> and related projects.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Dr Lewis replaced very early experiments using eXist-db 1.0b1 to index and search with Swish-E, and created a replacement for the Apache Cocoon system that we used for pipelining the dynamic conversions with a tool calledPycoon(because it was written in python). See<a href="https://github.com/ironchicken/pycoon">https://github.com/ironchicken/pycoon</a>for more information about Pycoon.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>c.f. <em>Endings Principles</em> , 1.2: “Data is subject to version control (Subversion, Git).”&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>This hack was partly responsible for catapulting climate change denialism into the public consciousness<a class="footnote-ref" href="#raman2020"> [raman2020] </a>. For more information on ClimateGate, the Wikipedia article contains a fairly in-depth explanation<a href="https://en.wikipedia.org/wiki/Climatic_Research_Unit_email_controversy">https://en.wikipedia.org/wiki/Climatic_Research_Unit_email_controversy</a>. Fact Check (a project of the Annenberg Public Policy Center that focuses on debunking political misinformation) also has a good summary<a href="https://www.factcheck.org/2009/12/climategate/">https://www.factcheck.org/2009/12/climategate/</a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Fortunately, it did have several snapshots taken by the Wayback Machine of the Internet Archive. See for example<a href="https://web.archive.org/web/20061012165859/http://www.cursus.uea.ac.uk/ed/c5111">https://web.archive.org/web/20061012165859/http://www.cursus.uea.ac.uk/ed/c5111</a>for antiphon c5111 from October 2006 shortly before Professor Chadd’s death. Until we reinstated the <em>CURSUS</em> website at<a href="http://cursus.org.uk/">http://cursus.org.uk/</a>, we directed people to the Wayback Machine instead.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>c.f. <em>Endings Principles</em> , 2.2: “All rights and intellectual property issues should be clearly documented. Where possible the Data and Products should be released under open licenses (Creative Commons, GNU, BSD, MPL)” .&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>As the pioneer of early computer science Rear Admiral Grace Hopper has been quoted as saying: “It is easier to ask forgiveness than permission.” The <em>CURSUS</em> Creative Commons licensing discussions certainly reinforce that lesson. Under the intellectual property policy of UEA at this date, the institution and not the individual academic owned the IPR. The AHRB encouraged the production of open access outputs but did not mandate it at this point. In preparation for the Endings Project Symposium Martin Holmes queried the small amount of risk that putting the site up would have entailed, and while it crossed our minds, we were also busy with other projects.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>The idea of recording interactive sessions with digital editions to preserve a sense of their functionality came up in discussion during the Endings Project Symposium. Of course, having videos helps but the full interactive user experience is lost, and any video will need to be preserved with the resource in a standard accessible format.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>The original URL,<a href="http://cursus.uea.ac.uk/">http://cursus.uea.ac.uk/</a>, ceased to function in 2010. The<a href="http://cursus.org.uk/">http://cursus.org.uk</a>site holds a legacy copy of what was on that site at the time.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>As part of writing this paper, a copy of the data and code, stored in GitHub at<a href="https://github.com/jamescummings/cursus">https://github.com/jamescummings/cursus</a>, was archived and put into the international open repository Zenodo<a href="https://doi.org/10.5281/zenodo.5090613">https://doi.org/10.5281/zenodo.5090613</a>ensure its survival.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>TEI ODD is the machine-readable meta-schema documentation and customisation format for the TEI Framework that most projects employing TEI should use to record their project’s schema and encoding guidelines.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>c.f. Endings Principles, 1.2: “Data is subject to version control (Subversion, Git).”&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>For more information about the diary of William Godwin see Mark Philp’sWilliam Godwin (and his diary)<a href="https://www.digitens.org/en/notices/william-godwin-and-his-diary.html">https://www.digitens.org/en/notices/william-godwin-and-his-diary.html</a>.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>These were the project members with whom I interacted, but I should also note the involvement of the co-editor Dr Victoria Myers from Pepperdine University who provided many of the initial draft transcriptions as Word documents before their conversion to TEI P5 XML. For a full acknowledgements list see<a href="http://godwindiary.bodleian.ox.ac.uk/team.html">http://godwindiary.bodleian.ox.ac.uk/team.html</a>.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>c.f. <em>Endings Principles</em> , 5.2: “A release should only be made when the entire product set is coherent, consistent, and complete (passing all validation and diagnostic tests).”&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>For more information about DataTables see<a href="https://datatables.net/">https://datatables.net/</a>. Using DataTables would contravene the <em>Endings Principles</em> 4.3: “No dependence on external libraries or services: no JQuery, no AngularJS, no Bootstrap, no Google Search.”&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>For more general numerical statistics of the diary content see<a href="http://godwindiary.bodleian.ox.ac.uk/stats.html">http://godwindiary.bodleian.ox.ac.uk/stats.html</a>.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>An example of this is in the source XML for the DataTables of information for both identified and unidentified people. Either the query was composed in an inefficient manner, or the XML poorly indexed, but the result took several seconds to retrieve, even locally. So the decision was made to pre-generate the results of the query and merely transform this to HTML when required. This approach is halfway along the route to the creation of a fully static website that would be more compatible with the <em>Endings Principles</em> .&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>If one toggles on all of this named-entity formatting, the site becomes an unreadable fruit salad of inaccessibility. The PI was challenged several times on his insistence for this feature. Using colours to denote semantics is usually a poor choice for reasons of accessibility.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>See<a href="https://www.politics.ox.ac.uk/news/william-godwins-diary-wins-award.html">https://www.politics.ox.ac.uk/news/william-godwins-diary-wins-award.html</a>for information about this award.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Those whose institutions have entirely centralized IT provision may find such parochial outlooks and redundant duplication inside a highly collegiate university confusing; so do many who have worked there.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>In a moment of deep irony, on the weekend during which I initially wrote these precise paragraphs the website was down. Given its legacy position, out-of-date software, and operating system, it should be considered at-risk, and yet is still frequently consulted and cited by those studying Godwin who likely have little sense of its precarity. Scholars may reasonably expect that a site hosted by the Bodleian Libraries is stable. But this expectation places additional maintenance burdens on their technical support teams.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Although this GitHub repository<a href="https://github.com/jamescummings/godwindiary">https://github.com/jamescummings/godwindiary</a>acts as another copy for preservation means, it would make sense to deposit a copy of this with the images into an international repository like Zenodo. I have not yet done this, mea culpa.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Other pan/zoom browsers of the time (such as OpenLayers which was quite popular) were tested and the user experience of the Google Maps version was preferred by the PI.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>c.f. <em>Endings Principles</em> , 4.7: “Graceful failure: every page should still function effectively even in the absence of JavaScript or CSS support” and 4.9 “The use of an external library may be necessary to support a specific function which is too complex to be coded locally (such as mapping or cryptography). Any such libraries must be open-source and widely-used, and must not themselves have dependencies.”&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>The <em>Endings Principles</em> are available at<a href="https://endings.uvic.ca/principles.html">https://endings.uvic.ca/principles.html</a>.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>c.f. <em>Endings Principles</em> , 1.1: “Data is stored only in formats that conform to open standards and that are amenable to processing (TEI XML, GML, ODF, TXT).”&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>c.f. <em>Endings Principles</em> , 1.2: “Data is subject to version control (Subversion, Git).”&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>c.f. <em>Endings Principles</em> , 1.3: “Data is continually subject to validation and diagnostic analysis.”&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>c.f. Endings Principles, 2.1: “Data models, including field names, descriptions, and controlled values, should be clearly documented in a static document that is maintained with the data and forms part of the products.”&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>To be fair, Creative Commons had just recently launched during the years of the <em>CURSUS</em> project and the number of academic research projects in the humanities using CC Licences was still tiny. c.f. <em>Endings Principles</em> , 2.2: “All rights and intellectual property issues should be clearly documented. Where possible the Data and Products should be released under open licenses (Creative Commons, GNU, BSD, MPL).”&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>c.f <em>Endings Principles</em> , 3.1: “Relentless validation: all processing includes validation/linting of all inputs and outputs and all validation errors should exit the process and prevent further execution until the errors are resolved.”&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>c.f Endings Principles, 3.2: “Continuous integration: Any change to the source data requires an entire rebuild of the site (triggered automatically where possible).”&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>c.f Endings Principles, 3.3: “Code is contingent: while code is not expected to have significant longevity, wherever possible, all code should follow Endings principles for data and products.”&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>c.f. <em>Endings Principles</em> , 4.1:No dependence on server-side software: build a static website with no databases, no PHP, no Python.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>c.f. <em>Endings Principles</em> , 4.2: “No boutique or fashionable technologies: use only standards with support across all platforms, whose long-term viability is assured. Our choices are HTML5, JavaScript, and CSS” , and 4.3: “No dependence on external libraries or services: no JQuery, no AngularJS, no Bootstrap, no Google Search.”&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>What is really needed, and StaticSearch is a good start, is end-to-end solutions that make it easier for projects to follow the Ending Principles. They should be using software because it is easy and as a benefit also get <em>Endings Principles</em> compliance<a class="footnote-ref" href="#cummings2019"> [cummings2019] </a>.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>c.f. <em>Endings Principles</em> , 4.4: “No query strings: every entity in the site has a unique page with a simple URL that will function on any domain or IP address.”&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>c.f. <em>Endings Principles</em> , 4.5: “Inclusion of data: every site should include a documented copy of the source data, so that users of the site can repurpose the work easily.”&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>c.f. <em>Endings Principles</em> , 4.6: “Massive redundancy: every page contains all the components it needs, so that it will function without the rest of the site if necessary, even though doing so means duplicating information across the site.”&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>c.f. <em>Endings Principles</em> , 4.7: “Graceful failure: every page should still function effectively even in the absence of JavaScript or CSS support.”&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>c.f. <em>Endings Principles</em> , 4.8: “Once a fully-working static site is achieved, it may be enhanced by the use of other services such as a server-side indexing tool (Solr, eXist) to support searching and similar functionality” and 4.9: “The use of an external library may be necessary to support a specific function that is too complex to be coded locally (such as mapping or cryptography). Any such libraries must be open-source and widely-used, and must not themselves have dependencies.”&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>c.f. <em>Endings Principles</em> , 5.1: “Releases should be periodical and carefully planned. The rolling release model should be avoided.”&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>c.f. <em>Endings Principles</em> , 5.2: “A release should only be made when the entire product set is coherent, consistent and complete (passing all validation and diagnostic tests)” and 5.3: “Like editions of print works, each release of a web resource should be clearly identified on every page by its build date and some kind of version number.”&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>c.f. <em>Endings Principles</em> , 5.4: “Web resources should include detailed instructions for citation, so that end-users can unambiguously cite a specific page from a specific edition.”&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>c.f. <em>Endings Principles</em> , 5.5: “URLs for individual resources within a digital publication should persist across editions. Any moved, retired, or deleted resources no longer available at a previously accessible URL should be redirected appropriately.”&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>As part of preserving the interface, as mentioned earlier, screen capture videos should be recorded in standard formats documenting the interactivity and user experience of the website for archiving alongside the data because the videos may be useful to information historians at a later date.## Bibliography&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="related" type="text/html" title="Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="related" type="text/html" title="Follow the Money?: Funding and Digital Sustainability"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="related" type="text/html" title="From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction to Special Issue: Project Resiliency in the Digital Humanities"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000660/?utm_source=atom_feed" rel="related" type="text/html" title="No Boutique or Fashionable Technologies: Project Development, Mentorship, and Sustainability in an Innovation-First World"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000667/</id><author><name>Nick Thieberger</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction1">Introduction<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></h2>
<p>Imagine a world in which research was valued so that research records were not periodically lost at the end of every research project. To avoid project endings resulting in data loss, researchers need a long-term data service that ensures continued access to their primary records. Storage on hard disks is not curation; it simply amasses files with no metadata, no license or deposit conditions, and no public access. In the absence of institutional or national work to preserve the outputs of research in our disciplines of linguistics and musicology, our project, the Pacific and Regional Archive for Digital Sources in Endangered Cultures (PARADISEC), developed exemplary methods and services for curating research data based on accepted standards for metadata and data formats. The data we have focused on is analog tape, recorded in fieldwork, and often the only recording made in a particular indigenous language. Initially recorded for the purposes of research, these recordings have heritage value to the people recorded and their descendants. In addition, we provide citable data for use in building on existing research that was previously inaccessible. We continue to train new generations of researchers to create well-described research materials, recognizing that archival formats should be created in the course of normal research to make the whole process of curation much easier for both the depositor and the archive. Researchers seek advice about how to manage their records and are open to learning how to make better records that they will be able to access in future. We act as a repository that curates and preserves research at all stages of its creation: recordings deposited during fieldwork, or at the end of a research project or a researcher’s career (or life). To support longevity we have always written an XML file of the complete catalog entry to the item (the package of files) updated each time the catalog entry is updated, so each item is self-describing. We are now developing an innovative curation method using emerging technology (Oxford Common File Layout and Research Object Crate) to ensure the collection can be decoupled from a catalog and still be self-describing, a first step to ensuring longevity.</p>
<p>And, perhaps more important than any of this, digitization has allowed us to engage with the communities in the Pacific, Papua New Guinea (PNG), and South-East Asia that are the source of the recordings, which we can now return, sometimes half a century or more after they were made.</p>
<p>We address the following research questions. How can we ensure the records we create in the course of our research will exist into the future and remain citable (see Coble and Karlin in this issue)? How can our research data be made available for a wider public, most importantly for the people recorded and their descendants? How can we prepare our students for this new approach to curation of primary research data so that they can build good methodology into their normal research practice, with much more productive outcomes? Finally, having built a collection of research data from projects that have ended, how can we manage this into the future? PARADISEC could be criticized for creating a collection that has no future, as there is no commitment from a national agency to the long-term carriage of the collection, but we suggest that we are not alone in this and that cases like PARADISEC need to be addressed as part of a strategic approach to research infrastructure. We have shown that it is possible to build the basis of future research by curating existing primary research material, and, in doing that, to provide access to research materials for the broader community. For each depositor their described and structured collection is typically in better shape than it was on their laptops or hard disks.</p>
<p>The loss of records when a research project ends is a major tragedy that needs to be avoided (see also Otis in this issue). For digital projects, the evanescence of the digital threatens imminent loss from any number of threats, such as power loss, physical breakdown of equipment, or network failure. For analog records, the senescence of unique media threatens loss by deterioration and is exacerbated by the lack of playback machinery. Much of the primary research data of linguistics, musicology, and anthropology from the latter part of the last century is still located on analog media and there is no more final ending to research data than its decay into unusability. There is an international effort to build language archives that are mainly based in Europe and North America, and linked by a network called the Digital Endangered Languages and Musics Archives Network (DELAMAN).<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Further, the Open Language Archives Community<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> has developed a standard metadata set that these archives can use that allows for interoperability between language archives.</p>
<p>In Australia, hundreds of analog tapes were at risk of loss as no national institution had it in their mandate to collect tapes containing material from outside of Australia. Experts predict<a class="footnote-ref" href="#nfsa2017"> [nfsa2017] </a>that analog tapes will be largely unplayable by the year 2025 due to media breakdown and a lack of playback machinery, and, in many places, the task of preservation and repatriation of the content of these tapes remains to be taken up. Our research group, based at three Australian universities, addressed this challenge in the early 2000s by building a repository and digitization workflow that now includes 210 terabytes of material, representing 1,350 languages in 16,000 hours of audio recordings along with manuscript and video materials. Many of these languages represent small<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> communities of indigenous speakers in the Pacific, South-East Asia, and PNG, and are under-resourced (in number of online resources available), and so the imperative to ensure their records are findable and accessible is all the more urgent<a class="footnote-ref" href="#barwick2018"> [barwick2018] </a>. Linguists increasingly require citation of primary records for the purposes of research, and in order to build new kinds of materials on the original records (books, online presentations, dictionaries, and so on), and that is predicated on those records having persistent identification, provided by a suitable repository. Thus, while there is in our case a particular imperative to ensuring these records are properly made, described, and curated, the same principles can be applied to research in many disciplines.</p>
<p>In the course of doing this work, we train new researchers in appropriate methods for creating reusable primary records, and we have built a platform for citation of data, allowing for verification and licensed reuse of that data. We have done this training with several 1-year infrastructure grants over the 20-year life of the project. While there was an Australian National Data Service, it paradoxically did not curate data but served metadata and provided data storage with no guarantee of longevity. The current Australian Research Data Commons (ARDC) also has no national service for curating research data (and so, noCommons,its focus being on infrastructure for current research). Neither national service had or has within its mandate to implement an ongoing data curation service that would house primary research records into the future. So, despite large funding sources apparently available for research data, they are typically not available for curating the kinds of humanities and social science (HASS) records we are concerned with in PARADISEC, nor to make them FAIR.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<p>For our community of linguists, musicologists, and ethnographers, this lack of mandate is a particularly acute problem as our records are the result of fieldwork that has taken some effort to undertake, usually in remote areas in Australia, PNG, or the island nations of the Pacific<a class="footnote-ref" href="#thieberger2012a"> [thieberger2012a] </a>. We enter into relationships with people whose languages or cultural traditions we record, and we want to act responsibly by making the recordings available to them into the future. These are sometimes the only recordings and perhaps the only presence of speakers of this language on the web. Furthermore, many of these small languages are at risk of loss, and some are no longer spoken due to many factors. So we have endangered records of endangered languages, compounding the responsibility of researchers to ensure they lodge records in a secure repository, or, if that repository does not exist, to build it, as we did with PARADISEC.</p>
<p>For our forebears it was not a simple matter to make recordings available to the communities they worked in. Analog tape could be returned to national cultural centres that had playback equipment, but there was no such capacity outside of capital cities. Clearly a colonial mindset was also at play, in which the records were taken as being the property of the recorder who typically made no provision for their long-term preservation<a class="footnote-ref" href="#thieberger2020"> [thieberger2020] </a>. In the latter part of the twentieth century there was not the necessary institutional infrastructure to look after these recordings in Australia, with the result that many fieldtapes remained in the possession of retired researchers, or in the hands of their executors once they had died.</p>
<p>This situation motivated a collaboration of linguists and musicologists who were successful in obtaining a one-year infrastructure grant from the Australian Research Council in 2003. With the title “Pacific and Regional Archive for Digital Sources in Endangered Cultures (PARADISEC),” we set the goal of digitizing 500 hours of recordings in the first year. We established a metadata schema to describe the files we created, conforming to DCMI<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> and the Open Language Archives Community (OLAC)<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> . With advice from the National Library of Australia and the National Film and Sound Archive, we bought reel to reel tape and cassette playback machines and employed an audio-engineer. Over time we built a lab with high quality analog to digital audio converters, a tape cleaning system, and a vacuum oven (required to re-adhere magnetic media to their carrier polyester tape backing) to deal with the range of conditions in which tapes were presented to us. With this foundation, we kept locating more and more tapes, and finding small grants to support continual digitization over the past 20 years. We have now digitized about 7,900 hours of analog tape, and house a further 8,000 hours of born-digital audio. Together with 2,600 hours of video and many text files, there are 420,000 files organized into 680 collections.</p>
<p>On accessing the collection, delivery versions of high resolution files are automatically created, for example, wav files have mp3 versions and tif files have jpg versions. A digital object identifier (doi) is assigned to all public collections, items, and files. Depositors assign rights, licensing the use of the files, which can include making items closed to all users except those nominated by the depositor (who can alter access conditions over time). They can also make items or collections private, which means no search engine finds them, and no doi is assigned, which is useful when a collection is being constructed. Once users are registered, they are then able to access any ‘open’ item, having first agreed to standard access conditions.</p>
<p>To maximize access to the collection, our catalog has several APIs that are picked up by national and international aggregators, including OLAC<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> , Research Data Australia<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> , and the National Library of Australia’s TROVE<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> . OLAC, in turn, presents its harvested records in single pages per language so that our metadata is then available along with any other material related to any one of the 7,000 or so of the world’s languages. And, of course, Google also picks up our catalog.</p>
<p>There are many locations in the world for which internet access is difficult, and often expensive, and so access to heritage materials in or near their source communities remains problematic. A solution we have tested in a few locations (a village in Vanuatu, an Australian Western Desert community, workshops in Honiara and in Papeete) is to load relevant items from the collection onto a small low-powered computer, known as a Raspberry Pi<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> , which includes a wifi transmitter. We plug in a usb drive with a catalog of just those files in a simple html form that can be retrieved on a mobile phone, from a local signal transmitted by the Raspberry Pi, independent of any internet access. The catalog is created by a service we wrote, called dataloader<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> , that harvests the XML file stored in each item and then creates the catalog of just that small collection. This catalog includes services that allow video files to be viewed, audio files to be heard, and pdf files to be scrolled. All files can then be downloaded to the mobile phone without being impeded by bandwidth considerations. In 2022/23 we plan to provide installations of these units to regional cultural centres (museums and similar agencies) in the Pacific so that files can be accessed locally. Recall that these are recordings made in the past few generations. They were analog tapes of people from villages in many locations, stored inaccessibly, and so they have not been available for the people recorded or their families. Once these recordings are back in the relevant communities they can inspire revitalization of oral traditions and additional contextual information that can enrich our catalog.</p>
<h2 id="what-has-been-preserved">What has been preserved?</h2>
<p>While the total hours and size of the collection is impressive, it is the content of each of the files that gives a sense of the enormous value held by PARADISEC. For example, a major collection among those that initially motivated our project was that left by Arthur Capell, the professor at the University of Sydney in the 1950s, with tapes in nearly 300 languages<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> , and thousands of pages of notes<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> . All of this was left in the house of Capell’s executor, who undertook the massive task of managing and describing the tapes and papers. We have<a href="https://paradisec.org.au/fieldnotes/AC2.htm">digitized this collection</a>as some 1,300 items, and put it online. This includes over 15,000 pages of notes from a large number of Pacific and south-east Asian languages, together with many recordings on open reels and cassettes. In my own experience, in Capell’s collection I have found a recording of a speaker of Nafsan, the language that I research in Vanuatu, and took that recording and associated notes back to the village where speakers live. The speakers can now also access all of this information via mobile phones themselves. So, a collection that was previously available only to visitors to the executor’s house is now an openly available and licensed set of research and heritage material. The physical copies of these items are held by the National Library of Australia.</p>
<p>An unsolicited collection was offered to us by Ruth Roesler, who had no other suitable repository available to her. This work, created with her husband Calvin Roesler in the 1950s<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> , was among the Asmat people of the south coast of what is now West Papua. It includes folktales, origin stories, documentations of customs, songs, descriptions of daily life and linguistic analysis. Items 001 to 054 were open reel audio recordings that we digitized and all following items are notes, most of which are transcripts of audio, and we have also put these into an online display<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> .</p>
<p>We worked with the anthropologist Ian Frazer who had more than 200 cassettes, and 40 open reels recorded from 1971 to 1985, in fieldwork in North Malaita, Solomon Islands, mainly in To&rsquo;abaita but with neighbouring groups as well (Lau, Baelelea, Pijin). These are recordings of music (traditional and contemporary), traditional stories, history, life histories, traditional and present day customs/culture, political history, labour history, and much else. This collection was located as a result of PARADISEC&rsquo;s “Lost and Found” <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> project and digitization was funded by an Endangered Languages Documentation Programme Legacy Materials Grant and the ARC Centre of Excellence for the Dynamics of Language.</p>
<p>An important aspect of all of this work is taking inaccessible records and preparing them for access, including licensing, and online curation. As noted in<a class="footnote-ref" href="#thieberger2020"> [thieberger2020] </a>, by archiving with PARADISEC, records made with indigenous people are available to those people as soon as possible after they are recorded. As<a class="footnote-ref" href="#jimerson2007"> [jimerson2007] </a>notes, archives contribute to the public interest “by documenting underrepresented social groups and fostering ethnic and community identities.” Similarly, Smith observes that</p>
<blockquote>
<p>imperialism and colonialism brought complete disorder to colonized peoples, disconnecting them from their histories, their landscapes, their languages, their social relations and their own ways of thinking, feeling and interacting with the world. […] To discover how fragmented this process was one needs only to stand in a museum, a library, a bookshop, and ask where indigenous peoples are located.<br>
<a class="footnote-ref" href="#smith1999"> [smith1999] </a><br>
I suggest that the process of making records available addresses some of Smith’s concerns and works to decolonize academic practice.</p>
</blockquote>
<p>To represent the beauty of the sounds in many of our collections, we have written a soundscape that takes a curated set of samples of audio and displays it on a map, playing a sample together with the metadata<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> . This kind of view is possible because the collection has a predictable structure, includes geographic metadata, and automatically transcodes files to a deliverable mp3 on ingestion. The soundscape provides another way to discover the material in the collection. We also made a virtual reality exploration of a geographic landscape in which shards of light emanating from the ground represent each language, allowing users to navigate between them, and hearing, in effect, a forest of languages as they pass through them.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> In a similar vein, material from our collection has been used by the artist Lena Herzog in her work “Last Whispers.” <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup></p>
<p>A collection of research data is of relevance to academic research as it provides a citable basis, for example, for verification of claims made in papers. Humanities research data has an additional appeal in that is it is likely to be comprehensible to the general public, and to be of particular relevance to the people involved in its creation. One way in which we are publicizing the collection is by producing a series of podcasts in which users of items in the collection discuss their reactions to finding the material, and, in some cases, relearn songs or oral tradition from the earlier materials.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></p>
<h2 id="how-to-prevent-data-endings">How to prevent data endings</h2>
<p>A repository can provide a solution for project endings for the primary data created in the course of research. Projects of fieldwork and analysis of language materials typically result in grammatical analysis, often a dissertation, or in publications that cite the primary data. Recently our discipline has focused more on citation of primary data to provide necessary context for analytical claims (<a class="footnote-ref" href="#thieberger2016"> [thieberger2016] </a>, see also Holmes and Takeda, this volume). At the same time, we have increasingly recognized our responsibility to prepare records for the speakers we work with. These two desiderata have led to an understanding of the need to create records in ways that allow them to be re-used, which, in turn, requires training for the researcher. We run regular training courses in the tools and methods that will result in well-constructed research corpora, emphasizing the importance of standard metadata descriptions that can then be imported into PARADISEC’s catalog.</p>
<p>In our experience, it is often only when arriving at the point of depositing records in an archive that a researcher consciously takes stock of their materials and prepares them in a structured format. At this point they may realize what remains to be done – which media have not been transcribed, which texts have not been annotated, which photographs are not identified, and so on. For most current researchers, this, in itself, is a satisfactory outcome. Regardless of the longevity of the archive, they are now able to find items in their own collections and to continue to build their research based on these well-structured data files. Of course, this management of research data is done more easily at the moment of creation of the records, and to assist with the task of building a well-structured collection from that moment, we have worked with colleagues<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> to develop a metadata entry tool called Lameta<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> , now available for general use. Lameta is a standalone app that presents files on your computer for description and organizes structured metadata that can then be exported to formats accepted by a range of existing language archives. For a researcher to end a project gracefully they need to have good guidance in managing their records, and a tool like Lameta is part of that guidance, making it as easy as possible to provide structured metadata. To promote the use of this and other tools we regularly run training workshops, and discuss the workflow<a class="footnote-ref" href="#thieberger2012b"> [thieberger2012b] </a>that takes records through from fieldwork, transcription, annotation, and to archiving.</p>
<p>An example of the new life of research data is my own collection of recordings made in Efate (Vanuatu) since the mid-1990s in the local language Nafsan. I prepared a set of data using the tools expected of my discipline, with outputs conforming to the standards required by PARADISEC (high resolution media, textual transcripts, structured lexicon, and so on). A guide to this collection is available as a webpage.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> Some of this material was then prepared as a book of 70 bilingual stories, a dictionary produced both as a book and a phone app, and the corpus of audio and transcripts and texts has been used in four international projects examining particular linguistic features and each requiring a structured media and text corpus. A PhD student began work on analysing tense and aspect in the language by working through the texts, before going on to conduct her own fieldwork, and a postdoc worked in detail on aspects of the language that I had only briefly addressed. Several videos from my collection have been put onto Facebook pages by speakers of the language. None of this would have been possible if I had kept the records on my laptop, or lost them when the hard disk failed.</p>
<h2 id="paradisecs-endings">PARADISEC’s endings</h2>
<p>We have ensured the longevity of many research collections in PARADISEC, all the while expecting that there would be a national digital repository that would take responsibility for collections like ours. There was in 2003 no national Australian repository for digital HASS research of this kind, motivating the work that we undertook, and, unfortunately, this continues to be the case. The timescale that projects like ours operate under is governed by funding cycles, and national research infrastructure for HASS in Australia is typically no different, usually with three-year horizons of funding and no commitment to long-term curation of the research data that has been invested in so heavily by the taxpayer. While repositories for genomics, bio-informatics, or astro-physical data are designated as national research capabilities<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> whose future is assured by governments, not a single humanities data repository is granted that status. This is despite our collection, for example, being just a fraction of the size of any of these STEM repositories. There is an Australian national server program, and data storage is provided on a merit-based system which we have benefited from, to house both the online collection and a mirrored offsite copy. However, storage on its own is not enough to ensure the safety of a collection like ours: we provide a rich catalog and set of services to allow interaction with the data, including discipline-specific viewers for media and transcripts, citation forms for data, and feeds to international aggregators for this kind of material, using standard language identifiers to build resource guides for each language in the world. All of this contributes to the value of a curated repository, and is much more than simply storage on disk. Because of the lack of a national data service, we have continued to operate PARADISEC for 20 years, despite funding hiatuses. We have built an automated system that allows ingestion of new items with minimal handling, and continues to provide access as long as the servers are running. This means that we can operate with a skeleton staff when needed, and, when funds are available, we can continue the more labour-intensive work of processing analog tapes. Clearly, this requires a commitment by our personnel that goes beyond a normal employment contract, a commitment for which we are all very grateful, and which has allowed the collection to endure over two decades so far.</p>
<p>We have learned, in our efforts to uncover unique materials on closed-down servers or hard disks, that files on a disk are only part of the preservation story, and the very simple solution that this suggests is one that keeps data and metadata together. For the past decade each time we save a catalog item it writes an XML file to the collection, and any subsequent edits to that catalog item are saved to the same location, so that files and metadata are co-located. As a result, we were able to quickly take advantage of a small grant in 2019 to convert the catalog and collection to a new format, using Research Object Crate (RO-Crate) and inspired by a platform we called Arkisto<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> . This creates bundles of data that can be stored on disk with no external catalog and that still maintain their contextual information, metadata, licence information, and access conditions, and so stand a far better chance of surviving into the future than files in proprietary systems, or those using monolithic databases for their descriptions. As the metadata is written in json, a commonly used format, it is not difficult to re-create a catalog of any of these bundles, independent of whatever software was used to create them originally.</p>
<p>Future work on this promising development will include changing the user’s interaction with the collection to a single page application that is built from the collection itself, with regular indexing creating the page. For the time being our catalog will continue to create the metadata that is then stored in the RO-Crate file with the collection object. The new catalog viewer already has improved ways of interacting with the collection. For example, any media that has a time-aligned transcript is playable together with that transcript, and the text of the transcript is searchable. This means that the text in the entire collection can be searched and the selected chunk of media can be heard or seen for each search result. This viewer can be deployed to other ways of delivering the collection, for example, on a Raspberry Pi for local wifi access. Such microservices can be added to the system as required, with the underlying structure of the collection in the standard RO-Crate format. This makes the catalog available for delivery in various forms, allowing for tailoring to different user groups if required (for example, localizing the interface or changing search terms depending on who the target users are).</p>
<h2 id="conclusion">Conclusion</h2>
<p>There is an urgent need for national repositories to take up the challenge presented by the increase in the number of orphaned and fragile digital projects. When those projects have created some of the few records in small languages there is a greater imperative to curate those records and ensure their longevity. The great risk to a collection of this kind is a lack of perennity common to allended projects,and we advocate for national data services that will capitalize on the investments already made in each research grant, each research project, and each researcher’s effort.</p>
<p>PARADISEC demonstrates a functioning repository that arises out of a disciplinary base. It models data management and provides training in data creation that benefits both the researcher and the repository, and as a result, the broader community can access curated and licensed items in the collection. PARADISEC has provided structure for collections that were previously disparate and undescribed. It has digitized analog materials and so made them more accessible. Copies of these collections are held by the depositors and, if permitted, by cultural or language centres relevant to the content of a particular collection. This, in itself, has been a valuable service provided by our project.</p>
<p>Ended projects have found a home in PARADISEC in a format that will endure as properly structured and described files on disk, even if the worst case eventuates and the current repository has no further funding. Our challenge as researchers, and the challenge for national research infrastructure planners, is how to make collections like PARADISEC’s continue to provide access into the future.</p>
<ul>
<li id="barwick2018">Barwick, L., and Thieberger, N. (2018) “Unlocking the archives” , in V. Ferreira and N. Ostler (eds.) _Communities in Control: Learning tools and strategies for multilingual endangered language communities_ . _Proceedings of the 2017 XXI FEL conference_ . Hungerford: FEL. pp. 135–139.
</li>
<li id="dorian2014">Dorian, N. C. (2014) _Small-Language Fates and Prospects: Lessons of Persistence and Change from Endangered Languages: Collected Essays. Brill’s Studies in Language, Cognition and Culture_ , 6. Leiden: Brill.
</li>
<li id="jimerson2007">Jimerson, R. C. (2007) “Archives for All: Professional Responsibility and Social Justice” , _The American Archivist_ , 70(2), pp. 252–281.
</li>
<li id="nfsa2017">NFSA. (2017) _DEADLINE 2025 Collections at risk_ . Canberra: National and Film and Sound Archive. Available at:<a href="https://www.nfsa.gov.au/corporate-information/publications/deadline-2025">https://www.nfsa.gov.au/corporate-information/publications/deadline-2025</a>.
</li>
<li id="smith1999">Smith, L. T. (1999) _Decolonizing Methodologies: Research and Indigenous Peoples_ . London; New York: Zed Books; Dunedin: University of Otago Press.
</li>
<li id="thieberger2016">Thieberger, N. (2016) “What remains to be done – Exposing invisible collections in the other 7000 languages and why it is a DH enterprise” , _Digital Scholarship in the Humanities_ 32(2), 1 pp. 423–434. Available at:<a href="http://dx.doi.org/10.1093/llc/fqw006">http://dx.doi.org/10.1093/llc/fqw006</a>.
</li>
<li id="thieberger2012a">Thieberger, N. and Barwick, L. (2012) “Keeping records of language diversity in Melanesia, the Pacific and Regional Archive for Digital Sources in Endangered Cultures (PARADISEC)” in Evans, N. and Klamer, M. (eds.) _Melanesian languages on the edge of Asia: Challenges for the 21st Century_ . LD&C Special Publication No. 5. Honolulu: University of Hawai'i Press. pp. 239–253. Available at:<a href="http://scholarspace.manoa.hawaii.edu/handle/10125/4567">http://scholarspace.manoa.hawaii.edu/handle/10125/4567</a>.
</li>
<li id="thieberger2020">Thieberger, N. (2020) “Technology in support of languages of the Pacific: neo-colonial or post-colonial?”  _Asian-European Music Research Journal_ 5(3) pp. 17–24<a href="https://doi.org/10.30819/aemr.5-3">https://doi.org/10.30819/aemr.5-3</a>.
</li>
<li id="thieberger2012b">Thieberger, N. and Berez, A. (2012) “Linguistic data management” in Thieberger, N. (ed.) _The Oxford Handbook of Linguistic Fieldwork_ . Oxford: OUP, pp. 90–118.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I acknowledge that I work on the unceded lands of the Gadigal people of the Eora Nation, the Ngunawal, and the Woiwurrung. I thank two anonymous reviewers for comments that have improved this article, and thank the organizers of the Project Endings for their work in bringing such an interesting group together to discuss the critical issue of longevity of access to research data. I particularly want to thank all members of the PARADISEC team, in particular my co-founders of the project, Linda Barwick, with Amanda Harris, and all who have contributed in various capacities: Sander Adelaar, I Wayan Arka, Peter Austin, Corinne Bannister, Grace Barr, Stas Belkov, Rosey Billington, Steven Bird, Lauren Booker, John Bowden, Kevin Bradley, Georgie Burke, Brighde Collins, Linda Connor, Aaron Corn, Miriam Corris, Ashisha Cunningham, Emma Cupitt, Frank Davey, Hugh de Ferranti, Mark Ellison, Nick Enfield, Nick Evans, Bethwyn Evans, Cathy Falk, Haofei Feng, John Ferlito, Janet Fletcher, William Foley, Nick Fowler-Gilmore, Steven Gagau, Lauren Gawne, Amit German, Cliff Goddard, Geneva Goldenberg, Tina Gregor, John Hajek, Jeremy Hammond, Michael Homsey, Tom Honeyman, Stuart Hungerford, Kari James, Katie Jepson, Jodie Kell, Sam King, Prash Krishnan, Marco La Rosa, Vi King Lim, Ewan Maidment, Allan Marett, David Marett, Julia Miller, Liana Molina, Kylie Moloney, Diego Mora, Mark Mosko, Aashild Naess, David Nathan, Peter Newton, Rachel Nordlinger, Carmel O&rsquo;Shannessy, Zephyr Pavey, Andrew Pawley, Murray-Luke Peard, Silvia Pfeiffer, Prashad Rajendra, Melody Ann Ross, Malcolm Ross, Alan Rumsey, Ely Ruttico, Ryan Schram, Jane Simpson, Robyn Sloggett, Juanita Sumner, Andrew Tanner, Nick Thieberger, Paul Trilsbeek, Jill Vaughan, Jacques Vernaudon, Michael Walsh, Nick Ward, Gillian Wigglesworth, and Aidan Wilson.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://delaman.org">https://delaman.org</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="http://www.language-archives.org">http://www.language-archives.org</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>These could also be called endangered languages, but that would limit the focus of our work. Whileendangeredis part of the name we established at the outset, it is probably not the most appropriate term to use to cover the many cultures and languages that continue to be spoken, even with few speakers, that are targeted by our work, hence my use of the termsmalllanguage, following<a class="footnote-ref" href="#dorian2014"> [dorian2014] </a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>ARDC and similar services all subscribe to the FAIR principles (<a href="https://www.force11.org/group/fairgroup/fairprinciples">https://www.force11.org/group/fairgroup/fairprinciples</a>) of Findable, Accessible, Interoperable, and Reusable data, but, without a long-term repository with licenses for re-use, data can not actually be FAIR beyond the current funding cycle.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p><a href="https://dublincore.org">https://dublincore.org</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p><a href="http://www.language-archives.org/">http://www.language-archives.org/</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p><a href="http://www.language-archives.org/">http://www.language-archives.org/</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p><a href="https://researchdata.edu.au">https://researchdata.edu.au</a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p><a href="https://trove.nla.gov.au/">https://trove.nla.gov.au/</a>&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p><a href="https://language-archives.services/about/pi/">https://language-archives.services/about/pi/</a>&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p><a href="https://language-archives.services/about/data-loader/">https://language-archives.services/about/data-loader/</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p><a href="https://dx.doi.org/10.4225/72/56E7A74251D08">https://dx.doi.org/10.4225/72/56E7A74251D08</a>You must be logged in as a registered user to access the files in this collection.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p><a href="https://paradisec.org.au/fieldnotes/AC2.htm">https://paradisec.org.au/fieldnotes/AC2.htm</a>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p><a href="https://dx.doi.org/10.4225/72/56E824684C625">https://dx.doi.org/10.4225/72/56E824684C625</a>&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p><a href="https://paradisec.org.au/fieldnotes/ROES/web/serieslist.htm">https://paradisec.org.au/fieldnotes/ROES/web/serieslist.htm</a>&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p><a href="https://www.delaman.org/project-lost-found">https://www.delaman.org/project-lost-found</a>&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p><a href="https://www.paradisec.org.au/Soundscape/index.html">https://www.paradisec.org.au/Soundscape/index.html</a>&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p><a href="https://glossopticon.com">https://glossopticon.com</a>&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p><a href="https://www.lenaherzog.com/last-whispers">https://www.lenaherzog.com/last-whispers</a>&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p><a href="https://www.paradisec.org.au/toksave-podcast">https://www.paradisec.org.au/toksave-podcast</a>&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>At the Endangered Languages Archive (London) and at the University of Hawa’i’ at Manoa, funded by the National Science Foundation, the ARC Centre of Excellence for the Dynamics of Language, and the Endangered Languages Documentation Programme.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p><a href="https://lameta.org">https://lameta.org</a>, written by John Hatton&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p><a href="https://www.nthieberger.net/sefate.html">https://www.nthieberger.net/sefate.html</a>&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p><a href="https://www.dese.gov.au/national-research-infrastructure/funded-research-infrastructure-projects">https://www.dese.gov.au/national-research-infrastructure/funded-research-infrastructure-projects</a>&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p><a href="https://arkisto-platform.github.io/">https://arkisto-platform.github.io/</a>## Bibliography&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Follow the Money?: Funding and Digital Sustainability</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="related" type="text/html" title="Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="related" type="text/html" title="Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="related" type="text/html" title="From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction to Special Issue: Project Resiliency in the Digital Humanities"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000660/?utm_source=atom_feed" rel="related" type="text/html" title="No Boutique or Fashionable Technologies: Project Development, Mentorship, and Sustainability in an Innovation-First World"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000666/</id><author><name>Jessica Otis</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>Humanities scholarship requires funding, whether for books or journals, database access or server space, research assistants or a trip to the archives, or simply a scholar&rsquo;s time to think and create. In the traditional book- and article-based humanistic workflows, colleges, universities, archives, special collections, publishers, and libraries have established labor and funding models that aim to support text-based research, writing, publishing, distribution, and preservation pipelines. But digital humanities (DH) projects don&rsquo;t fit neatly into these pipelines and digital humanists often struggle to work within these preexisting labor and funding models. While the differences between traditional and digital forms of humanities scholarship can cause funding difficulties at any stage of a DH project&rsquo;s lifecycle, these differences are particularly problematic when it comes to sustainability.</p>
<p>There are two common funding narratives often associated with DH projects in the United States. First, that DH projects are always grant-funded and that digital humanists are thuscash cowswho bring in large amounts of external funding into an institution with projects that could be accomplished only due to those infusions of outside cash. And second, that the open-source, open-access, and collaborative ethos of DH makes it possible for scholars to do DH forfree,without any institutional investments. Neither narrative is entirely false — and, indeed, thefreeproject model is crucial for many contingent and independent scholars who lack institutional support — but not only do most DH projects exist somewhere on the spectrum betweenfreeandfully funded,but also each narrative obscures the financial realities that exist at those poles.</p>
<p>No DH project is ever free; even if no money changes hands, there are always real costs associated with the work.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> At minimum, afreeDH project created by a single independent scholar with open-source software on their personal computer relies on the donated labor and resources of both that scholar and the community that created and shared the software. Larger DH projects with multiple collaborators rely on the donated labor and resources of all the project team members. If the project is web-facing, these donated resources may include real money for costs such as domain name registration or server space rental. Collaborators with access to institutional resources also effectively donate those resources to the project team on behalf of their institutions — from the costs of their salary and benefits, to hardware and software costs, to office space and utilities, to interlibrary loans and database access, and more. Some collaborators further involve their students as a source offreeproject labor — exchanging student labor for course credit in a model that should involve significant additional labor from the instructor.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> As a funding model, then, thefreeproject model is actually a self-funded or collaborator-funded project model.</p>
<p>When projects reach the limits of what can be accomplished forfree,or are conceived of in such a way that they can&rsquo;t even be attempted in such a model, one of the common next steps is for the project leaders to shift towards the other pole and seek grant funding — something that usually, though not always, requires institutional backing.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> US university and college administrators are particularly pleased when humanists join scientists and social scientists in bringing in outside funds to support both scholarly research and the overall operating costs of the institution. However, the grant application process itself has real costs, primarily in the form of the labor to write and submit the applications, which can take from days to weeks depending on how involved the application process is. Furthermore, most humanities grants are capped at a low dollar amount compared to other disciplines and funding ratios for both major <em>and</em> minor grants are also comparatively low. As of 2021, two of the major US grant opportunities that support digital project creation — the National Endowment for the Humanities (NEH) Digital Humanities Advancement Grants and Digital Projects for the Public — together fund a mere 30 projects a year, with a 14-15% funding ratio and maximum awards of $400,000.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> On average, then, an institution should expect to submit 6-7 DH grants to the NEH to get one success, translating to tens of thousands of dollars of investment with no guarantee of a return. Grant writing is thus a resource-intensive gamble that doesn&rsquo;t always pay off, especially for scholars playing outside a research-intensive institution who lack access to infrastructures designed to support grant writing and administration.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<p>Each of these models has implications for project sustainability, here defined as keeping the project live on a server and accessible to members of the public through typing a URL into a browser. This is different from preserving a digital project or keeping thebitsof the project safe somewhere — such as zipping up files and placing them into an institutional repository — even if they are not easily accessible.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> The sustainability of self-funded projects is reliant on team members continuing to invest their personal resources into — and generate internal team enthusiasm for — the project. If leadership and enthusiasm can be maintained, these projects have the potential to live on indefinitely. But this stream of donations can dry up at any time, at which point the project will begin to fall apart. Web-facing projects will even abruptly disappear at the first failure to renew server space rental or domain name registration.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> By contrast, grant-funded projects have pre-determined end dates; they can generally be relied upon to survive to that point, but afterwards no more funds will be forthcoming from the granting body. Unless the project team successfully finds a different source of funding to sustain the project — often in the form of new grant applications — it will begin to die slowly the day its grant funds run out.</p>
<p>While both funding models can work reasonably well for the traditional humanities research output of printed books, neither model is ideal to meet the sustainability requirements of digital projects. Both printed books and digital projects require a major initial investment, in time and research materials, to produce. But after the book is printed, it is no longer the creator&rsquo;s responsibility. Instead, hundreds, thousands, or tens of thousands of effectively identical copies are scattered across the globe. And the upkeep costs are low for each individual copy placed on a scholar&rsquo;s or a library&rsquo;s bookshelves: once an appropriate space is set up to hold bookshelves, the marginal cost of each additional book added to those shelves is negligible until there is no more room and either collection items must be deaccessioned or the space must be expanded again.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> Barring a roof leak, mouse infestation, or careless coffee spills, the book may remain in good shape for decades without much if any active curation; indeed, most books survive best by being left alone.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> In the carefully controlled environments of a special collections vault, books can last centuries. And as long as at least one physical copy of a book survives, its scholarly contents survive as well. Books thus require an upfront, time-limited financial investment for production, after which point their survival is turned over to a distributed series of owners who pay a set infrastructural cost to sustain hundreds, thousands, or millions of these physical objects.</p>
<p>While digital technologies are all too new to know if any DH projects will last for centuries, right now most are struggling to even last years, much less decades<a class="footnote-ref" href="#davis2019"> [davis2019] </a>. In stark contrast to books, digital projects are generally centralized to one copy, and they decay if they are not actively maintained.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> From a financial perspective, sustaining a digital project is more akin to sustaining a car than a book.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> Like a newly-purchased car, DH projects tend to run well for five to seven years with minimal recurring costs for server space or domain name renewal, only to begin to suffer increasingly dramatic breakdowns that require equivalently heftymechanic&rsquo;s billsto fix.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> And after a decade or maybe two, both cars and DH projects reach a point where they either become too much trouble to be worth fixing or they reachclassic carstatus and are deemed worth saving regardless of the costs.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> Unfortunately for digital humanists, book-based financial models falter and fail when faced with afleetof digital objects whose costs are ongoing, increasing, and directly related to the number of objects that need to be sustained.</p>
<p>The first step for ensuring the financial sustainability of a digital project is thus to understand the technical construction — and associated maintenance costs — of complex digital objects and plan accordingly. Simply being able to accurately predict the ongoing costs of sustaining a website will help ensure that any funding plan is adequate to meet the project&rsquo;s technical needs for its expected lifespan. A custom-coded phoneappwill be more difficult and expensive to sustain than a website based on an open-source content management system (CMS) such as WordPress, which in turn is more difficult and expensive than a website without an underlying database, such as aflatwebsite built only with HTML, CSS, and JavaScript. If the predicted funding requirements of sustaining the project end up too high, then building — or planning to reduce a project upon its completion — to the minimum viable complexity will reduce the sustainability costs of the project to a more achievable level. Once a project&rsquo;s needs have been identified, scholars can seek funding from a variety of diverse sources, prioritizing those that best fit the project.</p>
<p>Scholars associated with institutions can start by taking advantage of hard-funded institutional resources, such as specialized email addresses, listservs, or subdomains of their institutional domain, which have low marginal costs to the institution and are likely to be made available to employees who have a need for them. In institutions with more resources, IT services or the library might even supply shared server space for projects running a specific CMS, along with basic systems administration services such as keeping a WordPress installation and its plug-ins up to date. Hard funding and institutional inertia will help sustain projects built with such resources, so long as their creators remain associated with the institution, the projects continue to see active use, and nothing opens up the institution to legal or security threats — e.g. violating GDPR through listserv mis-management or using obsolete and vulnerable CMS plug-ins that open shared server spaces to hackers.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> And in the most well-resourced institutions, scholars may have access to student research assistants, course releases, or other research funds that can be deployed in support of digital project costs.</p>
<p>In addition to hard-funded resources, institutions can give scholars access to a variety of irregular — but still internal — funding sources. Research-intensive institutions often provide access to start-up funds and internal funding competitions for prototyping, with the implicit or explicit goal of leveraging those prototypes into external funding to further implement those projects. Some may even have internal, endowed prizes that could be sources of unrestricted funds; while they are rarely huge amounts of money, they may still be a significant source of project funds for humanities scholars who regularly apply for external grants as small as $500 or $1000 USD. But the biggest source of irregular institutional income by far is appropriations — money set aside for specific centers, departments, or projects — from friendly administrators who see the value in promoting DH on their campuses. While these funds sometimesroll overfrom year to year, the funds are more likely to be allocated on an annual basis, vanishing at the end of the budget year if not spent. These &ldquo;use or lose&rdquo; funds are good targets — especially for scholars with existing high-profile projects that need a brief bump in sustainability support, such as to pay for a CMS upgrade — because they must be spent down every year for the administrative unit in question to receive the same amount, or more, in their budget for the following years.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> The funds themselves come from a wide variety of sources, including tuition dollars, government appropriations for public institutions, endowment income for wealthier institutions, and grant overheads for research-intensive institutions.</p>
<p>Beyond institutional support there are, of course, external sources of financial resources. Digital humanists regularly participate in the grant economy, seeking funds from government agencies, foundations, not-for-profits, and corporations.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> Grants might seem like the optimal solution to digital humanists&rsquo; funding problems, as they entail receiving funding for a specific length of time to generate a specific project, much as other humanists are funded to visit a specific archive or come under contract to write a specific book. A variety of funders offer grants of varying sizes for the creation of digital projects, which makes it possible to align a scholarly agenda with the agenda of those funders in order to create something mutually beneficial. Furthermore, grants come with numerous additional benefits, including a peer review process that helps to establish the digital project&rsquo;s scholarly value prior to the investment of significant time and money; built-in project publicity from the grant funding announcement; and institutional and external prestige for having won a grant.</p>
<p>However, the grant-funding ecology favors the sciences and is not always friendly to humanists. Anyone applying for grant funding in the humanities will quickly recognize there are a limited number of major funders — the US has the NEH and ACLS, and other nations have their own analogous funders — and most of them have limited funding available for specific projects. These grants are not always sufficient to complete, much less sustain, a project, which means scholars must create projects in stages and occasionally creatively re-envision the project. Scope creep — adding unnecessary features to make a project appealing to a new funder — is an ever-present danger that must be guarded against. Opportunities may also be limited by funder agendas. If a project could go two directions and only one is fundable, choosing that direction is not scope creep, but it is a lost opportunity. Similarly, institutional and funder requirements may limit team members&rsquo; participation — insisting, for example, that team leaders have PhDs or be citizens of specific countries — and prohibit specific project activities, such as event catering. Funders also, quite reasonably, expect grantees to spend funds on the activities they agreed to fund; pivoting the project to new, unanticipated directions thus requires obtaining funder permission.</p>
<p>But the biggest funding issue, from a sustainability perspective, is the fact that grant-funding is term limited. No matter if a grant is for one, three, five, or more years, there is always a planned end to the financial support. There are ways to avoid a hard cut-off of funds, for example by writing a pre-payment for hosting or other sustainability costs into the budget. Scholars should also become familiar with their institution&rsquo;s policies on grant overhead, a surcharge added to all direct grant expenses intended to support the general operating of the institution.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> A percentage of these funds often &ldquo;trickles down&rdquo; from the institution writ large through the scholar&rsquo;s various administrative units — e.g. some goes to the university for general operating expenses, some to the scholar&rsquo;s college, some to the scholar&rsquo;s department, and some to the scholar themselves. For scientists, these overhead funds often help support their lab infrastructure. For digital humanists, these overhead funds can be funneled back into a project to support its long-term sustainability. However, these funds can only extend grant support so far past the grant&rsquo;s end date.</p>
<p>While there are no easy solutions to sustainability funding, the last decade has seen a growing sentiment that not everything needs to be free on the internet and that independent artists, writers, and other digital content creators should be paid for their work.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> Digital humanists can and should view themselves as digital content creators and pay attention to the business models “indies” use to support themselves. Not all these models will be appropriate to adopt — e.g. for scholars associated with an institution, a grant will bring more prestige and fit better into institutional workflows than a Kickstarter campaign — but an awareness of these models will help scholars creatively seek and acquire funding to create and sustain their projects.</p>
<p>Any list of current indie business models is likely to age poorly, and it&rsquo;s less important to debate the benefits of Patreon vs. Kofi vs. BuyMeACoffee here than to note the existence of business models based on community support. Universities and other large institutions are accustomed to fundraising for large amounts of money, because it costs money to process donations and a $1 USD donation might actually cost more to process than the donation itself. However, there are now and will likely continue to be a variety of platforms that support tip-jar-style microdonations of $1, $5, or even 10¢. There are also platforms that allow audience members to sponsor — or provide recurring donations to — creators, often in exchange for exclusive or early access to content. Freemium models — with a large amount of content available for free and additional content or services available for money — are also popular, and WordPress.com runs on this model; one can create a basic WordPress site on a WordPress.com subdomain for free, but it costs money to remove the advertisements and have a custom URL<a class="footnote-ref" href="#wordpress"> [wordpress] </a>. The Mozilla Foundation — creators of Firefox — have similarly been exploring freemium models to reduce digital advertising and support user privacy.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> And while advertisements can annoy users and raise ethical considerations about advertised content, they are an established model for earning revenue on free content. Podcast advertising, in particular, is a growing market segment that podcasting scholars should be aware of<a class="footnote-ref" href="#interactive2021"> [interactive2021] </a>. Crucially, these are all models that often are effective for people or projects with robust pre-existing audiences, which is often a key factor in determining which digital projects in a person or institution&rsquo;s portfolio should be prioritized for sustainability funds.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup></p>
<p>With no one set path for financing their work, digital humanists need to use a variety of funding strategies across their digital projects&rsquo; lifespans, optimizing strategies to fit a project’s evolving needs. Strategies that work well during the creation phase of a project are often insufficient to sustain the project after its completion, when it needs to be actively maintained for continued public access. Digital humanists need to be flexible about seeking money for their work — both from within their institutions and outside of it — and pay attention to larger funding trends among independent digital content creators. But most importantly, digital humanists need to be clear-sighted about the real costs of their project, aware of their prospective future revenue streams, and proactive in minimizing the technical complexity of projects so that their future revenues are able to cover future costs. Digital humanists need to follow the money — not in the sense of continuously reimagining their scholarly agendas to fit those of funders, but rather in the sense of understanding their project&rsquo;s technical needs, the real costs of that work, and the various avenues available for funding their project at every life stage. Only then can they choose paths that accomplish their intellectual objectives in a fiscally sustainable manner.</p>
<ul>
<li id="davis2019">Davis, R. C. (2019) “The Final Death(s) of Digital Scholarship — An Ongoing Case Study of DH2005 Projects” . Available at:<a href="https://www.robincamille.com/presentations/death_of_digital_scholarship/">https://www.robincamille.com/presentations/death_of_digital_scholarship/</a>.
</li>
<li id="estill2020">Estill, L. (2020) “Legacy technologies and digital futures” in Crompton, C., Lane, R, and Siemens, R. (eds.), _Doing More Digital Humanities_ . New York: Routledge, pp. 7–24.
</li>
<li id="fcphillipa2015">FC_Phillipa. (2015) “Don't work for free – people die of exposure!”  _Freelance Confidence_ . Available at:<a href="http://freelanceconfidence.com/dont-work-free-people-die-exposure/">http://freelanceconfidence.com/dont-work-free-people-die-exposure/</a>.
</li>
<li id="goddard2020">Goddard, L. and Seeman, D. (2020) “Negotiating Sustainability: Building digital humanities projects that last” in Crompton, C., Lane, R, and Siemens, R. (eds.) _Doing More Digital Humanities_ . New York: Routledge, pp. 38–57.
</li>
<li id="grant"> “Grant for the Web” . (n.d.) Available at:<a href="https://www.grantfortheweb.org">https://www.grantfortheweb.org</a>.
</li>
<li id="harvard">Harvard University, (n.d.) “Indirect Costs” . Available at:<a href="https://research.fas.harvard.edu/indirect-costs-0">https://research.fas.harvard.edu/indirect-costs-0</a>.
</li>
<li id="interactive2021">Interactive Advertising Bureau. (2021) “U.S. Podcast Ad Revenues Grew 19% YoY in 2020; set to exceed $1B this year and $2B by 2023” . Available at:<a href="https://www.iab.com/news/us-podcast-ad-revenues-grew-19-yoy-in-2020-set-to-exceed-1b-this-year-and-2b-by-2023/">https://www.iab.com/news/us-podcast-ad-revenues-grew-19-yoy-in-2020-set-to-exceed-1b-this-year-and-2b-by-2023/</a>.
</li>
<li id="keralis2018">Keralis, S. D. C. (2018) “Disrupting Labor in Digital Humanities; or, The Classroom is Not Your Crowd” in Kim, D. and Strommel, S. (eds.), _Disrupting the Digital Humanities_ . New York: Punctum Books. pp. 273–294. Available at:<a href="https://library.oapen.org/handle/20.500.12657/25400">https://library.oapen.org/handle/20.500.12657/25400</a>.
</li>
<li id="leckie2013">Leckie, A. (2013) “People Die of Exposure” . _Ann Leckie Blog_ , Available at:<a href="https://annleckie.com/2013/06/10/people-die-of-exposure/">https://annleckie.com/2013/06/10/people-die-of-exposure/</a>.
</li>
<li id="lucas2020">Lucas, M. W. (2020) _Cash Flow for Creators: How to Transform Your Art Into a Career_ . n.p.: Tilted Windmill Press.
</li>
<li id="meneses2019">Meneses, L. and Furuta, R. (2019) “Shelf life: Identifying the abandonment of online digital humanities projects” , _Digital Scholarship in the Humanities_ , 34, pp. 129–134, Available at:<a href="https://academic.oup.com/dsh/article/34/Supplement_1/i129/5270841">https://academic.oup.com/dsh/article/34/Supplement_1/i129/5270841</a>.
</li>
<li id="mozilla">Mozilla Foundation. (n.d.) “Unfck the Internet” . Available at:<a href="https://web.archive.org/web/20220608064838/https://www.mozilla.org/en-US/firefox/unfck/">https://web.archive.org/web/20220608064838/https://www.mozilla.org/en-US/firefox/unfck/</a>.
</li>
<li id="neha">National Endowment for the Humanities. (n.d.a.) “Digital Projects for the Public” . Available at:<a href="https://www.neh.gov/grants/public/digital-projects-the-public">https://www.neh.gov/grants/public/digital-projects-the-public</a>.
</li>
<li id="nehb">National Endowment for the Humanities. (n.d.b.) “Digital Humanities Advancement Grants” . Available at:<a href="https://www.neh.gov/grants/odh/digital-humanities-advancement-grants">https://www.neh.gov/grants/odh/digital-humanities-advancement-grants</a>.
</li>
<li id="nehc">National Endowment for the Humanities. (n.d.c.) “NEH's Application Review Process” . Available at:<a href="https://www.neh.gov/grants/application-process">https://www.neh.gov/grants/application-process</a>.
</li>
<li id="nsf">National Science Foundation. (n.d.) “Funding Rate by State and Organization from FY 2019 to 2020 for NSF” . Available at:<a href="https://dellweb.bfa.nsf.gov/awdfr3/default.asp">https://dellweb.bfa.nsf.gov/awdfr3/default.asp</a>.
</li>
<li id="otis2023">Otis, J. (2023) “Managing the Digital Backlist: Sustaining, Preserving, and Deleting Old Projects” .The Dev Log. Available at:<a href="https://jessicaotis.com/digital-humanities/managing-the-digital-backlist/">https://jessicaotis.com/digital-humanities/managing-the-digital-backlist</a>.
</li>
<li id="scire2020">Scire, S. (2020) “Scroll and Mozilla's Firefox team up to bring ad-free news to a wider audience” . Available at:<a href="https://www.niemanlab.org/2020/03/scroll-and-mozillas-firefox-team-up-to-bring-ad-free-news-to-a-wider-audience/">https://www.niemanlab.org/2020/03/scroll-and-mozillas-firefox-team-up-to-bring-ad-free-news-to-a-wider-audience/</a>.
</li>
<li id="smithies2019">Smithies, J., Westling, C., Sichani, A., Mellen, P., and Ciula, A. (2019) “Managing 100 Digital Humanities Projects: Digital Scholarship & Archiving in King's Digital Lab” . _Digital Humanities Quarterly_ 13(1). Available at:<a href="http://digitalhumanities.org:8081/dhq/vol/13/1/000411/000411.html">http://digitalhumanities.org:8081/dhq/vol/13/1/000411/000411.html</a>.
</li>
<li id="wordpress">Wordpress.com (n.d.) “There's a plan for you” . Available at:<a href="https://wordpress.com/pricing/">https://wordpress.com/pricing/</a>.
</li>
<li id="zittrain2021">Zittrain, Jonathan. (2021) “The Internet is Rotting” (originally published as “The Internet is A Collective Hallucination” ). _The Atlantic_ . Available at:<a href="https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/">https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/</a>.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I would like to thank the folks at the Nonprofit Finance Foundation, especially Robert Kagan and Cecil Daniels, for introducing me to the concept of real costs.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>I believe it <em>is</em> possible to incorporate work on active DH projects into for-credit courses, but only if the instructor is explicit about the conflicts of interest and prioritizes student learning outcomes over progress on the project. For a longer take on the ethical issues of using unpaid student labor on DH projects, see<a class="footnote-ref" href="#keralis2018"> [keralis2018] </a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>It is common for grants to be awarded to institutions rather than individuals, making it impossible for independent scholars to even apply for those grants in the first place unless they find a collaborator at an institution to serve as their project&rsquo;s figurehead.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Most of the grants awarded under these programs are for less than the maximum, especially as the advancement grants require matching funds to go above $350,000.<a class="footnote-ref" href="#neha"> [neha] </a>;<a class="footnote-ref" href="#nehb"> [nehb] </a>. Overall, the NEH funds approximately 900 projects a year, across all subject domains, whereas the National Science Foundation funds a whopping 12,000 projects a year, with an average award of over $400,000 and a funding ratio of 28%<a class="footnote-ref" href="#nehc"> [nehc] </a>;<a class="footnote-ref" href="#nsf"> [nsf] </a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Even within a research-intensive institution, access to grant writing and grant administrating infrastructure can vary dramatically, especially for scholars working in units without a history of receiving grants.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>For a book-based analogy: a sustained project is like a book on the open shelves of a library, whereas a preserved project is like one held in a special collections vault. See<a class="footnote-ref" href="#otis2023"> [otis2023] </a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>This is not a problem unique to DH projects. For more on the problem of link rot and disappearing websites see<a class="footnote-ref" href="#zittrain2021"> [zittrain2021] </a>and Coble &amp; Karlin in this issue.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>In addition to the sunk costs of creating such a space, there <em>are</em> costs to maintaining the space. However, these costs are effectively independent of the space&rsquo;s contents; adding a book or even 100 books to a bookshelf will have no measurable impact on the space&rsquo;s heating bill or property taxes.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Note, however, that not all books share the same physical properties — a book printed on acidic paper will have a far shorter lifespan and need greater curation than one printed to modern archival standards<a class="footnote-ref" href="#goddard2020"> [goddard2020] </a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>While diligent scholars may create numerous copies of their digital projects, and archive them in various places across the internet, these still pale in comparison to the number of physical objects printed in a single print run of a book. Furthermore, if these copies are not independently maintained, they are likely to face the same sustainability problems at the same time as links break (see Coble and Karlin in this issue), embedded content stops resolving, and outdated code leaves databases and servers open to hacking by malicious outside parties.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>No metaphor is perfect, including this one. There are absolutely times when a book-based metaphor makes more sense, such as when a junior scholar is trying to explain their digital project to a hiring or tenure committee. The car metaphor is specifically intended for discussions of the resources necessary to ensure digital projects&rsquo; sustainability. See<a class="footnote-ref" href="#otis2023"> [otis2023] </a>for my first use of the car metaphor.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>The average lifespan of a DH project is 5 years, which is about the same length as the extended warranty on a new car purchase<a class="footnote-ref" href="#meneses2019"> [meneses2019] </a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>The question of what projects to sustain and what projects to let decay or delete is a vexed one. While the intellectual merits of any particular project can be debated, there are some objective measures that can be used to assess them. These include the size of their userbase, whether they host unique or rare (born digital or digitized) cultural content, and whether they have been deemed prestigious by a scholarly community through, for example, citation as canonical works in a body of literature. These intellectual merits can then be placed in conversation with an analysis of the difficulty of remediation, current security risks, and projected long-term sustainability costs. For an example of this triage process, see<a class="footnote-ref" href="#smithies2019"> [smithies2019] </a>.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>For more on the problem oforphanedprojects that rely on institutional resources but no longer have an employee champion, see Cummings in this issue.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Whenever possible, scholars should compile metrics on their projects that can be used to make a case for support to administrators. A project that is regularly featured in news outlets, has won awards, or receives hundreds of thousands of site visits a year will be more attractive to administrators than a project without a tangible track record.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Corporations can also be a source of in-kind donations, especially data. Organizations with academic or teaching-centered business models — such as JSTOR, Gale, ProQuest, university presses, etc. — are often able and willing to provide data to scholars to help them achieve research goals. However, a more in-depth or long-term industry partnership is only likely if it eventually results in a monetizable product such as a subscription-only database or an educational resource that can be sold to teachers and students. While monetization can be good for sustainability — generating revenue that can be used to sustain the project itself — it may conflict with data-sharing agreements or field-wide expectations surrounding open access, and such arrangements should be approached carefully.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>While overhead is often a source of contention — especially when a third or half of a grant&rsquo;s already limited funds are taken up by such charges — it is important to recognize that the work of digital scholars is still embodied. Outside of an institutional setting, they might have had to pay rent, utilities, and a myriad of other expenses that are not directly charged to them within a university setting. Overhead payments help cover these real costs. This is not to defend, for example, Harvard University&rsquo;s current 69% overhead rate but rather to explain the general purpose of such funds<a class="footnote-ref" href="#harvard"> [harvard] </a>.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>This can be best summarized by a common creators&rsquo; retort to offers of beingpaidin exposure: “people die of exposure.” See, for example,<a class="footnote-ref" href="#leckie2013"> [leckie2013] </a>,<a class="footnote-ref" href="#fcphillipa2015"> [fcphillipa2015] </a>, and<a class="footnote-ref" href="#lucas2020"> [lucas2020] </a>.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>See for example<a class="footnote-ref" href="#mozilla"> [mozilla] </a>,<a class="footnote-ref" href="#grant"> [grant] </a>, and<a class="footnote-ref" href="#scire2020"> [scire2020] </a>.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>At the Roy Rosenzweig Center for History and New Media, we assign the highest priority to sustaining sites that receive over 100,000 unique visitors a year, whereas sites that receive less than 1,000 unique visitors a year are likely to be archived rather than sustained once their functionality begins to deteriorate. For sites in between, we look at the difficulty of remediation, security risks, intellectual merits, and project prestige to help assess whether sites that have begun to break should be remediated in their original format or flattened to static HTML/CSS/JS to ensure their sustainability with minimal additional investment of time or money.## Bibliography&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000660/?utm_source=atom_feed" rel="related" type="text/html" title="No Boutique or Fashionable Technologies: Project Development, Mentorship, and Sustainability in an Innovation-First World"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="related" type="text/html" title="Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="related" type="text/html" title="Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="related" type="text/html" title="Follow the Money?: Funding and Digital Sustainability"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction to Special Issue: Project Resiliency in the Digital Humanities"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000668/</id><author><name>Martin Holmes</name></author><author><name>Joey Takeda</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="1-introduction">1. Introduction</h2>
<p>This article, by two of the technical leads on Project Endings, represents the culmination of all we have learned over the last few years, during which we have rescued over a dozen projects from death by software obsolescence and reconstituted them as entirely static, standalone websites with minimal dependencies. We now know a great deal, mostly from our own mistakes, about how not to build robust, long-lasting digital resources, and we have developed a set of principles, practices, and software tools which we believe provide solid defences against digital extinction. Below, we describe the institutional context within which Project Endings was born, and lay out methodically the guiding principles by which we now develop digital editions and other web resources.</p>
<h2 id="2-early-days">2. Early Days</h2>
<p>What is now the Humanities Computing and Media Centre (HCMC) at the University of Victoria was once simply the Language Centre, a unit whose role was to maintain language laboratories and computer workstations and to write software applications used for language teaching courses. We had both Macintosh and Windows workstations, and would typically write custom software for either platform but not both, since writing cross-platform software applications was quite difficult in the days before the World Wide Web (WWW) and Java. When the Web first appeared, we seized on it enthusiastically as a practical way to provide language-teaching resources which could be delivered not only on both kinds of workstation in our labs but also to other locations. When JavaScript emerged around 1996, we were blessed with the capability to create truly interactive programmed teaching exercises, and by the turn of the millenium we had built language-teaching exercise collections for many languages, as well as desktop authoring tools to make the creation of such pages easy for non-coders (<a href="#arneilHolmes1998">Arneil and Holmes 1998</a>,<a href="#arneilHolmes1999">1999</a>, and<a href="#arneilHolmes2001">2001</a>).</p>
<p>The materials we created during this period still exist, and they still work perfectly. Examples can be seen in the Indonesian course materials created in 1999 (<a href="https://web.uvic.ca/hrd/indonesian/">https://web.uvic.ca/hrd/indonesian/</a>) and the endearingly-dated “Web Language” online presentation<a class="footnote-ref" href="#holmes1997"> [holmes1997] </a>, originally created in 1997 and last updated in 1999. The latter includes a feedback form which is still regularly used, so it still clearly has some relevance despite its appearance. The HTML and JavaScript is still fully functional, although non-standards-based cutting-edge technologies of the time, such as RealAudio, no longer work of course.</p>




























<figure ><img loading="lazy" alt="The home page and an example exercise from the Beginning Indonesian site, dating from the late 1990s." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of Beginning Indonesian homepage (left) and exercise (right). Screenshot taken in 2021, but it looked the same in 1999.
        </p>
    </figcaption>
</figure>
<p>In the early 2000s, the Language Centre was transformed into the Humanities Computing and Media Centre, and given a wider mandate to support what was then commonly termed Humanities Computing, now Digital Humanities. Better-funded projects came along, and more ambitious coding was undertaken, supporting not only language-teaching resources but also digital edition projects, historical datasets, mapping initiatives, and many other research and teaching activities. In particular, we developed some expertise in TEI and the XML-related languages, and began to create large online document collections such as the <em>Colonial Despatches</em> project (<a href="https://bcgenesis.uvic.ca/">https://bcgenesis.uvic.ca/</a>) and <em>Le Mariage sous l’Ancien Régime</em> (<a href="https://mariage.uvic.ca/">https://mariage.uvic.ca/</a>). In place of static (albeit interactive) web pages, we started to build more sophisticated web applications based on PHP/MySQL database stacks and the eXist XML database.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> Now blessed with our own server infrastructure thanks to the ground-breaking Canadian TaPOR (Text-Analysis Portal) initiative, we were able to run Tomcat, Cocoon, Postgresql, and a host of other backends to support the growing variety of DH projects under way at our institution.</p>
<p>These server-side systems enabled us (along with the rest of the DH community) to build resources which were more coherent and easier to maintain; information about a single entity, individual, or place could be encoded or stored in a single record, but retrieved and displayed in a multitude of contexts wherever it was needed. Documents could be transcribed and encoded once, but decorated and rendered in many different ways based on the needs of the user or the application context. Sophisticated searching, grouping, and presentation options were easy to implement. Beginning in 2003 we generated a large number of these projects; our servers were well-populated and their CPUs were busy running XQuery, XSLT, PHP, SQL, and even ASP code.</p>
<p>As Lou Burnard (<a href="#burnard2016">2016</a>) remarks, “nothing in digital form is ever really finished.” DH projects may languish untended and unloved for periods of time, but their progenitors typically intend to continue working on them periodically or when funding allows. Setting up such projects implies a commitment to maintaining them, and as our project portfolio burgeoned, so did our maintenance burden. As we moved into the 2010s and onwards, a clear pattern began to emerge: projects created in the 1990s continued to work as intended with virtually no maintenance at all, but the projects we had built on sophisticated backend systems such as MySQL and eXist required frequent and time-consuming maintenance work. As an example, the <em>Robert Graves Diary</em> (<a href="https://graves.uvic.ca/">https://graves.uvic.ca/</a>), one of our earliest digital edition projects, was originally written based on eXist version 0.9 in 2003–2004; it had to be steadily revised throughout 2005–2007, and then completely rewritten for eXist 1.4 in 2012, because the original Tomcat/Cocoon/eXist 0.9 stack became obsolete. Then in 2014 it had to be updated again. This was a project on which the core academic work had been completed in the first phase of the project, but due to infrastructure churn it regularly returned to haunt us. Over the years, we amassed a maintenance burden which threatened to overwhelm our ability to support new projects coming through our doors.</p>
<p>This problem was the impetus for Project Endings. The Web had solved for us the challenge to “write once, run anywhere” ;<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> the issue we were now addressing was how towrite once, run forever.Project Endings brought together a team consisting of academic digital humanists, programmers, and librarians, along with a selection of active, complex digital edition projects, to determine how we could best plan, execute, and archive our projects in such a way that they would live on indefinitely without further maintenance.</p>
<h2 id="3-a-catalogue-of-failures">3. A Catalogue of Failures</h2>
<p>In the early days of the Endings project, we began to examine in detail how our older digital editions and sites had progressively broken down. Some problems were obvious: obsolete versions of server-side applications and services (MapServer, MySQL, PHP) had been retired or replaced, and old code would not run on new versions, even if new versions existed. Other failures were more subtle. We investigated, for example, how successfully our applications had been archived by The Internet Archive (<a href="https://archive.org/">https://archive.org/</a>) and reproduced on the Wayback Machine (<a href="https://archive.org/web/">https://archive.org/web/</a>). It was immediately obvious that sites built on backend databases, wherepageswere in fact queries to the database, were very problematic. The project <em>Le Mariage sous l’Ancien Régime</em> , which linked to its anthology documents using URLs that queried the server (e.g. <code>http://mariage.uvic.ca/xhtml.xq?id=le_bourgeoise_desprit</code> ), was scarcely archived at all, presumably because the archive crawler was unable to follow or parse the query-based links successfully, so for the most part, the archived versions of the site consist mainly of notices that “The Wayback Machine has not archived that URL.”</p>




























<figure ><img loading="lazy" alt="An error page from the Wayback Machine, which has failed to archive a web page whose content is retrieved using a query string." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Wayback Machine error page
        </p>
    </figcaption>
</figure>
<p><em>Mariage</em> also had a rather gratuitous feature whereby the end user could choose between three available colour schemes, and because that functionality relied entirely on JavaScript, the required CSS files had been retrieved and stored as though they were HTML pages, and no styling appeared on the site pages at all. Site search engines failed completely, as did any annotation popups linked from texts which relied on retrieving data by querying the backend database, and JavaScript-based interactivity was generally broken. In fact, the majority of our large-scale, high-profile digital edition projects were scarcely functional at all in the Wayback Machine, and most of their content had not even been retrieved and stored.</p>
<p>The Internet Archive had never been one of our primary backup strategies, but it was disappointing to discover how unsuccessful it had been in its attempts to crawl and reproduce our sites. Although some of these failures could perhaps be laid at the door of the Internet Archive crawler, Heritrix, which had some limitations, most of them were clearly our fault, and resulted from our crude approach to URL construction. One site, the <em>Robert Graves Diary</em> , was represented by only a handful of static pages, since the majority of its content was designed to be accessed through explicit searches from the home page, with the search parameters encoded in URL query strings; the crawler would have had no way to know what pages existed on the site other than the few information and background pages linked directly from the home page. On the live versions of these sites, any pages accessed by a user were typically constructed on the fly by XQuery and XSLT, so they did not exist in any form which could be backed up even locally by any normal method.</p>
<p>Digging deeper into methods for backing up and replicating our projects within our own institution revealed other problems. Some sites and applications included hard-coded links to local resources using absolute URLs rather than relative ones, so if the site were replicated in a different location, it would still be dependent on, and prone to send the user over to, the original site.</p>
<p>Another problem faced by projects backed by online databases was a lack of consistency in versioning of content. Typically, multiple project members had rights to upload new material directly into the live database, thuspublishingit, but there was no attempt to ensure that the current state of the live site was — in Endings parlance — “coherent, consistent, and complete” (see<a class="footnote-ref" href="#holmesTakeda2019b"> [holmesTakeda2019b] </a>). Someone editing a primary source text might upload a new chapter to the site, forgetting that it contained links to newly-added people in the personography or locations in the placeography which also needed to be uploaded, so those links would fail. Everypagemight have a different publication date, and the site overall had no version or edition information, so anyone citing it would be forced to fall back on the rather unfortunatelast accesseddate to anchor their citation, knowing that the specific version of the document they were citing might change tomorrow with no warning and no way to retrieve the previous version. This was a problem of project organization rather than a technical issue, and it arose largely out of the working methods emerging in the early 2000s. In the excitement provoked by the new affordances and publication possibilities inherent in digital projects, there was a tendency to publish anything and everything as quickly as possible. A measured and thoughtful approach torolling publicationis of course possible, but, as we discuss in section 5.5, our work on Endings has convinced us that for most projects, a more traditional edition-based methodology is better.</p>
<p>Finally, we were forced to acknowledge that few of our projects had adequate documentation, making remediation and reconstruction doubly difficult.</p>
<p>We had, it seemed, spent a dozen years enthusiastically generating fragile, unmanageable, unmaintainable, unarchivable contraptions, and we were going to pay the price for our thoughtlessness.</p>
<p>This is not an unusual situation. In fact, our research suggests that it is the norm for DH projects.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> Many DH web applications are built rapidly, using off-the-shelf frameworks and libraries which date quickly and are ultimately guaranteed to fail, and most projects either rebuild their applications in repeated cycles of funding, or see them languish and ultimately disappear. Our situation was perhaps more pointed and critical because we are a base-funded unit with a long lifetime, committed to maintaining our projects even after their initial funding is exhausted. Units like ours are still relatively rare; in most cases, there is little or no institutional help and no expectation of any. But having caused the problem, we now had to fix it, not just by rebuilding multiple large projects, but by doing so in such a way that we would not have to do the same work again in another ten years.</p>
<h2 id="4-the-endings-project">4. The Endings Project</h2>
<p>The Endings Project was set up as a formal collaboration between the HCMC programmers grappling with the issue of project obsolescence, four Principal Investigators leading some of our largest and longest-running active projects, and a group from the University Library that specialized in digital preservation and collections. We began with the aim of researching, formalizing, and testing a range of strategies for rewriting four projects — <em>The Map of Early Modern London</em> , <em>Le Mariage sous L’Ancien Régime</em> , the <em>Nxaʔamxcín Dictionary Database</em> , and <em>The Robert Graves Diary</em> — with longevity in mind. The project, formally titled Endings: Concluding, Archiving, and Preserving Digital Projects for Long-Term Usability, was funded by the Social Sciences and Humanities Research Council of Canada (SSHRC) for four years starting in April 2016. Since then, we have added many more projects, some new and some dating back many years, to the project portfolio, and there are now 14 projects under the Endings umbrella. Each individual project has provided its own unique set of challenges and resulted in fresh ideas and strategies as we have learned to build static sites from them.</p>
<p>The Endings project has produced a range of outputs, including a survey with follow-up interviews, software, many articles and presentations, many static-site digital editions,<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> and the 2021 symposium from which this special issue was born. But perhaps the most important outcome of our work has been the set of principles that codifies our approach to site-building.</p>
<h2 id="5-endings-principles-or-from-tamagotchis-to-pet-rocks">5. Endings Principles, or: from Tamagotchis to Pet Rocks</h2>
<p>Readers of a certain age may remember the 1990s craze for the Tamagotchi, an electronic device that was designed to mimic a pet animal by requiring regular attention — feeding, education, play — from its owner in order to keep it healthy.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> Our digital edition projects had become rather like Tamagotchis in requiring constant tending simply to keep them functional. Slightly older readers, however, may remember a similar, pre-digital fad from the 1980s. The Pet Rock was exactly what it purported to be: a piece of rock, which required nothing whatsoever from its owner. “A rock would not need to be fed, walked, bathed, or groomed, and it would not die, become sick, or be disobedient” (<a href="https://en.wikipedia.org/wiki/Pet_Rock">Wikipedia</a>). Our Endings mission was to devise methods for turning our Tamagotchis into Pet Rocks.</p>
<p>The Endings Principles present a set of simple guidelines for this process, and are intended for two audiences: researchers who have Tamagotchi projects that are already too needy, and who are looking for an exit strategy; and (more importantly) researchers in the early stages of planning and setting up new projects, who are in a position to build a sustainable, low-maintenance digital edition from the outset.</p>
<p>This article lays out and discusses version 2.2 of the Endings Principles. This version does not differ substantially from the initial draft, first published on the Endings website in 2018, but the major sections have been re-ordered. Those sections cover the five principal aspects of a digital edition project which we consider to be crucial in designing for longevity: Data, Documentation, Processing, Products, and Release Management.</p>
<h2 id="51-data">5.1 Data</h2>
<p>Data is the expression of the source information, knowledge, and expertise of our researchers, and forms the basis and “necessary context for analytical claims” (Thieberger in this issue, and<a class="footnote-ref" href="#thieberger2016"> [thieberger2016] </a>). Digital Humanities praxis has often tended to blur the distinction between data and products; according to<a href="#baratsSchaferFickers2020">Barats, Schafer, and Fickers</a>, for example, “data management is not just about the data that are used, but also about those, which are produced (metadata, results of research, etc.). In fact, data management covers the whole life cycle of a research project, from data selection to their curation and description, from analyse and interpreting data to its publication and long term storage” <a href="#baratsSchaferFickers2020">para 4</a>. For the purpose of Endings principles, our definition of data is much more constrained: we define data as the source material from which end-user products are generated. In the case of a digital edition, data may take the form of TEI XML encodings of primary source or born-digital documents, but it may also include relational database data, digital images, audio or video recordings, and any other material acquired or generated during research, but which does not form part of the end product.</p>
<h2 id="511-data-is-stored-only-in-formats-which-conform-to-open-standards-and-which-are-amenable-to-processing-tei-xml-gml-odf-txt">5.1.1 Data is stored only in formats which conform to open standards and which are amenable to processing (TEI XML, GML, ODF, TXT).</h2>
<p>It is now common practice for funding agencies and host institutions to insist that projects create detailed data management plans. The Canadian Tri-Agency Statement of Principles on Digital Data Management, for example, specifies that “data should be collected and stored throughout the research project using software and formats that ensure secure storage, and enable preservation of and access to the data well beyond the duration of the research project” <a class="footnote-ref" href="#govCan2016"> [govCan2016] </a>. In practice, this means using open, well-documented standards and file formats (i.e. files that can be read, opened, and processed without the need of special software or tools) instead of proprietary formats.</p>
<h2 id="512-data-is-subject-to-version-control-subversion-git">5.1.2 Data is subject to version control (Subversion, Git).</h2>
<p>The use of version control for DH data is now widely accepted practice; by its very nature it supports LOCKSS (Lots of Copies Keep Stuff Safe) (every person checking out the repository to work on it creates a new copy), provides security against human error and data corruption, and enables sophisticated progress tracking<a class="footnote-ref" href="#holmesEtAl2019"> [holmesEtAl2019] </a>. We also believe that project history, as reflected in progressive changes to its dataset, merits preservation in itself, and version control systems support this. Jim McGrath, at our Endings Symposium, discussed in detail the importance of recognizing and surfacing contributions by students, post-doctoral researchers, and otherprecariouslabour, and Jessica Otis (in this issue) also addresses this topic. Version control allows detailed tracking of contributions file-by-file, allowing for more granular visualization of responsibilities.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<h2 id="513-data-is-continually-subject-to-validation-and-diagnostic-analysis">5.1.3 Data is continually subject to validation and diagnostic analysis.</h2>
<p>Since all products depend entirely on the reliability of the project’s dataset, it is essential to establish and maintain the accuracy of the data. For XML datasets, all files should be validated against the appropriate schemas; for other types of data, routines should be built into processing that confirm that the project’s data conforms to the project’s determined syntax and convention.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> In addition to confirming that individual files validate against the project’s schema, the entire dataset should also be checked using a set of what we have previously called “diagnostics” <a class="footnote-ref" href="#holmesTakeda2019b"> [holmesTakeda2019b] </a>. As we argued, projects contain multiple internal and external relationships — to project-defined entities, other pages within the project, or external vocabularies — that “need to be tested, checked, and validated, too, but it is impractical to do this using document-level schemas” <a class="footnote-ref" href="#holmesTakeda2019b"> [holmesTakeda2019b] </a>. Taken together, standard document validation and diagnostics are necessary for confirming that a project is consistent, coherent, and complete.</p>
<h2 id="52-documentation">5.2 Documentation</h2>
<p>Within the digital humanities (and many other fields), the literature of best practices is suffused with exhortations to document more, document better, and document everything. The reality for grant-funded projects, however, is that documentation is frequently the last task on the agenda and therefore likely to be curtailed or neglected when funding runs out or deadlines approach<a class="footnote-ref" href="#morgan2021"> [morgan2021] </a>. The Endings survey found that “60% [of projects] claimed to have a clearly documented data model, but 90% of those that had documentation considered it to be partial or inadequate, so it appears that a project’s data model is well documented in only about 50% of cases” <a class="footnote-ref" href="#arneilHolmesNewton2019"> [arneilHolmesNewton2019] </a>. We are no different in our exhortations to document thoroughly, but we do take a strong position regarding the availability of documentation.</p>
<h2 id="521-data-models-including-field-names-descriptions-and-controlled-values-should-be-clearly-described-in-a-static-document-that-is-maintained-with-the-data-and-forms-part-of-the-products">5.2.1 Data models, including field names, descriptions, and controlled values, should be clearly described in a static document that is maintained with the data and forms part of the products.</h2>
<p>In most of our larger projects, such as <em>The Map of Early Modern London</em> , training for research assistants and other contributors forms a core part of the project’s mission, and we have learned to build this kind of praxis documentation directly into the published digital edition itself. This has two significant advantages over keeping documentation segregated and private. First, since the documentation is published with the edition, it will always travel with the published product, increasing the likelihood that future researchers will be able to make sense of our materials and adopt or repurpose them easily. Second, the visibility of our documentation helps to keep us honest. Documentation is less prone to be aspirational and more likely to reflect the reality of our praxis if users of our editions can read it alongside the editions themselves, and point out any failures or discrepancies.</p>
<h2 id="522-all-rights-and-intellectual-property-issues-should-be-clearly-documented-where-possible-the-data-and-products-should-be-released-under-open-licenses-creative-commons-gnu-bsd-mpl">5.2.2 All rights and intellectual property issues should be clearly documented. Where possible the Data and Products should be released under open licenses (Creative Commons, GNU, BSD, MPL).</h2>
<p>As suggested above, a project’s best chance of long-term survival lies in making it as amenable as possible to copying and repurposing. While this article is mainly concerned with overcoming the technical barriers to digital longevity, it must also be noted that any materials or data accompanied by any sort of restrictive covenant or license will inevitably be less appealing to a future researcher considering making use of it. In the same way, the LOCKSS preservation strategy requires the collaboration of multiple institutions willing to host project products over the long term, and this is much less likely to happen if licensing issues make it more difficult to deliver the materials to the institution’s end-users in a convenient way. Therefore we strongly recommend that projects, where possible, make all their materials available under generous Creative Commons licenses, open-source all their code, and avoid depending on any proprietary data, programming, libraries, or other resources. For example, it is far better to try to acquire your own copy of a historical text and scan the pages yourself than to build a digital edition around page-images supplied under license by a corporation or other rights-holder who may restrict access to them.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup></p>
<p>Even worse than restrictive licensing is lack of clarity about license terms. If an institution or a researcher cannot discover the terms under which content has been released, they will never be able to determine whether they can or should archive or make use of it.</p>
<h2 id="53-processing">5.3 Processing</h2>
<p>There is no specific way to create an Endings-compliant site; different projects demand different technologies and there is no single language, framework, or tool that will work for every case. So the principles below are necessarily technology-agnostic and, while our own personal preferences may become apparent from the examples, we do not advocate for onestackover another. But there is certainly no shortage of processing pipelines for creating static sites. The uptake of theJAMstack(Javascript, API, and Markup) — a movement that grew out of the popularity of Node.js and NPM and is now closely allied with static asset providers like GitHub, Netlify, and Amazon S3 — has lead to both the popularization and proliferation of static site generators, such as Next.js, Hugo, and Jekyll.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> Within the digital humanities, proponents ofminimal computinghave mobilized these tools to create frameworks that significantly minimize the barriers to access in creating static digital editions and digital exhibits.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>
<p>But just because a pipeline produces static HTML output doesn’t mean that the processing produces a site that is archivable and sustainable in the long term. The Endings team was made painfully aware of this in the creation of our own Endings website, which was built initially using GitHub Pages and a pre-built Jekyll template. Though completely static, the site violated many core Endings principles: it was comprised of malformed, invalid HTML that relied on Bootstrap 4 and a set of JQuery-based JavaScript to handle various UI components. The site has since been developed into valid XHTML5 with all JQuery dependencies replaced by CSS3 and all updates handled by XSL transformations managed by an Ant build script. The problem with the old Endings site was not that it was built with Jekyll and that, had we just used Ant and XSL in the first place, all of our problems would have been solved; rather, the main issue was that the processing was meant only to create a static site, and not one that was coherent, consistent, complete, and free of technical debt.</p>
<p>We understand processing, then, not in terms of a particular pipeline, tool, or programming language, but rather as the set of steps necessary for creating robust, sustainable, and archivable resources. While we have created some tools — like our diagnostics toolsets<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> as well as staticSearch, which is discussed in detail in Section 6 — as part of the Endings project, these toolsets are neither necessary nor sufficient for an Endingsprocessingpipeline.</p>
<h2 id="531-relentless-validation-all-processing-includes-validationlinting-of-all-inputs-and-outputs-and-all-validation-errors-should-exit-the-process-and-prevent-further-execution-until-the-errors-are-resolved">5.3.1 Relentless validation: all processing includes validation/linting of all inputs and outputs and all validation errors should exit the process and prevent further execution until the errors are resolved.</h2>
<p>Our aspiration is never to release a flawed edition of any project, so validation of all inputs and products is a core requirement in the project build process. TEI XML files are always accompanied by a schema, and validation of those files is always the first step in the build; encoders should not normally commit invalid files to the repository, but this does happen from time to time. In the same way, the various other versions of XML that may be generated as part of the build process should also be validated to ensure they are functional and therefore useful to other projects. Naturally, output HTML also requires validation, and the W3C’s validator, which is available as a Java JAR file (vnu.jar), is simple to use for this purpose. We use CSS code not only in HTML output but also within TEI XML as a convenient formal language to describe the layout and appearance of primary source texts; this CSS can be extracted and validated using the same W3C validator, ensuring that our descriptions are logical and processable by any CSS processor.</p>
<p>Standard validation can catch many syntactic and stylistic errors in individual documents, but they do not necessarily confirm the collection’s coherence and completeness as a whole. As we have argued before<a class="footnote-ref" href="#holmesTakeda2019b"> [holmesTakeda2019b] </a>, validation should be accompanied by a set of project diagnostics, which can, among other things, confirm referential integrity between documents, check for potential duplication of data (people, places, or bibliographic citations), and trace a project’s progress across time.</p>
<h2 id="532-continuous-integration-any-change-to-the-source-data-requires-an-entire-rebuild-of-the-site-triggered-automatically-where-possible-processing-prioritizes-validity-and-maintainability-over-speed-and-efficiency">5.3.2 Continuous integration: any change to the source data requires an entire rebuild of the site (triggered automatically where possible). Processing prioritizes validity and maintainability over speed and efficiency.</h2>
<p>At its most basic, the processing for an Endings-compliant site could simply be a single individual who lovingly encodes an HTML document by hand and, after validating it against the W3C’s HTML validator, uploads it to their server. Most projects, however, require a more robust technical pipeline that can rearrange, transform, and aggregate their source materials into a fully functioning web application. While these builds should be able to be run locally, the project team seldom requires a local version as the project building is managed by a Continuous Integration and Continuous Deployment server (CI/CD). Our Jenkins server polls each repository and whenever it detects any change, it re-runs the entire build process, deleting all of the old artifacts and creating them anew.</p>
<p>Compared to server-side systems that prize rapid delivery of products in milliseconds, our build processes can seem painfully slow and massively inefficient: changing a single character in a single file initiates an entire re-build of the site, which, depending on the size of the project, can take anywhere from a few minutes to two hours. Much of that time is spent not on building the HTML products that comprise the final site, but on relentlessly validating any and all inputs and outputs. However, this processing is mechanical and generally requires no oversight at all.</p>
<p>One might question why a single change to a single document requires an entire project rebuild. But any given change may have significant repercussions throughout a document collection. A change to someone’s biography may affect every page which mentions that person; a change in a gazetteer may propagate through dozens of maps. In practice, it is often very complicated to pin down exactly which components of a site must be rebuilt following a change, and it is far more straightforward just to rebuild everything. This also ensures that site-wide edition/version information (which in the case of our sites usually includes the source code repository revision number from which the site was built) is consistent in every page footer.</p>
<h2 id="533-code-is-contingent-while-code-is-not-expected-to-have-significant-longevity-wherever-possible-all-code-should-follow-endings-principles-for-data-and-products">5.3.3 Code is contingent: while code is not expected to have significant longevity, wherever possible, all code should follow Endings principles for data and products.</h2>
<p>Much like the source data, all processing code should be subject to version control and should ideally reside in the same repository as the source data, which ensures that the data and the code are always in sync and thus makes rebuilding a project at a particular version trivial. This also means that all dependencies, including external JAR files and binaries, should be stored in the repository when the terms of the software permit (open-source software here is, of course, preferred). While it is a good idea to build routines into your processing that check for updates, upgrading a dependency should always be the developer’s responsibility and not something performed silently in the background by a package manager; the repository should always contain the last version of the dependency that works with the rest of the code, such that the processing can work even when that version, the organization, or the package registry disappears.</p>
<p>However, while data and products are designed to survive, processing code is necessarily impermanent; while we strive to create the appropriate conditions for maintaining reproducibility, there is no guarantee that code will work in a year, let alone fifty. This is a luxury afforded by static sites: while server-side infrastructures require a great deal of consideration and investment to ensure that the processing can be maintained in future, it makes no difference how a static site is created as they are, by definition, untethered from the processing that created them.</p>
<h2 id="54-products">5.4 Products</h2>
<p>Principles for products are at the heart of the Endings approach, since products are the only components of a project that we really hope and expect will survive. This section of the Principles outlines the technological choices, structure, and organization we recommend for digital edition projects aiming for longevity.</p>
<h2 id="541-no-dependence-on-server-side-software-build-a-static-website-with-no-databases-no-php-no-python">5.4.1 No dependence on server-side software: build a static website with no databases, no PHP, no Python.</h2>
<p>Lots of Copies Keep Stuff Safe,says the conventional wisdom, and Stanford has an entire digital preservation program (<a href="https://www.lockss.org/">https://www.lockss.org/</a>) named for this truism; certainly, the more copies of something that exist, the more likely it is to survive over the long term, especially if those copies are widely distributed geographically (see<a class="footnote-ref" href="#cayless2010"> [cayless2010] </a>). In the world of online digital resources, though, it doesn’t really matter how many archival copies of your TEI XML source encoding are distributed across the world; if the one hosting server running the database backend and WordPress front-end for your digital edition goes down, your project has essentially disappeared.</p>
<p>We have therefore focused on building digital editions which can run on any web server, anywhere, without any specific dependencies. If spinning up a new site requires nothing more than copying a collection of files to a server and circulating the URL, there is a far greater chance that <em>functional</em> copies of the <em>products</em> of your work will survive in a usable form. Every server-side dependency is a barrier to replication and therefore to survival.</p>
<h2 id="542-no-boutique-or-fashionable-technologies-use-only-standards-with-support-across-all-platforms-whose-long-term-viability-is-assured-our-choices-are-html5-javascript-and-css">5.4.2 No boutique or fashionable technologies: use only standards with support across all platforms, whose long-term viability is assured. Our choices are HTML5, JavaScript, and CSS.</h2>
<h2 id="543-no-dependence-on-external-libraries-or-services-no-jquery-no-angularjs-no-bootstrap-no-google-search">5.4.3 No dependence on external libraries or services: no JQuery, no AngularJS, no Bootstrap, no Google Search.</h2>
<p>The World Wide Web — the front-end of the modern Internet — is perhaps the most successful and prolific invention in the history of human communication. Its current scale dwarfs the entire prior history of text, and it continues to expand at an astonishing rate. Underlying its functionality are three core languages: the markup language HTML, the style language CSS, and the scripting language JavaScript (ECMAScript), all of which are well-managed by standards bodies. This trio of technologies underlies more than the web, of course; cell phone applications, EPUB documents, and many other forms of communication are also built on the base technologies of the Web, all of which are relatively simple and easy even for beginners to understand and learn.</p>
<p>However, the world of content-creators who build Web resources is not so simple; rarely do developers sit down and code HTML documents and write plain CSS. Instead, they tend to import large packaged libraries of existing code to generate the end-user Web pages we consume. Large coding frameworks for creating web-based resources come and go at a remarkable speed. At the time of writing, Angular, React, Vue, Express.js, Meteor, and Node are all popular JavaScript frameworks, while JQuery, Dojo, MooTools, and others have fallen out of favour; by the time you read this, the situation will certainly have changed again. The same is true of database-dependent content-creation and delivery tools such as WordPress, Ruby on Rails, Drupal, Joomla, and others, as well as all of the temptingfreeservices that have enabled DH practitioners to create intriguing mash-ups and to decorate their work with data from other sources. All of these efforts promise rapid site development at the cost of long-term maintenance issues. As Jim Nielsen (<a href="#nielsenJim2021">2021</a>) and others have pointed out, this creates an ecosystem in which “all web languages — HTML, CSS, and JS — are compile targets.” Programmers, in other words, no longer need to code directly in the target languages and instead become specialists in a few fashionable frameworks, chasing the changing fashions year by year.</p>
<p>And yet, the trifecta of HTML, CSS, and JavaScript is remarkably powerful. We know that because ultimately, all of those other languages, frameworks, and tools — from MySQL+PHP to PostGreSQL+Python to RethinkDB+Node.js — basically do one thing: they produce HTML/CSS/JavaScript Web pages, and those Web pages do all the things we need them to do. And while each of those technologies or frameworks or back-end services will eventually stop working, it is extremely unlikely that Web pages themselves will cease to function. One of the most remarkable things about HTML, CSS, and JavaScript is that over 20+ years of development, they have retained impressive levels of backward compatibility. The first Web pages ever created still work perfectly (<a href="http://info.cern.ch/hypertext/WWW/TheProject.html">http://info.cern.ch/hypertext/WWW/TheProject.html</a>) and, as noted above, the first projects we created at HCMC in the 1990s and early 2000s are also still perfectly functional. Given the astonishing quantity of resources built and delivered through HTML, CSS, and JavaScript, there is a strong chance that they will continue to function over the long term; and when they do, perhaps, alter in ways that make older forms of text less usable, there will be readily-available migration pathways and tools that can bring along everything that survives and is worth preserving. The same will not be true of this year’s favourite JavaScript framework or last year’s most popular content management system.</p>
<p>In the same way, if maintenance is ever required, it is very likely that there will be programmers who are able to read and understand the three core languages. It is not so certain that programmers capable of debugging and fixing a ReactJS application or a PHP script will be so common. Building your products from the three core technologies substantially increases their chances of survival; dependence on back-end or external services is a temporary solution for short-term projects.</p>
<h2 id="544-no-query-strings-every-entity-in-the-site-has-a-unique-page-with-a-simple-url-that-will-function-on-any-domain-or-ip-address">5.4.4 No query strings: every entity in the site has a unique page with a simple URL that will function on any domain or IP address.</h2>
<p>As noted above, older sites which queried back-end databases to construct theirpagestended to have page URLs whose distinctive factors lay in the query string rather than in the base location. For example, <em>The Robert Graves Diary</em> project formerly required the following URL to retrieve the diary entry for 22 February 1935 (line-wrapped for easier reading):</p>
<pre tabindex="0"><code>http://graves.uvic.ca/graves/site/xbrowse.xq? collection=%2Fdb%2Fgraves&amp;type=diaryentry&amp; query_stored=false&amp;action=browse&amp; search_text=-1&amp;day=22&amp;month=02&amp;year=1935
</code></pre><p>This concoction presented obvious difficulties for the Internet Archive crawler, so none of the diary entries were actually archived in the Wayback Machine from the original site. Contrast this with the current equivalent:</p>
<pre tabindex="0"><code>https://graves.uvic.ca/diary_1935-02-22.html
</code></pre><p>which itself is linked from a sitemap page to ensure its retrieval by standard crawlers (see<a class="footnote-ref" href="#holmes2017b"> [holmes2017b] </a>). Such URLs are not only cleaner and simpler for automated tools to process; they can also be manipulated by humans who happen to know exactly what date (in this case) they are looking for, removing the additional step of re-engaging with form controls or other GUI components when browsing the project. When rewriting <em>Le Mariage sous L’Ancien Régime</em> as a static Endings site, we were able to take advantage of our institution’s involvement in the Archive.org project to deploy the Internet Archive’s Heritrix crawler repeatedly on a pared-down version of the digital edition, inspecting the harvested results and tuning the site organization, linking, and filenaming until we were able to ensure that everything important was being successfully crawled and archived.</p>
<p>In addition to ensuring that every URL is simple and meaningful, we also believe that every entity (document, prosopography entry, bibliography entry, collaborator biography) should have its own unique page with its own URL. This provides maximum flexibility in terms of linking, extraction of individual pages, and re-use by future researchers (see below). Many metadata schemes (such as RDF) rely on URLs as unique identifiers for categories, concepts, and entities; a scholarly publication can embody this approach, and support Linked Open Data applications more effectively, by segmenting entities at the page level in the site structure.</p>
<h2 id="545-inclusion-of-data-every-site-should-include-a-documented-copy-of-the-source-data-so-that-users-of-the-site-can-repurpose-the-work-easily">5.4.5 Inclusion of data: every site should include a documented copy of the source data, so that users of the site can repurpose the work easily.</h2>
<p>Hugh Cayless (<a href="#cayless2010">2010</a>) points out that many ancient texts have come down to us only because of a long tradition of copying, reuse, quotation, and repurposing, and suggests that “we have returned to a situation somewhat like the one that existed in the ancient world and furthermore that perhaps some of the processes that governed the survival of ancient works might pertain to digital media. As in ancient times, a work released into the electronic environment may be copied, quoted, reused or resold without the originator’s having much control over what happens to it” <a class="footnote-ref" href="#cayless2010"> [cayless2010] </a>. We subscribe to the view that such copying and reuse is not only inevitable but profoundly desirable; although we hope and trust that our project editions will survive intact and remain functional over the long term, it is just as likely (perhaps far more likely) that fragments — either a small subset of documents or even a single page — of the project will be taken, repurposed, and reshaped by future scholars.</p>
<p>Therefore in projects such as <em>The Map of Early Modern London</em> , we create a variety of different versions of our XML, each intended for particular types of re-use (<a class="footnote-ref" href="#holmes2017a"> [holmes2017a] </a>). One version is astandardizedTEI in which all the most unusual or edge-case encoding features have been converted to more commonly-used encodings. Another is astandaloneTEI file into which all linked records from prosopographical resources, gazetteers, and other centralized data sources from the collection have been copied into the document, creating a single archive which can be taken and reused without any dependency on the constellation of surrounding linked resources. Our intention is to make it as easy as possible for any future scholar or student with an interest in a particular text to download an XML version of it which is ideally suited to their needs and can form the basis for their own project or research without special preparation.</p>
<h2 id="546-massive-redundancy-every-page-contains-all-the-components-it-needs-so-that-it-will-function-without-the-rest-of-the-site-if-necessary-even-though-this-means-duplicating-information-across-the-site">5.4.6 Massive redundancy: every page contains all the components it needs, so that it will function without the rest of the site if necessary, even though this means duplicating information across the site.</h2>
<p>Just as we offer repurposable XML versions of our documents, we try to provide HTML pages which can also be pulled out of the project and reused easily. While TEI XML is a widely-used and trusted archival format for digital scholarly work, compared with HTML, its audience is tiny. As we have noted elsewhere<a class="footnote-ref" href="#holmes2017b"> [holmes2017b] </a>, the many billions of HTML pages already created constitute many times the number of printed books produced in the entire history of humanity, and the variety of purposes already served by HTML (not only websites but mobile applications, archival storage, and others) will ensure that if anything from the current era of digital communication survives, it will be HTML. So our HTML is more likely to be reused than our XML in the long term.</p>
<p>Since we want to encourage this, it makes sense to provide documents in a form easily excised from the collection. Documents should, as far as is practical, stand alone, and therefore we usually generate our HTML outputs from the standalone versions of our XML source. Rather than having a document link to thirty external prosopography entries that live in other documents on the site, why not simply incorporate copies of all those entries inside the document itself? Text is typically small and compressible compared with some other digital resources. If we make a point of replicating all required linked records such as bibliographic citations, toponymic variants, and personography entries inside each individual document, any user can take a single HTML page and use it elsewhere without having to resolve a large number of pointers and retrieve a set of external resources to make the document functional. This of course means that the same individual personography entries may be replicated hundreds of times across a collection. This seems wasteful; but as we have said previously<a class="footnote-ref" href="#holmesTakeda2019a"> [holmesTakeda2019a] </a>, “We don’t care.”</p>
<h2 id="547-graceful-failure-every-page-should-still-function-effectively-even-in-the-absence-of-javascript-or-css-support">5.4.7 Graceful failure: every page should still function effectively even in the absence of JavaScript or CSS support.</h2>
<p>Graceful failure (or degradation) of internet services has been discussed and recommended since the 1990s (see for example<a class="footnote-ref" href="#nielsenJakob1999"> [nielsenJakob1999] </a>). However, while widely acknowledged, it is rarely implemented in a practical way. Many modern websites depend entirely on JavaScript and CSS and cannot function as plain HTML (imagine Google Docs or Office 365 without scripting), which makes it impractical for ordinary users to turn off JavaScript in their web browsers; consequently, no-one ever does, and graceful degradation is never needed or tested in the real world.</p>
<p>However, static websites lend themselves rather well to graceful degradation. If a page already contains all the secondary or supplementary information it requires in the form of biographies, bibliographical data, and so on, as we recommend above, then it can easily function effectively in the form of plain HTML, just like the earliest web pages of the 1990s. Through progressive enhancement, JavaScript may turn links to footnotes into buttons that generate convenient popups, but the underlying page structure can be plain and functional even in the absence of CSS and JavaScript. This makesrelentlessvalidation and link-checking trivial to implement during the processing stage.</p>
<p>Another advantage of this approach is that it conforms with the relatively new (at the time of writing) Content Security Policy header settings which are rapidly gaining traction. For example, the current default implementation of CSP settings will block the use of (very common) inline JavaScript or CSS<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> unless CSP explicitly includesunsafe-inlinesettings. It is very difficult to predict how CSP and other security headers may evolve over the next few years, but it is not unlikely that standard and preferred constraints on the majority of web servers may block many features which are currently widely used, so progressive enhancement is more important than ever.</p>
<p>The principles above are tempered by the following concessions:</p>
<h2 id="548-once-a-fully-working-static-site-is-achieved-it-may-be-enhanced-by-the-use-of-other-services-such-as-a-server-side-indexing-tool-solr-exist-to-support-searching-and-similar-functionality">5.4.8 Once a fully-working static site is achieved, it may be enhanced by the use of other services such as a server-side indexing tool (Solr, eXist) to support searching and similar functionality.</h2>
<p>Although it is perfectly practical to create an entirely static client-side JavaScript search engine for digital edition sites (see below, where we discuss the staticSearch engine we have created and use on all our static sites), it may be more convenient or practical to take advantage of search functionality available from a third-party provider such as Google, or an institutional host running a central search engine such as Solr. Indeed, it might be argued that search functionality is not a fundamental component of a digital edition, but rather a feature of the broader context of the Internet itself. However, if you take this view, and create an external dependency, it is vital to realize that the dependency is likely to fail at some point, and to consider that this feature of your digital edition is nonpermanent. External systems alter their APIs as well as their terms and conditions frequently, and if no-one is around to maintain the articulation of such dependencies, the functionality will not persist. This may be an acceptable compromise; for example, in the case of a small site with limited programming resources, it may be reasonable to assume that some kind of generalized search engine such as Bing or Google will always be available, and that such tools will automatically index a site and provide sophisticated users with methods of searching within that specific site, and in such a case, a dedicated search engine is not required. On the other hand, most digital editions have rich metadata that lends itself well to customized search pages with search filters based on date, document type, language, and many other idiosyncratic features of their specific dataset which will never be supported by a generic search engine.</p>
<h2 id="549-the-use-of-an-external-library-may-be-necessary-to-support-a-specific-function-which-is-too-complex-to-be-coded-locally-such-as-mapping-or-cryptography-any-such-libraries-must-be-open-source-and-widely-used-and-must-not-themselves-have-dependencies">5.4.9 The use of an external library may be necessary to support a specific function which is too complex to be coded locally (such as mapping or cryptography). Any such libraries must be open-source and widely-used, and must not themselves have dependencies.</h2>
<p>While we are strongly in favour of the injunction in 5.4.2,No boutique or fashionable technologies,and recommend the avoidance of large general-purpose web development platforms such as React or Angular, there are cases where using an external library is the only sensible option. One example is cryptography: as<a href="#jakobsenOrlandi2016">Jakobsen and Orlandi</a>note, “well-studied, provably secure encryption schemes that achieve strong definitions of security (e.g., authenticated-encryption) are to be preferred to home-brewed encryption schemes” <a class="footnote-ref" href="#jakobsenOrlandi2016"> [jakobsenOrlandi2016] </a>. Similarly, while it is possible to write your own mapping tools, the cost in time and money to do so for a single project is most likely prohibitive; it is much more practical to import and use an existing library such as Leaflet or OpenLayers. The important factor when integrating external libraries into a codebase is to choose them wisely. A relatively small library which is designed to do one specific job (such as mapping or cryptography) very well, and itself has no external dependencies, is a much better prospect than a general-purpose collection of functions and APIs trying to do a thousand things and pulling in hundreds of secondary dependencies to support them.</p>
<p>Similarly, for some features of a site, it may be essential to depend on an external service of some kind. Mapping is another obvious example here; very few projects are going to be in a position to run their own map tile servers, so they will rely on publicly-available services such as Open Street Maps or Bing Maps. These services will eventually cease operation, change their APIs, or change their terms of use, and the maps will stop working, but as long as they are not crucial to the main purpose of the site, this is not a disaster. The important thing is to build this expectation into the project plan.</p>
<p>Above all, as in the case of external searching or indexing tools, incorporating a dependency incurs a technical debt, and may result in a failure of functionality in the future. For this reason, it is important to ensure that such external dependencies are not providing functionality which is completely crucial to your digital edition. You can also mitigate the possibility of such failures by ensuring that (for example) your site has rich and exhaustive pre-compiled index pages so that users can find their way to desired documents without using a search engine, and that key components such as the names of people and places help to provide a network of linking throughout the edition, offering the user many paths through the data.</p>
<h2 id="55-release-management">5.5 Release Management</h2>
<p>Without good release management, a project can never end gracefully; it can only falter and die.</p>
<p>These principles apply to release management:</p>
<h2 id="551-releases-should-be-periodical-and-carefully-planned-therolling-releasemodel-should-be-avoided">5.5.1 Releases should be periodical and carefully planned. Therolling releasemodel should be avoided.</h2>
<p>In the world of traditional print scholarship, a publication is a coherent singular object, released on a particular day in a particular place, and provided with a convenient edition number which enabled scholars to cite it without ambiguity.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> However, many digital edition projects have adopted arolling releaseapproach modelled on the predominant approach to software publication, where corrections and new features are steadily made to a mutable product. Typos and errors on a single page are quickly fixed and the site can be endlessly tweaked as new problems are inevitably discovered.</p>
<p>Thisrolling releasemodel, however, makes it difficult to maintain consistency, coherence, and completeness as the site is in a perpetual state of flux; pages are constantly subject to change, and thus the project as a whole is always shifting. Not only does this make stable citation problematic, but it makes archiving difficult. Most large projects go through moribund phases in which work largely stops, and will most likely end in a similar way, and so it is essential that whatever is the current released state (edition) of a project constitutes an acceptable version for the long term. The edition model of digital publication ensures the stability and coherence of the project; much like a print publication, each edition of a digital publication should be planned carefully, with deadlines and milestones governing its release.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup></p>
<h2 id="552-a-release-should-only-be-made-when-the-entire-product-set-is-coherent-consistent-and-complete-passing-all-validation-and-diagnostic-tests">5.5.2 A release should only be made when the entire product set is coherent, consistent, and complete (passing all validation and diagnostic tests).</h2>
<p>The irreversible nature of print publication means that an edition is often scrutinized and carefully proofed prior to publication. In therolling releasemodel, since digital material is much easier to correct and changes can be applied soon after they are found, it is far less common for this level of diligent inspection to be applied to digital editions. Since each release is organized around a set of milestones and goals, much of this scrutiny can be automated (see 5.3.2). In<a class="footnote-ref" href="#holmesTakeda2019b"> [holmesTakeda2019b] </a>, we describe three distinct levels of diagnostic checks which can be incorporated into a project build process to provide mechanical proof that no links are broken, no content is missing, and all planned content and features are complete. This approach, combined with the detailed proofreading we would expect to apply to any scholarly publication prior to release, not only minimizes flaws in the released edition, but also ensures that each edition is archivable.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup></p>
<h2 id="553-like-editions-of-print-works-each-release-of-a-web-resource-should-be-clearly-identified-by-its-build-date-and-some-kind-of-version-number">5.5.3 Like editions of print works, each release of a web resource should be clearly identified by its build date and some kind of version number.</h2>
<p>Just like print editions, digital resources should carry a clear edition number on every page, which applies to every part of the resource. Our normal practice is to include this information in the page footer. At the time of writing, for example, the current version of <em>The Map of Early Modern London</em> contains this information in its footer:</p>
<blockquote>
<p>MoEML v.6.5, svn rev. 17540 2020-09-15 12:35:49 -0700 (Tue, 15 Sep 2020).<br>
This shows not only the specific edition number (6.5), but also the Subversion repository revision from which it was built, along with the exact date and time of the build.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup></p>
</blockquote>
<h2 id="554-web-resources-should-include-detailed-instructions-for-citation-so-that-end-users-can-unambiguously-cite-a-specific-page-from-a-specific-edition">5.5.4 Web resources should include detailed instructions for citation, so that end-users can unambiguously cite a specific page from a specific edition.</h2>
<p>Citation patterns for web-based resources are still subject to some confusion and change, so we recommend that projects make things easier for other scholars by providing copy/pastable citation blocks for each individual page, accessible from a link on the page. The example in Figure 3 comes from the <em>Mapping Keats’s Progress</em> project.</p>




























<figure ><img loading="lazy" alt="Citation popup in Mapping Keats’s Progress." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Citation popup in <em>Mapping Keats’s Progress</em> .
        </p>
    </figcaption>
</figure>
<h2 id="555-urls-for-individual-resources-within-a-digital-publication-should-persist-across-editions-any-moved-retired-or-deleted-resources-no-longer-available-at-a-previously-accessible-url-should-be-redirected-appropriately">5.5.5 URLs for individual resources within a digital publication should persist across editions. Any moved, retired, or deleted resources no longer available at a previously accessible URL should be redirected appropriately.</h2>
<p>The same resource in a digital edition should appear at the same URL in subsequent editions. Where a resource is removed, retired, or merged with another resource — when, for example, a person in a personography proves to be the same individual as another record, or is proved not to have existed at all — then the original URL should redirect to the replacement URL, or to an explanation of why the original resource is not available. This is essential for maintaining “cohesion and integrity in the scholarly record” (Coble and Karlin in this issue).<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></p>
<h2 id="6-the-lingering-problem-search">6. The Lingering Problem: Search</h2>
<p>With these Principles in place, we were able to convert the dormant projects, such as <em>The Robert Graves Diary</em> , and the on-going projects, like <em>The Map of Early Modern London</em> , from unwieldy eXist applications into a large bundle of static HTML, CSS, and JavaScript. Our intention was that these static incarnations look and function identically to the previous live application and, as these sites were steadily released and tested, we were happy to find that this process was not only feasible, but significantly improved the projects. Our staticization of <em>Graves</em> , for instance, surfaced various encoding errors that had gone unnoticed for many years, which we could now easily diagnose and fix. And in moving from a dynamic application to the static site, we had the opportunity to re-write the codebase from scratch, removing the layers of obsolete code that had sedimented within the codebase over its long history of updates, maintenance, and modernization of the CSS and JavaScript. Projects in active development benefitted similarly; these re-writes provided a good opportunity to scrutinize the project, lopping off irrelevant or deprecated code. Thanks to our Jenkins Continuous Integration server, following any change to the source data or the processing, we no longer needed to click anxiously around the site to confirm that we hadn’t broken the anything: any encoder could simply commit, wait a few minutes, and then, so long as the Jenkins server didn’t send itsBUILD FAILEDmessage, proof their changes in the context of the site.</p>
<p>But these sites all lacked a significant and crucial part of their functionality: search. Most digital editions require some form of text-based searching and, in many cases, the ability to search across a large and disparate document collection and aggregate documents based on multiple metrics is the project’s raison d’être. Search was, in other words, non-negotiable — we could not sacrifice the robust search mechanisms on the existing site. We could quietly ignore search for the time being in some projects, like <em>The Map Of Early Modern London</em> , where search was peripheral to the main functionality, but <em>The Robert Graves Diary</em> forced us to come up with a real solution: the homepage for the project was essentially one large, faceted search page, which we were able to replicate perfectly, but since search itself was handled entirely by eXist, the static version was rendered completely inert.</p>




























<figure ><img loading="lazy" alt="The original home page of _The Robert Graves Diary_ ." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The original home page of <em>The Robert Graves Diary</em> .
        </p>
    </figcaption>
</figure>
<p>We had always assumed that the kinds of search our projects required — complex faceting and filters, wildcards, and exact phrase queries split across multiple, collection specific search pages — was necessarily the stuff of servers and could not be made static. While some client-side search solutions were available, they were ill-equipped to handle the thousands of documents, millions of words, and complex metadata structures that comprise a standard digital edition.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> Outsourcing indexing to an external service, like Elasticsearch, was out of the question as it would violate the core Endings principles.</p>
<p>Our intermediate solution was to stick with what we knew: package the static sites into a XAR bundle and spin up a simple eXist instance whose only job would be to index, query, and retrieve the search results from the static HTML pages. Of course, this worked perfectly, and we released the first version of a number of our static sites following this approach. But it was a disappointing compromise. We had gone through the trouble of re-writing these sites in their entirety to remove the fragility inherent in their dependency on eXist, and had celebrated our success in building completely static, serverless websites, and now here we were, returning to eXist, hat in hand.</p>
<p>If we were to return to eXist, we reckoned, then we should at least try to improve the situation; in the spirit of LOCKSS and following our principle for “Graceful Failure” (5.4.7), we decided to take a decidedly maximalist approach. Using <em>Graves</em> as our case-study, we supplemented eXist with three distinct approaches, which all had their own limitations with respect to functionality, archiving, and sustainability, but could provide something of a safety net for the project. We discuss these approach in greater detail in<a class="footnote-ref" href="#holmesTakeda2018"> [holmesTakeda2018] </a>, but, in brief, those three approaches were: 1) a Google search widget, which would not offer anything beyond what Google already provides, but at least gave users a shortcut for a site-specific search; 2) an experimental interface for querying a Solr index provided by the UVic Library (the eventual archival home for all of these projects), which could provide many of the faceting and filtering structures required by the project; and 3) astandalone search,a Javascript-only client-side text search interface that would stem user input and match it against an pre-built inverted index generated during the build process. In this process, a list of distinct words was created for each document; the words were then run through the Python implementation of the Porter Stemmer, and then documents were grouped by stem, so that JavaScript could return a simple list of the documents in which that stem appeared. This solution, as we noted then, worked well for small document collections, but lacked the necessary features — keyword-in-context, search faceting, and filtering — and thus should be considered the “ultimate fallback when all else fails” <a class="footnote-ref" href="#holmesTakeda2018"> [holmesTakeda2018] </a>.</p>
<p>Over the last three years, we have continued to improve and expand what we then calledstandalone searchintostaticSearch: a fully-featured and sustainable search engine for static websites that has no server side dependencies. Now implemented by nearly a dozen projects, staticSearch has not only allowed us to replicate server-side search functionality, but has significantly expanded what these searches can do. So to revise our answer to the question from our 2018 paper, “Why do I need four search engines?” : You don’t.</p>
<h2 id="61-how-staticsearch-works">6.1 How staticSearch works</h2>
<p>Simple client-side search engines such as Lunr.js work by generating a large index file, which is then downloaded to the client, and queried by JavaScript in the search. Obviously, the larger a document collection, the larger the index, and any site consisting of more than a few dozen pages will rapidly outgrow this approach. The key insight which enabled us to create staticSearch was the idea that the search page need only download those components of the index it actually requires to respond to a specific query. Instead of a single large index, we create thousands of individual JSON files, one for each stemmed term, and the text search component of the search page simply stems all the search terms and retrieves only the specific JSON files for each of those terms. This enables rapid query response even for large sites.</p>
<p>Of course, text search alone is not enough; search facets such as topic, document type, date range, and other metadata-based filters are a fundamental requirement for searching digital editions and other rich document collections. One by one, we have added support for a range of these features, which can be configured by the addition of HTMLmetaelements with specific patterns to site pages. The staticSearch indexing process works its way through the HTML pages of a site indexing the text but also searching for thesemetaelements, building a collection of distinct JSON files which the search page can retrieve as needed to respond to queries and filter results.</p>




























<figure ><img loading="lazy" alt="One of several specialized search pages built using staticSearch for the _Digital Victorian Periodical Poetry_ project." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>One of several specialized search pages built using staticSearch for the <em>Digital Victorian Periodical Poetry</em> project.
        </p>
    </figcaption>
</figure>
<p><a class="footnote-ref" href="#holmesTakeda2020"> [holmesTakeda2020] </a>provides a more detailed explanation of how staticSearch works, and the full documentation for the current release is available on the Project Endings website.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup></p>
<h2 id="7-archiving">7. Archiving</h2>
<p>The technical principles that we have outlined so far demonstrate how we have created resources that can be archived, or that, at least, lack the technical barriers that have made digital preservation difficult (or impossible) in the past. However, there are still a number of issues and challenges that the Endings project has faced in preparing to archive these projects within institutional repositories and, in particular, in preserving the form and function of these projects such that they can continue to be useful as scholarly resources.</p>
<p>While librarians and archivists have long recognized the importance of secure archival storage, digital archiving initiatives have largely focused on data storage and management (see<a class="footnote-ref" href="#molloy2011"> [molloy2011] </a>or<a class="footnote-ref" href="#interpares2013"> [interpares2013] </a>for examples). Back in 2002, for instance,<a href="#gelawEtAl2002">Gelaw et al.</a> noted that “It is now common knowledge that digital information is fragile in ways that differ from traditional technologies, such as paper or microfilm. The fact that information is increasingly stored in digital form,[sic] has led to an accelerated search for effective methods of managing electronic information resources.” However, the very title of that article, “A Metadata Approach to Preservation of Digital Resources,” underscores that, in many cases, archiving is primarily a matter of metadata; as they note, the “creation of preservation metadata for electronic files and digital collections are [sic] among the most important steps.” This approach treats understanding digital resources as discrete blobs to be stored in large repositories with their accessibility and findability contingent on the provision of effective descriptive metadata. As Goddard and Seeman write, “in order to ensure longevity, the library will make multiple copies of our digital collections, aggregate them into Archival Information Packages (AIPs), and distribute these archival copies in offsite locations” <a class="footnote-ref" href="#goddardSeeman2020"> [goddardSeeman2020] </a>.</p>
<p>For end-users not able to access archiving services from libraries or similar institutions, there are also archiving services available on the Web, such as Zenodo (offered by CERN,<a href="https://zenodo.org/">https://zenodo.org/</a>), Preprints.org, or HAL (<a href="https://hal.archives-ouvertes.fr/">https://hal.archives-ouvertes.fr/</a>). All of these, however, follow a similar model: a single binary object such as an article is uploaded and associated with metadata. Datasets may also be attached, but these are viewed as objects to download. This kind of archiving, while it may be a useful backup strategy (and we can never have enough of those), will not make a digital edition project (i.e. a complex website) available in the way a user would want to access it: as a functioning website. The Text Encoding Initiative, for example, archives each version of its standards package, consisting of schemas, exemplars, and other documentation, on Zenodo, but the end user can only download a zipped package of materials; they cannot browse and read the TEI Guidelines itself, as they can on the TEI’s own website. As we have suggested above, if a digital edition is to remain relevant, to continue to be read, cited, and hold its place in scholarly dialogue, it must be fully functional, available, and usable; after all, as Morreale reminds us, “Humanities scholars have been taught that what they produce should be, first and foremost, consumed and understood by other scholars. Once this is accomplished, they want those who have received their work to reuse or build upon it, so that their contributions become part of a larger conversation, one that may stretch out for years, decades, or even centuries” <a class="footnote-ref" href="#morreale2019"> [morreale2019] </a>. However, a shelved DVD copy with metadata in a catalogue or a zip archive in a distributed repository does not facilitate the kinds of experience that are at the heart of a digital project; only a functional website does. Sacchi (<a href="#sacchi2015">2015</a>), based on a now-inaccessible technical report from the National Archives of Australia, offers a useful distinction between “stable artefacts” — resources preserved as blobs — and “performance” <a class="footnote-ref" href="#sacchi2015"> [sacchi2015] </a>. “Performance” here means the direct, live access to digital objects, which, like any live performance, is a unique experience bound to a specific occasion and is contingent on the availability of hardware and software components.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> Understanding digital archives as not just “stable artefacts” but also as “performance,” as Sacchi writes, “explicitly addresses the need for something concrete that needs to [be] experienced by a researcher in order [to] access the essence of a record” <a class="footnote-ref" href="#sacchi2015"> [sacchi2015] </a>. In other words, while it is essential that digital resources are archived as “stable artefacts,” preserving the “essence” of a digital edition requires maintaining its functionality and allowing users to experience it as “performance.”</p>
<p>Librarians and archivists are now beginning to focus on this important distinction. The University of Victoria Library is currently developing aDonation policy for legacy websites,which outlines the conditions under which an individual or a project group may transfer an entire website to the library for long-term storage, with the expectation that it will actually remain accessible as a website on the Internet for public access. Offering such a service is not simple, though. A library presented with a Tamagotchi-style web application, with dependencies on back-end databases and server-side scripting, will (and should, quite rightly) reject thedonationas it would, as we have argued, amount to the passing on of technical debt and the obligation for incessant maintenance. But the static site model we have proposed and implemented is not subject to these considerations. Assuming any functional webserver is available, a static site can be served for the foreseeable future with no maintenance burden whatsoever; only bandwidth and disk storage are required, just as is the case for binary-blob digital assets in the traditional archive model. With a static site approach, any given edition of a digital collection could be available in multiplelocations(i.e. at multiple URLs), hosted by different institutions, providing resilient and reliable access to the resource even in the face of occasional failures or closures at specific institutions.</p>
<p>Such a scenario presents its own challenges, though. If a site was originally offered at a custom domain (<a href="https://www.ourfabulousproject.net">www.ourfabulousproject.net</a>), should the archiving institution agree to take on the ongoing cost of preserving that domain? If there are multiple incarnations of a site, how is it to be cited, and how is a reader to know that they are viewing thesamesite as that cited in a publication, albeit perhaps on a different URL? This is one reason that the edition management and release model proposed in section 5.5 is so crucial. Each coherent, consistent, and complete edition of a digital project may be archived and served from many locations, so it must be reliably and obviously consistent and show clear dating and versioning information, just like an edition of a printed book.</p>
<h2 id="8-conclusion">8. Conclusion</h2>
<p>When Project Endings began, we really had no idea how practical it would be to build interactive digital editions without back-end services, but our initial work was very encouraging, and in fact it proved relatively straightforward to rewrite even very large and complex sites such as <em>The Colonial Despatches</em> (over 7,000 TEI-encoded documents) and <em>The Map of Early Modern London</em> (over 12,000 pages) into simple, fast, responsive, and easily searchable static sites. Other sites from our growing collection have taught us to handle a variety of different types of data such as video ( <em>Francotoile</em> ) and image collections ( <em>MyNDIR</em> ), while the largest dataset, the <em>Landscapes of Injustice Archive</em> , presents a searchable collection of over 150,000 pages representing diverse data including maps, oral histories, land title records, street directories (in Japanese and English), correspondence, and legal casefiles.</p>
<p>At this point, we can say with confidence that the approach we have taken is practical and effective. You <em>can</em> build digital editions this way, and it really doesn’t take much more work than it would to roll out a Tamagotchi of frameworks, libraries, software, and infrastructure. Once it’s done, it takes no maintenance at all, and you’re free to move on to the next project or focus on the next edition.</p>
<p>We’re doing it. You should do it too. You’ll regret it if you don’t.</p>
<h2 id="appendix-1-endings-compliant-projects">Appendix 1: Endings-compliant projects</h2>
<p>This is a list of all the projects which have been constructed or reconstructed in accordance with the Endings principles outlined in this article.</p>
<h2 id="the-original-four-projects">The original four projects</h2>
<ul>
<li><a href="https://mapoflondon.uvic.ca/">The Map of Early Modern London</a></li>
<li><a href="https://mariage.uvic.ca/">Le Mariage sous l’Ancien Régime</a></li>
<li><a href="https://graves.uvic.ca/">The Robert Graves Diary</a></li>
<li>The Nxa’amxcín Database and Dictionary (currently not public)</li>
</ul>
<h2 id="projects-later-adopted-by-endings">Projects later adopted by Endings</h2>
<ul>
<li><a href="https://bcgenesis.uvic.ca">The Colonial Despatches of Vancouver Island and British Columbia</a></li>
<li><a href="https://dvpp.uvic.ca">Digital Victorian Periodical Poetry</a>(site still under development)</li>
<li><a href="https://francotoile.uvic.ca">Francotoile</a></li>
<li><a href="https://loi.uvic.ca">The Landscapes of Injustice Archive</a></li>
<li><a href="https://johnkeats.uvic.ca">Mapping Keat’s Progress</a></li>
<li><a href="https://mvp.uvic.ca">Modernist Versions Project</a></li>
<li>The Scandinavian Canadian Studies Journal (Moved in 2022 to another host institution, and no longer Endings-compliant)</li>
<li><a href="https://winnifredeatonarchive.org">The Winnifred Eaton Archive</a></li>
</ul>
<h2 id="appendix-2-endings-principles-version-221">Appendix 2: Endings Principles (version 2.2.1)</h2>
<p>We divide digital projects into five primary components:</p>
<p><a href="#epData">Data</a><a href="#epDoc">Documentation</a><a href="#epProc">Processing</a><a href="#epProd">Products</a><a href="#epRel">Release management</a></p>
<h2 id="1-data">1 Data</h2>
<p>Data is the expression of the source information, knowledge, and expertise of our researchers. The following principles apply to data:</p>
<p>1.1 Data is stored only in formats that conform to open standards and that are amenable to processing (TEI XML, GML, ODF, TXT).</p>
<p>1.2 Data is subject to version control (Subversion, Git).</p>
<p>1.3 Data is continually subject to validation and diagnostic analysis.</p>
<h2 id="2-documentation">2 Documentation</h2>
<p>2.1 Data models, including field names, descriptions, and controlled values, should be clearly documented in a static document that is maintained with the data and forms part of the products.</p>
<p>2.2 All rights and intellectual property issues should be clearly documented. Where possible the Data and Products should be released under open licenses (Creative Commons, GNU, BSD, MPL).</p>
<h2 id="3-processing">3 Processing</h2>
<p>Processing code is written and maintained by the project technical staff, and is also subject to version control. Processing code provides all the following functions:</p>
<p>3.1 Relentless validation: all processing includes validation/linting of all inputs and outputs and all validation errors should exit the process and prevent further execution until the errors are resolved.</p>
<p>3.2 Continuous integration: any change to the source data requires an entire rebuild of the site (triggered automatically where possible).</p>
<p>3.3 Code is contingent: while code is not expected to have significant longevity, wherever possible, all code should follow Endings principles for data and products.</p>
<h2 id="4-products">4 Products</h2>
<p>Products are the project outputs intended for end-users, typically in the form of websites or print documents. The following principles apply to products intended for the web:</p>
<p>4.1 No dependence on server-side software: build a static website with no databases, no PHP, no Python.</p>
<p>4.2 No boutique or fashionable technologies: use only standards with support across all platforms, whose long-term viability is assured. Our choices are HTML5, JavaScript, and CSS.</p>
<p>4.3 No dependence on external libraries or services: no JQuery, no AngularJS, no Bootstrap, no Google Search.</p>
<p>4.4 No query strings: every entity in the site has a unique page with a simple URL that will function on any domain or IP address.</p>
<p>4.5 Inclusion of data: every site should include a documented copy of the source data, so that users of the site can repurpose the work easily.</p>
<p>4.6 Massive redundancy: every page contains all the components it needs, so that it will function without the rest of the site if necessary, even though doing so means duplicating information across the site.</p>
<p>4.7 Graceful failure: every page should still function effectively even in the absence of JavaScript or CSS support.</p>
<p>These principles are tempered by the following concessions:</p>
<p>4.8 Once a fully-working static site is achieved, it may be enhanced by the use of other services such as a server-side indexing tool (Solr, eXist) to support searching and similar functionality.</p>
<p>4.9 The use of an external library may be necessary to support a specific function that is too complex to be coded locally (such as mapping or cryptography). Any such libraries must be open-source and widely-used, and must not themselves have dependencies.</p>
<h2 id="5-release-management">5 Release management</h2>
<p>Release management handles the public release of products. These principles apply to release management:</p>
<p>5.1 Releases should be periodical and carefully planned. Therolling releasemodel should be avoided.</p>
<p>5.2 A release should only be made when the entire product set is coherent, consistent, and complete (passing all validation and diagnostic tests).</p>
<p>5.3 Like editions of print works, each release of a web resource should be clearly identified on every page by its build date and some kind of version number.</p>
<p>5.4 Web resources should include detailed instructions for citation, so that end-users can unambiguously cite a specific page from a specific edition.</p>
<p>5.5 URLs for individual resources within a digital publication should persist across editions. Any moved, retired, or deleted resources no longer available at a previously accessible URL should be redirected appropriately.</p>
<ul>
<li id="arneilHolmes1998">Arneil, S., andHolmes, M. D. (1998) “Hot Potatoes: Free Tools for Creating Interactive Language Exercises for the World Wide Web” , paper presented at the EuroCALL conference, Leuven, Belgium, September 1998.
</li>
<li id="arneilHolmes1999">Arneil, S., andHolmes, M. D.(1999) “Juggling hot potatoes: Decisions and compromises in creating authoring tools for the Web” , _ReCALL Journal_ , 11(2), pp. 12–19. Available at:[https://doi.org/10.1017/S0958344000004912](https://doi.org/10.1017/S0958344000004912)and[https://web.archive.org/web/20050526203034/http://www.eurocall-languages.org/recall/pdf/rvol11no2.pdf](https://web.archive.org/web/20050526203034/http://www.eurocall-languages.org/recall/pdf/rvol11no2.pdf).
</li>
<li id="arneilHolmes2001">Arneil, S., andHolmes, M. D.(2001) “Hot Potatoes, History and Future” , paper presented at EuroCALL Conference, Nijmegen, August 2001. Available at:[https://web.uvic.ca/hrd/eurocall2001/HotPotPastFuture/PastFutureHome.htm](https://web.uvic.ca/hrd/eurocall2001/HotPotPastFuture/PastFutureHome.htm).
</li>
<li id="arneilHolmesNewton2019">Arneil, S.,Holmes, M. D., andNewton, G.(2019) “Project Endings: Early Impressions From Our Recent Survey On Project Longevity In DH” , paper presented by Greg Newton at Digital Humanities 2019 Conference, Utrecht, the Netherlands, July 2019. Available at:[https://dev.clariah.nl/files/dh2019/boa/0891.html](https://dev.clariah.nl/files/dh2019/boa/0891.html).
</li>
<li id="baratsSchaferFickers2020">Barats, C.,Schafer, V., andFickers, A.(2020) “Fading Away... The challenge of sustainability in digital studies” , _DHQ: Digital Humanities Quarterly_ , 14(3). Available at:[http://www.digitalhumanities.org/dhq/vol/14/3/000484/000484.html](http://www.digitalhumanities.org/dhq/vol/14/3/000484/000484.html).
</li>
<li id="burnard2016">Burnard, L.(2016) “How to Update Your ODD” , TEI GitHub Repository. Available at:[http://teic.github.io/PDF/purifyDoc.pdf](http://teic.github.io/PDF/purifyDoc.pdf)(Accessed: 18 February 2019).
</li>
<li id="cayless2010">Cayless, H.(2010) “Ktêma es aiei: Digital Permanence from an Ancient Perspective” in Mahony, S., and Bodard, G. (eds.) _Digital Research in the Study of Classical Antiquity_ , pp. 139-150. Available at:[https://www.taylorfrancis.com/chapters/edit/10.4324/9781315577210-18/kt%C3%AAma-es-aiei-digital-permanence-ancient-perspective-hugh-cayless](https://www.taylorfrancis.com/chapters/edit/10.4324/9781315577210-18/kt%C3%AAma-es-aiei-digital-permanence-ancient-perspective-hugh-cayless).
</li>
<li id="diaz2018">Diaz, C.(2018) “Using Static Site Generators for Scholarly Publications and Open Educational Resources” , _The Code4Lib Journal_ , 42. Available at:[https://journal.code4lib.org/articles/13861](https://journal.code4lib.org/articles/13861).
</li>
<li id="gelawEtAl2002">Gelaw, D.,Hastings, S., andHartman, C.(2002) “A Metadata Approach to Preservation of Digital Resources: The University of North Texas Libraries’ Experience” , _First Monday_ , 7(8). Available at:[https://doi.org/10.5210/fm.v7i8.981](https://doi.org/10.5210/fm.v7i8.981).
</li>
<li id="gil2015">Gil, A. (2015) _The User, the Learner and the Machines We Make_ [Online].Minimal Computing: A Working Group of GO::DH. Available at:[http://godh.github.io/mincomp/thoughts/2015/05/21/user-vs-learner/](http://godh.github.io/mincomp/thoughts/2015/05/21/user-vs-learner/).
</li>
<li id="goddardSeeman2020">Goddard, L., andSeeman, D.(2020) “Negotiating Sustainability: Building Digital Humanities Projects that Last” , inCrompton, C.,Lane, R. J., andSiemens, S.(eds.) _Doing More Digital Humanities_ . London: Routledge, pp. 38–57.
</li>
<li id="govCan2016">Government of Canada. (2016) _Tri-Agency Statement of Principles on Digital Data Management_ [Online; updated 2021]. Available at:[https://science.gc.ca/eic/site/063.nsf/eng/h_83F7624E.html](https://science.gc.ca/eic/site/063.nsf/eng/h_83F7624E.html).
</li>
<li id="holmes1997">Holmes, M. D. “Web Language” . Online presentation showcasing the use of JavaScript-based exercises for language teaching (1997).[https://web.uvic.ca/lancenrd/martin/weblang/](https://web.uvic.ca/lancenrd/martin/weblang/).
</li>
<li id="holmes2017a">Holmes, M. D.(2017) “Whatever happened to interchange?” , _Digital Scholarship in the Humanities_ , 32(suppl_1), pp. i63–i68. Available at:[http://dx.doi.org/10.1093/llc/fqw048](http://dx.doi.org/10.1093/llc/fqw048).
</li>
<li id="holmes2017b">Holmes, M. D.(2017) “Selecting Technologies for Long-Term Survival” , paper presented at the SHARP Conference 2017: Technologies of the Book, Victoria, BC, Canada, June 2017. Available at:[https://github.com/projectEndings/Endings/raw/master/presentations/SHARP_2017/mdh_sharp_2017.pdf](https://github.com/projectEndings/Endings/raw/master/presentations/SHARP_2017/mdh_sharp_2017.pdf).
</li>
<li id="holmesEtAl2019">Holmes, M. D.,Fralick, K.,Fukushima, K.andKarlson, S.(2019) “How we tripled our encoding speed in the Digital Victorian Periodical Poetry project” , paper presented at the Text Encoding Initiative Conference, Graz, Austria, September 2019. Available at:[https://zenodo.org/record/3449241](https://zenodo.org/record/3449241).
</li>
<li id="holmesTakeda2018">Holmes, M. D., andTakeda, J.(2018) “Why do I need Four Search Engines?” , Proceedings of the Japanese Association of Digital Humanities Conference, Tokyo, Japan. Available at:[https://conf2018.jadh.org/files/Proceedings_JADH2018.pdf#page=58](https://conf2018.jadh.org/files/Proceedings_JADH2018.pdf#page=58).
</li>
<li id="holmesTakeda2019a">Holmes, M. D., andTakeda, J.(2019) “The Prefabricated Website: Who needs a server anyway?” , paper presented by Martin Holmes at the Text Encoding Initiative Conference, Graz, Austria, September 2019. Available at:[https://doi.org/10.5281/zenodo.3449196](https://doi.org/10.5281/zenodo.3449196).
</li>
<li id="holmesTakeda2019b">Holmes, M. D. andTakeda, J.(2019) “Beyond Validation: Using Programmed Diagnostics to Learn About, Monitor, and Successfully Complete Your DH Project” , _Digital Scholarship in the Humanities_ , 34(suppl_1), pp. i100–i109. Available at:[https://doi.org/10.1093/llc/fqz011](https://doi.org/10.1093/llc/fqz011).
</li>
<li id="holmesTakeda2020">Holmes, M. D. andTakeda, J.(2020) “Static Search: An Archivable and Sustainable Search Engine for the Digital Humanities” , paper presented at the Digital Humanities Summer Institute (DHSI) Colloquium (#VirtualDHSI), 6 June 2020. Available at:[https://doi.org/10.5281/zenodo.3883150](https://doi.org/10.5281/zenodo.3883150).
</li>
<li id="interpares2013">InterPARES 3 Team Canada (International Research on Permanent Authentic Records in Electronic Systems). (2013) _Case Study 09: Alma Mater Society of The University of British Columbia: Policies and Procedures for Web Site Preservation_ . Available at:[http://www.interpares.org/ip3/display_file.cfm?doc=ip3_canada_cs09_wks02_action_25_v1-3.pdf](http://www.interpares.org/ip3/display_file.cfm?doc=ip3_canada_cs09_wks02_action_25_v1-3.pdf).
</li>
<li id="jakobsenOrlandi2016">Jakobsen, J., andOrlandi. C.(2016) “On the CCA (in)security of MTProto” , _SPSM ’16: Proceedings of the 6th Workshop on Security and Privacy in Smartphones and Mobile Devices, October 2016_ , pp. 113–116. Available at:[https://doi.org/10.1145/2994459.2994468](https://doi.org/10.1145/2994459.2994468).
</li>
<li id="molloy2011">Molloy, L.(2011) _Oh, the Humanities! A Discussion about Research Data Management for the Arts and Humanities Disciplines_ . JISC MRD - Evidence Gathering. Available at:[https://web.archive.org/web/20141218214525/http://mrdevidence.jiscinvolve.org/wp/2011/12/16/oh-the-humanities-a-discussion-about-research-data-management-for-the-arts-and-humanities-disciplines/](https://web.archive.org/web/20141218214525/http://mrdevidence.jiscinvolve.org/wp/2011/12/16/oh-the-humanities-a-discussion-about-research-data-management-for-the-arts-and-humanities-disciplines/).
</li>
<li id="morgan2021">Morgan, P.(2021) _Further thoughts on collectivity_ .Paige Morgan. Available at:[https://web.archive.org/web/20221218222956/http://blog.paigemorgan.net/articles/21/further-thoughts.html](https://web.archive.org/web/20221218222956/http://blog.paigemorgan.net/articles/21/further-thoughts.html).
</li>
<li id="morreale2019">Morreale, L.(2019) “Medieval Digital Humanities and the Rite of Spring: Thoughts on Performance and Preservation” . Available at:[https://doi.org/10.34055/osf.io/7p2t6](https://doi.org/10.34055/osf.io/7p2t6).
</li>
<li id="newson2017">Newson, K.(2017) “Tools and Workflows for Collaborating on Static Website Projects” , _The Code4Lib Journal_ , 38. Available at:[https://journal.code4lib.org/articles/12779](https://journal.code4lib.org/articles/12779).
</li>
<li id="nielsenJakob1999">Nielsen, Jakob(1999) _Graceful Degradation of Scalable Internet Services_ .Nielsen Norman Group Website. Available at:[https://www.nngroup.com/articles/graceful-degradation-of-scalable-internet-services/](https://www.nngroup.com/articles/graceful-degradation-of-scalable-internet-services/).
</li>
<li id="nielsenJim2021">Nielsen, Jim. (2021) _Web Languages as Compile Targets_ .Jim Nielsen’s Blog. Available at:[https://blog.jim-nielsen.com/2021/web-languages-as-compile-targets/](https://blog.jim-nielsen.com/2021/web-languages-as-compile-targets/).
</li>
<li id="rinaldi2015">Rinaldi, B.(2015) _Static Site Generators_ . O’Reilly Media, Inc.
</li>
<li id="sacchi2015">Sacchi, S.(2015) “What Do We Mean by ‘Preserving Digital Information’? Towards Sound Conceptual Foundations for Digital Stewardship” , PhD thesis, University of Illinois at Urbana-Champaign. Available at:[https://doi.org/10.7916/D8WW7GMK](https://doi.org/10.7916/D8WW7GMK).
</li>
<li id="sayers2016">Sayers, J.(2016) _Minimal Definitions_ .Minimal Computing: A Working Group of GO::DH. Available at:[http://go-dh.github.io/mincomp/thoughts/2016/10/02/minimaldefinitions/](http://go-dh.github.io/mincomp/thoughts/2016/10/02/minimaldefinitions/).
</li>
<li id="takedaLines2019">Takeda, J.andLines, S.(2019) “Using Github and its Integrations to Create, Test, and Deploy a Digital Edition” , paper presented at the Text Encoding Initiative Conference, Graz, Austria, September 2019. Available at:[https://gams.uni-graz.at/o:tei2019.174](https://gams.uni-graz.at/o:tei2019.174).
</li>
<li id="thieberger2016">Thieberger, N.(2016) “What remains to be done – Exposing invisible collections in the other 7000 languages and why it is a DH enterprise” , _Digital Scholarship in the Humanities_ , 32(2), pp. 423–434. Available at:[http://dx.doi.org/10.1093/llc/fqw006](http://dx.doi.org/10.1093/llc/fqw006).
</li>
<li id="unsworth1997">Unsworth, J.(1997) “Documenting the Reinvention of Text: The Importance of Failure” , _The Journal of Electronic Publishing_ , 3(2). Available at:[https://doi.org/10.3998/3336451.0003.201](https://doi.org/10.3998/3336451.0003.201).
</li>
<li id="viglianti2017">Viglianti, R.(2017) “Your Own Shelley-Godwin Archive: An off-line strategy for on-line publication” , paper presented at the Text Encoding Initiative Conference, Victoria, BC, Canada, November 2017. Available at:[https://hcmc.uvic.ca/tei2017/abstracts/t_126_viglianti_shelleygodwin.html](https://hcmc.uvic.ca/tei2017/abstracts/t_126_viglianti_shelleygodwin.html).
</li>
<li id="warwick2020">Warwick, C.(2020) “Interfaces, Ephemera, and Identity: A Study of the Historical Presentation of Digital Humanities Resources” , _Digital Scholarship in the Humanities_ , 35(4), pp. 944–971. Available at:[https://doi.org/10.1093/llc/fqz081](https://doi.org/10.1093/llc/fqz081).
</li>
<li id="wikleWilliamsonBecker2020">Wikle, O.,Williamson, E., andBecker, D.(2020) “What is Static Web and What’s it Doing in the Digital Humanities Classroom?” , _dh+lib_ . Available at:[https://dhandlib.org/2020/06/22/what-is-static-web-and-whats-it-doing-in-the-digital-humanities-classroom/](https://dhandlib.org/2020/06/22/what-is-static-web-and-whats-it-doing-in-the-digital-humanities-classroom/).
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://www.exist-db.org/exist/apps/homepage/index.html">https://www.exist-db.org/exist/apps/homepage/index.html</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://en.wikipedia.org/wiki/Write_once,_run_anywhere">https://en.wikipedia.org/wiki/Write_once,_run_anywhere</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>In our Endings survey, for example, 31% of projects used a MySQL database, 15% used Drupal, and 18% used WordPress; others depended on Ruby/Rails, Django, Omeka, Plone, Cocoon, and eXist.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>The Appendix lists most of the static sites we have produced so far.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p><a href="https://en.wikipedia.org/wiki/Tamagotchi">https://en.wikipedia.org/wiki/Tamagotchi</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>See, for example, this video of SVN commits generated using Gource from MoEML’s svn repository:<a href="https://www.youtube.com/watch?v=Qor69c2Cvmc">https://www.youtube.com/watch?v=Qor69c2Cvmc</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>We discuss this processing in greater detail in 5.4.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>There are of course contexts in which it may be impossible to make all data publicly available; one of our own Endings projects, the <em>Nxa’amxcín Database and Dictionary</em> , contains culturally-sensitive personal and linguistic data which cannot be shared outside the original language community.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>At the time of writing, the JAMStack website lists 326 generators across 45 programming languages.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Some of the most popular of these tools are the GO:DH Minimal Computing Group’s digital-edition platformEdand their digital exhibit builderWaxas well as LIB-Static’sCollection Builder.For a more comprehensive outline of the goals of minimal computing for the GO:DH Minimal Computing Group, see<a class="footnote-ref" href="#gil2015"> [gil2015] </a>and<a class="footnote-ref" href="#sayers2016"> [sayers2016] </a>. There is also a growing interest in the use of static collections within libraries as demonstrated by<a class="footnote-ref" href="#newson2017"> [newson2017] </a>,<a class="footnote-ref" href="#diaz2018"> [diaz2018] </a>, and<a class="footnote-ref" href="#wikleWilliamsonBecker2020"> [wikleWilliamsonBecker2020] </a>.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>See<a href="https://github.com/projectEndings/diagnostics">https://github.com/projectEndings/diagnostics</a>and<a href="https://github.com/projectEndings/html_diagnostics">https://github.com/projectEndings/html_diagnostics</a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Google Web Fundamentals,<a href="https://developers.google.com/web/fundamentals/security/csp">https://developers.google.com/web/fundamentals/security/csp</a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>This is not strictly true, of course — minor typographical variants are common within a single edition — but for most practical purposes we behave as though it is.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>While this paper does not address project management per se, it is worth noting that this model provides some significant benefits in terms of digital project management. For instance, milestones help prevent feature creep as each release requires careful and considered planning regarding project priorities; by the same token, it allows some space — when combined with Continuous Integration processing mentioned in 5.3 — for experimentation since there is no connection between the deployed site and the source data and thus no risk of breaking the existing site.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p><em>The Map of Early Modern London</em> retains all past static editions of the site. See “<a href="https://mapoflondon.uvic.ca/edition/">Previous Map of London Editions</a>” for all editions.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Including the version control information also makes it possible to rebuild this edition exactly as it is, if data is lost or corrupted.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>While redirects are often created via server configuration, static sites can implement redirects using HTTP headers and other mechanisms. See MDN, “Alternative way of specifying redirects” (<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections#alternative_way_of_specifying_redirections">https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections#alternative_way_of_specifying_redirections</a>).&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Perhaps the best-known examples are FlexSearch, Lunr.js and Elasticlunr.js. None of the available alternatives provided the sophistication and scalability our sites needed.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p><a href="https://endings.uvic.ca/staticSearch/docs/index.html">https://endings.uvic.ca/staticSearch/docs/index.html</a>.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>See<a class="footnote-ref" href="#warwick2020"> [warwick2020] </a>for a recent historical analysis of digital humanities interface and for a discussion of the challenges presented by an incomplete or unusable archived copy of a project.## Bibliography&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Introduction to Special Issue: Project Resiliency in the Digital Humanities</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="related" type="text/html" title="Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="related" type="text/html" title="Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="related" type="text/html" title="Follow the Money?: Funding and Digital Sustainability"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="related" type="text/html" title="From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000660/?utm_source=atom_feed" rel="related" type="text/html" title="No Boutique or Fashionable Technologies: Project Development, Mentorship, and Sustainability in an Innovation-First World"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000671/</id><author><name>Martin Holmes</name></author><author><name>Janelle Jenstad</name></author><author><name>J. Matthew Huculak</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h1 id="introduction-to-special-issue-project-resiliency-in-the-digital-humanities">Introduction to Special Issue: Project Resiliency in the Digital Humanities</h1>
<blockquote>
<p>What we call the beginning is often the end<br>
And to make an end is to make a beginning.<br>
The end is where we start from.<br>
– T. S. Eliot, <em>Little Gidding</em></p>
</blockquote>
<h2 id="the-end-is-where-we-start-from">“The end is where we start from”</h2>
<p>Over the past decade, digital humanists have come a long way in recognizing when a project is “done” <a class="footnote-ref" href="#kirschenbaum2009"> [kirschenbaum2009] </a>. But DH still has a problem when it comes to project resiliency. As<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000660/000660.html">Constance Crompton</a>points out in her contribution to this issue, DH grant funding is disproportionately awarded to new and shiny digital technologies and tools rather than to disciplinary scholarship implemented and published with standard digital tools. Almost no funding is available for maintenance, remediation, upgrading, and remaking, even though technological frameworks will have changed considerably in a five-year funding cycle. The result is a huge maintenance burden for project leads and developers (<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000668/000668.html">Holmes &amp; Takeda</a>in this issue) and/or a hosting and storage problem for institutions (<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000669/000669.html">Cummings</a>in this issue).</p>
<h2 id="what-we-call-a-beginning--project-endings">“What we call a beginning” : Project Endings</h2>
<p>Most of the papers in this <em>DHQ</em> special issue are the product of a virtual symposium held in April 2021 by<a href="https://endings.uvic.ca">The Endings Project</a>at the University of Victoria. The Endings Project, a five-year collaboration funded by the Social Sciences and Humanities Research Council (<a href="http://www.sshrc-crsh.gc.ca/">SSHRC</a>), is creating tools, principles, policies, code, and recommendations to help digital scholarship practitioners create accessible, stable, long-lasting resources in the humanities. Unusually for DH, the Endings Project was initiated by developers (see<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000668/000668.html">Holmes and Takeda</a>in this issue). It brings together digital humanists and librarians because, as Matthew Kirschenbaum has argued, “Digital humanists need the long-term perspective on data that archivists have” <a class="footnote-ref" href="#kirschenbaum2013"> [kirschenbaum2013] </a>. The Endings team’s developers (all of them humanists by their first training) are the bridge between Humanities researchers and Librarians/archivists. The Endings Project facilitates a long-term conversation between the three constituencies responsible for the intellectual generation, building, and long-term preservation of digital research products.</p>
<p>The impetus for The Endings Project was the substantial maintenance burden accrued by UVic’s Humanities Computing and Media Centre (<a href="https://hcmc.uvic.ca/">HCMC</a>), which has been involved in over 200 digital humanities projects since the 1990s. Its history, as described in<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000668/000668.html">Holmes &amp; Takeda</a>, clearly shows the problems inherent in current approaches to digital edition projects, particularly projects with short-term or sporadic grant funding. The growing maintenance burden facing the HCMC was ultimately unsustainable. Project Endings was conceived and convened to address this problem.</p>
<p>The mission of The Endings Project was:</p>
<ul>
<li>to discover what human and institutional factors prevent completion of projects;</li>
<li>to learn how to make web-based digital editions that will last indefinitely without maintenance; and</li>
<li>to learn how to archive finished projects without placing undue burdens on the repository.</li>
</ul>
<p>Ultimately, we wanted to know how projects end, why and when they fail to achieve their final milestone, what constitutes a good ending, and where best to store the finished product so that its research outputs continue to be available long-term.</p>
<h2 id="to-evaporate-ones-thoughts-in-a-sonnet--cultures-of-constraint">“To evaporate one’s thoughts in a sonnet” : Cultures of constraint</h2>
<p>The Earl of Essex was said to have put his arguments to Queen Elizabeth in the highly constrained form of the sonnet<a class="footnote-ref" href="#wotton1672"> [wotton1672] </a>. While sonnets did not save the earl’s neck, we do believe that the answer to the question of how to create long-term, accessible resources is found in cultivating cultures of constraint. We have phrases like “scope creep” and “feature creep” to describe the near-irresistible temptations to act on every good idea a project member may have. We introduce the term “platform creep” to describe easy-to-deploy platforms that facilitate rapid deployment of a new project, but incur technical debt leading to inevitable obsolescence. At the end of these types of projects, project leads are often surprised when their institutional library or archive is unable to preserve the bespoke software stack they’ve cobbled together. Instead of trying to preserve what we accidentally made, we should be trying to make what can be preserved.</p>
<p>The fewer flourishes in software, the longer the project seems to last. The recent work of the HCMC has been to be innovative within a limited set of technologies, in order to minimize the maintenance burden of over 200 projects, so that developer time can be invested in newer projects coming in. We learned quickly that asimplesecurity update could render sites unreadable, thus necessitating constant tending and time. The need for action within very strict constraints (time and funding) forced us to be creative to serve our users.</p>
<p>There are unspoken constraints in the library, as well. Space and human resources force librarians and archivists to make hard decisions about what stays and what goes – weeding the stacks of unused material to make room for new books is one of the less understood aspects of librarians’ jobs. Recently, a member of the Humanist Discussion List asked why librarians can’t preserve digital projects as they do books. It seems like a reasonable request at first glance, but the vast number of bespoke DH projects that would require continual software updates and rewrites in order to keep running quickly would quickly made library preservation an unmanageable task — even with strong documentation created by the projects (and good documentation also tends to be something we run out of time to do). Although libraries and archives can’t fire up hundreds or thousands of Wordpress and Drupal sites, they certainly can run a server on which flat sites can be stored, accessed, and preserved. Asking for such a server is a reasonable request. In this way, limitations need to be the drivers of innovation and the DH community should seeconstraintas an admirable feature of a project since it will give the project the best chance of survival. As a community, we need to adopt constraint as an aesthetic, and make it a part of “the stories we tell,” a phrase<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000665/000665.html">Claire Battershill</a>explores in this issue, about our work.</p>
<h2 id="the-symposium">The Symposium</h2>
<p>The work of Endings began with a day seminar in which the UVic Endings researchers, developers, and librarians<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> met to describe their work, share their institutional vantage point, and learn from each other. We made many surprising discoveries about each other and deconstructed erroneous assumptions about the roles of our institutional colleagues. For example, the Library’s position on archiving was effectively invisible to researchers and developers; the web subdomain of a project (mapoflondon.uvic.ca, for example) seemed self-evidently crucial to researchers as an extension of the project’s title andbrand,while to the Library it seemed obvious that the subdomain didn’t matter at all and that an archived project should be delivered through a library-specific domain.</p>
<p>This day seminar led to our conducting a survey of DH practitioners, in order to learn about the experiences and realities faced by those working in other contexts and institutions. What we learned from the survey (see<a class="footnote-ref" href="#carlin2018"> [carlin2018] </a>;<a class="footnote-ref" href="#endingsTeam2022"> [endingsTeam2022] </a>) was not surprising: most projects faced exactly the same sorts of problems and limitations, although the scale of technical support and resources provided by host institutions varied widely. From the 125 survey respondents, we identified 25 project leads with whom we conducted more in-depth interviews during 2019 and 2020.</p>
<p>These interviews were then transcribed and encoded (see<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000661/000661.html">Comeau</a>in this issue for a detailed description of the interview and analysis process) to provide us with a searchable resource from which we could easily draw examples and examine general tendencies and issues across the DH landscape. Papers are forthcoming that describe the results of those interviews. Finally, we invited a selection of our interviewees from a range of different disciplines to continue the co-created conversation by participating in the 2021 symposium that gave rise to this special issue.</p>
<h2 id="the-papers">The Papers</h2>
<p>We begin with a pair of papers that address two of the key problems in foreseeing an ending to a digital project. In “The Stories We Tell,” <a href="http://www.digitalhumanities.org/dhq/vol/17/1/000665/000665.html">Claire Battershill</a>addresses our very human reluctance to imagine our own projects coming to an end. She proposes that if we think about DH projects “in a literary sense, we can analyze and read digital projects as the creative and multifaceted texts that they are and become. We can perhaps approach them with intention and care not only as technical artifacts but also as works that we’ve made, often along with a number of collaborators.” Projects begin in “promise, potential, and excitement” ; despite challenges along the way, we keep projects going because the project becomes intrinsic to our purpose and definition, especially for the many digital humanists in precarious employment. Resolving disciplinary and other inequities would go a long way towards helping projects reach their end, she argues, because a team in stable institutional positions may keep collaborating on other projects, large or small.<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000660/000660.html">Constance Crompton</a>points out the ways in which funding structures that reward innovation have discouraged sustainable, replicable practices until the “recent turn to sustainability, signalled by the rise of data management plans and data deposit requirements.” Given the self-replicating nature of DH practices through the apprenticeship model whereby students work on large projects, mentorship will be a crucial factor in breaking the cycle of unsustainable, boutique project building.</p>
<p><a href="http://www.digitalhumanities.org/dhq/vol/17/1/000669/000669.html">James Cummings</a>discusses two well-known digital edition projects, the <em>CURSUS</em> project and <em>William Godwin’s Diary</em> . Both projects were severely endangered by the lack of legacy planning. When key personnel are lost, and a project has no champion at its host institution, the consequences can be disastrous, especially when the project depends on a technical framework that is not part of the institution’s core infrastructure. Both of these projects would have been completely lost without Cummings’s persistent intervention.</p>
<p>In telling two digital disaster stories,<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000670/000670.html">Sara Diamond</a>reminds us that even the most important and socially significant projects are subject to institutional changes, career moves, and shifting priorities. The Banff New Media Institute was deaccessioned after a leadership change, resulting in the overnight disappearance of a vast archive of Indigenous art and history. The Daniel Langlois Foundation archive survived only because of the determined efforts of Jean Gagnon, on whose good will the project is still worryingly dependent. Diamond’s own fonds and sub-collections have been built with the lessons of these two experiences in mind. Ultimately, Diamond suggests that “institutions, creators of archives and their users all bear responsibility for the protection and continuity” of those archives.</p>
<p><a href="http://www.digitalhumanities.org/dhq/vol/17/1/000667/000667.html">Nick Thieberger’s</a>paper, on the monumental PARADISEC project, describes an attempt to thwart the forces of entropy on a massive scale. PARADISEC has rescued over 14,000 hours of field audio tape recordings representing over 1300 languages from the Pacific Region, and is hosting them in a public archive, as well as attempting to return them in accessible format to the originating Indigenous communities. This enormous project is itself facing resiliency issues, since it has no stable funding and depends on a small team of dedicated researchers, reminding us that the process of data rescue and retrieval may be cyclical and repetitive without reliable commitments to long-term archiving.</p>
<p>Like Battershill,<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000666/000666.html">Jessica Otis</a>is concerned with deconstructing narratives — in this case the funding narratives that suggest, erroneously, that DH projects are either “cash cows” bringing money into the institution via grants or “free” because of donated scholarly labor. Having shown the hidden costs of project maintenance, Otis discusses the prospects of obtaining long-term funding to sustain a project beyond its initial grant-funding, the availability of hard-funded resources from the institution, and the practical realism required to retool projects to fit into sustainable long-term funding models.</p>
<p>There is a traditional assumption that what matters about a digital project is itsdata(however we might define that), rather than its web interface, which is considered ephemeral. However, every session at the symposium touched on the issue of interface, arguably the most recognizable and least preservable part of a digital project. Preserving the look and feel of web-based digital projects continues to be a challenge. Symposium attendees discussed the possibility of doing video captures of website tours and archiving video along with a digital project’s data.<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000670/000670.html">Diamond</a>points to emulation as a preservation strategy, and we can undoubtedly learn much from the work of electronic literature scholars as well. Emulation is expensive in terms of hardware, software, and maintenance, and perhaps only works like those described by Diamond will merit such preservation.</p>
<p>Our final two papers were not presented at the symposium. However,<a href="http://www.digitalhumanities.org/dhq/vol/17/1/000668/000668.html">Holmes and Takeda</a>, as Endings team members and co-hosts of the symposium, shared their ideas in the discussion. They approach the practical issues of project resiliency from a technical point of view. Their role on the Endings team was to develop the detailed guidelines and recommended practices that would govern the rewriting of many HCMC projects as pure static websites, and then to put the guidelines into practice, rebuilding a dozen or so existing HCMC projects in Endings-compliant form. Along the way, they developed diagnostic tools and an entirely static search engine that can be deployed for any static digital edition.</p>
<p><a href="http://www.digitalhumanities.org/dhq/vol/17/1/000662/000662.html">Coble and Karlin’s</a>paper is a serendipitous addition to our collection; the authors were not presenters at our symposium, but their paper is an apt counterpoint to the other work on project resiliency. They examine not the reliability of individual project data and outputs, but the larger web of scholarly referencing within which they live. Their research looks at citations of digital resources from articles in <em>DHQ</em> itself, to see not just whether links still function, but also whether the resources to which they point are the same resources the author intended to cite.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Sometimes things are meant to be ephemeral: there is ephemeral employment and there are ephemeral products of scholarship, which is fine as long as ephemerality is intentional. Yet the majority of DH projects find themselves in the unfortunate position of being unintentionally ephemeral. One of the anonymous reviewers of this issue made the point that we shouldn’t have to keep making the point that digital projects need to be more robust and preservable. The reviewer wondered why we are still having to advocate for what they characterized as common knowledge and common sense. Taken together, the essays in this collection show the difficulty of realizing common sense in practice. The roots of this persistent problem are both social and technological.</p>
<p>DH has a strong tradition ofcollaboration,which frequently includes students, colleagues from across campus, and programmers, as well as librarians and archivists. However, each group brings to the table its own cultural norms and presuppositions, and each group works within existing structures of power, funding, and promotion that are frequently at odds with one another.</p>
<p>A faculty member who may want to launch a project quickly may be seduced by the siren song ofeasy to deploy,which is nearly always at odds with long-term survivability. A hastily-concocted Wordpress or Drupal site, although ready for a promotion file — or replaced with the next big project — will be at the mercy of how much time the scholar actually has to commit to regular updates (usual answer: little to none). The programmer may resist the upfront work of setting up a sustainable long-term platform because they are accustomed to working with specific platform stacks and are tempted to fall back on what they already know, or to pick up whatever library or platform is momentarily newest and most interesting; projects built out of such a mindset will be at the mercy of security vulnerabilities, software obsolescence, and personnel changes. Librarians and archivists are constrained by a scarcity economy of space and funding — it is easy to eschew preserving digital projects when you know it will be impossible to maintain them. Although the dream of auniversal libraryis a beautiful ideal, it will nonetheless remain a fiction until we choose universal technologies.</p>
<p>The first stage in building an Endings-compliant project is having an honest conversation among faculty, programmers, and librarians/archivists about expectations, abilities, and sustainability that is agreed upon and documented. This step should happen before the first byte is saved to disk. Normally trained to work in solitude, faculty may need to rely on experts beyond their discipline who work at a different pace. Programmers may have to be open to different ways of programming and take the extra time to design for the eventual flattening of sites even if a dynamic site is preferred for the length of the project (which is perfectly fine, assuming there is funding and time for a complete rewrite at the end). Librarians and archivists need to invest in people, services, and technologies to sustain flat websites — which could simply be a server that is part of the libraries’ long-term preservation plan. As this issue was being created, the <em><a href="https://graves.uvic.ca">Diary of Robert Graves</a></em> project became the first archived DH project at UVic Libraries, a process which was possible only because the site is Endings compliant. UVic Libraries is committing to preserving flattened, Endings-compliant sites as part of its preservation activities. It has taken some time to reach this point and the process has involved stakeholders from across the institution (Systems, Metadata, Digital Scholarship, and the University Librarian&rsquo;s Office), but we’re here. Hosting a server for static sites is eminently achievable for most university libraries. With collaboration comes compromise in the name of long-term access and discoverability. Everyone on the team needs to understand the needs and limitations of the others, while also mutually agreeing to Endings Principles.</p>
<p>Finally, if there’s one constant in DH, and computing in general, it is that technologies will change. Our toolkit is not a technological solution that will be out of date next year. Rather, it is a series of practices for you to consider when starting your project. Moreover, each DH project exists within a unique environment with unique challenges. We’ve thus made our recommendations adaptable to any project, at any scale, with the hope of creating something sustainable. Who knows what tomorrow will bring? What we do know is that the fewer dependencies a digital edition has, the longer it is likely to last. The first HTML page marked up by Tim Berners-Lee in 1991 is still renderable by modern browsers.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Simplicity for the win.</p>
<ul>
<li id="carlin2018">Carlin, C. 2018. “Endings: Concluding, Archiving, and Preserving Digital Projects for Long-Term Usability” . _KULA: Knowledge Creation, Dissemination, and Preservation Studies_ , 2(1). DOI:[https://doi.org/10.5334/kula.35](https://doi.org/10.5334/kula.35).
</li>
<li id="eliot1942">Eliot, T.S. (1942) “Little Gidding.” London: Faber and Faber.
</li>
<li id="endingsTeam2022">Endings Team. 2022. “Endings Project Survey Results” .[https://endings.uvic.ca/survey.html](https://endings.uvic.ca/survey.html).
</li>
<li id="holmes_takeda">Holmes, M. and Takeda, J. “From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles.”  _Digital Humanities Quarterly_ . Forthcoming.
</li>
<li id="kirschenbaum2009">Kirschenbaum, M. G. 2009. “Done: Finishing Projects in the Digital Humanities” . _Digital Humanities Quarterly_ 3(2).[http://www.digitalhumanities.org/dhq/vol/3/2/000037/000037.html](http://www.digitalhumanities.org/dhq/vol/3/2/000037/000037.html).
</li>
<li id="kirschenbaum2013">Kirschenbaum, M. 2013. “The .txtual Condition: Digital Humanities, Born-Digital Archives, and the Future Literary.”  _Digital Humanities Quarterly_ 7(1).[http://www.digitalhumanities.org/dhq/vol/7/1/000151/000151.html](http://www.digitalhumanities.org/dhq/vol/7/1/000151/000151.html).
</li>
<li id="wotton1672">Wotton, Sir Henry. 1672. _Reliquiae Wottonianae: Or, a Collection of Lives, Letters, Poems, with Characters of Sundry Personages, and Other Incomparable Pieces of Language and Art_ . London: T. Roycroft, 1672.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The Endings Team originally consisted of researchers Claire Carlin, Ewa Czaykowska-Higgins, Elizabeth Grove-White, and Janelle Jenstad; developers Stewart Arneil, Martin Holmes, and Greg Newton; and librarians Corey Davis, John Durno, and Lisa Goddard. Since 2016, Elizabeth Grove-White has retired, and J. Matthew Huculak has replaced Corey Davis on the team. Research assistants and collaborators have included Emily Comeau, Tye Landels, Daniel Martin, and Joey Takeda.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="http://info.cern.ch/hypertext/WWW/TheProject.html">http://info.cern.ch/hypertext/WWW/TheProject.html</a>.## Bibliography&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">No Boutique or Fashionable Technologies: Project Development, Mentorship, and Sustainability in an Innovation-First World</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000660/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="related" type="text/html" title="From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="related" type="text/html" title="Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="related" type="text/html" title="Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="related" type="text/html" title="Follow the Money?: Funding and Digital Sustainability"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction to Special Issue: Project Resiliency in the Digital Humanities"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000660/</id><author><name>Constance Crompton</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>In recent decades, university research has been bound up in the expectation of innovation without the material support for sustainability. As a guiding principle, innovation has shaped the goals of universities and funders; the recent turn to sustainability, signaled by the rise of data management plans and data deposit requirements, may indicate a welcome discursive shift. This article explores the interplay of knowledge creation and mentorship in the development of digital humanities research projects, with the aim of addressing the artificial tension between innovation and sustainability. While often framed in opposition to each other, or used in a neoliberal framework to force researchers to do more with fewer resources, innovation and sustainability can, this article argues, be dual goals in the development of lasting digital humanities scholarship. The Endings Project principles and framework, as outlined in the introduction to this issue, represent a methodological innovation that provides a solution to the challenge of sustainability. Drawing on the Lesbian and Gay Liberation in Canada project as a case study, this article considers the tensions between sustainability and innovation in the ongoing life of digital humanities projects, and role of the TEI mark-up language and Endings Project principles for the future creation and preservation of humanities scholarship online.</p>
<h2 id="scope-scale-and-sustainability-at-the-turn-of-the-twenty-first-century">Scope, Scale, and Sustainability at the turn of the Twenty-First Century</h2>
<p>Throughout the 1990s, most North American digital humanities work fell into one of two camps: edition and online resource creation or software development. Many of us started as junior faculty or graduate students in the former camp even if we now work in the latter. There were few graduate or undergraduate courses in the digital humanities in Canada at the time. Most of the graduate training that shaped the scholarship in which we now engage was offered through workshops or research assistantships. In addition to the challenge of accessing training, the generation of graduate students from the first decade of the 2000s in Canada were working when digital humanities methods were occasionally hampered by disciplinary mistrust. In North America, the digital humanities, when they garnered attention, were dogged by concerns that they did not constituterealhumanities scholarship<a class="footnote-ref" href="#kirschenbaum2012"> [kirschenbaum2012] </a>.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>The digital humanities’ outsider status notwithstanding, in the period from the mid 1990s to 2010, large-scale digital humanities publishing projects flourished online. Digital humanities scholars reveled in the affordances and pleasures of online publishing. Hypertext&rsquo;s ability to let readers move through texts in non-linear ways attracted a good deal of scholarly attention<a class="footnote-ref" href="#mcgann2001"> [mcgann2001] </a><a class="footnote-ref" href="#hayles2007"> [hayles2007] </a>. More important, perhaps, for questions of sustainability and innovation, was the sheer scope of the projects that scholars undertook to recuperate and share material that traditional publishers could not provide in print. Many flagship projects from this era had a huge remit. For example, <em>Orlando</em> , started in 1995, provides interpretive and biographical information about “women’s writing in the British Isles from the beginnings to the present” ; the <em>Women Writers’ Project</em> (WWP), started in 1988, is dedicated to early women’s writing in English; and <em>Voices from the Gaps</em> , started in 1996, aims to “share the works of marginalized artists, predominantly women writers of color living and working in North America” (see<a class="footnote-ref" href="#brown1997"> [brown1997] </a>,<a class="footnote-ref" href="#hockey2004"> [hockey2004] </a>,<a class="footnote-ref" href="#flanders2006"> [flanders2006] </a>,<a class="footnote-ref" href="#earhart2012"> [earhart2012] </a>, and<a class="footnote-ref" href="#mcnaron"> [mcnaron] </a>). These projects are distinct from those with the more narrow scope that characterize current digital humanities projects. The directors of smaller projects with short development cycles can more easily frame a project as novel or innovative. Larger, longer-running projects, which are in greater need of sustaining maintenance, must develop new micro-projects to frame their work as innovative. Theseprojects are often central to humanities research and teaching, and their long-term stability is key to maintaining access to the cultural record (for example, the disappearance of information about the cultural conditions of generations of women’s writing in the British Isles would be a significant loss, and yet there are few funding mechanisms to support the maintenance of such a corpus). As Jessica Otis has pointed out in her discussion of how the Roy Rosenzweig Center for History and New Media decides which projects to continue to support, principal investigators from the turn of the century often promised funders not only a broad project scope, but also that digitized material would stay up online indefinitely. The move from early hypertext-only sites to database-backed sites and content management systems that now need to be migrated forward or need virtual environments to run has made keeping the sites functional sometimes difficult and often impossible (see Holmes &amp; Takeda and Otis in this issue).</p>
<p>In the age of large-scale online publishing projects at the turn of the twenty-first century, scholars took the mechanisms of publishing into their own hands. Many “scholars invested in early work on race [and class and gender] in digital humanities insisted on building editions and digital texts as an activist intervention in the closed canon” <a class="footnote-ref" href="#earhart2012"> [earhart2012] </a>. This move was not always an indictment of traditional publishers: many scholars recognized that, for example, publishing 400 texts written by women between 1526 and 1850, as the WWP has, represented a greater financial burden than most print-based publishers could undertake or hope to recover through sales. Furthermore, the affordances of hypertext and of databases to reorganize and connect texts nearly endlessly offered advantages that printed texts could not supply. The development of easily archivable mark-up languages, such as TEI, has been key to the development of corpora that are easy to sustain.</p>
<p>TEI, the XML-based language of the Text Encoding Initiative Consortium for modeling documents and formalizing text in a computationally tractable way, has been a major part of the digital humanities’ efforts to engage in sustainable long-running publication and textual analysis. The TEI was conceived by a multidisciplinary group of scholars and students at a Vassar-hosted meeting in 1987; over 50 scholars worked on its initial release in 1990<a class="footnote-ref" href="#historytei"> [historytei] </a>. The development of TEI-SGML (now TEI-XML) for representing textual material was an area of major intellectual effort and innovation that provided a useful tool for online edition production, and responded directly to the needs of editors and readers in a way that print publication could not. The proliferation of TEI impacted the growth of the digital humanities at the turn of the twenty-first century: many junior scholars were introduced to TEI through workshops and research assistantships. Not only is the TEI designed to meet the needs of textual editors, it also offers a number of advantages to users who have no prior technical background. TEI is human-readable in a way that other formats, for example JSON or Turtle, are not. TEI is platform-agnostic, which means that anyone can start writing valid TEI without the expensive overhead and resource-intensive setup of other tools, such as databases, Hadoop clusters, Adobe Creative Suite software, or 3D printers. Finally, TEI is not a language or tool borrowed from another discipline to be put to a humanities&rsquo; purpose. Instead, it is a community-led humanities-specific language. The language continues to grow in response to TEI-sponsored Special Interest Groups and in response to requests from regular users who want the language to expand to include new use cases. Volunteers govern the TEI Consortium through a Board of Directors and a Technical Council who undertake the demanding governance and stewardship of the TEI Guidelines, services, and documentation. The TEI Consortium provides tools to analyze and customize TEI such as the eXtensible Stylesheet Transformation Language (XSLT) scripts, the XML-ODD format for TEI customization, and tools for users to display TEI–including the TEI Archiving, Publishing, and Access Service (TAPAS) and CETEIcean. For many humanities scholars, TEI has been <em>the</em> introduction to digital humanities scholarship and learning to use these scripts and tools has been key to analysis and online publication.</p>
<p>While there have been advances in artificial intelligence and application design that support some branches of digital humanities scholarship, the TEI continues to be the gold standard for edition encoding. Confronted with a plain text transcription of a primary source, a computer will know nothing about either text structure (for example, where pages start and end, or where the boundaries of paragraphs are) or about more nuanced content (for example, who added the interlinear glosses to a manuscript, how many years separate the original scribe and the glossator, how abbreviations ought to be expanded, or which calendar system is used in the text). Broadly, encoders use TEI to add what they know or wish to argue about a transcribed text in a computationally parsable form. The TEI was originally designed to help scholars describe what they know about a source text; the language has since expanded to let scholars describe images and any number of other cultural artifacts and ancillary information in a robust and systematic way. Best of all, TEI creation does not rely on databases, content management systems, or any other technology that requires perennial migration.</p>
<h2 id="a-personal-account-of-mentorship-and-project-development-in-the-canadian-context">A Personal Account of Mentorship and Project Development in the Canadian Context</h2>
<p>A part of the TEI-user community consists of scholars who are engaged in largely DIY encoding and publishing practices. In the Victorian Studies community in which I trained, this ethos grew out of the inaugural Networked Infrastructure for Nineteenth-Century Electronic Scholarship (NINES) workshop in July 2005, which catalyzed the use of TEI to facilitate the aggregated search of a number of now-iconic digital humanities projects, including the <em>Nineteenth-Century Serials Edition</em> <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> <a class="footnote-ref" href="#brakearmstrongnd"> [brakearmstrongnd] </a>, <em>The Poetess Archive</em> <a class="footnote-ref" href="#mandellnd"> [mandellnd] </a>, and <em>The Vault at Pfaff&rsquo;s</em> <a class="footnote-ref" href="#whitleynd"> [whitleynd] </a>. The initial NINES projects each ran on its own project-specific stack: at the time there were no content management systems or prefabricated hosting services for TEI. That said, NINES was a community-led standards success: projects federated within NINES used TEI as a common encoding format, shared NINES keywords, and featured stable project URIs. These shared standards allowed for listing and linking within NINES, leaving the question of interface and backend development to individual projects. My formative training was on one of the projects initiated at the inaugural NINES summer workshop, the <em>Yellow Nineties Online</em> (1890s.ca). Relaunched as <em>Yellow Nineties</em> 2.0 in 2015, the <em>Yellow Nineties</em> and its federated sister projects feature eight fin-de-siècle little magazines, with supporting biographies and essays that focus on the context and networks of the little magazines’ production and reception; teaching resources and student scholarship; and tools for visual culture analysis<a class="footnote-ref" href="#yellownineties2015"> [yellownineties2015] </a>.</p>
<p>Smaller digital humanities teams rely on project members’ understandings of their shared project as a whole. This holistic knowledge is a boon for sustainability. As Frank Tough has argued, humanities research is a craft, and, at the graduate level is often taught through intensive, one-on-one research assistantships<a class="footnote-ref" href="#tough2021"> [tough2021] </a>. In Canada in the 2000s, this model continued in the digital humanities, with many graduate students learning from principal investigators on small teams. The Canadian funding system, particularly the support provided by the mid-sized SSHRC Standard Research Grant (1998-2011, $21,000-$250,000 over three years), and the uptake of digital humanities predominantly at smaller universities, added structural elements that encouraged the creation of small teams, as opposed, for example, to the broader, multidisciplinary, multi-university projects with dedicated staff of more recent years. Research assistants on these small projects got to learn how projects were built, to understand what each member of a small and intimate team was doing, to contribute to the infrastructural and content development of each project, and to see how the technical infrastructure and subject matter of each project were knit together in the intellectual labor of each project<a class="footnote-ref" href="#engel2015"> [engel2015] </a><a class="footnote-ref" href="#anderson2016"> [anderson2016] </a>. Both Matthew Kirschenbaum and Julia Flanders suggest that this refusal to separate out infrastructure and content development from the intellectual effort was a distinctive feature of digital humanities in the United States at the time (this approach is certainly central to the development of TEI as a language), as indeed it was in Canada. While the parallel development of infrastructure and content may be framed as the result of happenstance, this feature is consonant with humanities approaches to research as well as to the craft-aligned mentorship of the next generation of scholars. As Lorraine Janzen Kooistra–one of the two original principal investigators of the <em>Yellow Nineties</em> –has pointed out when comparing the project to more recent digital humanities projects: “we did not know that we were <em>supposed</em> to have a technical manager or even collaborators with a background in computer science” <a class="footnote-ref" href="#janzenkooistra2021"> [janzenkooistra2021] </a>. The project was instead developed by the principal investigators and students with extensive consultation with librarians and with hosting support (initially on a desktop computer running as a server) from a single Faculty of Arts systems administrator.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
<p>In this craft system of humanities research training, graduate students tend to go on to reproduce the methods of their supervisors and to work in ways that build on the conditions of their training. This has certainly been the case in my career: having learned the technical aspects of digital humanities work from humanities scholars, often on small teams, I came away with the sense that each project should not have any elements that the principal investigator did not understand herself, and whose creation or deployment she could not undertake at a high level. In short, no one working on the project would do anything the principal investigator could not have done herself, given sufficient time. This approach is a useful safeguard against any changes in university affiliation or changes in local IT policy that might require moving a project, although it is not necessarily a safeguard against the demands of upgrades. The approach also makes it easier to communicate with funders, since the principal investigator is conversant with all parts of the project. Finally, and perhaps most importantly, it is enormously intellectually fulfilling<a class="footnote-ref" href="#rouedcunliffe2016"> [rouedcunliffe2016] </a>. Mentorship on digital projects that fit this model is indeed like traditional humanities mentorship, in which research assistants join principal investigators in the archives, on field research trips, in literature review preparation, in discussion of argumentation, and in manuscript revision. If the assistantship lasts long enough, assistants can get to know every part of the project, and can graduate with the knowledge they need to develop their own projects.</p>
<h2 id="balancing-sustainability-and-innovation-in-digital-humanities-projects">Balancing Sustainability and Innovation in Digital Humanities Projects</h2>
<p>A single principal investigator who understands all parts of a project reduces project dependencies and so can safeguard a project. However, this is not the only, or even necessarily best, model for digital humanities project development. The model has two central drawbacks that may work against sustainability: fragility and non-scalability. If the documentation is poor and there is little buy-in from others, it is hard to maintain the project if the principal investigator has to leave the team for any reason. The project will also be fragile if the principal investigator does not update the project’s technology stack, especially once the technology reaches an end-of-life stage and options to ensure backwards compatibility become cumbersome (for more on this topic see Jessica Otis’ article in this issue of <em>DHQ</em> ; for a more general discussion see<a class="footnote-ref" href="#barats2020"> [barats2020] </a>).</p>
<p>The second challenge of the model of a sole principal investigator who could perform every project task is that of scalability. I do not mean to use the term <em>scalable</em> as a neoliberal dog whistle meaning to <em>do more with less</em> , or meaning to get students to pay for what were once government- or endowment-supported low student-to-researcher ratios enjoyed by previous generations. Instead, I would like to point to the benefits of larger, more collaborative research projects. They are often less fragile, with more opportunities for leadership and therefore more people who could steward the project if the principal investigator has to step back. They are also more scalable in terms of knowledge creation, in that they will have multiple research questions, spanning several domains, with distinct areas of investigation of interest to, for example, collaborators in computer science, information science, the social sciences, and the humanities.</p>
<p>No matter what the leadership or collaboration structure of a research project may be, the central goal of primary research is the creation of new knowledge. This goal is the hallmark of university-led research, and yet it may be at odds with the discourses of innovation and sustainability in the contemporary research funding landscape. In exploring these tensions in project development, I will use the <em>Lesbian and Gay Liberation in Canada</em> ( <em>LGLC</em> ) project, which I co-direct with Michelle Schwartz (Toronto Metropolitian University), as my case study.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
<p>The goal of the <em>LGLC</em> project is to analyze the emergence and expansion of gay liberation as an intellectual movement backed by informal and formal political action, in order to better understand the conditions that foster political change and to recover gay liberation history for a popular audience. The project has been built around two books by our collaborator Donald McLeod, <em>Lesbian and Gay Liberation in Canada</em> volumes 1 and 2<a class="footnote-ref" href="#mcleod1996"> [mcleod1996] </a><a class="footnote-ref" href="#mcleod2017"> [mcleod2017] </a>. McLeod’s chronologies consist of 3,100 chronological events spanning 1964 to 1981. Using TEI, the <em>LGLC</em> team has encoded each event, marking up names, places, dates, organizations, and periodicals. The core events are contextualized by, to date, a further 32,000 entity records about people, location, publications, and organizations. The team is now involved in further archival research to uncover more events spanning 1960 to 1985. The TEI serves as a discovery mechanism for our analysis, letting us explore the relationships between the entities, and as the basis for our public-facing web app at lglc.ca. The lglc.ca web app consists of the standard set of tools, or <em>stack,</em> for web publication: a server, a database, a programming language to retrieve material from the database, and front-end scripts to create HTML for display in a browser. lglc.ca is hosted and supported by Toronto Metropolitan University Library&rsquo;s Collaboratory. It consists of a neo4j database, a node.js app for retrieval, and jade.js/pug.js-templates to create the HTML front end. It offers visitors to the site a graphic user interface that enables many of the exploratory and analytical features that otherwise would be available only to users with the skills to process the TEI that feeds the neo4j database.</p>
<p>I must say that, to this day, working with TEI and its user community is one of my greatest professional pleasures.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> Moreover, for the purposes of this special issue, I must stress the safety and archivability the TEI lends to my projects, including the <em>LGLC</em> . From the first, TEI has been central to the <em>LGLC</em> preservation strategy. Unlike our database, TEI is human readable without specialized software or an integrated development environment (IDE). We are certain that our validated data can be preserved as a series of flat files, microfiche, or even as a printout that will be legible to future generations<a class="footnote-ref" href="#holmes2019"> [holmes2019] </a>. The code itself does not need more than text editor software to view, and the ubiquity of XML leaves us assured that if our TEI is not decipherable in the future it will be because of a more significant failure of digital systems well beyond the scope and control of academia, commercial companies, or even governments.</p>
<p>But what of our web app? Databases and their interfaces are, as this special issue underscores, notoriously difficult to maintain after the end of a project&rsquo;s active development. We have, therefore, never expected that the lglc.ca web application would exist forever. However, having been trained on the <em>Yellow Nineties</em> , which is part of the generation of digital humanities projects that are the enduring focus of a principal investigator or a pair of investigators for decades, we too expect to work on the <em>LGLC</em> project for many years to come. Unlike many more recent digital humanities projects, like the original collaborative <em>Torn Apart</em> map project, the Serendip-o-matic web app, or other shorter-term projects, our plans for decades of active development may, on the one hand, be attractive to funders, but on the other hand, have kept us from devoting resources to infrastructural changes that we would need for the graceful end to the project beyond periodic or final deposits of our TEI in national and institutional repositories.</p>
<p>Our attention to innovation in the development of lglc.ca at the expense of sustainability has been shaped by one of the best parts of the university research culture: the commitment to creating new knowledge. We are not alone in this approach. While replication and verification are central parts of the research ecosystem, most research is meant to break new ground and benefit the public through sharing the knowledge they supported us in creating. That said, in the last twenty years in the Canadian funding context, that drive to create new knowledge was coupled with a focus on innovation. Cultural and governmental privileging of innovation is, for example, hardwired into the main source of institutional research infrastructure funding in Canada, the Canadian Foundation for Innovation (CFI). And, in as much as it dovetails with the pleasure of new knowledge creation, innovation is no bad thing. A key drawback, however, to the assumption that innovation constitutes a good end in itself, perhaps at the expense of sustainability, is that <em>innovation</em> and <em>sustainability</em> have been discursively opposed to one another<a class="footnote-ref" href="#kirschenbaum2009"> [kirschenbaum2009] </a><a class="footnote-ref" href="#russell2016"> [russell2016] </a>. Principal investigators&rsquo; perceptions that they may be turned down for research funding if they focus on using tried and true methods or on maintaining projects, rather than innovating, materially entrenches this discursive opposition.</p>
<p>There is, however, a sea change under way. In Canada, our public funders are increasingly requiring the open-access publication of results, the deposit of data where appropriate, and the creation of sustainability plans. Happily, on the <em>LGLC</em> project, some of our innovations have led us back to sustainable research development plans: one of our initial innovations in 2013 was to use a then-new graph database, neo4j, as the backend for our public web app. This choice involved thinking through how best to convert our TEI, which relies on a hierarchical tree structure, for representation in neo4j&rsquo;s non-hierarchical node-and-edge-filled graph structure. The exercise of thinking through how to model our data as both a tree and a graph led my research lab into work on how to represent TEI as linked data, another format that relies on graph structures. Linked data has, unlike a neo4j instantiation of the data, the option of remaining in flat files for knowledge creation and long-term preservation.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<p>Sustainability and innovation: it may be possible to have it both ways. Indeed, Project Endings methods represent a marriage of sustainability and innovation. One of the project&rsquo;s principles brings together these two concepts: “no boutique or fashionable technologies: use only standards with support across all platforms, whose long-term viability is assured,” <a class="footnote-ref" href="#endings"> [endings] </a><a class="footnote-ref" href="#carlin2018"> [carlin2018] </a>. The recommendation resolves the tension between sustainability and innovation: as languages, HTML, CSS, and JavaScript are sustainable and secure, but the Project Endings recommendation that researchers use them from the first, rather than producing database-based backed sites that are not sustainable in the long term, is a methodological innovation. While flat files that researchers deposit in repositories will be preserved, and in the case of TEI will remain human readable, these deposited files are less readily accessible to the members of the public who fund our research than a searchable web-version of the same material. The creation of project sites that are accessible (by virtue of being on the web) and that will remain accessible (by virtue of being lightweight, secure, and easy to host) is truly innovative. As someone who trained in the creation of digital humanities projects that are intended to run for decades under a model of development using tools that any principal investigator could understand, I welcome the Project Endings’ recommendation. As someone who is keen to see digital humanities projects of any duration persist in a format that is of maximum utility to the public, I am doubly pleased. The challenge will be to continue to use Project Endings principles to keep digital scholarship accessible, even after the Project Endings recommendations move from being innovative to being the gold standard.</p>
<ul>
<li id="anderson2016">Anderson, K. et al. (2016) “Student Labour and Training in Digital Humanities” , _Digital Humanities Quarterly_ , 10(1).
</li>
<li id="barats2020">Barats, C., Schafer, V., & Fickers, A. (2020). “Fading Away... The challenge of sustainability in digital studies” , _Digital Humanities Quarterly_ , 14(3).
</li>
<li id="brown1997">Brown, S., Grundy, I. and Clemens, P. (1997) “The Orlando Project: Building Digital Resources for an Integrated History of Women’s Writing in the British Isles” . Available at:<a href="https://web.archive.org/web/20150727031408/http://www.ualberta.ca/ORLANDO/publications/o-DRH97.htm">https://web.archive.org/web/20150727031408/http://www.ualberta.ca/ORLANDO/publications/o-DRH97.htm</a>.
</li>
<li id="carlin2018">Carlin, C. (2018). “Endings: Concluding, Archiving, and Preserving Digital Projects for Long-Term Usability” . _KULA: Knowledge Creation, Dissemination, and Preservation Studies_ , 2, 19–19. Available at:<a href="https://doi.org/10.5334/kula.35">https://doi.org/10.5334/kula.35</a>.
</li>
<li id="earhart2012">Earhart, A. (2012) “Can Information Be Unfettered? Race and the New Digital Humanities Canon” , in Gold, M. (ed.) _Debates in the Digital Humanities_ . Minneapolis, MN: U Minnesota P, pp. 309–318.
</li>
<li id="engel2015">Engel, D. and Thain, M. (2015) “Textual Artifacts and their Digital Representations: Teaching Graduate Students to Build Online Archives” , _Digital Humanities Quarterly_ , 9(1).
</li>
<li id="flanders2006">Flanders, J. (2006) “The Women Writers Project: A Digital Anthology” , in Burnard, L., O’Brien O’Keeffe, K., and Unsworth, J. (eds.) _Electronic Textual Editing_ . MLA, pp. 226–244. Available at:<a href="http://www.tei-c.org/About/Archive_new/ETE/Preview/flanders.xml">http://www.tei-c.org/About/Archive_new/ETE/Preview/flanders.xml</a>.
</li>
<li id="hayles2007">Hayles, N. K. (2007) “Electronic Literature: what is it?” Available at:<a href="https://eliterature.org/pad/elp.html">https://eliterature.org/pad/elp.html</a>. Republished 2016 in Crompton, C., Siemens, R., and Lane, R. (eds.) _Doing Digital Humanities: Practice, Training, Research_ . Routledge. pp. 197–226.
</li>
<li id="historytei"> _History – TEI: Text Encoding Initiative_ (n.d.). Available at:<a href="https://tei-c.org/about/history/">https://tei-c.org/about/history/</a>.
</li>
<li id="hockey2004">Hockey, M. (2004) “The History of Humanities Computing” , in Schreibman, S., Siemens, R., and Unsworth, J. (eds.) _Companion to Digital Humanities_ . Oxford: Blackwell P. pp. 3–19.
</li>
<li id="holmes2019">Holmes, M. and Takeda, J. (2019) “Beyond validation: Using programmed diagnostics to learn about, monitor, and successfully complete your DH project” , _Digital Scholarship in the Humanities_ , 34(Supplement_1), pp. i100–i109. Available at:<a href="https://doi.org/10.1093/llc/fqz011">https://doi.org/10.1093/llc/fqz011</a>.
</li>
<li id="janzenkooistra2021">Janzen Kooistra, L. (2021) “Personal communication” .
</li>
<li id="yellownineties2015">Janzen Kooistra, L. _About – Yellow Nineties 2.0_ (2015). Toronto. Available at:<a href="https://beta.1890s.ca/about/">https://beta.1890s.ca/about/</a>.
</li>
<li id="kirschenbaum2009">Kirschenbaum, M. G. (2009) “Done: Finishing Projects in the Digital Humanities” , _Digital Humanities Quarterly_ , 3(2).
</li>
<li id="kirschenbaum2012">Kirschenbaum, M. (2012) “What is Digital Humanities and What is it Doing in English Departments?” in Gold, M. (ed.) _Debates in the Digital Humanities_ . Minneapolis, MN: U Minnesota P, pp. 3–11.
</li>
<li id="kirschenbaum2014">Kirschenbaum, M. (2014) “What Is 'Digital Humanities,' and Why Are They Saying Such Terrible Things about It?”  _differences_ , 25(1), pp. 46–63. Available at:<a href="https://doi.org/10.1215/10407391-2419997">https://doi.org/10.1215/10407391-2419997</a>.
</li>
<li id="kirschenbaum2016">Kirschenbaum, M. (2016) “Am I a Digital Humanist? Confessions of a Neoliberal Tool” , _Medium_ . Available at:<a href="https://medium.com/@mkirschenbaum/am-i-a-digital-humanist-confessions-of-a-neoliberal-tool-1bc64caaa984">https://medium.com/@mkirschenbaum/am-i-a-digital-humanist-confessions-of-a-neoliberal-tool-1bc64caaa984</a>.
</li>
<li id="mandellnd">Mandell, L., et al. (n.d.) _The Poetess Archive_ . Available at:<a href="https://poetessarchive.org/">https://poetessarchive.org/</a>.
</li>
<li id="mcgann2001">McGann, J. (2001) _Radiant Textuality: Literature After the World Wide Web_ . New York: Palgrave Macmillan.
</li>
<li id="mcleod1996">McLeod, D. W. (1996) _Lesbian and Gay Liberation in Canada: A Selected Annotated Chronology, 1964-1975_ . Toronto: ECW Press/Homewood Books.
</li>
<li id="mcleod2017">McLeod, D. W. (2017) _Lesbian and Gay Liberation in Canada: a Selected Annotated Chronology, 1976-1981_ . Toronto: ECW Press/Homewood Books.
</li>
<li id="mcnaron">McNaron, T. and Miller, C. (n.d.) _Voices from the Gaps_ . Available at:<a href="https://hdl.handle.net/11299/164018">https://hdl.handle.net/11299/164018</a>.
</li>
<li id="brakearmstrongnd">Blake, L., Armstrong, I., et al. (n.d.) _Nineteenth-Century Serials Edition_ . Available at:<a href="https://ncse.ac.uk/">https://ncse.ac.uk/</a>.
</li>
<li id="rouedcunliffe2016">Roued-Cunliffe, H. (2016) “The Digital Future of Humanities through the Lens of DIY Culture” , _Digital Humanities Quarterly_ , 10(4).
</li>
<li id="russell2016">Russell, A. and Vinsel, L. (2016) “Innovation is overvalued. Maintenance often matters more” , _Aeon_ . Available at:<a href="https://aeon.co/essays/innovation-is-overvalued-maintenance-often-matters-more">https://aeon.co/essays/innovation-is-overvalued-maintenance-often-matters-more</a>.
</li>
<li id="endings">The Endings Project Team (n.d.) “Principles” . Available at:<a href="https://endings.uvic.ca/principles/">https://endings.uvic.ca/principles/</a>.
</li>
<li id="tough2021">Tough, F. (2021) “Métis Archival Project: 20 Years of Research and Rights” , in _Making the Net Work_ . _Canadian Society for Digital Humanities_ , Edmonton, Alberta. Available at:<a href="https://dh-abstracts.library.cmu.edu/works/10357">https://dh-abstracts.library.cmu.edu/works/10357</a>.
</li>
<li id="whitleynd">Whitley, E. (n.d.) _The Vault at Pfaff's_ . Available at:<a href="https://pfaffs.web.lehigh.edu/">https://pfaffs.web.lehigh.edu/</a>.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>This dismissal of the non-traditional scholarly output of digital humanities projects is distinct from the later dismissal of digital humanities scholars as cool kids who have undue access to funds. For more on these debates see Matthew Kirschenbaum’s “What Is &lsquo;Digital Humanities,&rsquo; and Why Are They Saying Such Terrible Things about It?” and “Am I a Digital Humanist? Confessions of a Neoliberal Tool” <a class="footnote-ref" href="#kirschenbaum2014"> [kirschenbaum2014] </a><a class="footnote-ref" href="#kirschenbaum2016"> [kirschenbaum2016] </a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Since I trained on the <em>Yellow Nineties</em> , which initially had two principal investigators, I cannot be surprised, on reflection, that the <em>Lesbian and Gay Liberation in Canada</em> project, which I co-direct with my research partner, Michelle Schwartz, also has two principal investigators, owes much of its structures and ways of working to the <em>Yellow Nineties Online</em> . I will refer to sole principal investigatorship below even though joint investigatorship is relatively common in Canadian digital humanities (see, for example, the investigatorship of Patricia Clements and Isobel Grundy on <em>Orlando</em> , Geoffrey Rockwell and Stéfan Sinclair on <em>Voyant</em> , and Ian Milligan, Nick Ruest, Jeremy Lin, and Jefferson Bailey on <em>Archives Unleashed</em> ).&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>European digital humanities scholars and others have made great strides in the creation of linked data that focuses on cultural material central to the humanities. Some notable projects, such as Social Networks and Archival Context Project (SNAC), originate in the United States. In Canada, where there is real new growth in cultural linked data creation in the digital humanities, libraries, and government. For more information see work by the Canadian Heritage Information Network, Linked Infrastructure for Networked Cultural Scholarship, and the Single Interface for Music Score Searching and Analysis.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>LGLC has been supported by two Social Science and Humanities Research Council of Canada Insight Grants (2014–20, 2021-25) and by the Ministry of Canadian Heritage’s Canada History Fund (2021-2023). Grant partners include Susan Brown director of the <em>Canadian Writing Research Collaboratory</em> ( <em>CWRC,</em> University of Guelph), Don McLeod (University of Toronto Libraries), El Chenier director of the <em>Archives of Lesbian Oral Testimony</em> ( <em>ALOT</em> , Simon Fraser University), Fabien Galipeau (Archives gaies du Québec), and Fangmin Wang and M.J. Suhonos (Toronto Metropolitan University Library &amp; Archives). The project has been built with the support of 16 paid research assistants since 2014. Their scholarship has included archival research, encoding, UX, data conversion, frontend design, and implementation. We are also grateful for the support of Toronto Metropolitan’s Centre for Digital Humanities, the Toronto Metropolitan Library Collaboratory, the University of Ottawa’s Labo de données en sciences humaines/Humanities Data Lab, the Canadian Foundation for Innovation, and Compute Canada (for more please see<a href="https://lglc.ca/about">https://lglc.ca/about</a>).&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Like many digital humanities scholars of my generation, I learned to write and process TEI in graduate school, but was enrolled in my PhD before most Canadian universities had a digital humanities course curriculum. My formal education in TEI creation and project development came from workshops offered through the <em>Women Writers Project</em> (now at Northeastern University), the Digital Humanities Summer Institute (DHSI, University of Victoria), and the Initiative for Digital Humanities, Media, and Culture (Texas A&amp;M). The <em>Yellow Nineties Online</em> and the Toronto Metropolitan University Centre for Digital Humanities funded my travel and registration fees for many of these workshops. I now teach TEI at the DHSI and in undergraduate classes. Not only is it a useful language for representing textual and visual sources, it helps me teach undergraduates how to think like editors and how to knit together primary and secondary sources in their analysis of text. While teaching others how to create and process XML in various formats likely appeals to the misguided neoliberalhard skillsapproach to higher education, it is in practice a key tool to empower students how to think about editing, research, analysis, and about how they can literally shape the systems that underpin our experience of technology.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p><a href="https://ncse.ac.uk/index.html">https://ncse.ac.uk/index.html</a>.## Bibliography&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Reference Rot in the Digital Humanities Literature: An Analysis of Citations Containing Website Links in DHQ</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000662/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="related" type="text/html" title="Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="related" type="text/html" title="Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="related" type="text/html" title="Follow the Money?: Funding and Digital Sustainability"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="related" type="text/html" title="From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction to Special Issue: Project Resiliency in the Digital Humanities"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000662/</id><author><name>Zach Coble</name></author><author><name>Jojo Karlin</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>The ubiquity of the web has dramatically transformed scholarly communication. The shift toward digital publishing has brought great advantages, including an increased speed of knowledge dissemination and a greater uptake in open scholarship. There is also an increasing range of scholarly material being communicated and referenced. References have expanded beyond books and articles to include a broad array of assets consulted or created during the research process, such as datasets, social media content like tweets and blogs, and digital exhibitions. There are, however, numerous challenges posed by the transition to a constantly evolving digital scholarly infrastructure. This paper examines one of those challenges: link rot, which serves as a way towards understanding its corollary, reference rot. Link rot is likely most familiar in the form of404 Not Founderror messages, but there are other less prominent obstacles to accessing web content. Our study examines instances of reference rot in <em>Digital Humanities Quarterly</em> articles and its impact on the ability to access the online content referenced in these articles after their publication. We also look at the extent to which article references rely on links in order to gain a more complete understanding of the threat posed.</p>
<p>This study provides an important step in assessing remediative actions as well as a broader examination of perceptions of cohesion and integrity in the digital humanities literature. As the Endings Project team mentions in their DH2019 paper,HTML is the most popular standard output for DH projects,meaning that websites continue to be a key mechanism for delivering digital humanities (DH) outputs<a class="footnote-ref" href="#arneil2019"> [arneil2019] </a>. The ongoing costs and resources required to maintain and repair web-based DH outputs is well known, as shown by efforts such as the Endings Project and the Socio-Technical Sustainability Roadmap<a class="footnote-ref" href="#sociotechnical"> [sociotechnical] </a><a class="footnote-ref" href="#ending2022"> [ending2022] </a>. Our research contributes to this area of knowledge from a particular angle: the impact on the stability of the DH scholarly record.</p>
<h2 id="literature-review">Literature Review</h2>
<p>Looking at the literature, we observe three main categories relevant to this article: theory of citation, evolving guidelines for proper citation, and studies of the practice of link preservation. Citation theory describes the continuous tug between the ideals of citation and the disciplinary administrative function of scholarly discourse<a class="footnote-ref" href="#zuckerman1987"> [zuckerman1987] </a>. Broadly speaking, a reference is a piece of information provided in a scholarly work that specifies the work of another person used in the creation of the former. A citation is a paraphrase, quotation or allusion to a source, a specific instance of a reference such as a paraphrase or quotation. The scholarly literature rests on the premise that citations and references exist to pay homage and give credit to prior work, to substantiate claims and maintain intellectual honesty, and to provide leads and background reading<a class="footnote-ref" href="#garfield1994"> [garfield1994] </a>. Consequently, if readers cannot access the referenced material, then they are unable to uphold these standards or corroborate the scholarly record. The arguments of individual articles are weakened, and the integrity of the scholarly literature is threatened. Recent efforts have contributed critical approaches to citation theory, such as citation justice, that seek to expand understanding of social systems of credit within academia<a class="footnote-ref" href="#knowledgeequity"> [knowledgeequity] </a>.</p>
<p>Hyperlinks are a critical component of scholarly discourse in the digital era, and in the late 1990s and early 2000s, we see researchers beginning to adapt citation guidelines to accommodate new online resources. Janice Walker created MLA-Style Citations of Electronic Sources for referencing emerging formats such as Telnet, listservs, and video games<a class="footnote-ref" href="#walker1995"> [walker1995] </a>, whereas Anita Greenhill and Gordon Fletcher sought to catalog citation recommendations in the World Wide Web Virtual Library<a class="footnote-ref" href="#greenhill2003"> [greenhill2003] </a>, and the Library of Congress’sLearning Pagedemonstrates the concern for capturing appropriate links. Across disciplines, citation guidelines have grown to accommodate, and hustled to keep up with, shifts in web practices. As of the 7th edition, the APA Handbook (<a href="#apa2020">2020</a>) offers examples for 27 types of electronic resources, from websites to Wikipedia to datasets to podcasts. This range of electronic resources points to the widening understanding of viable source materials as well as the complex set of standards that authors and stewards of scholarly output must reconcile.</p>
<p>In “Scholarly Context Not Found: One in Five Articles Suffers from Reference Rot,” <a class="footnote-ref" href="#klein2014"> [klein2014] </a>studied science, technology, and medicine articles to document the extent of reference rot, which they define as a combination of link rot and content drift. They define content drift as a resource changing or evolving over time, up to the point where it no longer reflects the originally referenced content. Attributing the lagging system of link preservation to the swift adoption of web-based scholarly communications, the expanding capacity to reference different types of things, and the challenge of bridging digital reference systems and paper-based communications, the authors call for robust solutions to ensure integrity of the web-based scholarly record. To Klein and co-authors, the integrity of the link maintains the context necessary to ensure sound scholarship, for “as references rot or as the content they originally referred to changes, it becomes impossible to revisit the intellectual context that surrounded the referencing article at the time of its publication” <a class="footnote-ref" href="#klein2014"> [klein2014] </a>.</p>
<p>Zhou et al.<a href="#zhou2015">2015</a>studied the persistence of web resource citations by developing a machine-learning model for assessing link rot in scholarly articles. They propose establishing a system of priority for archival preservation of links by proactively predicting links more prone to rot.<a class="footnote-ref" href="#brunelle2015"> [brunelle2015] </a>attempt to measure the impact of missing resources through web user experience interviews that evaluate how the loss of embedded resources affects user trust in archived websites. The Hiberlink and Robust Links projects have contributed valuable research framing the problem of reference rot in the scholarly literature. While their recommendations rely on a specific set of digital publishing tools that has not yet been widely adopted across the academy, the project has contributed a more sophisticated understanding of how link preservation requires attending not only to the ideals of citation and web maintenance best practices but also to the social expectations concerning who is responsible for these linkages<a class="footnote-ref" href="#robustify"> [robustify] </a>.</p>
<p>Our study joins these and others that have examined instances of link rot in the scholarly literature. Our aim here is not only to document the amount of link rot but also to understand the extent to which citations rely on links. To do so we also looked at the percentage of articles that contain links, the average number of links per article, and the percentage of citations that are links. Only two other studies to date have examined all of these topics together.<a class="footnote-ref" href="#aronsky2007"> [aronsky2007] </a>examines PubMed articles immediately after publication, and<a class="footnote-ref" href="#yang2010"> [yang2010] </a>provide a comprehensive study of Chinese humanities and social science journals. Several studies examine one or two of these topics, and are used in the Analysis section to contextualize our data and to understand how the DH literature compares to other disciplines.</p>
<h2 id="methodology">Methodology</h2>
<p>Our study examines the prevalence of websites listed as citations in <em>DHQ</em> articles and the status of those websites. <em>DHQ</em> is one of the most long-standing, well known journals within the field of digital humanities and is listed in the Directory of Open Access Journals as well as indexed in the Clarivate Analytics “Emerging Sources Citation Index” <a class="footnote-ref" href="#dhqabout"> [dhqabout] </a>. All types of articles were included in the analysis (e.g. Introductions, Articles, Reviews) as each article type consistently contained references. Our analysis examined only citations appearing in the Works Cited section and excluded citations in the Notes section as well as in-text links. When analyzing an individual link, we manually opened the link in a new browser tab, observed any changes in the URL as the page loaded, and once the page loaded (or not) placed it into one of seven categories. In a small number of cases, the link was correctly displayed but the HTML code contained a minor formatting error. We chose to follow the (correctly) displayed link, under the assumption that a reader interested in following the citation would do the same. Beyond this, we did not perform any additional searching to track down if a page had been relocated or archived, since the object of study is the link as it appears in the citation. The browser environments used for analysis were free of ad blockers and similar browser extensions, which can significantly alter how URLs and pages perform. The analysis was performed in the United States, and we acknowledge that results will likely differ depending on geographic location due to Internet Protocol (IP) address restrictions.</p>
<p>We examined articles published in <em>DHQ</em> from its inception in 2007 up to 2019. To make the data collection process more manageable, we used systematic sampling to determine which articles to analyze. Systematic sampling uses a fixed interval, and fits this particular dataset because the citations and links within the articles in <em>DHQ</em> are sufficiently normally distributed. This method ensures even representation of the characteristics of the articles published per year that we want to observe (i.e., number of citations, number of links and working status of the links), which was important in allowing us to reliably track trends over time<a class="footnote-ref" href="#hibberts2012"> [hibberts2012] </a>. Since the population size is known, we chose the sampling interval based on our desired confidence interval, 95%, and margin of error, 5%, for the proportion of citations that are links, assuming a variance of 25%. In order to achieve this, the target sample size would be 205 with a sampling interval of 0.47. We rounded up the sample interval to 0.50, meaning that we analyzed every other article (226 total), which slightly improves the margin of error to 4.55% while maintaining the 95% confidence interval.1 We decided that defining the population as the total number of articles, rather than total number of citations, would better foster future re-use of the data set, which is openly available online<a class="footnote-ref" href="#coble2021"> [coble2021] </a>.</p>
<p>Each citation that appeared as a link in the sample was labeled using one of seven categories:</p>
<p><em>Link resolves correctly</em> :</p>
<ol>
<li>Page exists2. Redirected, to the same page</li>
</ol>
<p><em>Link does not resolve correctly</em> :</p>
<ol start="3">
<li>Page exists, but is different4. Redirected, to same site5. Redirected, but page or site is different6. Page does not exist, site exists7. Page does not exist, site does not exist</li>
</ol>
<h2 id="1-page-exists">1. Page Exists</h2>
<p>The link resolves as expected and it resolves to a page with content that is clearly the cited source. This category includes Handles and DOIs, paywalled content with previews (e.g. <em>New York Times</em> ), and pages with SSL certificate issues that still resolve.</p>
<h2 id="2-redirected-to-the-same-page">2. Redirected, to the same page</h2>
<p>The link redirects automatically and takes you to a page with content that is clearly the cited source. It is important to note that, for all categories, determinations of whether a page is the <em>same</em> or <em>different</em> are based primarily on clues given in the citation — most notably the page title, creator, and similar URL structure. Some assumptions were made based on information available, and this is a potential source of error in the study.</p>
<h2 id="3-page-exists-but-is-different">3. Page exists, but is different</h2>
<p>The link resolves but the page content is obviously and significantly different from what was cited, such as web technologies that are no longer supported by browsers (e.g. Abode Flash).</p>
<h2 id="4-redirected-to-same-site">4. Redirected, to same site</h2>
<p>The link redirects, although the user is taken to a different page on the same top-level domain (typically the homepage) rather than the page specified in the citation. This outcome was common in cases where a site migration had occurred. Though this is not the most worrisome category, since the intended page often still exists and is findable with additional effort, technically speaking the link does not resolve correctly.</p>
<h2 id="5-redirected-but-page-or-site-is-different">5. Redirected, but page or site is different</h2>
<p>Redirected to a page or site that is obviously and significantly different from the cited source.</p>
<h2 id="6-page-does-not-exist-site-exists">6. Page does not exist, site exists</h2>
<p>The page no longer exists but the site it was part of still resolves. One challenge with our approach of differentiating a web page and a website is determining what exactly is the “site.” Practices can vary widely, particularly in citations of non-academic works, and we used discretion when it was obvious from contextual clues in the content and URL structure, otherwise we defaulted to using the top-level domain.</p>
<h2 id="7-page-does-not-exist-site-does-not-exist">7. Page does not exist, site does not exist</h2>
<p>Neither the page nor the site it was part of still resolves. This is the most worrying category, as there is effectively no original trace left of the cited source. Such pages might be captured in the Internet Archive or other web archives, but that outcome was outside the scope of this study.</p>
<h2 id="findings">Findings</h2>
<p>Summary of Sampled DataTotal articles analyzed (including articles without links)226Total articles analyzed (only articles with links)180Articles in sample without any citations containing links46Total citations analyzed (only links)1,924Total citations in sample (links &amp; non-links)6,934<br>
Table 1 provides general information about the sample. There were 226 total articles in the sample. Of these, 180 articles contained links and 46 articles did not contain any citations with links. There were 6,934 total citations in the sample (links and non-links) and 1,924 of those citations contained links.</p>




























<figure ><img loading="lazy" alt="Image of a bar chart in orange and blue. The blue bar shows citations per article and the orange links per citation." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     >
</figure>
<p>Figure 1 breaks down this information by year, where the first column (in blue) shows the average number of total references (links and non-links) contained in the sampled articles published that year. For instance, on average, an article published in 2007 contains twenty-three citations, which includes both references to print sources and links to websites. This data was collected using web scraping and it maps onto the primary axis (i.e., the y axis on the left, with the range 0 - 45). The second column (in yellow) shows the percentage of citations that are links for that year. For example, for all sampled articles published in 2007, 32% of the citations are links. Conversely, 68% of the citations point tonon-websitesources, such as print materials, interviews, and other types of media. This number is calculated by dividing the total number of citations that are links by the total number of citations overall (links and non-links), and it maps onto the secondary axis (i.e., the y axis on the right, with the range 0% - 100%).<br>
Totals for Link Status CategoriesPage exists1131 (58.8%)Redirected, to the same page197 (10.2%) <em>Total links that work correctly</em>  <em>1328 (69%)</em> Page exists, but is different37 (1.9%)Redirected, to same site53 (2.8%)Redirected, but page or site is different22 (1.1%)Page does not exist, site exists333 (17.3%)Pages does not exist, site does not exist151 (7.8%) <em>Total links that do not work correctly</em>  <em>596 (31%)</em><br>
Table 2 provides totals for the link status categories analyzed in the sample. Figure 2 visualizes this data, where each column is one year and contains the total percentage for each category, represented by color. The total number of sampled citations analyzed each year is given at the top of each bar. The sections in blue represent links that work correctly (i.e., the link resolves to the cited source). The sections in green represent links that do not work correctly (i.e., the link does not resolve to the cited source). While the data is not entirely uniform — for instance, there are only nine citations in the sample for 2008 — a clear trend is observable where over time it becomes increasingly likely that a link will not resolve correctly.</p>




























<figure ><img loading="lazy" alt="Image of a bar chart in shades of green and blue." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     >
</figure>
<h2 id="analysis">Analysis</h2>
<p>Percentage of links in citations that do not resolve <em>Field</em>  <em>Link Source</em>  <em>Years</em>  <em>N</em> Journalism &amp; CommunicationURLs contained in citations in 5 journals<a class="footnote-ref" href="#dimitrova2007"> [dimitrova2007] </a>2000-200339%Library &amp; Information ScienceOnline resources cited in 4 journals<a class="footnote-ref" href="#sadatmoosavi2012"> [sadatmoosavi2012] </a>2005-200836%Digital HumanitiesWorks cited containing links in <em>Digital Humanities Quarterly</em> 1997-201931%NursingLinks in citations from 20 journals<a class="footnote-ref" href="#oermann2008"> [oermann2008] </a>2004-200528%Science, Technology, &amp; MedicineURLs in references in 3 databases<a class="footnote-ref" href="#klein2014"> [klein2014] </a>1997-201213-22%PubMedInternet references in bibliographies<a class="footnote-ref" href="#aronsky2007"> [aronsky2007] </a>200612%<br>
We know that link rot exists on the web, and Figure 2 demonstrates that there is something significant at stake as it relates to the integrity of the DH literature. Within the sample, there are 596 works cited that are links that do not work correctly. This count means that 31% of citations containing links, and 8.7% of all sampled citations, including non-link citations, no longer work correctly. Conversely, 69% of links still resolve to the cited source.</p>
<p>These numbers become more troubling when compared to other disciplines. Table 3 compares our data to other studies examining links that appear in references or works cited section and reveals that <em>DHQ</em> has a comparable and relatively high percentage of link rot. Since we looked only at the works cited section, we excluded comparison studies that analyzed links in other areas, such as abstracts or entire articles.<br>
Percentage of articles that contain links <em>Field</em>  <em>Link Source</em>  <em>Years</em>  <em>N</em> Humanities and Social SciencesCitation links from articles in the Chinese Social Sciences Index<a class="footnote-ref" href="#yang2010"> [yang2010] </a>1998-200782%Library &amp; Information ScienceURLs in references from 9 journals<a class="footnote-ref" href="#veena2008"> [veena2008] </a>2000-200681%Digital HumanitiesWorks cited containing links in <em>Digital Humanities Quarterly</em> 1997-201980%ScienceLinks in citations from 3 high impact journals<a class="footnote-ref" href="#dellavale2003"> [dellavale2003] </a>200330%PubMedInternet references in bibliographies<a class="footnote-ref" href="#aronsky2007"> [aronsky2007] </a>20069%<br>
Compounding the threat of link rot is the extent to which references in the DH literature rely on internet resources. According to sampled data, 80% of articles in <em>DHQ</em> contain at least one reference with a URL. As Table 4 indicates, this percentage is relatively high compared to other fields where data is available. Additionally, Table 5 shows that <em>DHQ</em> articles contain an average of 8.5 links per article, which is significantly higher compared to other disciplines. This suggests that the problem of link rot is spread across a high proportion of articles. The higher frequency of links as citations indicates a greater reliance on links compared to other fields.<br>
Average number of links per article <em>Field</em>  <em>Link Source</em>  <em>Years</em>  <em>N</em> Digital HumanitiesWorks cited containing links in <em>Digital Humanities Quarterly</em> 1997-20198.5HistoryLinks in articles from 2 journals<a class="footnote-ref" href="#russell2008"> [russell2008] </a>1999-20063.9NursingLinks in citations from 20 journals<a class="footnote-ref" href="#oermann2008"> [oermann2008] </a>2004-20053.1EcologyCitation to material on the internet<a class="footnote-ref" href="#duda2008"> [duda2008] </a>1997-20052.0Computer science &amp; engineeringArticles containing URLs in 2 journal databases<a class="footnote-ref" href="#spinellis2003"> [spinellis2003] </a>1995-19991.7Humanities and Social SciencesCitation links from articles in the Chinese Social Sciences Index<a class="footnote-ref" href="#yang2010"> [yang2010] </a>1998-20070.37PubMedInternet references in bibliographies<a class="footnote-ref" href="#aronsky2007"> [aronsky2007] </a>20060.18<br>
Overall, 27% of sampled citations in <em>DHQ</em> are links. Table 6 shows that <em>DHQ</em> ranks high among studies that calculate the percentage of citations that contain links; only library and information science contain more (44%). This figure shows that, more than most disciplines, the DH literature relies heavily on links.<br>
Percentage of citations that are links <em>Field</em>  <em>Link Source</em>  <em>Years</em>  <em>N</em> Library &amp; Information ScienceURLs in references from 9 journals<a class="footnote-ref" href="#veena2008"> [veena2008] </a>2000-200644%Digital HumanitiesWorks cited containing links in <em>Digital Humanities Quarterly</em> 1997-201927%Humanities and Social SciencesCitation links from articles in the Chinese Social Sciences Index<a class="footnote-ref" href="#yang2010"> [yang2010] </a>1998-20073.60%ScienceLinks in citations from 3 high impact journals<a class="footnote-ref" href="#dellavale2003"> [dellavale2003] </a>20032.60%PubMedInternet references in bibliographies<a class="footnote-ref" href="#aronsky2007"> [aronsky2007] </a>20060.60%<br>
There are some caveats to our findings. For instance, even if a link does not work, the page might still exist at a different link. The web is fluid, and our study is only a snapshot of a particular moment from a particular geographic location. Also, a broken link does not necessarily mean a non-existent page. A simple search could reveal the new URL, a site may only be temporarily unavailable, or it might be available in the Internet Archive or another web archive. A study of library and information science literature found that employing these two strategies decreased the rate of inaccessible URLs from 36% to 5%<a class="footnote-ref" href="#sadatmoosavi2012"> [sadatmoosavi2012] </a>.</p>
<h2 id="discussion">Discussion</h2>
<p>Our data shows that a significant number of works cited no longer exist, are inaccessible, or have additional barriers to access. Instances of link rot increase with time. Additionally, there is a higher frequency and higher proportion of links contained in <em>DHQ</em> articles, showing that internet resources are a critical part of the DH literature. Taken together, the combined result is a persistent and cumulative threat to the integrity and stability of the DH literature, and one that is even more alarming when compared to other disciplines.</p>
<p>Just as there are multiple causes of link rot, there is no single or simple solution to this threat. Here we revisit the three categories presented in the literature review to use as a framework for discussion: theory of citation, evolving guidelines for proper citation, and studies of the practice of link preservation. We focus on recent initiatives as well as overlooked aspects that we believe are worth greater attention.</p>
<p>The area of citation theory has much potential for reframing our understanding of the problem. Many technical solutions have been proffered, but after almost three decades the problem of link rot is as persistent as ever and there has not yet emerged a convincing full-scale solution. Thus, perhaps we need new lenses through which to view this phenomenon. For instance, it may be worth revisiting the broad assumption that scholarly literature should be accessible for the long term. Put differently, are there wider epistemological shifts or perceptions toward academic systems of credit that are being reflected in our commitment to widening the scope of verifiable sources?</p>
<p>In <em>Digital Diaspora: A Race for Cyberspace</em> <a class="footnote-ref" href="#everett2009"> [everett2009] </a>, Anna Everett lays out the critical ways a Black digital public sphere developed parallel to the white, masculinist domain of the early Internet. Kelly Baker Josephs and Roopika Risam continue this thread in their introduction to <em>Digital Black Atlantic</em> <a class="footnote-ref" href="#josephs2021"> [josephs2021] </a>and work to name these digital spaces of resistance. Josephs and Risam, in pursuit of the objective “to create a provisional space and framework for academic conversation that could emerge by virtue of acts of citational and conceptual juxtaposition,” gesture toward alternative acts of scholarly activation. Current pedagogies of writing also point to a shifting sense of how to cite sources. In “Web Writing and Citation: The Authority of Communities,” <a class="footnote-ref" href="#switaj2015"> [switaj2015] </a>, Elizabeth Switaj lists the variations on retweet (RT), modified tweet (MT), via, and hat-tip (h/t) that indicate a move on social media to gestural citation, its paths to conversation, and its social system of credit.</p>
<p>The second area, guidelines for citation, has the potential for incremental improvements to the health of the scholarly record. For authors, Sadat-Moosavi et al.<a href="#sadatmoosavi2012">2012</a>suggest best practices for constructing links, such as citing documents in repositories (which typically use persistent identifiers) rather than private for-profit platforms such as Academia.edu and ResearchGate. When available, using persistent identifiers is a key practice. Of the 108 DOI links in our data, 107 resolved correctly (99.1%). Some publishers use DOIs in the URL string (e.g.<a href="https://onlinelibrary.wiley.com/doi/10.1002/9781118680605.ch23">https://onlinelibrary.wiley.com/doi/10.1002/9781118680605.ch23</a>) but such links are not persistent (i.e. the persistent link is<a href="https://doi.org/10.1002/9781118680605.ch23">https://doi.org/10.1002/9781118680605.ch23</a>). Seemingly minor details make a difference, and ideally such strategies would be more widely incorporated into citation manuals in an effort to provide authoritative guidance to researchers.</p>
<p>There are a number of approaches to the third area, the practice of link preservation. Building on Aronsky et al.<a href="#aronsky2007">2007</a>finding that 12% of links in PubMed were already broken two days after publication, journals should incorporate link-checking as a regular part of the editorial process. Further, scanning all article links on a regular basis would make this work more manageable for journals and also help to identify patterns or issues specific to their field. Another option would be to implement measures such as those of the <em>Review Journal of the IDE</em> , which also requires authors to use the Internet Archive’sSave Page Nowservice<a class="footnote-ref" href="#ride"> [ride] </a>for referenced links. This helps ensure that a record exists of the site as it was originally referenced, which Jones et al.<a href="#jones2021">2021</a>identify as a core issue but one that is not inherently guaranteed by web archiving services such as the Internet Archive, Archive-It, or Conifer. The on-demand service Perma.cc was specifically designed to address reference rot by generating permanent links to affix web citations used in publishing<a class="footnote-ref" href="#permacc"> [permacc] </a>. Perma.cc comes the closest to providing a turnkey solution, although its approach is to replace the original resource with a replica. Each of these web archiving strategies show different approaches that can be employed by journals, although it is worth noting that they rely on external service providers.</p>
<p>Finally, there are several recent initiatives providing resources for website creators and maintainers as well as a growing general awareness of the labor and craft required to build and sustain web-based DH outputs. Page-level redirects, or URL forwarding, is a proven and established technique for ensuring that links resolve correctly, and is particularly important when migrating a site or performing other updates that alter the URL structure of references. Best practices for this are thoughtfully articulated in Guidelines for Preserving New Forms of Scholarship<a class="footnote-ref" href="#greenberg2021"> [greenberg2021] </a>.</p>
<p>More broadly, the Socio-Technical Sustainability Roadmap gives a practical framework and holistic approach for the range of work involved in the entire lifecycle of a project<a class="footnote-ref" href="#sociotechnical"> [sociotechnical] </a>. And the Endings Project has produced a valuable set of tools, principles, and body of knowledge that advances our ability to create “accessible, stable, long-lasting resources in the humanities” <a class="footnote-ref" href="#ending2022"> [ending2022] </a>. Additionally,<a class="footnote-ref" href="#minimalNd"> [minimalNd] </a>provides an ethos that undergirds this work, and tools like Wax directly put these principles into practice by generating static sites<a class="footnote-ref" href="#minimalNd"> [minimalNd] </a><a class="footnote-ref" href="#nyrop2021"> [nyrop2021] </a>. None of these will inherently ensure long-term access to websites, and it is crucial to acknowledge that all require real and sustained institutional investments in staff and technical resources (see the articles by Otis and Cummings in this issue). However, there is some room for optimism given the overlap and shared history between DH and scholarly communication<a class="footnote-ref" href="#coble2014"> [coble2014] </a>. The practitioners of the latter, who share a keen interest in the stewardship of the scholarly record and have already taken great strides to address this phenomenon, are well positioned in terms of expertise and resources to continue these efforts. Taken together, they constitute an engaged community bringing necessary advancements to digital scholarly infrastructure.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Scholarly discourse depends on the practice of referencing sources. Our study shows that over a quarter of sampled citations are links to websites. Over 30% of these references are inaccessible or have additional access barriers. When compared to other fields, articles in <em>DHQ</em> contain the highest number of links per article, a high proportion of citations that are links, and a high proportion of articles that contain links. This problem is persistent and gets worse over time, creating a significant threat to the stability and integrity of the DH literature.</p>
<p>Even when we acknowledge that link rot and content drift present a risk to the DH literature, it is worth exploring to what extent this is a problem. It is unwise to simply assert that all websites should be accessible forever. Rather, within the context of scholarly literature, we should consider what criteria or considerations would be helpful to better understand which sites require longer term access. Preserving the record of a resource does not inherently preserve access to that resource, and understanding the social expectations of citation practice within a given field should be taken into account as DH citations are created. Maintaining access to websites is different from maintaining links to those websites, and it is always worth emphasizing that implementing such approaches at scale requires significant investments of labor and resources from institutional coalitions of publishers, libraries, and archives.</p>
<h2 id="notes">Notes</h2>
<p>Three main characteristics were observed in our analysis: number of citations per article, percentage of citations that are links and percent of links that work. Our sample size was chosen to ensure confidence about the percentage of citations that were links and we observed the status of all of those. Given the observed standard deviations of our sample characteristics we are able to calculate the margin of error for a 95% and a 99% confidence interval. The results are presented on the following table:</p>
<p>Citation data statisticsLinks per articlePercent citations that are linksPercent of links that workMean8.528%69%Standard Deviation11.324%29%Sample size226213<em>180**Population438438438Margin of error (95% confidence interval)1.473%4%Margin of error (99% confidence interval)1.934%5%</em> For this we only consider papers that have citations** For this we only consider the papers where at least one citation is a link</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>The authors give thanks to Luiza Nassif Pires.</p>
<h2 id="bibliography">Bibliography</h2>
<ul>
<li id="apa2020">American Psychological Association. (2020). Publication manual of the American Psychological Association 2020: the official guide to APA style (7th ed.). American Psychological Association.
</li>
<li id="arneil2019">Arneil et al. (2019) “Project Endings: Early Impressions from Our Recent Survey On Project Longevity In DH”  _DH2019_ , Utrecht, Netherlands. Available at:<a href="https://doi.org/10.34894/SIKOBN">https://doi.org/10.34894/SIKOBN</a>.
</li>
<li id="aronsky2007">Aronsky, D., Madani, S., Carnevale, R. J., et al. (2007) “The prevalence and inaccessibility of Internet references in the biomedical literature at the time of publication” , _Journal of the American Medical Informatics Association_ , 14(2), pp. 232–234. Available at:<a href="https://doi.org/10.1197/jamia.M2243">https://doi.org/10.1197/jamia.M2243</a>.
</li>
<li id="brunelle2015">Brunelle, J. F., Kelly, M., SalahEldeen, H. et al. (2015) “Not all mementos are created equal: measuring the impact of missing resources” , _International Journal on Digital Libraries_ , 16, pp. 283–301. Available at:<a href="https://doi.org/10.1007/s00799-015-0150-6">https://doi.org/10.1007/s00799-015-0150-6</a>.
</li>
<li id="burnhill2015">Burnhill, P., Mewissen, M., & Wincewicz, R. (2015) “Reference rot in scholarly statement: threat and remedy” , _Insights_ , 28:2, 55–61. Available at:<a href="http://doi.org/10.1629/uksg.237">http://doi.org/10.1629/uksg.237</a>.
</li>
<li id="coble2014">Coble, Z., Potvin, S., and Shirazi, R. (2014) “Process as Product: Scholarly Communication Experiments in the Digital Humanities” , _Journal of Librarianship and Scholarly Communication_ , 2:3. Available at:<a href="https://doi.org/10.7710/2162-3309.1137">https://doi.org/10.7710/2162-3309.1137</a>.
</li>
<li id="coble2021">Coble, Z and Karlin, K. (2021) “Reference Rot in the DH Literature” . Available at:<a href="https://github.com/nyu-dss/dh-citation-links">https://github.com/nyu-dss/dh-citation-links</a>.
</li>
<li id="dellavale2003">Dellavalle, R. P., Hester, E. J., Heilig, L. F., et al. (2003) “Going, Going, Gone: Lost Internet References” , _Science_ , 302:5646, 787-788. Available at:<a href="https://doi.org/10.1126/science.1088234">https://doi.org/10.1126/science.1088234</a>.
</li>
<li id="dimitrova2007">Dimitrova, D. V. and Bugeja, M. (2007) “The half-life of internet references cited in communication journals” , _New Media & Society_ , 9:5, 811–826. Available at:<a href="https://doi.org/10.1177/1461444807081226">https://doi.org/10.1177/1461444807081226</a>.
</li>
<li id="dhqabout"> _Digital Humanities Quarterly_ , “About” . The Alliance of Digital Humanities Organizations and The Association for Computers and the Humanities. Available at:<a href="http://digitalhumanities.org/dhq/about/about.html">http://digitalhumanities.org/dhq/about/about.html</a>.
</li>
<li id="duda2008">Duda, J. J., and Camp, R. J. (2008) “Ecology in the information age: patterns of use and attrition rates of internet-based citations in ESA journals, 1997–2005” , _Frontiers in Ecology and the Environment_ , 6(3), pp. 145–151. Available at:<a href="https://doi.org/10.1890/070022">https://doi.org/10.1890/070022</a>.
</li>
<li id="ending2022"> “The Endings Project” , University of Victoria, 2022. Available at:<a href="https://endings.uvic.ca/about.html">https://endings.uvic.ca/about.html</a>.
</li>
<li id="everett2009">Everett, A., (2009) _Digital Diaspora_ . Albany, NY: State University of New York Press.
</li>
<li id="garfield1994">Garfield, E. (1994) “When to Cite” , _Library Quarterly_ , 66(4), pp. 449–58.
</li>
<li id="greenberg2021">Greenberg, J., Hanson, K., & Verhoff, D. (2021) “Guidelines for Preserving New Forms of Scholarship” , _NYU Libraries_ . Available at:<a href="https://doi.org/10.33682/221c-b2xj">https://doi.org/10.33682/221c-b2xj</a>and<a href="https://preservingnewforms.dlib.nyu.edu/guidelines">https://preservingnewforms.dlib.nyu.edu/guidelines</a>.
</li>
<li id="greenhill2003">Greenhill, A., and Fletcher, G. (eds.) (2003) “Electronic References & Scholarly Citations of Internet Sources” , _The World-Wide Web Virtual Library_ . Available at:<a href="http://www.spaceless.com/WWWVL/">http://www.spaceless.com/WWWVL/</a>.
</li>
<li id="hibberts2012">Hibberts M., Burke Johnson R., and Hudson K. (2012) “Common Survey Sampling Techniques” In L. Gideon (ed.), _Handbook of Survey Methodology for the Social Sciences_ . New York, pp. 53–74. Available at:<a href="https://doi.org/10.1007/978-1-4614-3876-2_5">https://doi.org/10.1007/978-1-4614-3876-2_5</a>.
</li>
<li id="jones2021">Jones, S. M., Klein, M., Sompel, H. V. D. (2021) “Robustifying Links To Combat Reference Rot” , _Code4Lib_ , 50. Available at:<a href="https://journal.code4lib.org/articles/15509">https://journal.code4lib.org/articles/15509</a>.
</li>
<li id="josephs2021">Josephs, K. B., and Risam, R. (eds.) (2021) _Digital Black Atlantic_ . Minneapolis: University of Minnesota Press. Available at:<a href="https://doi.org/10.5749/9781452965321">https://doi.org/10.5749/9781452965321</a>.
</li>
<li id="klein2014">Klein M, Van de Sompel H, Sanderson R, et al. (2014) “Scholarly Context Not Found: One in Five Articles Suffers from Reference Rot” , _PLoS ONE_ 9(12), e115253. Available at:<a href="https://doi.org/10.1371/journal.pone.0115253">https://doi.org/10.1371/journal.pone.0115253</a>.
</li>
<li id="knowledgeequity"> “Knowledge Equity Lab” University of Toronto Scarborough. Available at:<a href="https://knowledgeequitylab.ca/">https://knowledgeequitylab.ca/</a>.
</li>
<li id="minimalNd"> “Minimal Computing” , Global Outlook::Digital Humanities. Available at:<a href="https://go-dh.github.io/mincomp/">https://go-dh.github.io/mincomp/</a>.
</li>
<li id="nyrop2021">Nyröp, M. “What is Wax?” Available at:<a href="https://minicomp.github.io/wax/about/">https://minicomp.github.io/wax/about/</a>.
</li>
<li id="oermann2008">Oermann, M. H., Nordstrom, C. K., Ineson, V., and Wilmes, N. A. (2008) “Web Citations in the Nursing Literature: How Accurate Are They?”  _Journal of Professional Nursing_ , 24(6), pp. 347–351. Available at:<a href="https://doi.org/10.1016/j.profnurs.2007.12.004">https://doi.org/10.1016/j.profnurs.2007.12.004</a>.
</li>
<li id="permacc"> “Perma.cc”  _Harvard Library Innovation Lab_ . Available at:<a href="https://perma.cc/">https://perma.cc/</a>.
</li>
<li id="ride">Review Journal of the IDE. “Writing Guidelines” , _Institute for Documentology and Scholarly Editing_ . Available at:<a href="https://ride.i-d-e.de/reviewers/writing-guidelines/#links">https://ride.i-d-e.de/reviewers/writing-guidelines/#links</a>.
</li>
<li id="robustify"> “Make Your Links Robust” , _Memento Project_ . Available at:<a href="https://robustlinks.mementoweb.org/">https://robustlinks.mementoweb.org/</a>.
</li>
<li id="russell2008">Russell, E., & Kane, J. (2008) “The Missing Link: Assessing the Reliability of Internet Citations in History Journals” , _Technology and Culture_ , 49(2), pp. 420–429. Available at:<a href="https://doi.org/10.1353/tech.0.0028">https://doi.org/10.1353/tech.0.0028</a>.
</li>
<li id="sadatmoosavi2012">Sadat-Moosavi A., Isfandyari-Moghaddam A., and Tajeddini O. (2012) “Accessibility of online resources cited in scholarly LIS journals: A study of emerald ISI-ranked journals” , _Aslib Proceedings_ , 64(2), pp. 178–192.
</li>
<li id="sociotechnical">Visual Media Workshop at the University of Pittsburgh. “The Socio-Technical Sustainability Roadmap” . Available at:<a href="http://sustainingdh.net/">http://sustainingdh.net</a>.
</li>
<li id="spinellis2003">Spinellis, D. (2003) “The decay and failures of web references” , _Communications of the ACM_ , 46(1), pp. 71–77. Available at:<a href="https://doi.org/10.1145/602421.602422">https://doi.org/10.1145/602421.602422</a>.
</li>
<li id="switaj2015">Switaj, Elizabeth. (2015) “Web Writing and Citation: The Authority of Communities” In Dougherty, J and O'Donnell T (eds.), _Web Writing: Why and How for Liberal Arts Teaching and Learning_ . Ann Arbor: University of Michigan Press, pp. 223–32. Available at:<a href="https://doi.org/10.2307/j.ctv65sxgk.24">https://doi.org/10.2307/j.ctv65sxgk.24</a>.
</li>
<li id="veena2008">Veena, SVR and Sampath Kumar, B. T. (2008) “Web citation behaviour in scholarly electronic journals in the field of library and information science” , _Webology_ , 5(2). Available at:<a href="https://www.webology.org/data-cms/articles/20200515041147pma57.pdf">https://www.webology.org/data-cms/articles/20200515041147pma57.pdf</a>.
</li>
<li id="walker1995">Walker, J. R. (1995) “MLA-Style Citations of Electronic Sources” Ver.1.0. Cited in: Harnack, A and G. Kleppinger. (1996) K A I R O S: 1.2. Kairos.technorhetoric.net. Available at:<a href="https://kairos.technorhetoric.net/1.2/binder.html?inbox/mla.html">https://kairos.technorhetoric.net/1.2/binder.html?inbox/mla.html</a>.
</li>
<li id="yang2010">Yang, S., Qiu, J. and Xiong, Z. (2010) “An Empirical Study on the Utilization of Web Academic Resources in Humanities and Social Sciences Based on Web Citations” , _Scientometrics_ , 84, pp. 1–19. Available at:<a href="https://doi.org/10.1007/s11192-009-0142-7">https://doi.org/10.1007/s11192-009-0142-7</a>.
</li>
<li id="zhou2015">Zhou, K, Grover, C, Klein, M, and Tobin, R. (2015) “No More 404s: Predicting Referenced Link Rot in Scholarly Articles for Pro-Active Archiving” , _JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries_ , New York, pp. 233–236. Available at:<a href="https://doi.org/10.1145/2756406.2756940">https://doi.org/10.1145/2756406.2756940</a>.
</li>
<li id="zuckerman1987">Zuckerman, H. (1987) “Citation analysis and the complex problem of intellectual influence” , _Scientometrics_ , 12(5), pp. 329–38.
</li>
</ul>
]]></content></entry><entry><title type="html">The Dangers of Disappearance, the Opportunities of Recovery</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000670/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="related" type="text/html" title="Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="related" type="text/html" title="Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="related" type="text/html" title="Follow the Money?: Funding and Digital Sustainability"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="related" type="text/html" title="From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction to Special Issue: Project Resiliency in the Digital Humanities"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000670/</id><author><name>Sara Diamond</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>This essay considers two archives and their traces: the Banff New Media Institute (BNMI) and the Daniel Langlois Foundation (DLF). Both archives are the product of transitory but significant initiatives in the media arts and digital media context. Both suffered unanticipated project endings due to institutional and human agency and are now in varying stages of recovery and rediscovery. A third personal artistic, cultural, and social history collection – the Sara Diamond Fonds – seeks lessons from the endings of those first two archives; administrators of this third archive at the Christa Dahl Media Library and Archives and Simon Fraser University have developed a dynamic partnership strategy to prevent the same issues that resulted in the disappearance of the BNMI and DLF archives.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> In the instances of the BNMI and DLF, disappearance has meant the removal from public access. Disappearance has a second meaning in the context of digital media whether online or platform (such as CDs, DVDs). As Grau, Hoth, and Wandl-Vogt (<a href="#grau">2019</a>) stress: “Due to lack of institutional support and rapid changes in storage and presentation media, works that originated ten years ago can no longer be recovered technically for exhibition or preservation purposes” <a class="footnote-ref" href="#grau2019"> [grau2019] </a>. Giselle Beiguelman further asks, “How to deal in the field of preservation and conservation with files that disappear, works that stop functioning, services that vanish from one day to the next<a class="footnote-ref" href="#beiguelman2019"> [beiguelman2019] </a>? Media art works and Internet art rely on connections to databases, links, and third-party servers and services. Moreover, many works are interactive and contributor-driven so there is no easy beginning and end and often exist in many versions. Both interpretations of disappearance address the challenge that, as Sue Breakell suggests, “the records do not simply go through a life cycle from creation and currency through to interactivity and the archive but move in and out of currency” <a class="footnote-ref" href="#breakell2008"> [breakell2008] </a>. This is in part an argument to sustain institutional archives that mark a specific time period and to exert best practices such as emulation in preserving digital materials and licensing to allow the use of copyrighted materials. It is also an argument for the creators of collections, whether inside institutions (BNMI), or as alternative archives (DLF, CDMLA), to negotiate clear accessioning and deaccessioning relationships with their own institution (The Banff Centre) or potential partner institutions (DLF, CDMLA) early in the process of creating or acquiring an archive, or as soon as there is a perceived sense of the significance of that collection, whether within the institution and/or the stakeholders that it serves.</p>
<p>The period of the late 1990s through the early twenty-first century was one of intense interest in archives on the part of institutions, governments, curators, and artists, and coincides with the creation of the BNMI and the DLF documentation centre. Theallureof the archive, as Sue Breakell (<a href="#breakell2015">2015</a>) notes, was sparked by a heightened engagement with memory and the emergence of memory technologies (such as databases, hard drives, and centralized server storage). The drive to digitize meant that some records would be left behind, fueling concerns about inclusion, and about who should have the right to choose which materials would be digitized. The massive production of online materials seemed to some to be a gift towards a universal human memory; to others, “the more absolute knowledge on the Internet becomes, the harder it is to comprehend as it [knowledge] transforms into an unreadable amount of data” <a class="footnote-ref" href="#hoth2021"> [hoth2021] </a>.</p>
<p>Post-modernism challenged the authoritative nature of historical records and archives, in part instigated by Michel Foucault’s (<a href="#foucault1969">1969</a>) analysis of archives as a demonstration of relationships and institutions in process, perpetually incomplete repositories that represent power, through what is present and absent in their contents. Jacques Derrida in Archive Fever: A Freudian Impression, argues for the political nature of the archive, observing that power resides in control over its content and access. Anticipating the rise of the Internet and digital preservation, he astutely described a contemporary obsession with archives and the desire to preserve. He painted a tension between the public domain and personal memory materials that plays out today, for example, in debates about the right to be forgotten,<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> or the ways that social media intermingle personal and institutional commentary and politics, or the growing interface between personal health data collection and medical records. In An Archival Impulse (<a href="#foster2004">2004</a>), Hal Foster recognizes the archival turn and analyzes three kinds of artists’ works: those that use archival content, those where the artist performs methods drawn from archival practices, and those in which artists create unique archives. Powerful works have occurred when archivists invite artists into collections to create new interpretations. The Artist-in-Residency Program at the City of Portland Archives and Record Centre supported Portland Archives artists-in-residence Garrick Imatini and Kaia Sand. They interviewed selected subjects who were documented in the city’s Police Bureau’s surveillance fonds of 576 activists, augmenting the police fonds with “lives embedded, yet silenced, in the records” , resulting in a new understanding of that history and the expungement of criminal records<a class="footnote-ref" href="#carbone2015"> [carbone2015] </a>. Antonio Muntadas’ The File Room is at the same time both an emulation and critique of archival practices and an archive in its own right. It is a project intentionally without an ending, a travelling installation of physical archival files and a connected and collectively created and ongoing database of instances of censorship–political, cultural, and scientific.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> The historical context provides a framework for motivations and activities at the core of the three case studies that follow.</p>
<p>Archives and archivists have various standards to guide them in considering which collections to acquire, the methods of accessioning collections and conditions to deaccession collections. The Canadian Council of Archives (<a href="#cca2018">CCA, 2018</a>) describes accessioning as, “… the physical and legal addition of predominantly unpublished documentary material to an archival repository’s holdings. It follows an archival appraisal decision identifying the records as having enduring value in relation to the acquisition mandate and policies of the repository.” <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> The Society of American Archivists (SAS) provides terms, process and considerations for deaccessioning<a class="footnote-ref" href="#society2017"> [society2017] </a>. Deaccessioning represents the removal of materials from an archive and is perceived by most archives to be a component of best practices, but it is understandably controversial. SAS argues that policy and guidelines are needed, with clear options for the materials deaccessioned. Decisions should be made by archivists, the archive, and its home institution. Processes need to be transparent, properly documented, and overseen in an ethical manner. The SAS suggests that deeds of gift should include clear deaccessioning terms. Reasons for deaccessioning materials include reappraisal of a collection’s relevance to institutional mandate, frequency of use, its potential research value, whether it would be more meaningful and better used in a different repository, its condition, and maintenance costs. Other considerations include the ability to define provenance, or legal requirements to retain documents over time periods. Archives ideally seek a transfer of fonds to a different repository. They may return materials to original owners, or they may sell the collection or, ultimately, destroy the records. These routes are relevant for the case studies considered below.</p>
<p>Also relevant are increased options in collections management and permissions, given the rise of digitization and the acquisition of creative media works. The British Archive for Contemporary Writing has adopted two complementary practices, the creation of astorehouseand acollection.The first is the short-term loan of writers’ archives to support thematic archival research, for example for six months rather than the 20 years minimum required by most archives<a class="footnote-ref" href="#whibley2019"> [whibley2019] </a>. The goal is that emerging writers will see BACW as a trusted agent, and that writers will provide their archives to the collection as their careers mature<a class="footnote-ref" href="#eastanglia2022"> [eastanglia2022] </a>. Licensing is an alternative todepositas it allows multiple institutions to hold digital materials and retains the originator’s copyright. For example, with a deposit license, such as that of the Oxford University Research Archive (<a href="#ora2014">ORA, 2014</a>), the intellectual property creator retains their rights and can continue to license it and earn revenue and agrees to grant the University a non-exclusive, sub-licensable, worldwide license to store and access the work to the public.</p>
<p>The last decades have witnessed continued dialogue within the archival community and between communities and archivists that shift archival best practices in relation to Indigenous records and records of other vulnerable groups. This includes replevin, or repatriating holdings to Indigenous groups at their request, or the renegotiation of ownership and access with Indigenous peoples for archives remaining in collections. Call 70 of Canada’s Truth and Reconciliation Commission requires the inclusion of Indigenous recordkeepers and researchers, their perspectives, and their methodologies within the Canadian archival system. Critical archival studies foster archival practices that resist reinforcing oppression based on race, class, gender, sexuality, and ability. Instead, the goal is to develop inclusive, accessible, multivocal sites for cultural participation and dissemination<a class="footnote-ref" href="#caswell2019"> [caswell2019] </a>.</p>
<h2 id="the-case-studies">The Case Studies</h2>
<h2 id="the-banff-new-media-institute">The Banff New Media Institute</h2>
<p>The Banff New Media Institute (BNMI) ran from 1995 to 2010 at The Banff Centre (TBC) in Alberta, Canada, on the heels of the centre’s early history of virtual reality and new media research. It was an international think tank on the present and future practices of new media, with leaders engaged in developing the science and technologies, creative and design practices, jurisprudence, business models, and theories; it was also a training hub and business incubator, with three research labs and a co-production program. BNMI staff curated exhibitions and events both at the Walter Phillips Gallery on site and abroad.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> Over the course of its first ten years, it held over 150 summits, symposia, workshops, conferences, and events which were recorded (audio) and from which relevant records such as release forms, agendas, analysis of events, and other memorabilia were kept. Co-productions were described and catalogued, and the documentation made available on-line, as were exhibition descriptions and documentation. The BNMI created Horizonzero.ca, a Heritage Canada funded experimental online gallery and site for discourse regarding the new media world which acted as a guide back to the summits and co-productions.</p>
<p>The BNMI team were attentive to gender imbalance in the growth of the new media industry, the presence of female identified creative practitioners and their lack of inclusion in festivals, and the burgeoning of a diverse global creative new media community. As much as possible there was mitigation against digital exclusion, accepting George Gerbner’s concept ofsymbolic annihilation,where absence from the historical record removes practices and voices that could shape the future, a concept applied to archives by Caswell<a class="footnote-ref" href="#caswell2016"> [caswell2016] </a><a class="footnote-ref" href="#caswell2014"> [caswell2014] </a>.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> A feature of BNMI was its deep commitment to Indigenous creators and technical leaders, whose creative practices and self-governed events were supported by BNMI (such as <em>Drum Beat to Drum Byte</em> ., two gatherings regarding Indigenous practices and presence on the Internet that were two decades apart). Indigenous artists, technicians, theorists, curators, and elders engaged in all manner of BNMI activities. BNMI also built collaborations with local Indigenous communities.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> Despite its government and industry funding the BNMI fearlessly hosted agonistic debates over video game sexism, algorithmic bias, anthropocentric notions of intelligence, open-source vs copyright, bioengineering and environment, and other controversial topics.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup></p>
<p>In synch with Foucault, Derrida, and Foster’s calls to reexamine the archives, the BNMI held summits and workshops that considered the transition to digital archives; events debated memory and history, the archive versus the database and their ultimate integration, and the question of what should be digitized and how it should be conserved, with titles such as “Media, Material and Culture: Communicating Canada’s Heritage” . “Unforgiving Memory” . and “ReFresh” . (which have become the biannual Media Art History conferences).<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> These strengthened the acceleratingarchive feverwithin the BNMI and the belief that it must leave a record of this complex era. That intuition is rewarded today as the BNMI fonds include documentation of prescient debates that are in contemporary reprise (such as the nature of social media, gender, and race bias in AI systems, the mapping potential of GPS/GIS technologies, or control over data), and engage deeply diverse actors regarding technologies, systems, tools, and creative expressions that have shaped our lives today.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>
<p>For the archive project, a decade of audio recordings and documents were digitized and brought up to 2005 standards and a physical archive and finding aid were created by a professional archivist seconded from the National Archives Canada. There was an online interface which was searchable by events, names, and dates, and it was easily accessed on TBC’s website, as was the co-production catalogue. The BNMI team felt a contractual, financial, and emotional connection to the fonds. We had raised a significant amount of public funding to build this collection and create a related book. Speakers had signed release forms and expected that the associated materials would be present on the BNMI web site. The same contractual and affective bonds were not shared across The Banff Centre. In 2005 the BNMI team hoped that the fonds could reside with the Paul Fleck Library and Archive at the Banff Centre, but the Archive had no interest in the physical or digital archive nor did the archivist at that time recognize value in placing the BNMI fonds online.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> I left TBC in 2005; Susan Kennard, then Director of the BNMI, left in 2010; and TBC closed the BNMI shortly afterwards. The digital archive persisted, available on the main web site, and was well used. Dr. Sarah Cook and I co-edited the book <em>Euphoria and Dystopia: The Banff New Media Institute Dialogues</em> and it was published in 2011 by TBC and University of Waterloo’s Riverside Press.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> The e-book version in 2013 was meticulously linked to the online archive as a thematic, discursive, and critical finding aid. The BNMI efforts represented a strategy for archival access comprising multiple interpretive publications (the e-book and Horizonzero.ca) linked to a digital archive. This approach is appropriate for reinvigorating archives, introducing fonds to new audiences, and making them available for creative interpretation by artists and new generations of scholars.</p>




























<figure ><img loading="lazy" alt="Screenshot of a book cover for a book entitled “Euphoria and Dystopia” . Image 2 is a screenshot of a poster for an event called horizon^0" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Euphoria &amp; Dystopia and Horizonzero.ca DVDs – physical traces of digital archives
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Screenshot of a book cover for a book entitled “Euphoria and Dystopia” . Image 2 is a screenshot of a poster for an event called horizon^0" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Euphoria &amp; Dystopia and Horizonzero.ca DVDs – physical traces of digital archives
        </p>
    </figcaption>
</figure>
<h2 id="euphoria--dystopia-and-horizonzeroca-dvds--physical-traces-of-digital-archives">Euphoria &amp; Dystopia and Horizonzero.ca DVDs – physical traces of digital archives</h2>
<p>In 2016 Indigenous artist Cheryl L’Hirondelle found that the archive was no longer accessible and sounded an alert. Indeed, it had been removed after a change of leadership and a web rebranding and would never return to its original online form, thus severing all the meticulous links made to several thousand digital records and to the digital archives from other publications. Two years later, The Banff Centre did not renew the HorizonZero.ca domain or pay the small fee for hosting, so this legacy of the BNMI also disappeared.</p>
<p>Contributors to the archive – most poignantly Indigenous artists and historians – along with other scholars and archivists, the book publisher Philip Beesley, Sarah Cook, and I appealed to The Banff Centre to return the archive to researchers and the public again through a digital interface and volunteered to find or contribute funding. In 2018 TBC’s archivist John Yolkowski stepped in and moved the project from an IT-led web site initiative to an archive-led initiative. The physical fonds moved to the Paul Fleck Library and Archives and were accessioned. Work began and a number of documents were made available on the TBC’s archive site and mirrored on Alberta on Record.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> Then Yolkowski left. Indigenous artists and media historians insisted that the Indigenous media arts history be reconstructed, as TBC was an epicenter of Indigenous and international media production, new media, and digital arts creativity. The Banff Centre acted on this in 2021 and hired a team of researchers to undertake an oral history of Indigenous media art at TBC, which is now completed. These efforts underscore the responsibility (Bergis, 2016) that institutions bear in relation to their engagement with Indigenous and other equity seeking communities if they collect and represent their data.</p>
<p>Perhaps The Banff Centre leadership perceived the BNMI archive as the expression of a specific leadership and their program priorities, not as an archive. While many institutions do retain program records, they are rarely featured as part of a current marketing web site. There was no continuity in Banff’s Indigenous leadership, and hence no awareness of the archive’s Indigenous contents or advocate. Institutional memory is fragile at best; however, the formal nature of an archive and the policies surrounding it can create some ballast. The collection represented consciously collected and ordered institutional records, but it was not an archive – in this period it was not yet appraised or perceived as havingenduringinstitutional value and hence formally accessioned. Rather, it was a counter archive within an institution. TBC has a deaccessioning policy in place for its visual art collection, and its Paul Fleck Library and Archives holdings, but the BNMI archive, treated as an orphan record of program contents, was not covered under this policy.</p>
<p>It is valuable, nonetheless, to consider the principles of deaccessioning in collections management as defined by the SAS (<a href="#sas2017">2017</a>). Richard Gerrard (<a href="#gerrard2013">2013</a>) in his instructional text on deaccessioning lays out the rigorous staged nature of removing collections: due diligence institutional governance processes are required. The driver should be to improve the collection, and the goal of disposal to find a new home more able to house a collection. Writing on “Archival Appraisal and Deaccessioning” in <em>Indigitization: Tools for Digitizing and Sustaining Indigenous Knowledge</em> (<a href="#larson2020">2020</a>), Kayla Lar-son says of deaccessioning that materials should be returned to the original donors or holders of a collection. This principle is relevant for HorizonZero.ca as thetellissue included a reversioning of the Elderspeak website of the Meadow Lake Tribal Council with their permission as they could no longer host the original Elderspeak collection of stories. The issue was edited by Cheryl L’Hirondelle who undertook that reversioning. With the end of Horizonzero.ca, an unforeseen consequence was that MLTC lost access to Elderspeak although it is present on the Internet Archive.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> With L’Hirondelle’s support, MLTC will work with the DVD version and L’Hirondelle’s original files to repatriate the files and recreate the site.</p>
<p>A formal agreement should have been put in place for the care and transition of the BNMI records and the maintenance of HorizonZero, or for its disciplined disposal to another identified archive. As its creators, we should have built in redundancy and distributed the responsibility for maintenance while we were still working at TBC (Endings Symposium chat 14:08:32), and possibly created a fund to upgrade and support the fonds. In the Q. and A. of my presentation at the Project Endings conference, Martin Holmes urged “archives, mirrors, repos, web servers, Internet Archive — make as many copies as possible.” We should have arranged for a second repository. Alternatively, The Banff Centre could have returned the BNMI archive to Cook, Diamond, and Beesley and enabled them to find a home, as several institutions stepped up to offer to take it — but even that would have required staff effort and institutional prioritization.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> The physical and some digital archives are available on site to researchers who travel to The Banff Centre. In 2022 Jessica Zimmerman, the new archivist of the Paul Fleck Archive, reached out with a commitment to “find a home for the BNMI story,” integrating it into The Banff Centre’s history and timeline and revitalizing its online presence, including its audio recordings and previous archival interface. Banff is initiating this process and I will collaborate with the archives to seek funds for these endeavors. They may redescribe material into AtoM<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> to afford greater public accessibility and retrieval options and create a Rules for Archival Description (RAD) standard-compliant finding aid for easier access for distance researchers.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> Demand for access to the archive has grown and The Banff Centre seeks to revitalize its digital programs and celebrate its fifty years of work with Indigenous communities. The collection now fits CCA’s criteria for accessioning (<a href="#cca2018">2018</a>). This plan would mean that the BNMI’s role and impact will be visible to the current generation of scholars, artists, and researchers, heralding a happy ending.</p>




























<figure ><img loading="lazy" alt="Screenshot of an event called &#34;Unforgiving Memory&#34; agenda. The agenda also includes brands who sponsored the event" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Unforgiving Memorysummit event agenda - Alberta on Record provides access to several BNMI documents digitized in 2018.
        </p>
    </figcaption>
</figure>
<h2 id="daniel-langlois-foundation-documentation-centre">Daniel Langlois Foundation Documentation Centre</h2>
<p>The second case study underscores the importance of establishing a back-up repository. The Daniel Langlois Foundation Centre for Research and Documentation was initiated in 1998 by Jean Gagnon with the support of Daniel Langlois, the co-founder of Softimage.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> It became an important repository for the new media art works funded by the foundation and an expanded place to collect archives from artists, institutions and events that represented the history of media arts.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> Langlois renovated the Ex-Centris buildings which included theatres, gathering spaces, and a home for the documentation centre’s materials, with offices for visiting researchers. The DLF bought collections including those of stellar video artists the Vasulkas, and EAT, Experimental Art and Technology — the 9 EVENINGS OF THEATRE AND ENGINEERING, an exhibition that heralded the opening of an American epoch of art and science collaboration. A robust web presence accompanied the centre, allowing users to identify artists and projects. In 2005, the Documentation and Conservation of Media Arts Heritage (DOCAM) network, led by Alain de Pacard, was spearheaded by DLF, and comprised 20 institutions, from universities, to the prestigious new media journal <em>Leonardo</em> , to digital media centres and museums, with funding from SSHRC. It sought to create standards for the documentation, exhibition, and archiving of new media art works. DOCAM and the Education Centre invited artists, curators, and historians into this rich collection through a series of residencies. For example, in her residency, Dr. Caroline Langill produced<a href="https://www.fondation-langlois.org/html/e/page.php?NumPage=742"> <em>Shifting Polarities: Proposing a Canon of Canadian Electronic Media Art, 1970-1990</em> </a>(2006), an influential treatise that made the case that the contemporary art canon must expand to integrate new media art.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup></p>
<p>Over time Langlois’ attention drifted. His investments were not flourishing, and the cinemas at Ex-Centris were bleeding $2 million/year. By 2006, concerned about the sustainability of the documentation centre, Gagnon began approaching DOCAM members as well as the La Cinémathèque québécoise to take the centre’s holdings and turn them into an archive. Acquisition contracts stipulated that the Foundation was legally responsible to find a not-for-profit home if it stopped functioning. Gagnon left in 2008. Langlois was hard hit by the 2008 financial crash. Access to the documentation centre ended with the collection boxed up and stored. International scholars and donors alike began to pressure the DLF to find a home for the collection. Ultimately, contractual obligations with individuals or agents who had donated their records, user activism, and the commitment of an individual, Jean Gagnon, resulted in a safe landing for this valuable archive. This transfer represents a deaccessioning best practice as defined by the SAS (<a href="#sas2017">2017</a>).</p>
<p>La Cinémathèque québécoise accepted the fonds as the director Pierre Renault was interested in new media. Gagnon moved to the CQ as head of collections in 2010. He immediately began negotiations with the DLF, and secured a grant of $75,000 to move and update the finding aid and web site; the collection formally moved on October 11, 2011. No further acquisitions would occur, hence avoiding a debate about whether CQ should begin to acquire new media art works which could have halted the transfer of the collection. The DLF collection remains one of CQ’s most popular archives, with valuable holdings like the records of 1960s Xerox artist Sonia Sheridan.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></p>
<p>The DLF site also leads to the DOCAM project web site.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> DOCAM research identified and investigated five axes that distinguish methodologies and tools needed to address the preservation and technological documentation of electronic works of art, relevant to all archives, museums, libraries, and other collecting agencies managing new media and digital arts collections: “conservation, documentation, cataloguing, history of technologies and terminology.” DOCAM includes case studies conducted with museum partners.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> The association of the DOCAM and DLF sites is valuable because DOCAM provides a contextual understanding of the works in the collection as well as wisdom for current archives that collect physical, online, or post-Internet art (online with physical expression). Langlois recently subsidized the conversion of elements of the collection through emulation, including works with online links from Flash to HTML5 as many artists’ websites and related CD-ROM and DVD projects were built in Flash in the early 2000s., Although proprietary, Flash provided highly malleable graphic design tools. This is a positive example of the archive’s originator in concert with the current archive taking responsibility for the ongoing maintenance of the fonds.</p>
<p>When asked if he regretted the path that he took to create a media arts documentation centre, Gagnon indicated his belief that there was no other route available at the time. He had just left his role as Media Arts curator at the National Gallery of Canada and there was no capacity or interest there.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> He is concerned that CQ remains dependent on him for deep knowledge of the archive because there is no time or resources there to train another expert.</p>




























<figure ><img loading="lazy" alt="Screenshot of a website with tabs for themes, works, artists, and publications. the header image includes images from the archive" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Sub-navigation through La Cinémathèque québécoise to Daniel Langlois Foundation documentation centre interface, 2021
        </p>
    </figcaption>
</figure>
<h2 id="sara-diamond-fonds-crista-dahl-media-library--archive">Sara Diamond Fonds, Crista Dahl Media Library &amp; Archive</h2>
<p>The Crista Dahl Media Library &amp; Archive (CDMLA) is housed within the VIVO Media Arts Centre and holds a  significant repository of 8000 items, including video art, documentary, experimental documentary, narrative, synaesthetic, animation, and event documentation videotapes by artists and independent producers. The collections represent sixty years of production, an extensive archive of publications from the video and media art world and documentation of events, exhibitions, organizations, social movements, government policies, as well as the history of VIVO, founded in 1973. Over the last decade it has expanded its efforts to create fifteen special collections, as well as nine major fonds and five minor fonds. The CDMLA fonds align with Foster’s description of artists’ engagement with archives. The CDMLA has developed finding aids and projects including exhibitions built from the collections and fonds with artists’ residencies to reinterpret contents. They have raised funds to digitize aspects of the archive and provide effective navigation interfaces. In 2016-17, VIVO approached me to donate my materials to them from my earlier life as an artist, activist, and academic. I was the board president and an artist and curator there for many years.</p>
<p>My archive, built over the last four years, holds multiple sub-collections: the Women’s Labour History Project; my personal video art and new media works including the extensive<a href="http://www.codezebra.ca/">www.codezebra.ca</a>Post-Internet art project which itself consists of software, a website, performances, wearable art, and artifacts;<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> Amelia Productions, a five-person feminist collective (1980–1982) of which I was a member; and documents regarding international solidarity, Indigenous rights, feminism, LGBTQ2+, anti-censorship activities, labour activism, and curriculum development. The experimental documentaries of the Women’s Labour History Project and its photographic and print exhibitions relied heavily on film, television, photographic, and institutional archives in Canada and British Columbia — hence components of this collection are archives of archives, acting as a means of understanding what was collected and what was absent. The oral histories in the archive compensated for the sparse records regarding women workers available in archives. The art works are available on the site under a licensing agreement<a class="footnote-ref" href="#ora2014"> [ora2014] </a>.</p>
<p>Archivist Karen Knights has created a permanent online exhibition Women and West Coast Labour: Eighty years of action for equity in domestic and workplace labour by women in B.C.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> featuring two sub-exhibitions. One on women’s activism holds Chambermaids and Whistlepunks 1900–1970, featuring oral histories of labor organization from the Women’s Labour History Project, and the fonds of Amelia Productions. A second exhibition, Working Women in Focus 1970–1980, presents the fonds of the Women in Focus feminist artist-run production, distribution, and exhibition centre.</p>




























<figure ><img loading="lazy" alt="screenshot of the homepage for the women&#39;s labour history project. the website includes navigation and information about the project" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Women’s Labour History Project fonds launch page, Crista Dahl Library and Archives
        </p>
    </figcaption>
</figure>
<p>As with Jean Gagnon and the DLF, VIVO relies on one person, Karen Knights, who is the current driving force behind the media archive, just as it relied on Crista Dahl for the print and print materials archive. I moved forward with the donation with the stipulation that we bring Simon Fraser University into the project as a formal partner, acting on lessons learned from the BNMI and DLF archives. Copies of my Women’s Labour History Project audio collection reside in the Royal British Columbia Museum archives, which were the first repository, and the SFU archive, where I am an alumna and recipient of an Honorary Doctorate. SFU has made a contractual commitment to acquire my collection should VIVO need to deaccession it. The responsibility for the digitization, maintenance, and dissemination of this fonds is shared between the archive (CDMLA), SFU, and me, the living donor. While there are currently affective ties to the collection on the part of VIVO, SFU, and me, the former could wane with generational change. We have curated a partnership to create an ecosystem that will link my fonds at VIVO with nine other relevant collections and interested organizations and research centres.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> Partners will gain by examining the histories and methodologies that shaped their institutions and fonds and by making connections between historical and contemporary actors including originating communities and individuals to explore reinterpretation and redescription.</p>
<p>Our methods to develop the bridge are highly collaborative and include participatory design<a class="footnote-ref" href="#simonsen2013"> [simonsen2013] </a>incorporating Sabharwal’s concept ofsocialized digital curation(<a href="#sabharwal2021">2021</a>); visualization<a class="footnote-ref" href="#harris2019"> [harris2019] </a><a class="footnote-ref" href="#bahde2017"> [bahde2017] </a>; and research-creation (<a href="#sabharwal2014">2014</a>) in a case study approach. We will undertake workshops to create the specification for the ecosystem and develop microsites that foreshadow the design. Metadata, annotation, and social media tagging tools<a class="footnote-ref" href="#fatona2021"> [fatona2021] </a><a class="footnote-ref" href="#allisoncassin2020"> [allisoncassin2020] </a>will be applied through metadata and redescription workshops with Indigenous, Black, and other community groups. Artist-in-the-archives and researcher workshops will encourage exploration, discovery, application, integration, and dissemination of archival contents. We will sketch visualizations that show relationships between fonds and metadata. A series of historical case studies by Dr. Andrea Fatona, Dana Claxton and Dr. Karrmen Crey, Karen Knights, and me will include research, curation, and/or artmaking.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Perhaps institutions, creators of archives, and their users all bear responsibility for the protection and continuity of archives. Individuals have affective ties to the artists and archives that house their work and that they have built, but it is not viable to rely only on a few knowledgeable and emotionally-attached individuals. Collections within institutions, alternative archives, and significant fonds would benefit from strategies and contracts that address deaccessioning and alternative repositories. Temporary forms of accessioning such as the storehouse may serve to test interest in a collection before its donation. Where possible, donor commitments to raise dollars for maintenance and dissemination in partnership with archives are beneficial but should not lead to excluding the acquisition of fonds from marginalized groups. Institutions need to address duty of care for fonds representing Indigenous knowledge and history. Knowledge dissemination that creates new interest and new proponents for an archive including its recovery and rereading is both an individual and an institutional responsibility. Dr. Jennifer Kennedy from Queen’s University serves as an example — she is exploring the BNMI archives to understand contemporary feminist practices in new media that were sparked through encounters at the BNMI events and its co-productions and became a strong advocate for its revitalization (<a href="#bnmi2021">2021</a>). The partnership between VIVO, other archives, and community organizations and underrepresented groups should stimulate ongoing interpretation of my fonds. And the renewal of the BNMI’s Indigenous media archive through oral histories is testimony to effective user activism.</p>
<ul>
<li id="alberta2016">Alberta Foundation for the Arts. “Collection Management Policy” . Available at:<a href="https://www.affta.ab.ca/sites/default/files/AFACollection_CollectionManagementPolicy_20161213.pdf">https://www.affta.ab.ca/sites/default/files/AFACollection_CollectionManagementPolicy_20161213.pdf</a>.
</li>
<li id="albertaa">Alberta on Record. “Banff New Media Institute” . Available at:<a href="https://albertaonrecord.ca/banff-new-media-institute;rad?sf_culture=fr">https://albertaonrecord.ca/banff-new-media-institute;rad?sf_culture=fr</a>.
</li>
<li id="albertab">File 1.G - 12 “Unforgiving Memory” . Agenda, BNMI.
</li>
<li id="allisoncassin2020">Allison-Cassin, S. “Indigenous knowledge architecture and metadata workshops” . _Social ecology of vulnerable media_ , Vulnerable Media Lab. June 2020. Available at:<a href="http://vulnerablemedialab.ca/indigenous-knowledge-architecture-and-metadata-workshops/">vulnerablemedialab.ca/indigenous-knowledge-architecture-and-metadata-workshops/.</a>
</li>
<li id="archivescanada2018">Archives Canada (2018) “CCA Canadian Archives Information Standard (CAAIS) National Archival Accession Standard Working Group (NAASWG)” . Available at:<a href="http://archivescanada.ca/CWG_AccessionStandard#Accessioning_e">http://archivescanada.ca/CWG_AccessionStandard#Accessioning_e</a>.
</li>
<li id="artspace2014">Artspace Editors. “How the Art World Caught Archive Fever” . Jan. 22, 2014. Available at:<a href="https://www.artspace.com/magazine/art_101/art_market/the_art_worlds_love_affair_with_archives-51976">https://www.artspace.com/magazine/art_101/art_market/the_art_worlds_love_affair_with_archives-51976</a>.
</li>
<li id="bahde2017">Bahde, A. “Conceptual data visualization in archival finding aids: Preliminary user responses” . _Libraries and the Academy_ , 17(3): pp. 485–506.
</li>
<li id="beiguelman2019">Beiguelman, Giselle. “Museums of Losses for Clouds of Oblivion” . In O. Grau, J. Hoth, and Wandl-Vogt (eds.), _Digital Art through the Looking Glass: New strategies for archiving, collecting and preserving in digital humanitie_ s. Austria: Edition Donau-Universität (2019).
</li>
<li id="belkin2008">Belkin, N. J. “Some (what) Grand Challenges for Information Retrieval” . _ACM SIGIR Forum_ , 42(2008): 47–54.
</li>
<li id="bergis2016">Bergis Jules, (2016) “Confronting Our Failure of Care Around the Legacies of Marginalized People in the Archives” . _Medium_ . Available at:<a href="https://medium.com/on-archivy/confronting-our-failure-of-care-around-the-legacies-of-marginalized-people-in-the-archives-dc4180397280">https://medium.com/on-archivy/confronting-our-failure-of-care-around-the-legacies-of-marginalized-people-in-the-archives-dc4180397280</a>.
</li>
<li id="birkin2015">Jane (2015) “Art, Work, and Archives: Performativity and the Techniques of Production” , November 2015, _Archive Journal_ . Available at:<a href="https://www.archivejournal.net/essays/art-work-and-archives/">https://www.archivejournal.net/essays/art-work-and-archives/</a>.
</li>
<li id="breakell2008">Breakell, Sue (2008) “Negotiating the Archive” . _Tate Papers_ #9. Available at:<a href="https://www.tate.org.uk/research/publications/tate-papers/09/perspectives-negotiating-the-archive">https://www.tate.org.uk/research/publications/tate-papers/09/perspectives-negotiating-the-archive</a>.
</li>
<li id="breakell2015">Breakell, Sue. (2015) “Archival practices and the practice of archives in the visual arts’ Archives and Record” , _The Journal of the Archives and Records Association_ , 36(1) pp. 1–5. Available at:<a href="https://doi.org/10.1080/23257962.2015.1018151">https://doi.org/10.1080/23257962.2015.1018151</a>.
</li>
<li id="canadianarchitect2019">Canadian Architect. (2019) “Design Exchange to Deaccession Collection and Pivot to Programming” . Available at:<a href="https://www.canadianarchitect.com/design-exchange-to-deaccession-collection-and-pivot-to-programming/">https://www.canadianarchitect.com/design-exchange-to-deaccession-collection-and-pivot-to-programming/</a>.
</li>
<li id="cbc2009">CBC Montreal. (2019) “Film Fans Boo Closure of Ex-Centris Cinema” . Jan. 14, 2009. Available at:<a href="https://www.cbc.ca/news/canada/montreal/montreal-film-fans-boo-closure-of-ex-centris-cinema-1.862563">https://www.cbc.ca/news/canada/montreal/montreal-film-fans-boo-closure-of-ex-centris-cinema-1.862563</a>.
</li>
<li id="carbone2020">Carbone, Kathy. (2020) “Archival Art: Memory Practices, Interventions, and Productions” ,  _Curator: The Museum Journal_  63(2), pp. 257–263.
</li>
<li id="carbone2015">Carbone, Kathy (2015) “Artists in the Archive: An Exploratory Study of the Artist-in-Residence Program at the City of Portland Archives & Records Center” , _Archivaria_ 79 (Spring 2015), pp. 27–52.
</li>
<li id="caswell2019">Caswell, M. & Cifor, M. (2019). “Neither a beginning nor an end: Applying an ethics of care to digital archival collections” in _The Routledge International Handbook of New Digital Practices in Galleries, Libraries, Archives, Museums, and Heritage Sites_ . Routledge.
</li>
<li id="caswell2016">Caswell, Michelle, Cifor, Marika & Ramirez, Mario H. (2016) “To Suddenly Discover Yourself Existing: Uncovering the Impact of Community Archives” , _The American Archivist_ , 79(1) (SPRING/SUMMER 2016), pp. 56–81. Published by: Society of American Archivists.
</li>
<li id="caswell2014">Caswell, M. (2014) “Seeing yourself in history: Community archives and the fight against symbolic annihilation” , _The Public Historian_ , 36(4), pp. 26–37. ISSN: 0272-3433, electronic ISSN 1533-8576.
</li>
<li id="cohen2014">Cohen, H. (2014). “Research creation: A scholarship of creativity” , _Journal of the New Media Caucus_ . Available at:<a href="http://median.newmediacaucus.org/research-creation-explorations/research-creation-a-scholarship-of-creativity/">http://median.newmediacaucus.org/research-creation-explorations/research-creation-a-scholarship-of-creativity/</a>.
</li>
<li id="cook2012">Cook, Sarah & Diamond, Sara (2012) _Euphoria and Dystopia: The Banff new media dialogues_ . Banff: Banff Centre Press and University of Waterloo, Riverside Architectural Press. Available at:<a href="https://livingarchitecturesystems.com/publication/euphoria-dystopia/">https://livingarchitecturesystems.com/publication/euphoria-dystopia/</a>.
</li>
<li id="cinematheque2011">Cinémathèque québécoise and Daniel Langlois Foundation and Cinema Press Release (2011). Available at:<a href="http://nt2.uqam.ca/en/repertoire/la-fondation-daniel-langlois">http://nt2.uqam.ca/en/repertoire/la-fondation-daniel-langlois</a>.
</li>
<li id="deleuze1988">Deleuze, Gilles. (1988) _Bergonism_ . Princeton: Zone Books.
</li>
<li id="diamondbattershill2021">Project Endings Symposium, April 16, 2021.
</li>
<li id="diamond2021">Project Endings Symposium, April 16, 2021.
</li>
<li id="fatona2021">Fatona, A. (2021) “Digging us: making visible Black Canadian narratives” in Crooks, J., Fontaine, D. & Forni, S. (eds.),  _History, art, and Blackness_ . McGill-Queen’s University Press.
</li>
<li id="hall2004">Foster, Hal. (2004) “An Archival Impulse” ,October110, Fall 2004, pp. 3–22. _© 2004 Hal Foster_ .
</li>
<li id="foucault1969">Foucault, Michel (1969).  _The Archaeology of Knowledge_ . Trans. A. M. Sheridan Smith. London and New York: Routledge, 2002. ISBN 0-415-28753-7.
</li>
<li id="gagnon2001">Gagnon, Jean. (2001) Consumption: Jean Gagnon Presentation, CRUMB Seminar Presentation. Available at:<a href="http://www.crumbweb.org/getPresentation.php?presID=19&op=4&sublink=&fromSearch=1">http://www.crumbweb.org/getPresentation.php?presID=19&op=4&sublink=&fromSearch=1</a>.
</li>
<li id="gagnon2021">Gagnon, Jean (2021) “Interview with Sara Diamond” . Zoom, March 2021.
</li>
<li id="gerrard2013">Gerrard, Richard. (2013) An Introduction to the Deaccession and Disposal of Collections. Ontario Museums Association. Available at:<a href="https://members.museumsontario.ca/sites/default/files/members/AnIntroductionToTheDeaccessionAndDisposalOfCollections29May2013.pdf">https://members.museumsontario.ca/sites/default/files/members/AnIntroductionToTheDeaccessionAndDisposalOfCollections29May2013.pdf</a>.
</li>
<li id="grau2019">Grau, Oliver, Hoth, Janina & Wandl-Vogt, Eveline (eds.). (2019) _Digital Art through the Looking Glass: New strategies for archiving, collecting and preserving in digital humanities_ . Austria: Edition Donau-Universität.
</li>
<li id="harris2019">Harris, K. & Harris, A. (2019) “Data visualization tools for archives and special collections” , _MAC Newsletter_ , pp. 26–29. Available at:<a href="https:/ecommons.udayton.edu/imri_faculty        _publications/39">https:/ecommons.udayton.edu/imri_faculty _publications/39</a>.
</li>
<li id="hoth2021">Hoth, Janina. (2021) “Databases and the Representation of Knowledge” , _ADA Net, Media Art Research Thesaurus_ . Available at:<a href="http://mediaartresearch.org/analysis.html">http://mediaartresearch.org/analysis.html</a>.
</li>
<li id="hoth2019">Hoth, Janina. (2019) “Historicization in the Archive: Digital art and originality” . In Grau, Oliver, Hoth, Janina & Wandl-Vogt, eds. (2019) _Digital Art through the Looking Glass: New strategies for archiving, collecting and preserving in digital humanities_ . Austria: Edition Donau-Universität.
</li>
<li id="kennedy2021">Kennedy, Jen. (2021) “Across the Nebraska Border and the virtual-material divide: contextualizing Shu Lea Cheang’s Brandon, 1994–1999” , In _International Journal of Performance Arts and Digital Media_ , 17(2): Affiliated Issue with 2020 _College Art Association Annual Conference_ Panel “Flesh and Circuit: Rethinking Performance and Technology” (Chicago, IL, USA), Guest Editors: Conor McGarrigle and EL Putnam.
</li>
<li id="langill2006">Langill, Caroline (2006) _Shifting Polarities: Proposing a Canon of Canadian Electronic Media Art, 1970-1990_ . Available at:<a href="https://www.fondation-langlois.org/html/e/page.php?NumPage=742">https://www.fondation-langlois.org/html/e/page.php?NumPage=742</a>.
</li>
<li id="larson2020">Lar-Son, Kayla. (2020) “Archival Appraisal and Deaccessioning” , _Indigitization – Tools for Digitizing and Sustaining Indigenous Knowledge_ . Available at:<a href="https://www.indigenization.ca/">https://www.indigenization.ca</a>.
</li>
<li id="lacinematheque2011">Daniel Langlois Foundation. (2011), “La Cinémathèque québécoise et la fondation Daniel Langlois ont conclu uneentente permettant ainsi d'assurer la conservation et l'accessibilité de la collection de la foundation” . Available at:<a href="https://www.cinematheque.qc.ca/en/collections/daniel-langlois-fondation/">https://www.cinematheque.qc.ca/en/collections/daniel-langlois-fondation/</a>.
</li>
<li id="muntadas1994">Muntadas, Antonio (1994 – present). Available at:<a href="http://www.medienkunstnetz.de/works/the-file-room/">http://www.medienkunstnetz.de/works/the-file-room/</a>.
</li>
<li id="nass2014">Nass, M. (2014) “Derrida's Preoccupation with the Archive in ‘The Beast and the Sovereign’” , _SubStance_ : 43(2), ISSUE 134: _Fabled Thought: On Jacques Derrida's _The Beast & the Sovereign_ _ , pp. 20–36.
</li>
<li id="ora2014">ORA. (2014) “ORA deposit license” . _Version_ 5:27 November 2014.
</li>
<li id="sadharwal2021">Sabharwal, A. (2021). “Functional frameworks for socialized digital curation: Curatorial interventions and curation spaces in archives and libraries” , _Library Trends_ , 69(3), pp. 672–695. Project MUSE, DOI: 10.1353/lib.2021.009.
</li>
<li id="simonsen2013">Simonsen, Jasper, and Robertson, Toni. (2013)International Handbook of Participatory Design. Routledge.
</li>
<li id="smith2020">Smith, Madelaine Page. (2020) _Caring for the Moving Image in Art Museums: Matters in Media Art and the Stewardship of Time-Based Media Artworks_ . Thesis Department of Cinema Studies New York University.
</li>
<li id="smith2017">Smith, R. C., Bossen, C., & Kanstrup, A. M. (2017) “Participatory design in an era of participation” ,CoDesign, 13(2), pp. 65–69. DOI: 10.1080/15710882.2017.1310466.
</li>
<li id="society2017">Society of American Archivists (2017) _Guidelines for Reappraisal and Deaccessioning_ , Revised by the Technical Subcommittee on Guidelines for Reappraisal and Deaccessioning, and approved by the SAA Council. Available at:[https://www2.archivists.org/sites/all/files/GuidelinesForReappraisalDeaccessioning_2017.pdf](https://www2.archivists.org/sites/all/files/GuidelinesForReappraisalDeaccessioning_2017.pdf).
</li>
<li id="eastanglia2022">University of East Anglia. 2022. Available at:<a href="https://www.uea.ac.uk/library/british-archive-for-contemporary-writing/about-us">https://www.uea.ac.uk/library/british-archive-for-contemporary-writing/about-us</a>.
</li>
<li id="vivo2021">VIVO Media Arts Centre 2021. Available at:<a href="https://www.vivomediaarts.com/">https://www.vivomediaarts.com/</a>.
</li>
<li id="whibley2019">Whibley, Sara. (2019) Week 2 – Collection Strategy and the Storehouse Model at the British Archive for Contemporary Writing. Available at:<a href="https://archivecultureclub.wordpress.com/2019/02/10/week-2-collection-strategy-and-the-storehouse-model-at-the-british-archive-for-contemporary-writing/">https://archivecultureclub.wordpress.com/2019/02/10/week-2-collection-strategy-and-the-storehouse-model-at-the-british-archive-for-contemporary-writing/</a>.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The BNMI archive does not contain complex interactive new media art works. The Langlois Collection includes documentation of video, web, CD, and interactive works but few are online. My collection includes video and web works. New Media archiving is demanding because of changing platforms - many works have found a home with the Archives of Digital Art (ADA) and Rhizome, discussed later in this essay.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>This is the argument that an individual should be able to have their records removed from social media and other Internet sites.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>It opened in 1994 and the database was hosted over the years at several sites, eventually migrating to Rhizome (a digital arts archive) who upgraded and restored it for exhibition in 2016 at its affiliate the New Museum and online presence&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>The CCA’s National Archival Accession Standard Working Group (NAASWG) wrote a content standard for archival accession information which governs metadata standards, information sharing, research within and across archives, and management of digital archives. See<a href="http://archivescanada.ca/CWG_AccessionStandard">http://archivescanada.ca/CWG_AccessionStandard</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>To see the breadth of the events and participants explore<a href="https://livingarchitecturesystems.com/publication/euphoria-dystopia/">https://livingarchitecturesystems.com/publication/euphoria-dystopia/</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>For example, the sequential events Bridges (co-created with Celia Pearce from the University of Southern California), Bridges 2, and Skinning Our Tools bear testimony to the ways that the BNMI insisted on bringing discussions of race and Indigenous identity to art, science, and technology tables.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Jules Bergis (<a href="#bergis">2016</a>) underscores the danger that digital archives in particular, because of technical and programming needs will exclude traditionally marginalized groups.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>The BNMI was funded by the Canadian Tri-council research agencies, Alberta research, Telefilm Canada, the Canada Council for the Arts, Heritage and Industry Canada, international councils, and Canadian and international industry.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p><a href="https://www.mediaarthistory.org/mah-conf-series">https://www.mediaarthistory.org/mah-conf-series</a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>These include machine learning, genomics, neuroscience, nanotechnology, Artificial General Intelligence, social media, blogs, mobile devices and their affordances, Augmented and Virtual Reality, open source, streaming, and digital currencies.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>This memory was provided by Susan Kennard, who was the Director of the BNMI from 2005 – 2010.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>It included essays reflecting on the activities and themes of the BNMI, transcripts from the BNMI archives, information on attendees, and a visualization of BNMI activities. A DVD documenting horizonzero.ca was bundled with the book. The full version is available here:<a href="https://livingarchitecturesystems.com/publication/euphoria-dystopia/">https://livingarchitecturesystems.com/publication/euphoria-dystopia/</a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p><a href="https://albertaonrecord.ca/banff-new-media-institute">https://albertaonrecord.ca/banff-new-media-institute</a>.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p><a href="https://web.archive.org/web/20160316203351/http://www.horizonzero.ca/elderspeak/index.html">https://web.archive.org/web/20160316203351/http://www.horizonzero.ca/elderspeak/index.html</a>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>In another example, the leadership of Toronto’s Design Exchange brought back the original curator of its collection for the sole purpose of finding it a new home; they followed Canadian Museum Association standards and it now resides with the ROM and the Canadian Museum of History.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>“AtoM stands for Access to Memory. It is a web-based, open source application for standards-based archival description and access in a multilingual, multi-repository environment” (<a href="https://www.accesstomemory.org/en/">https://www.accesstomemory.org/en/</a>).&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>AtoM (Access to Memory) provides the following definition of an archival description, “Archival description is a body of information about an archival record or records. The descriptions provide contextual information about the archival materials and are arranged into hierarchical levels (<a href="https://www.accesstomemory.org/en/docs/2.3/user-manual/glossary/glossary/#term-fonds">fonds</a>, series, files, items, and variations of these in accordance with institutional standards).” <a href="https://www.accesstomemory.org/en/docs/2.3/user-manual/add-edit-content/archival-descriptions/#archival-descriptions">https://www.accesstomemory.org/en/docs/2.3/user-manual/add-edit-content/archival-descriptions/#archival-descriptions</a>.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Jean Gagnon provided details of the motivation for these initiatives and the transition process in an interview with me in March of 2021.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>The collection grew to comprise 2691 video works or source documents, DVDs, documentary works and documentation of art works, 2084 files of artists, festivals, biennales, 764 audio documents, documentation, and CD-ROMs by artists. From 2000 to 2005 the Centre acquired 6,000 books.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p><a href="https://www.fondation-langlois.org/html/e/page.php?NumPage=742">https://www.fondation-langlois.org/html/e/page.php?NumPage=742</a>.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Xerox is used here to denote that Sheridan used Xerox processes rather than that she was a Xerox employee.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p><a href="https://www.docam.ca/index-2.html">https://www.docam.ca/index-2.html</a>.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Partners are the National Gallery of Canada, Musée d’art contemporain de Montréal, Montreal Museum of Fine Arts, and Canadian Centre for Architecture including artists such as Janet Cardiff, Stan Douglas, Gary Hill, Nam June Paik, David Rokeby, Greg Lynn, and Bill Viola. Resources include a <em>Preservation Guide for Technology-Based Artwork</em> ; a  <em>Cataloguing Guide for New Media Collection</em> ; a   <em>Documentary Mode</em>  adapted to media arts; <em>DOCAM Glossauru</em> , a bilingual terminological tool; and a  <em>Technological Timeline</em> , which includes both media artworks and technological components.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>After Jean Gagnon left, the NGC terminated the role of media arts curator.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>CodeZebra was emulated from Flash onto the HTML5 platform, maintaining the initial quality of its integrated web sites which began in 1997 and continued until 2004. Unfortunately, several of the servers where the original games and software resided are no longer connected and reconstructing the links from the last version of the software to the site is a project requiring future efforts.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p><a href="http://www.vivomediaarts.com/archive/women-and-west-coast-labour/">http://www.vivomediaarts.com/archive/women-and-west-coast-labour/</a>.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>The partnership is comprised of OCAD University’s Centre for the Study of the Black Canadian Diaspora (CBCD) and Visual Analytics Laboratory (VAL), Simon Fraser University Archives (SFUA) and SFU Library Special Collections and Rare Books (SCRB), City of Vancouver Archives (CVA), The Royal British Columbia Museum (RBCM), the BC Labour Heritage Centre (BCLHC), BLAK, a Black artists’ centre in Surrey, B.C., and Satellite Video Exchange Society’s VIVO Media Arts Centre programming committee and Crista Dahl Media Library &amp; Archive (CDMLA).## Bibliography&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The Project Endings Interviews: A Summary of Methodological Foundations</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000661/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="related" type="text/html" title="Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="related" type="text/html" title="Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="related" type="text/html" title="Follow the Money?: Funding and Digital Sustainability"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="related" type="text/html" title="From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction to Special Issue: Project Resiliency in the Digital Humanities"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000661/</id><author><name>Emily Comeau</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>In 2016, the <em>Project Endings</em> team, a group of experienced digital humanities (DH) scholars, librarians, and programmers at the University of Victoria in British Columbia, Canada, was awarded a multi-year grant from the Social Sciences and Humanities Research Council (SSHRC) of Canada to explore questions around the ending and archiving of DH projects. The overarching goals of <em>Project Endings</em> are “to align the aims of faculty researchers producing projects and the archivists who will eventually be responsible for curating their work” and “to provide practical solutions to issues attendant on ending a project and archiving the digital products of research, including not only data but also interactive applications and web-based publications” <a class="footnote-ref" href="#arneil2019"> [arneil2019] </a>.</p>
<p>From a brief review of SSHRC-funded digital projects conducted between 2000 and 2009, the <em>Project Endings</em> team had learned that many of these projects had no visible surviving digital outputs. This motivated us to seek hard data about the status of digital projects from other countries and other funding programs in order to produce quantitative and qualitative data to support future recommendations. The first task of the research aspect of <em>Project Endings</em> was to conduct a survey, which was sent to DH scholars, including faculty members, researchers, programmers, and librarians across Canada and around the world, via various DH and library email lists. In total, 127 survey responses were received. The survey consisted of 37 questions in total, and sought information on topics such as project beginning and end dates, completion status, respondent’s career stage, project planning considerations, institutional support, major tools and technologies used, project maintenance, and major obstacles to project preservation. The full list of questions can be found online (<a href="https://hcmc.uvic.ca/endings/survey.html">https://hcmc.uvic.ca/endings/survey.html</a>). Survey results showed that more than half of survey respondents had not set an endpoint for their projects, and had no long-term plans for project preservation. 38% of respondents listed a lack of ongoing funding as the main obstacle they faced in preserving their projects long-term, while 33% of respondents listed a lack of expertise or poor choices in technology as their main obstacle<a class="footnote-ref" href="#arneil2019"> [arneil2019] </a>. Furthermore, as Arneil et al. (<a href="#arneil2019">2019</a>) state:</p>
<blockquote>
<p>While a reassuringly high 42% of respondents reported that university services were responsible for long-term maintenance of the project’s work, an alarming 45% reported that this responsibility fell to the Principal Investigator or nobody, demonstrating either significant vulnerability or great confidence.</p>
</blockquote>
<p>At the end of the survey, respondents were asked whether they were interested in participating in an interview with the <em>Project Endings</em> team to further elaborate on their responses and to have a more in-depth conversation about the issues facing DH work. In our approach to the interview process and subsequent analysis, we looked to qualitative methodologies such as constructivist grounded theory, narrative inquiry, and phenomenology in order to faithfully represent the diverse experiences of interview participants. The methodological principles of these approaches align with the collaborative nature of <em>Project Endings</em> and have allowed us to collaboratively co-construct knowledge with research participants. This knowledge has been mobilized in a number of practical and tangible ways, such as through conference presentations and scholarly publications (e.g.,<a class="footnote-ref" href="#carlin2018"> [carlin2018] </a>), as well as through the development of toolkits for ending and archiving digital projects, which are being made available to the DH community. The purpose of this paper is to summarize the methodological foundations of the <em>Project Endings</em> interviews and to demonstrate how these foundations have been reflected in the interviews and subsequent analysis conducted by the <em>Project Endings</em> team. I will also discuss the many ways in which knowledge has been co-constructed by participants over the course of the <em>Project Endings</em> interviews and analysis, as well as through the Endings Symposium in April 2021. Finally, I will provide a brief summary of the interview analysis.</p>
<h2 id="the-_project-endings_-interviews">The <em>Project Endings</em> Interviews</h2>
<p>After gathering quantitative data through the survey, we wanted to gather more in-depth qualitative data about participants’ experiences around the human and technological factors that have contributed to or impeded the completion of their digital projects. From the 127 survey responses received, we conducted 25 semi-structured interviews in the spring and summer of 2018. The interview team comprised three <em>Project Endings</em> primary investigators (PIs) — one from each of three primary areas of expertise (i.e. one faculty member, one librarian, and one programmer) — as well as myself (Comeau) as a research assistant, mainly for administrative and technical support. All interviews except one were conducted via Skype and recorded on a PI’s laptop using an external multidirectional microphone in the interview room. One interview was conducted in person and recorded on a standalone microphone. Once interviewees confirmed their consent to being interviewed and to their interviews being recorded, they were invited to describe their project(s) to the interview team. Following this initial question, which provided context for the interviewee’s narratives, our two main questions were: “In retrospect, what would you have done differently to improve the possibilities for archiving/preservation?” and “What decisions, plans, and measures proved effective and beneficial?” Interviewers then asked follow-up questions based on the interviewees’ responses to these initial questions, and often offered comments. Each interview was transcribed verbatim in order to facilitate text encoding and analysis. Following this transcription, all interviews were encoded in TEI-XML (the eXtensible Markup Language of the Text Encoding Initiative) using the oXygen XML Editor. Encoding was done to make the interviews machine readable and to enable various analysis techniques using different applications, as well as to facilitate data archiving. Transcription and encoding of all interviews were conducted by myself (Comeau) and Danny Martin, another research assistant at the UVic Humanities Computing and Media Centre.</p>
<p>In line with the overall goals of <em>Project Endings</em> , these interviews sought the diverse perspectives and experiences of DH scholars in a variety of academic roles related to digital projects, including as faculty researchers, programmers and developers, archivists, and librarians. The questions asked during the interviews were intended to point towards practical solutions for ending and archiving digital projects.</p>
<h2 id="methodological-foundations">Methodological Foundations</h2>
<p>In this study, we have followed the principles of constructivist grounded theory, narrative inquiry, and phenomenology to conduct the interviews and the subsequent analysis. These approaches have influenced our management of the research process, our self-location within the research, and our interpretations of the perspectives and experiences shared with us. These methodological approaches have allowed us to co-construct knowledge in a number of ways, such as through narrative over the course of the interviews, collaboratively as a team through the process of analyzing the interviews, and through in-depth discussions with each other and with fellow DH scholars (previous interviewees) at the Endings Symposium in 2021.</p>
<h2 id="constructivist-grounded-theory">Constructivist Grounded Theory</h2>
<p>A constructivist grounded theory (CGT) approach “aims to locate the research participants within the social, cultural, temporal, and situational conditions in which they live and to recognize how structural conditions and positions affect the researcher and the research process” <a class="footnote-ref" href="#charmaz2020"> [charmaz2020] </a>. In this approach, it is important for the researcher to reflect not only on the holistic context of participants’ perspectives, but also on their own perspectives and positionality within the research. According to<a href="#coghlan2014">Coghlan and Brydon-Miller (2014)</a>, “positionality refers to the stance or positioning of the researcher in relation to the social and political context of the study — the community, the organization or the participant group” (628). These contexts influence every stage of the research process. The positionality of the researchers includes our individual experiences as university-affiliated DH scholars, developers, and librarians, as well as our access to institutional resources and support — both individually and collectively through <em>Project Endings</em> and other DH projects.</p>
<p>CGT recommends the use of interviews as an emergent and collaborative process where the interviewer and the interviewee co-construct the research data through an “exploration of the interviewee’s experiences and perspectives” <a class="footnote-ref" href="#charmaz2021"> [charmaz2021] </a>. In terms of analysis, Charmaz and Thornberg recommend using line-by-line coding and memo-writing to determine what lines of data mean individually and in connection with each other. These were the primary tools we used in analyzing the <em>Project Endings</em> interviews. While we did not conduct any preliminary coding during the data collection period, as Charmaz and Thornberg (2021) recommend, we did reflect on the data after each interview and considered how to refine our follow-up questions in subsequent interviews.</p>
<p>One of the main aims of the research interviews was to understand the context of participants’ experiences and perspectives on ending and archiving DH projects. This research emerged from <em>Project Endings</em> PIs’ own complex experiences with project endings. The <em>Project Endings</em> PIs have openly shared their own perspectives and interests throughout the research process, and have continually reflected on the “social, historical, local, and interactional contexts” of both participants’ experiences and their own, acknowledging their positionality within the project specifically and in the research field more generally<a class="footnote-ref" href="#charmaz2021"> [charmaz2021] </a>.</p>
<h2 id="narrative-inquiry">Narrative Inquiry</h2>
<p>A narrative inquiry approach is a collaborative process<a class="footnote-ref" href="#butlerkisber2019"> [butlerkisber2019] </a>where researchers and participants work together to “make sense of experience and organise it into a body of practical knowledge” <a class="footnote-ref" href="#mertova2020"> [mertova2020] </a>. As with CGT, an important aspect of a narrative inquiry approach is reflexivity, in terms of what perspectives and preconceptions the researchers bring to the research process<a class="footnote-ref" href="#butlerkisber2019"> [butlerkisber2019] </a>. Using this approach, we have been able to share participants’ experiences “holistically in all [their] complexity and richness” <a class="footnote-ref" href="#mertova2020"> [mertova2020] </a>, acknowledging that the experiences shared with us are situated within specific contexts and that our understanding of these experiences can change over time. As<a href="#butlerkisber2019">Butler-Kisber (2019)</a>explains, narrative inquiry “illustrates the selectivity of experience” as iterative and continuous and “emphasizes the social and contextual aspects of understanding” (4–5).</p>
<p>This study follows a narrative inquiry approach in a number of ways. The interviews, and later the symposium, provided participants with the space to share their experiences in a relatively low-pressure environment. Participants were asked whether or not they consented to the interview process (both the audio recording and transcription thereof) at the beginning of each interview, and were given the option of veto-power or full anonymity in terms of how their narratives were shared. This allowed participants to speak as freely as they wished, particularly about any potentially negative experiences. Through narrative, participants were able to represent their experiences in their own words, interpreting events that they felt were important to the general topic of the interviews — ending and archiving digital projects.</p>
<p><em>Project Endings</em> team members were acquainted with a number of the interviewees prior to this project, and as peers and members of the DH community, we also share many parallel experiences with the interviewees. As an observer more than an active participant in the interviews, I witnessed this peer relationship as important to creating trust in the interview process and in allowing interviewees to feel safe enough to be honest about their experiences and perspectives.<a href="#mertova2020">Mertova and Webster (2019)</a>illustrate, through educational experience narratives, how interviews allow participants to reorder their experiences “into a usable past and present, with the aim of promoting an understanding of that experience and perhaps providing insights into our judgements” (9).</p>
<p>Not only did the interviews themselves deploy a narrative approach, the analysis of the interviews also followed a narrative inquiry approach. The interview analysis was a collaborative process between <em>Project Endings</em> PIs and research assistants; we reflected upon common and recurring themes in the interviews. Our analysis was iterative in that our interpretation of the interviews as a whole evolved continually as new themes emerged. We have collectively developed a narrative of the interview analysis and of this research as a whole, and this narrative continues to shift as <em>Project Endings</em> team members conduct further analyses and gain new insights into the data.</p>
<h2 id="phenomenology">Phenomenology</h2>
<p>A phenomenological approach to research goes beyond describing experiences empirically; it attempts to interpret experiences in order to understand their meaning, how they arise, and how they relate to each other<a class="footnote-ref" href="#cresswell2007"> [cresswell2007] </a><a class="footnote-ref" href="#engelland2020"> [engelland2020] </a><a class="footnote-ref" href="#zahavi2019"> [zahavi2019] </a>. According to Hopp (<a href="#hopp2020">2020</a>), phenomenology “is a search for genuine understanding, an attempt to render objects, relations, and states of affairs intelligible” (p.<a href="#hopp2020">243</a>).<a href="#zahavi2019">Zahavi (2019)</a>further elaborates, explaining that “for many phenomenologists, the task of phenomenology is not to describe empirical and factual particularities, but to investigate the essential structures characterizing our experiences, their correlates, and the connection between the two” (44).</p>
<p>Similar to CGT and narrative inquiry, research using a phenomenological approach often entails “in-depth interviewing, preferably over time, and open-ended questions that draw out accounts of experience, their descriptions and explanations” <a class="footnote-ref" href="#butlerkisber2019"> [butlerkisber2019] </a>.<a href="#cresswell2007">Cresswell et al. (2007)</a>explain that in contrast with grounded theory, which gathers participant views in order to generate theoretical models, phenomenology “describe[s] what all participants have in common as they experience a phenomenon” (252). The researcher collects data from participants “who have experienced the phenomenon and develops a composite description of the essence of the experience for all the individuals — what they experienced and how they experienced it” <a class="footnote-ref" href="#cresswell2007"> [cresswell2007] </a>.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>Several authors make a distinction between psychological and hermeneutical phenomenology. In psychological phenomenology, researchers employ transcendental reduction to set aside their own experiences and preconceptions, become essentially “spectator[s] to experience” <a class="footnote-ref" href="#engelland2020"> [engelland2020] </a>, and “take a fresh perspective of the phenomenon under examination” <a class="footnote-ref" href="#cresswell2007"> [cresswell2007] </a>. According to<a href="#engelland2020">Engelland (2020)</a>, “the point of the transcendental reduction is to step back, [and] to retrace the steps that make experience happen” (6). Proponents of this approach argue that it allows researchers to focus more on understanding participants’ experiences rather than their own interpretations<a class="footnote-ref" href="#butlerkisber2019"> [butlerkisber2019] </a>.<a href="#cresswell2007">Cresswell et al. (2007)</a>explain that while researchers may aim towards entirely “bracketing out their views before proceeding with the experiences of others” (254), it is rarely achieved perfectly. In contrast, hermeneutical phenomenology focuses on interpreting lived experiences through the researcher’s lens. As<a href="#butlerkisber2019">Butler-Kisber (2019)</a>explains, hermeneutical phenomenology “move[s] beyond description to interpretation where the researcher actively takes a role in explaining participant meanings” (3). The use of a phenomenological approach in the <em>Project Endings</em> interviews sits somewhere between these two approaches, though perhaps leaning more towards hermeneutical phenomenology: while we have made a point of trying to set aside our own perspectives in order to describe and organize interview data accurately, a major aspect of this study has been to understand participant narratives as they relate to our own experiences as DH scholars.</p>
<h2 id="co-constructing-knowledge">Co-constructing Knowledge</h2>
<p>There are few references in the literature to the co-construction of knowledge as an intentional practice, particularly in DH research. Rather, the co-construction of knowledge seems to be more often described as a result of particular qualitative methodologies, such as narrative inquiry. As such, there is no clear consensus on what co-constructing knowledge looks like, since qualitative methodologies are used in such wide and varied contexts. However, one idea that emerges repeatedly in the literature is the importance of active participation by all actors in the research task or process. For example,<a href="#assmuth2015">Assmuth and Lyytimaki (2015)</a>talk about the importance of participation in environmental impact assessments, saying that “impact assessments serve as tools for co-constructing knowledge for policy-making, planning and associated resolution of conflicts” (341–342). The authors also describe an open web-platform, called Opasnet, which “collects, synthesizes and distributes scientific and other factual information,” and where users can “[engage in] research, store and display data, make and run models, and perform assessments, and discuss all of that work in one workspace” <a class="footnote-ref" href="#assmuth2015"> [assmuth2015] </a>. In another example,<a href="#enloe2021">Enloe et al. (2021)</a>describe a study they conducted where they used photovoice methods — where participants are provided with cameras and invited to take photos of places and objects in their lives that they connect to a prompt from the researcher — combined with interviews, workshops, and field visits, to learn about the needs and priorities of farmers in Malawi. This method “supported a process of co-constructing agroecological knowledge” <a class="footnote-ref" href="#enloe2021"> [enloe2021] </a>by “provid[ing] a platform through which researchers, practitioners, and farmers could learn from each other, identify priorities for trainings and research, and determine next steps for generating new, locally applicable agroecological strategies” (pp.<a href="#enloe2021">1098–1099</a>). These examples reflect what<a href="#pratt2019">Pratt (2019)</a>describes as the process of co-constructing knowledge, which involves “bringing together multiple kinds of knowledge and multiple perspectives to construct an understanding of research phenomena based on a plurality of situated knowledges” (806).</p>
<p>According to<a href="#pratt2019">Pratt (2019)</a>, the co-construction of knowledge is an important aspect of public health research, particularly in studies where community-based participatory research methods are used and where social justice is a goal of the research. In Pratt’s model of knowledge co-construction, researchers and participants “design and conduct research together in ways that achieve the purpose of both sets of actors” and share responsibilities for “decision-making in all phases of research projects” <a class="footnote-ref" href="#pratt2019"> [pratt2019] </a>. Pratt does acknowledge, however, that there is a range of public engagement within participatory research methods, from “informing and consultation to power‐sharing strategies of partnership” (p.<a href="#pratt2019">806</a>).</p>
<p>In terms of news journalism,<a href="#conradie2012">Conradie (2012)</a>explains that “interviews represent a special form of dialogue in which knowledge is co-constructed between two or more participants” and which “differs markedly from everyday conversations” (499) in a number of ways. For instance, there is generally a power difference between interviewers and interviewees, however slight, where the interviewer has more control over the interaction and resulting texts. As well, participants’ roles in the interview process are governed by particular rules and conventions — for instance, interviewers “[determine] the topic and duration of the discussion” while interviewees “respond within the limits already demarcated by the [interviewer]” <a class="footnote-ref" href="#conradie2012"> [conradie2012] </a>. Additionally, all participants understand that the knowledge they co-construct “will eventually be viewed by the public,” which can influence what information is shared during the interview<a class="footnote-ref" href="#conradie2012"> [conradie2012] </a>. Through the <em>Project Endings</em> interviews, participants — both interviewers and interviewees – co-constructed knowledge by sharing narratives. Much as<a href="#conradie2012">Conradie (2012)</a>illustrates through news interviews, the roles of the interview participants in our research, and in the subsequent symposium, were clearly defined between interviewer and interviewee. The methodological approaches listed above (constructivist grounded theory, narrative inquiry, and phenomenology) allowed us to co-construct knowledge throughout the interview and analysis processes, and later through the Endings Symposium, both within our research team and with fellow DH scholars as interview and symposium participants.</p>
<h2 id="analyzing-the-interviews">Analyzing the Interviews</h2>
<p>Before analyzing the interviews, the <em>Project Endings</em> team (including PIs and research assistants) met to establish a basic taxonomy of codes to guide the analysis. We discussed the recurring themes we noticed from our experiences conducting, transcribing, and reading the interviews, and grouped our impressions into twelve broad themes: Data; Documentation; Funding; Hosting; Institutional issues; Migration; Project management; Project outputs; Rights; Scholarly or academic issues; Storage, backup, and preservation; and Team. This taxonomy continued to evolve over the course of the analysis process, as each of these twelve broad themes came to include a number of narrower codes. We met around a large table, with emergent themes written on slips of paper, and grouped them into categories. In total, 200 individual codes were established through our analysis of the interviews. See Appendix A for a full summarized list of the themes and narrow codes.</p>
<p>The first few interviews were analyzed through line-by-line coding by Danny Martin and myself (Comeau). For inter-coder reliability, we would encode our individual analyses separately in XML, and then meet to discuss any discrepancies between our analyses, eventually coming to a consensus on the final codes. Once we had established a process for conducting the analysis that was straightforward and replicable, we demonstrated this process to the rest of the <em>Project Endings</em> team, after which all team members took part in analyzing the remaining interviews. Each interview was independently analyzed by two researchers, who then resolved and merged their coding choices. In order to facilitate analysis on such an extensive dataset, <em>Project Endings</em> team member Martin Holmes developed a schema to aid in the visualization of our analyses. Figure 1, below, illustrates how this schema was used to visualize our analyses, with an example from an interview with participant James Cummings. The various colours denote the themes ofRights,Storage, backup, and preservation,Funding,Data,Institutional Issues,andDocumentation.</p>




























<figure ><img loading="lazy" alt="Screenshot of a quote with lines highlghted in pink, blue, green, and yellow" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Excerpt from an interview with James Cummings (June 5, 2018)
        </p>
    </figcaption>
</figure>
<p>These interviews and the subsequent analysis led directly to the 2021 Endings Symposium. Symposium speakers were selected from the scholars we interviewed in 2018, and the key issues that emerged from our analysis of the interviews guided us in selecting both the symposium speakers and the major topics that would guide the symposium discussions. A more in-depth discussion of the interview analysis and results will be published in future articles by <em>Project Endings</em> team members.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Knowledge has been co-constructed over the course of the <em>Project Endings</em> interviews in several ways. Interviewees shared their experiences, and interviewers followed up with questions based on their own understandings of the shared narratives, as well as their own experiences. The goals of the interviews were clearly laid out ahead of time, as were the objectives of <em>Project Endings</em> — to develop recommendations, guidelines, and tools to help with ending and archiving digital projects, from the perspectives of DH scholars, developers, and librarians. Knowledge has also been co-constructed by <em>Project Endings</em> team members through the interview analysis process and the subsequent dissemination and mobilization of these analyses. The interview analysis was a collaborative process where <em>Project Endings</em> team members engaged in summarizing, interpreting, and distilling the narratives shared with us by other DH scholars. Lastly, knowledge has been co-constructed between participants at the Endings Symposium in April 2021 and in subsequent publications (such as this special issue). The Endings Symposium panel comprised <em>Project Endings</em> PIs, research assistants, and previous interviewees. During the symposium, participants were invited to reflect on their experiences and discuss their perspectives on ending and archiving digital projects. Since the symposium took place later in the <em>Project Endings</em> timeline, participants came to the symposium having already been part of the knowledge co-construction process in the interview phase. The <em>Project Endings</em> research team had concluded the TEI-XML encoding of the interviews by this time, and had completed the process of analysis through co-construction of categories and qualitative coding. Our perspectives had evolved over the course of the project and we were able to engage with questions about project endings in deeper ways.</p>
<p>Methodologically, this study was guided by elements of constructivist grounded theory, narrative inquiry, and phenomenology. The <em>Project Endings</em> interviews, subsequent analysis, and final Endings Symposium validated many of the researchers’ own experiences, at the same time as they provided new perspectives and allowed us to expand our understanding of the issues facing DH scholars with regards to the ending and archiving of digital projects. As DH scholars and members of the DH community, <em>Project Endings</em> team members are now well positioned to make recommendations based on the results of this study.</p>
<h2 id="appendix-a-summarized-list-of-interview-themes-and-narrow-codes">Appendix A: Summarized list of interview themes and narrow codes</h2>
<p>Data: issues concerning data formatting; specific file types; data modelling and management; the importance of metadata; findability; decisions around digitization; born digital data; and sharing data as content.</p>
<p>Documentation: the creation, availability, and completeness of documentation; images, text, or video documentation; and metadata as documentation.</p>
<p>Funding: experiences with funding body requirements; public funding through organizations such as SSHRC or the Canada Council; crowd-sourcing; funding difficulties and running out of funds; institutional financial support; and fundraising.</p>
<p>Hosting: experiences surrounding commercial hosting; using platforms such as Google, Wordpress, or Zenodo; hosting and storage issues; housing an archive; loss of hosting; hosting a mirror site; institutional servers and university repositories; and long-term hosting.</p>
<p>Institutional issues: access to administrative, research, and technical support; infrastructure and logistics for supporting DH projects at the institutional level; experiences particular to arts institutions and research institutions; change and continuity in leadership at the institutional level; politics and conflict at institutions; institutional hosting; public vs. private institutions; planning and integration of DH goals into institutional priorities and policies; institutions’ responsibilities to DH projects; loss of access to institutional support and resources; jurisdictional issues of ownership and control over DH projects; long term maintenance of DH projects; differences between institutional support available to DH projects across regional and national borders; institutions’ reputations regarding support or lack of support for DH projects.</p>
<p>Migration: issues surrounding migration of any kind, including migration of data, project outputs, or hosting.</p>
<p>Project management: project planning and management; organizing project workflow; ad hoc solutions to issues arising in project development or maintenance; deadlines and completion of DH projects; recognizing signals that it is time to end a project; realistic expectations for the scope of a project; tools for project management (e.g. Basecamp, content management, etc.); responsibility for certain aspects or tasks in the development, storage, or maintenance of a project; and complications that arise later in a project’s life cycle.</p>
<p>Project outputs: different kinds of outputs, such as immersive 3-D experiences, CD-ROMs, websites, digital and text editions, books, journals, physical or digital archives, and presentations or workshops; accessibility of data or content that is developed and provided through the launching of a project; encouragement of dialogue or helping to change attitudes toward DH (intentionally or not); code, interface, or framework development as project outputs; design issues that become evident after a project is launched; points at which progress within a project is measurable; contribution to the development or understanding of interoperability of various technical/technological components; searchability of project outputs; focus on creating content rather than a single product; a focus on results, effects, or changes, etc., rather than a single product; and other less tangible project outputs such as research or pedagogical goals.</p>
<p>Rights: issues surrounding rights agreements; changing privacy laws, complex protocols and implementation; jurisdictional issues and crossing regional legal boundaries; documentation of rights; ethical issues in terms of participant consent, ownership of data, etc.; intellectual property rights for data, content, etc.; Indigenous creators and representation in content, as well as in project governance and team composition; issues particular to open access projects, resources, data, software, etc.; and the researcher’s responsibilities to participants, organizations, the project itself, the broader field, society, etc.</p>
<p>Scholarly or academic issues: issues such as academic value of and credit for DH work; authenticity of digital versions; citing other scholars or being cited by other scholars; disciplinary background and its effects on practice; decisions regarding what to include in a project and how these decisions are made; differences between project genres and how a genre is represented by a project; technical advice provided by programmers, developers, or consultants and humanists being ill-equipped to judge the advice given; Indigenous representation and work in DH; intellectual value of DH work in the academy, in particular fields, and in society in general; the precarity of employment for early-career scholars involved in DH projects, and using DH projects in tenure files; and the impact of scholarly workload on a project.</p>
<p>Storage, backup, and preservation: issues facing the preservation of data and project components for long-term storage; challenges involved in archiving projects; changing attitudes to technology in terms of the preservation of DH projects; backing up project components in case of a single point of failure; causes of failure in long-term preservation; challenges maintaining hardware and software for long-term preservation, particularly the effects of hardware obsolescence; reliance on institutional hosting, specific hardware or software, the WayBack Machine, etc. for long-term storage; fragility and erasure of stored data; preserving projects or components on GitHub; guaranteeing project preservation through a contract with an institution or an independent organization; LOCKSS — using multiple copies and mirror sites to back up a project; searchability of stored data; and particular technologies used for storage, such as USB-connected storage devices, servers, hard drives, DropBox, iCloud, etc.</p>
<p>Team: priorities, commitment, and flexibility of team members or member institutions; challenges in working with creative or independent colleagues; team leadership change because of retirement, career change, death, etc.; changes in the capacities of participants; collaborating on a DH project with other scholars, institutions, etc.; communication problems and conflict that arise between collaborators; community politics and the challenges they present to the archiving process; the importance of common understanding of priorities and practice amongst team members; continuity of team members’ involvement in a project; expertise within the team; team composition, including a variety of personnel, e.g. faculty, research staff, students, administrators, fellows, etc.; and the importance of a range of specializations within a team in making decisions about a project.</p>
<ul>
<li id="arneil2019">Arneil, S., Holmes, M., and Newton, G. (2019) “Project Endings: Early Impressions from Our Recent Survey on Project Longevity in DH” , _Digital Humanities 2019 Conference Papers_ , Utrecht University, July 2019.
</li>
<li id="assmuth2015">Assmuth, T. and Lyytimaki, J. (2015) “Co-constructing Inclusive Knowledge within Converging Fields: Environmental Governance and Health Care” , _Environmental Science and Policy_ , 51, pp. 338–350.
</li>
<li id="butlerkisber2019">Butler-Kisber, L. (2019) _Qualitative Inquiry: Thematic, Narrative and Arts-Based Perspectives_ . London: Sage.
</li>
<li id="carlin2018">Carlin, C. (2018) “Endings: Concluding, Archiving, and Preserving Digital Projects for Long-Term Usability” , _KULA: Knowledge Creation, Dissemination, and Preservation Studies_ , 2(1).
</li>
<li id="charmaz2020">Charmaz, K. (2020) “‘With Constructivist Grounded Theory You Can't Hide’: Social Justice Research and Critical Inquiry in the Public Sphere” , _Qualitative Inquiry_ , 26(2), pp. 165–176.
</li>
<li id="charmaz2021">Charmaz, K. and Thornberg, R. (2021) “The Pursuit of Quality in Grounded Theory” , _Qualitative Research in Psychology_ , 18(3), pp. 305–327.
</li>
<li id="coghlan2014">Coghlan, D. and Brydon-Miller, M. (2014) “Positionality” In Coghlan, D. and Brydon-Miller, M. (eds.), _The SAGE Encyclopedia of Action Research_ . London: SAGE Publications Ltd., p. 628.
</li>
<li id="conradie2012">Conradie, T. (2012) “Co-constructing Knowledge in News Interviews: An Application of Hardy and Palmer's (1998) Discourse Model” , _Southern African Linguistics and Applied Language Studies_ , 30(4), pp. 497–509.
</li>
<li id="cresswell2007">Cresswell, J. W., Hanson, W. E., Clark, V. L. P., and Morales, A. (2007) “Qualitative Research Designs: Selection and Implementation” , _The Counseling Psychologist_ , 35(2), pp. 236–264.
</li>
<li id="engelland2020">Engelland, C. (2020) _Phenomenology_ . Cambridge: MIT Press.
</li>
<li id="enloe2021">Enloe, S. K., Banda, D., Moyo, P., Dakishoni, L., Msachi, R., Kerr, R. B. (2021) “Photovoice as a Method for Co-constructing Agroecological Knowledge in Northern Malawi” , _Agroecology and Sustainable Food Systems_ , 45(7), pp. 1083–1103.
</li>
<li id="hopp2020">Hopp, W. (2020) _Phenomenology: A Contemporary Introduction_ . New York: Routledge.
</li>
<li id="pratt2019">Pratt, B. (2019) “Engagement as Co-constructing Knowledge: A Moral Necessity in Public Health Research” , _Bioethics_ , 33(7), pp. 805–813.
</li>
<li id="mertova2020">Mertova, P. and Webster, L. (2020) _Using Narrative Inquiry as a Research Method: An Introduction to Critical Event Narrative Analysis in Research, Teaching and Professional Practice_ . New York: Routledge.
</li>
<li id="zahavi2019">Zahavi, Z. (2019) _Phenomenology: The Basics_ . New York: Routledge.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>This work is ongoing and will result in a final journal article on the <em>Project Endings</em> interviews.## Bibliography&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The Stories We Tell: Project Narratives, Project Endings, and the Affective Value of Collaboration</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000665/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000669/?utm_source=atom_feed" rel="related" type="text/html" title="Academics Retire and Servers Die: Adventures in the Hosting and Storage of Digital Humanities Projects"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000667/?utm_source=atom_feed" rel="related" type="text/html" title="Doing it for Ourselves: The New Archive Built by and Responsive to the Researcher"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000666/?utm_source=atom_feed" rel="related" type="text/html" title="Follow the Money?: Funding and Digital Sustainability"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000668/?utm_source=atom_feed" rel="related" type="text/html" title="From Tamagotchis to Pet Rocks: On Learning to Love Simplicity through the Endings Principles"/><link href="https://startwords.cdh.princeton.edu/vol/17/1/000671/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction to Special Issue: Project Resiliency in the Digital Humanities"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000665/</id><author><name>Claire Battershill</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>In a story beloved by many kindergarteners, <em>We are in a Book!</em> , by Mo Willems, early readers are introduced to an Elephant named Gerald and his friend Piggie. Gradually, Elephant and Piggie come to the realization that they are in fact characters in a book. They peer curiously out of their pages and stare at the reader before them. At first the whole situation seems amusing and they play games with the reader, exhorting them to say silly words out loud and to turn the pages. However, after an initially carefree time joking around about the absurdity of narrative, poor Gerald comes to a terrible recognition: that the story will come to an end. He proceeds to work his way through a crisis of completion, worrying that the ending will come too soon for him to tell his story in its fullness. As is the case with many brilliant works of children’s literature, a lot of us can probably relate to Gerald. His cartoonish anguish at the prospect of an ending is familiar. A lot of academics who begin digital humanities projects start out just like this little elephant: enjoying a new way of doing scholarly work, relishing the collaborative possibilities that digital projects can offer, enjoying good company, and not thinking much about how the project will end or even acknowledging, really, that it will inevitably be over sooner or later<a class="footnote-ref" href="#carlin2018"> [carlin2018] </a>.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>The Endings Project initiative whose work occasioned this cluster of essays and the symposium on which they were based is asking those involved in DH projects to think deeply on hard questions. DH projects often begin with specific scholarly goals in mind, whether these are editorial, theoretical, archival, or methodological. When projects begin, all is promise, potential, and excitement. The grant funding structure on which many larger projects are founded also demands that projects begin with an optimistic view and a future-oriented perspective. Until recently, very little in the grant application process, at least in the Canadian context, had to do with sustainability.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> The emergence of data management requirements at the Social Sciences and Humanities Research Council (SSHRC), for example, is a relatively recent phenomenon, and goes some way to address the open-ended futurity that throughout the 2010s was often a hallmark of many DH projects.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> Before such requirements and before the Endings Project suggestions, a team dreamt up a vision and created a plan for executing it, and it could be difficult both practically and epistemologically to think about an ending while constructing a beginning. Even with more stringent requirements for sustainability, these projects still begin in heightened moments of collegiality, collaboration, and shared vision among scholars; they’re premised on new and exciting relationships as much as they are on research materials and anticipated scholarly outcomes. By devising this innovative and much-needed framework ofendings compliance,<a class="footnote-ref" href="#endingsprinciples"> [endingsprinciples] </a>the Endings Project team offers future new projects the opportunity to think on their own sustainability from the very start of any DH workflow. The Endings project team is also making difficult questions easier by offering a set of technical standards that can help emergent projects conceive of their endings right from the start without taking the many common missteps (expensive technical contracts, unreliable server-side software requiring endless updates) that they otherwise might.</p>
<p>In this paper I’d like to argue that in addition to thoughtful sustainability planning on the technical side, there is value in thinking with a literary perspective about digital humanities projects, about the stories and relationships we are making along with the websites, digital archives, databases, tools, marked-up texts, maps, and innumerable other digital artifacts that arise from large-scale collaborations in this field. The provocation I offer here is that applying some of the discursive analytical structures of literary genres to the construction of a digital project and foregrounding its human components of affect and relation can also show a team its ideal duration and ending. These matters require a multi-dimensional approach: we need to think beyond institutional repositories and mirror sites to consider the lived experience of project making and the structure of the stories we tell about digital work.</p>
<p>If we think about endings and about projects in a literary sense, we can analyze and read digital projects as the creative and multifaceted texts that they are and become. We can perhaps approach them with intention and care not only as technical artifacts but also as works that we’ve made, often along with a number of collaborators. Thinking through stories and endings also necessitates thinking about, with, and through time and then about how time manifests in projects. Here, too, narratives and genres can be illuminating. Some notable projects in my own field of literary modernist studies, The Modernist Journals Project<a class="footnote-ref" href="#latham2011"> [latham2011] </a>and The Orlando Project,<a class="footnote-ref" href="#brown2007"> [brown2007] </a>have decades-long stories involving hundreds of contributors and thousands of digitized artifacts. These are the digital humanitiesepics: they are long, they are ambitious, and they carry on sometimes through several generations of scholars. They are the kinds of resources that might be almost impossible for users ever to know in their totalities. Others, again drawing from modernist studies, like the Mina Loy project’s digitalflash mob,are momentary. These can perhaps be seen as thelyrics: short in duration, beautiful in their immediacy, able to be apprehended, perhaps, in a sitting. Is your project more like an 800-page Victorian doorstopper, or is it an aphorism? Perhaps even a haiku? There might of course be a wide array of other genres to consider: what might a digital humanities comedy look like, for instance? In more practical terms, how does the project relate to the PI and other collaborators’ own academic autobiographies? Will the project span a 35-year academic career and beyond, or a semester? Will the collaborators be life-long friends or collegial fleeting workplace acquaintances? If you know the type of project you’re making, not only in the more practical sense of TEI standards or approaches to versioning, but also the more epistemological questions about why this project exists and how its story will be shaped, it becomes possible to orient labour and personnel and even affective connections to the project<a class="footnote-ref" href="#evalyn2020"> [evalyn2020] </a>in a more intentional fashion that serves a clear purpose and design and, yes, has an ending in mind that suits its overall form.</p>
<p>One of the important points to make about the different possibilities for project genres is that they do not all have to be big, or long, or consuming in order to make significant contributions. During a panel discussion in the symposium that gave rise to this cluster of papers, Jessica Otis and Jim McGrath expressed theliberationthat they both had individually felt upon creating smaller projectsfor funthat might be completed ina season.These short-duration projects contrast with what Otis in her remarks during the discussion identified as the tacit expectation in DH of always undertaking “huge career shaping long term project[s].” Small projects can be beautiful, and they can be freeing.</p>
<p>Here I’m offering a more general meditation on the matter of project genres, of the narrative endings of digital projects, and of the characters involved in the stories of DH. However, my remarks are informed by having worked on different types of projects in recent years. Two in particular have led me to my thinking in this piece: The Modernist Archives Publishing Project (MAPP) (which I would consider, in this framework, an epic) and Make Believe: The Secret Library of M. Prudhomme (which feels more like a lyric). MAPP is a critical digital archive of early 20th-century publishing materials. The project began in 2013 and is ongoing. The team consists of six Co-Directors (Nicola Wilson, Alice Staveley, Helen Southworth, Elizabeth Willson-Gordon, and Matthew Hannah) who have formed friendships through this work. As literary scholars, we have been conscious of the need for narrative in the project from the start: we wrote a book together, <em>Scholarly Adventures in Digital Humanities</em> (2018), that told the scholarly story of how the project came to be and of the vision for our field that we wanted to realize in making it. We thought a lot about where we would store our images, our metadata, and our born-digital content for the long haul. We built in deliberate redundancies and we wrote sustainability plans. We thought very little, however, about the life of the project as a whole, beyond the digitalstuffwe were creating and beyond the sorts of things that are generally considered in technical terms when thinking about digital sustainability. We thought very little, in other words, about what it would mean for us personally to be five or ten or even fifteen years into a project like this. Like Elephant Gerald, we found and still find ourselves a little alarmed at the prospect of closing the metaphorical book, and the prospect has become more challenging the more our friendships have developed over the years. MAPP’s story has a happy continuation: we want to keep this thing going, we have all committed to it, and we have agreed that every five years we will reassess. We’ve also created a strong network of feminist intergenerational mentorship above and beyond the day-to-day requirements of the project. We support each other’s individual writing, we talk about our lives outside of work, and we look out for each other. We still want to keep this going, because we are having fun. As Sara Diamond put it in the discussion following our session at the Endings colloquium, “The affective bonds that form in creating these kinds of projects and archives are a really fundamental piece of the connective tissue and the survival [of the projects].” So fundamental that we can imagine, perhaps, that we may not in fact need to talk about endings to the affective or relational aspects of this kind of project work. Even if a website is no longer in active use, friendships and intergenerational mentorships can endure.</p>
<p>Nowhere was this more true for me than with the Make Believe project, a research creation/creative research/historical fiction/conceptual art project and was funded by a Canada Council New Chapter Grant 2017-19 and consisted of an in-person exhibition that took place over the course of a summer in 2019, accompanied by a digital exhibition to supplement the site-specific in-person experiences. There were over a hundred artists, writers, students, translators, librarians, and others who worked on the project in various capacities, but at the core was the intimacy of female friendship. Heather Jessup, Jillian Povarchook, and I made the project sitting at each other’s kitchen tables with babies in our laps. Heather and I had already been dear friends for many years, and the project came out of that friendship rather than the other way round. For that project, the ending was built into the project’s story from the start and we recognized it when it came: we knew that when we took down the physical exhibition from the Vancouver Public Library in August 2019, that was it. It was wild and exhausting and wonderful and fleeting, and making it with Heather and all of our amazing collaborators opened a little locked door inside me. It felt, in other words, like a perfect lyric.</p>
<p>While I hope the broader ideas in this short essay about the narrative and affective dimensions of project work will resonate beyond these two specific and personal examples, all of my work and thinking in DH has been informed by the sustaining collaborations at the core of each of these very different projects.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> In her call to action for a more humane approach to academic work, Kathleen Fitzpatrick suggests that “Grounding our work in generous thinking might […] lead us to place a greater emphasis on — and to attribute a greater value to — collaboration in academic life, and to understand how to properly credit all our collaborators. It might encourage us to support and value various means of working in the open, of sharing our writing at more and earlier stages in the process of its development, and of making the results of our research more readily accessible and usable by more readers” <a class="footnote-ref" href="#fitzpatrick2019"> [fitzpatrick2019] </a>. Part of this openness, I think, can be found in narrating some of these lived experiences. Openness of course is not always ideal, and complexity is always attendant on even the most fruitful and fulfilling of collaborations:Genuine generosity,Fitzpatrick reminds us, “is not a feel-good emotion, but an often painful, failure-filled process related to what Dominick LaCapra has called ‘empathetic unsettlement,’ in which we are continually called not just to feel for others but to simultaneously acknowledge their irreconcilable otherness” <a class="footnote-ref" href="#fitzpatrick2019"> [fitzpatrick2019] </a>. Lest I seem too optimistic about collaboration and its affective rewards, I would like to turn now to some of the fears and vulnerabilities that also can attend DH project work. As Jim McGrath pointed out in his symposium presentation, “actually liking your collaborators” is tremendously important, but “the challenge is making sure our employers are aware of our value/the value of those collaborations.” Too often the intangible values of collaborative practice are left out of discussions altogether.</p>
<p>No matter the genre, a digital project begins, and then its life proceeds and gets complicated. Of course, as project teams devise digital methods for exploring humanistic questions, they are often confronted with challenges and opportunities they would not have encountered were they writing a single-author monograph or creating a print edition. One such challenge, as the Endings Project team acknowledges, is defining the endpoint of the project in a digital environment that is by nature iterative and surrounded by a mythology of ongoingness and perpetuity. The print publishing process, conversely, naturally produces a moment of completion: a book is published and then it is out in the world and often that’s the end of the active day-to-day work on that particular project (leaving aside the “unfinished” nature of published textual artifacts which of course as a book historian I can never really leave aside). The developmental arc of the monograph is so well-established at this point that we’re used to it; it does not possess the same complexity as discussions of digital project endings. Much as the author might wish to continue to revise and augment a book after it’s done, the illusory fixity of the printed object at least imposes an artificial endpoint on the active work of the project. The existence of a physical object can also seem more definitive than any ending a digital project might devise or arrange for itself. The milestones in the life of a digital project — the launch of a website, say — are often possessed of a more malleable quality. One often launches a website with the idea that it will change and grow over time. However, the discourses of ongoingness and iteration in digital project work, while they do point to a truth about the type of media in question, have their limits. The edition release model<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> proposed by the Endings team creates, among other things, some narrative closure on particular phases of the project. It allows for the satisfaction of completion that is often absent from a moreagileapproach. The edition release also prevents slippage as digital project team members move through their careers — from PhD to postdoc to demanding jobs both within and outside the academy — and finding space for an ever-expanding and ever-continuing digital project within the team members’ individual careers can be a further challenge. Grant cycles come to an end, program centres open and close, and resources run out. Thinking about the long life of a project is twinned with thinking about the long future of an academic career, and even, these days, of the discipline.</p>
<p>One of the major factors that can turn DH practitioners into nervousElephant Geralds,reluctant to engage in future thinking and afraid of endings, is precarious labour conditions. These conditions, of course, are not specific to DH, nor are they particular to the academic profession, though they are endemic in it. Contract faculty now outnumber tenure-track faculty in Canada, and as Deidre Rose notes, “non-regular faculty constitute a reserve of low-paid and marginalized academic workers, and an increase in the number of doctorates granted each year in Canada guarantees a continuous supply of highly exploitable workers” <a class="footnote-ref" href="#rose2020"> [rose2020] </a>. The situation is even worse in the United States, as amply documented in scholarly literature and online<a class="footnote-ref" href="#childress2019"> [childress2019] </a>. This of course is not a new problem of capitalist work structures, though it is intensifying. In a 1997 talk at a gathering of economists in Grenoble, Pierre Bourdieu articulated the affective significance of increasing precarity in a capitalist system: “casualization,” he writes, “profoundly affects the person who suffers it: by making the whole future uncertain, it prevents all rational anticipation and, in particular, the basic belief and hope in the future that one needs in order to rebel, especially collectively, against present conditions, even the most intolerable” <a class="footnote-ref" href="#bourdieu1998"> [bourdieu1998] </a>. While Bourdieu is speaking in part of the difficulty and even danger for precarious workers in engaging in strikes and other labour actions, the effect can be more general too: preventingrational anticipationis also preventing considered approaches to futurity. Precarious labour conditions, Bourdieu suggests, have more than an economic effect: they lead at their most extreme to what he describes as “the destructuring of existence, which is deprived among other things of its temporal structures, and the ensuing deterioration of the whole relationship to the world, time and space” <a class="footnote-ref" href="#bourdieu1998"> [bourdieu1998] </a>. Narrative and endings are so deeply reliant on their connections to and structuring of time that any threat to that kind of order is necessarily perilous. Precarious conditions threaten to cut stories off before they can even begin.</p>
<p>Here, as in the domain of collaboration, affect becomes crucial to consider in thinking about digital projects as whole entities. However, the feelings associated with precarity are fearful and vulnerable ones that are more difficult to discuss and disclose. These are the tragedies of academia, the stories so painful they are hard to tell (although not speaking about them, as Bourdieu also notes, does not make them go away). Sometimes, as in my own experience through seven years of precarious work, the divergent affective dimensions of digital project work can create complexity: the constant fear and uncertainty of precarious labour can be counterbalanced by the positive collegial and friendly relations that collaborative work can foster. It becomes possible to survive precarious conditions with the help of friends, as Gerald the Elephant also finds in his sweet and affirming relationship with Piggie. And yet, the fear of endings looms large for all precarious workers. How can it be possible to plan for a reasonable project ending when doing so requires confronting the reality of an uncertain personal future? If we want sustainable projects, we need sustainable labour practices.</p>
<p>In the end, Gerald and Piggie devise a solution to their endings conundrum: they ask the reader to start the book again from the beginning, creating an endless loop of repetition. Starting again from the beginning would seem like a genuine nightmare for most digital project PIs and collaborators and is obviously not an advisable sustainability plan, so perhaps this is where the analogy between digital projects and the genre of comic children’s literature must end. It might, however, still be possible to draw encouragement from Elephant and Piggie’s collaboration: they make their way from the first page to the last in one another’s good company, finding their way together.</p>
<ul>
<li id="researchdata"> “Research Data Management” , _Social Sciences and Humanities Research Council_ , Government of Canada. Available at:<a href="https://www.sshrc-crsh.gc.ca/funding-financement/nfrf-fnfr/transformation/research_data_management-gestion_des_donnees_de_recherche-eng.aspx">https://www.sshrc-crsh.gc.ca/funding-financement/nfrf-fnfr/transformation/research_data_management-gestion_des_donnees_de_recherche-eng.aspx</a>.
</li>
<li id="endingsprinciples"> “Endings Principles for Digital Longevity” , _The Endings Project_ . Available at:<a href="https://endings.uvic.ca/principles.html">https://endings.uvic.ca/principles.html</a>.
</li>
<li id="bourdieu1998">Bourdieu, P. (1998). “Job Insecurity is Everywhere Now” , _Acts of Resistance: Against the New Myths of Our Time_ . Translated by R. Nice. Polity Press, Cambridge. pp. 81–87.
</li>
<li id="brown2007">Brown, S. et al. (2007) “The Story of The Orlando Project: Personal Reflections” , _Tulsa Studies in Women’s Literature_ 26.1 pp. 135–143.
</li>
<li id="carlin2018">Carlin, Claire et al. (2018) “Endings: Concluding, Archiving, and Preserving, Digital Projects for Long-Term Usability” , _KULA: Knowledge Creation, Dissemination, and Preservation Studies_ , 2(1), p.19. DOI:<a href="http://doi.org/10.5334/kula.35">http://doi.org/10.5334/kula.35</a>.
</li>
<li id="childress2019">Childress, H. (2019) _The Adjunct Underclass: How America’s Colleges Betrayed Their Faculty, Their Students, and Their Mission_ . University of Chicago Press, Chicago.
</li>
<li id="evalyn2020">Evalyn, L., et al. (2020) “One Loveheart at a Time: The Language of Emoji and the Building of Affective Community in the Digital Medieval Studies Environment” , _DHQ: Digital Humanities Quarterly_ 14.3. Available at:<a href="http://digitalhumanities.org/dhq/vol/14/3/000474/000474.html">http://digitalhumanities.org/dhq/vol/14/3/000474/000474.html</a>.
</li>
<li id="fitzpatrick2019">Fitzpatrick, K. (2019) _Generous Thinking: A Radical Approach to Saving the University_ . Johns Hopkins UP, Baltimore.
</li>
<li id="latham2011">Latham, S. (2011) “The Mess and Muddle of Modernism: The Modernist Journals Project and Modern Periodical Studies” , _Tulsa Studies in Women’s Literature_ 30(2), pp. 407–428.
</li>
<li id="rose2020">Rose, D. (2020). “A Snapshot of Precarious Academic Work in Canada” , _New Proposals: Journal of Marxism and Interdisciplinary Inquiry_ 11(1) (Summer 2020), pp. 7–17.
</li>
<li id="willems2010">Willems, M. (2010) _We Are in a Book!_ Hyperion Books, New York .
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>See<a class="footnote-ref" href="#carlin2018"> [carlin2018] </a>for an analysis of surveys and interviews of project directors, which indicated that the majority of those surveyed had not considered a specific end point for their DH project when they began to work on it.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>See Jessica Otis’s essay in this issue for an analysis of the American context.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>For the most recent information about data management requirements in the Canadian context, see “Research Data Management.”&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>And through the equally rich collaboration on the topic of DH pedagogy that I’ve shared for several years now with Shawna Ross.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>See “Release Management” in Holmes and Takeda in this volume for details of this approach.## Bibliography&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">A Keyword Analysis of Climate Change in Contemporary Literary Studies, 2000-2022</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000672/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000672/</id><author><name>Matt Morgenstern</name></author><published>2023-02-03T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>The Marxist scholar and critic Raymond Williams was one of the first to suggest the importance of keywords for literary studies. Originally published in 1976, Williams’s book <em>Keywords: A Vocabulary of Culture and Society</em> challenges conceptions of everyday terms through historical analysis. Specifically, Williams’s keywords demonstrate how shared discourse changes over time. As Williams notes, “When we come to say ‘we just don’t speak the same language’ we mean something more general: that we have different immediate values or different kinds of valuation, or that we are aware, often intangibly, of different formations and distributions of energy and interest” <a class="footnote-ref" href="#williams2014"> [williams2014] </a>. Studying conceptual keywords in this view not only enables insights into semantic shifts but also reveals how historically contingent conditions embed themselves within such shifts. As such, composing keyword entries revealed to Williams that “words which seem to have been there for centuries, with continuous general meanings, have come in fact to express radically different or radically variable, yet sometimes hardly noticed, meanings and implications of meaning” <a class="footnote-ref" href="#williams2014"> [williams2014] </a>. These insights have since generated a rich tradition of keyword analysis projects in the humanities, including but not limited to select critical theory books, the “Living Lexicon” series from the journal <em>Environmental Humanities</em> , as well as the <em>Keywords</em> series from New York University Press, which includes entries on disability, gender and sexuality, and environmental studies.</p>
<p>Since Williams, scholars have relied on keywords in reading, writing, and teaching. For many, a different kind of keyword engagement influences research methods. Keyword indexing in databases such as the Modern Language Association (MLA) International Bibliography facilitates access to published scholarship’s metadata. Selecting effective keywords on such databases enables the act of finding, citing, and responding to scholarship. Scholars interested in climate change, for instance, search databases for articles that effectively deal with the topic’s complexity, which, as Andrew Ross [<a href="#ross2016">2016</a>] notes, connects to historical ramifications for scientific knowledge and planetary, geopolitical conflict<a class="footnote-ref" href="#ross2016"> [ross2016] </a>. However, it is important to note for not only contemporary literary studies but also the digital humanities that disjunctions in database indexing impede digital access to scholarship. In this article, I explore how select academic journals from contemporary literary studies exemplify this disjunction through the occurrence ofclimate changeas a keyword. Applying the VOSviewer bibliometric analysis tool, I analyze thousands of unique citations in four academic journals representative of work in contemporary literary studies that scholars in the field consider trendsetters. Large datasets of bibliographic data allow us to survey scholarship through their indexed citations and authorial networks<a class="footnote-ref" href="#nolen2016"> [nolen2016] </a><a class="footnote-ref" href="#friedman2017"> [friedman2017] </a><a class="footnote-ref" href="#lei2019"> [lei2019] </a><a class="footnote-ref" href="#earhart2021"> [earhart2021] </a><a class="footnote-ref" href="#sanderman2021"> [sanderman2021] </a>. Digital bibliometric analyses therefore enable scaled-up analyses of how keywords impact precise framing of and engagement with indexed research.</p>
<p>The field of contemporary literary studies presents a valuable case study in how we categorize humanistic scholarship about climate change and related environmental issues because its scholarship reviews direct representations of climate change. Owing to established fields such as ecocriticism, the discipline enjoys many conferences, journal articles, and monographs dedicated to climate change<a class="footnote-ref" href="#streeby2018"> [streeby2018] </a><a class="footnote-ref" href="#deloughrey2019"> [deloughrey2019] </a><a class="footnote-ref" href="#houser2020"> [houser2020] </a><a class="footnote-ref" href="#fiskio2021"> [fiskio2021] </a>, and scholarship will only proliferate in the coming years. Digital humanists will thus benefit from looking at the use of keywords in contemporary literary studies. The field reflects ongoing some of the more significant developments in humanities scholarship on myriad environmental issues, including but not limited to climate change. Deriving insights from a bibliometric analysis of contemporary literary studies will, in turn, suggest new possibilities for indexing scholarship that encourage engagement and access. While I go into more detail about the results below, this project’s central purpose is to identify how climate change occurs as an object of scholarly inquiry in the humanities through its use as a keyword in contemporary literary studies.</p>
<h2 id="corpus-and-methods">Corpus and Methods</h2>
<p>The following sections encompass a bibliometric analysis of four journals from contemporary literary studies: <em>ISLE: Interdisciplinary Studies in Literature and Environment</em> ( <em>ISLE</em> ); <em>Contemporary Literature</em> ( <em>CL</em> ); <em>MFS Modern Fiction Studies</em> ( <em>MFS</em> ); and <em>PMLA: Publications of the Modern Language Association</em> ( <em>PMLA</em> ). I analyze the <em>ISLE</em> corpus as a reference case for the occurrence ofclimate changeas a keyword in a journal explicitly interested in environmental issues. With this corpus as a basis, I compare the other three corpora as benchmarks of contemporary literary studies scholarship. In selecting journals for analysis, I gathered indexed citations from journals with approximately 500-750 results in the MLA International Bibliography. These results derive from filtering out non-English language results and citations that occur prior to 2000. The <em>ISLE</em> corpus counts 665 unique citations; the <em>CL</em> corpus counts 620; the <em>MFS</em> corpus counts 763; and the <em>PMLA</em> corpus counts 1,964. Though I considered journals such as <em>Environmental Humanities</em> and <em>Resilience: A Journal of Environmental Humanities</em> as supplemental reference cases to <em>ISLE</em> , they were excluded because their indexed citation counts in the MLA International Bibliography were less than 500 at the time of data collection.</p>
<p>Although the periodization ofcontemporary literatureis highly contested<a class="footnote-ref" href="#martin2019"> [martin2019] </a>, my scope includes literature published from 1985 to the present while limiting scholarship on said literature from 2000 to early 2022. I adopt this timeline because I am most interested in scholarship that addresses recent representations of climate change that benefit from engagement (or lack thereof) with the past three decades of climate science. At the same time, I acknowledge that these journals — besides <em>ISLE</em> — do not tally significant counts ofclimate changeas a keyword because the topic was likely peripheral to their interests up until the last decade. However, I find them valuable test cases because they have since published on the topic and, thus, can be analyzed as a corpus with keyword connections that either do or do not reflect the topic’s many connections. With these variables in mind, I assembled each journal’s corpus, limiting their indexed citations in the MLA International Bibliography to English-language citations from 2000 to the present.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> I then exported the citations as research information system files to process with VOSviewer, a bibliometrics tool with modularity algorithms for visualizing author networks and keyword occurrence clusters<a class="footnote-ref" href="#janvaneck2022"> [janvaneck2022] </a>. I initially isolated keywords that occur at least ten times in the top fifty keywords across the run of journal articles and book reviews, removing keywords that convey period duration or generalist categories.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> I began with 10 keyword occurrences because that number suggests a keyword’s relative frequency in a corpus of at least 500 citations. If aclimate changecluster did not emerge at ten keywords, I decreased the occurrence count to five and, if necessary, one keyword to find the climate change keyword cluster. I simultaneously increased the top count in permutations of 50, 100, and 1,000, while decreasing the occurrence count (if a cluster does not emerge in the top fifty, it will emerge at subsequent scales). I followed these steps to determine the relative significance ofclimate changeas a keyword in each reviewed corpus.</p>
<p>While this article derives inspiration for bibliometric analyses elsewhere in literary studies<a class="footnote-ref" href="#goldstone2014"> [goldstone2014] </a>, it also follows bibliometric analyses in applied environmental sciences that propose new avenues for research<a class="footnote-ref" href="#haunschild2016"> [haunschild2016] </a><a class="footnote-ref" href="#zyoud2020"> [zyoud2020] </a><a class="footnote-ref" href="#xiao2021"> [xiao2021] </a>. Reconciling differences between these projects will inform framings of climate change in digital humanities research and points to the utility of digital interventions in the environmental humanities. Survey approaches of contemporary literary studies, ecocriticism, and the environment humanities precede this project, as we see in select articles from Ursula K. Heise [<a href="#heise2006a">2006a</a>] [<a href="#heise2006b">2006b</a>] [<a href="#heise2008">2008</a>] [<a href="#heise2013">2013</a>]. But because digital humanities tools can analyze thousands of citations in databases, scaled-up bibliometric analyses can determine common terms of engagement between otherwise disconnected disciplines. As such, I focus on climate change as a keyword because keywords such asclimate malaise,climate fatigue,andclimate perturbationare not commonly recognized. The project also must rely on the keywords provided by the indexers of the MLA International Bibliography:climate changeis the keyword because it is what appears on the database. I follow this parameter because climate change is a discursive mainstay, a keyword in the truest sense of Williams’s work. For example, a brief search for publications withEnvironmentin the Scopus database reveals the predominance of climate change as a keyword (both for authors and the database indexers) in pertinent research. Of 2,000 publications surveyed, selecting for at least 10 keyword occurrences, the keyword for climate change occurs in 188 articles with 723 links to other pertinent topics such ascarbon,drought,andclimate models(Fig. 1).<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>




























<figure ><img loading="lazy" alt="Screenshot of a network disgram. The network has large notes around words like Climate Change, Carbon, and China" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The node forclimate changein the Scopus corpus demonstrates its proximity to numerous topics important to not only the sciences but also the humanities.
        </p>
    </figcaption>
</figure>
<p>While not the leading keyword in the Scopus corpus (these beingarticle,controlled study,andnonhuman),climate changeis in the top 15, indicating its relative significance. As a keyword, then, climate change presents significant inroads for a variety of ecological issues with which literary studies, as well as the digital humanities, will benefit from informed engagement.</p>
<p>When evaluating the corpora, I do not critique any author, journal, or publisher for how a given citation does or does not employ certain keywords. This is in part because the MLA International Bibliography’s keyword selection process is unclear. The Modern Language Association’s website for the database notes the number of indexers who cite publications and the thousands oftermsthey use for indexing<a class="footnote-ref" href="#mla"> [mla] </a>, but does not mention if keywords derive from authors, journals, or other parties. I also do not know if the initial stage of keyword selection affects later indexing of pertinent metadata. I therefore survey this corpus of journal citations mindful of the many components that result in a keyword’s appearance in a scholarly database. The article’s conclusion considers how responding to these limitations may inspire more effective indexing practices for future digital environmental humanities projects, in addition to future contemporary literary studies and digital humanities scholarship (not to say that the two are distinct). These digital environmental humanities projects include not only analyses of emergent cultural forms<a class="footnote-ref" href="#buckland2018"> [buckland2018] </a><a class="footnote-ref" href="#joergensen2014"> [joergensen2014] </a><a class="footnote-ref" href="#musiol2021"> [musiol2021] </a>, but also ongoing conversations about how the digital humanities will respond to climate change through its methods, tools, and critiques of extant technologies<a class="footnote-ref" href="#nowviskie2015"> [nowviskie2015] </a><a class="footnote-ref" href="#posthumus2018"> [posthumus2018] </a><a class="footnote-ref" href="#travis2022"> [travis2022] </a>.</p>
<h2 id="reference-case-isle">Reference Case: ISLE</h2>
<p>Since its 1993 debut, <em>ISLE: Interdisciplinary Studies in Literature and Environment</em> (hereafter <em>ISLE</em> ) has served as a hub for environmental scholarship in literary studies. As its editors wrote in its first issue, <em>ISLE</em> ’s founding “reflects the rapid growth of ecological criticism in the United States in recent years, which in turn reflects the steady increase in the production of environmental literature and nature writing over the past several decades and the attendant increased visibility of such writing in college literature courses” <a class="footnote-ref" href="#glotfelty1993"> [glotfelty1993] </a>. At the time of writing, 29 volumes of <em>ISLE</em> have been published as part of the Association for the Study of Literature and environment. The journal’s mission statement pinpoints its influence as a pillar for literary studies: “Celebrating the rich confluence of environmental humanities, ecocriticism, and environmental justice, ISLE welcomes submissions from authors creatively engaging these fields from a broad range of disciplines, geographies, and perspectives. ISLE invites scholarly articles and creative writing that interpret the environment in complex, imaginative, and generative ways” <a class="footnote-ref" href="#isle"> [isle] </a>. Owing to the journal’s long publication history and dedicated interest in the ways cultural texts grapple with environmental issues, and how these issues are explored through such genres as climate fiction and ecopoetics, <em>ISLE</em> presents a fruitful archive for bibliometric analysis. I therefore refer to <em>ISLE</em> as areferencecase that generates an array of keywords for literary studies scholarship concerned with the environment.</p>
<p>The <em>ISLE</em> corpus presents multiple occurrences ofclimate changeas a keyword. The VOSviewer tool presents clusters that cohere around significant keyword occurrences at various scales. Links between clusters suggest the relative significance of keywords to other relevant topics of interest. An initial reading of the <em>ISLE</em> corpus suggests the significance of keywords (referred to assubject termsin the MLA International Bibliography) such asecocritical approach,american literature,andnature(Fig. 2), many of which characterize the initial stages of ecocriticism in the US.</p>




























<figure ><img loading="lazy" alt="Screenshot of a network diagram with large nodes around ecocritical, nature, american literature" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>An Overlay Visualization of keywords in the <em>ISLE</em> corpus. Nodes in darker shades of blue indicate older keywords, while nodes in brighter shades of yellow indicate newer keywords. The node betweenclimate changeandecocritical approachisenvironmental crisis.
        </p>
    </figcaption>
</figure>
<p>While these keyword clusters are the most frequent at a scale of 10 occurrences in the top 50, they are not the most recent. More recent clusters of significance includepostapocalyptic novel,environmental crisis,andclimate change.Theenvironmental crisiskeyword occurs 85 times, with 29 links to other clusters; theclimate changekeyword occurs 18 times with 13 links. As we can readenvironmental crisisin several ways, a discrepancy emerges between these two keywords in the <em>ISLE</em> corpus. Doesenvironmental crisisrefer to climate change, a mass extinction event, or something else entirely? Does indexingenvironmental crisispreclude the mention of “climate change,” making the keywords mutually exclusive?</p>
<p>Closer analysis of the <em>ISLE</em> clusters hardly distinguishes the keywords. Scaling down from ten to five keyword occurrences producesenvironmental crisisandclimate changenodes with more connections in the top 50: the former adds 23 links for a total of 52 connections while the latter gains three for a total of 16. The node forenvironmental crisislinks withmeat,petroleum industry,andsocial justice.The node forclimate changedoes not link to any nodes not already connected toenvironmental crisis,suggesting that the conceptual keyword ofenvironmental crisisincludes but is not limited toclimate change.Three <em>ISLE</em> articles in the corpus indexed withclimate changeare also indexed withenvironmental crisis<a class="footnote-ref" href="#schneidermayerson2019a"> [schneidermayerson2019a] </a><a class="footnote-ref" href="#rosenthal2020"> [rosenthal2020] </a><a class="footnote-ref" href="#dini2021"> [dini2021] </a>. Our empirical knowledge of climate change daily evolves with applied modeling and research,<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> and, whether in popular media coverage or in everyday conversation, we commonly do not associate the phraseenvironmental crisiswith ecological catastrophe more than we doclimate change.As a conceptual keyword,climate changeis commonplace among environmental humanists, scientists, and policymakers alike. At the same time, the conceptual keywordenvironmental crisismay lend itself to complexities thatclimate changedoes not present because the former touches on issues such as pollution, biodiversity loss, and changing ecosystems. These more specific problems and their local occurrences are not always direct effects of climate change. Consequently, indexing an article with the keywordenvironmental crisismay misrepresent its account of environmental issues that require further contextualization.</p>
<p>It should not surprise us thatclimate changeoccurs significantly in the <em>ISLE</em> corpus. Yet it is surprising that theenvironmental crisiscluster seemingly absorbs theclimate changecluster in that the former attaches to topics discussed in concert with climate science. Though I argue that the distinction betweenenvironmental crisisandclimate changeremains significant, the <em>ISLE</em> reference corpus presents a valuable example of wrestling with the two keywords as only two among many in its set. Now that we have seen a sampling of keywords from the <em>ISLE</em> corpus, we can see how these keywords emerge, or do not emerge, in the other corpora that are not exclusively concerned with the environmental humanities.</p>
<h2 id="test-cases-contemporary-literature-mfs-and-pmla">Test Cases: Contemporary Literature, MFS, and PMLA</h2>
<p>This section reviews the <em>Contemporary Literature</em> ( <em>CL</em> ), <em>MFS Modern Fiction Studies</em> ( <em>MFS</em> ), and <em>Publications of the Modern Language Association</em> ( <em>PMLA</em> ) corpora. While these journals have not historically foregrounded climate change as an object of inquiry, I look to their corpora to consider how their recent keywords reflect contemporary literary studies’ emergent interests in climate change. With the <em>ISLE</em> keywords as a reference for work elsewhere in literary studies, I am interested in analyzing how journals indexed in the same database do, and do not, engage similar and dissimilar keywords. I begin with <em>CL</em> , which publishes scholarly articles and book reviews. <em>CL</em> published the “first articles on Thomas Pynchon and Susan Howe and the first interviews with Margaret Drabble and Don DeLillo; it also helped to introduce Kazuo Ishiguro, Eavan Boland, and J. M. Coetzee to American readers” <a class="footnote-ref" href="#contemporaryliterature"> [contemporaryliterature] </a>. As of late, <em>CL</em> has also published ecocritical and environmental humanist scholarship. The most recent volume in the corpus includes articles that consider Black American conceptions of land use<a class="footnote-ref" href="#huehls2020"> [huehls2020] </a>, postapocalyptic environmental conditions in the novel <em>Red Plenty</em> <a class="footnote-ref" href="#singer2020"> [singer2020] </a>, and a review of scholarship on the Anthropocene and cultural production in the Global South<a class="footnote-ref" href="#samuelson2020"> [samuelson2020] </a>.</p>
<p>In the <em>CL</em> corpus,climate changeas a keyword occurs infrequently. At 10 occurrences in the top 50, noclimate changeorenvironmental crisisclusters occur. Scaling the corpus down further by selecting for five keyword occurrences in the top one hundred producesecocriticismandenvironmental crisisnodes quite distant from the network’s center (Fig. 3). Each cluster numbers six occurrences, indicating their relative insignificance in the corpus.</p>




























<figure ><img loading="lazy" alt="A screenshot of the network diagram from figure 2, zoomed in on the community around &#34;american literature&#34;" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Node forenvironmental crisisin an Overlay Visualization of the <em>CL</em> corpus. Note the node’s connection tonatureandecocriticismat the top of the graph.
        </p>
    </figcaption>
</figure>
<p>The occurrence ofenvironmental crisischanges at subsequent scales. Selecting for one keyword in the top five hundred,environmental crisisoccurs six times with eighteen links. Selecting for one keyword in the top seven hundred-and-fifty, the occurrence count ofenvironmental crisisremains the same but adds new links. A cluster forclimate changedoes not occur at any of these scales. We must scale down considerably to find a cluster: selecting for one keyword in the top one thousand registers a single occurrence ofclimate changewith four cluster links.</p>
<p>At first glance, these results corroborate the MLA International Bibliography’s listing of <em>CL</em> ’s citations: only one article in the last 20 years has been indexed withclimate change<a class="footnote-ref" href="#garrard2009"> [garrard2009] </a>.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> This does not mean the corpus does not include citations geared toward prominent environmental issues, as theenvironmental crisiskeyword surfaces when scaling down. The six citations indexed withenvironmental crisisare not indexed withclimate change,though they are indexed with important topics such asglobal warming,pesticide,poisoning,andviolence.In the corpus, these citations include both reviews<a class="footnote-ref" href="#didur2012"> [didur2012] </a><a class="footnote-ref" href="#irr2018"> [irr2018] </a><a class="footnote-ref" href="#bloomfield2019"> [bloomfield2019] </a><a class="footnote-ref" href="#samuelson2020"> [samuelson2020] </a>and articles<a class="footnote-ref" href="#chisholm2014"> [chisholm2014] </a><a class="footnote-ref" href="#vazquez2017"> [vazquez2017] </a>. Because theenvironmental crisiscluster in the <em>CL</em> corpus is attached to a constellation of topics, the corpus presents a notable discursive gap between the use ofenvironmental crisisandclimate change.If the latter is used seldomly, the former is used in reference to important topics that may, or may not, be discussed separately from climate change.</p>
<p>I now turn my attention to the <em>MFS</em> corpus. <em>MFS</em> publishes articles and book reviews concerned with twentieth- and twenty-first century literature on a quarterly basis, with an emphasis on modernist, postmodernist, and contemporary fiction. A journal with a prestigious publishing record of nearly 60 years, <em>MFS</em> is a benchmark publication for innovative debates and topics in contemporary literary studies. Of note to this article is the fact that <em>MFS</em> has published multiple special issues concerned with climate change and related environmental issues. These special issues include “Modern Fiction and the Ecological: The Futures of Ecocriticism” <a class="footnote-ref" href="#marzec2009"> [marzec2009] </a>, “Anthropocene Fictions” <a class="footnote-ref" href="#marzec2018"> [marzec2018] </a>, and “Literature and Extraction” <a class="footnote-ref" href="#amatya2020"> [amatya2020] </a>; the first special issue in that list published prominent environmental humanist Rob Nixon’s early writing onslow violence<a class="footnote-ref" href="#nixon2009"> [nixon2009] </a>.</p>
<p>Compared to the <em>CL</em> corpus, the occurrence ofclimate changeas a keyword in the <em>MFS</em> corpus differs greatly. The emergence of anenvironmental crisisnode at the scale of 10 keyword occurrences in the top 50 suggests the cluster’s relative significance. However, noclimate changecluster emerges. Scaling down to five keyword occurrences in the top fifty and top one hundred returns the same result. Scaling the corpus down to one keyword in the top five hundred produces aclimate changecluster with three occurrences and fourteen links to other keywords (Fig. 4). Several clusters related to the environment occur at this scale, includingecology,ecocritical approach,environmental movement,natural gas industry,petroleum industry,andplant imagery.</p>




























<figure ><img loading="lazy" alt="Screenshot of network diagram from figure 2, zoomed in on the community around ecocritical approach" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Bottom center location ofclimate changeas a keyword in an overlay visualization of the <em>MFS</em> corpus. Note the node’s size compared toenvironmental crisisin a nearly vertical position.
        </p>
    </figcaption>
</figure>
<p>Different keyword connections forclimate changeandenvironmental crisischaracterize their occurrence in the <em>MFS</em> corpus. While the former keyword primarily occurs around geopolitical clusters such asunited states imperialismandafghanistan war (2000-2021),the latter connects topetroleum industry,nature,andecocritical approach.While I do not mean to focus on these two keywords throughout the essay, these distinctions are worth noting, as many of theenvironmental crisisconnections are relevant to any literary studies account ofclimate change.Three citations appear that explicitly address climate change<a class="footnote-ref" href="#malewitz2015"> [malewitz2015] </a><a class="footnote-ref" href="#johnsputra2016"> [johnsputra2016] </a><a class="footnote-ref" href="#oh2020"> [oh2020] </a>; searching elsewhere in the corpus, citations withenvironmental crisisrepresent a range of important but different environmental issues.</p>
<p>Databases such as the MLA International Bibliography operate with directed user engagement, and the difference between keyword selection may elide opportunities for accessible engagement. Regarding such engagement in the <em>MFS</em> corpus, we can turn to Caroline Levine’s article “The Long Lure of Anti-Instrumentality: Politics, Aesthetics, and Sustainability” as an example of disjunctions in keyword indexing. Levine’s article asks readers to revise conceptions of literature’santi-instrumentalityin the context of climate change’s emergence<a class="footnote-ref" href="#levine2021"> [levine2021] </a>. Levine situates this argument for literature’s instrumentality in the context of extant issues such as climate migration, resource allocation, ecological degradation, and climate denialism and pessimism<a class="footnote-ref" href="#levine2021"> [levine2021] </a>, Levine’s article provokes new ways of thinking about climate change and contemporary literary studies in scholarship and pedagogy. In the MLA International Bibliography, Levine’s article is indexed with three keywords:themes and figures;aesthetics; andleft-wing politics.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Climate change is absent from this list. Yet the termclimateis used 18 times throughout the article, with 8 unique instances ofclimate change.In highlighting the indexing of Levine’s article, I do not aim to criticize any party for the absence ofclimate changeas a keyword; we should still read, consider, and cite the article regardless of how it is indexed. While reading through journals may remain the best way to assess their scholarship, many contemporary scholars instead rely on Googling, library search portal browsing, and databases. Scholars’ targeted research practices help them get what they need when they need it (especially when increased teaching loads and immensely reduced funding opportunities undermine research capacities), and precise keyword selection makes the difference. Yet the absence ofclimate changeas a keyword impedes our engagement with articles such as Levine’s that discuss it with significance.</p>
<p>My final test case, the <em>PMLA</em> corpus — which is significantly larger than either the <em>CL</em> or <em>MFS</em> corpora — publishes scholarship on a diverse range of fields and periods in literary studies, including contemporary literature. The journal’s active cultivation of novel approaches speaks to its importance, not only as the cornerstone publication of the Modern Language Association but also as a publication for established disciplinary conversations. As its website states, “The ideal  PMLA essay exemplifies the best of its kind, whatever the kind; addresses a significant problem; draws out clearly the implications of its findings; and engages the attention of its audience through a concise, readable presentation” <a class="footnote-ref" href="#pmla"> [pmla] </a>. <em>PMLA</em> is also a competitive site for submission: disciplinary journals may therefore not be as receptive to relatively new work, or even submissions from graduate students and junior scholars<a class="footnote-ref" href="#belcher2019"> [belcher2019] </a>. However, <em>PMLA</em> has published work relevant to contemporary literary studies, the digital humanities<a class="footnote-ref" href="#so2017"> [so2017] </a><a class="footnote-ref" href="#underwood2020"> [underwood2020] </a>, the environmental humanities, and even an early iteration of digital environmental humanities referred to as the “ecological digital humanities” <a class="footnote-ref" href="#cohen2015"> [cohen2015] </a>, even as much of the journal’s writing offers surveys of scholarship in their respective topics.</p>
<p>Starting with 10 keyword occurrences in the top 50, noenvironmental crisisorclimate changeclusters emerge in the corpus. The notable absence of climate change is still visible when we scale for at five keywords in the top fifty and top one hundred. At each of these scales, zero clusters emerge for topics associated with environmental issues. A cluster forclimate changeappears if we select for one keyword occurrence in the top five hundred: the keyword occurs six times and links with twenty-six additional clusters (Fig. 5).</p>




























<figure ><img loading="lazy" alt="Screenshot of network diagram focused on the word &#34;poetry&#34;" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>An Overlay Visualization ofclimate changeas a keyword in the <em>PMLA</em> corpus. The node (directly in the center) does not share significant associations with other clusters.
        </p>
    </figcaption>
</figure>
<p>Additional clusters associated with environmental issues emerge at this scale, includingnature,ecocriticism,landscape,and evenanthropocene epoch.In two unique citations,climate changeis indexed withnature; in two other citations, withweather(alsoseasons of the yearin one of those two); in another unique citation, withenvironmental studies; and, in a final unique citation,pollutionandindustrialization<a class="footnote-ref" href="#menely2012"> [menely2012] </a><a class="footnote-ref" href="#tait2015"> [tait2015] </a><a class="footnote-ref" href="#bronstein2019"> [bronstein2019] </a><a class="footnote-ref" href="#dimock2018"> [dimock2018] </a><a class="footnote-ref" href="#dimock2019"> [dimock2019] </a><a class="footnote-ref" href="#steer2021"> [steer2021] </a>. In the <em>PMLA</em> corpus, then,climate changeas a keyword enjoys distinct cluster connections that speak to different yet interconnected topics. For example, we have Philip Steer’s [<a href="#steer2021">2021</a>] recent article on nineteenth-century Britain, Australia, and the Anthropocene withclimate changeas a keyword.Environmental crisisoccurs as a keyword twice, and neither citation is indexed withclimate changeor the above terms<a class="footnote-ref" href="#hsy2016"> [hsy2016] </a><a class="footnote-ref" href="#malkmus2017"> [malkmus2017] </a>. Is there a tradition of selectingenvironmental crisisin lieu of or as complement toclimate changein <em>ISLE</em> , <em>CL</em> , and <em>MFS</em> but not in <em>PMLA</em> ? This difference may account for the concerns of field- or period-based journals versus disciplinary journals. <em>ISLE</em> , <em>CL</em> , and <em>MFS</em> publish scholarship with foci relevant to scholars; <em>PMLA</em> publishes scholarship with a broad focus for multiple fields. Regardless of their differences, each corpus presents different accounts ofclimate changeas a keyword.</p>
<h2 id="conclusion-keywords-and-digital-environmental-humanities">Conclusion: Keywords and Digital Environmental Humanities</h2>
<p>How fields such as contemporary literary studies and the digital humanities respond to climate change requires shared conceptual keywords that extend beyond disciplines. In the future, we may wish to derive inspiration for these terms from various keyword projects<a class="footnote-ref" href="#adamson2016"> [adamson2016] </a><a class="footnote-ref" href="#schneidermayerson2019b"> [schneidermayerson2019b] </a>. In addition, we may write a publicly available keyword selection guide for precise database indexing and engagement: Lauren Klein and Catherine D’Ignazio’s [<a href="#klein2020">2020</a>] discussion ofdatasheetsas a contextual tool for big datasets may serve as first step toward realizing this approach, encouraging what Johanna Drucker may refer to as a moresustainabledigital humanities praxis [<a href="#drucker2021">2021</a>]. In this case, I suggest a specific lexicon for environmental issues and how they connect to climate change. Although some may say that all humanities work is in some way imbricated in climate change<a class="footnote-ref" href="#mcdougall2022"> [mcdougall2022] </a>, I argue that only humanities work that explicitly addresses climate change should merit attention as climate humanities scholarship. For instance, an essay that addresses topics such as climate-induced biodiversity shifts, climate engineering, or climate fiction should be indexed with climate change only if the essay makes a significant connection between said topics and climate change. Such meaningful connections allow us to avoid the nebulousness ofenvironmental crisis,which does not offer as many interdisciplinary inroads. This is not to overlook the fact that keyword indexing can be an imperfect practice; however, I hope my results show that it can be standardized for renowned publications interested in publishing on the topic.</p>
<p>A systematic adoption of keywords, as Williams writes, grants us “a vocabulary to use, to find our own ways in, to change as we find it necessary to change it, as we go on making our own language and history” <a class="footnote-ref" href="#williams2014"> [williams2014] </a>. Whether one works in contemporary literary studies or the digital humanities (or both), following similarly determined examples of keyword selection will ensure continued collective meaning making in scholarly discourse. Students, scholars, and teachers interested in digital environmental humanities will also benefit from deliberate indexing choices. As the digital environmental humanities take on new, forms, effective indexing practices that precisely frame discussions of climate change in teaching, scholarship, and outward facing projects will enrich the field’s interdisciplinary significance. At the same time, becauseclimate changeis a phrase with meaning beyond academic indexing, it can be a keyword that encompasses diverse yet globally interconnected environmental issues; subsuming it within theenvironmental crisishierarchy only dilutes outward access to such scholarship.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>My thanks to Matt Hannah for feedback on the project in its many stages. My gratitude, as well, to the <em>DHQ</em> reviewers for their suggestions.</p>
<ul>
<li id="adamson2016">Adamson, J., Gleason, W.A. and Pellow, D.N. (eds.). _Keywords for Environmental Studies_ . New York University Press, New York (2016).
</li>
<li id="belcher2019">Belcher, W.L. _Writing Your Journal Article in Twelve Weeks, Second Edition: A Guide to Academic Publishing Success_ . University of Chicago Press, Chicago (2019).
</li>
<li id="bloomfield2019">Bloomfield, M. “Beyond Nature Poetry: Ecopoetics for a New Era,”  _Contemporary Literature_ , 60 (2019): 132-37.
</li>
<li id="bronstein2019">Bronstein, M. “Taking the Future into Account: Today’s Novels for Tomorrow’s Readers,”  _PMLA: Publications of the Modern Language Association of America_ , 134 (2019): 121-36.
</li>
<li id="buckland2018">Buckland, P.I., Dell’Unto, N. and Pálsson, G. “To tree, or not to tree? On the Empirical Basis for Having Past Landscapes to Experience,”  _Digital Humanities Quarterly_ , 12.3 (2018).
</li>
<li id="chisholm2014">Chisholm, D. “Juliana Spahr’s Ecopoetics: Ecologies and Politics of the Refrain,”  _Contemporary Literature_ , 55 (2014): 118-47.
</li>
<li id="cohen2015">Cohen, J. J. and LeMenager, S. “Introduction: Assembling the Ecological Digital Humanities,”  _PMLA: Publications of the Modern Language Association of America_ , 131.2 (2015): 340-46.
</li>
<li id="contemporaryliterature"> _Contemporary Literature_ [n.d.],<a href="https://uwpress.wisc.edu/journals/journals/cl.html">https://uwpress.wisc.edu/journals/journals/cl.html</a>(accessed January 4, 2023).
</li>
<li id="deloughrey2019">DeLoughrey, E.M. _Allegories of the Anthropocene_ . Duke University Press, Durham (2019).
</li>
<li id="didur2012">Didur, J. “Provincializing Ecocriticism,”  _Contemporary Literature_ , 53 (2012): 585-91.
</li>
<li id="dimock2018">Dimock, W.C. “Editor’s Column: Climate Humanists,”  _PMLA: Publications of the Modern Language Association of America_ , 133 (2018): 9-18.
</li>
<li id="dimock2019">Dimock, W.C. “Editor’s Column: Hanging with Chefs,”  _PMLA: Publications of the Modern Language Association of America_ , 134 (2019): 989-95.
</li>
<li id="dini2021">Dini, R. “‘Resurrected from Its Own Sewers’: Waste, Landscape, and the Environment in J. G. Ballard’s 1960s Climate Fiction,”  _ISLE: Interdisciplinary Studies in Literature and Environment_ , 28 (2021): 207-29.
</li>
<li id="drucker2021">Drucker, J. “Sustainability and complexity: Knowledge and authority in the digital humanities,”  _Digital Scholarship in the Humanities_ , 36.2 (2021): ii86-ii94.
</li>
<li id="earhart2021">Earhart, A.E., Risam, R. and Bruno, M. “Citational politics: Quantifying the influence of gender on citation in _Digital Scholarship in the Humanities_ ,” 36.3 (2021): 581-94.
</li>
<li id="fiskio2021">Fiskio, J. _Climate Change, Literature, and Environmental Justice: Poetics of Dissent and Repair_ . Cambridge University Press, Cambridge (2021).
</li>
<li id="friedman2017">Friedman, A. and Bernstein, J.H. “Measures of greatness: A Lotkaian approach to literary authors using OCLC WorldCat,”  _Library & Information Science Research_ , 39.3 (2017):180–188.
</li>
<li id="garrard2009">Garrard, G. “Ian McEwan’s Next Novel and the Future of Ecocriticism,”  _Contemporary Literature_ , 50.4 (2009): 695-720.
</li>
<li id="goldstone2014">Goldstone, A. and Underwood, T. “The Quiet Transformations of Literary Studies: What Thirteen Thousand Scholars Could Tell Us,”  _New Literary History_ , 45.3 (2014): 359-84.
</li>
<li id="dignazio2020">D’Ignazio C and Klein L. “Chapter Six: The Numbers Don’t Speak for Themselves.”  _Data Feminism._ Available at:<a href="https://data-feminism.mitpress.mit.edu/pub/czq9dfs5/release/3">https://data-feminism.mitpress.mit.edu/pub/czq9dfs5/release/3</a>(accessed January 4, 2023). (2019).
</li>
<li id="haunschild2016">Haunschild, R., Bornmann, L. and Marx, W. “Climate Change Research in View of Bibliometrics,”  _PloS One_ , 11.7 (2016).
</li>
<li id="heise2006a">Heise, U.K. “Greening English: Recent Introductions to Ecocriticism,”  _Contemporary Literature_ , 47.2 (2006a): 289-98.
</li>
<li id="heise2006b">Heise, U.K. “The Hitchhiker’s Guide to Ecocriticism,”  _PMLA: Publications of the Modern Language Association of America_ , 121.2 (2006b): 503-16.
</li>
<li id="heise2008">Heise, U.K. “Ecocriticism and the Transnational Turn in American Studies,”  _American Literary History_ , 20.1-2 (2008): 381-404.
</li>
<li id="heise2013">Heise, U.K. “Globality, Difference, and the International Turn in Ecocriticism,”  _PMLA: Publications of the Modern Language Association of America_ , 128.3 (2013): 636-43.
</li>
<li id="houser2020">Houser, H. _Infowhelm: Environmental Art and Literature in an Age of Data_ . Columbia University Press, New York (2020).
</li>
<li id="hsy2016">Hsy, J. “Language Ecologies: Ethics, Community, and Digital Affect,”  _PMLA: Publications of the Modern Language Association of America_ , 131 (2016): 373-80.
</li>
<li id="huehls2020">Huehls, M. “The Radical Conservatism of Black Rural Literature,”  _Contemporary Literature_ , 61.4 (2020): 431-59.
</li>
<li id="isle"> _ISLE: Interdisciplinary Studies in Literature and Environment_ (n.d.),<a href="https://academic.oup.com/isle/pages/About">https://academic.oup.com/isle/pages/About</a>(accessed January 4, 2023).
</li>
<li id="irr2018">Irr, C. “Contemporary Ecocriticism and the Weather,”  _Contemporary Literature_ , 59 (2018): 261-73.
</li>
<li id="janvaneck2022">Jan van Eck, N. and Waltman, L. _VOSviewer_ (n.d.),<a href="https://www.vosviewer.com/">https://www.vosviewer.com/</a>(accessed April 11, 2022).
</li>
<li id="johnsputra2016">Johns-Putra, A. “‘My Job Is to Take Care of You’: Climate Change, Humanity, and Cormac McCarthy’s _The Road_ ,”  _MFS Modern Fiction Studies_ , 62.3 (2016): 519-40.
</li>
<li id="joergensen2014">Jørgensen, F.A. “The Armchair Traveler’s Guide to Digital Environmental Humanities,”  _Environmental Humanities_ , 4.1 (2014): 95-112.
</li>
<li id="lei2019">Lei, L. and Liu, D. “Research Trends in Applied Linguistics from 2005 to 2016: A Bibliometric Analysis and Its Implications,”  _Applied Linguistics_ , 40.3 (2019): 540-61.
</li>
<li id="levine2021">Levine, C. “The Long Lure of Anti-Instrumentality: Politics, Aesthetics, and Sustainability,”  _MFS Modern Fiction Studies_ , 67.2 (2021): 225-46.
</li>
<li id="malewitz2015">Malewitz, R. “Climate-Change Infrastructure and the Volatilizing of American Regionalism,”  _MFS Modern Fiction Studies_ , 61.4 (2015): 715-30.
</li>
<li id="malkmus2017">Malkmus, B. “‘Man in the Anthropocene’: Max Frisch’s Environmental History,”  _PMLA: Publications of the Modern Language Association of America_ , 132 (2017): 71-85.
</li>
<li id="martin2019">Martin, T. _Contemporary Drift: Genre, Historicism, and the Problem of the Present_ . Columbia University Press, New York (2019).
</li>
<li id="mcdougall2022">McDougall, R., Ryan, J.C., and Reynolds, P. (eds) _Postcolonial Literatures of Climate Change_ . Brill, Leiden, The Netherlands (2022). 
</li>
<li id="menely2012">Menely, T. “‘The Present Obfuscation’: Cowper’s Task and the Time of Climate Change,”  _PMLA: Publications of the Modern Language Association of America,_ 127 (2012): 477-92.
</li>
<li id="mla"> _Modern Language Association_ (n.d.),<a href="https://www.mla.org/Publications/MLA-International-Bibliography/Frequently-Asked-Questions">https://www.mla.org/Publications/MLA-International-Bibliography/Frequently-Asked-Questions</a>(accessed January 4, 2023).
</li>
<li id="musiol2021">Musiol, H. “Beyond the Word: Immersion, Art, and Theory in Environmental and Digital Humanities Prototyping,”  _Digital Humanities Quarterly_ , 15.2 (2021).
</li>
<li id="nixon2009">Nixon, R. “Neoliberalism, Slow Violence, and the Environmental Picaresque,”  _MFS Modern Fiction Studies_ , 55.4 (2009): 443-67.
</li>
<li id="nolen2016">Nolen, D.S., and Richardson, H.A. “The Search for Landmark Works in English Literary Studies: A Citation Analysis,”  _The Journal of Academic Librarianship_ , 42.4 (2016): 453-58.
</li>
<li id="nowviskie2015">Nowviskie, B. “Digital Humanities in the Anthropocene,”  _Digital Scholarship in the Humanities_ , 30.1 (2015): i4-i15.
</li>
<li id="oh2020">Oh, R.S. “Making Time: Pacific Futures in Kiribati’s _Migration with Dignity_ , Kathy Jetñil-Kijiner’s _Iep Jaltok_ , and Keri Hulme’s _Stonefish_ ,”  _MFS Modern Fiction Studies_ , 66.4 (2020): 597-619.
</li>
<li id="pmla"> _PMLA_ (n.d.),<a href="https://www.mla.org/Publications/Journals/PMLA/Submitting-Manuscripts-to-PMLA">https://www.mla.org/Publications/Journals/PMLA/Submitting-Manuscripts-to-PMLA</a>(accessed April 11, 2022).
</li>
<li id="posthumus2018">Posthumus, S., Sinclair, S. and Poplawski, V. “Digital and Environmental Humanities: Strong Networks, Innovative Tools, Interactive Objects,”  _Resilience: A Journal of the Environmental Humanities_ , 5.2 (2018): 156-71.
</li>
<li id="rosenthal2020">Rosenthal, D.J. “Climate-Change Fiction and Poverty Studies: Kingsolver’s _Flight Behavior_ , Diaz’s 'Monstro,' and Bacigalupi’s 'The Tamarisk Hunter,'”  _ISLE: Interdisciplinary Studies in Literature and Environment_ , 27.2 (2020): 268-86.
</li>
<li id="ross2016">Ross, A. “Climate Change,” in Adamson, Gleason, and Pellow (2016): 37-41.
</li>
<li id="samuelson2020">Samuelson, M. “Thinking the Anthropocene South,”  _Contemporary Literature_ , 61.4 (2020): 537-49.
</li>
<li id="sanderman2021">Sanderman, E., Verhoeven, D. and Mandell, L. “The 21o3’N of separation of the Journal of Cultural Analytics: Mapping the first five years.”  _Journal of Cultural Analytics_ , September 21, 2021,<a href="https://culturalanalytics.org/post/1144-the-21-3-n-of-separation-of-the-journal-of-cultural-analytics-mapping-the-first-five-years">https://culturalanalytics.org/post/1144-the-21-3-n-of-separation-of-the-journal-of-cultural-analytics-mapping-the-first-five-years</a>(accessed January 4, 2023).
</li>
<li id="schneidermayerson2019a">Schneider-Mayerson, M. “Whose Odds? The Absence of Climate Justice in American Climate Fiction Novels,”  _ISLE: Interdisciplinary Studies in Literature and Environment_ , 26.4 (2019): 944-67.
</li>
<li id="schneidermayerson2019b">Schneider-Mayerson, M. and Bellamy, B.R. _An Ecotopian Lexicon_ . University of Minnesota Press, Minneapolis (2019).
</li>
<li id="singer2020">Singer, M. “The Future that Failed: Speculation and Nostalgia in Francis Spufford’s _Red Plenty_ ,”  _Contemporary Literature_ , 61.4 (2020): 483-504.
</li>
<li id="so2017">So, R.J. “All Models Are Wrong.”  _PMLA: Publications of the Modern Language Association_ , 132 (2017): 668-73.
</li>
<li id="steer2021">Steer, P. “The Climates of the Victorian Novel: Seasonality, Weather, and Regional Fiction in Britain and Australia,”  _PMLA: Publications of the Modern Language Association of America_ , 136.3 (2021): 370-85.
</li>
<li id="streeby2018">Streeby, S. _Imagining the Future of Climate Change: World-Making through Science Fiction and Activism_ . University of California Press, Oakland (2018).
</li>
<li id="tait2015">Tait, P. “Love, Fear, and Climate Change: Emotions in Drama and Performance,”  _PMLA: Publications of the Modern Language Association of America_ , 130 (2015): 1501-05.
</li>
<li id="travis2022">Travis, C., et al. (eds.) _Routledge Handbook of the Digital Environmental Humanities_ . Routledge, New York (2022).
</li>
<li id="underwood2020">Underwood, T. “Machine Learning and Human Perspective.”  _PMLA: Publications of the Modern Language Association_ , 135 (2020): 92-109.
</li>
<li id="vazquez2017">Vázquez, D.J. “Their Bones Kept Them Moving: Latinx Studies, Helena María Viramontes’s _Under the Feet of Jesus_ , and the Crosscurrents of Ecocriticism,”  _Contemporary Literature_ , 58 (2017): 361-91.
</li>
<li id="williams2014">Williams, R. _Keywords: A Vocabulary of Culture and Society_ . Oxford University Press, Oxford (2014).
</li>
<li id="xiao2021">Xiao, Y. Wu, H., Wang, G. and Mei, H. “Mapping the Worldwide Trends on Energy Poverty Research: A Bibliometric Analysis (1999-2019),”  _International Journal of Environmental Research and Public Health_ , 18.4 (2021): 1764.
</li>
<li id="zyoud2020">Zyoud, S.H. and Fuchs-Hanusch, D. “Mapping of climate change research in the Arab world: a bibliometric analysis.”  _Environmental Science and Pollution Research International_ , 27.3 (2020): 3523-40.
</li>
<li id="marzec2009">Marzec, Robert P. “Speaking Before the Environment: Modern Fiction and the Ecological,”  _MFS Modern Fiction Studies_ , 55.3 (2009): 419-42.
</li>
<li id="marzec2018">Marzec, Robert P. “Reflections on the Anthropocene Dossier,”  _MFS Modern Fiction Studies_ , 64.4 (2018): 585-616.
</li>
<li id="amatya2020">Amatya, A. and Dawson, A. “Literature in an Age of Extraction: An Introduction,”  _MFS Modern Fiction Studies_ , 66.1 (2020): 1-19.
</li>
<li id="glotfelty1993">Glotfelty, Cherryl B. “From the Editors,”  _ISLE: Interdisciplinary Studies in Literature and Environment_ , 1.1 (1993): 1-4.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>This corpus reflects the reviewed journal’s index counts as of January 24, 2022; it therefore does not include citations indexed after data gathering. The corpus is available for review on request.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>For each journal’s corpus, I removed select keywords that disproportionately impacted the visualizations. While select keywords do not occur in each corpus (unlike <em>CL</em> and <em>MFS</em> , <em>PMLA</em> ’s scope extends its range to medieval literary studies, which leads to keywords such as1500-1599and1600-1699), the listed keywords reappear frequently enough across corpora to justify exclusion:400-1499,1100-middle English,1500-1599,1600-1699,1700-1799,1800-1899,1900-1999,2000-2009,english language literature,fiction,prose,short story,andfilm.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>As of October 21, 2022.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Though well-documented across the globe, reports from the Intergovernmental Panel on Climate Change (IPCC) offer the most current scientific consensus on climate change.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>At the time of writing.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>At the time of writing.## Bibliography&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The case of the golden background, a virtual restoration and a physical reconstruction of the medieval Crucifixion of the Lindau Master (c. 1425)</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000663/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000663/</id><author><name>Liselore Tissen</name></author><author><name>Sanne Frequin</name></author><author><name>Ruben Wiersma</name></author><published>2023-02-03T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction--blue-or-gold-thats-the-question">Introduction – Blue or Gold, that’s the question.</h2>
<p><em>The Crucifixion</em> of the Master of the Lamentation of Christ in Lindau (which is part of the collection of Museum Catharijneconvent) is an early fifteenth-century panel painting (Figure 1). It shows Christ on the Cross with Mary and St John the evangelist mourning his death. Four angels catch his blood in golden chalices. The painting has a blue background decorated with golden tendrils. The painter has added a layer of plaster on the panel in order to create depth in this panel. In this layer, the space between the tendrils was cut away thus leaving the figures, the cross, and the tendrils in a slightly higher relief that it currently has with the now visible dark blue colored background.</p>
<p>The painting was in a bad condition and has stayed in the museum depot for decades. Its paint was obscured with dirt and yellowed varnish. Furthermore, it contained many discolorations, darkened retouches, and overpaints. When it was taken out of the depot for the <em>Body Language</em> exhibition (2020) of the museum the work was cleaned and a provisional restoration was carried out by restorer Caroline van der Elst<a class="footnote-ref" href="#museumcatharijneconvent2020"> [museumcatharijneconvent2020] </a>.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> During this process, an interesting discovery was made. The currently visible blue background of the panel originally was golden: golden shining tendrils were placed on a gold field (the gold field was done intremolierung, small scales, applied with a gouge) (Figure 2.). The blue azurite layer that remains visible today is old. It probably dates from the late sixteenth or early seventeenth century, yet it was not the original intention of the Lindau master.</p>
<p>This leads to an important dilemma in the restoration of the painting. Should the blue layer be removed as it is not part of the original work? This would mean a large and irreversible intervention in the painting, which opposes the ethics of conservation practice. To prevent this, the dark blue layer can also be maintained. It was applied not long after the creation of the work and it is therefore part of the life story of the painting. The owner of the work decided to have it painted over, perhaps because of a change of taste or perhaps a bad condition of the goldentremolierung.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> To remove it, is to remove this layer of meaning, or to put it differently, to remove this important life event of the painting. Yet, by preserving the blue layer, it is not possible to experience the earliest version of the painting.</p>
<p>Traditionally, the golden background of medieval panel paintings is connected to the divine space. Wölfgang Schöne aptly called it “the echo of Paradise” (Schöne, 1954). Another vein of scholars led by Ernst Gombrich has stressed the importance of the materiality, or, in his words: the “thingness” of gold<a class="footnote-ref" href="#gombrich1932"> [gombrich1932] </a>. The use of gold turned the average object into a precious material thing. Gold was a costly material, connected with other worlds via trading routes<a class="footnote-ref" href="#dunlop2009"> [dunlop2009] </a>. The material could be manipulated – using techniques like punch work or thetremolierungthat was used in the <em>Lindau Crucifixion</em> – in ways that wouldn’t be possible using tempera. One could argue that panel paintings with a golden background, manipulated to play with the light, are objects that linger between a representation of Paradise and physical reality. As David Young King puts it, the gold ground connects the material and the immaterial, the worldly and otherworldly<a class="footnote-ref" href="#kim2019"> [kim2019] </a>. The current version of the Lindau painting, with the blue obscuring thetremolierung, does not do justice to this pivotal role of the painting as the ambassador between the worldly and the divine both in materiality as in its symbolic meaning.</p>
<p>This report will not deliver the final answer to this complex question. However, we aim to propose a methodological solution that potentially can serve both sides of this discussion: a virtual restoration of the painting using a 3D scan and a 3D print of this restoration or the original work. In this project, for the first time, the virtual restoration of the work is presented as an argument that plays a role in the conservation process. Here we would like to share the steps we have taken so far and look into the future of this project.</p>




























<figure ><img loading="lazy" alt="Color photograph of the Lindau Master&#39;s _Crucifixion_ in its unrestored state, with blue background" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Master of the Lamentation of Christ in Lindau, <em>The Crucifixion</em> , ca. 1425. Tempera on panel, 125 × 89 cm, Museum Catharijneconvent – Courtesy of Museum Catharijneconvent
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="The Lindau Master&#39;s Crucifixion as it might have appeared when first made, with golden background" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Digital photo reconstruction where the azurite layer was removed and a golden background was added – Ruben Wiersma
        </p>
    </figcaption>
</figure>
<h2 id="capturing-the-current-state-of-_the-crucifixion_">Capturing the current state of <em>The Crucifixion</em></h2>
<p>The basis for the digital restoration of the Lindau Crucifixion was a 3D scan of the panel. To record the current state of the panel in terms of color and topography, the Lucida 3D Scanner was used<a class="footnote-ref" href="#factumfoundation2021c"> [factumfoundation2021c] </a>. This scanner was developed thanks to the collaboration between artist Manuel Franquelo and a team of professionals of different backgrounds (e.g. artists, architects, engineers, and software developers) from the Factum Foundation, a Spanish foundation specialized in digital recording of cultural heritage and in creating three dimensional facsimiles of recorded objects.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> The Lucida 3D Scanner is a close-range triangulation laser recording system. It provides a non-invasive method that documents the surface texture data of the artwork. The scanner projects a mechanically moving strip of red light onto the panel’s surface. The relief and curvature of the panel’s surface distort the light as it moves from left to right, completing scanning sections of about 48 x 48 cm. These deformations of the laser are captured by two cameras that are positioned 45° to the panel’s surface <em>normal</em> . These cameras take black and white videos of the laser’s trail, which are then processed as relief information into a grayscale depth map, using a geometric information system (GIS) and shaded render formats.</p>
<p>The combination of laser scanning and black and white video results in the capture of the panel’s topography at a high resolution (up to 100μm).<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> Furthermore, the scanner makes it possible to capture and unveil the topography of the panel without getting distorted and misled by its color or other material information. By relying upon the combination of laser and video information and the specific algorithms that were developed to interpret the video information, it becomes possible to scan highly reflective and glossy surfaces, such as the golden elements of the panel. This would not be possible when using a technology that solely relies on high-definition photography, such as photogrammetry or systems casting a fringe pattern. Furthermore, scanning the topography this way, it is easier to actually obtain more detailed data in deeper areas of the painting. With photographic methods relying on light sources, this information cannot be captured, meaning that the data of some of the depths relies on calculations rather than actual measurements.</p>
<p>A downside of this technology, in contrast to photographic methods, is the fact that the color information of the panel had to be recorded separately. This was done by using panoramic photography in combination with a two-direction lighting system. In contrast to “regular” parallel photography where each image is taken with its own view point, the panoramic method uses a single point from which the whole surface is recorded in smaller sections, arranged as a mosaic of rows and columns<a class="footnote-ref" href="#factumfoundation2021d"> [factumfoundation2021d] </a>. This makes recording fast (approximately one hour per 4 square meters, resulting in a file with a resolution of around 600 dpi) and efficient. Reflections are avoided by creating neutral lighting by using two strobe lights and the colors are balanced with the help of an X-rite color checker among other control methods. The separate color photographs (tiles) are automatically aligned and stitched into one full color map with PTGui. We store the geometry of the panel as a heightmap. This representation fits the surface of the panel, is lightweight, and allows users to process the data with image processing software, such as Photoshop. This way, the geometry and shading derived from the geometry can be blended with the color map.</p>
<p>The color information was combined with the heightmap that was recorded by the Lucida Scanner into the final 3D model. The Lucida&rsquo;s capacity of working with 3D information as grayscale depth map images, avoids the need of working with cloud points or polygon meshes. Combining color information with a 3D scan is much more efficient using a GIS map and the final model can be edited easily, making this a user-friendly method of 3D scanning (Figures. 3,4,5.).</p>
<p>Additionally, the digital model will be supplemented with data resulting from other types of material research that will be carried out during the conservation process of the painting (e.g. X-ray, ultraviolet, infra-red analyses)<a class="footnote-ref" href="#factumfoundation2021a"> [factumfoundation2021a] </a>.<br>




























<figure ><img loading="lazy" alt="Detail of the Lindau Master&#39;s _Crucifixion_ featuring an angel, with blue background. Depth of plaster bas-relief is not shown." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color photograph – Made by Factum Foundation
        </p>
    </figcaption>
</figure></p>




























<figure ><img loading="lazy" alt="Detail of the Lindau Master&#39;s _Crucifixion_ featuring an angel, in greyscale and showing plaster bas-relief." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>3D shaded heightmap – Made by Factum Foundation
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Detail of the Lindau Master&#39;s _Crucifixion_ featuring an angel, with color and bas-relief." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color and height combined Color photograph – Made by Factum Foundation
        </p>
    </figcaption>
</figure>
<h2 id="processing-the-virtual-reproduction">Processing the virtual reproduction</h2>
<p>The 3D model of the painting was the basis of the virtual restoration of the work to its earlier state with the golden background. Not only the appearance (now blue, originally gold leaf) had to be restored, also the geometry (tremolierung) had to be adapted. The blue over paint has filled thetremolierungs lacunae, and made them less deep than they originally were.</p>
<p>We created a virtual copy of the painting that could be rendered in real-time. The low-frequency geometry, such as the large-scale curvature of the panel, was mapped to a planar mesh with 16x16 quads. High frequency details were applied to the mesh with normal mapping, yielding a convincing virtual object suited for real-time applications<a class="footnote-ref" href="#blinn1978"> [blinn1978] </a>.</p>
<p>The panel was rendered using Blender’s Eevee renderer for real-time rendering and Cycles for offline, ray-traced rendering.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> It can be transported to other programs and into VR and AR applications using a universal scene description file<a class="footnote-ref" href="#elkouraetal2019"> [elkouraetal2019] </a>. The appearance of the materials in the painting were modeled with a GGX-based principled BSDF, which allows the user to set material properties such as base color, metallicness, and roughness<a class="footnote-ref" href="#walteretal2007"> [walteretal2007] </a>.</p>
<p>To virtually restore the object, we assigned both the appearance and geometry masked regions. Mask A is the set of all points that were originally painted with gold leaf and mask B ⊂ A only contains the regions withtremolierung. These masks were created by selecting all pixels with a color within a certain distance to the color of a representative pixel in thetremolierungregion and corrected manually.</p>
<p>The appearance for mask A was adjusted by setting the base color to an ochre yellow blended with imperfections modeled with Perlin noise<a class="footnote-ref" href="#perlin2002"> [perlin2002] </a>. The metallic property was set to 1 and roughness property to 0.6. All other regions were given the base color from the Factum scans, metallic property of 0 and roughness set to 0.4. The appearance was validated by the restorer of the painting Caroline van der Elst.</p>
<p>The geometry in mask B was adjusted to approximate a reconstruction of thetremolierungpattern. We opted for a simple intervention: scaling and offsetting the geometry, which is equivalent to increasing the contrast of the height map. This approximates the removal of a layer of paint. In future work, we aim to virtually recreate thetremolierungpattern using geometry processing techniques and to investigate the use of the virtual model to situate the piece in its original setting.</p>
<h2 id="the-3d-printed-facsimile">The 3D printed facsimile</h2>
<p>Based on the previous explanation, it can be stated that 3D scanning the panel’s materials will contribute to documenting highly detailed information about the artwork. Moreover, it digitalizes the panel in such a way that we can modify, manipulate and alter it to our own liking without having to alter the original work. This way, it becomes possible to visualize potential outcomes of future conservation treatments. In our case, we were able to reconstruct the original appearance of the painting, with the golden background.</p>
<p>Subsequently, this data can be translated into 3D printable data, which makes it possible to create an exact reproduction of the panel in various stages. In this research two versions will be made: oneas-iswith the blue background and one with the appearance (gold) and the geometry (tremolierung) texture restored. The first phase of the creation of an exact 3D replica, is making an elevated print (a technique developed by Canon Production Printing, Venlo).<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> This technology uses computer data – the grayscale depth map – which is translated into a printable format. This digital information is combined with a 3D printing technique called material jetting, which involves hardening a material of choice (in our case polymer) by exposing it to ultraviolet (UV) light. This way, the panel’s relief can be created by printing layer upon layer of plastic until the right height is reached. Elevated printing thus allows for a highly detailed reproduction of textures.</p>
<p>The second phase is the application of color. The polymer that is used in this process has a light gray color. To reconstruct the polychromy of the painting, it is possible to print the last layer in color. Additionally, layers of transparent ink can be added to achieve some glossiness on the surface. Although the developments in improving the quality of these 3D color prints are promising, there still are some limitations to overcome. One major issue is the quality of color. As this technology uses inkjet printing and the curing of photopolymers, the colors achieved are not complex and as a result of the heating process, the color can look grainy. Furthermore, the material is very stiff, which results in an artificialfeelof the reproduction.</p>
<p>The aim of this project is an exact 3D replica of the painting in its current, and in its restored state. The current quality of the inkjet printing does not yet meet our demands for this project.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> To overcome these issues our partner Factum Foundation has found a solution. The elevated printing is used to create the topography of the painting. This is done by using the uncolored elevated print as a positive to create a mold. This mold is then used as a negative, for another positive that consists of a silicon solution, a more flexible material. This monochrome siliconprintis a basis on which a separately printed two dimensional high quality color image of the artwork is attached. Lastly, to make the material appearance more convincing, paramount features of the artwork’s material appearance (e.g. glossiness, varnish) are added manually. In the case of the Lindau <em>Crucifixion</em> , the background of the two facsimiles will be gilded manually.</p>
<h2 id="the-meaning-of-material">The meaning of material</h2>
<p>The creation of exact reproductions using elevated printing generates the opportunity of visualizing and physicalizing the potential effects of decisions made and treatments done during the restoration process. It allows us to think about the way this 3D print could provide a solution to the important dilemma in the restoration of the painting and whether or not the blue layer be removed as it is not part of the original work. Could the 3D print help in understanding and discussing the complexities of this discussion within the field of art restoration. Additional questions that automatically come to mind are: What this type of reproduction means to the original panel? In what way does this second physical manifestation of the panel (in its current blue and its earlier golden state) contribute to the understanding of the original artwork? How does 3D printing a panel affect the value of the original? Could the 3D print potentially have its own value at some point?</p>
<p>The authenticity of art and the role of facsimiles – which are everything but original, and are often considered as anti-authentic – has been a heated topic of debate ever since German sociologist Walter Benjamin<a class="footnote-ref" href="#benjamin1936"> [benjamin1936] </a>described how reproduction (in his case photography) changes artworks’ historic value – in Benjamin&rsquo;s words: “aura” – into one of exhibition value<a class="footnote-ref" href="#benjamin1936"> [benjamin1936] </a>. It has lost its artistic relevance and connections to the past. Contemporary Western society has been highly fixated on themagicalencounter with the physical original artwork. Nowadays, art reproductions are omnipresent (e.g. on mobile devices and posters). The discussion that Benjamin started has gained momentum and still continues to grow (<a class="footnote-ref" href="#jones2010"> [jones2010] </a>;<a class="footnote-ref" href="#latour_lowe2011"> [latour_lowe2011] </a>;<a class="footnote-ref" href="#tissen2020"> [tissen2020] </a>;<a class="footnote-ref" href="#tissen_malik_vermeeren2021"> [tissen_malik_vermeeren2021] </a>;<a class="footnote-ref" href="#digiuseppantoniodifranco_galeazzi_vassallo_2018"> [digiuseppantoniodifranco_galeazzi_vassallo_2018] </a>). There has been an increase in theorists specifically examining the moral and ethical implications of art reproduction. A reason for this might be the rapid development of advanced reproduction technologies such as 3D printing. In today’s world offake news, not knowing what to believe and where to find the truth when information is at our disposal at any time and any place, the material qualities of original artworks, carefully guarded in the museum seem to be the one of the only sources that can validate an artwork — the survivor of the passage of time — as genuine. Consequently, in conservation practice this has resulted in the prevalent goal to keep and conserve as much of the artworks&rsquo; material features as possible in their current state — thus includingpatina, cracks, losses and other material traces of time — for generations to come. This means that any form of treatment should be done in favor of its original materials and implies that treatment should be reversible, in the case that better conservation methods are discovered and can be applied.</p>
<p>With this information in mind, how can a 3D print, a visually indistinguishable copy yet one without the material features of the artwork itself, mean something to the original artwork? In the case of the Lindau <em>Crucifixion</em> , it is precisely the materiality of the artwork that poses the dilemma. As previously described, the biggest issue we are currently facing during the restoration of the panel is the decision regarding the appearance of its background. During a seminar <em>The digital reconstruction of the crucifixion of the Lindau master (ca. 1425)</em> (held on the 9th of June 2021 at Museum Catharijneconvent (Utrecht)) we presented this dilemma to a group of professionals from different backgrounds (curators, restorers, (technical) art historians, and art scholars) and the online participants<a class="footnote-ref" href="#tissen2021"> [tissen2021] </a>.</p>
<p>3D scanning the panel’s materials and the possibility to 3D print exact reproductions generate the opportunity of visualizing and physicalizing the potential effects of decisions made and treatments done during the restoration process in two ways. Firstly, by using the 3D print, the blue background can be documented and physicalized before it would be lost, due to an irreversible restoration of the painting’s background to the earlier version. Secondly, when the decision would be made to maintain the blue azurite layer, the 3D print could be used to show a reconstruction of the painting to the primary version without the azurite blue layer that is currently covering the golden background. We asked the participants whether or not the azurite blue should be removed and what role a 3D print of the panel could function as a solution for this issue. Here, when proposing these options, in the discussion it soon became evident that the panel’s value cannot be solely attributed to its material qualities. In this report we would like to reflect on two arguments considering theauthenticityof the 3D print that came up during the discussion.</p>
<p>The first important aspect of authenticity mentioned was the intention of the artist, which is oftentimes a highly valued quality<a class="footnote-ref" href="#martens2010"> [martens2010] </a>. In the case of the panel, the Master of Lindau himself initially decided to fully gild the panel’s background. When this intention is considered of utmost importance, this would imply that the 3D print with the reconstruction of thisoriginalbackground with the gold leaf in itself could be considered more valuable than the panel in its current state, with the blue. The latter does not visually simulate what the Master would have intended, and thus one could argue that the 3D printed reconstruction of the golden background is closer to the artist&rsquo;s original intentions than the panel in its current state, thus more significant in terms of authenticity.</p>
<p>Furthermore, another participant mentioned, what should be remembered when looking at original artworks (or at their facsimiles), is that the artwork’s current state is just a snapshot of a single moment in time. Artworks have their own lifecycle which spans over decades if not centuries, not only in their material composition but also in their function, communal and social value. Their conceptual value is not set in stone, it changes over time. This way, an artwork knows manyfacesoridentities. With the help of conservation methods, it can be decided to freeze the panel’s material appearance. But this does not do justice to the lifecycle of the artwork. An example of how reconstructions can help to demonstrate this lifecycle is the recently revealed reconstruction of missing parts of Rembrandt van Rijn’s <em>The Night Watch</em> at the Rijksmuseum (Amsterdam)<a class="footnote-ref" href="#rijksmuseum2021"> [rijksmuseum2021] </a>. For centuries the public has looked at a mutilated version of this painting. In the case of the Night Watch, the reconstruction has revealed an earlier, lost identity of the art work.</p>
<p>Both arguments show that reproductions of artworks and especially the high-quality 3D printed facsimiles can contribute to visualizing and physicalizing the elements that contribute to the diversity of identities one artwork can have. The authenticity of <em>The Crucifixion</em> is not static and solely based on the original panel’s unique materials alone. In contrast, the discussions during the symposium showed that the panel’s authenticity is considered diverse, it changes over time and it can be attributed to many different elements (e.g. the intention of the artist and changes in materiality). Reproductions of artworks and especially the high-quality 3D printed facsimiles can contribute to visualizing and physicalizing the elements that contribute to the diversity of values,authenticities, and identities one artwork can have, such as its artistic and conceptual value to name a few<a class="footnote-ref" href="#latour_lowe2011"> [latour_lowe2011] </a>. As the original artwork can only represent one specific moment in time due to its unique material, 3D printed reproductions can be used in addition to the original artwork to express its life cycle and multiplicity of values.</p>
<p>The question that arises in this case and which we hope to solve using the 3D prints, is which version will be considered to be more genuine orauthentic: would this be to present the painting in its current state, conserving its materials the way it looks today and by considering the blue layer as a part of its history? Or to irreversibly remove the azurite layer, but coming closer to the way the Master would have wanted the panel to look and in a way more similar to the way the artwork was experienced during the Middle Ages? This relates to the question if the availability of a high quality facsimile of one over these versions will play a role in the conservation process? How will the restoration committee weigh the availability of both versions in their decision on what conservation treatment will be applied to the panel?</p>
<h2 id="discussion">Discussion</h2>
<p>Within this research, we want to use a 3D facsimile to see whether visualizing a past state of an artwork can help to get a better understanding of the material changes an artwork goes through, which might aid the final restoration of the original. Although it is a high-quality reproduction based on detailed 3D data and extensive material research opting to be as scientifically close to the original painting as possible, it is important to realize that a facsimile will and can never be identical to a previous state of the artwork. For this reason, it is essential to pinpoint where the differences lie. First and foremost, a synthetic 3D print is different in terms of materials and could therefore never provide an exact and accurate model of the panel in a previous state.</p>
<p>Furthermore, although the way the facsimile looks is partly based on accurate measurements, it will always be abest guess. However, the same can be said in the case of the actual restoration of the original for the interpretation of the past is always subjective and place and time dependent<a class="footnote-ref" href="#stols-witlox2021"> [stols-witlox2021] </a>. Consequently, both the 3D prints as well as the original represent the object in a specific moment in time: one 3D print will show the artwork before the restoration; one 3D print will show a reconstructed version of what we think the artwork must have looked like in 1425; the painting itself will show a restored version of the panel. Although the facsimiles make it possible to visualize multiple stages of the artwork’s lifecycle, it simultaneouslyfreezesthem in time. Subsequently, all threetime-freezeswill impact the way the artwork will be perceived and interpreted for the years to come. For this reason, similarly to the actual restoration, the way the 3D reconstructed version looks must be carefully discussed. For instance, one could question that if the background would be reconstructed to apristinestate, should the figurines and the tendrils be reconstructed as well? Or since the figurines and the tendrils are weathered, to what extend should the golden background be adjusted? Simultaneously, the same kinds of questions can be asked in terms of storytelling and explaining the context in which this artwork was made. Do we know how the artwork was used and how it was displayed?</p>
<p>Yet, we want to emphasize that although the 3D print might not be exactly accurate to the original’s current or past state, it meets the inquiry central to this research project<a class="footnote-ref" href="#fors_principe_sibum2016"> [fors_principe_sibum2016] </a>. Furthermore, we believe that using reproduction and visual reconstructions could be greatly beneficial to get a better and more life-like idea of how the artist and his contemporaries must have experienced the artwork. This way, not only researchers and conservators can understand the inquiries central to the conservation of art, but also the public can get an insight in the difficulties of restoring this panel.</p>
<h2 id="future-works">Future works</h2>
<p>Currently, after recording the panel’s colors and topography, we are aiming to continue this research by processing the data. By researching the artwork’s materials (e.g. using dendrological research, IRR, MA-XRF scanning), damages, art historical past, and by relying on the knowledge of the restorer, we will analyze the digital model on its accuracy. This way, we can combine the digital data gathered by Factum Foundation with the knowledge of the professionals involved in the conservation to come to a digital model which most accurately presents the current and past state of the panel. We aim to explore how we can combine different modalities to learn more about the materials and stratigraphy of the panel. This could be used to study the effect of changes in material composition.</p>
<p>Consequently, multiple printed facsimiles of the artwork will be made to see the physical effects of digital changes made to the materials. Two 3D prints will be made by Factum Foundation in collaboration with the restorer of the painting, Caroline van der Elst. She will be involved with the digital restoration and will check the facsimiles to make the final material appearance correspond to what the panel originally must have looked like. Additionally, in collaboration with Canon Production Printing, we will try to create a third 3D printed facsimile without the post-printed craftsmanship (the retouchings of the restorer). This way, we aim to analyze both the digital model as well as the 3D printing technology’s ability to correctly reconstruct the material appearance of the panel. The 3D prints will be useful in communicating the dilemma to a larger audience (of both professionals and non-professionals) and will help in making the multifaceted authenticity of the artwork more clear during a potential exhibition about this project. Additionally, perception research done during this event and using the 3D prints will provide insight into the perception of the artwork and the potential effects of removing the background.</p>
<p>The two accurate 3D prints of Factum Foundation of both versions of the painting also allow the investigation of the perception of the artwork. An eye tracking experiment will be conducted to analyze the viewing experience of the visitor, regarding the two versions of the artwork. The eye tracking research will be combined with the think aloud-method, in which raw eye-tracking data is supported with qualitative data based on the conversations of the participants. We will focus on the effect of the light source (stable / unstable) on the perception of both versions of the painting. A hypothetical difference in perception is the appearance of the blood of Christ in the painting. Using an unstable light source (e.g. flickering candle-light), the contrast between the shine of the full golden background and the matte red tempera used for the blood could mean a better visibility and thus a stronger symbolic presence, in comparison to the current blue background. The perception research using the 3D prints will provide insight in the perception of the artwork and the potential effects of removing the background. This, together with the high quality of the reproductions, will be highly important for the final restoration of <em>The Crucifixion</em> .</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>This project is done in collaboration with Museum Catharijneconvent, Delft University of Technology, Leiden University, Utrecht University, and The Factum Foundation.</p>
<p>The authors would like to extend their sincere thanks to Carlos Bayod of the Factum Foundation for reviewing the technical information; Micha Leeflang as the representative of Museum Catharijneconvent; Caroline van der Elst for restoring this artwork; Clemens Weijkamp of Canon Production Printing for the elevated printing; Stichting Rembrandt, Leiden University Centre for the Arts in Society and LDE – Centre for Cultural Heritage and Development, The Netherlands Institute for Conservation+Art+Science+ for making this project possible.</p>
<ul>
<li id="benjamin1936">Benjamin, W. (1936) _The work of art in the age of mechanical reproduction_ (J. A. Underwood, Trans. 2007). Penguin Books.
</li>
<li id="blendercommunity2018">Blender Community (2018) _Blender – a 3D modelling and rendering package_ . Stichting Blender Foundation, Amsterdam. (Retrieved from<a href="http://www.blender.org">http://www.blender.org</a>20 March 2022)
</li>
<li id="blinn1978">Blinn, J.F. (1978) “Simulation of wrinkled surfaces” , _Proceedings of the 5th annual conference on Computer graphics and interactive techniques_ , 286–292
</li>
<li id="cohen1998">Cohen, J.D. (1998) _Appearance-preserving simplification of polygonal models_ . PhD thesis, (Chapel Hill: The University of North Carolina)
</li>
<li id="digiuseppantoniodifranco_galeazzi_vassallo_2018">Di Giuseppantonio Di Franco, P., Galeazzi, F., and Vassallo, V., eds. (2018) _Authenticity and cultural heritage in the age of 3D digital reproductions_ . McDonald Institute for Archaeological Research, University Cambridge.
</li>
<li id="dunlop2009">Dunlop, A. (2009) “Materials, Origins and the Nature of Early Italian Painting” , in _Crossing Cultures: Conflict, Migration and Convergence_ , ed. Jaynie Anderson (Carlton, 2009): 472–76.
</li>
<li id="elkouraetal2019">Elkoura, G., Grassia, S., Boonyatera, S., Mohr, A., Jeremias-Vila, P., and Kuruc, M. (2019) “A deep dive into universal scene description and hydra” , _ACM SIGGRAPH 2019 Courses,_ 1–48.
</li>
<li id="factumfoundation2021a">Factum Foundation. (2021) _High resolution image viewer of the Crucifixion_ ,<a href="https://www.highres.factum-arte.org/Utrecht_Crucifixion_Panel/shared/viewer.html">https://www.highres.factum-arte.org/Utrecht_Crucifixion_Panel/shared/viewer.html</a>[accessed 09 September 2021]
</li>
<li id="factumfoundation2021b">Factum Foundation. (2021) _High resolution image viewers_ ,<a href="https://www.factumfoundation.org/high-resolution-multi-layered-viewers">https://www.factumfoundation.org/high-resolution-multi-layered-viewers</a>[accessed 09 September 2021]
</li>
<li id="factumfoundation2021c">Factum Foundation. (2021) _Lucida 3D scanner_ ,<a href="https://www.factumfoundation.org/pag_fa/1478/lucida-3d-scanner">https://www.factumfoundation.org/pag_fa/1478/lucida-3d-scanner</a>[accessed 09 September 2021]
</li>
<li id="factumfoundation2021d">Factum Foundation. (2021) _Panoramic Composite Photography_ ,<a href="https://www.factumfoundation.org/pag_fa/1343/panoramic-composite-photography">https://www.factumfoundation.org/pag_fa/1343/panoramic-composite-photography</a>[accessed 09 September 2021]
</li>
<li id="factumfoundation2021e">Factum Foundation. (2021) _Recording with the Lucida 3D scanner_ ,<a href="https://www.factumfoundation.org/pag_fa/1552/recording-with-the-lucida-3d-scanner">https://www.factumfoundation.org/pag_fa/1552/recording-with-the-lucida-3d-scanner</a>[accessed 09 September 2021]
</li>
<li id="gombrich1932">Gombrich, E. (1932/33) “Dinghaftigkeit” , “Review of Josef Bodonyi, Entstehung und Bedeutung des Goldgrundes in der Spätantiken Bildkomposition (1932/33),”  _Kritische Berichte zur Kunstgeschichtlichen Literatur_ 5, 65–7.<a href="https://doi.org/10.17863/CAM.27029">https://doi.org/10.17863/CAM.27029</a>
</li>
<li id="fors_principe_sibum2016">Fors, H., Principe L.M., and Sibum, H.O. (2016) “From the Library to the Laboratory and Back Again: Experiment as a Tool for Historians of Science” , _Ambix_ , 63:2, 85–97,<a href="https://doi.org/10.1080/00026980.2016.1213009">https://doi.org/10.1080/00026980.2016.1213009</a>
</li>
<li id="jones2010">Jones, S. (2010) “Negotiating Authentic Objects and Authentic Selves: Beyond the Deconstruction of Authenticity” , _Journal of Material Culture_ , vol. 15(2), 181–203.<a href="https://doi.org/10.1177/1359183510364074">https://doi.org/10.1177/1359183510364074</a>
</li>
<li id="kim2019">Kim, D.Y. (2019) “Points on a Field: Gentile da Fabriano and Gold Ground” , _Journal of Early Modern History_ 23, vol. 2(3), 191–226.
</li>
<li id="latour_lowe2011">Latour, B., and Lowe, A. (2011) “The Migration of the Aura, or How to Explore the Original through Its Facsimiles” , _Switching Codes: Thinking Through Digital Technology in the Humanities and the Arts_ . Eds: Thomas Bartscherer, Roderick Coover. (Chicago: Chicago UP): 275–298.
</li>
<li id="martens2010">Martens, M.P.J. (2010) “Leave it or take it away: ethical considerations on the removal of overpaintings” , _CeROArt_ [Online],<a href="doi.10.4000/ceroart.4765">doi.10.4000/ceroart.4765</a>[accessed 06 September 2021]
</li>
<li id="museumcatharijneconvent2020">Museum Catharijneconvent (2020–2021) _Body Language_ ,<a href="https://www.catharijneconvent.nl/tentoonstellingen/body-language/">https://www.catharijneconvent.nl/tentoonstellingen/body-language/</a>[accessed 09 September 2021]
</li>
<li id="perlin2002">Perlin, K. (2002) “Improving noise” , _Proceedings of the 29th annual conference on Computer graphics and interactive techniques_ . 681–82.
</li>
<li id="rijksmuseum2021">Rijksmuseum (2021) _Nachtwacht Missende Stukken_ ,<a href="https://www.rijksmuseum.nl/nl/stories/operatie-nachtwacht/story/nachtwacht-de-missende-stukken">https://www.rijksmuseum.nl/nl/stories/operatie-nachtwacht/story/nachtwacht-de-missende-stukken</a>[accessed 09 September 2021]
</li>
<li id="stols-witlox2021">Stols-Witlox, M. (2021) “Imperfect Copies. Reconstructions in Conservation Research and Practice” , _Reconstruction, Replication and Re-enactment in the Humanities and Social Sciences_ (Amsterdam: University of Amsterdam Press): 30.
</li>
<li id="tissen2020">Tissen, L.N.M. (2020) “Authenticity vs 3D reproduction: Never the twain shall meet?”  _Arts in Society. Academic Rhapsodies,_ (Leiden: Leiden University Press), 21–40.
</li>
<li id="tissen2021">Tissen, L. (2021) “The digital reconstruction of the crucifixion of the Lindau master (ca. 1425)” , Museum Catharijneconvent, Utrecht. 9 June.<a href="https://www.globalheritage.nl/news/the-digital-reconstruction-of-the-crucifixion-of-the-lindau-master-ca-1425">https://www.globalheritage.nl/news/the-digital-reconstruction-of-the-crucifixion-of-the-lindau-master-ca-1425</a>
</li>
<li id="tissen_malik_vermeeren2021">Malik, U.S., Tissen, L.N.M., and Vermeeren, A.P.O.S. (2021) “3D Reproductions of Cultural Heritage Artefacts: Evaluation of Significance and Experience” , _Studies in Digital Heritage_ vol. 4:1.
</li>
<li id="walteretal2007">Walter, B., Marschner, S.R., Li, H., and Torrance, K.E. (2007) “Microfacet Models for Refraction through Rough Surfaces” , _Rendering Techniques 2007: Eurographics Symposium on Rendering: Grenoble, France, June 25–27, 2007_ . 195–206.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The authors would like to thank Dr. Micha Leeflang, Caroline van der Eyck and Carlos Bayod for their valuable input in this research project.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>The question why the painting was overpainted is part of the ongoing conservation process.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Since 2011, the Factum Foundation has been using this scanner to record the surface topography of 200+ paintings and cultural heritage objects with low relief surfaces all over the world (e.g. the tombs of the Valley of the Kings in Luxor and Michelangelo’s Epifania at the British Museum)<a class="footnote-ref" href="#factumfoundation2021e"> [factumfoundation2021e] </a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Factum Foundation, 2021. <em>Lucida 3D scanner,</em> <a href="https://www.factumfoundation.org/pag_fa/1478/lucida-3d-scanner">https://www.factumfoundation.org/pag_fa/1478/lucida-3d-scanner</a>. Accessed 09 September 2021.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Blender Community. 2018. <em>Blender – a 3D modeling and rendering package</em> . Stichting Blender Foundation, Amsterdam. (Retrieved from<a href="http://www.blender.org">http://www.blender.org</a>20 March 2022)&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>3D printing (or additive manufacturing (AM) is a technique that uses digital computer information to rapidly create a physical three-dimensional object. This digital design can either be acquired by scanning an existing object or by constructing a shape from scratch. The physicalization of the digital model can be done using various methods, but this process is either additive (printing layers upon layers of photosensitive filament) or subtractive (by gradually removing materials until the desired design has been achieved).&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Although currently, 3D printing is not yet up to par with the requirements of art historians and restorers working with these reproductions, the developments of the technology are promising. Thanks to the work of Clemens Weijkamp, it will be a matter of time before the creation of high quality reproductions of artworks with mixed materials are possible without any manual labor.## Bibliography&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The Page Is an Image Again: Bleedmapping as an Analysis Technique for Historical Newspapers</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000658/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000658/</id><author><name>Quintus van Galen</name></author><published>2023-01-06T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="the-page-is-an-image-again-bleedmapping-as-an-analysis-technique-for-historical-newspapers">“The Page Is an Image Again:” Bleedmapping as an Analysis Technique for Historical Newspapers</h2>
<p>When I was younger, I used to know exactly which page of the paper the sports column was on, just as my father could find the stock updates without looking. The TV-guide had a rear cover dedicated to children&rsquo;s letters and could always be found upside-down on the couch. Books were filled with dogears and would fall open on favourite pages. That we could navigate through these complex textual compositions by referring to their spatial nature – what page and column a certain kind of content lives in are just some intimately everyday examples of the relationship between a text and the spatial context it occupies.</p>
<p>When considering the meanings behind any word, our first instinct as researchers, and textually-minded humans, is to look at the words in the spaces around it. Are the signs that point to a more complete understanding of its meaning in the surrounding sentence, paragraph or page? There exist a multitude of techniques that provide researchers with these insights: Latent Dirichlet Analysis, Latent Semantic Indexing, Hierarchical Latent Tree Analysis, Concordance analysis, and many more. Yet all of these ignore the non-textual aspects of a text: the choice of font, the addition of images or embellishments, or the placement on the page. Already in 1927 the French philosopher and poet Paul Valérie wrote in an essay on the importance of the materiality of text. He stated: “Une page est une image. Elle donne une impression totale, présente un bloc ou un système de blocs et de strates, de noirs et de blancs, une tâche de figure et d&rsquo;intensité plus ou moins heureuse.” <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> However, digitised historical collections are often accessible only through a text-based interface<a class="footnote-ref" href="#mussell2012"> [mussell2012] </a>, which has the effect of masking its non-textual aspects.</p>
<p>Other methods have been developed to analyse periodicals in a manner that rescues these sources from being reduced to just text. Some early work on the form of the newspaper stems from<a class="footnote-ref" href="#barnhurst1991"> [barnhurst1991] </a>,<a class="footnote-ref" href="#barnhurst2002"> [barnhurst2002] </a>, who provided the theoretical foundations and proved its relevance to studying the cultural connotations of the patterns of placement. Their work relied on a visual close reading of their selection of newspapers, and sought to reach a general context true for all papers, rather than a specific context of one article. It also meant their methods do not scale well to encompass a digitised archive of thousands of newspapers. Additionally, the result of their visual close reading is itself textual, which has been described as problematic by some scholars, as it occludes the original nature of the material<a class="footnote-ref" href="#haskell1993"> [haskell1993] </a>. Some effort to address these problems has been made recently by Beals<a class="footnote-ref" href="#beals2018"> [beals2018] </a>, however her proposed visualisation of word counts doesn&rsquo;t show the space itself, only an estimate based on the length of text. Meanwhile Moreaux<a class="footnote-ref" href="#moreaux2016"> [moreaux2016] </a>has shown the value of metadata analysis and visualisation for nineteenth-century newspapers.</p>
<p>This article presents a solution to this problem in the form of a tool for visualising the spatial pattern of article placement based on the positional data encoded in its metadata. The visualisation proposed by this paper will allow the heatmapping of common places where a given subset of articles in a periodical appear, allowing for the identification of the context in which a text needs to be seen.</p>
<p>Bleedmapping was developed as a tool to answer a simple research question: where do articles appear within a paper&rsquo;s pages, in single issues and over a longer print run of a title? It does so by extracting the positional metadata for each article in a generated subset, and visualising these as grids on a density map (heatmap), creating the effect of thousands of pages being put on top of each other and bleeding through to reveal the meta-textual structure that frames its contents. Answering this question is relevant for all research searching for non-textual contexts of appearance, but it is of particular interest for studies in historical identities. It has long been acknowledged that newspapers signpost the reader whether a story should be read in an national or international context by grouping stories together. The banality of this act serves as a marker of identity for the reader, who sees their own perspective on the world validated by the paper&rsquo;s distinction betweenhomelandandforeign, betweeningroupandoutgroup<a class="footnote-ref" href="#billig1995"> [billig1995] </a>. Beyond studying the identity of any prospective readers of a publication, bleedmapping also allows for an insight in the periodical itself. As the distribution of articles through a print run of issues is not random, but instead a deliberate act on behalf of the editor, we can look at the pattern of article appearance as part of construction of the identity of the publication itself<a class="footnote-ref" href="#mussell2012"> [mussell2012] </a>.</p>
<p>There are several advantages to the approach Bleedmapping takes. First, it is methodologicaly and epistemologically transparent. This means it avoids being a black box by virtue of not just being transparent to tool critics wishing to investigate the source code, but also to any scholar unfamiliar with digital approaches who may want to use it. The basic function of bleedmapping can be understood as a digital version of a manual operation: drawing and counting rectangles. In this way, it stands vis-à-vis methods such as topic modelling, which to fully understand require a degree of mathematical aptitude that is seldom found in the humanities. The second advantage is from the data it uses. Instead of being forced to rely on approximations of place and size Bleedmapping can rely on (relatively) accurate positional data.</p>
<p>It pays to take a moment to reflect on that positional data itself. Most digitised newspaper archives generate article blocks as part of the image processing undertaken when a page is transformed from adumbimage to an archival page<a class="footnote-ref" href="#gatos2000"> [gatos2000] </a>. Such a step is required to have the OCR softwarereadthe text accurately, and to allow text to be read across a page boundary. This article segmentation step is the field where advances in Document Image Recognition and Analysis have made major contributions to accuracy<a class="footnote-ref" href="#meier2017"> [meier2017] </a>,<a class="footnote-ref" href="#oyallon2015"> [oyallon2015] </a>. The coordinates of these article blocks are then retained in the metadata of a page, and are key part of keyword search implementation, allowing the user to be dropped exactly on the article they requested. Crucially, the way search indexes are set up suggests that these coordinates are never used outside of this purpose: the coordinate field cannot be searched, nor easily requested. Bleedmapping therefore relies on creative reuse of this data, and has to take at times roundabout ways to extract it.</p>
<p>When it comes to discussing the process of Bleedmapping, it is important to first discuss the source of the data used. Not each digital newspaper archive is created equally, and some were produced in a more structured manner than others. For example, the Delpher-archive of the Dutch Royal Library is very consistent in the quality of its segmentation and has a uniform resolution for all page images, while the British Library 19th Century Newspapers archive was digitised by two different external partners, producing different image resolutions<a class="footnote-ref" href="#fyfe2016"> [fyfe2016] </a>,<a class="footnote-ref" href="#beals2020"> [beals2020] </a>. This has substantial implications for the Bleedmapping process, as it means in one case resolving scaling issues is vital, while in the other it can be approximated in favour of processing speed. The implementation below is for the British Library 19th Century Newspapers archive on the “legacy” Gale Text Mining Drives produced prior to 2018<a class="footnote-ref" href="#beals2020"> [beals2020] </a>. Yet for all implementations, as alluded to above, the existence of the positional metadata is crucial. Without this, bleedmapping is not possible. Thus, if this data is not present in the archive, the researcher has to either generate zoning data themselves from page images, or opt for a text-length approximation approach, such as used by Beals<a class="footnote-ref" href="#beals2018"> [beals2018] </a>.</p>
<p>Overall, the process of generating the visualisation is divisible into four main steps:</p>
<p>The(Meta)data lookupcollects the data that the visualisation corpus needs from the different parts of the archive with a keyword search.TheScaling Stepprepares the data for visualisation by harmonising the coordinate systems that each article is in, and resolving, as far as possible, ambiguities in the assignment of blocks of text to multiple pages. The harmonised coordinate systems are then handed off to theTable-of-Occurrence Generator. It should be noted that this step is only necessary in the case an archive does not consist of images of a uniform size and resolution.TheTable-of-Occurrence Generationtallies the number of articles that occupy a certain space on a certain page into a tabular format.TheHeatmap Visualisationgenerates the final image.</p>




























<figure ><img loading="lazy" alt="Graphic indicating a series of boxes that represent the steps in a keyword query" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Graphic representation of the steps involved in generating article placement heatmaps. Each dashed rectangle corresponds to one of the sections below.
        </p>
    </figcaption>
</figure>
<h2 id="metadata-lookup">Metadata Lookup</h2>
<p>The first step to visualising the placement of newspaper articles is to create a subset out of the corpus. This subsetting serves an epistemological goal. After all, if we were to visualise all the articles in the corpus, we would produce a representation of all articles in the newspaper, which means there would be no areas of greater intensity from which to draw any conclusions. Thus, the creation of a subset of articles whose positions might produce insight into the subject of choice, or which might answer a research question is a necessity. For example, if we wanted to visualise patterns in the placement of poetry columns across four decades of a specific newspaper, we would first need to identify and create a subset of all the poetry columns that we wish to measure. Theoretically, this subset could be assembled by manually identifying each column, but in order to visualise long-term trends and deal with large bodies of journalism, we need to identify material for our subset using digital search methods.</p>
<p>The visualisation corpus is first generated by the keyword search, which extracts the article ID&rsquo;s, article coordinates, and the article text. Next, the list of article ID&rsquo;s is used to perform a reverse lookup of the source images, using the page ID&rsquo;s derived from the articles. This produces a link to the page&rsquo;s raw image file on disk, which is then accessed and the image size in pixels and resolution in dpi pulled from its metadata. The results are used to build a dictionary of page ID&rsquo;s, sizes, and resolutions for the nest steps, alongside a regular list of articles from the keyword search. This process is represented in Figure 2.</p>




























<figure ><img loading="lazy" alt="Graphic indicating how data is retrieved from an archive" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Diagram of the retrieval of article- and page data. The keyword query is used to subset articles, for which Text, Coocrdiante and ID are used further.
        </p>
    </figcaption>
</figure>
<h2 id="scaling-and-harmonisation">Scaling and Harmonisation</h2>
<p>The newspapers contained in this archive are far from uniform in size, ranging from the regular-sized dailies, which were typically 12 ¼ by 18 ¾ inches, to the much smaller <em>Pall Mall Gazette</em> , which was only 6 by 9 inches<a class="footnote-ref" href="#beals2018"> [beals2018] </a>. Additionally, even if the pages were the same, the idiosyncrasy of the digitisation process mean that a page might have gained or lost an inch or two to the binding or simply to the way it was placed on the scanner. Compounding this issue is the fact that the coordinates of an article are in pixels, not in inches, and there is no universal translation between these two units. The reason for this is simple: the coordinates were never intended by the archive creators to be used this way. All it was designed to do was to provide a visual indication to the user where on the digitised page the article they were looking at was located, either in a preview thumbnail or in an image viewer. This means these coordinates were always intended to be image-specific, and there was no need for uniformity of any kind between the images. In a similar vein, the choice halfway through the project to use higher resolutions took place for the sole reason of providing better segmentation and OCR. However these choices were made, they shape the archival reality researchers have to deal with<a class="footnote-ref" href="#fyfe2016"> [fyfe2016] </a>.</p>
<p>Both of these issues need to be addressed in order to compare different articles on different pages with one another. First, the frames of reference in which the coordinates of the article exist need to be normalised; that is, both coordinate systems need to be given the same meaning. In the case of the <em>British Library Newspapers</em> parts I and II, there is a disparity in resolution, with part I images being 300 dpi and part II at 400 dpi. This provides us with an unworkable situation for visualisation if the goal is to compare an entire print run of a paper or even multiple different newspapers for a year or decade, as these may be from different parts of the archive. Using the image size and dpi information of the page from which an article comes, we transpose the coordinates of the article onto anidealnewspaper page at a resolution of 400 dpi that is the same for all articles, by multiplying the 300 dpi coordinates with 1.33. Next, the result is scaled non-isometrically to fit the ideal page&rsquo;s width and height, as shown in Figure 3. A separate X and Y scale are used for this, to assist in columns over different pages aligning with each other. The size of the ideal page was chosen so it has an aspect ratio that is equal to modern A4 for easier printing.</p>




























<figure ><img loading="lazy" alt="Graphic showing proportions of a page at different dpi" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stages of Normalisation and Scaling. Left: Original Page. Centre: Normalised for resolution. Right Non-Isometric Scaling for size.
        </p>
    </figcaption>
</figure>
<h2 id="table-of-occurrence-generation">Table-of-Occurrence Generation</h2>
<p>Once the pages have been normalised and scaled, and the coordinate systems harmonised, it remains to generate the table of occurrence from which the heatmaps are drawn. These are the values that inform the intensity of the heatmap, and represent the amount of articles that occupy any given space. For this we need to determine the coordinates of each pixel within the article&rsquo;s area. It was found that using every pixel was impractical and unnecessary: it increases computation time and memory used substantially, but when analysing it offers no additional benefit. The tool therefore uses 200 by 200 pixel blocks in its calculations, as it saves significant resources. These represent an area of 0.5 inch square in physical terms, which is small enough to show the detail we need, but big enough to not squander computer time.</p>
<p>At this point in the process, we have generated a collection of articles, with each article containing all the necessary information needed to generate the occurrence tables: a harmonised and unified set of coordinates covering each point within the bounds of an article, with each rectangle assigned to their correct page, for each article in the visualisation corpus. An example instantiation of this form is illustrated in Figure 4, realised for an article consisting of a single column on page 3, covering the area from point (150,55) to point (950,1255). This process is repeated for every article.</p>




























<figure ><img loading="lazy" alt="Graphic showing proportions of a page at different dpi" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Example instance of a single page article stretching from 150,55 to 950,1255 during different stages of the visualisation process. Top left: schematic representation of the data structure. Top right: tabular representation of position data with number of observed articles. Bottom left: heatmap showing underlying number of observances and x- and y-coordinates.
        </p>
    </figcaption>
</figure>
<p>Thus, this table has the X and Y coordinate of the 200-pixel square, the amount of times an article occurs in that square, and the page number on which the article sits as their own columns. The program iterates over the articles it needs to visualise, and looks up the space occupied by the article in the table. A model of the table is shown as Table 1 below. If an article has already been observed in that place, it increments the number of observations by one; if not, it adds a new row to the table with the article&rsquo;s position.<br>
Model of the table underlying article placement visualisation. Following the tidy data conventionRowContentsXX-coordinate of the 200 pixel squareYY-coordinate of the 200 pixels squareNo. ArticlesNumber of articles that occur in the square corresponding to these X and Y coordinatesPageThe page from which the article originated, as given in its archival metadataTopicWhich topic in the topic model an article was assigned to. If assigned to multiple topics, the one with the highest certainty is chosen. Optional.</p>
<h2 id="image-generation">Image Generation</h2>
<p>With the data scaled and presented in a tidy format, it only remains to generate the images. A key problem is visualising multiple pages at the same time, while maintaining a uniform density scale between the graphs. If all pages were simply visualised on their own without such a precaution, each would default to a local scale, and the same hue on the heatmap could then indicate widely varying numbers of articles observed. Neither seaborn nor matplotlib were designed to support generating multiple heatmaps with a common scale, so a workaround using the manual scale settings had to be found. This necessitated discovery of the maximum number of articles observed before generating the heatmaps, in order to place a set value as the maximum, by generating the table of occurrence for all pages in the paper, and using the maximum value from the incidences column. This results in a sequence of heatmaps, which each represent a page, but which share a common colour scale. An example of this is included as Figure 5.</p>
<p>Various forms of colouration were experimented with. The initial visualisations used a schema of increasingly dark shades of a single colour. This was highly effective at showing the areas with the strongest presence of articles, but it was found that in places where there were only slight variations in the number of article occurrences, such as on page 2 or page 5 of the visualisation in Figure 5, the slight variation in shade was not easily spotted. For these visualisations a three-tone colour scheme is advisable, as it combines ease of interpretation with an aesthetically pleasing form. The bleedmaps generated for this paper all use a yellow-green-blue colourmap.</p>




























<figure ><img loading="lazy" alt="A series of heatmaps for the wordsaustralia,canada, andindiain the years 1870–1875." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Article placement for threeImperialkeywords in Reynold&rsquo;s Newspaper for 1870-1875 shown to illustrate interpretative difference in colour. The variance in colour scheme is particularly noticeable for pages where the number of observed articles are close to each other.
        </p>
    </figcaption>
</figure>
<p>Reading these heatmaps is simple and intuitive. Each square heatmap represents a page, which is compressed into a unified scale. This is more apparent in the vertical than in the horizontal, as this makes the columns more pronounced. The columns on the page form by themselves, as the article placement data of each overlaps slightly with the adjacent column. This has the effect of creating a darker area delineating the column. The origins of this overlap lie in the segmentation undertaken during the digitisation process, which appears to have defined the article zoning with relatively wide margins. This is a direct result of the image being slightly curved or misaligned on the scanner, while the zoning is limited to drawing perfect rectangles between its topmost left and bottommost right points. The relative inaccuracy of such an approach would not impact the goal of using the zoning to highlight areas in a preview window. Occasionally, this can lead to artefacts forming when the newspaper changes its layout within a subset; during tests with <em>Reynolds&rsquo; Newspaper</em> it was found that at one point between 1885 and 1889 that paper changed over from a six-column to a seven-column layout, which distorted the image. This in itself was a surprise, as the literature has described <em>Reynolds&rsquo;</em> as an eight-column newspaper for its entire existence<a class="footnote-ref" href="#shirley2009"> [shirley2009] </a>.</p>
<p>In these bleedmaps, a darker hue of blue represents a stronger presence of the subset in that space. In the example above, the strongest concentration is in the bottom-right corner of page 8, with a medium concentration on pages 3 and 4. All pages have some level of article occurrence; if there are no articles (the observance count is zero), the space on the image would be white (for example at the bottom edge of page 1). In practice, these snapshots, be they per year, per decade, or per month, can be stacked on a page, showing the way focal points of keywords move through the title in their repetition.</p>
<h2 id="a-case-study-renolds-newspaper">A case study: Renolds&rsquo; Newspaper</h2>
<p>Having laid out the process of generating and interpreting Bleedmaps, it now remains to make a case for their usefulness as a means for research in digitised historical newspapers. To do this, a compact historical case study is in order, showing the difference in the findings attainable by commonly-used textual analysis methods such as LDA Topic Modelling and Corpus Analysis using Antconc, and the more metatextual approach offered by Bleedmapping. This difference in analytical level means this is not an either-or comparison, but rather a way in which Bleedmapping may supplement other techniques. The case study will center around the hypothetical research question: how did <em>Reynold&rsquo;s Newspaper</em> report on imperial news compared to foreign news between 1850 and 1900?</p>
<p>The data underpinning this comparison will be drawn from Gale&rsquo;s Legacy text Mining Drives<a class="footnote-ref" href="#beals2020"> [beals2020] </a>. For this comparison, we need two datasets generated by keyword search, and one composed of random articles, for a total of three. India, Canada and Australia are used as markers of empire. These were chosen because they were three of the major possessions of the British Empire, spread around the three major continents on which it held territory, and they related to colonies in different stages of development and of different types: Canada as a developed settlement colony, Australia as a pioneer settlement colony, and India as thecrown jewelof the empire. Earlier tests to find suitable search terms for Britain&rsquo;s African holdings proved unsuccessful, as there the geographic descriptors were too fluid. For the comparison with foreign news, three imperial competitors were chosen. France, Britain&rsquo;s oldest enemy and competitor in Africa, Russia, which competed with Britain for influence in Central Asia, and Germany, which began to challenge British naval power towards the end of this period, but with whom Britain had strong dynastic ties in the earlier part of the century. These are respectively the imperial and foreign datasets.</p>
<p>Starting on a metatextual level with the bleedmaps, both datasets were divided into five-year slices to ease computational load and to improve the level of detail with which they reveal change over time. This will provide the spatial context in which the semantic elements that emerge through corpus analysis and LDA exist. Of course, understanding this spatial context comes with a major caveat: there has been very little research into the layout and visual language used in nineteenth-century newspapers. As modern scholars used to certain stylistic tropes we need to be cognisant of the fact that we may not understand the importance of certain cues embedded in the paper&rsquo;s layout, or interpret them incorrectly. For example, we may consider, in our twentieth- or twenty-first century mindset, the front page the most important part of a paper - but this need not have been the case for a Victorian reader who would first see the colourful advertisement wrapper.</p>
<p>This being said, there is still great value in exploring the pages of <em>Reynold&rsquo;s</em> as a space in a general sense, before involving semantics. Figure 6 shows two selected pages; from these we can see <em>Reynolds&rsquo;s</em> went through a redesign in 1885/86, changing from a six-column layout to a seven-column design. This was completely unexpected, as the literature describes the paper as being laid out on eight larger pages and eight columns<a class="footnote-ref" href="#shirley2009"> [shirley2009] </a>. A verification using the images themselves confirms the presence of six and later seven columns. Having more columns allowed the editor more options when composing the various articles into a coherent page and made more room for adverts, though at the cost of column width.</p>




























<figure ><img loading="lazy" alt="Heatmaps for Reynolds Newspaper, page 7 pre-1886 and post 1886." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Columns in Reynolds Newspaper before and after the 1886 redesign. Only page 7 is shown. This illustrates the difference in number of columns observed.
        </p>
    </figcaption>
</figure>
<p>During second half of the nineteenth century covered here, <em>Reynolds&rsquo;s</em> never switched to a columnless or modern layout. However, this does not mean it was without an underlying design philosophy: despite the appearance of disorder and immutability of newspaper design in the second half of the nineteenth century, rational and bureaucratic design elements did emerge. The centre and the periphery were made visual on the page by dynamic whitespacing, which had the most central and important content in airy, double-spaced lines on the top left and centre columns, with the density of the text increasing towards the bottom-right, where more peripheral content was placed<a class="footnote-ref" href="#barnhurst2002"> [barnhurst2002] </a>. However, more recent newspaper scholars such as Liddle<a class="footnote-ref" href="#liddle2012"> [liddle2012] </a>have argued that Victorian newspapers were very much in flux, with the information density, and by necessity, organisation, of their pages changing throughout the century. He states that the pages and genres within them only stabilised during the latter decades of the nineteenth century. If this is the case, analysing article placement would be of little value, as it would show no underlying structure. Additionally, whatever the editor intended the placement of content to be, the final say on the allocation of space in a newspaper was reserved for the foreman at the printers. Usually, until the 1870s his task required cutting back material or cramming in content wherever it would fit.</p>
<p>However, based on the Bleedmaps produced here (IMG), we may conclude that <em>Reynolds Newspaper</em> did possess a consistent layout for the entirety of the period investigated. This conclusion derives from the clearly present clustering of articles for both keyword-selected subsets: if articles that contain the same keywords, and thus cover the same or similar topics, appear in similar places over a long period of time, we can safely consider there to be evidence for arational and bureaucraticdesign being imposed on the paper. The way these clusters shift shows that after 1886 the paper was redesigned in such a way that the political content, both foreign and imperial, occupied a very different space, barring one major exception. The most obvious section where the imperial and the foreign subsets overlap is in the first two columns of page 4 after 1886, which contains the densest concentration for both these families of article by far. With between 250 and 300 articles, these rows are hotbeds of occurrence.</p>
<p>Their appearance becomes even more intriguing once the space is given proper context: these columns housed the very popularNotices to Correspondentssection of the paper. These kinds of sections have been theorised as “the principal forum for reader opinion” , and the space for items that have “earned their legitimate place in the public debate” <a class="footnote-ref" href="#richardson2008"> [richardson2008] </a>. Started by <em>Reynolds&rsquo;s</em> as a way to connect with his audience, readers could send questions, both on the mundane and the political to the newspaper&rsquo;s offices, which the editor (G.W.M. Reynolds himself until his death in 1879, subsequently his brother Edward and son William) would respond to.Notices to Correspondentshelped create a community of readers and was an integral piece of the paper&rsquo;s formula. The change we observe in the placement of political content in general, but of foreign political content in particular, from adverts, economics and news sections to these discussion pages is suggestive of a deeper change in the way newspapers were read in the nineteenth century.</p>




























<figure ><img loading="lazy" alt="Series of heatmaps showing article placement with keywords. Organized sets of five years and representing years 1865-1899." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Imperial article placement in Reynolds Newspaper visualised in five-year intervals (January 1st of the first year to December 31st of the last). Keywords used:India,Canada, andAustralia. Note the prevalence of columns 1 and 2 on page 4 after 1885, representing the imperial debate in theAnswers to Correspondentscolumns.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Series of heatmaps showing article placement with foreign keywords. Organized sets of five years and representing years 1865-1899." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Foreign article placement in Reynolds Newspaper visualised in five-year intervals. Keywords used:France,Germany, andRussia. Note the presence of foreign news on the front page compared to imperial keywords.
        </p>
    </figcaption>
</figure>
<p>The dominance ofNotices to Correspondentsin the discourse of the empire and the foreign in <em>Reynold&rsquo;s</em> is remarkable; it outperforms its closest competitor, the advertisements on page seven, by a wide margin. But making note of this is as far as computer-supported research methods can take us: closer reading (or a targeted topic model) is needed to show the ways in which these places were referenced. It showed two contexts in which both the empire and the foreign Other were used. First, they may be invoked in direct response to a question from a reader. For example, in response to a query byW.Gin 1851: “Theatrical managers in France are made to pay one-tenth of the receipts to the support of the poor.” Or in October 1852, in an answer to A. Milner of Glasgow, when the response reads “If your health, age, character, &amp;c., is such as to meet the view of the Government Emigration Commissioners, a person of your calling might obtain a free or assisted passage to Australia.” In both cases, the original query obviously specified that they were inquiring into something foreign or imperial—in this case the payment into a social security system by French theatre owners or the ways fora man of certain callingto make it to Australia.</p>
<p>The second invocation of imperial and foreign places in the editor&rsquo;s responses is as a yardstick by which a certain factoid or measurement is to be taken. In these cases, the enquirer is asking after foreign practices to compare them with those within Britain. These are much more difficult to identify, as without the original query, they can look much like the simple queries, and a degree of close reading is required to find them. One example is the response to a question on the use of colonial troops by the French byM.E.of Wye: “The Zauaves [sic] are natives of the French provinces of Algiers, disciplined and exercised by French officers, and now forming part of the French contingent employed in the Crimea. They hold exactly the same relation to the French army as the Sepoys in India have to the regular British troops.” In this case, the editor recognised that by making a comparison between an unknown foreign entity and a known imperial one, the reader would better understand the former.</p>
<p>While newspapers offered a forum for public discussion since their inception, it has been theorised that the rise ofnew journalismsaw these interactive practices reach new heights<a class="footnote-ref" href="#barker2002"> [barker2002] </a><a class="footnote-ref" href="#jackson2001"> [jackson2001] </a>. The bleedmaps confirm those readings, as they show the newspaper&rsquo;s shift from being a vessel for news and information about the political developments of the world to being a platform for debating those politics, which suggests a substantial emotional investment by the average Britton into the empire. However, we could also read this as an example of the agenda-setting powers of the press: starting and fostering debate on topics in a way that forces political parties to respond. Said debate has, of course, shades of chickens and eggs, but nonetheless Bleedmaps may contribute to this debate by providing clues to the metatextual background of the words used to debate and discuss.</p>
<p>The way in whichReynold&rsquo;splaces political imperial news suggests that it is placed alongside or amongst articles covering national matters. The articles that are keyword-selected with imperial keywords, and occupy political spaces in the newspaper, do so mainly in the parliamentary columns. Here, the empire is discussed as an integral part of British political life. Additionally, news from parts of the empire, relating to (political) events that take place there are not reported separately. This suggests the empire does hold a special position in British political discourse, and in the political identities it imparts on its citizens. It is not merely an overseas place, but one that, because of the power Britain holds over it, is a space that the British social, economic and political lives intersect with on a regular basis. While the foreign only appears when it is relevant, the empire is on every page, as it is always relevant to Britain&rsquo;s political debates.</p>
<p>These insights can be used to better understand the results of more textual analysis methods, such as a corpus analysis by tools such as AntConc or LDA topic modelling. For this case study, LDA topic modelling is an appropriate tool to extend the insights gained into the placement of articles: we have a space and a rough content based on the keyword search, but what more can we learn from them? For this purpose, we use a the Gensim implementation of LDA<a class="footnote-ref" href="#rehurek2010"> [rehurek2010] </a>. This model was constructed using the same data as was used for the Bleedmaps, divided in the same article-sized chunks. We now turn to the two important aspects that greatly influenced the quality of the resulting model, both of which underline the potential issues inherent in using digitised archival data “as is” and which show the importance of critical data literacy. These two are OCR quality and article segmentation.</p>
<p>Article segmentation influences the size (and quality) of the chunks that are used to build the model, and in the case of Gale&rsquo;s Legacy Text mining drives – and the British Library data these drew from – the creators decided to segment articles conservatively, that is, if a page contains six columns of ten adverts each, all these sixty adverts are considered one article. This was not an unreasonable approach to take when the digitisation took place around 2004–2007. Even today, on much more powerful hardware and using much more sophisticated techniques, article segmentation, especially of historic newspapers, remains an unsolved problem<a class="footnote-ref" href="#barman2021"> [barman2021] </a>. Additionally, a greater level of precision was not needed for the intended use as an index of the digitised contents of the newspaper collection<a class="footnote-ref" href="#king2005"> [king2005] </a>. However, the choices made then poses a major problem for a document-level LDA model now, as it means that one of the fundamental assumptions underpinning it no longer holds true: that the writer of each text sought to produce sensible texts where words from the same topic-specific bag-of-words are used together more often than words from other topic-specific bags-of-words. Hence, topic models generated from this dataset are often barely coherent (ie. no meaning can be found in the collection of tokens) or badly fragmented (ie. multiple topics contain almost the same tokens).</p>
<p>Compounding the challenges facing the LDA model is the variable quality of OCR in the source material. While the OCR accuracy of this particular archive was excellent when it was digitised between 2004 and 2007<a class="footnote-ref" href="#tanner2009"> [tanner2009] </a>, it falls behind when compared to modern standards<a class="footnote-ref" href="#kettunen2016"> [kettunen2016] </a><a class="footnote-ref" href="#breuel2017"> [breuel2017] </a>. The average character transcription error rate in these articles is acceptable for human readers and for search indexing, as this was what it was designed to facilitate, yet it poses significant challenges for LDA. After all, if most tokens are unique, how can a model learn the patterns that underlie their use? With all these caveats out of the way however, the topic model does provide some additional insights in the language that occupies the spaces identified by the Bleedmapping.</p>
<p>Topic modelling may, on this particular dataset, raise further research questions on how the various news items of the day interacted and intersected on the pages of Reynolds. It is notable that for the period 1860–69, for example, most topics contain tokens that refer to the American Civil War, such asConfederate,WashingtonorAmerican. This is not in and of itself unexpected, as the Civil War was followed closely in the British press and loomed large in the public imagination<a class="footnote-ref" href="#grant2000"> [grant2000] </a>. This interest was connected with deep-seated economic concerns about the war&rsquo;s impact on the global cotton supply, and whether supplies from India would be enough to replace unavailable or destroyed stocks. Due to the way articles are segmented in this archive, it is impossible to know if this is a legitimate reading of the topic model, or if it is simply caused by different imperial news articles onIndiabeing contaminated with larger (yet semantically separate) articles on the Civil War. This problem gets more acute the later in the century we go, as forms of reporting change. While in the middle of the century foreign and imperial reporting tends to be longform, by its end shorter telegraph bulletins are the norm.</p>
<p>Questions around this issue of “contamination” of articles by segmentation become even more complex as we consider another popular genre of article in Reynold&rsquo;s: the army and navy list. These articles are by their very designcontaminatedwith mentions of places all over the globe, named without much if any contextual information. These lists of regiments of the British army and ships of the royal navy and their postings throughout the Empire form into topics with high probability, because they follow the same pattern for decades on end. These lists were not unique to Reynold&rsquo;s and were often a case ofscissors and paste journalism<a class="footnote-ref" href="#beals2018"> [beals2018] </a>, where newspapers copied whole articles from other -more specialized- periodicals. Interpreting the meaning of these lists is difficult – were they solely intended to inform the loved ones of serving personnel<a class="footnote-ref" href="#jones2018"> [jones2018] </a>, or did they also instill a feeling of imperial pride? Whichever is the case, the lack of a clear hotspot on the bleedmap that could correlate with their placement suggests they were regarded as filler, to be placed wherever there was room left.</p>
<p>The topic models have given us additional insight into the textual contents of the page, as they are designed to, while they reinforce the findings of the Bleedmaps. While the technical constraints of this project were such that using them truly in unison was not feasible, it is no great stretch to imagine how there two can reinforce each other further. Starting from a topic model, a bleedmap might show the spatial context of each topic. This can ease the topic&rsquo;s interpretation by providing valuable metatextual clues. Alternatively, starting from a bleedmap, a topic model generated for a particular hotspot and modelling only those articles that appear in a (known) space in the newspaper, can be a valuable tool to further explore its textual contents. These improvements, as well as integrating direct web access through api calls, are being included in the mature version of the Bleedmapper I am currently building for the Delpher newspaper archive.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In conclusion, this article has presented a method for visualising the spatial placement of digitised periodical articles, by creating a density map of their positional data. It has shown this method ofbleedmappingis an improvement over previous (manual) visual analysis methods, as it boasts a high level of scalability and a low reliance on human data tagging, while still retaining human authority in the analysis step. These Bleedmaps are a useful addition to the toolbox of the digital historian when exploring collections of sequential publications, such as newspapers and periodicals. They provide metatextual context for other, text based analysis methods such as topic models, and can in future be made to show the location of individual topics for easier interpretation. The method does not, however, solve issues related to article segmentation and OCR accuracy completely, but it can help mitigate the impact of these known issues when applying methods that are more reliant on accurate segmentation and OCR, such as Topic Modelling.</p>
<p>Bleedmapping relies on the creative re-uses of pieces of the archive, which were never intended to be used as such. They show the density of articles that match a set of selection criteria on each page of the newspaper, which can then be linked back to certain categories of article through analysing these specific spaces. They are thus particularly valuable for understanding the patterns of repeated content in a periodical, which are known to possess this spatial identity. They are however limited in their ability to carry the burden of historical evidence alone: until we gain a fuller understanding of the meanings of article placement, they will have to be supplemented by other methods of analysis for the identified areas of interest, be it a closer textual reading or application of computational approaches. Bleedmapping has the major advantage of making the subtext of each article visible by showing the spatial context in which they exist.</p>
<p>These bleedmaps fundamentally open up new possibilities for research. Exploring article placement has only been done on a small scale, as it was time-intensive when using the prior existing methods. The development of this tool allows for overviews of article placement to be generated without human involvement. It makes it possible to answer questions about the space occupied by specific genres of content; it makes us ask whether these places were static over time or if articles changed places; it generates questions about the redesigning of the layout by incoming editors. It has the potential to be valuable for both the field of periodicals studies and for historians wishing to gauge the impact or prominence of certain content. However, in its current embryonic form, it suffers from a lack of secondary literature and historical theory to embed itself in. At present, there has been very little work done on the visual language of Victorian newspapers, the way their layout spoke to their readers. Did readers value the front page the same as we do nowadays, or did the presence of the advertising wrapper mean the key content would be most eye-catching on the inner folio? Did readers learn to expect certain patterns to their newspapers that editors themselves were restrained by, such as expecting the Parliamentary debates to be on page three? There are countless questions like this, but most of the answers are yet to be found. Additionally, theories on content placement in a historical context will need to be developed; those that are available for newspapers generally consider only more modern columnless newspapers, which makes them unusable for content such as that in this archive. Bleedmapping allows us to finally explore and theorise the pages of historical newspapers the same way we navigate our everyday reads: spatially.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>I am indebted to the staff at Edge Hill University, specifically Bob Nicholson for his guidance and aid during the research for this article, always being available to bounce ideas off and putting up with a server in his office for two years. Mark Hall was invaluable for sorting out the access to Text Mining Disks Gale-Cengage graciously provided to the university and waded through my amateur attempts at coding to show me how it should be done.</p>
<p>The work of Melodee Beals was a great inspiration, and she kindly gave her time to listen to the outline for what would become Bleedmapping and provided feedback and encouragement. Further great feedback came from James Mussell and the attendees at DH2019 in Utrecht.</p>
<p>I am also thankful to Melvin Wevers and Mano Delea at Amsterdam University, who helped greatly in ironing out the kinks in the writing process and for providing support when needed. They were great at coming up with workarounds for the loss of access to the source data due to my switching institutions.</p>
<p>Lastly, I would like to thank the anonymous reviewers, for being the whetstone to sharpen my arguments, and the editors of this journal, for the polish and shine. Any imperfections or errors that remain are fully my own.</p>
<ul>
<li id="barker2002">Barker, H., and Burrows, S. (2002) _Press, Politics and the Public Sphere in Europe and North America, 1760-1820_ , Cambridge University Press.
</li>
<li id="barman2021">Barman, R., Ehrmann M., Clematide S., Ares Oliveira, S., Kaplan F. (2021) “Combining Visual and Textual Features for Semantic Segmentation of Historical Newspapers” , _Journal of Data Mining and Digital Humanities_ .
</li>
<li id="barnhurst1991">Barnhurst, K.G., Nerone J.C. (1991) “Design Trends in US Front Pages, 1885–1985” , _Journalism Quarterly,_ 68(4), pp.796-804.
</li>
<li id="barnhurst2002">Barnhurst, K.G., Nerone J.C. (2002) _The Form of News: A History_ . New York: Guilford Press.
</li>
<li id="beals2018">Beals, M.H. 2018. “Close Readings of Big Data: Triangulating patterns of textual reappearance and attribution in the Caledonian Mercury, 1820-1840” , _Victorian Periodicals Review_ 51(4), pp.616-639.
</li>
<li id="beals2020">Beals, M.H., Bell, E. (2020) _The Atlas of Digitised Newspapers: Reports of Oceanic Exchanges._ Available at: https://figshare.com/articles/online_resource/The_Atlas_of_Digitised_Newspapers_and_Metadata_Reports_from_Oceanic_Exchanges/11560059/2.
</li>
<li id="billig1995">Billig, M. (1995) _Banal Nationalism_ , SAGE, London.
</li>
<li id="breuel2017">Breuel, TM. (2017) “High Performance Text Recognition using a Hybrid Convolutional-LSTM Implementation” , _Proceedings of the Fourteenth IAPR International Conference on Document Analysis and Recognition_ , International Association for Pattern Recognition, Kyoto, pp.11-16.
</li>
<li id="fyfe2016">Fyfe, P. (2016) “An Archology of Victorian Newspapers” , _Victorian Periodicals Review_ , 49(4), pp.546-577.
</li>
<li id="gatos2000">Gatos, B., Mantzaris S., Perantonis S. and Tsigris A. (2000) “Automatic page analysis for the creation of a digital library from newspaper archives” , _International Journal on Digital Libraries_ , 3, pp.77–84.
</li>
<li id="grant2000">Grant, A. (2000) _The American Civil War and the British Press_ , Jefferson, NC: McFarland.
</li>
<li id="haskell1993">Haskell, F. (1993) _History and Its Images: Art and the Interpretation of the Past_ , New Haven: Yale University Press.
</li>
<li id="jackson2001">Jackson, K. (2001) _George Newnes and the New Journalism in Britain, 1880–1910: Culture and Profit_ , Farnham: Ashgate.
</li>
<li id="jones2018">Jones, H. (2018) “She Had Only Navy-Lists and Newspapers for Her Authority” , _Persuasions: The Jane Austen Journal On-Line_ 39(1).
</li>
<li id="kettunen2016">Kettunen, K. and Pääkkönen T. (2016) “Measuring Lexical Quality of a Historical Finnish Newspaper Collection – Analysis of Garbled OCR Data with Basic Language Technology Tools and Means” in _Proceedings of the Tenth International Conference on Language Resources and Evaluation_ , European Languages Recources Association, Portoro, pp.956-961.
</li>
<li id="king2005">King, E. (2005) “Digitisation of Newspapers at the British Library” , _The Serials Librarian_ , 49(1–2), pp.165–81.
</li>
<li id="liddle2012">Liddle, D. (2012) “Reflections on 20,000 Victorian Newspapers: Distant Reading The Times Using The Times Digital Archive” , _Journal of Victorian Culture_ , 17(2), pp. 230–237.
</li>
<li id="meier2017">Meier, B., Stadelmann T., Stampfli J., Arnold M., Cieliebak M. (2017) “Fully Convolutional Neural Networks for Newspaper Article Segmentation” , _2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)_ , pp.414-419.
</li>
<li id="moreaux2016">Moreaux, J.P. (2016) “Innovative Approaches of Historical Newspapers: Data Mining, Data Visualization, Semantic Enrichment” , _IFLA News Media Satellite Sessions_ , 8-11-2016.
</li>
<li id="mussell2012">Mussell, J. (2012) _The Nineteenth-Century Press in the Digital Age_ , Basingstoke: Palgrave Mcmillan.
</li>
<li id="oyallon2015">Oyallon, E., Rabin, J. (2015) “An Analysis of the SURF Method” , _Image Processing On Line_ 5, pp.176–218.
</li>
<li id="rehurek2010">Řehůřek, R., Sojka, P. (2010) “Software Framework for Topic Modelling with Large Corpora” , in _Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks_ , pp.45–50.
</li>
<li id="richardson2008">Richardson, J. (2008) “Reader's Letters” , in Franklin B. (ed.) _Pulling Newspapers Apart_ , London and New York: Routledge, pp.56–66.
</li>
<li id="shirley2009">Shirley, M. (2009) “Renolds' Newspaper” , in Demoor, M. and Brake, L. (eds.) _Dictionary of Nineteenth-Century Journalism in Great Britain and Ireland_ , London: British Library, pp.539–41.
</li>
<li id="tanner2009">Tanner, S., Muñoz, T., and Ros, P.H. (2009) “Measuring Mass Text Digitization Quality and Usefulness: Lessons Learned from Assessing the OCR Accuracy of the British Library’s 19th Century Online Newspaper Archive” , “D-Lib Magazine” , 15(7/8).
</li>
<li id="valerie1927">Valérie, P. (1927) “Les deux vertus d'un livre” , _Arts et Métiers Graphiques,_ 1, pp.3-8.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>A page is an image. It gives a total impression, presents a block or a system of blocks and strata, of blacks and whites, to a task of figure and intensity more or less joyous.## Bibliography&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">More than Distant Viewing: Qualitative Views on Machine Learning as an Automated Analysis Method in Networked Climate Image Communication</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000654/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000654/</id><author><name>Paul Heinicker</name></author><author><name>Janna Kienbaum</name></author><author><name>Birgit Schneider</name></author><published>2022-12-22T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Algorithmic image sorting and its visualisation are increasingly used as tools in digital art history and image science. These include, among others, their use as hermeneutic and epistemic engines in art historical image search<a class="footnote-ref" href="#bell2018"> [bell2018] </a>, in the organisation of museum or collection-specific image datasets<a class="footnote-ref" href="#googleartsandculture2011"> [googleartsandculture2011] </a>, or in digital cultural analysis<a class="footnote-ref" href="#manovich2020"> [manovich2020] </a>. For this reason, for example, machine learning algorithms can be used to automatically develop dimensions of image similarities. In particular, human-computer interactions are enabled in the mode of “distant viewing” <a class="footnote-ref" href="#moretti2000"> [moretti2000] </a>. The visualisation of abstract data allows the identification of trends and correlations in the data. A main component of distance representation lies in the rapid recognition of optical patterns on the part of the recipient<a class="footnote-ref" href="#dork2018"> [dork2018] </a><a class="footnote-ref" href="#dork2020"> [dork2020] </a>. Graphical and image-specific methods of data representation are thus given increased attention in DH research for knowledge production and organisation – as opposed to primarily used textual methods. In our article we discuss the development of methods for a semi-automated comparison<a class="footnote-ref" href="#schnapp2012"> [schnapp2012] </a>.</p>
<p>The starting point for these questions is our research project on intercultural comparison of climate images on the World Wide Web. Using the Internet search engine Google Images, we collected images from different regional cultural areas based on specific keywords related to climate change. Using machine learning as a digital method, we want to find out how globalised or differentiated the visual language of climate change is. For this purpose, we use a method of dimensionality reduction (t-SNE) based on machine learning algorithms, which enables human interaction with huge amounts of images by making them accessible to the human eye in the form of a data visualisation. Within our mixed-methods approach of quantitative computer science and qualitative image science, qualitative image analysis and reflection thus begins with data visualisation, which thus takes on a central role. However, our focus is not only on visualisation as a quantitative end product or phenomenon. Rather, we focus on the process of data processing and its curation, to which diverse data-shaping decision-making processes are subjective: from collecting, to clustering, to visualisation. Following Johanna Drucker&rsquo;s statement –distant reading isn&rsquo;t<a class="footnote-ref" href="#drucker2017"> [drucker2017] </a>– we would like to emphasise that computer-assisted image analysis including data visualisation is not only a distant viewing method in the supposed sense of viewing:</p>
<p>Machine learning as a method is promisingly applicable within the digital humanities, as it promises the analysis or comparison of large amounts of data. However, the automated processes only ever consider the isolated structural levels of the images. They are subject to unseen steps (black box) and qualitative-curatorial decisions. The visualisation of the data as visualisations of the distance within an operable interface is only a part of it. Although the qualitative interpretation of the automated image sorting starts from this distance view, we understand distanced seeing as the critical dialogue between the pure image artifacts and the abstracted data visualisations of computer vision<a class="footnote-ref" href="#offert2021"> [offert2021] </a>. With being distanced we focus on the presupposition and technical standards that are used to abstract image data.</p>
<p>In the following, we would like to use the metaphor of the pipeline to critically explain the development process of the t-SNE method. In individual steps, we describe the process of method development and reflect on the central qualitative as well as quantitative influences. Rather than focusing on the added value of machine learning as a new method, we want to reveal how much the structure of data and information is subject to constant decision-making processes and how interdisciplinary difficulties emerge in the process. In this deliberately open and critical handling of (visualised) image data, we see the central added value of mixed-methods or DH research.</p>
<h2 id="methods-pipeline">Methods pipeline</h2>
<p>Within Google&rsquo;s image policy, one encounters a very standardised visual language, which at the same time reveals considerable differences in the preferred image types (e.g. photos, maps, curves, documents, comics) and in the framing of climate change. Our present study on the cross-cultural comparison of climate images is based on the framing approach from a qualitative image science perspective<a class="footnote-ref" href="#rodriguez2013"> [rodriguez2013] </a>, which was tested by means of automated image analysis. We focus on the development of a technically constructed gaze, which we critically explore in our study as part of the pipeline. Its importance is particularly evident in corpus creation and Google&rsquo;s page rank algorithms, as well as in image analysis based on the definition of the machine learning algorithm. This led to our central research questions: What is the role of automated image searches in terms of pre-sorting and ranking climate images? What do machine learning algorithms<a class="footnote-ref" href="#vandermaaten2008"> [vandermaaten2008] </a>accomplish as a digital method for analysing image collections? To what extent are qualitative human image sorting and t-SNE visualisation interdependent?</p>
<p>As noted in the introduction, by distanced vision we mean the constant dialogue of quantitative and qualitative decision-making processes. This already becomes clear in the methodological orientation of our research project. As an interdisciplinary mixed-methods research team, we oriented ourselves to the so-called embedded design of mixed-methods research according to John W. Creswell (<a href="#creswell2007">2007</a>). Here, the quantitative and qualitative approaches are considered separately, but in a consciously conceived interdependence in dialogue. The focus is on the quantitative image data and their machine image comparison using t-SNE as algorithmic image sorting and visualisation and the subsequent qualitative reading of the resulting data images.</p>




























<figure ><img loading="lazy" alt="black and white image of a flowchart. There are nine boxes in the flowchart which outline the steps of the method pipeline" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Diagram of the method pipeline and structure of the following keypoints
        </p>
    </figcaption>
</figure>
<h2 id="1--parametrisation---thinking-technically-about-cultural-spaces">1 – Parametrisation - Thinking technically about cultural spaces</h2>
<p>In this first step of project design, primarily qualitative distinctions are drawn and decisions are made as to which phenomena of the object of study are analytically and statistically usable. We call this basic step of formalising the research projectparameterisation.</p>
<p>Specifically, to describe intercultural climate image communication, two basic aspects had to be formalised for our study: on the one hand, cultural spaces <em>per se</em> , and on the other hand, the spaces in which climate images circulate. Thinking technically about cultural spaces turned out to be a challenge. Our study looks at the most global arrangement of climate communication possible, made possible by infrastructures such as the internet. The political order of nation states is too reductionist in this structure, as neither networked nor intercultural spaces can be thought of with the rigid state model. The question, then, was how cultural spaces can be conceived on the Net. After discussions with cultural scholars, we decided on the concept oflocalesas a unit of cultural space. Alocalecombines the idea of a specific language with a region or country.</p>
<p>The second question about the representability of climate images related primarily to their technical media spaces, since the global reality of image communication on climate change is impossible to represent in its entirety. However, the global technology of the internet allows us to consider the cultural implications of this interconnectedness as a simplified model for cross-cultural climate communications. Compared to social media such as Instagram or Tik Tok, we were interested in the largest possible, extensively used, and highly formalized media spaces. The focus therefore fell on the search platform Google and Google Images as the largest manifestation.</p>
<p>So, in order to do justice to the technical idea of cultural spaces in the WWW and Google as a search engine, we used the notion oflocales. We are aware that alocaledoes not correspond to the idea of a cultural space, but is a heuristic for our research questions.</p>
<h2 id="setting-the-locales">Setting the locales</h2>
<p>The next step was to clarify whichlocalesshould be compared with each other. We developed a focus list of eighteenlocales. Theselocalesform a purely subjective selection based on previous research, contacts with international researchers, and climate policy relevance. To counteract a perceived biased perspective, we supplemented this with a number-based analysis of climate indices, so that qualitative and quantitative approaches were mixed. To do this, we created a two-dimensional mapping of the rankings for nation states of two climate indices: the ND-GAIN index from the Notre Dame Global Adaptation Initiative and the TCI indicator from the Stockholm Environment Institute. In a subsequent identification of groupings, we captured five clusters that outline focal points in each country&rsquo;s climate policy. The following seven countries were exemplary selected: USA, Brazil, Germany, Kenya, United Arab Emirates, Bangladesh, and Australia. Theirlocaleswere generated using simulated VPN searches.</p>




























<figure ><img loading="lazy" alt="image of a number plot with several points on it. There are circles drawn around clusters of the points in the colors blue, red, purple, white, and green" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Mapping TCI and ND-GAIN with five resulting clusters
        </p>
    </figcaption>
</figure>
<h2 id="google-image-search--keywords">Google image search – keywords</h2>
<p>Our conducted image search via Google works by keywords. We were therefore confronted with the problem of differentiating the climate change discourse into a few but essential terms. In a highly iterative and qualitative process, we randomly evaluated different keywords in different languages related to climate change discourse in Google Image Search. We coordinated the exact definition of the keywords with experts working in the field of climate research and communication. In the end, we decided on eight terms to use as keywords and search terms: (1) climate change, (2) climate change disaster, (3) climate change impacts, (4) climate change risk, (5) climate emergency, (6) climate crisis, (7) climate collapse, and (8) global warming.</p>




























<figure ><img loading="lazy" alt="Image of a spreadsheet that is color coded using yelloew and blue" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Extract from the translation chart with confirmed keywords
        </p>
    </figcaption>
</figure>
<h2 id="2--googles-image-structure-as-a-corpus">2 – Google&rsquo;s image structure as a corpus</h2>
<p>To create the image corpus, we extracted the essential data using the method of web scraping via a Python script (via Beautiful Soup package). Web scraping describes an automated procedure that makes it possible to retrieve specific web pages and to retrieve previously defined elements of these pages. The data was thus filtered by algorithms from the information architecture of Google Images. This procedure is equivalent to an automated, qualitative curation of images since it has to be manually decided which items from a website are taken. On the basis of the Tor browser and its VPN tunnelling capabilities we technically imitated search queries from different cultural regions concerning climate issues.</p>
<p>For sevenlocales, we agreed on a subjectively determined quantity of 250 images per keyword, since too many images would have limited the qualitative evaluation of the image analysis at the level of perception. As a tendency, it can be said that each technical arrangement benefits from more data, but must remain manageable for the human eye to ensure qualitative intervention. In addition to the image artifacts themselves, meta data of the images and the source of origin were also collected.</p>
<p>The challenge that arose in our work with Google, understood by us as an epistemic search engine, is which perspective of research with or about Google results from this. According to the media scientist Richard Rogers, two approaches can be described asmedium researchandsocial research<a class="footnote-ref" href="#rogers2017"> [rogers2017] </a>. Medium research asks about algorithmic mechanisms and political motivations, i.e., how a web application is designed and for whom. As a critical research strand, the technical limitations and ethical-social implications of Google and its non-public page ranking algorithms are discussed here in detail. In contrast to medium research, we have decided in favour of the second strand, social research according to Rogers. This seeks not so much to expose the secret structures of search algorithms, but rather to productively read the given structures of the algorithm. For example, Google&rsquo;s rankings can be understood as indicators of social trends, and questions about the popularity of search words and regional emphases can be examined. Following this principle, we made a conscious decision to use the t-SNE technology to visualise Google&rsquo;s ordering structures that express the current social interest of global climate communication - i.e., our research subject.</p>
<h2 id="3--automated-image-analysis-and-its-opacity">3 – Automated image analysis and its opacity</h2>
<p>Our web scraping process resulted in a corpus of approximately 16,000 images. To analyse this dataset, we searched for algorithms capable of formulating, at best, their own criteria of similarity according to which image motif recognition could be automated.</p>
<p>We used the artificial neural network method, specifically the Convolutional Neural Networks (CNN) architecture<a class="footnote-ref" href="#lecun1999"> [lecun1999] </a>. Another big resource factor in neural network learning is the amount of data sets required. Our 16,000 images from Google Image Search are too few to make them usable for a CNN. Again, for resource reasons, we therefore decided to use a pre-trained CNN following Google&rsquo;s Inception v3 architecture<a class="footnote-ref" href="#szegedy2015"> [szegedy2015] </a>based on ImageNet&rsquo;s image dataset<a class="footnote-ref" href="#stanford2020"> [stanford2020] </a>. In the practical application, we had the approximately 16,000 images from Google Image Search pre-processed by a Python script (via TensorFlow library) and obtained multi-dimensional similarity vectors (2048 dimensions) for each image in relation to the learned images and keywords from ImageNet by the pre-trained neural network <em>Inception</em> .</p>
<p>The identification of image similarities is central to our intercultural image comparison. It is based in the method of image comparison, which is thought of in a technical way compared to an art-historical orientation. Regarding the exploration of the quantitative technical view, similarity means the structural relation based on the trained ImageNet dataset. This can be structured in colour, shape, but also semantic content. Only differences can be made that are already created in the taxonomy of ImageNet. Since ImageNet is not specifically designed for climate change imagery and Inception has not been explicitly trained for this application, inaccuracies are to be expected. Thus, all images are compared to the broadest classification system embedded within <em>ImageNet</em> rather than particular climate image settings. In addition, due to the structural complexity of neural networks, it is difficult to identify the basis on which the algorithm has made decisions<a class="footnote-ref" href="#distillpub2017"> [distillpub2017] </a>. In addition to the black box in Google Images, another major discordance is evident in the work with automated image analysis using pre-trained neural networks.</p>
<h2 id="4--dimension-reduction-or-to-be-spoilt-for-choice">4 – Dimension reduction or to be spoilt for choice</h2>
<p>The 2048 dimensions of structural similarity resulting from the neural networks are difficult to imagine for the human eye, which is why we applied techniques for dimension reduction to an imaginable level in the next step. As statistical methods, such methods have been developed in many different forms and focuses. Established algorithms are, for example, principal component analysis (PCA) or newer approaches, such as UMAP (Uniform Manifold Approximation and Projection). Due to its effectiveness, performance, and resource-efficient implementation, we decided to use a t-SNE (T-distributed Stochastic Neighbour Embedding) algorithm<a class="footnote-ref" href="#vandermaaten2008"> [vandermaaten2008] </a>. t-SNE is a machine learning algorithm that models high-dimensional objects through a two- or three-dimensional space in such a way that, in principle, structurally similar objects are modelled by nearby points and dissimilar objects by more distant points. These models can then be represented by plots on a surface.</p>
<p>While t-SNE plots often appear to represent groupings, these visual clusters can be strongly influenced by the calibration chosen, so a good understanding of the variables for t-SNE is necessary. Thus, the creation of a t-SNE algorithm is primarily a qualitative decision by the programmer about the variable values. Calibrating the variables is a particularly consequential step within our pipeline because it is on the basis of their data that the subsequent visualisation is created: Reducing the high-dimensional relations to a two- to three-dimensional space by the t-SNE algorithm creates distortions in the data representation in every case. They manifest themselves in the fact that very similar artefacts in a low-dimensional visualisation do not necessarily have to be in spatial proximity to each other.</p>
<p>For our analysis, we created a t-SNE calculation for each <em>locale</em> and for each keyword. We calibrated the variables the same for each <em>locale</em> due to the number of calculations and for comparability reasons. In case of doubt, however, not every t-SNE is thus optimally set up for the specific dataset. It is possible, in addition to the general bias due to dimensionality reduction, that apparent groupings are not present in the actual clustered data and thus may be spurious findings. This is a principal challenge when working with automated dimension reduction and subsequent visualisation. t-SNE visualisations cannot be simply read, but should be understood primarily as a dynamic image under the calibration dependencies described.</p>
<h2 id="5--visualisation---qualitative-reading-needs-visibility">5 – Visualisation - Qualitative reading needs visibility</h2>




























<figure ><img loading="lazy" alt="image of a network graph with a black background. There are cluster names and images on the left side in the margins" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of the visualisation interface based on the Yale DH framework
        </p>
    </figcaption>
</figure>
<p>To merge the computational methods and the visualisation of the statistical results, we created a web interface based on Yale University&rsquo;s PixPlot tools with an interactive layout arrangement of the image corpus<a class="footnote-ref" href="#yale2017"> [yale2017] </a>. The web-assisted visualisation (WebGL) consists of a two-dimensional projection in which similar images are grouped based on the similarity vectors computed by the Inception v3 neural network.</p>
<p>In a further step, we complemented a k-means clustering in the t-SNE reduced two-dimensional space of the images. Clustering is applied for the purpose of identifying major centres of the t-SNE array by numerically comparing the dimension-reduced similarity vectors. In the image analysis, these centres were referred to as <em>hotspots</em> . It should be noted, however, that t-SNE operates in continuous space, i.e., it does not group in a strict sense. Thus, not every image in t-SNE corresponds to a complete and unique centre, and thus there are no unique membership boundaries. The k-means clustering does not perform the clear identification of clusters within the t-SNE array, since the t-SNE data is not structurally meant to be clustered by proximity. From a quantitative perspective, it serves only as an additional statistical procedure to present the results for human perception in such a way that one can orient oneself in the following t-SNE visualisation.</p>
<p>At this point, the important dual role of interfaces becomes clear: On the one hand, only the visual representation allows access to the digital data structures, which are thus imperceptible to human viewers. On the other hand, the final representation allows little or no insight into the many decision-making processes, constraints, and (subjective) interventions that led to this representation.</p>
<p>From a humanities perspective, in the further course of the pipeline we asked ourselves whether and to what extent the algorithmic t-SNE procedure can be understood as a framing method for image masses. Because from the technical sorting of Google&rsquo;s climate images, groupings of similarities resulted in this pipeline that allowed thematic image focusses.</p>
<p>Overall, despite <em>locale</em> -specific differences, we were able to identify the following dominant or concise main motifs and image genres in the collected images, which expressed themselves either as technically generated image clusters or qualitative image groups. They can be understood as the result of climate image communication in relation to Google&rsquo;s ranking and image structures. In terms of image science, so-calledcatch images<a class="footnote-ref" href="#diers1997"> [diers1997] </a>could be identified within the identified image groups, which were characterised by recurring motifs and formal stylistics. These appeared more frequently in the Google query due to their similarity and are reflected, among other things, in the technically generatedhotspotimages. The following overview shows the most dominant image groups with central catch images as single images.</p>




























<figure ><img loading="lazy" alt="Image of a list of twelve words wiht images next to each" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Overview of all image clusters with an according catch image
        </p>
    </figcaption>
</figure>
<p>In total, three image types as an average of five concise main motif groups could be located according to size:</p>
<p>photographs, divisible into a) a group of images on the subject of environment, nature, landscape, b) a group of people (conferences, groups, politics versus protest/demonstrations), c) a group of images with representations of the earth, and d) a group of images on the polar bear.text-image documents, including text-only documents, documents with diagrams, covers of books and brochures, individual slides with text, activist posters with slogans, occasional maps, cartoons or cartoon-style graphics, infographics, and chartshighly artificial photomontages (representations of contrast)</p>




























<figure ><img loading="lazy" alt="screenshot of three tsne plots. The plots each have circles around different clusters of points as well as accompanying images" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The three different main image types or genres exemplified by the t-SNE visualisation of the German Google search query Left: Photographs, centre: text-image documents, right: artificial photo montages
        </p>
    </figcaption>
</figure>
<p>It could be determined that the t-SNE algorithm thus does not sort the images exclusively according to image types and juxtaposes the image-text documents with the photographs as central image clusters, but according to similar motifs or image contents. In the t-SNE visualisations, images motivated by content – as far as one can speak of content in computer image recognition – are placed next to image clusters of another image type. This observation is significant because it shows how similar technical-automated image vision and cultural-scientific vision are on this level.</p>
<h2 id="6---digital-image-swarms-as-a-gestalt">6 - Digital image swarms as a Gestalt</h2>
<p>The qualitative assessment of the algorithmically sorted image motifs within the t-SNE interface was based on the reception of large image swarms in which the individual images were not perceived as such.</p>




























<figure ><img loading="lazy" alt="image of a tsne plot with many points on a black background. There is a list of images on the left side of the screen" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Image t-SNE of Locales Brazil as a whole.
        </p>
    </figcaption>
</figure>
<p>Thus, far from any visual content, initial hypotheses about the composition of the visual landscapes could be detected on a structural level. For example, in the t-SNE of the search query for the Brazilianlocale, a total of five image groupings could be identified: a very large and colourful one (centred), an isolated conspicuously dense and bright group (far upper right), two image groups of heterogeneous colourfulness (centred right and lower right), of which the centred one seems to merge into the large image group, and a conspicuously strongly isolated elongated and dense image group in the colour blue (lower left).</p>
<p>In addition, a very high similarity of the formation of the shape of the t-SNE visualization from the Australian image query with that of the USA could be found. Both image landscapes were similar in terms of density and distance or scatteredness as well as colourfulness of the image landscapes. It was reasonable to assume that despite different VPN tuning, these twolocaleswere very similar in their Google image content due to the same language of search terms.</p>




























<figure ><img loading="lazy" alt="image of a tsne plot with many points on a black background. There is a list of images on the left side of the screen" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>T-SNE visualisation of Australian Google image query.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="image of a tsne plot with many points on a black background. There is a list of images on the left side of the screen" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>T-SNE visualisation of the American Google image query.
        </p>
    </figcaption>
</figure>
<p>Due to the visual complexity of the t-SNE visualisations from a distance, an initial reading is based onGestalt, as formulated by perceptual psychology orGestalttheory. Perceptible were</p>
<p>light-dark contrastscolour contrasts (white or coloured structures) and dominant colour structures,an interplay between the homogeneity and density of the image tiles and their heterogeneity and scatteredness.</p>
<p>Thus, the three perceptual patterns already allowed a comparison of the country-specific t-SNE visualisations based on their different size ratios, colour occurrence, and homogeneous or heterogeneous distribution of images.</p>
<p>With regard to the evaluation of the similarity of the images among each other, hypotheses could be derived: The closer or denser the elements, the higher their commonality is interpreted. The more elements are condensed into groups, the more likely it is a common connection. This finding was expected after the description of the technical clustering. However, it can be emphasized because it is an expression for the actually invisible t-SNE-algorithm. Its logic of image sorting becomes perceptible and operable as cluster visualisation for content-related statements.</p>
<h2 id="7--toggling-as-a-digital-image-experience">7 – Toggling as a digital image experience</h2>
<p>On a qualitative level, the process of human perception of the climate images versus the automated pattern analysis of the machine learning algorithm was characterised by constant zooming in and out, atogglingprocess, within the country-specific interfaces<a class="footnote-ref" href="#schnapp2012"> [schnapp2012] </a>. In order to be able to compare the image clusters according to their size and their content, it was necessary to switch between individual images from a close view and the image landscapes from a distant view. The procedure of the distance view, if understood literally, offers the recipient an overview of the image collection and helps to recognise patterns and structures, but it stands in contrast to the individual viewing of objects: “At the same time, distance views, due to their quantitative methods, are visually more abstract and more detrimental” <a class="footnote-ref" href="#dork2020"> [dork2020] </a>.</p>
<p>Using toggling, the individualhotspotimages were displayed by the machine learning algorithm as representative of a cluster in the visualisation and qualitatively indexed with terms. The twenty algorithmically evaluatedhotspotswere thus given a name according to human classification and interpretation of the image object. The qualitative naming of thesehotspotsserved us as a first step to get to know the image objects and to be able to name them descriptively. It was done intuitively, but it was done iteratively by three different people. This is because the indexing partly demanded a uniform and general naming of the picture subjects or motifs (e.g., CO2 emission, polar bear, glacier), since these occurred repeatedly in the intercultural country queries.</p>




























<figure ><img loading="lazy" alt="Screenshot of a list of sentences" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Example of indexing the hotspot images from the t-SNE visualizations to the Brazil and Germany locales
        </p>
    </figcaption>
</figure>
<h2 id="8--cluster-versus-image-group">8 – Cluster versus image group</h2>
<p>In the designation of thehotspotsand their technical image clusters, methodological differences between quantitative and qualitative clustering emerged that had to be considered for the further course of the qualitative image analysis:</p>
<p>a)Hotspotimages detected by the algorithm did not correspond to any or only a very marginal cluster in the sense of an image group according to qualitative assessment.</p>
<p>Methodologically, the question arose with regard to the t-SNE algorithm as to how the computer technically defines a cluster and thus also detects the <em>hotspot</em> image. As the hotspot image of Greta Thunberg from the Brazilian t-SNE visualisation, which occurred twice, showed, it was an image that qualitatively did not take on any status as an image group. Rather, the portrait of Greta Thunberg seemed to exhibit a high similarity factor precisely in its duplicity.</p>




























<figure ><img loading="lazy" alt="image of a tsne plot with many points on a black background. There is a list of images on the left side of the screen. There is a red box drawn around two images in the center" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Hotspot image of Greta Thunberg from the Google search query of the Brazilian locale, which qualitatively does not correspond to any cluster.
        </p>
    </figcaption>
</figure>
<p>b) At the same time, the problem arose that some images, which qualitatively showed a high motivic similarity and evidence, were not detected as ahotspotby the algorithm. For example, the algorithm identified images of the Earth as a colour contrasting globe within the t-SNE visualisation of thelocaleBangladesh as anhotspotimage, while the same motif was merely a section of the general cluster of Earths within the t-SNE-visualisation of the Brazillocale.</p>




























<figure ><img loading="lazy" alt="image of a tsne plot with many points on a black background. There is a list of images on the left side of the screen with a red box drawn around a cluster of images on the right side" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Hotspot-cluster C13 from the Earth (burning) and the general Earth cluster, within which the Earth forms a section as a diptych and was subsequently qualitatively determined in the t-SNE-visualisation of the Brazil locale.
        </p>
    </figcaption>
</figure>
<p>Accordingly, it can be stated that the determination of a t-SNE cluster technically does not necessarily result from a high number of images, but due to a high similarity rate of sometimes only two images.</p>
<p>The German translation of the word cluster as accumulation or group therefore does not find its fundamental meaning technically. We therefore used the word cluster as a technical term in the sense of the t-SNE clustering algorithm, the word image group as a qualitative determination of dominant motifs in their frequency. Thesis-wise, it can be stated on a technical level that the higher the similarity factor of the images, the more likely it is a technical cluster with ahotspot. The higher the similarity value, the closer the images tend to be to each other and the stronger the separation of the cluster from the rest of the image swarm. On the level of human perception, it can be stated that the higher the frequency of motifs with a common similarity criterion, the more likely it is to be an image group.</p>
<h2 id="9--screenshot-tableau">9 – Screenshot tableau</h2>
<p>The distribution of denotatively determined main image content manifests itself through observable variation amonglocales. We qualitatively created a screenshot tableau that sorted and contrasted the concise and central image clusters or groups of main motifs perlocale. Methodologically, the systematic comparison of the 90 screenshot clusters was a quantitative process within the qualitative image analysis. As a procedure, the tableau in the form of a tiled overview allowed us to determine size distributions, commonalities, and differences among the clustered climate images.</p>




























<figure ><img loading="lazy" alt="Screenshot of a table with several rows of images. Some of the images have blue backgrounds and some have red" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot table with image groups of the t-SNE
        </p>
    </figcaption>
</figure>
<p>The determination of the group sizes only took place in the form of tendencies. The formation of the images according to iconographic similarity criteria is partially interrupted by the algorithm due to formal-technical structural differences. For example, the photographs of artificially created contrast representations diverged strongly in the visualisation of the Google images according to the U.S. American <em>locale</em> . While from a semiotic and iconographic perspective the green-orange contrast represents the symbolic and evidential similarity feature for the dichotomy of healthy versus dystopian climate futures, the algorithm separates this into two image clusters distant from each other by structural image properties (structure of the tree versus that of the landscape).</p>




























<figure ><img loading="lazy" alt="image of a tsne plot with many points on a black background. There is a list of images on the left side of the screen. Two images have been zoomed in on on the right side of the screen." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Formal-structurally separated image group of contrast photographs in t-SNE of US-American Google images, source of the single images:<a href="https://www.azocleantech.com/images/Article_Images/ImageForArticle_898(1).jpg">https://www.azocleantech.com/images/Article_Images/ImageForArticle_898(1).jpg</a>(above),<a href="https://thumbs-prod.si-cdn.com/PKIvqzZfGkfhGDKTRxJ6_SodI1U=/420x240/https://public-media.si-cdn.com/filer/5c/cc/5ccc5513-30b1-41b3-96b7-41b88524ed3a/cambio-climatico.jpg">https://thumbs-prod.si-cdn.com/PKIvqzZfGkfhGDKTRxJ6_SodI1U=/420x240/https://public-media.si-cdn.com/filer/5c/cc/5ccc5513-30b1-41b3-96b7-41b88524ed3a/cambio-climatico.jpg</a>(down)
        </p>
    </figcaption>
</figure>
<h2 id="conclusion">Conclusion</h2>
<p>In the previous critical description of our pipeline, the qualitative inscription and strong influence of the technical method of machine learning by us as image researchers and due to &rsquo;external&rsquo; software became clear. In contrast, the qualitative view of the evaluation regarding the location of image groups was strongly influenced by quantitative measurement and counting methods, such as in the creation of the screenshot table. Becoming aware of this difficulty of insight and technical complexity through the juxtaposition of different algorithms is an essential building block in this form of mixed-method and thus DH research. It is a circumstance that we will callmore-than-distant viewingfor our study, building on Franco Moretti&rsquo;s (<a href="#moretti2000">2000</a>) concept of distant reading and following Johanna Drucker&rsquo;s (<a href="#drucker2017">2017</a>) countering approach of “distant reading isn&rsquo;t.”</p>
<h2 id="discussion-of-the-methods-potentials-and-limits">Discussion of the methods: potentials and limits</h2>
<p>While our automated image analysis described here is based on machine learning, the algorithms are based on a lengthy and highly qualitative interpretation and decision-making process. Thus, it became clear to us how our methodological approach and use of Google as an access point to the universe of climate imagery revealed more about current imagery occurrence in Google and how machine learning algorithms can be made applicable to our topic, namely culturally distinct climate imagery communication. The many preconceived technical standards and qualitative inscriptions inherent in any computational process became conspicuous at different levels and had a drastic effect on the entire research process, including qualitative image analysis. We conclude with citing four examples that illustrate this shift:</p>
<p>The basic parameterisation as a first step, for example, fundamentally shifted our research question. In our example, the initially content-driven research question about the globalisation of the visual language of climate change became a formal description problem of how intercultural image communication can be made measurable in itself. Such research then describes not so much the actual object of research as the constraints and dynamics through abstraction for a numerical logic. This statistical description and reductionist ordering of the research object is the conceptual foundation for the so-called digital methods in general, because every computer-based process needs the concrete distinction and knows no spaces in between.</p>
<p>In a second step, we had to curate our image corpus of a global climate communication. We are interested in mainstream image communication in cultural spaces and, therefore, deliberately decided on the largest possible, extensively used and highly formalized image space – Google Image Search. The so-called <em>PageRank</em> algorithm that orders the search results via Google Images was responsible for the type and diversity of climate images that we analysed. It is known that around 200 factors<a class="footnote-ref" href="#searchengineland2010"> [searchengineland2010] </a>are influencing this algorithm, while some are known the most relevant are kept well hidden. This is why such a technical framework is often referred to as ablack box. Ultimately, this means that we do not know the intrinsic ideas and models of the algorithms used and intentionally reproduce them. In the end, what we ultimately analysed was not a neutral perspective on climate communication, but the one shaped by google engineers. One open challenge, therefore, is how to deal with the obvious but undetectable biases of machine learning as a service applications.</p>
<p>Another challenge was the choice of algorithms for automated image analysis. We decided to use machine learning algorithms for similarity comparison due to the amount of climate images collected. This proved an important decision on several levels: On the one hand, the productivity and the pure image volume that can be processed were greatly expanded by automating the image analysis, as expected. On the other hand, the calibration (training) and data requirements of such machine learning algorithms are very expensive in acquisition and maintenance, and thus far exceeded the resources of our project. Therefore, we decided to use a pre-trained neural network called Inception v3 by Google, which was trained based on the ImageNet dataset. The concrete implications for the study are that the computed similarity between images is not based on a dataset explicitly designed for the climate imagery corpus, but is searched using a very generalist image corpus tagged with unknown motifs and models. In addition, the machine learning architecture makes it not impossible, but very difficult, to trace in detail the basis on which similarity relations between images were found. We know that such algorithms develop a structural view. We can thus deduce approaches, but not understand them in their entirety.</p>
<p>Finally, the choice of dimension reduction had a decisive impact on the qualitative reading of the visualisation. It decided on the definition of thehotspotsas well as the image clusters and, connected to this, their reception in terms of content. The process of qualitative perception and interpretation of the various image clusters or groups turned out to be a challenging moment within the pipeline. In order to be able to make content-related statements about Google&rsquo;s intercultural climate image occurrence, it was necessary to permanently switch between distance view and close view. Thus, a purely quantitative reading suggested by the t-SNE technology and its visualisation could not be fulfilled. The quantitative influence that the automated image analysis had on the qualitative image analysis was unambiguous. For example, the indexing of thehotspotimages manifested itself in a counting of recurring similar terms and their comparison among thelocales. In addition, the creation of the screenshot table finally provided a measurement method to decompose the t-SNEs into comparable components, to design order tableaus, and to be able to make cross-cultural statements about climate image occurrence.</p>
<p>Through the examples summarised, it is clear that our approach evolved over the course of the study intomore than distant viewingthat profoundly changed the epistemic practice of image analysis. Here, the methodological combination of automated image analysis and qualitative reading of data visualisation manifests itself as a challenging yet productive method for examining large image datasets. The combination of machine learning and visualization offers an alternative to graph-based layout methods and an alternative to purely keyword-based image research, where clusters emerge via language alone. The approach helps in the search for framings and the exploration of images themselves. Ultimately, the following questions stood at the end:</p>
<p>Why are Google image search results so clichéd in the case of climate change? At the level of how climate change image searches differ in different regions and language areas, the following points need to be discussed further: Climate communication using images seems to be fairly standardised around the world. It was striking how many similar and identical images Google displays in each location. Each location has similar clusters such as polar bears, polar regions, or people at conferences.</p>
<p>When we look at a t-SNE visualisation, the question is: How do these images cluster? There is no automated method for detecting the clusters. We had no comprehensible criterion for thehotspotsor for measuring the similarity of the images as what we eventually interpreted visually. Discrepancies between the qualitative determination of a group of images and the technical detection of the clusters by the algorithm became apparent. Similarity in the technical sense in the form of thehotspotsdoes not guarantee the determination of a high number of related images. As we have seen, the term clustering as a hinge term between methodological approaches can even be confusing. Thus, it is better to understandhotspotsas technical catch images instead of (qualitative) image groups. Regarding the t-SNE approach, we can recommend to mention the language use explicitly to be fair to the concepts of the different disciplines.</p>
<p>To what extent do human and automatic image recognition differ in image sorting? At first glance, it can be stated that humans tend to sort images according to motifs, while algorithms sort images according to structure. This became particularly clear in the form of a workshop in which we as a research team developed a section of the Google image corpus&rsquo; on the Germanlocale(550 images) as photographs and sorted them by hand. The sorting was intuitive and based on themes and motifs. In doing so, unlike the t-SNE algorithm in physical space, we did not set distances between image groups, since we did not know at the outset how many images would belong to each image group and since the size of the floor was limited. The efficiency of the technology to manage huge amounts of images was clearly felt here. The colour distribution of the manually created t-SNEs was a result of the image themes, while the algorithm sometimes blew up content-related image correlations due to different colour patterns. It nevertheless came out surprisingly that the human image selection converged with that of the t-SNE in terms of clustering the dominant image groups (drought/dry soil, heat/fire, earths, CO2- refineries, maps, cartoons, etc.). This is significant because the process of creating t-SNE visualisations from the source images does not extract semantic information from the dataset.</p>




























<figure ><img loading="lazy" alt="Image of pictures printed out and organized into clusters" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Manual image sorting of photographic prints to the dataset of the German locale with annotations
        </p>
    </figcaption>
</figure>
<h2 id="outlook">Outlook</h2>
<p>In conclusion, further research and in-depth arguments are needed to understand the full implications and scope of the use of automated image recognition in order to make a sound argument about the methods described. For example, Google image ranking and the logic of the PageRank algorithm, i.e., the images Google ranks on websites, need to be examined: Where exactly does the image corpus come from? Who supplies the images to be found? Are there some globally ubiquitous sources? Working with machine learning in the context of the Digital Humanities also needs to be questioned, especially on an infrastructural level. This is because working with datasets depends on software companies. There are few and large tech companies able to offer their pre-trained algorithms (often free and freely available). Reflection on the worldviews and values inscribed in them must not give way to strong fascination with technical productivity. In general, considering the qualitative moments in automation and the quantitative aspects in analysis according to our model of &lsquo;more than distant viewing&rsquo; is an elaborate and laborious investment, but ultimately rewarding for the research process.</p>
<h2 id="bibliography">Bibliography</h2>
<ul>
<li id="anci2007">Anci. (2017) _Analysing networked climate images._ <a href="https://anci.fh-potsdam.de">https://anci.fh-potsdam.de</a>.
</li>
<li id="bell2018">Bell, P. and Ommer, B. (2018). “Computer Vision und Kunstgeschichte – Dialog zweier Bildwissenschaften,” in Bell, P.; Dieckmann, L. and Kuroczyński, P. (ed.) _Computing Art Reader: Einführung in die digitale Kunstgeschichte_ . Heidelberg: arthistoricum.net. pp. 60-75.
</li>
<li id="creswell2007">Creswell, J. and Plano Clark, V. L. (2007) _Designing and Conducting Mixed Methods Research._ CA: Sage.
</li>
<li id="diers1997">Diers, M. (1997) _Schlagbilder: Zur politischen Ikonographie der Gegenwart_ . Frankfurt a.M.: Fischer. p. 7.
</li>
<li id="distillpub2017">Distill Pub. (2017) _Feature Visualization_ .<a href="https://distill.pub/2017/feature-visualization">https://distill.pub/2017/feature-visualization</a>.
</li>
<li id="drucker2011">Drucker, J. (2011) “Humanities approaches to graphical display,”  _Digital Humanities Quarterly_ , volume 5(1).<a href="http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html">http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html.</a>
</li>
<li id="drucker2017">Drucker, J. (2017) “Why Distant Reading Isn’t,”  _PMLA_ , volume 132(3), pp. 628-635.<a href="https://doi.org/10.1632/pmla.2017.132.3.628">https://doi.org/10.1632/pmla.2017.132.3.628</a>.
</li>
<li id="dork2018">Dörk, M. and Glinka, K. (2018) “Zwischen Repräsentation und Rezeption – Visualisierung als Facette von Analyse und Argumentation in der Kunstgeschichte,” in Bell, P.; Dieckmann, L. and Kuroczyński, P. (ed.) _Computing Art Reader: Einführung in die digitale Kunstgeschichte_ . Heidelberg: arthistoricum.net. p. 237.
</li>
<li id="dork2020">Dörk, M.; Bludau, M-J. and Brüggemann, V. (2020). “Zwischen Distanz und Nähe. Formen der Betrachtung und Bewegung in (digitalen) Sammlungen,” in Geipel, A.; Hohmann, G. and Sauter, J. (ed.) _Das digitale Objekt – Zwischen Depot und Internet_ . Munich: Deutsches Museum Verlag. pp. 115-123.
</li>
<li id="googleartsandculture2011">Google Arts & Culture (2011). _Google Arts & Culture Experiments_ .<a href="https://experiments.withgoogle.com/collection/arts-culture">https://experiments.withgoogle.com/collection/arts-culture</a>.
</li>
<li id="lecun1999">LeCun, Y. et al (1999) “Object Recognition with Gradient-Based Learning,”  _Shape, Contour and Grouping in Computer Vision_ , volume 1681.<a href="https://doi.org/10.1007/3-540-46805-6_19">https://doi.org/10.1007/3-540-46805-6_19</a>.
</li>
<li id="manovich2020">Manovich, L. (2020) _Cultural Analytics,_ Cambridge: MIT Press.
</li>
<li id="moretti2000">Moretti, F. (2000) _Conjectures on World Literature._ New Left Review.
</li>
<li id="offert2021">Offert, F. and Bell, P. (2021) “Perceptual bias and technical metapictures: critical machine vision as a humanities challenge,”   _AI & Soc,_  volume 36, pp. 1133–1144.<a href="https://doi.org/10.1007/s00146-020-01058-z">https://doi.org/10.1007/s00146-020-01058-z</a>.
</li>
<li id="rodriguez2013">Rodriguez, L. and Dimitrova, D.M. (2013) “The levels of visual framing,”  _Journal of Visual Literacy_ , volume 30(1), pp. 48-65.<a href="https://doi.org/10.1080/23796529.2011.11674684">10.1080/23796529.2011.11674684</a>.
</li>
<li id="rogers2017">Rogers, R. (2017) “Foundations of Digital Methods – Query Design,” in Van Es, K. and Schäfer, M.T. (ed.) _The Datafied Society – Studying Culture Through Data_ . Amsterdam: Amsterdam University Press. pp. 75–94.
</li>
<li id="schnapp2012">Schnapp, J. et al (ed.) (2012) _Digital Humanities_ . Cambridge: MIT Press.
</li>
<li id="searchengineland2010">Search Engine Land (2010) _Dear Bing, We Have 10,000 Ranking Signals To Your 1,000. Love, Google._ <a href="https://searchengineland.com/bing-10000-ranking-signals-google-55473">https://searchengineland.com/bing-10000-ranking-signals-google-55473</a>.
</li>
<li id="stanford2020">Stanford Vision Lab (2020) _ImageNet._ <a href="https://www.image-net.org">https://www.image-net.org</a>.
</li>
<li id="szegedy2015">Szegedy, C. et al. (2015) “Going deeper with convolutions,”  _Proceedings of the IEEE conference on computer vision and pattern recognition_ , pp. 1-9.
</li>
<li id="vandermaaten2008">Van der Maaten, L and Hinton, G.E. (2008) “Visualizing Data using t-SNE,”  _Journal of Machine Learning Research_ , volume 9, pp. 2579-2605.
</li>
<li id="yale2017">Yale Digital Humanities Lab (2017) PixPlot.<a href="https://dhlab.yale.edu/projects/pixplot/">https://dhlab.yale.edu/projects/pixplot/</a>.
</li>
</ul>
]]></content></entry><entry><title type="html">Radically Accessible Shakespeare: Cripping the Digital Shakespeare Canon through Universal Design and Disability Studies</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000659/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000659/</id><author><name>Christine M. Gottlieb</name></author><published>2022-12-22T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>The internet has vastly expanded access to Shakespeare resources and has led to the proliferation of born-digital Shakespeareana. Shakespeare exists online in archival materials, digital texts, apps, films, recordings of theatrical performances, YouTube videos, and other digital media. Shakespeare has enough of a digital presence to justify considering online Shakespeare a subset of the Digital Humanities field<a class="footnote-ref" href="#carson_kirwan2014"> [carson_kirwan2014] </a>. Articles in <em>DHQ</em> testify to the innovations of Digital Humanities projects focused on Shakespeare and early modern studies (<a class="footnote-ref" href="#lee_lee2017"> [lee_lee2017] </a>;<a class="footnote-ref" href="#giglio_venecek2009"> [giglio_venecek2009] </a>;<a class="footnote-ref" href="#mueller2014"> [mueller2014] </a>;<a class="footnote-ref" href="#jenstadetal2017"> [jenstadetal2017] </a>;<a class="footnote-ref" href="#kelley2017"> [kelley2017] </a>;<a class="footnote-ref" href="#boyd2021"> [boyd2021] </a>). In addition to disseminating established forms of Shakespeare scholarship to wider audiences, online modalities allow opportunities for radically new interpretations, perspectives, and ways of interacting with Shakespeare to emerge.</p>
<p>Making Shakespearean texts, performances, and scholarship more accessible to wider audiences motivates much of the online Shakespeare world. This view of Shakespeare’s accessibility often focuses on making materials more engaging, comprehensible, and freely available; accessibility for people with disabilities, however, is not often mentioned. While there has been productive scholarly dialogue between Disability Studies and Shakespeare studies (<a class="footnote-ref" href="#hobgood_wood2013"> [hobgood_wood2013] </a>;<a class="footnote-ref" href="#iyengar2015"> [iyengar2015] </a>;<a class="footnote-ref" href="#rowheyveld2018"> [rowheyveld2018] </a>;<a class="footnote-ref" href="#love2018"> [love2018] </a>;<a class="footnote-ref" href="#dunn2020"> [dunn2020] </a>;<a class="footnote-ref" href="#loftis2021"> [loftis2021] </a>;<a class="footnote-ref" href="#hobgood2021"> [hobgood2021] </a>;<a class="footnote-ref" href="#schaapwilliams2021"> [schaapwilliams2021] </a>), between Digital Humanities and Shakespeare studies (<a class="footnote-ref" href="#hirsch_craig2014"> [hirsch_craig2014] </a>;<a class="footnote-ref" href="#carson_kirwan2014"> [carson_kirwan2014] </a>;<a class="footnote-ref" href="#estill_jakacki_ullyot2016"> [estill_jakacki_ullyot2016] </a>;<a class="footnote-ref" href="#jenstadetal2018"> [jenstadetal2018] </a>;<a class="footnote-ref" href="#oneill2019"> [oneill2019] </a>;<a class="footnote-ref" href="#squeo_pennacchia_winckler2021"> [squeo_pennacchia_winckler2021] </a>), and between Disability Studies and Digital Humanities (<a class="footnote-ref" href="#williams2012"> [williams2012] </a>;<a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>;<a class="footnote-ref" href="#ellcessor2016"> [ellcessor2016] </a>;<a class="footnote-ref" href="#ellcessor2018"> [ellcessor2018] </a>;<a class="footnote-ref" href="#hamraie2018"> [hamraie2018] </a>), it is necessary to foster further collaboration across these three interdisciplinary fields. Words likeaccessibleanddemocratizedare often applied in discussions of online Shakespeare. However, until the world of online Shakespeare fully includes people with disabilities, it will not be truly accessible or democratized. Following Carson and Kirwan, I consider “the importance of Shakespeare as a case study to understand the developing nature of the digital world” <a class="footnote-ref" href="#carson_kirwan2014"> [carson_kirwan2014] </a>. In addition to providing acase study,the world of online Shakespeare can be a site in which interventions are implemented and shared to enhance the accessibility and inclusivity of digital worlds more broadly.</p>
<p>Scholars have illustrated the need for more inclusivity in Digital Humanities. The #TransformDH movement has drawn attention to how “Questions of race, class, gender, sexuality, and disability should be central to digital humanities and digital media studies” <a class="footnote-ref" href="#Baileyetal2016"> [Baileyetal2016] </a>. At the same time, Shakespeare’s outsized presence in Digital Humanities projects has been interpreted as a key example of the field’s “canon problem” <a class="footnote-ref" href="#estill2019"> [estill2019] </a>. Laura Estill writes: “It has been well-documented that major digital literary studies projects often focus on canonical authors. [&hellip;] yet comparatively few scholars have critiqued how digital humanities overrepresents perhaps the most canonical figure in all of English literature: Shakespeare” <a class="footnote-ref" href="#estill2019"> [estill2019] </a>. While the overrepresentation of Shakespeare in digital space is problematic, the massive scope of Shakespeare’s online presence makes it a useful entry point for critically evaluating accessibility and advocating for the accessibility and inclusivity of digital resources generally. It is crucial to fund and build Digital Humanities projects that focus on marginalized authors and communities. In addition to supporting projects that decenter the canon, it is also useful to critically analyze how the Shakespeare canon is continually reimagined in digital environments, and to work toward making this expanding canon as diverse, inclusive, and accessible as possible.</p>
<p>Digitization has already significantly transformed the Shakespeare canon. Douglas M. Lanier writes: “The disciplinary field of Shakespeare has expanded dramatically in recent decades. […] Shakespeare now includes performances, translations, transmediations, adaptations, appropriations, and even memes, not just in English but also in myriad languages from around the world” <a class="footnote-ref" href="#lanier2017"> [lanier2017] </a>. Digital projects, such as the MIT Global Shakespeares Video &amp; Performance Archive, highlight the diversity of Shakespearean performance and curate an ever-expanding canon<a class="footnote-ref" href="#mitglobalshakespeares"> [mitglobalshakespeares] </a>. As digital projects related to Shakespeare continue to grow, it is crucial to continually reflect upon who is included in and excluded from the digital corpus that comprisesShakespeare.Productions of Shakespeare’s plays by Deaf and disabled artists and Shakespearean criticism by Deaf Studies and Disability Studies scholars<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> are an integral part of the ever-expanding Shakespeare canon; these performances and perspectives can be further highlighted in digital projects.</p>
<p>Since digital Shakespeare resources are widely used pedagogical tools, critical reflection upon their accessibility and inclusivity is especially urgent. A recent special issue in <em>Research in Drama Education</em> examines the “diversity of pedagogical approaches to Shakespeare” borne through Shakespeare’s overrepresentation in educational and digital spaces globally<a class="footnote-ref" href="#bell_borsuk2020"> [bell_borsuk2020] </a>. The special issue “aim[s] to illustrate the cultural hegemonies present in teaching Shakespeare on a global scale, and how digital technologies potentially maintain these hegemonies, or confront them” <a class="footnote-ref" href="#bell_borsuk2020"> [bell_borsuk2020] </a>. In a similar vein, this article argues that Shakespeare pedagogy and digital technologies can maintain or confront ableism. The “canon problem” <a class="footnote-ref" href="#estill2019"> [estill2019] </a>that Shakespeare’s massive online presence encapsulates also presents an opportunity to “crip the canon,” to use Ann M. Fox’s phrase<a class="footnote-ref" href="#fox2010"> [fox2010] </a>.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Universal Design and Disability Studies can be employed to crip the digital Shakespeare canon, transforming both Shakespeare studies and digital spaces. I argue that cripping the digital Shakespeare canon includes two main components: (1) incorporating Universal Design to create digital environments that are as accessible as possible and (2) incorporating Disability Studies perspectives and disability representation to create anti-ableist content. This dual approach emphasizes both the importance of accessible technology and the necessity of incorporating Disability Studies theories and methods, including highlighting the contributions of Deaf and disabled artists and scholars and critically analyzing cultural representations of disability. Integrating Universal Design and Disability Studies approaches can improve the accessibility of Shakespeare resources, create engaging and empowering instructional technologies, and allow interpretations of Shakespeare’s works by Deaf and disabled scholars and artists to reach wider audiences.</p>
<p>In the following section, I provide an overview of Universal Design, review how it has been critiqued from Disability Studies perspectives, and discuss its continued importance for Digital Humanities projects. I then argue for centering disability in the digital Shakespeare canon and provide an overview of accessibility in Shakespeare studies. Following that, I analyze a key example of a digital work that expands the Shakespeare canon. I then analyze how YouTube functions as a digital Shakespeare archive with significant accessibility failures and discuss how Shakespeare’s overrepresentation in digital spaces can be utilized to improve accessibility. Finally, I discuss how crowdsourcing has been used and can continue to be used to improve accessibility. By highlighting both work that has been done to expand the canon and work that still must be done to make the expanding canon more accessible,I argue for engaging in ongoing critical reflection on the accessibility and inclusivity of the digital Shakespeare canon. Because of its canonicity, cripping online Shakespeare has the potential to impact digital archives generally by promoting increasingly accessible digital environments and anti-ableist content.</p>
<h2 id="universal-design">Universal Design</h2>
<p>Originally an architectural concept, Universal Design was developed by Ronald Mace who described it as “a way of designing a building or facility, at little or no extra cost, so it is both attractive and functional for all people, disabled or not” (<a class="footnote-ref" href="#mace1985"> [mace1985] </a>qtd. in<a class="footnote-ref" href="#hamraie2013"> [hamraie2013] </a>). George H. Williams has called for Digital Humanities projects to incorporate Universal Design, which he defines as “design that involves conscious decisions about accessibility for all” <a class="footnote-ref" href="#williams2012"> [williams2012] </a>.</p>
<p>Aimi Hamraie’s critical analysis of Universal Design defines its key features in the following quote:</p>
<blockquote>
</blockquote>
<p>Accessibility by design (design that prioritizes accessibility)Broad accessibility (accessibility for the greatest number of people possible)Added value (design that benefits disabled people also has benefits for nondisabled people)</p>
<p><a class="footnote-ref" href="#hamraie2013"> [hamraie2013] </a><br>
Drawing from feminist and disability theories, Hamraie critically analyzes these principles and discusses how Universal Design can be “a broad and intersectional social justice method through which designers can address more collective, overlapping, and intersectional exclusions from the built environment” <a class="footnote-ref" href="#hamraie2013"> [hamraie2013] </a>.</p>
<p>The purporteduniversalityof Universal Design has been critiqued (<a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>;<a class="footnote-ref" href="#hamraie2013"> [hamraie2013] </a>;<a class="footnote-ref" href="#hamraie2017"> [hamraie2017] </a>). Hamraie writes: “When the content of the universal is unspecified, UD can slip into vague notions of all or everyone that assume normate users and de-center disability” <a class="footnote-ref" href="#hamraie2013"> [hamraie2013] </a>. Hamraie emphasizes the importance of intersectional, disability justice-oriented approaches to design and focuses on “broad accessibility,” writing: “Broad accessibility serves as a more complex notion of inclusion, showing that UD must still center disability access in order to avoid lapsing into the normate template” <a class="footnote-ref" href="#hamraie2013"> [hamraie2013] </a>.</p>
<p>Richard H. Godden and Jonathan Hsy’s “Universal Design and Its Discontents” is a Digital Humanities-focused critique of Universal Design. Godden writes: “Although UD arose out of a real social and political response to the disabling aspects of everyday life for People with Disabilities, I want to suggest that the Universal in UD can carry with it some unintended and unexpected assumptions about normalcy and our physical orientation to the world” <a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>. Godden argues “we need to move forward by balancing the Universalist and utopian aims of UD with a more local, attentive approach to individual use” <a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>. Hsy writes: “Both UD and DH advocates often invoke an unrealized and idealized conception of collective space (physical or online) in order to challenge dominant beliefs and practices and to encourage people to join in a newly reconfigured sense of common purpose” <a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>.</p>
<p>As Hamraie argues in a section entitled “Cripping Universal Design,” while disability is often elided in Universal Design discourse, subsumed by an undertheorized concept ofuniversality,the termcrippowerfully centers disability, highlighting its critical, political, and cultural resonance<a class="footnote-ref" href="#hamraie2017"> [hamraie2017] </a>. Hamraie writes:</p>
<blockquote>
<p>in the early twenty-first century, around the time that Universal Design became a predominantly disability-neutral discourse, critical and crip theories of disability emerged to challenge the social model for overemphasizing the environmental construction of disability oppression over embodied experiences of disablement.Crip,a reclamation of the termcrippledating to the 1970s independent living movement, resists imperatives for normalization and assimilation. Crip theories contribute that disability is a valuable cultural identity, a source of knowledge, and a basis for relationality.<br>
<a class="footnote-ref" href="#hamraie2017"> [hamraie2017] </a><br>
Following Hamraie, I use the term cripping in its radical reclaimed sense to address the problem of discussions of universality and accessibility frequently eliding disability. When universality and accessibility are discussed generally, in both Shakespeare studies and Digital Humanities discourse, people with disabilities are often left out. Cripping Universal Design centers people with disabilities in the project of building an inclusive digital Shakespeare world — or any digital or physical world.</p>
</blockquote>
<p>As Tanya Titchkosky<a class="footnote-ref" href="#titchkosky2011"> [titchkosky2011] </a>has shown, the structures and spaces of universities, and even bureaucratic attempts to create moreaccess,are laden with and constitutive of conceptions about who belongs and what disability signifies. The same is true for digital spaces, and particularly academic digital spaces. As the physical and the virtual spaces of universities and knowledge circulation are increasingly blurred, attending to the digital worlds being created and analyzing who is constructed as “ <em>essentially excludable</em> ” <a class="footnote-ref" href="#titchkosky2011"> [titchkosky2011] </a>is crucial. Titchkosky writes: “I am particularly interested in how disability is socially produced as something that is not yet considered an essential participant in social life. Still, including disability as excludable is a scene where the meaning of the concept of all people is forged” <a class="footnote-ref" href="#titchkosky2011"> [titchkosky2011] </a>.</p>
<p>Rather than promoting utopian fantasies of Shakespeare asaccessible to allor design that is truly universal, I call for more attention to be paid to exclusions of disability in the world of digital Shakespeare, and in digital worlds generally. While truly Universal Design may be impossible, it is still a useful framework for pursuing increased accessibility. While truly universal access may be unattainable, we can still critique and correct inaccessibility, moving in the direction of broadened access.</p>
<p>Similarly, cripping the digital Shakespeare canon entails critiquing, rather than reinforcing, Shakespeare’s purporteduniversality.In advocating for inclusive Shakespeare programs and performances, Sonya Freeman Loftis cautions against “the failure of universal design and the way in which universal design may become bound up with notions about universal Shakespeare” <a class="footnote-ref" href="#loftis2021"> [loftis2021] </a>. The salience ofuniversalityandaccessin Shakespeare studies highlights the need to incorporate the Disability Studies critiques of these concepts in the interdisciplinary field.</p>
<p>My argument for cripping the digital Shakespeare canon is founded on Shakespeare’s ubiquity, not universality. Considering the size of Shakespeare’s massive presence online and how often these resources are used for educational purposes, the world of online Shakespeare should be a driving force in advancing Universal Design approaches. When Shakespeare resources are not fully accessible, people with disabilities — scholars and non-scholars alike — are excluded from exploring and co-creating the digital Shakespeare canon. Moreover, incorporating Universal Design principles into online Shakespeare resources enhances their pedagogical potential for a broad range of users. Captions on videos of Shakespearean performances make the work accessible to Deaf and hard-of-hearing audiences, while also aiding comprehension for hearing audiences. Descriptions of visual images make paintings accessible to blind users and can provide significant details to sighted audiences as well. While incorporating Universal Design increases accessibility and can deepen engagement for a broad range of users, attentiveness to Disability Studies theory is necessary to combat the tendency to reproduce notions ofuniversalandaccessthat exclude disability (<a class="footnote-ref" href="#hamraie2013"> [hamraie2013] </a>;<a class="footnote-ref" href="#hamraie2017"> [hamraie2017] </a>;<a class="footnote-ref" href="#titchkosky2011"> [titchkosky2011] </a>;<a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>).</p>
<h2 id="cripping-the-digital-shakespeare-canon">Cripping the Digital Shakespeare Canon</h2>
<p>In addition to designing digital resources that are more accessible, cripping the digital Shakespeare canon must also include analyzing how disability is represented in online content. Shakespeare’s plays are full of characters with disabilities that require critical analysis, as Allison P. Hobgood and David Houston Wood discuss in their introduction to <em>Recovering Disability in Early Modern England</em> :</p>
<blockquote>
<p>Shakespeare’s creative output encompasses a broad range of disabled selfhoods: it moves across a spectrum from bodily to metaphysical disfigurement, ranging from instances of blindness to limping, from alcoholism to excessive fat, from infertility to war wounds, from cognitive impairments to epilepsy, from senility tomadness,and from feigned disability to actual.<br>
<a class="footnote-ref" href="#hobgood_wood2013"> [hobgood_wood2013] </a><br>
Shakespeare’s representations of disability can either reinforce or challenge ableism depending on how the plays are taught in classrooms, performed on stage and in film, and — crucially — presented online. Online resources may reinforce stereotypes by presenting Shakespeare’s representations of physical and mental differences without the critical awareness that Disability Studies provides. Cripping the digital Shakespeare canon entails both correcting inaccessible digital forms and confronting ableist content.</p>
</blockquote>
<p>Digital humanists can learn from pedagogical and theatrical experiments in cripping content and increasing accessibility. In “How to Crip the Undergraduate Classroom: Lessons from Performance, Pedagogy, and Possibility,” Fox outlines methods to center disability in courses and on campuses<a class="footnote-ref" href="#fox2010"> [fox2010] </a>. In a section entitled “Cripping the Canon,” Fox asks: “how do we make the knowledge about and creative work of disabled people (including activists, educators, artists, scholars, and thinkers) available to our students within our classrooms?” <a class="footnote-ref" href="#fox2010"> [fox2010] </a>. She poses the question: “Where could I locate the presence of disability into that which I was already teaching?” <a class="footnote-ref" href="#fox2010"> [fox2010] </a>. These questions can animate not only classrooms, but also the world of online Shakespeare and Digital Humanities projects generally. Digital humanists can “locate the presence of disability” <a class="footnote-ref" href="#fox2010"> [fox2010] </a>by making accessibility, inclusivity, and critical analysis of representations of disability integral parts of their projects. Cripping the canon involves not only giving critical attention to disability-related content, but also to expanding academic epistemologies; Fox writes: “To crip the canon might also mean cripping our rather canonical ways of reading, researching, and otherwise approaching and engaging an individual discipline, its core ideas and subject matter, introducing or framing them instead with a disability perspective” <a class="footnote-ref" href="#fox2010"> [fox2010] </a>. Cripping the digital Shakespeare canon requires going beyond making digital materials usable by people with disabilities; it entails incorporating critical Disability Studies perspectives, increasing disability representation, analyzing how digital materials are reinforcing or combatting ableism, and considering whose perspectives are represented or omitted. This can be applied to not only to digital Shakespeare resources, but also to digital projects generally. The range and volume of Shakespearean material online makes it a useful site for evaluating accessibility and inclusivity, developing practices that can be applied more widely, and, more radically, reimagining and reinventing both the canon and methods of engaging with it. Cripping Shakespeare — the center of the English literary canon — transforms our understanding not only of Shakespeare’s poems and plays, but also of literary studies and digital environments more broadly.</p>
<p>Sonya Freeman Loftis’s recent book, <em>Shakespeare and Disability Studies</em> , makes a compelling case for “Cripping Shakespeare Studies” <a class="footnote-ref" href="#loftis2021"> [loftis2021] </a>. Loftis analyzes how Shakespeare’s canonicity and ubiquity have promoted a focus on accessibility, writing:</p>
<blockquote>
<p>Over the past twenty years, Shakespeare theatres have been particularly innovative in the area of accessibility. This is, in part, because modern Shakespearians have always been driven by the need for access. Shakespeare has a central place in the curriculum, and making Shakespeare accessible to students has long been a goal in the modern classroom. […] four hundred years have already reduced the accessibility of the source text for lay readers and audiences. Indeed, popular culture often depicts Shakespeare as inherently difficult to understand. Shakespeare has become the classic symbol of that which is highbrow, and teachers and directors are charged with making his work accessible for everyone — from popular audiences to reluctant high schoolers. This means that Shakespearians are in a natural position to consider disability access; it makes sense that Shakespeare theatres would approach disability as just one more point of potential inaccessibility.<br>
<a class="footnote-ref" href="#loftis2021"> [loftis2021] </a><br>
As Loftis has shown, a commitment to making Shakespeare accessible has led to Shakespeare theaters becoming leaders in inclusive performance. Loftis writes: “it is natural that an emphasis on general accessibility would lead to increased disability awareness — in the wake of the disability rights movement and in light of the growing neurodiversity movement, the endeavour to create access for all must also include those with physical and mental disabilities” <a class="footnote-ref" href="#loftis2021"> [loftis2021] </a>. People working on online Shakespeare projects, and indeed, digital humanists generally, should have the same goal of becoming leaders in accessibility. Access is not only a key term in Shakespeare studies, it is also a central concept in Digital Humanities discourse. Ellcessor writes: “Digital tools and services are routinely lauded for their ability to increase <em>access</em> to texts, resources, educational experiences, and new forms of pedagogy. Yet, merely making material available is insufficient to promote genuine access” <a class="footnote-ref" href="#ellcessor2018"> [ellcessor2018] </a><sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
</blockquote>
<p>In discussing inventive approaches to accessibility by Shakespeare’s Globe, the Royal Shakespeare Company, and the Oregon Shakespeare Festival, Loftis writes: “Access can be artistic — it can be an integral part of the performance experience, shaping the interpretation both of the show and of Shakespeare’s text” <a class="footnote-ref" href="#loftis2021"> [loftis2021] </a>. The same spirit of accessibility as innovation can be foregrounded in digital Shakespeare projects, and in Digital Humanities projects generally. Loftis writes: “an understanding of disability theory is essential for scholars, teachers, and directors of Shakespeare. Statistics suggest that as many as one out of four people could potentially be considered as disabled. Since providing quality accommodations and pedagogical materials for users with disabilities requires a basic understanding of disability theory, teachers and directors of Shakespeare who wish to reach general audiences have a good reason to engage with disability studies” <a class="footnote-ref" href="#loftis2021"> [loftis2021] </a>. Similarly, it is essential that creators of digital Shakespeare resources — and indeed, all digital resources — have an awareness of Disability Studies. As Loftis notes, incorporating disability theory entails valuing the knowledge that comes from lived experience, and thus including people with disabilities in projects’ leadership positions<a class="footnote-ref" href="#loftis2021"> [loftis2021] </a>. In her review of inclusive Shakespeare theaters, Loftis notes that “accessibility is always a work in progress, never a static end goal that can be achieved” <a class="footnote-ref" href="#loftis2021"> [loftis2021] </a>. Working toward making performances as accessible as possible requires ongoing collaboration with people with disabilities and a commitment to welcoming audience members with disabilities into the theater, which often begins by highlighting access through the theater’s website<a class="footnote-ref" href="#loftis2021"> [loftis2021] </a>. Jill Marie Bradbury<a class="footnote-ref" href="#bradbury2022"> [bradbury2022] </a>provides a critical account of theatrical performances of Shakespeare that include ASL, written from her perspective as a deaf audience member. Bradbury writes: “I argue that hearing directors who work with deaf actors and ASL have an ethical responsibility to be inclusive of deaf audiences. This can be accomplished by centering deaf perspectives and experiences both onstage and in front-of-house practices” <a class="footnote-ref" href="#bradbury2022"> [bradbury2022] </a>.</p>
<p>What would it mean to truly welcome Deaf and disabled people into the world of online Shakespeare? How could the digital Shakespeare canon be more accessible and inclusive? I have been arguing that this process includes incorporating Universal Design to increase the accessibility of digital content and incorporating Disability Studies perspectives to confront ableism in both form and content. In the next section, I will analyze a digital work that expands the Shakespeare canon through Universal Design and Deaf studies perspectives.</p>
<h2 id="expanding-the-digital-shakespeare-canon-tyrone-giordano-and-jill-marie-bradburys-_digital-shakespeares_">Expanding the Digital Shakespeare Canon: Tyrone Giordano and Jill Marie Bradbury’s <em>Digit(al) Shakespeares</em></h2>
<p>Tyrone Giordano and Jill Marie Bradbury’s <em>Digit(al) Shakespeares</em> <a class="footnote-ref" href="#giordano_bradbury2015"> [giordano_bradbury2015] </a>is a work of digital scholarship at the intersection of Deaf studies, Digital Humanities, and Shakespeare studies.The project consists of a 10-minute film, presented in ASL with English subtitles, and without audio. Crucially, the project also consists of a transcript and description of the video, which has been provided by Giordano and Bradbury as an integral part of the digital work. This delivery of the content through multiple forms exemplifies the Universal Design approach of <em>Digit(al) Shakespeares</em> : it is designed, from the start, with accessibility built in. The high-quality transcript and description of the video makes the content accessible to screen reader users and provides rich descriptions of and contextual information for video clips included in the film, which enhances the learning experience for all users.</p>
<p>The description of the project states:</p>
<blockquote>
<p>Digit(al) Shakespeares brings Deaf studies perspectives to bear on both disability studies and digital humanities. Deaf studies focuses on what the experience of deafness enables, rather than disables. Just as we can reconceptualize hearing loss as deaf gain, so we can reframe Shakespeare’s works as being at heart visual rather than auditory. This can lead to a richer experience of Shakespeare for everyone, regardless of hearing status. Throughout the video, clips illustrate the power of sign language to convey the Bard’s virtuosity in creating images through words. New media and technology allow Deaf people to share translations and performances of Shakespeare’s works across the globe. Digital archives can collect and preserve these, so they are available for Deaf, hard of hearing, and hearing people to study and appreciate. Deaf and hard of hearing people also need access to digital Shakespeare archives based on spoken language via high quality captioning. Access should be built into digital archives from the start, so that it becomes a central element of the overall project design, rather than a problem to be solved at the end.<br>
<a class="footnote-ref" href="#giordano_bradbury2015"> [giordano_bradbury2015] </a><br>
This description highlights the pedagogical and scholarly value that a Universal Design approach adds for all users, a centerpiece of Universal Design philosophy, through the claim that “This can lead to a richer experience of Shakespeare for everyone” <a class="footnote-ref" href="#giordano_bradbury2015"> [giordano_bradbury2015] </a>. However, rather than tacitly endorsing an undertheorizeduniversalsubject, as Universal Design approaches have frequently done, the project powerfully centers Deaf perspectives, both in representational content (through curating and presenting a performance history of Shakespeare in ASL) and through digital design (by featuring built-in accessibility that centers ASL and by advocating for digital archives to be accessible to Deaf and hard of hearing people).</p>
</blockquote>
<p>The content, methodology, and design of Giordano and Bradbury’s project illuminate the scholarly, artistic, and social value of approaching Shakespeare from a Deaf perspective. The Universal Design of the project welcomes a broad range of users to engage with and respond to this significant and underrepresented approach to Shakespeare. Giordano and Bradbury highlight the need for more accessible digital archives while showcasing what is gained from studying Shakespeare from Deaf studies perspectives.</p>
<p><em>Digit(al) Shakespeares</em> goes beyond Universal Design to decenter the customary privileging of hearing audiences. The lack of audio in the video both highlights the methodology of centering the visual over the auditory in the project’s approach to Shakespeare and decenters audist privilege. While the content of the digital work can be accessed by a broad range of users, hearing audiences are informed: “NOTE: There is no sound throughout the video” <a class="footnote-ref" href="#giordano_bradbury2015"> [giordano_bradbury2015] </a>.</p>
<p>Hsy has explored how the <em>Deaf Studies Digital Journal</em> ( <em>DSDJ</em> ) decenters the privileging of hearing audiences by providing video of scholarship in ASL that is not always accompanied by English translations<a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>. Hsy describes the productive tension of exploring <em>DSDJ</em> in a workshop focused on increasing the accessibility of Digital Humanities projects:</p>
<blockquote>
<p>An intriguing aspect of the group discussion of <em>DSDJ</em> in the <em>Accessible Future</em> workshop in Austin in 2014 was the sense that the lack of audio or captions in these videos make the contentinaccessibleby one set of embodied norms (that is, a set of UD principles that would call for embedded features for internet users who have visual impairments). As I reflect on this conversation afterwards, I have come to realize that the uneven media functionality of the journal suggested a discomforting social reality for those of us who were present at that particular workshop: much of the content of this Deaf-oriented journal was at the time rendered <em>inaccessible to a hearing majority</em> (or, to put things more precisely, the online journal’s content was only partially accessible to non-ASL users).<br>
<a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>As Hsy analyzes, this is an instance in which a digital work’s non-adherence to Universal Design principles is revelatory: “the current user interface appropriately forces me to confront my own audiocentric (and Anglophone) privilege and I find myself navigating an online linguistic environment that is only unevenly or partially configured for my use” <a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>.</p>
</blockquote>
<p>While <em>Digit(al) Shakespeares</em> is broadly accessible due to its Universal Design approach, it still powerfully decenters the privilege of non-ASL users. While English subtitles appear during experts’ statements and some ASL Shakespeare performances, many clips of actors performing Shakespeare in ASL are not subtitled. The transcript and description of the video provide information about all of the clips included in the film, cataloguing a rich archive of ASL Shakespeare performance history. This combination of providing broad accessibility while centering Deaf perspectives makes <em>Digit(al) Shakespeares</em> a strong example of a Digital Humanities work that incorporates Universal Design principles without tacitly endorsing auniversaluser and audist privilege.</p>
<p>Giordano and Bradbury’s project highlights the potential of combining Digital Humanities and Deaf Studies approaches. Hsy analyzes how Giordano and Bradbury’s project “deftly exploits the manifold valence of the digit in its pluralized title <em>Digit(al) Shakespeares</em> ” <a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>. Viewing Shakespeare from a visual perspective fundamentally transforms the Shakespeare canon and opens up new modes of engagement that utilize possibilities that digital environments provide. Miako Rankin explains: “So much has happened in the last 15 years, with smartphones, touchpad technology, video-to-video interaction, Deaf people are interacting and communicating with one another more than ever before” <a class="footnote-ref" href="#giordano_bradbury2015"> [giordano_bradbury2015] </a>. As Jill Bradbury discusses, this technology has a significant impact on Deaf approaches to Shakespeare: “Digital technology is fast and cheap now, enabling Deaf people the world over to experience Shakespeare’s poetry and create films and translations to share so others might enjoy that work” <a class="footnote-ref" href="#giordano_bradbury2015"> [giordano_bradbury2015] </a>.</p>
<p>Bradbury continues: “It is paramount that we collect those films and experiences, essentially forming a digital archive for us, not only to preserve this work for future generations, but also to create a space where deaf and hearing people both can study and appreciate the work” <a class="footnote-ref" href="#giordano_bradbury2015"> [giordano_bradbury2015] </a>. Ethan Sinnott explains the enormous potential of digital archives: “All this becomes a library, one that the Deaf community can access regardless of their background: whether their interests lie in theatre, education, English, or if they are interested in improving bilingual ASL-English access” <a class="footnote-ref" href="#giordano_bradbury2015"> [giordano_bradbury2015] </a>.</p>
<p>Online spaces provide significant opportunities to present and preserve ASL translations of Shakespeare. The ASL Shakespeare Project’s website<a class="footnote-ref" href="#ASLShakespeare"> [ASLShakespeare] </a>, which documents the process of translating Shakespeare’s <em>Twelfth Night</em> into ASL, is “the first bilingual and bicultural website on Shakespeare on the internet” <a class="footnote-ref" href="#novak2008"> [novak2008] </a>. The ASL Shakespeare Project, like Giordano and Bradbury’s <em>Digit(al) Shakespeares</em> project, employs digital technologies to expand the Shakespeare canon.</p>
<h2 id="the-inaccessible-shakespeare-archive-on-youtube">The Inaccessible Shakespeare Archive on YouTube</h2>
<p>The world of online Shakespeare includes spaces that encourage productive exchange between humanities scholars and the broader public. This traffic is not one-way: while scholars can reach wider audiences online, scholars and students routinely use online content created by non-academics. The Shakespeare canon is curated, adapted, and expanded in these digital spaces. For the evolving Shakespeare canon to be inclusive, these sites of exchange and engagement must be fully accessible.</p>
<p>YouTube is a key platform on which this exchange occurs. Christy Desmet refers to YouTube as “what for the past decade has been one of the most popular, most prevalent, and most innovative sources for teaching Shakespearean drama” <a class="footnote-ref" href="#desmet2016"> [desmet2016] </a>. Indeed, YouTube has transformed Shakespeare performance studies, as John Lavagnino writes: “YouTube was not founded for the purpose of transforming the study of Shakespeare in performance by providing a vastly larger range of material to see than had ever been available before, but that was one of its effects. In this as in other areas of study, digital approaches became prominent because they had vast numbers of people outside the academy behind them” <a class="footnote-ref" href="#lavagnino2014"> [lavagnino2014] </a>. YouTube users are producing a seemingly-democratized Shakespearean archive, as Stephen O’Neill describes: “the small screens of YouTube grant access to an accidental archive of Shakespeareana, to user-generated Shakespeares and to such genres as the video mashup (combining one or more audio tracks with moving images, sometimes with ironic effect), the vlog (or video diary) and the fan-made movie trailer” <a class="footnote-ref" href="#oneill2014"> [oneill2014] </a>.</p>
<p>YouTube’s seemingly-democratized Shakespeare archive, however, is failing miserably when it comes to accessibility. Many Shakespeare videos do not have captions or use automatically generated captions that are grossly inaccurate when attempting to capture Shakespeare’s verse.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> It is crucial that these videos are captioned accurately, especially since they are often used as educational resources. Accurate captions are both an essential accessibility feature and an aid to all users’ comprehension of Shakespearean language.</p>
<p>Williams has surveyed ways in which the accessibility of Digital Humanities projects could be improved and offered suggestions, including crowdsourcing the captioning and transcriptions of video content<a class="footnote-ref" href="#williams2012"> [williams2012] </a>. Shakespeare’s texts are freely available in Open Access digital formats,<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> which can aid the captioning of Shakespeare videos. Crowdsourcing the captioning and transcriptions of digital Shakespeare videos could make use of the abundance of Shakespeare material online to significantly improve accessibility. This is an example of how Shakespeare’s overrepresentation in digital spaces (in both text and video) can be utilized to improve accessibility and model best practices for digital archives.</p>
<p>YouTube’s community captions feature had the potential to be used to crowdsource captions in this way and radically improve the accessibility of the digital Shakespeare archive, yet this feature was discontinued on September 28, 2020<a class="footnote-ref" href="#lyons2020"> [lyons2020] </a>. Deaf YouTuber and advocate for captions Rikki Poynter has discussed the importance of this feature in Deaf, hard of hearing, and disability communities and critiqued YouTube’s failure to promote the feature, make it accessible on mobile devices, or improve the feature rather than dismantling it<a class="footnote-ref" href="#poynter2020"> [poynter2020] </a>. While more YouTube users are now submitting their own captions due to increased awareness<a class="footnote-ref" href="#odell2021"> [odell2021] </a>, much more remains to be done. Especially since YouTube has been transformative in Shakespeare studies, it is imperative that Shakespeareans raise awareness about accurately captioning the Shakespeare performance archive on YouTube. Doing so will not only improve the accessibility of the ever-growing Shakespeare canon, but will also increase awareness about the importance of captioning videos generally.</p>
<p>In addition to captions, audio descriptions are needed to make the Shakespeare archive on YouTube accessible. Hamraie writes: “Miele’s crowdsourcing technology, YouDescribe.org, enlists sighted people to audio-describe YouTube videos, creating a database of integrated narrative tracks, providing information not included in YouTube’s automatic textual captions” <a class="footnote-ref" href="#hamraie2018"> [hamraie2018] </a>. At the time of this writing, two audio-described videos were available whenShakespearewas searched on <em>YouDescribe</em> <a class="footnote-ref" href="#youdescribe"> [youdescribe] </a>. Especially since Shakespeare videos on YouTube are often used as educational resources, crowdsourcing audio descriptions for more Shakespeare content would be a valuable digital accessibility project.</p>
<p>In addition to improving the accessibility of YouTube materials, it is important to critically analyze how disability is represented and performed in YouTube content. Ayanna Thompson has demonstrated that YouTube’s “large and complex archive of classroom-inspired Shakespeare performances” provides “a window onto production and reception that highlights uncomfortable aspects of the texts […] specifically, the dynamics of race and gender” <a class="footnote-ref" href="#thompson2010"> [thompson2010] </a>. Scholars have critically analyzed representations of race, gender, and sexuality in YouTubers’ Shakespeare adaptations (<a class="footnote-ref" href="#thompson2010"> [thompson2010] </a>;<a class="footnote-ref" href="#oneill2014"> [oneill2014] </a>;<a class="footnote-ref" href="#iyengar_desmet2012"> [iyengar_desmet2012] </a>). More scholarship is needed on how physical and mental disability is represented and metatheatrically performed in Shakespeare-related YouTube videos. As the user-generated Shakespeare archive of YouTube continues to evolve, ongoing research into how intersections of race, gender, sexuality, and disability are represented is essential.</p>
<h2 id="crowdsourcing-shakespearean-accessibility">Crowdsourcing Shakespearean Accessibility</h2>
<p>In addition to improving the accessibility of YouTube videos, crowdsourcing can be used to make a wide range of digital content more accessible. Melissa Terras, in an introduction to “Crowdsourcing in the Digital Humanities,” writes:</p>
<blockquote>
<p>Alongside the widespread success of collaboratively produced resources such as <em>Wikipedia</em> came a movement in the cultural and heritage sectors to trial crowdsourcing – the harnessing of online activities and behavior to aid in large-scale ventures such as tagging, commenting, rating, reviewing, text correcting, and the creation and uploading of content in a methodical, task-based fashion (Holley, 2010)–to improve the quality of, and widen access to, online collections.<br>
<a class="footnote-ref" href="#terras2016"> [terras2016] </a>While a general view ofaccessis highlighted here, crowdsourcing methods can be used to improve accessibility for people with disabilities<a class="footnote-ref" href="#williams2012"> [williams2012] </a>.</p>
</blockquote>
<p>Victoria Van Hyning<a class="footnote-ref" href="#vanhyning2019"> [vanhyning2019] </a>has discussed how crowdsourcing can increase the accessibility of digital archives, particularly for archives of early books and manuscripts that cannot be rendered accurately through OCR. Van Hyning writes: “Virtual volunteers all around the world are eager to learn and contribute to the vast project of making the world’s textual records more widely accessible, not only for search, but for those, such as blind and partially sighted people, who use screen readers” <a class="footnote-ref" href="#vanhyning2019"> [vanhyning2019] </a>.</p>
<p>Van Hyning discusses her work on the <em>Shakespeare’s World</em> project, a collaboration between Zooniverse (at which she was Humanities Principal Investigator), the Folger Shakespeare Library, and the <em>Oxford English Dictionary</em> . The project used crowdsourcing to transcribe early modern handwritten recipes and letters, which increases the accessibility of these texts for all users, expands the searchable digital archive, and provides early modern manuscript sources to be considered in the <em>Oxford English Dictionary</em> , which can increase the representation of women writers<a class="footnote-ref" href="#vanhyning2019"> [vanhyning2019] </a>. Van Hyning writes:</p>
<blockquote>
<p>The primary goal of <em>Shakespeare’s World</em> is to create base transcriptions for <em>Early Modern Manuscripts Online</em> (<a href="https://emmo.folger.edu/">https://emmo.folger.edu/</a>) at the Folger Library, which provides manuscript images and word searchable diplomatic, semi-diplomatic, and regularized transcriptions. Manuscript curator Heather Wolfe and the creators of <em>EMMO</em> intend for it to democratize access to manuscripts and to give manuscripts parity with print: the name is a deliberate homage to <em>EEBO and ECCO</em> .<br>
<a class="footnote-ref" href="#vanhyning2019"> [vanhyning2019] </a>Whitney Sperrazza’s review of <em>Early Modern Manuscripts Online</em> notes “its unprecedented ability to bring together early modern scholars, students, and wider public audiences around a digital resource” <a class="footnote-ref" href="#sperrazza2020"> [sperrazza2020] </a>. Sperrazza discusses the project’s implications in relation to the democratization of paleography and accessibility of manuscripts.</p>
</blockquote>
<p>The success of the <em>Shakespeare’s World</em> project, and its media coverage, including Roberta Kwok’s “Crowdsourcing for Shakespeare” article in <em>The New Yorker</em> <a class="footnote-ref" href="#kwok2017"> [kwok2017] </a>, demonstrate how Shakespeare can motivate volunteers to participate in significant crowdsourcing projects, such as the transcription of non-Shakespearean materials produced during Shakespeare’s era. Building upon this, it is crucial to ensure that ever-growing online Shakespeare archives are fully accessible to people with disabilities. What would it look like to apply the crowdsourcing techniques of the <em>Shakespeare’s World</em> project to make the entire world of Shakespeare online more accessible? From manuscripts to YouTube, centering accessibility will expand access for people with disabilities and benefit all users. Centering accessibility is essential to recognizing the goal of democratizing access so often seen in online Shakespeare discourse, and in Digital Humanities discourse generally.</p>
<p>Tyrone Giordano’s thesis, “Toward a Crowdsourced Model for ASL Translations of Shakespeare’s Works” <a class="footnote-ref" href="#giordano2013"> [giordano2013] </a>, explores the possibilities that current digital technologies offer for sharing and preserving ASL translations of Shakespeare. The thesis “attempts to address the problem of lack of translation material by proposing an internet-based crowdsourcing model to create and allow for a multiplicity of and successive generations of ASL translations of Shakespeare’s plays to exist” <a class="footnote-ref" href="#giordano2013"> [giordano2013] </a>. Giordano writes:</p>
<blockquote>
<p>The increasing digitization of Shakespeare, and the market for localization of Shakespeare’s texts, illustrates the need for an online resource utilizing ASL in connection with Shakespeare. This leads to the not-yet-realized vision of what I believe is the next level in ASL translation: an open source internet-based project where anybody can input his or her own translations of Shakespeare’s works, and those seeking a translated body of work can pick and choose from among these translations, making the translations their own.<br>
<a class="footnote-ref" href="#giordano2013"> [giordano2013] </a>Giordano’s proposal balances collaboration and sharing of content with respect for translators’ intellectual property and attentiveness to the exploitation Deaf communities have faced<a class="footnote-ref" href="#giordano2013"> [giordano2013] </a>.</p>
</blockquote>
<p>Hamraie describes bringing a disability justice perspective to crowdsourcing in a Digital Humanities project mapping campus accessibility, writing: “Critical accessibility mapping yields new modes of subjectification around accessibility, reconceptualizing the labor of critical publics and participants such that marginalized users retain leadership as experts who devise accessibility <em>criteria</em> , while allies collaborate on data collection” <a class="footnote-ref" href="#hamraie2018"> [hamraie2018] </a>. While Hamraie<a class="footnote-ref" href="#hamraie2018"> [hamraie2018] </a>focuses on mapping the accessibility of physical spaces, a similar approach could be applied to make online spaces more accessible. Iranowska<a class="footnote-ref" href="#iranowska2019"> [iranowska2019] </a>has analyzed users’ experiences with platforms used for crowdsourcing projects, such as <em>Shakespeare’s World</em> . It would be useful to include perspectives of users with disabilities in reviews of digital projects and platforms, for Shakespeare resources and for digital projects generally.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Incorporating Disability Studies perspectives and methodologies into the wide-ranging and ever-expanding digital Shakespeare archive will ensure that this critical awareness reaches a larger audience. Shakespeare has a massive audience, as Sylvia Morris notes:</p>
<blockquote>
<p>It’s been estimated that his work is studied by 50 per cent of schoolchildren worldwide, and at all educational levels. He’s read and performed in translation [&hellip;] and his plays are constantly re-invented by groups from all over the world. There is huge potential for digitised versions of his work, for images and video of plays in performance, to be enjoyed as they are, or to be reinterpreted by creative artists and users of social media, not just by an academic audience.<br>
<a class="footnote-ref" href="#morris2014"> [morris2014] </a>Shakespeare’s immense audience highlights both the “canon problem” <a class="footnote-ref" href="#estill2019"> [estill2019] </a>and the urgency of creating a more accessible and inclusive digital Shakespeare canon. Because of Shakespeare’s wide-ranging impact in education, the arts, and popular culture, it is crucial to increase the accessibility and inclusivity of online Shakespeare resources. Cripping the digital Shakespeare canon can impact how Shakespeare is taught, engaged with, and performed. Due to Shakespeare’s outsized influence, it will also impact how other digital environments are constructed.</p>
</blockquote>
<p>Disability Studies and other cultural studies approaches to Shakespeare must reach beyond academic subfields to general readers who engage with Shakespeare’s texts and to the actors, artists, and educators who mediate and re-create these texts for future generations. Online environments are ideal for this type of outreach. Alan Liu<a class="footnote-ref" href="#liu2012"> [liu2012] </a>has argued that advocating for the humanities can be a key contribution of the Digital Humanities field. He writes: “The digital humanities […] can create, adapt, and disseminate new tools and methods for reestablishing communication between the humanities and the public” <a class="footnote-ref" href="#liu2012"> [liu2012] </a>. Liu calls for digital humanists to “move seamlessly between text analysis and cultural analysis” ; he writes: “Truly to partner with the mainstream humanities, digital humanists now need to incorporate cultural criticism in a way that shows leadership in the humanities” <a class="footnote-ref" href="#liu2012"> [liu2012] </a>. Incorporating Universal Design approaches and Disability Studies awareness in Digital Humanities projects can create truly accessible and inclusive resources and further projects’ public humanities impact.</p>
<p>Godden and Hsy<a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>have discussed how Universal Design was not intended to be limited to adding accessibility features; it is far more radical. As Hsy puts it:</p>
<blockquote>
<p>I wonder if a general discursive tendency to conflate UD with narrower discourses ofaccessibilityrisks enacting the reverse of what UD initially envisions. Rather than attending to embodied variance as a way to multiply and sustain diverse modes of interaction with physical or digital environments, a narrowly conceived notion of UD as a set of separate (or supplemental)accessibility featuresconceives the challenge of UD as one of integrating disabled people into an existing set of nondisabled norms.<br>
<a class="footnote-ref" href="#godden_hsy2018"> [godden_hsy2018] </a>Rather than merely adding accessibility features to Shakespeare resources, cripping the digital Shakespeare canon requires designing accessible and inclusive resources from the start, bringing critical attention to characters with disabilities, and centering performances, scholarship, and resources created by and for Deaf and disability communities. It entails promoting diverse ways of reading Shakespeare, performing Shakespeare, and responding to Shakespeare. It demands continually evaluating and expanding the Shakespeare canon as it evolves online.</p>
</blockquote>
<p>Conversations about Shakespeare’s accessibility in online spaces, and digital access in general, will always be insufficient if accessibility for people with disabilities is overlooked. As Shakespeare continues to be reinvented in digital space, as streamed videos and remixes inspire educators and filmmakers of the future, let’s ensure that these spaces are not only fully accessible, but also incorporate perspectives from Disability Studies. Doing so will not only benefit Shakespeare studies, but will also promote the creation of more accessible and inclusive digital environments more widely.</p>
<ul>
<li id="ASLShakespeare">ASL Shakespeare. _ASL Shakespeare: The American Sign Language Shakespeare Project_ . Available at:<a href="http://aslshakespeare.org/">http://aslshakespeare.org/</a>.
</li>
<li id="Baileyetal2016">Bailey, M., Cong-Huyen, A., Lothian, A., and Phillips, A. (2016) “Reflections on a Movement: #transformDH, Growing Up” in Gold, M.K.and Klein, L.F. (eds.), _Debates in the Digital Humanities 2016_ . Available at:<a href="https://dhdebates.gc.cuny.edu/projects/debates-in-the-digital-humanities-2016">https://dhdebates.gc.cuny.edu/projects/debates-in-the-digital-humanities-2016</a>.
</li>
<li id="bell_borsuk2020">Bell, H. and Borsuk, A. (2020) “Teaching Shakespeare: Digital Processes” , _Research in Drama Education: The Journal of Applied Theatre and Performance_ , 25(1): pp.1-7. Available at:<a href="https://doi.org/10.1080/13569783.2019.1704241">https://doi.org/10.1080/13569783.2019.1704241</a>.
</li>
<li id="besner2019">Besner, L. (2019) “When Is a Caption Close Enough?” , _The Atlantic_ , 09 August. Available at:<a href="https://www.theatlantic.com/health/archive/2019/08/youtube-captions/595831/">https://www.theatlantic.com/health/archive/2019/08/youtube-captions/595831/</a>.
</li>
<li id="bradbury2022">Bradbury, J.M. (2022) “Audiences, American Sign Language, and Deafness in Shakespeare Performance” , _Shakespeare Bulletin_ , 40(1), pp. 45-67.
</li>
<li id="boyd2021">Boyd, J. (2021) “Digital Stages for Old Plays: A Review of Shakespeare’s Language in Digital Media: Old Words, New Tools” , _DHQ: Digital Humanities Quarterly_ , 15(3). Available at:<a href="http://digitalhumanities.org/dhq/vol/15/3/000572/000572.html">http://digitalhumanities.org/dhq/vol/15/3/000572/000572.html</a>.
</li>
<li id="burch_kafer2010">Burch, S. and Kafer, A. (2010) “Introduction: Interventions, Investments, and Intersections” , in Burch, S. and Kafer, A. (eds), _Deaf and Disability Studies: Interdisciplinary Perspectives_ . Washington, DC: Gallaudet University, pp. xiii-xxvii.
</li>
<li id="carson_kirwan2014">Carson, C. and Kirwan, P. (2014) “Shakespeare and the Digital World: Introduction” in Carson, C. and Kirwan, P. (eds.), _Shakespeare and the Digital World: Redefining Scholarship and Practice_ , Cambridge: Cambridge University Press (2014), pp. 1-7.
</li>
<li id="desmet2016">Desmet, C. (2016) “Shakespeare and the Digitized World” , _CEA Critic_ , 78(2), pp. 213-22.
</li>
<li id="dunn2020">Dunn, L.C. (2020) _Performing Disability in Early Modern English Drama_ . Cham, Switzerland: Palgrave Macmillan.
</li>
<li id="ellcessor2016">Ellcessor, E. (2016) _Restricted Access: Media, Disability, and the Politics of Participation_ . New York: New York University Press.
</li>
<li id="ellcessor2018">Ellcessor, E. (2018) “A Glitch in the Tower: Academia, Disability, and Digital Humanities.” In Sayers, J. (ed.), _The Routledge Companion to Media Studies and Digital Humanities_ . New York: Routledge, pp. 108-116.
</li>
<li id="estill2019">Estill, L. (2019) “Digital Humanities’ Shakespeare Problem” , _Humanities_ , 8(1). Available at:<a href="https://doi.org/10.3390/h8010045">https://doi.org/10.3390/h8010045.</a>
</li>
<li id="estill_jakacki_ullyot2016">Estill, L., Jakacki, D.K., and Ullyot M. (eds.) (2016) _Early Modern Studies after the Digital Turn_ . New York: Iter Press.
</li>
<li id="fox2010">Fox, A. M. (2010) “How to Crip the Undergraduate Classroom: Lessons from Performance, Pedagogy, and Possibility” , _Journal of Postsecondary Education and Disability_ , 23(1), pp. 38-47.
</li>
<li id="giglio_venecek2009">Giglio, K. and Venecek, J. (2009) “The Radical Historicity of Everything: Exploring Shakespearean Identity with Web 2.0” , _DHQ: Digital Humanities Quarterly_ , 3(3). Available at:<a href="http://digitalhumanities.org:8081/dhq/vol/3/3/000063/000063.html">http://digitalhumanities.org:8081/dhq/vol/3/3/000063/000063.html</a>.
</li>
<li id="giordano2013">Giordano, T. (2013) “Toward a Crowdsourced Model for ASL Translations of Shakespeare’s Works.” M.A. Thesis. California State University, Northridge.
</li>
<li id="giordano_bradbury2015">Giordano, T. and Bradbury, J. M. (2015) “Digit(al) Shakespeares” , _#transformDH._ Available at:<a href="http://www.transformdh.org/2015-video-showcase/digital-shakespeares-tyrone-giordano-and-jill-marie-bradbury/">www.transformdh.org/2015-video-showcase/digital-shakespeares-tyrone-giordano-and-jill-marie-bradbury/.</a>
</li>
<li id="godden_hsy2018">Godden, R. and Hsy, J. (2018) “Universal Design and Its Discontents” in Kim, D. and Stommel, J. (eds.), _Disrupting the Digital Humanities_ , Punctum Books, pp. 91-112. Available at:<a href="https://punctumbooks.com/titles/disrupting-the-digital-humanities/">https://punctumbooks.com/titles/disrupting-the-digital-humanities/</a>.
</li>
<li id="hamraie2013">Hamraie, A. (2013) “Designing Collective Access: A Feminist Disability Theory of Universal Design” , _Disability Studies Quarterly_ , 33(4). Available at:<a href="http://dx.doi.org/10.18061/dsq.v33i4.3871">http://dx.doi.org/10.18061/dsq.v33i4.3871</a>.
</li>
<li id="hamraie2017">Hamraie, A. (2017) _Building Access: Universal Design and the Politics of Disability._ Minneapolis: University of Minnesota Press.
</li>
<li id="hamraie2018">Hamraie, A. (2018) “Mapping Access: Digital Humanities, Disability Justice, and Sociospatial Practice” , _American Quarterly_ , 70(3), pp. 455-482.
</li>
<li id="hirsch_craig2014">Hirsch, B. D. and Craig, H. (eds.) (2014) _The Shakespearean International Yearbook, Volume 14: Special Section: Digital Shakespeares: Innovations, Interventions, Mediations._ Burlington: Ashgate.
</li>
<li id="hobgood2021">Hobgood, A.P. (2021) _Beholding Disability in Renaissance England_ . Ann Arbor: University of Michigan Press.
</li>
<li id="hobgood_wood2013">Hobgood, A.P. and Wood, D.H. (eds.) (2013) _Recovering Disability in Early Modern England_ . Columbus: Ohio State University Press.
</li>
<li id="iranowska2019">Iranowska, J. (2019) “Greater good, empowerment and democratization? Affordances of the crowdsourcing transcription projects” , _Museum & Society_ , 17(2), pp. 210-228.
</li>
<li id="iyengar2015">Iyengar, S. (ed.) (2015) _Disability, Health, and Happiness in the Shakespearean Body_ . New York: Routledge.
</li>
<li id="iyengar_desmet2012">Iyengar, S. and Desmet, C. (2012) “Rebooting Ophelia: Social Media and the Rhetorics of Appropriation” in Peterson, K. L. and Williams, D. (eds.) _The Afterlife of Ophelia_ . New York: Palgrave Macmillan, pp. 59-78.
</li>
<li id="jenstadetal2018">Jenstad, J., Kaethler, M., and Roberts-Smith, J. (eds.) (2018) _Shakespeare’s Language in Digital Media: Old Words, New Tools_ . New York: Routledge.
</li>
<li id="jenstadetal2017">Jenstad, J., McLean-Fiander, K. and McPherson, K.R. (2017) “The _MoEML_ Pedagogical Partnership Program” , _DHQ: Digital Humanities Quarterly_ , 11(3). Available at:<a href="http://digitalhumanities.org:8081/dhq/vol/11/3/000302/000302.html">http://digitalhumanities.org:8081/dhq/vol/11/3/000302/000302.html</a>.
</li>
<li id="kelley2017">Kelley, S. (2017) “Getting on the Map: A Case Study in Digital Pedagogy and Undergraduate Crowdsourcing” , _DHQ: Digital Humanities Quarterly_ ,11(3). Available at:<a href="http://www.digitalhumanities.org/dhq/vol/11/3/000330/000330.html">http://www.digitalhumanities.org/dhq/vol/11/3/000330/000330.html</a>.
</li>
<li id="kwok2017">Kwok, R. (2017) “Crowdsourcing for Shakespeare” , _The New Yorker_ . 16 January. Available at:<a href="https://www.newyorker.com/tech/annals-of-technology/crowdsourcing-for-shakespeare">https://www.newyorker.com/tech/annals-of-technology/crowdsourcing-for-shakespeare</a>.
</li>
<li id="lanier2017">Lanier, D.M. (2017) “Shakespeare/Not Shakespeare: Afterword.” In Desmet, C., Loper, N. and Casey, J. (eds.), _Shakespeare/Not Shakespeare_ . Cham, Switzerland: Palgrave Macmillan, pp. 293-306.
</li>
<li id="lavagnino2014">Lavagnino, J. (2014) “Shakespeare in the Digital Humanities” in Carson, C. and Kirwan, P. (eds.) _Shakespeare and the Digital World: Redefining Scholarship and Practice_ . Cambridge: Cambridge University Press, pp. 14-23.
</li>
<li id="lee_lee2017">Lee, J. and Lee, J. (2017) “Shakespeare’s Tragic Social Network; or Why All the World’s a Stage,”  _DHQ: Digital Humanities Quarterly_ , 11(2). Available at:<a href="http://digitalhumanities.org:8081/dhq/vol/11/2/000289/000289.html">http://digitalhumanities.org:8081/dhq/vol/11/2/000289/000289.html</a>.
</li>
<li id="liu2012">Liu, A. (2012) “Where Is Cultural Criticism in the Digital Humanities?” in M.K. Gold (ed.) _Debates in the Digital Humanities_ . Available at:<a href="https://dhdebates.gc.cuny.edu/projects/debates-in-the-digital-humanities">https://dhdebates.gc.cuny.edu/projects/debates-in-the-digital-humanities</a>.
</li>
<li id="loftis2021">Loftis, S.F. (2021) _Shakespeare and Disability Studies_ . New York: Oxford University Press.
</li>
<li id="love2018">Love, G. (2018) _Early Modern Theatre and the Figure of Disability_ . London: Bloomsbury.
</li>
<li id="lyons2020">Lyons, K. (2020) “YouTube is Ending its Community Captions Feature and Deaf Creators Aren’t Happy About It” , _The Verge_ , 31 July. Available at:<a href="https://www.theverge.com/2020/7/31/21349401/youtube-community-captions-deaf-creators-accessibility-google">https://www.theverge.com/2020/7/31/21349401/youtube-community-captions-deaf-creators-accessibility-google</a>.
</li>
<li id="mace1985">Mace, R. (1985) “Universal Design: Barrier-Free Environments for Everyone” , _Designers West_ , 33(1), pp. 147-152.
</li>
<li id="mitglobalshakespeares">Global Shakespeares Video & Performance Archive. Available at:<a href="https://globalshakespeares.mit.edu/">https://globalshakespeares.mit.edu</a>.
</li>
<li id="morris2014">Morris, S. (2014) “Gamekeeper or Poacher? Personal Blogging/Public Sharing” in Carson, C. and Kirwan, P. (eds.) _Shakespeare and the Digital World: Redefining Scholarship and Practice_ . Cambridge: Cambridge University Press, pp. 176-187.
</li>
<li id="mueller2014">Mueller, M. (2014) “Shakespeare His Contemporaries: Collaborative Curation and Exploration of Early Modern Drama in a Digital Environment” , _DHQ: Digital Humanities Quarterly_ , 8(3). Available at:<a href="http://digitalhumanities.org:8081/dhq/vol/8/3/000183/000183.html">http://digitalhumanities.org:8081/dhq/vol/8/3/000183/000183.html</a>.
</li>
<li id="murphy2010">Murphy, A. (2010) “Shakespeare Goes Digital: Three Open Internet Editions” , _Shakespeare Quarterly_ , 61(3), pp. 401-414.
</li>
<li id="novak2008">Novak, P. (2008) “ Where Lies Your Text? : Twelfth Night in American Sign Language Translation” in Holland, P. (ed.), _Shakespeare Survey 61_ , Cambridge: Cambridge University Press, pp. 74-90. Available at:<a href="https://doi.org/10.1017/CCOL9780521898881.006">https://doi.org/10.1017/CCOL9780521898881.006</a>.
</li>
<li id="odell2021">O’Dell, L. (2021) “YouTube Pulled its Community Captions Feature, So Now More Creators are Making Their Own”  _The Verge_ , 21 May. Available at:<a href="https://www.theverge.com/2021/5/21/22443577/youtube-captions-increased-deaf-campaigners">https://www.theverge.com/2021/5/21/22443577/youtube-captions-increased-deaf-campaigners.</a>
</li>
<li id="oneill2014">O’Neill, S. (2014) _Shakespeare and YouTube: New Media Forms of the Bard_ . London: Bloomsbury.
</li>
<li id="oneill2019">O’Neill, S. (ed.) (2019) “Special Issue: Shakespeare and Digital Humanities: New Perspectives and Future Directions” , _Humanities_ , 8(1-2). Available at:<a href="https://www.mdpi.com/journal/humanities/special_issues/Shakespeare">https://www.mdpi.com/journal/humanities/special_issues/Shakespeare</a>.
</li>
<li id="poynter2020">Poynter, R. (2020) _YouTube is Officially Getting Rid of Community Captions_ . 08 August. Available at:<a href="https://www.youtube.com/watch?v=wh5sxszpGog">https://www.youtube.com/watch?v=wh5sxszpGog</a>.
</li>
<li id="rowe2014">Rowe, K. (2014) “Living with Digital Incunables, or: A Good-Enough Shakespeare Text” in Carson, C. and Kirwan, P. (eds.) _Shakespeare and the Digital World: Redefining Scholarship and Practice_ . Cambridge: Cambridge University Press, pp. 144-159.
</li>
<li id="rowheyveld2018">Row-Heyveld, L. (2018) _Dissembling Disability in Early Modern English Drama_ . Cham, Switzerland: Palgrave Macmillan.
</li>
<li id="schaapwilliams2021">Schaap Williams, K. (2021) _Unfixable Forms: Disability, Performance, and the Early Modern English Theater_ . Ithaca: Cornell University Press.
</li>
<li id="sperrazza2020">Sperrazza, W. (2020) “Early Modern Manuscripts Online. Other,”  _Renaissance and Reformation / Renaissance et Réforme_ , 43(2), pp. 335–38. Available at:<a href="https://www.jstor.org/stable/26977617">https://www.jstor.org/stable/26977617</a>.
</li>
<li id="squeo_pennacchia_winckler2021">Squeo, A., Pennacchia, M. and Winckler, R. (eds.) (2021) “Special Issue: Experiencing Shakespeare in Digital Environments” , _Lingue e Linguaggi_ , 45. Available at:<a href="http://siba-ese.unisalento.it/index.php/linguelinguaggi/article/view/24524">http://siba-ese.unisalento.it/index.php/linguelinguaggi/article/view/24524</a>.
</li>
<li id="terras2016">Terras, M. (2016) “Crowdsourcing in the Digital Humanities” in Schreibman, S., Siemens, R. and Unsworth, J. (eds.) _A New Companion to Digital Humanities_ , Chichester: Wiley, pp. 420-438.
</li>
<li id="thompson2010">Thompson, A. (2010) “Unmooring the Moor: Researching and Teaching on YouTube” , _Shakespeare Quarterly_ , 61(3), pp. 337-356.
</li>
<li id="titchkosky2011">Titchkosky, T. (2011) _The Question of Access: Disability, Space, Meaning_ . Toronto: University of Toronto Press.
</li>
<li id="vanhyning2019">Van Hyning, V. (2019) “Harnessing Crowdsourcing for Scholarly and GLAM Purposes” , _Literature Compass_ , 16(3-4), pp. 1-11. Available at:<a href="https://doi.org/10.1111/lic3.12507">https://doi.org/10.1111/lic3.12507</a>.
</li>
<li id="virdi2021">Virdi, J. (2021) “Black Bars, White Text” , _Literature and Medicine_ , 39(1), pp.29-33. Available at:<a href="https://doi.org/10.1353/lm.2021.0004">https://doi.org/10.1353/lm.2021.0004</a>.
</li>
<li id="williams2012">Williams, G. H. (2012) “Disability, Universal Design, and the Digital Humanities” in Gold, M.K. (ed.) _Debates in the Digital Humanities_ . Available at:<a href="https://dhdebates.gc.cuny.edu/projects/debates-in-the-digital-humanities">https://dhdebates.gc.cuny.edu/projects/debates-in-the-digital-humanities</a>.
</li>
<li id="youdescribe">YouDescribe. Available at:<a href="https://youdescribe.org/">https://youdescribe.org/</a>.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>For a discussion of intersections and tensions between Deaf Studies and Disability Studies, see<a class="footnote-ref" href="#burch_kafer2010"> [burch_kafer2010] </a>. I follow the convention of capitalizing Deaf, which “distinguish[es] deaf (signifying an auditory condition) from Deaf (signifying a coherent culture based on shared language, identity, and history)” <a class="footnote-ref" href="#burch_kafer2010"> [burch_kafer2010] </a>. Bradbury<a class="footnote-ref" href="#bradbury2022"> [bradbury2022] </a>has critiqued distinctions between Deaf and deaf that align the former with using ASL and the latter with not using ASL, writing: “As someone who grew up oral (speaking and using assistive listening devices) but is now fluent in ASL and immersed in the deaf community professionally and personally, I find this nomenclature reductive and exclusionary in its oppositional binaries” <a class="footnote-ref" href="#bradbury2022"> [bradbury2022] </a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Fox explains the use ofcripas a reclaimed term that expresses pride, and as a verb that has been used, likequeer,to deconstruct binaries, writing: “ to queer or to crip the known is to twist our expectations of it, defamiliarize it, and render it anew in ways that open up new kinds of possibility. That promise is built on denying the very binarism that would establish queer and crip identities as that against which, respectively, norms of sexuality and ability can be defined” <a class="footnote-ref" href="#fox2010"> [fox2010] </a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>In <em>Restricted Access: Media, Disability, and the Politics of Participation</em> , Ellcessor provides anaccess kitto facilitate studying media access<a class="footnote-ref" href="#ellcessor2016"> [ellcessor2016] </a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Rikki Poynter began the #NoMoreCRAPtions campaign to raise awareness about rampant problems with automatically-generated captions and the need for high-quality captions (<a class="footnote-ref" href="#besner2019"> [besner2019] </a>;<a class="footnote-ref" href="#virdi2021"> [virdi2021] </a>. For discussion of the importance of captioning Shakespeare resources, see<a class="footnote-ref" href="#giordano_bradbury2015"> [giordano_bradbury2015] </a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>For a discussion of open source Shakespeare texts, see<a class="footnote-ref" href="#murphy2010"> [murphy2010] </a>. For a discussion of teaching with digital Shakespeare texts, see<a class="footnote-ref" href="#rowe2014"> [rowe2014] </a>.## Bibliography&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The History of Digital History: A Review of Crymble (2021)</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000653/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000653/</id><author><name>Helen B. Kampmann Marodin</name></author><published>2022-12-22T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="the-history-of-digital-history-a-review-of-crymble-2021">The History of Digital History: A Review of Crymble (2021)</h2>
<p>A most basic and overly simplistic definition of history would state that the field comprises tracking and contextualizing change over time, which is exactly what Adam Crymble admirably does in <em>Technology and the Historian</em> . The author presents an overdue comprehensive perspective on the birth and growth of Digital History as a new field within the historical discipline. Rather than setting fire to the outdated writings of the past, the author rescues that literature to present the origins and rationale behind the development of what we currently call by Digital Humanities and, more precisely, Digital History. He calls historians to recognize the influence of technology in historical practices and the impact that computers had on historical studies in the information age, independently of their scholarly work being categorized as “digital history” or not. Crymble argues that historians have chosen to gloss over the transformative role of technology for too long and claims that his book is a first attempt to overcome thisblind spotin historical inquiry. In his own words, “a history [of Digital History] also forces historians to acknowledge that their field is influenced not only by philosophical shifts and theory, but by each new gadget or piece of software coming out of the Silicon Valley” <a class="footnote-ref" href="#crymble2021"> [crymble2021] </a>.</p>
<p>One of the main merits of the book, therefore, is an analysis of literature produced utilizing digital methods in the last decades, and how they provide opportunities to understand the synchronic relation between methodological and theoretical demands of the field and computational methods – in the context in which they were created. Rather than trying to define Digital History as a concise field in a “single overarching narrative” <a class="footnote-ref" href="#crymble2021"> [crymble2021] </a>, the book seeks to present a historical account of digital history in its plurality, with a rationale that created the demand for computational methods and a common vocabulary for historians. He even includes a glossary at the end of the book to uniformize the terminology that historians working with digital methods should use. Finally, Crymble advocates for building a solid and critical historiography of digital history to free digital scholars from the loop of the “eternal present” <a class="footnote-ref" href="#crymble2021"> [crymble2021] </a>, i.e., the perfunctory rejection of older literature in favor of the most recent one.</p>
<p>The chapters are divided into what Crymble identifies as the five realms of digital history: historical research, archive, classroom, self-learning eco-system, and scholarly communication channels. Chapter 1 seeks to institute the twofold origin of digital history as a set of practices that use computers for scholarly inquiry based on either “records of bureaucracy” for quantitative research (begun by Frank Owsley’s <em>Plain Folk of the South</em> ) or “big data” for “humanities computing” (begun by Robert Busa’s project Index Thomisticus). Chapter 2 focuses on mass digitization and archival practices as two intertwined factors that shape one another and, most importantly, not only revolutionize the way scholars conduct research but also the outreach of their scholarly production. The archival turn and the revisionism in library and museum sciences shed light on the ways archival entries (be they texts, documents, or artifacts) are selected and organized into collections and, conversely, how digital collections are built and presented. Digital collections and the access to them (consider the internet and the different devices we use), according to Crymble, create new spaces that profoundly change the ways scholars and public alike engage with collections and, consequently, with the past. Chapter 3 presents how digital technologies meet the premises of an already ongoing revision of teaching methods undertaken by educational theorists and psychologists in which lectures and teacher-centered methods are called into question in favor of student-centered approaches. Crymble identifies four waves of experiments in the teaching of history (data-centric, audience-focused multimedia, data analysis, return to history with some digital component) to highlight that, although digital methods are not the only innovative initiatives undertaken, the “technology-inflected history classroom” <a class="footnote-ref" href="#crymble2021"> [crymble2021] </a>is one of the most obvious places for experimentation.</p>
<p>In Chapter 4, Crymble explores what he calls “the invisible college,” or the support network that many historians and historians-to-be need to independently build due to the lack of institutional structures to contemplate computing and technological skills in their curricula. That encompasses an eco-system that provides not only self-learning resources but, basically, advice in what to learn and how. Chapter 5 analyzes how historians used computational technologies such as blogs as a continuation of older practices to share their work and communicate with peers in a space parallel but outside institutional centers of higher education. Challenging long-established and rigid academic hierarchies, historian bloggers create channels for disrupting disciplinary boundaries and build communities with similar goals that might surpass geographical and other limitations in unprecedented ways. Be it by presenting their findings to larger audiences, sharing research (and often activist) agendas, or simply ranting about the hardships of academia, social media certainly has demanded a more self-reflective attitude from history professionals occupying different ranks. Finally, Chapter 6 acts as a conclusion chapter in which the author clearly enunciates the greater contribution of his book: to disprove historiographies that neglect the impact of the not only methodological but also material influence of technology (encompassing computers, scanners, tablets, Kindles, cell phones, and so on) on the history profession in favor of intellectual influences. Moreover, he encourages historians to define their scholarship in specific ways rather than as “digital history,” a terminology too broad and even disparate to convey any intelligible information.</p>
<p>Crymble invites historians to engage in collaborative work that will consider social, not only technical, differences across geographical locations and briefly cites examples of digital histories applied to different social and cultural contexts, such as the activist nature of the historical profession in South Africa, the translation of the <em>Programming Historian</em> to Spanish speakers, and the promising scenario in India. Crymble closes the book by remembering Marshall McLuhan’s idea of “global village” <a class="footnote-ref" href="#crymble2021"> [crymble2021] </a>, and highlighting the potential that the digital age offers as a powerful venue for historical inquiry. The book is a thoughtful reflection on the evolution of digital history and digital humanities relevant to anyone interested in the subject, including graduate students in the humanities, historians, literary theorists, linguists, and educators in general.</p>
<h2 id="bibliography">Bibliography</h2>
<ul>
<li id="crymble2021">Crymble, A. (2021) _Technology and the Historian: Transformations in the Digital Age_ . Urbana: University of Illinois Press.
</li>
</ul>
]]></content></entry><entry><title type="html">Tiresias: A Novel Approach for Mining Book Indices</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000651/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000651/</id><author><name>Moshe Blidstein</name></author><author><name>Daphne Raban</name></author><published>2022-12-22T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="1-introduction-the-challenges">1. Introduction: the challenges</h2>
<p>Locating primary source (henceforth: source) material for humanities&rsquo; research is labor-intensive. Three methods frequently used to perform this task are: 1. Reading large amounts of source texts and manually collating the relevant passages; 2. Reading prior research (henceforth: books) on the subject, collating references from these books, and locating source texts according to these references; 3. Searching by keyword in full-text corpora (usually in the source language, such as Perseus, Thesaurus Linguae Graecae, papyri.info, or Ma&rsquo;agarim)<a class="footnote-ref" href="#green2000"> [green2000] </a><a class="footnote-ref" href="#dalton2004"> [dalton2004] </a><a class="footnote-ref" href="#sinn2014"> [sinn2014] </a>.</p>
<p>Each of these methods has certain disadvantages. Many researchers&rsquo; continued recourse to methods 1 and 2 demonstrates the current limits of full-text keyword search<a class="footnote-ref" href="#green2000"> [green2000] </a>. Further criticisms of keyword searches describe forcing historians to retrieve texts in a specific way, producing biases, blind spots and false positives<a class="footnote-ref" href="#hitchcock2013"> [hitchcock2013] </a>. “[Historians&rsquo;] topics of interest are described through words but cannot be pinpointed through simple keywords alone. Yet, once sources have been digitized, entering isolated keywords often becomes a prerequisite for access” <a class="footnote-ref" href="#huistra2016"> [huistra2016] </a>.</p>
<p>In this paper, we describe Tiresias, a novel database created by juxtaposing back-of-book indices in scholarly books. Tiresias&rsquo; aims are to provide simple and efficient retrieval of ancient sources by subject, and to be a tool useful for beginners, advanced students and researchers in the disciplines of ancient history, epigraphy, papyrology, theology, and kindred areas, as a complement to full text keyword searches. First, we shall describe how the database was created and the possibilities it affords for the study of ancient history. We then review some of the available databases and their limitations and describe how Tiresias fills the gap of providing a digital search tool while maintaining the intellectual value of book indices.</p>
<h2 id="2-tiresias">2. Tiresias</h2>
<p>Tiresias (<a href="https://tiresias.haifa.ac.il/">https://tiresias.haifa.ac.il/</a>), named after the mythological blind prophet, is a detailed, searchable database of subject tags to ancient texts and artifacts, currently consisting of almost 140,000 subject tags for about 16 million references to sources. The search form allows for searches of several keywords, filtering by various fields (e.g., author, work, subject, keyword), and immediate full-text retrieval for efficient perusal of the relevant sources.</p>
<p>The database was constructed through the following innovative method. Many research books in the fields of ancient history, classics, or biblical studies, are published with two indices: one for subjects (called a subject index, index of terms, orindex rerum) and one for ancient source references (also known as anindex locorum). Through these indices, each page of the indexed book was identified as relating to certain subjects as well as certain sources, indicating with a high probability that these source references can be tagged as related to these subjects. This probability was improved by a validation method which we describe and assess in this article. Using this method, we produced asubject tagfor each source reference, i.e., a short description of a subject highly relevant to the source reference. For example, the source reference “Genesis 1.3” could be tagged with the subjectslightandcreation.With the help of a computer program, the tags were combined to create a general database of subject tags for ancient sources. The subject-source database is thus based on existing expert-made back-of-book indices, unified and assisted by digital means.</p>
<h2 id="3-corpora-and-methods">3. Corpora and methods</h2>
<p>The creation of Tiresias can be divided into the following stages:</p>
<h2 id="31-selection-and-retrieval-of-books">3.1 Selection and retrieval of books</h2>
<p>The database focuses on ancient Mediterranean religion. This appeared to be a relatively well-defined area with many academic books, of which many have both subject and source indices. The books used are mostly by leading publishers in the field (Oxford University Press, Cambridge University Press, Brill and De Gruyter), all of which have a strong presence in digital publishing, from the following areas: classics, biblical studies, Jewish studies, patristics, and ancient history. The Ancient Near East is not included for technical reasons – too few indices meeting the relevant criteria.</p>
<p>There were two essential criteria for inclusion of books: a. the existence of both anindex locorumand a subject index. b. cheap, convenient, and legal access to a high-quality scan of the indices. It was clearly preferable to use books for which PDFs with embedded text are readily available, in order to obviate the stage of OCR of scanned text. This meant that the books used were usually published after 2000, as indicated in Figure 1. About 600 books were identified as meeting all these criteria and their indices were downloaded via subscriptions of the Younes &amp; Soraya Nazarian Library at the University of Haifa. Additional book indices are continuously entered with expanded availability and continued publication of new books.</p>




























<figure ><img loading="lazy" alt="Bar chart" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Count of books per year.
        </p>
    </figcaption>
</figure>
<h2 id="32-index-parsing">3.2 Index parsing</h2>
<p>Indices are relatively structured data, and this facilitates reading them algorithmically. Nevertheless, there are many idiosyncrasies of different indices requiring both computerized and human processing to make use of the indices in a shared database.</p>
<h2 id="a-subject-indices">a. Subject indices</h2>
<p>Published subject indices are typically constructed of alphabetized subject headings and sub-headings, with the latter indented, as demonstrated in Figure 2. Therefore, in order to include all the information in the index, it was necessary to correctly identify subject headings and sub-headings. This was done algorithmically in Python 3.10, with human input and supervision. The stages were as follows:</p>
<p>Algorithmic conversion of PDF to text format (.txt).Human identification of subject index format: whether sub-headings exist; whether each sub-heading is on a separate line and marked by an indent; if not, what character is used to mark sub-headings.If the sub-headings are marked with a character, this is used to algorithmically differentiate them from main headings. Otherwise, since the order of the main headings is always alphabetized, a human marks on which row the first letter of the subject headings begins and this marking is used to identify main headings (beginning with this letter) and sub-headings (not beginning with this letter). Also, lines beginning with propositions (and,by, etc.) are identified as sub-headings, and additional minor corrections are applied (e.g., identifying sub-headings when they start with the same letter as the heading).</p>
<p>At the end of the process, the subject headings and sub-headings were joined by a comma, and page ranges were expanded.</p>




























<figure ><img loading="lazy" alt="Image of topic and subheadings. Text reads Baptism: 100, Christian 90-91, Jewish 93-95, With fire 12-14" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>An example of a main subject heading and sub-headings, with each sub-heading on a separate line.
        </p>
    </figcaption>
</figure>
<p>Table 1 provides an example of data entry for the output appearing in Figure 2.<br>
Example of subject entry and corresponding page numbers from a book subject indexSubjectBook #Page #Baptism1100Baptism, Christian190Baptism, Christian191Baptism, Jewish193Baptism, Jewish194Baptism, Jewish195Baptism, with fire112Baptism, with fire113Baptism, with fire114</p>
<h2 id="b-source-indices">b. Source indices</h2>
<p>Every reference in the source index was parsed and divided into the following columns: 1. author and title identifying number, 2. reference, and 3. Page number, as seen in Figure 3.</p>




























<figure ><img loading="lazy" alt="Image of source index data. Text for one entry reads: New Testament, 1 Cor., 3:16-17, 152-155" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Standardized Tiresias references vs. the original source references
        </p>
    </figcaption>
</figure>
<p>Table 2 provides an example of data entry for the output appearing in Figure 3.<br>
Example of source entry and corresponding page numbers from a book source indexAncient Work #ReferenceBook #Page #80563.16115280563.16115380563.16115480563.16115580563.17115280563.17115380563.17115480563.17115580565.11115180565.12115180565.131151805610.2190805610.319023091.23151<br>
Clearly identifying the various ancient authors and works was challenging as publications use highly varied conventions to refer to ancient authors, works, and references<a class="footnote-ref" href="#romanello2018"> [romanello2018] </a>. The source indices contained more than 12 thousand unique ancient works from different traditions and languages. For example, The New Testament book, First Corinthians, can be written in various abbreviated forms such as “1 Cor.” , “First Corinthians” , “I Cor.” , etc. Many ancient works have several naming conventions for the title and for the author. Furthermore, the chapter and verse number can also be written according to different conventions, using Roman or Arabic numerals, and different types of dividers. To meet this challenge, we constructed an author-title database of modern naming conventions and abbreviations of ancient authors and works, which the program consults to identify the references included in the indices. This database utilized and collated existing free databases such as the TLG canon of Greek Authors and Works, abbreviation tables from various Greek and Latin dictionaries available online, the Classical Works Knowledge Base, SBL handbook, and other lists. Many additional authors and titles for Greek, Latin, Coptic, Hebrew and Syriac works were added incrementally to the database as more indices were processed and additional authors and titles were identified manually. The script checked each line in the source index against this database to identify authors and titles. When a match was made of both author and title, a work number was assigned. Fuzzy matches were not used because different works can have very similar titles (e.g., 1 Corinthians and 2 Corinthians). Lines which were not identified as authors or titles were assumed to be of references and page numbers. These were distinguished by manually inputting the differentiating character (usually a whitespace) between them. This script generally produces good results, but with some errors as a result of unrecognized authors or titles, or incorrect differentiation of reference and page numbers, usually in cases of unusual references. Therefore, an expert examined the outputs (in csv format) to delete or correct wrong rows.</p>
<h2 id="33-database-construction">3.3 Database construction</h2>
<p>The main database, in a flat csv file, was constructed by combining the subject and source indices along the page column. This database currently contains 16,420,264 rows. For example, in Figure 3 the source index of a certain book tells us that the 1 Corinthians 10:2 is discussed on p. 90, while the subject index tells us thatbaptism, Christianis discussed on pages 90-91 (Table 1). Juxtaposing this data provides a certain probability that First Corinthians 10:2 deals with, is connected with, or relates to, Christian baptism. 1 Corinthians 10:2 is therefore tagged with the subject tagbaptism, Christian. The resulting rows in the database are shown in Table 3.<br>
Database rowsRow #Ancient Work #ReferenceBook #Page #subject1805610.2190baptism, Christian2805610.3190baptism, Christian<br>
However, this process can produce false positives for several reasons: Book pages usually discuss several subjects, and source references on these pages may be connected to a specific subject and not to the others. Moreover, references may be supplied as examples for some side point in the discussion, having no link at all to the main subject of the page. Another problem is that references are not always consistent, with different editions dividing the source text in different ways. Therefore, the juxtaposition of indices alone will provide a large proportion of irrelevant, or only slightly relevant, results.</p>
<h2 id="34-validation">3.4 Validation</h2>
<p>As a remedy to the false positives problem, we attempt to validate results by the following method. First, we retrieved all source references appearing in more than one book. Then, we extracted all the subject tags for these source references, split them into word tokens, removed non-significant words, and morphologically stemmed the words to capture variants such as plural/singular, or different verb forms. For example, Table 4 displays the unvalidated data, and Table 5 shows the same data after stemming.<br>
Unvalidated database rowsRow #Ancient Work #ReferenceBook #Page #Subject1805610.2790baptism, Christian2805610.27150baptismal, spirit3805610.2870Spiritual life411001.2910baptism, Christian511001.2910Spiritual lifeThe rows of table 4, tokenized and stemmedRow #Ancient Work #ReferenceBook #Page #subjecttokens1805610.2790baptism, Christianbaptis2805610.2790baptism, Christianchristi3805610.27150baptismal, spiritbaptis4805610.27150baptismal, spiritspirit5805610.2870Spiritual lifespirit6805610.2870Spiritual lifelife711001.2910baptism, Christianbaptis811001.2910baptism, Christianchristi911001.2910Spiritual lifespirit1011001.2910Spiritual lifelife<br>
If the same token was found in the subject tags derived from more than one book for the same source reference, this token was considered validated for this reference and the row was entered into the validated table, under the assumption that a match of subjects from two books (even if only in one word) would usually mean that the pairing is significant, and not a mistake or coincidence. For example, as seen in table 4, if the source reference “1 Cor. 10:2” was tagged with the subject tagsbaptismal, spiritin one book andspiritual lifefrom another, then “1 Cor. 10.2” will be entered into the table of validated references with the tokenspirit, and the following rows in the validated table could be added as seen in Table 6.<br>
Validated database rowsRow #Ancient Work #ReferenceBook #Page #subjecttoken1805610.27150baptismal, spiritspirit2805610.2870Spiritual lifespirit<br>
The two rows in the validated table were derived from rows 4 and 5 in the unvalidated table, which have the same source reference, an identical token (spirit) and derive from different books (7 and 8). These are the only rows meeting these criteria.</p>
<p>Currently, the validated table includes about 3.7 million rows. We intend to systematically assess the precision and recall performance of this validation method in future research. In a preliminary examination of 1075 randomly selected validated source-subject pairs, we looked at the tagged source text to assess the suitability of the subject tag. The results are summarized as follows:</p>
<p>355 (33%) of the tagged source texts included the tagged word (e.g., a text tagged bybaptism, where the wordbaptismappears in the source text);280 (26%) of the source texts included synonymous or closely related words (e.g.,immersionorinitiationin the same case);340 (31%) of the source texts included discussions or reference to subjects relevant to the subject tag, (for example, a scene from the Hebrew Bible which was later explained by Christian writers as relating to baptism or a text discussing pagan rituals similar to baptism).100 (9%) of the tags were a mistake or unclear – 28 (2.6%) an unclear reference, 10 (0.9%) other mistakes, 59 (5.4%) references which happened to appear on the same page as the tagged subject but were not connected to it.</p>
<p>Though this data is preliminary and more rigorous methods and larger sample sizes are needed, it indicates that less than 10% of the results were irrelevant (article 4 above), while a third of the results would have been identified also through full-texts searches (article 1); more than 50% of the results are relevant to varying degrees and would not have been located through full-text searches (articles 2 and 3).</p>
<p>Though only ~23% of the results are validated, this percentage will presumably rise with the expansion of the database. Beyond database size, two other reasons for the moderate validation rate are: a. subject tags which are semantically similar but not identical were not identified by the validation script; b. references to the same text which used different conventions and are not covered by the author-title database described above (Section 3.2b) and were therefore not identified as identical. The validation rate can be improved by solving these problems i.e., by semantic pairing, which will allow matching non-identical but synonymous subject tags, and by expanding the author-title database.</p>
<h2 id="35-online-search-interface">3.5 Online search interface</h2>
<p>Finally, the database was made freely accessible to the scholarly community on the web with a search interface (<a href="https://tiresias.haifa.ac.il/">https://tiresias.haifa.ac.il/</a>). The main search currently offers three options:</p>
<p>for validated references only, which provides a list of all validated source references tagged by subjects containing the searched keyword, sorted by date of the sources.for all references (i.e., unvalidated and validated combined), which provides a list of all references tagged by subjects containing the searched keyword, sorted by date of the sources.for secondary literature, which provides a list of all subject tags containing the searched keyword and the book pages from which these subject tags derived, without the source references. This provides a much shorter list focused on the subjects rather than the sources, and is sorted by alphabetical order of the subjects.</p>
<p>Search results can be filtered by one or two subject keywords, as well as by ancient author, work, or according to the century the ancient work was written. Filters are essential as many subject searches return thousands of results. Figure 4 shows that each result includes an ancient work reference (author, title, and internal reference); the approximate date of the ancient work; the subject tags for this specific reference in the database; the books and page numbers from which the subject tags derived; and the texts of the ancient work reference, in the original language and in English translation, when available.</p>




























<figure ><img loading="lazy" alt="Image from website showing a passage including women and oaths in Greek side by side with the English translation" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Example result of search forwomenandoathsin the unvalidated option.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Image from website providing search terms and book references" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Example results of search foroathin the secondary literature option.
        </p>
    </figcaption>
</figure>
<p>In order to facilitate study of the texts, more information was included:</p>
<p>Links were created for each subject tag to the relevant pages of the book in Google Books. This allows the user to go directly to the secondary literature which supplied the subject tag. While this is not its main function, Tiresias becomes a gateway not only to ancient sources but also to the scholarly literature (albeit only in books, not articles). Though Google Books allows only partial access to the books, this is currently the only way known to us for general users to directly access non-open access books online through a link to a specific page.The ancient text in its original language (Greek, Latin, Hebrew, Aramaic, Arabic, Syriac, Coptic) and/or its translation to English is also presented, in cases in which the text is readily available in machine readable format – about 50% of the references. The user can thus search for a subject and immediately read the relevant texts, without the need to search for the text in other sites or offline. Full texts for Hebrew Bible and rabbinic texts is kindly supplied by Sefaria; for Greek and Latin texts, by Perseus Scaife; for the Quran, by Tanzil.net; for Syriac, from the Digital Syriac Corpus; for Coptic, from the Coptic Scriptorium. These projects provide large amounts of texts with TEI markup, which is essential for extracting the texts according to reference. Full texts for epigraphy and papyri is not yet supported but is planned in the future. English translations were provided for Rabbinic texts by Sefaria; for Greek and Latin texts by Perseus Scaife and Bill Thayer&rsquo;s website Lacus Curtius; for early Christian and Patristic texts, from publicly available 19th century translations.A search form for searching by reference – the user enters an ancient source reference and receives all the subject tags and book pages concerning this source reference, as well as the full text itself when available. This feature is useful for studying specific ancient texts rather than a subject.</p>
<h2 id="36-visualizations">3.6 Visualizations</h2>
<p>We used the database to allow users to create network and heatmap visualizations on subjects or works of their choosing. The visualizations help users understand how the subject tags in the database are connected to each other, and thus identify links of which they were unaware. Each type of visualization has its advantages: networks facilitate understanding of the degree and nature of connections between various subjects and their relative importance, while heatmaps can be used to understand changes in these connections over time. For ease of comprehension and to prevent visual overload, both types of visualizations were limited to validated subjects only. Furthermore, subject tags were split into one-word terms, so that the visualizations show relationships between one-word terms rather than whole subject tags.</p>
<h2 id="network-visualizations">Network visualizations</h2>
<p>To perform network visualization, we first manipulated the files to create a network graph based on shared subjects and references. The validated table was grouped by references and the number of shared references between each subject was found. For example, the rows in Table 7 would produce the network graph in Table 8:<br>
Rows from validated tableRow #Ancient Work #ReferenceBook #Page #subjecttoken110015.612513Evil spiritspirit2902310.1014075Holy spiritspirit310015.612012Water, from wellswater4902310.1014075Holy waterwater510015.613012Sacrifice, of breadbreadnetwork graph derived from table 6sourcetargetWeight (=number of shared references)waterspirit2waterbread1breadspirit1<br>




























<figure ><img loading="lazy" alt="connections between the words spirit, water, and bread" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>schematic visualization of network graph example from table 6
        </p>
    </figcaption>
</figure></p>
<p>Using Gephi<a class="footnote-ref" href="#bastian2009"> [bastian2009] </a>we visualized the network graph of subjects, as seen in Figure 7. In this visualization of the graph, words from subject tags which share the most references are adjacent on the network, while subjects not sharing references are far apart. The size of each node is determined according to the number of incoming and outgoing links (edges), so that subjects (nodes) with the most source references appear largest. Furthermore, communities of closely connected subjects are determined using the Louvain method for community detection and marked by color. This creates a mapping of the whole field based directly on the scholarly research, intuitively displaying the centrality or marginality of specific subjects, the relationship between subjects, and the different sub-disciplines of the study of ancient religion. The visualization is also instructive concerning subjects which are on the borders between sub-disciplines, that is, which are shared by one more of these sub-disciplines, as opposed to subjects which are in the core area of each. Figure 7 illustrates the part of the subject network dealing mainly with core subjects of two ancient religions - Jewish (in purple) and Christian (green), and some subjects connecting both areas.</p>




























<figure ><img loading="lazy" alt="Image of a word cloud" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Sample of the large network of subjects from Tiresias
        </p>
    </figcaption>
</figure>
<p>Though the general subject network is instructive, it is very large and therefore not so informative concerning specific subjects or subject areas. We therefore constructed an interface for online users to create smaller networks ad-hoc, based on the same principles, using the Python module Networkx. In both cases, to reduce congestion, no more than 70 of the largest nodes (i.e., subjects with the most references) are shown. There are two options for network construction:</p>
<p>a. Subject based: the network is limited to subjects connected to a specific subject supplied by the user. Using this tool, users can visualize the relative importance and the interconnections of different subjects connected to their subject of interest, according to the books in the database.b. Ancient work based: the network is limited to subjects connected to a specific ancient work supplied by the user. Using this tool, users can quickly identify subjects related to the specific ancient work by scholars. In addition, the visualization displays the relative importance and interconnections of subjects (see Figure 8 for an example).</p>




























<figure ><img loading="lazy" alt="Image of a network" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Network of subjects connected to the ancient work Metamorphoses by Ovid, constructed on user request by the online tool.
        </p>
    </figcaption>
</figure>
<h2 id="heatmap-visualizations">Heatmap visualizations</h2>
<p>A heatmap is a visual representation of data based on color allowing quick identification of high, medium and low values of a variable. Using the Seaborn<a class="footnote-ref" href="#waskom2021"> [waskom2021] </a>visualization library for Python, we constructed a tool through by which users can produce heatmaps of the subjects sharing many references with a specific subject, per century of the reference. This is based on the same network graph file from the network visualization, but divided according to the century in which the source reference was written. The color shade corresponds to the number of references tagged by unique subjects, divided by all references from this century, serving as a normalized measure of the salience of the connection between the two subjects in a certain period. Figure 9 displays the heatmap of the wordoathwith other words through the centuries. Since some centuries are overrepresented in the database, the number of references tagged by each subject in each century was divided (normalized) by the total number of references of that century in the database to provide an index for the color shade, shown on the right column.</p>




























<figure ><img loading="lazy" alt="Image of a heatmap" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Linked subjects heatmap foroathfrom the 12th century B.C. to the 2nd century C.E
        </p>
    </figcaption>
</figure>
<p>With the expansion of the database, heatmaps can serve to understand how the connection between subjects changed historically over time, providing insight on historical processes or on the scholarship on which the database is based. For example, Figure 6 indicates that most of the studies of oaths focused on Classical Greece rather than on later periods. It may also indicate that the sources speak of women swearing oaths only in sources from the 5th century BCE and not earlier, or that oaths by goddesses Persephone and Kore were less popular before this period. The heatmap cannot, of course, demonstrate actual historical trends, but it can provide pointers, questions and intriguing phenomena which can then be followed up by research.</p>
<h2 id="4-comparison-with-existing-tools">4. Comparison with existing tools</h2>
<p>In order to contextualize Tiresias as a tool in the digital humanities toolset, this section discusses several other tools including full text search tools, major subject indices of secondary literature, and other relevant online tools.</p>
<p>Several excellent online tools provide access to ancient primary sources in full-text format with search capabilities. Prime examples for these are the TLG for ancient and medieval Greek works (currently including more than 110 million words from over 10,000 works); the Brepols Library of Latin text (over 60 million words from 3100 works); <em>Ma&rsquo;agarim</em> , for Hebrew works (over 9 million words from 4500 works as of 2008); CAL lexicon, for Aramaic (3 million words). Many other databases exist, but these examples stand out for offering parsing, lemmatization, searches by lemma, advanced searches with wildcards, filtering by author, period, genre, and other tools. Also notable is the Perseus site, which is at the forefront of facilitating access to Greek and Latin texts in the original and in translation, allowing the insertion of commentary, browsing and searching by reference, and linking to relevant artworks. A large percentage of published Greek and Latin papyri and epigraphical material are online via Trismegistos, PHI searchable Greek inscriptions, Papyri.info, and other sites, with lemmatization and extensive metadata for each of the documents. However, all of sites hardly provide information on the subject of the text, and therefore do not allow for searching by primary texts according to subject, or, in other words, searching through a controlled vocabulary as opposed to a free text search (unusual in this regard are the papyri search sites, where the metadata of each document occasionally includes a description of the text and keywords of its subject, usually in German. Research has shown that user retrieval of information is best accomplished through a combination of controlled vocabulary and free text searches, as these methods retrieve different types of data or have complementary functions<a class="footnote-ref" href="#croft2002"> [croft2002] </a><a class="footnote-ref" href="#gross2015"> [gross2015] </a>.</p>
<p>As opposed to primary sources, much effort has been expended in the past decades on subject indexing and categorizing of secondary literature by controlled vocabularies. An important function of all the online databases for articles and book chapters (e.g., JSTOR, Wiley Academic, Atla databases,L&rsquo;Annee Philologique, RAMBI, Index Islamicus, etc.), as well as of library catalogues, is to help the user locate secondary literature on a specific subject. There has been extensive research on best practices of subject indexing in the context of such databases and catalogues (see<a class="footnote-ref" href="#yu2017"> [yu2017] </a>;<a class="footnote-ref" href="#landry2011"> [landry2011] </a>) as well as thought on alternative visualizations of indices and searches<a class="footnote-ref" href="#mercun2016"> [mercun2016] </a><a class="footnote-ref" href="#wlodarczyk2013"> [wlodarczyk2013] </a>. A central question that arises from this research is how to create comprehensive, efficient and understandable subject trees, while minimally imposing the viewpoint of its creator, in order to assist researchers rather than constrain them to a specific taxonomy. Researchers have recommended basing subject indices on topic maps, semantic webs or universal thesauri, which represent the language as a whole, rather than ad-hoc subject headings<a class="footnote-ref" href="#wlodarczyk2013"> [wlodarczyk2013] </a><a class="footnote-ref" href="#nilbe2014"> [nilbe2014] </a>. This question is even more significant in the case of a primary source index, as the source texts are the objects of study and not only, as in secondary literature, assisting instruments. In Tiresias, we currently use the subjects presented in the indices without any attempt at constructing a subject tree or topic map as an aid for subject retrieval. However, in the future we may attempt to parse the structure of the subjects and sub-headings of indices themselves as an innovative method to construct subject trees or ontologies of specific scholarly fields. The source indices alone can also be used to build innovative co-citation networks of source and research literature. See<a class="footnote-ref" href="#blidstein2022"> [blidstein2022] </a>for an analysis of the different options based on the indices from the Tiresias project</p>
<p>A number of digital tools have been developed in the past decade for linking ancient sources to secondary literature or to other ancient sources. Biblindex is an index for locating quotations and allusion of biblical verses in early Christian literature, created at first manually and then using dedicated software. The Proteus project developed a quotation detection tool for locating quotations of classical Greek and Latin texts (in original and English translation) in the Internet Archive, which includes 16 million open access documents. The Tesserae project<a class="footnote-ref" href="#scheirer2016"> [scheirer2016] </a>has developed tools for comparing identical passages in two ancient texts, and even for locating similar passages which are not verbatim quotes through topic modeling (however, the tool does not actually identify the topics discussed, only the similarity in vocabulary of two passages). The Cited Loci project locates all the articles on JSTOR discussing specific words or lines of an ancient text, and then allows reading the text in the central pane while scrolling through the relevant paragraphs of the articles discussing it in a side pane<a class="footnote-ref" href="#colavizza2019"> [colavizza2019] </a>. These projects demonstrate the current scholarly interest in utilizing computation to locate, compare and link ancient and modern texts, but also that these tools are based directly on the lexical level of the texts or on quotation, neglecting the level of topic or subject.</p>
<p>A small number of projects have attempted to harvest back-of-the-book index data for various aims. Piotrowski<a class="footnote-ref" href="#piotrowski2010"> [piotrowski2010] </a>has used place names listed in indices of a Swiss law book corpus in order to geo-tag the texts and has discussed some of the challenges and possibilities of utilizing indices in this way. Romanello, Berti, Babeu and Crane<a class="footnote-ref" href="#romanello2009"> [romanello2009] </a>have discussed how to extract information from indices of critical editions to locate and identify fragments of ancient authors. Both publications provide important technical information on the tools needed to read and mine the information in indices. Michael Huggett and Edie Rasmussen<a class="footnote-ref" href="#huggett2013"> [huggett2013] </a>constructed a small meta-index of subjects from the indices of a hundred open access books to allow users to approach the relevant pages of these books directly from the meta-index. They also studied the responses of users to their meta-index. This publication is especially useful regarding the challenges this project encountered in unifying different indices and their solutions, as well the features users most appreciated.</p>
<h2 id="5-tiresias-in-context">5. Tiresias in Context</h2>
<p>Tiresias has several salient advantages compared to existing tools:</p>
<p>Tiresias is not based on keyword searching of full text. Rather, it retrieves the texts based on the viewpoint of scholarship, filtered through book subject indices. It therefore provides a radically different perspective than that currently used in digital historical scholarship, and indeed in scholarship and text retrieval in general.Tiresias is derived from a wide range of secondary sources, from many disciplines. It can therefore facilitate study of various subjects across periods, cultures and languages and help in reducing barriers between historical sub-disciplines. It can be especially helpful for comparative research between areas, cultures or languages, or for scholars working on long-term trends, who are therefore less familiar with sources which are not in their area of specialization.Tiresias&rsquo; sources are multilingual. In other words, Tiresias&rsquo;s method provides English subject-based access to primary sources from different languages. This can help with the inherent difficulties of researching a subject in texts in various ancient languages, all of which require years of training for full proficiency.Tiresias facilitates access to texts which have not yet been digitized. Despite ongoing digitization efforts, many ancient texts are still in print or in manuscript only, and/or were not translated into European languages. This is especially true in certain languages such as Aramaic, Coptic, Persian, Georgian, Armenian and Arabic, but even Greek and Latin works are far from fully digitized. These texts are therefore less accessible to the general researcher and even to the expert, who is frequently simply unaware of the contents of many texts (or even of their existence). The database helps researchers recognize the relevance of these texts for their subjects and seek them out.As is usual in library catalogues, searches can be narrowed down by crossing two or more subjects; they can also be narrowed down by details such as author, date, religion, region or language.While most library items or journal articles are tagged with 5–10 keywords, book indices typically include hundreds of subject headings, broken down into sub-headings. Therefore, Tiresias provides granularity far beyond what is now typically provided for secondary literature.</p>
<h2 id="6-usage-scenarios">6. Usage scenarios</h2>
<p>We shall present here three usage scenarios for Tiresias by researchers, students and teachers of ancient history. The use cases serve to exemplify usage for various skill levels and needs. Researchers use the full functionality of the database to surface unique patterns that give rise to research questions. Students may suffice with the search functionality to retrieve primary sources as required for term papers. Teachers can use Tiresias to show learners that novel technology can help uncover historical knowledge and they can give their class interactive assignments to promote curiosity and literacy.</p>
<h2 id="case-no-1-research">Case no. 1: Research</h2>
<p>A senior scholar on ancient religion is writing a book on oaths and swearing in antiquity. Searching foroathorswearand their derivatives in full text databases returns thousands of results. Therefore, to start their research, together with reading scholarship on the subject, they turn to Tiresias. Here they use several dimensions of the database to gain a general view of the subject in contemporary scholarship.</p>
<p>First, they search foroathamong the subjects indexed by Tiresias.Oathappears in 621 different subjects. This list provides the scholar with a detailed overview of the different sub-headings in which oaths in antiquity have been discussed in the scholarship: for example,language of oaths, and gender,homicide trials, oaths inorblood rituals, surrounding oaths.</p>
<p>Second, they create a linked subjects heatmap foroathby entering the keyword in in the relevant search form and receives a heatmap graph showing the subjects sharing most references withoathin the database, sorted by century of the reference (see Figure 9). Here, they see thatsacrifice,womenandwitnessesandlaw courtare subjects strongly linked with oaths. Moreover, they see that almost all the references linked to oaths are from before the 4th century BCE. This can lead to the research question: are oaths in decline after this period? Or is there not enough scholarship on oaths after the 4th century BCE?</p>
<p>Pursuing these questions and a select set of sub-headings, they decide to limit their research to oaths by women. They search Tiresias for references tagged with bothwomenandoaths. Currently there are 13 validated results for this search, and 220 unvalidated results (see above for an explanation of the validation process).</p>
<p>They start from investigating the validated results using the texts provided and can also go directly from the results to the modern publications in which they were discussed. After studying these, they turn to the unvalidated results, which were mentioned only in one book as connected to the subject. Some of these results do not appear relevant to the subject and can be discarded, but some of them are relevant, and considering their large number this facilitates location of relatively less known texts on the subject.</p>
<h2 id="case-no-2-ba-student">Case no. 2: BA student</h2>
<p>A BA student in religion, writing a term paper on conceptions of resurrection from the dead in early Christianity. The student reads scholarly literature on the subject, but as this is a large subject is finding it difficult to cope with the large and varied literature. Furthermore, the term paper instructions called for engagement with primary sources on the subject, and (beyond the New Testament) they are finding such sources difficult to locate. They turn to sites for searching the full text of Greek and Latin literature, and search forresurrection. This supplies them with some texts for analysis, but these are limited to cases in which the keyword explicitly appears in the text, and only in translations of Greek and Latin texts; furthermore, some of the cases turn out to be not actual discussions of resurrection but random mentions.</p>
<p>Turning to Tiresias, they search the same keyword among the validated results. They receive 76 results, with texts from the Hebrew Bible, second temple literature, the New Testament, Church fathers and rabbinic literature. They can read these texts in the original language (Greek, Latin, Hebrew and Aramaic) and in facing English translations. These results are not limited to cases in which the keyword appears in the text, but include texts discussing the subject without the keyword. Furthermore, all the results are relevant to the subject. Of these, they choose two ancient sources for further study, assisted by the detailed sub-heading tags. After choosing these, they click on to the modern publication in which these ancient sources were discussed, to find scholarship on the subject.</p>
<h2 id="case-no-3-teaching">Case no. 3: Teaching</h2>
<p>An instructor is building a new module on the history of emotions in antiquity. The study of the ancient sources is central in the module, as they are also interested in a broad, comparative view of several ancient cultures. When thinking of the general subjects and structure of the module, they turn to the heatmap and network visualizations to gain a general feeling of the subject. Here they see connections with Stoic and Platonic thinkers, but also the connections between emotion, the body and nature (Figure 10). Searching foranger,loveand other emotions provides more information.</p>




























<figure ><img loading="lazy" alt="Image of a network diagram." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Network tool result foremotion
        </p>
    </figcaption>
</figure>
<p>More concretely, searching the database foremotionleads to 54 validated results, from a wide range of periods and genres, as well as links to the modern publications. Some of these they find useful for background discussion, others for study together with their students, with texts and translations already available. Here too, searching for several other terms linked to emotions (some of them obvious such asloveorfear, others found from the network, the heatmap or the subject subheadings of the validated results) leads to further texts on more specific subjects.</p>
<p>In class, the instructor asks their students to search for the termangeron Tiresias and to explore the results (for digital humanities usage in the classroom, see<a class="footnote-ref" href="#locke2017"> [locke2017] </a>,<a class="footnote-ref" href="#fyfe2018"> [fyfe2018] </a>). This leads to a discussion of the validity of using english terms of emotion to describe ancient phenomena and to how using different types of indices can direct our focus and structure our worldview, as well as more specific questions concerning the validity of the the method used by Tiresias to locate subjects and texts.</p>
<p>In summary, the usage scenarios were developed based on our experience in academic research and teaching. Scholars are likely to become highly skilled in using the continually developing functionality of Tiresias and adopt it as one of their standard tools for aiding research based on primary sources. Users with simpler needs can also benefit substantially from access. For example, the BA student will realize that studying in the humanities can be supported uniquely by innovative digital technologies that were developed in academia, thus forming a mental link between humanities and innovation. Further, usage of Tiresias in addition to library databases will sharpen the understanding regarding the difference between primary and secondary sources. The teacher would be able to show younger learners that novel technology can help uncover historical knowledge and that the study of history may involve interactive assignments to promote curiosity and literacy, while problematizing the methods used to create such technologies and their impact on our thought.</p>
<h2 id="7-generalizability">7. Generalizability</h2>
<p>Book indices are a long-time subject of extensive research as part of the broader domain of information retrieval. Our contribution to this vein of research is both specific and generalizable. Specifically, we constructed a novel database based on book indices which aids in intellectually describing the content of ancient texts. This paper explains through description and usage scenarios how this improved access to ancient texts in Tiresias serves scholars and students of ancient history, helping them to save considerable research time, to raise new questions and to achieve a broader view of the field.</p>
<p>The generalizable aspect of our work is the notion to automatically construct new knowledge based on joining data from two independent indices pointing to the same book page, adding a contextual level to an otherwise technical reference. One may envision the applicability of the current approach to additional fields of research. For example, art books containing a picture index and subject index are good candidates for a similar approach, promoting a solution for another longstanding issue, the challenge of assigning meaning to visual materials. The 2016 scandal surrounding Facebook&rsquo;s removal of the Pulitzer prize winning, iconic photograph known asnapalm girlis a vivid reminder for the critical importance of context and the poor ability of algorithms to contextualize, especially when visual materials are concerned. Another example could be literary, scientific or engineering books that contain a subject index and an author index. By crossing subject and author indices, one might draw inferences in two directions: 1) authors&rsquo; areas of knowledge; 2) the prolific authors writing about a certain subject.</p>
<p>A practical contribution of this research concerns publishers who may find value in applying Tiresias logic to their collections of books as an added-value service to readers. Publishers could leverage their existing data to combine additional sources such as academic journals to enrich and further validate the data.</p>
<h2 id="8-summary">8. Summary</h2>
<p>In summary, Tiresias offers access to ancient primary texts through the lens of humanistic scholarship described in the subject indices of academic books. It is a valuable tool for researchers wishing to gain fast and broad retrieval of sources combined with modern interpretations of their meaning. The database provides opportunities for filtering and visualization which aid the research process. In future research, we aim to further augment the validity of the source-subject pairs as well as investigate aspects of historical knowledge extraction. We encourage our readers to visit the Tiresias web site (<a href="https://tiresias.haifa.ac.il/">https://tiresias.haifa.ac.il/</a>) and send us feedback. Finally, the method of cross-indexing may apply to other research fields and offers opportunities for developing databases on other fields of science.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>We thank Mr. Jonathan Blam for his work on validation assessment (paragraph 21). This research was supported by the University of Haifa Data Science Research Center</p>
<h2 id="bibliography">Bibliography</h2>
<ul>
<li id="bastian2009">Bastian, M., Heymann, S., and Jacomy, M. (2009) “Gephi: An Open Source Software for Exploring and Manipulating Networks” , _Third International AAAI Conference on Weblogs and Social Media_ , pp. 361–362.
</li>
<li id="blidstein2022">Blidstein, M. and Zhitomirsky-Geffet, M. (2022) “Towards a New Generic Framework for Citation Network Generation and Analysis in the Humanities” , _Scientometrics_ , 127(7), pp. 4275-4297.
</li>
<li id="colavizza2017">Colavizza, G., Romanello, M., and Kaplan, F. (2017) “The References of References: A Method to enrich Humanities Library Catalogs with Citation Data” , _International Journal on Digital Libraries._ 
</li>
<li id="colavizza2019">Colavizza, G., and Romanello, M. (2019) “Citation Mining of Humanities Journals: The Progress to Date and the Challenges Ahead” , _Journal of European Periodical Studies_ , 4(1).
</li>
<li id="croft2002">Croft W. B. (2002) “Combining Approaches to Information Retrieval” , in Croft, W. B. (ed.) _Advances in Information Retrieval. The Information Retrieval Series 7_ . Boston, MA: Springer.
</li>
<li id="dalton2004">Dalton, M., and Charnigo, L. (2004) “Historians and Their Information Sources” , _College & Research Libraries_ , 65(5), 400–425.
</li>
<li id="fyfe2018">Fyfe, P. (2018) “Reading, Making, and Metacognition: Teaching Digital Humanities for Transfer” , _Digital Humanities Quarterly_ , 12(2).
</li>
<li id="green2000">Green, Rebecca. (2000) “Locating Sources in Humanities Scholarship: The Efficacy of Following Bibliographic References” , _The Library Quarterly_ , 70(2), pp. 201–29.
</li>
<li id="gross2015">Gross, Tina, Taylor, Arlene G., and Joudrey, Daniel N. (2015) “Still a Lot to Lose: The Role of Controlled Vocabulary in Keyword Searching” , _Cataloging & Classification Quarterly_ , 53(1), pp. 1–39.
</li>
<li id="hitchcock2013">Hitchcock, T. (2013) “Confronting the Digital” , _Cultural and Social History_ , 10, pp. 9–23.
</li>
<li id="huggett2013">Huggett, Michael, and Rasmussen, Edie. (2013) “User Interface Evaluation of Meta-Indexes for Search” in _Proceedings of the 13th ACM/IEEE-CS Joint Conference on Digital Libraries_ (JCDL '13), pp. 435–436.
</li>
<li id="huistra2016">Huistra, H., and Mellink, B. (2016) “Phrasing history: Selecting sources in digital repositories” , _Historical Methods: A Journal of Quantitative and Interdisciplinary History_ , 49, pp. 220–229.
</li>
<li id="landry2011">Landry, Patrice, Bultrini, Leda, O'Neill, Edward T., and Roe, Sandra K. (2011) _Subject Access: Preparing for the Future_ . Walter de Gruyter.
</li>
<li id="locke2017">Locke, Brandon T. (2017) “Digital Humanities Pedagogy as Essential Liberal Education: A Framework for Curriculum Development” , _Digital Humanities Quarterly_ , 11(3): pp. 116–123.
</li>
<li id="mercun2016">Merčun, Tanja, Žumer, Maja, and Aalberg, Trond. (2016) “Presenting Bibliographic Families: Designing an FRBR-Based Prototype Using Information Visualization” , _Journal of Documentation_ , 72(3): pp. 490–526.
</li>
<li id="nilbe2014">Nilbe, Sirje, and Tarkpea, Tiiu. (2014) “Using the Estonian Subject Thesaurus in the Digital Environment” , _Cataloging & Classification Quarterly_ , 52(1), pp. 32–41.
</li>
<li id="piotrowski2010">Piotrowski, Michael. (2010) “Leveraging Back-of-the-Book Indices to Enable Spatial Browsing of a Historical Document Collection” . In _Proceedings of the 6th Workshop on Geographic Information Retrieval_ (GIR '10), 17:1–17:2.
</li>
<li id="romanello2018">Romanello, Matteo. (2018) “Large-Scale Extraction of Canonical References: Challenges and Prospects” , January.
</li>
<li id="romanello2009">Romanello, Matteo, Berti, Monica, Babeu, Alison, and Crane, Gregory. (2009) “When Printed Hypertexts Go Digital: Information Extraction from the Parsing of Indices” in _Proceedings of the 20th ACM Conference on Hypertext and Hypermedia_ (HT '09), pp. 357–358.
</li>
<li id="scheirer2016">Scheirer, W., Forstall, C., and Coffee, N. (2016) “The Sense of a Connection: Automatic Tracing of Intertextuality by Meaning” , _Literary and Linguistic Computing_ , 31(1), pp. 204–17.
</li>
<li id="sinn2014">Sinn, D., and Soares, N. (2014) “Historians' use of digital archival collections: The web, historical scholarship, and archival research” , _Journal of the Association for Information Science and Technology_ , 65, pp. 1794–1809.
</li>
<li id="waskom2021">Waskom, M. L. (2021) “Seaborn: Statistical Data Visualization” , _Journal of Open Source Software_ , 6(60), 3021. Available at https://doi.org/10.21105/joss.03021.
</li>
<li id="wlodarczyk2013">Włodarczyk, Bartłomiej. (2013) “Topic Map as a Method for the Development of Subject Headings Vocabulary: An Introduction to the Project of the National Library of Poland” , _Cataloging & Classification Quarterly_ , 51(7), pp. 816–29.
</li>
<li id="yu2017">Yu, Holly, and Young, Margo. (2017) “The Impact of Web Search Engines on Subject Searching in OPAC” . _Information Technology and Libraries_ , 23(4), pp. 168–80.
</li>
</ul>
]]></content></entry><entry><title type="html">Whitman Tracked Between Editions, Rossetti as a Complex Subversive, and the Collective Sense of Authorship: A Mixed Methods Accounting of a Hyperlinked Calamus</title><link href="https://startwords.cdh.princeton.edu/vol/17/1/000657/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/17/1/000657/</id><author><name>David Thomson</name></author><published>2022-12-22T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>In editing <em>Poems by Walt Whitman</em> (1868) for a British readership, William Michael Rossetti strode the line between censorship and advocacy, as well as that between an enabling and co-opted subversion. That Hotten edition removed about one-half of <em>Leaves of Grass</em> (1867) — including what would become “Song of Myself” — toward making possible Whitman’s broader circulation in the United Kingdom. <em>Poems</em> was praised by the <em>Saturday Review</em> for bringing forth <em>the comely</em> after removal of the <em>indescribably filthy</em> <a class="footnote-ref" href="#whitley2020"> [whitley2020] </a>. That <em>Poems</em> was published at all, and continued to be published into the 20th century, remains remarkable in a British publishing culture that allowed officials to seize an entire press run before either the author or publisher appeared in court to argue its merit.</p>
<p>Declaring <em>Poems</em> to be a bowdlerized, censored or expurgated text betrays an editorial/critical orientation contrary to the values of a digital humanities community underscored by openness to process and collaboration with others. It permits authorial identity and preferences to trump the slate the values that permitted publication, however second-guessed that edition was. To understand <em>Poems</em> to be bowdlerized puts it in the company of <em>The Family Shakespeare: in which nothing is added to the original text, but those words and expression are omitted which cannot with propriety be read in a family</em> <a class="footnote-ref" href="#bowdler2009"> [bowdler2009] </a>. That family-friendly Shakespeare continues to remove the vulgarity and bawdy joys that Thomas’s sister Henrietta sensed more than two centuries ago; the entire six volume set published by Cambridge University Press can be acquired for about $350. Encamping <em>Poems</em> with <em>The Bowdler Shakespeare,</em> while distantly viable, is to dismiss its achievement as the end result of another morally squeamish, superficially selective editor whose first purpose is to serve the family rather than the author. It is also to place <em>Poems</em> in a timeless void, removed from the very social dynamics upon which production and dissemination take place in the digital humanities.</p>
<p>More viable is to describe <em>Poems</em> as an expurgated Whitman. Rossetti can be accurately but narrowly understood as expurgating <em>Leaves</em> in his selection criterion “to omit entirely every poem which could with any tolerable fairness be deemed offensive to the feelings of morals or propriety in this peculiarly nervous age” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>. However, Henrietta’s editing of Shakespeare made no allowance for the limitations of an age; her Shakespeare was in fact elevated as that fit for all time. By contrast, Rossetti’s edition was qualified and even necessitated by his particularly Victorian <em>nervous age.</em> Just as importantly, one purpose of Rossetti’s edition was to serve a living author rather than the sanctity of the family. He upheld American endorsers Burroughs (1867/1971) and O’Connor (1866/2021), who each declared Whitman to be “ <em>the</em> poet of the epoch” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>. In judging Whitman as particularly suited for the present age of his edition, Rossetti declared that Victorian readers would benefit by judging for themselves the merits of Whitman, who “beyond all his competitors” is “incapable of all compromise and an initiator in the scheme and form of his works” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>.</p>
<p>Less viable, by far, is to judge <em>Poems</em> as a censored text. First, Rossetti served no official office in presenting his selected Whitman. He merely offered his edition to the court of literary deliberation. Second, I doubt any censor has so thoroughly considered and documented a case for censorship. Rossetti offered his edition at invitation of a commercial publisher. Further, he did so after first encountering Whitman’s work as a reader and a leading commentator of Victorian publishing 12 years before his <em>Chronicle</em> article. That secretary to the Pre-Raphaelite Brotherhood may have even identified in Whitman the American complement of the movement. Yet further, his goal was to advance reception of an author rather than thwart it.</p>
<p>Rather than argue Rossetti was either an advocate for or an expurgator of Whitman, I offer a conciliatory, more utilitarian position. Rossetti brought forward a <em>selected</em> Whitman that he thought possible to publish within the constraints of his time. Moreover, he did so for the benefit of a living author and a readership whose understanding of the man was all too frequently shaped by the hearsay-report of the periodicals of the day. While his depiction of a democratic spokesman championing the humanity of all is only one aspect of Whitman, he also presented a Whitman who yearned to receive the love that he offered to others and yet could only indirectly state. Accordingly, I argue that Rossetti presented a Whitman who was both an all-too-humanly needy American citizen and an egalitarian spokesman for the inherent worth of all — regardless of nationality, vocation or any caste formation. This Whitman should be the herald for the digital humanities on his dual insistence on hearing others — all others — well, and being heard. This is a Whitman that should leap off the page of any particular edition into the life of a poem inside and outside of an edition. This is a Whitman that can be summoned from the free access universe of individual editions and re-animated for present readers.</p>
<p>Rossetti’s pragmatism was also noted by Folsom (<a href="#folsom1991">1991</a>), who observed that Whitman granted <em>Leaves</em> was “a commodity in a publishing market” (642). From the 1868 <em>Poems</em> through <em>Selected Poems</em> <a class="footnote-ref" href="#stedman2008"> [stedman2008] </a>, Whitman sought that larger audience not yet ready to read the ever-growing <em>Leaves</em> editions but who might be prompted to do so after a kinder, gentler introduction. The compromise was not that of Whitman’s redactors, but Whitman’s in his complicity to allow <em>Leaves</em> to be partitioned into slimmer volumes and anthology samples<a class="footnote-ref" href="#folsom1991"> [folsom1991] </a>. Any excerpt — no matter how large or tamed into making Whitman one of other conventional poets — called into question Whitman’s lifelong insistence that <em>Leaves</em> should be read as a whole. Only the entirety of that reading experience with its lauds for “cities, immigrants, commerce, mass culture, industry, physicality, nondiscrimination, democratic affection, equality and anti-Puritanism” <a class="footnote-ref" href="#folsom1991"> [folsom1991] </a>could secure for Whitman the place he wished to occupy in American letters. Any less thorough presentation amounted to asanitizing process,making Whitman “palatable for a public that he had set out to challenge and remake” <a class="footnote-ref" href="#folsom1991"> [folsom1991] </a>.</p>
<p>Challenging that <em>sanitizing</em> assessment of <em>Poems,</em> in particular, motivates my examination of the multi-dimensional, variegated Whitman I sense Rossetti surveyed in <em>Poems</em> . Simultaneously, I challenge another dearly held cultural narrative that locates authorship most authentically achieved in the literary vision and products of a single writer. Today, <em>Whitman</em> is a brand name in present publishing, translation and commentary more than an author who oversaw nine editions of <em>Leaves</em> in his lifetime. Even from the outset, <em>Whitman</em> ceased to be an author whose name was merely a placeholder for various literary works. In reception and by his own design, <em>Whitman</em> was seen at once as shamelessly self-aggrandizing, noble in promoting democratic virtues, and beastly in celebrating the place of sex in human affairs. The ongoing attention he receives depicts an author who rewards, cautions and edifies readers so variously that the author <em>Whitman</em> must make way for various <em>Whitmans,</em> who indeed “contain multitudes” <a class="footnote-ref" href="#whitman1867"> [whitman1867] </a>and, in fact, are prompted by their many receptions. The multitudinous author of the poem that would become “Song of Myself” is not overtly present in <em>Poems</em> because Rossetti excerpted no portion of it. However, a Whitman comprised by and capable of containing multitudes is surveyed by Rossetti in the various narrative voices that collectively illustrate both a complexly declarative and privately evasive author.</p>
<p>In support of that position, I annotate the lexical and semantic traces of the “Calamus” sequence. Even while the sequence has been consistently regarded as the most overtly homoerotic material of <em>Leaves</em> — and among that glossed as gross and indecent — Rossetti included 11 of 40 of those poems that appeared in the 1867 <em>Leaves.</em> I do so by the semantic indexing technology by which many of us daily access the world wide web. Accordingly, I argue that <em>Poems</em> is truer to the spirit of the 1867 <em>Leaves</em> than was apparent both to Whitman dismissing it as a dismemberment and subsequent readers who primarily see authorship as the stylistic verve at work in a singular literary work, as envisioned by one writer. The alternative sense of authorship that I explore is found in a <em>Whitman</em> who strides among the various editions of his work, even while he is assisted by others. This <em>Whitman</em> in particular should be considered as a herald of our particularly nervously collaborative and open-access age. Among those are sympathetic readers and editors. That is to suggest that even the career tendencies indexed by <em>oeuvre</em> fail to contain an author understood as much by his particular literary projects as by reception from his many sorts of readers proposing and disposing of critical approaches. That Whitman may be empirically tracked in <em>Poems</em> not only by the “Calamus,” content that Rossetti included, but also by that excluded. This <em>hypertextual Whitman</em> Rossetti knew as a sympathetic reader because in his selection and framing of <em>Leaves</em> he had to acknowledge its past and present reception, even as he anticipated what may entice future readers in <em>Poems</em> .</p>
<h2 id="a-cross-atlantic-reception">A Cross-Atlantic Reception</h2>
<p>Before addressing the present reception of Whitman and “Calamus,” in particular, I pause to frame the case for how Whitman the author was initially presented to readers on each side of the Atlantic. I merely sample that reception and so refer Whitman enthusiasts to the exhaustive catalogue of reviews prepared by Barney et al. (<a href="#barney2007">2007</a>). In doing so, I argue that neither the acerbic dismissals nor sympathetic receptions were singularly instrumental in shaping the Whitman whose name came to index a person and poetic more than singular literary works. <em>Whitman</em> as a cultural product is implicitly acknowledged whenever the man is equated with either his body of work or his critical reception. I do so, moreover, because his early reception continues to shape present commentary in this age in which cultural studies is a new edifice framing authors for the next generation of authors seeking to ally themselves to or reject influence. These present <em>authors</em> are not only emerging and canonical writers, but also those who make the cases for authorship and who few may even be regarded or come to be regarded as authors in their own rites.</p>
<p>Rossetti’s advocacy for Whitman enfolded the poet’s career. That story begins with Rossetti reading the 1855 <em>Leaves,</em> recommended to him by William Bell Scott, the Pre-Raphaelite painter and poet who introduced the brother of Christina and Dante to the 1855 first edition. Then, as he argued in a republished letter to Scott prefacing his introduction to <em>Poems</em> , Rossetti “perceived its substantiality and power were still ahead of any eulogium with which it might have been commended to me” <a class="footnote-ref" href="#rossetti1868"> [rossetti1868] </a>. As the Pre-Raphaelite chronicler perhaps eager to recognize an international cadre devoted to depicting people at their quotidian best and worst, Rossetti favorably reviewed Whitman’s poetry in the (London) <em>Chronicle</em> in 1867. One outcome of that review was an invitation by John Camden Hotten to edit a selected poems “offering the first tolerably fair chance Whitman has had of making his way with English readers on his own showing” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>. That edition was presented as a counter to the “mostly short-sighted, sneering, and depreciatory” reception Whitman had so far received.</p>
<p>In his 1867 <em>Chronicle</em> review of Whitman’s work, Rossetti declared the American was an exemplary man of his time, even while he granted that Whitman “alludes to gross things, and in gross words — the clearest, bluntest, and nearly the least civilly repeatable which can come uppermost to the lips” <a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>. For him Whitman’sentire originalitydemanded some allowance among readers if their hesitations over his coarse language “would exclude him from court” <a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>run by censors. He found <em>Leaves</em>  “intensely modern and intensely American,” even while he declared the book to be “ <em>the</em> largest poetic work of our period” <a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>. He defended his selected <em>Leaves</em>  “because it was clearly impossible that the book, with its audacities of topics and of expression included, should run the same chance of justice, and of circulation through refined minds and hands, which may possibly be accorded to it after the rejection of all such peccant poems” <a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>. Regardless of Whitman’s reservations of <em>Poems</em> , Peattie declared in his introduction to Rossetti’s <em>Selected Letters</em> that <em>Poems</em> helped secure Whitman’s place in literature outside of the United States.</p>
<p>In a letter to Moncure Conway, an American pastor working at South Place Chapel in London while Rossetti was preparing <em>Poems,</em> Rossetti relates he is pleased to work on a British edition of Whitman’s poetry<a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>. In one letter to fellow Whitman critic James McNeill Whistler, Rossetti maintains “a debtor and creditor account” in his critical commentary. That sober balance between “expounding beauties” and “detailing faults” is particularly important “in the case of so aboriginal and transcendent a genius as Whitman” <a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>. In responding to Whitman’s complaint of receivingungrateful treatmentfor his work in the United States, Rossetti returns the encouragement lacking among Whitman’s countrymen: “I suppose it is a very general if not universal experience that anything that is at once great and extremely novel encounters for some considerable time much more hostility than acceptance” <a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>. In that letter he offers further consolation to Whitman by observing that the hostile reception the poet reports is “rather indeed a testimonial … [to] the great intrinsic value of your writings” <a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>.</p>
<p>Whitman’s animus toward his American contemporaries may be understood to be the result of his radical eschewal of traditional rhyme and meter, and the radically dissident voice of self-creation he namedWalt,rather than Walter, in the long untitled poem that became “Song of Myself.” Readers’ conflation of persona and poet is a constant in the 150 years of commentary and scholarship reviewed in the <em>Cambridge Companion to Whitman</em> <a class="footnote-ref" href="#killingsworth2007"> [killingsworth2007] </a>.</p>
<p>One early anonymous reviewer of the <em>Brooklyn Daily Times</em> well represents that trend in an opening assertion: Judgment “on real poems” requires “an account of the poet himself” <a class="footnote-ref" href="#anonymous2002"> [anonymous2002] </a>. The fecund, coarse language of the opening poem in which Whitman names himself as “Walt Whitman, an American, one of the roughs, a kosmos” prompted the reviewer to declare, “Politeness this man has none, and regulation he has none” <a class="footnote-ref" href="#anonymous2002"> [anonymous2002] </a>. The depiction of a “rude child of the people! — No imitation — Nor foreigner — but a growth and idiom of America” parodies Whitman’s introduction to the first edition written in an equally unorthodox, but ecstatic manner. The reviewer derided both the style and the man in judging the literary effects as those of afine brutewho self-satisfyingly refuses “the artificial teaching of a fine writer or speaker” <a class="footnote-ref" href="#anonymous2002"> [anonymous2002] </a>. While other poets celebrate the actors and sites of history, the poet of <em>Leaves</em>  “celebrates natural propensities in himself; and that is the way he celebrates all” <a class="footnote-ref" href="#anonymous2002"> [anonymous2002] </a>. The end result of that “what I assume you shall assume” poetic<a class="footnote-ref" href="#whitman1867"> [whitman1867] </a>is “what the serpent left the woman and the man, the taste of the Paradisiac tree of the knowledge of good and evil, never to be erased again” <a class="footnote-ref" href="#anonymous2002"> [anonymous2002] </a>. Equally offensive to the reviewer is the class betrayal of a poet who fails to acknowledge other poets, even while he “likes the ungenteel ways of the laborers — is not prejudiced one mite against the Irish — talks readily with them — talks readily to niggers — does not make a stand on being a gentleman, nor on learning or manners” <a class="footnote-ref" href="#anonymous2002"> [anonymous2002] </a>.</p>
<p>Soon afterward, Edward Everett Hale reviewed the 1855 <em>Leaves</em> in <em>North American Review,</em> similarly conflating persona and poet. However, Hale credited the unnamed author as bringing to the reader “the freshness, simplicity and reality of what he reads, just as the tired man, lying on the hillside in summer, enjoys the leaves of grass around him” <a class="footnote-ref" href="#anonymous2002"> [anonymous2002] </a>. Hale’s greatest praise for <em>Leaves</em> , however, comes in his commentary on Whitman’s broken prose preface celebrating the unique possibilities of producing a national literature equal to the promise of the nation. Hale praised Whitman’s assertion of native genius found most urgently among the common people. Thus, Whitman’s public literary persona was accorded the egalitarianism to which Rossetti was drawn and especially represented in his handling of the “Calamus” poems.</p>
<p>The commentary most out of the step with Whitman’s contemporary reception came from a woman remarkably out of step in her own rite. That came from Fanny Fern, a.k.a. Sara Payson Willis, the highest paid columnist in the mid-19th century, and one of Whitman’s inner circle of New York writers and artists. She declaredLeavesto be “unspeakably delicious, after the forced, stiff, Parnassian exotics” of the reigning literati. She found the world was in want of Whitman on two counts. First, she found him an advocate for <em>women</em> not <em>ladies.</em> Second, the world was in want of <em>men</em> not <em>gentlemen.</em> The man she found in <em>Leaves</em>  “dared speak out his strong, honest thoughts, in the face of pusillanimous, toadying, republic aristocracy” <a class="footnote-ref" href="#fern2002"> [fern2002] </a>. While the persona and poet remain conflated, Fern grants that Whitman spoke to and for others.</p>
<p>Rossetti also advocated for Whitman in introducing the American poet to his circle of intimates. The most sustaining of those for Whitman was Anne Gilchrist, who was introduced to Whitman’s poetry by Rossetti as he was compiling <em>Poems.</em> Gilchrist, widowed at age 33 and mother to four children, went on to complete Alexander Gilchrist’s biography of Blake with the encouragement of the Rossetti brothers. She first read Whitman at age 41 when serving as a single parent to her children and completing her husband’s great life work. At that difficult time, Rossetti gave her his copy of the 1867 <em>Leaves.</em> In response to the transport she experienced as a reader, she wrote a series of letters to Rossetti wondering how “words could cease to become words, and become electric streams like these” <a class="footnote-ref" href="#gilchrist2002"> [gilchrist2002] </a>. At Rossetti’s encouragement, Gilchrist turned those letters into the one of the earliest substantive critical commentaries on <em>Leaves</em> . Among the poems prompting her to lay aside <em>Leaves</em> at times in response to all that it demanded of her was the “Calamus,” sequence. What became known as “An Englishwoman’s Estimate of Walt Whitman” was first anonymously published in <em>The Radical</em> (Boston). One commentator annotated Gilchrist’s reading of <em>Leaves</em> as “an intellectual revolution, a spiritual illumination, a physical arousal, a personal passion” toward accounting for how a book reporting itself to be a man “allow[ed] her to realize, after a lengthy dormant period, tendencies that had been long in developing” <a class="footnote-ref" href="#mardsen2006"> [mardsen2006] </a>. Only a year later did she reveal herself to and declare her love for Whitman in the first installment of a life-long correspondence.</p>
<p>At the end of the century, well after the deaths of both Whitman and Gilchrist, Rossetti in a letter to Anne’s daughter, Grace, laments the vapid praise given to Whitman, whom he believed was due “the reasonable, solid, and lofty homage to which his writings are entitled” <a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>. Before Whitman’s death, Rossetti believed Whitman’s life as an artist and patriot should also be acknowledged. Accordingly, Rossetti wrote then President Grover Cleveland in particular and more generally the American public to succor the impoverished poet in his remaining years<a class="footnote-ref" href="#peattie1986"> [peattie1986] </a>.</p>
<p>While Peattie well annotated the background to the professional relationship between Whitman and Rossetti entirely conducted by correspondence, Erkkila (<a href="#erkkila1989">1989</a>) and Ramsey (<a href="#ramsey1997">1997</a>) are among the few commentators who acknowledged how Whitman benefitted as a poet. In particular, both scholars recognized how Rossetti’s grouping of Whitman’s civil war poems under the headingDrum-Tapswas instrumental to the later 1871 <em>Leaves.</em> Erkkila found the finalDrum-Tapscluster of the 1881 <em>Leaves</em> appealing to Providence as it moves from patriotic exultation over the mustering of troops to the suffering and loss of the war. Ramsey extended those insights to argue that Whitman “borrowed this suggestive ‘providential’ sequence for the Drum-Taps ” (<a href="#ramsey1997">166</a>) sequence as it was realized in 1871 <em>Leaves.</em> She observed that “the underlying structure … remains Rossetti’s, who provided … the thematic ‘cycle of war’ pattern by which Whitman is taken to have interpreted the American civil upheaval” (<a href="#ramsey1997">166</a>).</p>
<p>To Whitman’s collaboration with Rossetti, and through him to Tennyson, Symonds, Swinburne and Carpenter,the paradigmaticpoet “was more widely celebrated in Britain than in his own country” <a class="footnote-ref" href="#collins2017"> [collins2017] </a>at the time of his death in 1892. Drawing the admiration of English composer Vaughn Williams, as well, was “Whitman’s political egalitarianism — expressed through notions of ‘manly love’ and comradeship” <a class="footnote-ref" href="#collins2017"> [collins2017] </a>. That manly-love fellowship, Collins observed “presented a powerful alterative to prevailing Victorian forms of political and social relations” (<a href="#collins2017">65</a>). For that depiction of Whitman’s egalitarianism Rossetti should receive some credit.</p>
<p>Simultaneously, Rossetti could be understood as one of Whitman’s (albeit sympathetic) redactors. In his presentation of a Whitman heralding an international brotherhood of comrades and celebrating the general revelation of nature, he altered <em>Leaves’</em> clusters, at once reassigning and renaming poems in complement to his sense of thematic unity. See Table 1 for an overview. Rossetti is censorious in removing the material that would prompt righteous indignation, rather than a considered response, from readers. Rossetti’s dual role of redactor of and advocate for Whitman introduces the complex terrain of subversion.</p>
<p>In introducing a collection of essays annotating Victorian publishing, Womack and Decker (<a href="#womack2016">2016</a>) observed “the entangled relationships among writer, text, and reader” (<a href="#womack2016">xi</a>) that accompanies any act of subversion. For Rossetti that demanded acknowledging a “peculiarly nervous age” in which readers were expected to principally object to any overt expression of sexual agency. Simultaneously, however, he had to present that aspect of Whitman’s work that the dominant culture of his day rejected. More distantly, in allying himself<br>
“Calamus,” Included and Excluded from ‘Poems,’ and Assessed as Laudatory or Cautionary<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 1867 <em>Leaves</em> 1867 label <em>Poems</em> titleRossetti grouplaudWhoever You are Now Holding My HandWhoeverFit AudienceSongs of Parting0These I Singing in SpringSingSinging in SpringSongs of Parting1A SongASongLove of ComradesSongs of Parting1Not Heaving from my Ribb&rsquo;d Breast OnlyHeavingPulse of My LifeSongs of Parting0Of the Terrible Doubt of AppearancesTerribleAppearancesWalt Whitman0Recorders Ages HenceRecordThe FriendWalt Whitman1Of Him I Love Day and NightDayNightA DreamWalt Whitman0To a StrangerStrangerTo a StrangerWalt Whitman1This Moment Yearning and ThoughtfulYearnOther LandsWalt Whitman1When I Peruse the Conquer&rsquo;d FamePeruseEnvyWalt Whitman0What Think You I Take Pen in HandPenParting FriendsWalt Whitman1I Dreamed in a DreamDreamedThe City of FriendsWalt Whitman1Among the MultitudeMultiAmong the MultitudeWalt Whitman0Full of Life, NowFullCenturies HenceSongs of Parting1As I Ebb’d with the Ocean of LifeEbb’dElemental DriftsWalt WhitmanStarting from PaumanokSPStarting from PaumanokChants DemocraticIn Paths UntroddenPaths1Scented Herbage of my BreastScented1Are You the New Person Drawn to MeNewPerson0Roots and Leaves Themselves AloneRootsLeaves1Not Heat Flames Up and ConsumesNotHeat1Trickle DropsTrickle0City of OrgiesOrgies1Behold This Swarthy FaceBehold1I Saw in Louisiana a Live-Oak GrowingLouisiana1I Hear It Was Charged Against MeCharged1The Prairie Grass DividingPrairie1We Two Boys Together ClingingClinging1A GlimpseGlimpse1A Promise to CaliforniaPromise1Here, Sailor!Sailor1Here the Frailest Leaves of MeFrailest0No Labor-Saving MachineMachine1To the East and to the WestEastWest1Earth! My Likeness!Earth0A Leaf for Hand in HandLeaf1Fast Anchor&rsquo;d, Eternal, O LoveEternal1Sometimes with One I LoveSometimes0That Shadow, My LikenessShadow1To a Western BoyWestern0Of You Whom I Often and Silently ComeSilently1<br>
to Whitman, he had to account for a literary movement that emerged in response to its time rather than was engineered by a coterie of young artists dissatisfied with the Royal Academy.</p>
<p>Rossetti’s solution, I argue, was to present the new man of a new democratic nation, whose love-longings for comrades could be spiritualized as canonically as did Dante in <em>La Vita Nuova</em> , Edmund Spenser in <em>Amoretti</em> , and Elizabeth Barrett Browning in <em>Songs of the Portuguese.</em> Framing Whitman as a transcendental wooer of soldiers, stevedores, farmers, and tradesmen was also resonant with the Pre-Raphaelite standard of naturalism. Those <em>roughs</em> were for Whitman in his broken prose manifesto “the genius of the United States [in] Their manners speech dress friendship — the freshness and candor of the physiognomy — the picturesque looseness of their carriage” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>. Perhaps in Whitman’s egalitarian trope of “the President’s taking off his hat to them not they to him” (<a href="#whitman1868">iv</a>) Rossetti early on found another Pre-Raphaelite brother. The depiction of Whitman as the outsider artist “unfettered by existing conventions” <a class="footnote-ref" href="#prettejohn2012"> [prettejohn2012] </a>complemented the self-creation of an author who learned carpentry from his father and was trained in a trade at the printing press. More certainly, by 1868, Rossetti surveyed Whitman’s attempt to define the new man in a new nation by eschewing rhyme and even blank verse to the point that some poems may be regarded as “a warp of prose amid the weft of poetry” (<a href="#prettejohn2012">3</a>).</p>
<p>More urgently, however, Rossetti celebrated Whitman’s open, extending and inviting humanity. The poet’s subject, he noted in his introduction to <em>Poems,</em> is “every subject” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>. He summarized Whitman’s verve as realizing “One’s self” amid the “En Masse” of humanity. For Rossetti, <em>Leaves</em>  “is the poem both of Personality and of Democracy … in it the most literal view of things is continually merging into the most rhapsodic or passionately abstract” (<a href="#whitman1868">5</a>). Whitman’s British advocate and Pre-Raphaelite chronicler, thus, illustrates the entanglement of relations that Womack and Decker observed in reading and positively responding to the subversive presence of a new art form.</p>
<p>Consider the double-edged subversion evident in the Swedenborg epigraph leading off <em>Poems.</em> That emendation was entirely Rossetti’s, who employed it to spiritualize Whitman’s emphasis on the body as another sacred site of creation. Rossetti excerpted the reflections of the 17th century Christian mystic on the bodily presence of angels to suggest that both Whitman and his panoply of American citizens may be regarded as emanations of heaven, despite the “gross ignorance” Swedenborg observed “respecting Angels and Spirits as to suppose them to be minds without a form, or mere thoughts” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>. Through Swedenborg, Rossetti at once elevates the peripheral citizenry of the United States, exhorts readers for failing to entertain angels well, and sanctifies Whitman’s work as that proceeding from an other-worldly messenger finding his subject matter in the very stuff of the world. That gesture could be understood as an enabling subversion because it honors Whitman’s project of recognizing the inherent value of the entire citizenry, even those who are rarely seen and still more rarely lauded. Yet, that spiritualization of people in their material conditions simultaneously reifies understanding some as radically Other than the captains of commerce, statesmen and exceptional artists. In even acknowledging that polarism of spiritual and material conditions to which Swedenborg objected and by which readers were likely to dismiss Whitman, Rossetti may be understood to accede to the values and thinking of a dominant culture well practiced in bigotry. In Rossetti’s gesture of elevating <em>manly love</em> as a trope for egalitarianism, his subversion may be understood to be co-opted and absorbed within the dominant culture’s practices of finding and treating some more worthily than others. That is to observe that if the roughs, criminals and men attracted to other men should be entertained as possible angels, as Rossetti suggests in the epigraph he appended to his selected Whitman, then the editor has only further muddied their better reception as members of a common humanity. Likewise, if Whitman’s celebration of manly love is spiritualized to emphasize a new and better humanity emerging, then that better world remains shackled in caste and entitlement by even acknowledging a material-spiritual split.</p>
<h2 id="present-reception-of-the-calamus-sequence-in-the-united-states">Present reception of the ‘Calamus’ sequence in the United States</h2>
<p>Rossetti’s tenuous walk among his cultural terrain of reception has been undertaken more recently by “Calamus” commentators who depict Whitman as a democratic, yet quite vulnerable speaker. Simultaneously, the sequence commands critical attention in indexing frailty and desire independently of sexual orientation<a class="footnote-ref" href="#sherman1992"> [sherman1992] </a>. Cocks found it astutely illustrating the Victorian evasion of sexual desire byspiritual communion<a class="footnote-ref" href="#cocks2001"> [cocks2001] </a>.</p>




























<figure ><img loading="lazy" alt="three depictions of whitman in three different editions of leaves" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     >
</figure>
<p>Thomas found Whitman adopting a different rhetorical strategy than “Song of Myself” in a speaker foregoing contradiction to state the complexities of love in order to more ambivalently and fully accept the polar pairing of life and death (<a href="#thomas2010">2010</a>). The “Calamus” sequence Thomas observed dramatizes love “as predicated upon loss and vice versa” (<a href="#thomas2010">643</a>) toward identifying “the complexities of human experience” (<a href="#thomas2010">644</a>). That more general human experience in love is a check to “presidential incompetency and growing sectional tensions” <a class="footnote-ref" href="#reynolds2010"> [reynolds2010] </a>. In the 1860 <em>Leaves</em> in which “Calamus” premiered, Reynolds observed a campaign to appeal to a middle-class readership and show Whitman neatly trimmed and conventional, rather than theroughpersona of the first edition. Figure 1 illustrates that contrast in personae, as well as showing the more grandfatherly Whitman with whom Rossetti began a dialogue to launch the first British edition of a radically redacted and regrouped <em>Leaves.</em></p>
<p>That rebranded, more fashionable Whitman of 1860, enticed clerks and gaffers to become Whitmaniacs<a class="footnote-ref" href="#cocks2001"> [cocks2001] </a>. Wheat identified <em>Leaves</em> as therapeutic literature meant to form the free reader into a free person and “therefore an appropriate citizen for a fully democratic party” <a class="footnote-ref" href="#wheat1990"> [wheat1990] </a>, while “Calamus” complements that spokesmanship quality of the sequence in its insistence on speaking to the political and philosophical appeals of democracy. How we adhere to one another, regardless of regional differences, is a primary driver of the content, which Wheat interpreted as a spiritual counterpoint to the far more carnal “Children of Adam” sequence. Sexual desire should be understood as another cultural production that exists in negotiation within a complex set of rules larger than our tendency to dichotomize sex into a private experience distinct from public consequence<a class="footnote-ref" href="#grossman1990"> [grossman1990] </a>. Accordingly, in the evangel-poem “Starting from Paumanok,” Grossman found Whitman only implicitly figuring as the apologist for manly love, while explicitly he does so for the common mother of liberty, Ma Femme.</p>
<p>Common to all of these perspectives is the function of indirection in expressing difficult and even repressed content. In recognition of that skillful avoidance of explicit content that would raise the ire of a censor, gay writers emphasize the otherness they sense in their sexual desire and identity<a class="footnote-ref" href="#bergman1991"> [bergman1991] </a>. Their otherness is particularly pronounced in a “categorical, perhaps even ontological” sense of difference from their heterosexual counterparts<a class="footnote-ref" href="#peterson1998"> [peterson1998] </a>. The result is indirection, until that time when same-sex desire may be as simply and directly stated as does Whitman in “A Leaf for Hand in Hand” . Then we will “see it common for you to walk hand in hand” <a class="footnote-ref" href="#whitman1867"> [whitman1867] </a>.</p>
<p>The sequence’s relation to the earlier manuscript grouping of “Live Oak, with Moss” brings attention both to the subversive act of declaring same-sex love and self-censorship. Scholnick reviewed charges that Whitman self-censored in distributing the contents of the 12-poem “Live Oak, with Moss” throughout the larger “Calamus” sequence. Doing so effectively “blunted their meaning” <a class="footnote-ref" href="#scholnick2004"> [scholnick2004] </a>, two commentators held. Allen anticipated this dispute by noting that Whitman’s notebook manuscript of the “Live Oak” sequence more coherently told the love story of one man for another than was evident in “Calamus,” <a class="footnote-ref" href="#allen1955"> [allen1955] </a>. While Scholnick agreed that the narrative unity of “Live Oak, with Moss” was compromised in “Calamus,” he argued that the sequence “extends and deepens its themes in quite surprising ways” (<a href="#schnolnick2004">110</a>). Countering a charge of Whitman self-censoring<a class="footnote-ref" href="#helms1992"> [helms1992] </a>, Parker assessed “Live Oak, with Moss” as a “gay manifesto” <a class="footnote-ref" href="#parker1984"> [parker1984] </a>when he selected it for inclusion in the fourth edition of <em>The Norton Anthology of American Literature.</em> The sequence Parker commented upon was that which Bowers found in 1958 in the Valentine Collection of Whitman’s manuscripts, while the one that Helms read was restored to its original manuscript order but gathered from the 45-poem “Calamus” of the 1860 <em>Leaves</em> . Scholnick observed that both critics “make textual judgments on the basis of their assumption that Whitman faced such widespread homophobia that he was forced to engage in self-censorship” <a class="footnote-ref" href="#scholnick2004"> [scholnick2004] </a>. The silencing homophobia each argued must have influenced the dissolution of “Live Oak, with Moss” into “Calamus” was not present in American letters until much later in the 19th century, Scholnick argued.</p>
<p>A further commonality is this: Both Helms and Parker privilege particular texts in noting authorship. Neither regarded process as an integral process in publication and a fostering component in authorship. By contrast, I argue that the typeset-altered printer’s copy for the 1860 <em>Leaves</em> that Whitman prepared co-existed in his mind with the manuscript version of “Live Oak, with Moss.” That is a nod toward a new era of critical commentary enabled by computer-aided assessment of texts that may be understood to co-exist, regardless of manuscript dates and year of publication.</p>
<p>In that simultaneity of texts in dialogue with one another, an inter-edition Whitman emerges who ever reminds readers that <em>Leaves</em> is accretive as the Mississippi delta in receiving the stuff of a continent. If left unchecked, the river would shift its banks. Within the unchecked and celebrated accretion of <em>Leaves,</em> one current is “Calamus” as another is the “Children of Adam” cluster. Both find common expression in the human need to <em>adhere</em> to one another, regardless of expression in sexual attraction.</p>
<p>In “Starting from Paumanak” (SP), the poem that serves as a Genesis function for Whitman and that which Rossetti selected to introduce <em>Poems,</em> Whitman illustrates the primacy of the sexual drive in listening to a mockingbird “inflating his throat, and joyfully singing” (<a href="#whitman1868">78</a>). The moment underscores not only lyric beauty and a poet finding his counterpart in the natural world, but also that drive to find the best expression of ourselves — as citizens and sojourners — in “the subtle, clandestine, away beyond” (<a href="#whitman1868">78</a>). Immediately following Whitman allegorizes democracy as Ma Femme and pledges to “make the songs of passion, to give them their way” (<a href="#whitman1868">79</a>). Among that humanity Whitman declares he will represent areoutlawed offenderswhose songs Whitman will transform into “the true poem of riches — To earn for the body and the mind whatever adheres, and goes forward, and is not dropped by death” (<a href="#whitman1868">79</a>).</p>
<p>In this manifesto celebrating life itself and the lives of all citizens, even those outlawed offenders, Whitman naturalizes his commitment to egalitarianism and his stance in indirection. Whitman realizes the mockingbird sang not only for himself, his mate attending to her brood, and for others listening. That song was also “a charge transmitted, and gift occult, for those being born” (<a href="#whitman1868">78</a>) delivered in a poem surveying the circumstances and settings of a poet’s birth. That birth song I sense resounding in <em>Poems</em> as much for the citizenry of a new nation as for men loving one another in nonchalance in the regrouped and disguised “Calamus” poems.</p>
<p>Accordingly, I neither seek to arbitrate which Whitman is at work in the “Calamus” sequence nor what that sequence held for its own time. Neither do I wish to assess the aesthetic or ethical merit of one edition over another. More urgent is simply following its rhetoric of indirection through two distinct groups of “Calamus” poems toward showing a method of establishing influence in a literary text. However rebranded, compromised and appropriated is that content, I sense the “Calamus” content of <em>Poems</em> substantively recalls the entire sequence presented in the 1867 <em>Leaves.</em> Those poems also underscore both the loudly declarative Democratic spokesman and the more personally evasive, vulnerable speaker Rossetti recognized in <em>Leaves</em> .</p>
<p>The extra-human processing that enables texts to co-exist may be understood ashypertextual. This term from information science is now commonplace. Presently, hypertext is not merely a device by which additional information may be <em>clicked</em> and so accessed in a moment. It also suggests a state of mind that returns readers to the cacophony of literary texts speaking to and against one another <em>before</em> being orchestrated by the activity of critical response.</p>
<h2 id="inside-a-semantic-indexing-machine">Inside a Semantic Indexing Machine</h2>
<p>Hypertextwas first introduced as a device through which, for example, the work of “handling personal file systems” may be better effected during the drafting of a technical paper<a class="footnote-ref" href="#nelson1965"> [nelson1965] </a>. At that early meeting of the Association for Computing Machinery, Nelson observed that those files “shade into manuscripts” while “the assembly of textual notes <em>becomes</em> the writing of text without a sharp break” (<a href="#whitman1868">84</a>). Those personal files exist in non-linear relation to what becomes the linearized account of a paper read from start to finish. However, he noted a cost to that linear ordering. The alternative or unrealized connections among the strands of those information swirls are lost. Hypertext, by contrast, allows for “a body of written or pictorial material” to be “interconnected in such a complex way that it could not conveniently be presented or represented on paper” (<a href="#whitman1868">96</a>).</p>
<p>That hypertextual mind, I argue, is fundamental to those who write poetic sequences. Nelson may be understood to well account for that simultaneity of poems speaking to one another in complement, contrast and qualification in the title of his paper, “A File Structure for the Complex, The Changing and the Intermediate.” That provisional world variously ordered in either a literary work or a technical paper becomes yet more revealing when all possible content is proximately represented in a relevance score.</p>
<p>Hypertext as an idea rather than a technique in information relay implicitly acknowledges the modern topical indexing accomplished within a search engine. Search terms survey a collective sensibility. Search engines simultaneously offer assessment of the fit of our terms to particular internet resources. As the ideas of a literary work are executed in but one of many possible linear presentations, search terms similarly reveal the possible but not exhaustive components of any given inquiry. While the results of a search may be judged to be either spurious or helpful, we soon learn how to better locate that information, audio or video that prompted an inquiry. Our trial and error employment of the terms that may take us to internet topics may be understood as the theoretical framing we bring to understanding a literary work. If our search terms represent the theoretical framing we bring to any reading experience, then the relevance scores of our internet queries represent assessment of fit for a critical perspective.</p>
<p>I offer the analogies of internet searches and relevance scores to literary study to illustrate a different approach to interpretation enabled by the digital humanities. Regardless of the critical framing we bring either knowingly or naively to reading literature, we can assess the rightness of its application against the givenness of the word to word associational terrain fundamental to a literary work. In that capacity alone we may be saved from imposing a critical framing on a literary work. In complement to any exegetical program of interpretation is the empirical presence of words proximately represented. Open-source programming techniques in natural language processing, then, offer a boon to the reader who first wishes to proceed from the radical givenness of a text’s composition.</p>
<p>I pause over these now familiar wonders of search engine inquiry to illustrate the basic mechanics of latent semantic analysis (LSA). It developed as an information retrieval tool to index the relation of one term to another within a static dataset, like a literary corpus<a class="footnote-ref" href="#deerwester1990"> [deerwester1990] </a>. It has become a theory of knowledge acquisition for the human capacity to infer meaning by the context of usage<a class="footnote-ref" href="#landauer1997"> [landauer1997] </a>. In demonstrating that an LSA application could correctly supply the right answer to a multiple choice synonym test at a better-than-guessing rate, Landauer and Dumais offered two interpretations. The more conservative explanation is that the “contextual statistics of usage alone” (<a href="#landauer1997">211</a>) sufficiently enable a machine to make the appropriate choice. The more radical interpretation is that this inductive model of learning reveals “an important underlying mechanism of human cognition in general” (<a href="#landauer1997">212</a>). I follow that stronger argument in exploring the machine-aided complement to demonstrating the relation of one poem to another.</p>
<p>The <em>web</em> of the present study is comprised mainly by the word to word relations of <em>Poems</em> , as well as the largely absent “Calamus” sequence as Whitman realized it in the 1867 <em>Leaves.</em> That inter-edition resonance of influence may be understood ashypertextualto suggest a state of mind that returns readers to literary texts speaking to and against one another. It is anterior to critical response. Accordingly, I use LSA to index the radical givenness of terms within Whitman’s poetry.</p>
<p>LSA works by surveying the frequency of terms whittled down from words by root-stemming in order to approximate their cross-document senses in a static corpus. It is abag-of-wordsmethod because neither syntax nor part-of-speech is integral to the representation of content. Fundamental is the frequency of terms in the corpus as a whole, not only within individual documents. That corpus is assumed to model “a system of simultaneous equations that can determine the similarity of meaning of words and documents to each other” <a class="footnote-ref" href="#kulkarni2014"> [kulkarni2014] </a>, thus approximating shop talk or discourse.</p>
<p>LSA is only one approach in distributional semantics. However, whether the architecture employed represents a corpus by its term-to-term relatedness or from a window of its terms as does Hyperspace Analogue to Language (HAL)<a class="footnote-ref" href="#lund1996"> [lund1996] </a>, word count is formative. Context is indirectly established by a matrix formed by a survey of the words retained for analysis as those appear in a document by document indexing. Both HAL and LSA are <em>count</em> models<a class="footnote-ref" href="#mandera2017"> [mandera2017] </a>, or bag-of-word approaches in modeling meaning through a set of term to term co-occurrences. This approximation of sense-making Landauer and Dumais (<a href="#landauer1997">1997</a>) equated with the verbal conditioning that prompts learning by means of inference. One limitation of count models is that all information must be present before meaning can be represented in a series of statistical transformations that represent a corpus by only its most resonant terms. Syntax, however, never entirely weights a <em>count</em> representation.</p>
<p>Count and predict approaches each benefit the digital humanities. Selecting the appropriate representational method should hinge upon the purpose for bringing a set of texts together. If that collection of literary texts is assembled because novelty of trope is expected, then the count method of LSA makes sense, for the corpus itself argues against the value of predicting the likelihood of a term followed by another. By contrast, if the corpus were comprised, for example, to understand the nature of stylistic continuity between passages, then a predict model is the appropriate choice.</p>
<p>The count model approach is right for the present study because novelty of trope is instrumental in a poetic sequence. It is also appropriate toward understanding the sensibility of an author rather than its expression in particular works. The poems Rossetti excerpted from “Calamus” are identical to their <em>Leaves</em> presentation; regrouping and redacting the number of them were Rossetti’s most important editorial tasks. The central matter of the present study is tracking the possible resonance in sense between excluded and included “Calamus” content.</p>
<p>This study hinges upon the ideational, non-linear presence of words summoned to speak for the content of a literature meant for a new republic. Its emphasis is the numinous presence of words like <em>love, state</em> and <em>manly</em> rather than development within a field of expertise or the continuity of one draft of a novel with a later draft. Accordingly, I selected LSA to model the influence I sense in the entirety of “Calamus” being resonant within <em>Poems</em> and the excluded content found in <em>Leaves.</em></p>
<p>LSA emulates an inductive method of learning by two principles in cognitive psychology: 1) we understand a topic by a set of words, and 2) those associations are enriched, refined and schematized by further and even widely variant exposure to that topic. LSA, then, is both a method for statistically emulating induction and a theory of human learning<a class="footnote-ref" href="#landauer2007"> [landauer2007] </a>. It represents semantic sense in three steps. The first is by indexing the co-occurrence of terms within and between documents of a corpus. The second step of LSA employs a widely used factor reduction process known as singular value decomposition (SVD). This step multiplies a matrix of term values by those of the documents to produce ranked cross-products, or singular values. The greater the singular values of those cross-products, the more information each provides for the representation of a corpus. More concretely, those singular values in the present study represent the sensibility most central to Rossetti’s edition even as those poems are simultaneously influenced by the excluded “Calamus” content of <em>Leaves.</em></p>
<p>The final LSA step truncates the full representation of a set of documents to one that preserves its complexity but also eliminates noise. Each poem or section contributes to semantic space by its unique term to term relationality. Truncating dimensions, then, does not eliminate the full array of terms used to summon sense, for documents rather than terms are ranked by their singular values. This dimension reduction step eliminates not terms assigned to the row of a matrix, but the column-defined documents that address corpus wide tendencies. Because those columns are rank-ordered or orthogonal, the singular value as the cross-product of both documents and terms offers a way for less to say more. This dimension reduction step is precise enough that the original matrix can be recomposed. Truncation, then, may be understood as the decision at what decimal place to the right of the zero may be rounded up.</p>
<p>In the following research questions, I follow the distributed semantics of one poem considered in its similarity to another. I do so without hyperlinks per se, for that would require some personal set of files to have been constructed in advance of inquiry. However, I follow a hyperlinked sensibility in allowing the poems to speak to their relatedness in a common metric that can be readily employed within the digital humanities. Moreover, I do so without imposing any program to their relatedness. Rather, while entertaining a rhetoric of indirection, I simultaneously test a theory that “Calamus” is comprised by both lauds and cautions for those who would love bystandards not yet publish’d( “Paths” 6). Accordingly, I asked:</p>
<p>What is the within-group relatedness of “Calamus” poems included in <em>Poems?</em> How related are “Calamus” poems across editions?What is the relation of the “Calamus” content Rossetti sampled to “Elemental Drifts” in Rossetti’sWalt Whitmangroup?Does the excluded content show resonance with the evangel-poem “Starting from Paumanok” ?</p>
<h2 id="a-hypertextual-program-of-reading-the-calamus-sequence">A hypertextual program of reading the “Calamus” sequence</h2>
<p>I account for the importance of Rossetti’s <em>Poems</em> more truly representing the Whitman’s legacy than either Whitman or modern scholars grant by a hypertextual frame. That allows the 1867 Leaves to co-exist with Poems, even as “Live Oak, with Moss” may be understood to co-exist with “Calamus.” In that hypertextual field an author’s texts may speak simultaneously before they are ordered to represent the linear frame of an argument conducted within the bounds of any critical reading approach. Doing so implicitly derides the New Critical claim that a text is sufficient onto itself. I argue otherwise, especially in the case of <em>Poems</em> ’ troubling relation to the 1867 <em>Leaves</em> . Accordingly, I argue <em>Poems</em> reveals a greater sense of authorship than any of Whitman’s singular products of composition, whether those be found in a poem, sequence or book. The present study, then, courts the New Historicist allowance for the formative presence of extra-textual material, especially that of the “Calamus” poems excluded in Poems even while the 1867 “Calamus” has been completely erased by Rossetti’s alternative groupings. In that sense of authorship I necessarily call into question the power dynamics evident in dismissing Poems as the compromised, bowdlerized or sanitized Whitman.</p>
<p>To examine that hypertextual Whitman, I employ the open-source statistical platform R, which enables 10,000 distinct statistical operations, data handling and imaging techniques. In complement to two particular software packages, I used a freely available editor (Rstudio 2021) to process the text set, which I captured in poem and section divisions on an Excel spreadsheet. The <em>lsa</em> package allowed me to create a corpus comprised by the whole of <em>Poems</em> and the excluded “Calamus” content<a class="footnote-ref" href="#wild2020"> [wild2020] </a>. I also employed that package to aggregately score the similarity of one poem’s words against those from another poem. See Tables 2-4. That representation I could further pass on to the <em>LSAfun</em> package toward doing the passage to passage scoring featured in Tables 5-8<a class="footnote-ref" href="#guenther2015"> [guenther2015] </a>. That package also enabled me to examine the closest semantic neighbors of a word.</p>
<p>I found 111 poems or sections sharing the greatest semantic similarity indexed by stemmed terms comprising the whole of Poems and the excluded “Calamus” content. Those most generally applicable components of a text set retained for analysis are called dimensions. In general, an LSA best performs in a space of 200 to 500 dimensions, although an empirical survey of 49 studies found optimal factors from 6 to 1,000 dimensions<a class="footnote-ref" href="#bradford2008"> [bradford2008] </a>. Singular values &lt; .94 were effectively removed from the corpus representation by setting each to 0. This procedure highlights the underlying semantic structure of words. Those words that are most similar are shown to be proximate to one another “even if they never co-occur in a document,” while documents similarly benefit “even if they share no types (or words/terms) in common” <a class="footnote-ref" href="#martin2007"> [martin2007] </a>. This technique, then, removes the limitations of tracking lexile usage. The advantage of the share function in the present study is that the reduced set references the semantic space of the corpus by the largest poem/section-level tendencies and the entirety of the word-set that comprise it.</p>
<p>As reported in Table 1, I labeled each “Calamus” poem either as a laud or a caution for living out comradely love either in same-sex desire or in the service of a new republic. That designation I held to be provisional, for it springs from my own reading of “Calamus” as a poetic sequence granting that those who love will experience both a sense of wondrous revelation and resignation over lovers’ human limitations. I granted, too, at the outset that one poem may have elements of each sensibility motivating it. A <em>laud</em> I took to be celebratory of a lover’s progress through the difficult terrain of desire that can only be sensed at the periphery of those standards Whitman in “Paths” declared depart from “the pleasures, profits, conformities” (<a href="#whitman1868">4</a>) of social sanction. I considered a <em>caution</em> to be either a warning to those who would dare to love or an illustration of a hazard in love. However, Whitman troping his poems asherbagemay make each a laud in celebration of an authentic life, even while those same poems, or “body-leaves growing up above me above death” ( “Scented” 3), resound in caution.</p>
<p>I test that laudatory-cautionary distinction by the distributed relation of one word to another across both <em>Poems</em> and the “Calamus” sequence excluded from it. That distributed sense of one poem’s relation to another I annotate by the cognitive science fundamental to information retrieval<a class="footnote-ref" href="#deerwester1990"> [deerwester1990] </a>, disciplinary trends in language use<a class="footnote-ref" href="#kulkarni2014"> [kulkarni2014] </a>, and what mood or mind is operative within a discussion<a class="footnote-ref" href="#muthasima2019"> [muthasima2019] </a>. I do so first to demonstrate a method of reading that allows to literary texts to speak to one another, even while offering metrics that approximate the degree of similarity that may be found within and between groups of texts.</p>
<p>Such proximal indexing of a term within a poem and across others consequently allows us to follow the aggregated relation of all terms within a poem to another. That relation, or resonance, I track in the present study by reporting thecosineapproximation of relatedness. Most generally, a cosine may be interpreted as a correlation, which in the present study range continuously in strength from 0 to 1. Those correlations are more precisely stated as the “semantic distance between two vectors … given by the cosine of the angle between them” <a class="footnote-ref" href="#kintsch2014"> [kintsch2014] </a>. Accordingly, I report a degree of topical and thematic resonance between Whitman editions as the averaged cosine similarity of one passage to another<a class="footnote-ref" href="#guenther2016"> [guenther2016] </a>. Because cosine may be understood as a correlation, we can expect different statements of concept overlap. I consider the categorical predictor of “Calamus” content to be either included or excluded in Poems to be weak for a cosine of .10, while moderate is &gt; .30 and strong &gt; .50<a class="footnote-ref" href="#cohen1992"> [cohen1992] </a>.</p>
<p>All Whitman texts employed in the present study came from the 1867 <em>Leaves of Grass</em> and 1868 <em>Poems by Walt Whitman</em> archived on the Whitman archive maintained by the Center for Digital Research in the Humanities at the University of Nebraska, Lincoln. All pages cited conform to the eBook edition of <em>Poems</em> archived by the center. I cited excluded “Calamus” content by the line number of the center’s 1867 <em>Leaves</em> edition.</p>
<p>The more nuanced decisions came in deciding which texts supply a non- “Calamus” complement to examineCalamusphenomenality. I also considered what introductory sequence Rossetti admitted could possibly serve the naming function of what became “Song of Myself,” but what Whitman called in 1867 the “Walt Whitman” sequence.</p>
<p>“Calamus” bridges <em>Poems</em> and the 1867 <em>Leaves</em> . Accordingly, I used it to examine the within-group and between-group relatedness of its poems (Q1 and Q2). I partitioned the poems either by the laud or caution distinction earlier described. I further partitioned the text set by “Calamus” content included or excluded from <em>Poems.</em> I selected “Elemental Drifts” for two reasons to explore the resonance of “Calamus” content with an introductory poem Rossetti believed he could publish without having to go to court (Q3). First, it appears in Rossetti’sWalt Whitmancluster, where most of the “Calamus” he excerpted is contained. Second, “Elemental Drifts” is widely anthologized and so serves it as its own Whitman introduction to new readers. Finally, to examine the semantic resonance of “Calamus” content with another of Whitman’s origin poems (Q4), I selected “Starting from Paumanok” (SP). Grossman identifies what would becomeSPas “Proto-Leaf,” which introduces the 1860 <em>Leaves</em> <a class="footnote-ref" href="#grossman1990"> [grossman1990] </a>. Likewise, Rossetti allowed this “evangel-poem” to introduce <em>Poems.</em> Its mission to bring “comity by day and by night between all The States” (<a href="#whitman1868">73</a>) is present in the “Calamus” sequence as well. Grossman observed thatSPcelebrates the Union as “the evangel-poem of comrades” (<a href="#whitman1868">74</a>).</p>
<h2 id="results">Results</h2>
<p>Correlations in the Laudatory and Cautionary “Calamus” Content of <em>Poems</em> <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> 12345678Whoever.75.58.41.41.10.46.04.20Heaving.46.07.27.47.003.27.39.02Terrible.54.16.52.27.32.30.05.03DayNight.34.18.28.52.04.31.71.04Peruse.17.03.17.12.01.02.01.03Multi.06.02.17.05.03.10.01.01</p>
<h2 id="q1-what-is-the-within-group-relatedness-of-calamus-poems-included-in-poems">Q1: What is the within-group relatedness of “Calamus” poems included in Poems?</h2>
<p>Precisely because of the novelty of trope expected in a poetic sequence, few poems designated either as a laud or a caution resonate strongly in that distinction. Rather, some poems celebrate manly love while others caution its practice. That is clear in the poem to poem comparisons measured by the averaged correlations of cosine that comprise each poem. More toward illustrating a method in testing the caution-laud distinction in “Calamus” than toward arguing for its utility, I discuss the relationship of the cautionary “Whoever” to poems I take to be lauds for those who love others unconventionally or in service of a new republic. My primary point is this: Reader’s conclusions can be put to the test within that distributive semantics fundamental to either a count or predict approach. Any argument can then be assessed and reconsidered by the evidence of document to document and word to word phenomena.</p>
<p>In the cautionary “Whoever,” the speaker warns away a suitor. That intimate must complete an apprenticeship to be in relation with the speaker. Better that the suitor “Put [him] down and depart on [his] way” (<a href="#whitman1868">12</a>) than “give up all else” (<a href="#whitman1868">8</a>). In the laudatory “Record” that warning is not issued to a suitor, but to any who would love as does the speaker and understands the dread of an indifferent response from another. In “Stranger” the speaker returns to the direct address, but in possibly warning the stranger away from the fervor he or she may expect. While the speaker in “Whoever” grants the suitor may perhaps be worthy of his attention, the counterpart in “Sing” declares he is the only one worthy to praise the love of comrades. By contrast, a troop gathers around him in “Sing.” To that possibly worthy suitor in “Whoever,” the speaker names himself “the new husband” and “comrade” (<a href="#whitman1868">26</a>). That identity is most explicit in “Sing” at another pond-side, where “him that tenderly loves me, and returns again never to separate from me” (<a href="#whitman1868">19</a>) receives a calamus root as token from the speaker. In “ASong” that husband fathers “the most splendid race the sun ever shone upon/ … With the life-long love of comrades” (<a href="#whitman1868">2-3</a>). Those who remember Whitman as the husband of the few who dare to love as completely as he does and father to the many in “Record” should name him “the tenderest lover” (<a href="#whitman1868">3</a>). Although unacknowledged in “Stranger,” the speaker might have “surely lived a life of joy” (<a href="#whitman1868">3</a>) with another. Whitman again fancies himself as the husband who received “parting [as] the parting of dear friends” (<a href="#whitman1868">5</a>) in “Pen,” where he sees the embrace of two men on a pier. In “Full,” which concludes the “Calamus” sequence, the speaker is husband “to you yet unborn” (<a href="#whitman1868">4</a>). He can only fulfill that office by his poems. Yet, the “Calamus” speaker also grants a legacy of being misunderstood, as he does in “Whoever.” In “Pen” that speaker cautions that his subject matter is neither the majestic battleship nor “splendors of the past day” (<a href="#whitman1868">3</a>), but only that scene of two men parting as dear friends. His future readers, he grants in “Sing,” will find only what they need in his poems, while fewer still would receive calamus as their due. That husband-longing professed in “Record” reframes the speaker as one “Who was not proud of his songs, but of the measureless ocean of love within him” (<a href="#whitman1868">5</a>).</p>
<p>The caution-laud distinction, then, does not define a sub-genre for Whitman as much as provide poles by which a non-scripted love will be experienced by the wooer, the beloved and the society framing both. The non-scriptedness of expressing that love either for another man or in service of a more radically inclusive republic is a topic larger than either a cautionary or laudatory rhetoric. Whitman’s sometimes cautious, sometimes joyful negotiation of manly love returns us to the experience of reading a poetic sequence. The difficult, even damning terrain of loving both out of bounds and out of measure is recognized even within the same poem celebrating that adventure. Accordingly, while the way to that greater love in “Whoever” issuspiciousanduncertain,it rewards by revealing the new husband of a new republic. The “Calamus” content Rossetti selected for <em>Poems</em> qualifies the laud or caution theme defining each of the selections, for as was shown above, the decidedly cautionary “Whoever” strongly resonates with the exemplary laud found in “Sing.” In Table 3 reported below, I further test that laud-caution distinction in examining the lauds included and excluded from <em>Poems,</em> thus beginning to explore inter-edition resonance between <em>Poems</em> and <em>Leaves.</em> I next do so with poems I take to be cautionary (Table 4). Those annotations I offer in response to Q2. I continue that rippling-outward investigation to examine resonance in two other thematic groups identified by Rossetti toward answering Q3 and Q4. The first cluster, “Walt Whitman,” holds most of the “Calamus” content excerpted for <em>Poems.</em> The second cluster I examine is Rossetti’s “Chants Democratic,” which introduces his Whitman edition. I examine the first poem of that cluster, “Starting from Paumanok” (SP), in particular.<br>
Correlations of the Laudatory “Calamus” Included and Excluded in <em>Poems</em> 12345678910111213Sing.49.75.66.11.08.45.58.11.02.03.15.16.01Asong.46.51.33.09.15.44.38.32.10.09.04.28.03Record.16.45.24.17.19.40.78.05.01.04.01.09.01Stranger.29.49.31.03.03.16.39.08.06.03.05.10.02Yearn.15.08.24.09.01.02.12.01.01.10.09.20.01Pen.15.40.15.15.21.56.75.002.17.05.01.20.12Dreamed.01.04.06.02.04.14.21.05.004.004.01.001.01Full.37.07.22.01.01.02.11.01.01.004.012.001.01Correlations of the Laudatory “Calamus” Included and Excluded in <em>Poems</em> continued.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> 141516171819Sing.11.0416171819Asong.27.01.10.14.08.36Record.08.01.01.08.03.08Stranger.05.04.47.10.27.42Yearn.01.01.08.02.49.12Pen.03.03-.01.02.49.04Dreamed.004.01.02.01.01.35Full.004.01.02.01.01.02</p>
<h2 id="q2-how-related-are-calamus-poems-across-editions">Q2: How related are “Calamus” poems across editions?</h2>
<p>“Sing” and “Scented” (.75) most dramatically resonated in the laudatory “Calamus” content Rossetti included and excluded. Both poems are united in praise for lovers and in the speaker’s unique ability to issue that praise. More strongly at the level of trope, these poems advance through catalogues of the natural world tokens the speaker imparts to those whom he finds have joined him in approaching a liminal space defined as much by nature as desire. The leaves and roots of “Scented” are more directly troped as the pages of a book springing from the speaker that will yet be better regarded in the days to come. In “Sing” those leaves take many forms: lilac, pine branches, moss from a live-oak, laurel, maple, chestnut, wild orange and the calamus root, which is “the token of comrades” (<a href="#whitman1868">19</a>). These other tokens of the natural world the speaker dispenses as each follower needs and as he desires. He only reserves the “Calamus,” root “to them that love as I myself am capable of loving” (<a href="#whitman1868">28</a>).</p>
<p>The strongest thematic resonance between the poems is the poet commissioned to represent that love of comrades that will make possible a truly inclusive and fostering democracy. In “Scented” that commission is expected to enable “immortal reverberations through the States” (<a href="#whitman1868">25</a>) and will one day be seen when comrades can “dissipate this entire show of appearance” (<a href="#whitman1868">36</a>). That coming enlightenment is more immediately sensed in “Sing” as the troop that gathers around the speaker in his wildwood walkabouts. This troop comes to take on the presence of a cloud of witnesses ( <em>Hebrews</em> 12:1) because it is comprised by “dear friends dead or alive” (<a href="#whitman1868">13</a>). These friends surround the speaker, at once commissioning him and in need of the tokens he dispenses. The poems are also joined in their strong resonance with other poems in the “Calamus” sequence. Of the 16 that may be understood to be laudatory, two are strongly resonant ( “RootsLeaves” and “Louisiana” ) in comparison to “Sing,” while three others demonstrate moderate resonance between aggregate cosine relations between .25 and .49. “Scented” resonates strongly with one of the laudatory poems Rossetti included in <em>Poems,</em> while moderately so with three others. The near-zero correspondences of “Calamus” content occur most generally in the briefest poems (e.g., “Full” and “Prairie” ).</p>
<p>I considered the moderate resonance of “Full” with “Paths” (.38). This final poem of “Calamus” proposes that the Whitman who was once 40 years old in 1859, then visible in public and as a poet of these States, would beinvisiblewhen the imagined reader finds his poems a century or more later. That second life for Whitman is in the reader’s imagination, “Fancying how happy you were if I could be with you” (<a href="#whitman1868">8</a>). The complement for the first poem of the sequence comes also in 1859, as the speaker is “Bequeathing hence types of athletic love” (<a href="#whitman1868">14</a>). In establishing the project of the “Calamus” sequence and in anticipation of the imagined reader finding it one day, the speaker “Proceed[s] for all who are or have been young men,/To tell the secret of my nights and days,/To celebrate the need of comrades” (<a href="#whitman1868">16-18</a>). That moderate resonance between its place as a laud for a comradely literature that Rossetti included in <em>Poems,</em>  “Full” bears no greater relation to the excluded, far more overtly amorous content of “Calamus.”<br>
Correlations of the Cautionary “Calamus” Content Included and Excluded in <em>Poems</em> NewPersonTrickleFrailestEarthSometimesWesternWhoever.28.18.03.04.19.12Heaving.09.03.01.01.09.01Terrible.03.05.01.08.01.06DayNight.03.02.01.02.03.02Peruse.02.01.01.01.01.01Multi.01.01.01.01.01.02<br>
In these poems that might all be considered cautionary, there is at best only near moderate resonance. “Whoever” provides exempla of that point in its various ways of figuring caution. Its speaker cautions that he is not what a suitor supposes, for the way to meet him is at best uncertain and even destructive. That suitor would have to become a novitiate in order for the speaker to becomeyour sole and exclusive standard(<a href="#whitman1868">8</a>), that requiring the suitor to abandon “The whole past theory of [his] life and all conformity to the lives around [him]” (<a href="#whitman1868">10</a>). Because the courtship would require so much, the speaker warns away the suitor, unless he is willing to seek him “by stealth in some wood for trial” (<a href="#whitman1868">11</a>). Only in the marginal spaces of “Paths” will the suitor find the speaker as “the new husband” or “comrade” (<a href="#whitman1868">21</a>). The peril of approaching the Beloved is equal to that of reading his poems. Those poems, moreover, are evasive, “for it is not for what I put into it that I have written this book” (<a href="#whitman1868">32</a>).</p>
<p>Of all the poems that may be considered cautionary in the sequence, “NewPerson” is the most resonant with “Whoever” (.28). That relation is weakly moderate, but is best underscored by warning a suitor against his suppositions. To press that point, the speaker of “NewPerson” asks the suitor if he believes friendship to be an “unalloy’d satisfaction” (<a href="#whitman1868">5</a>). That metallurgical framing of friendship suggests an unlikely but marvelous union of materials. In “New Person” those are suggested by regard for trust, fidelity and heroism, all of which the speaker offers as instances ofmaya,or illusion. That difficult union in “Trickle” is troped by the wounds the speaker receives “made to free you whence you were prison’d” (<a href="#whitman1868">4</a>). Those wounds also attend the confessional, sacrificial sense of authorship summoned in “Whoever,” for they “Stain every page, stain every song I sing, every word I say” (<a href="#whitman1868">8</a>). Yet, because the caution voiced in each poem is so differently troped, there is only a weak correlative resonance (.18).</p>
<p>That capacity of the trope to level thematic resonance is clearly demonstrated in the near zero correlations ofMultiwith the cautionary “Calamus” content Rossetti excluded from <em>Poems.</em>  “Multi” congratulates the suitor for identifying the speaker bysecret and divine signs(<a href="#whitman1868">2</a>), even as the poem cautions that recognition of a comrade can only proceed by such “faint indirections” (<a href="#whitman1868">6</a>). The obstacle in recognition catalogued by “NewPerson” is expecting a more socially scripted, idealistic relationship. Common to both poems is the speaker acknowledging the interest of another at the cost of prioritizing the Beloved above all others. Yet, because the poems so differently address courtship and even recognition by another, they bear almost no measurable relation (.03).</p>
<h2 id="q3-what-is-the-relation-of-the-calamus-content-rossetti-sampled-to-elemental-drifts-in-rossettis-walt-whitman-group">Q3: What is the relation of the “Calamus” content Rossetti sampled to “Elemental Drifts” in Rossetti’s “Walt Whitman” group?</h2>
<p>Resonance of “Calamus” and “Ebb’d” Part 1Ebb’dPathsUntroddenScentedHerbageRootsLeavesBehold <em>1 — her castaways</em>  <em>for all who are, or men have been, young men</em> the <em>many passing by</em>  <em>Scents brought to men and women from the wild woods</em>  <em>a Manhattanese</em>  <em>2 — hoarse and sibilant</em>  <em>the Soul of the man I speak for</em>  <em>immortal reverberations through the States</em> To hear the sibyl one must nourish love.The poet as sibyl, drawing only those who ready to hear. <em>3 — seized by the spirit</em>  <em>the soul of man I speak for rejoices in comrades</em>  <em>O slender leaves! O blossoms of my blood!</em> The prompt to wander wild-woodsA robust kiss <em>4 — likenesses</em>  <em>the life that exhibits itself</em>  <em>That you hide in these shifting forms of life</em> Poems as roots reaching into the readerNonchalance dramatized in a kiss offered and returnedAverage cosine.40.53.55.31<br>
As I followed the resonance of “Calamus” into “Ebb’d,” in Rossetti’s “Walt Whitman” cluster, I selected passages from the first two sections of “Ebb’d” I thought might have counterparts in the “Calamus” content. I also shifted my analysis from looking at the thematic resonance of entire poems to passages I sensed following a rhetoric of disclosure modeled by portions of “Ebb’d” andSP.In common for Tables 5-8, I first briefly outline the structure of those non- “Calamus” poems Rossetti selected. I then examine their counterparts to the “Calamus” excluded in <em>Poems</em> and so note that thematic continuity if I could identify it. I italicize those structural counterparts when suggested by the very language Whitman employed. In Table 5, I could find “Ebb’d” counterparts in four “Calamus” poems excluded from <em>Poems,</em> but did not find the “Ebb’d” structure of part 2 as uniformly resonant with “Calamus” content examined in Table 6. In measuring the similarity I detected, I gathered passages in the “Calamus” content I found resonant with the non- “Calamus” content. That resulted in the final row of Tables 5-8, in which I report the aggregated cosine of that multi-passage similarity for each “Calamus” poem in relation to either “Ebb’d” orSPpassages. All passage to passage comparisons were either moderate or strong in magnitude. Those far more consistently stable statements of thematic resonance resulted from the tighter focus each demanded. While the poem to poem comparisons reported in Tables 2-4 are useful in globally examining the laud-caution tendency I find in “Calamus,” the passage-driven analysis of Tables 5-8 forced me to identify precisely how I found excluded “Calamus” content to be in dialogue with material in <em>Poems.</em></p>
<p>Thecastawaysin “Edd’d” trope all who wander, have wandered and will wander the beach. While Paumanok is a birth site for Whitman who hears a “fierce old mother” in the surf and embraces a father in the sand, Paumanok is more urgently an elemental site of creation. The castaways of “Edd’d” then may also be found in the young and old men whom Whitman addresses in “Paths” as much as in the “many passing by” (<a href="#whitman1868">6</a>) the poems Whitman tropes as scented herbage, the scents of foliage brought to those wandering the wild-wood, or the Manhattanese come with a robust kiss for the “Swarthy” speaker. Thesibilantsurf of “Ebb’d” summons the standards published and unpublished of “Paths.” In “Scented” the speaker offers sibilant utterances in thoseimmortal reverberations through the States(<a href="#whitman1868">25</a>). That revealing spirit requires sympathetic magic, if not also sacrifice, in “RootsLeaves” as its speaker promises the reader that love-buds will open “If you bring the warmth of the sun to them” (<a href="#whitman1868">9</a>). In “Behold” the Whitman speaker performs the sibilant function by drawing to him only those worthy in their nonchalance. The spirit seizing the speaker of “Ebb’d” may also be understood, alternately, as the soul rejoicing in comrades in “Paths,” while the spirit most manifestly reveals itself in the poems of “Scented” speaker. Spirit seizure prompts a robust kiss in “Behold,” while in “RootsLeaves” it is sensed in the walkabouts of wild places. At Paumanok Whitman findslikenessesof himself strewn on the beach. In “Paths” those likenesses are resonant with standards exhibiting themselves as much in the drawing room as in “the margins of pond-waters.” The “Scented” speaker finds likeness itself blurring the boundaries between life and death, while Whitman’s catalogue of woodland wonders in “RootsLeaves” are likened to poems exhorting love for the reader “whoever you are” (<a href="#whitman1868">7</a>). Nonchalance is likened to the urge to bestow and return a kiss between comrades in “Behold.”<br>
Resonance of “Calamus” and “Ebb’d” Part 2 in Rossetti’s <em>Walt Whitman</em> Group<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> Ebb’d 2PathsUntroddenScentedHerbageRootsLeavesLouisiana1 — I know notWriting to know, if only in retrospectKnowledge only comes in time and practice2 — the dirge, the voices of men and women wreck’sthe speaker escaping <em>the clank of the world</em> The dirge heard in recognition of death inseparably entwined with lifeMen and women sufficiently dissatisfied with the conventional world to seek authenticity in the natural3 — merge myself <em>the margins of pond-waters</em> Immersion within poems both bitter and beautifulA woodland walkThe poet as a live-oak4 — the real Me stands yet untouch’d <em>Unpublished standards</em> The authentic self is that behind <em>the mask of materials</em> 5 — have not really understood anythingThat <em>real reality</em> hidden among <em>forms of life</em> The poet disavowing the utility of his own tropeAverage cosine.33.70.32.33<br>
The speaker of “Ebb’d” is less a spokesperson for Everyman than Just Another Person as seemingly strewn and randomly assembled in the detritus washed ashore. That speaker makes no qualification for his ignorance at the start of the second section. His not-knowing is that of other men and women deposited on shore by the surf mother of whom they did not ask to be born. His oppression is daring to speak sense to his condition; more so to ours: “before all my arrogant poems the real Me stands yet untouch’d, untold, altogether unreach’d” (<a href="#whitman1868">28</a>). That abashed humility finds counterpart in the “Scented” speaker who writes “to be perused best afterwards” as much by his readers as himself. The “RootsLeaves” speaker claims time and practice precede knowledge, for the intuited revelation of a poem is only seed material for that greater to come. Thedirgethe “Scented” speaker enjoins comes in recognition of our common end as both bitter and beautiful. InRootsLeavesthat dirge is the dissatisfaction with the conventional world that prompts men and women to wander in wild spaces. In “Louisiana” the speaker again senses himself in another natural world wonder: a solitary live-oak “rude, unbending, lusty” (<a href="#whitman1868">4</a>). He, then, disavows the trope because he could not prosper as solitarily since he thinks of “little else” (<a href="#whitman1868">9</a>) than of friends. That unknown, authentic self of “Ebb’d” seeks the unpublished standards in “Paths.” Death hiding “in these shifting forms of life” in “Scented” does so for its own reasons beyond what the speaker can sense in other than the material world obscuring “the real reality” (<a href="#whitman1868">33</a>).</p>
<p>The thematic resonance above identified brings evidence for the possibility that the excluded “Calamus” content is more largely at play in <em>Poems</em> than has been previously acknowledged. However, that resonance indexed by the aggregate cosine relations of one poem to another simultaneously illustrates that the thematic resonance suggested by words’ distributional sense may and may not find complement between poems. The self-confessed ignorance in “Ebb’d” only speaks in part to the confidence of a speaker dismissing some standards but affirming others in “Paths” or proposing a trope for himself in “Louisiana” and then resolving the poem by dismissing it.</p>
<h2 id="q4-does-the-excluded-content-show-resonance-with-the-evangel-poem-starting-from-paumanok-">Q4: Does the excluded content show resonance with the evangel-poem “Starting from Paumanok” ?</h2>
<p>In the commentary below, I annotate hypertextual inquiry in responding to poem excerpts and ideas reported in Table 8. I wanted to know if “Calamus” content is resonant in the non- “Calamus” poems Rossetti assembled to represent Whitman to a UK Victorian audience. I selected “Starting from Paumanok” (SP) because the sequence had always provided for Whitman a prelude-like purpose: <em>from these origins I proceed because I was formed to do so.</em> The sequence also serves as a proxy for another prelude poem, the “Song of Myself” sequence Rossetti chose neither to excerpt nor include in whole. In particular, I wanted to know if the excluded “Calamus” content was resonant with the poetics presented inSP.</p>
<p>While I could have more exhaustively catalogued such passage to passage resonance, I opted to look at only thoseSPpassages I found to be thematically present. Accordingly, I confine my annotation toSP7of <em>Poems,</em> which, as reported in Table 8, is either moderately or strongly semantically resonant with the content from four “Calamus” poems Rossetti excluded. While the cosine similarity score reported refers to the entire set of words’ relationality from one passage to another, I reported the textual prompts I found thematically resonant.</p>
<p>In the frame of “Calamus” content, I find four components realized inSP7:</p>
<p>An orienting poetic sprung from the natural world: <em>I will make poems of materials</em> Stating subject matter: <em>I will sing the song of companionship</em> Consequents for that decision: <em>I will therefore let flame from the burning fires that were threatening to consume me</em> Statement of commission: <em>And who but I should be the poet of comrades?</em></p>
<p>Correlations of “Starting from Paumanok, 7” and Excluded “Calamus” ContentSP7 componentPathsScentedRootsLeavesBehold1In the growth by <em>margins</em> of pond-watersHerbage, roots, leaves <em>Breast-Sorrel, pinks of love, fingers</em> Swarthy face, these gray eyes2Joy in comrades <em>I write, to be perused best afterwards</em>  <em>Scents brought to men and women</em>  <em>Comes one of Manhattanese</em> 3 <em>No longer abash’d</em>  <em>I will say what I have to say by itself</em>  <em>Give a kiss in return</em> 4 <em>Manly attachment</em>  <em>Sound myself and comrades only</em>  <em>Love-buds put before you</em>  <em>American comrades land and sea</em> Average cosine.47.82.46.41<br>
The poems found within the excluded “Calamus” content reported in Table 7 entirely spring from natural world settings. That may be done to naturalize or license the prohibited content of the same-sex love that may be only indirectly named in <em>Poems.</em> Perhaps, too, the settings resonate with the larger Romantic sensibility of turning toward the natural world as a site of authenticity. More certain is this:SP7demonstrates either a high moderate or strong resonance with this group of “Calamus” poems. In all of the poems, the speaker identifies Nature as the spiritualized complement of human love. Further, each of the speakers are declaratively bold for manly love and camaraderie. Each speaker, moreover, can be identified as a moral spokesman. In “Paths” the speaker is concerned for the standard of a fostering companionship that can feed a soul. The false standards of “pleasures, profits, conformities” (<a href="#whitman1868">4</a>) in “Paths” havelong enough stifled and choked(<a href="#whitman1868">51</a>) the “Scented” speaker. The common motivation of seeking companionship enfolds men and women in “RootsLeaves,” as well as “young persons wandering out in the fields when winter breaks up” (<a href="#whitman1868">6</a>). The “Calamus” poems become “Love-buds put before you and within you whoever you are” (<a href="#whitman1868">7</a>). That community united by the need for companionship fosters love in “Behold,” whose speaker returns the kiss of a Manhattanese and allows it to become “natural and nonchalant” (<a href="#whitman1868">7</a>). Companionship is so central of a standard in “Louisiana” that its speaker confesses that he thinks oflittle elsethan hisdear friends(<a href="#whitman1868">8-9</a>).</p>
<p>The template or form of “Calamus” resonance I found apparent inSP7is the structure of resonance suggested only by that section. That suggested bySP13takes own on its own rhetorical pattern and within the same magnitude of resonance found inSP7:</p>
<p>A figure of democracy summonedWhitman insisting that this figure sings for allPoems spring from “whatever adheres and goes forward” (<a href="#whitman1868">163</a>) “The bard of personality” (<a href="#whitman1868">164</a>) will declare all worthy and equal, even while unifying our perceptions of separationAll poems and all things reference the soul</p>
<p>Correlations of “Starting from Paumanok, 13” and Excluded “Calamus” ContentSP13 componentPathsUntroddenScentedHerbageRootsLeavesBeholdSwarthy1 <em>for all who are, or men have been, young men</em> Death as the great leveler, <em>the real reality</em>  <em>American comrades</em> 2 <em>the Soul of the man I speak for</em>  <em>an example to lovers</em> an <em>I</em> who can return a kiss <em>in the public room, or on the crossing of the street, or on the ship’s deck</em> 3 <em>Bequeathing, hence, types of athletic love</em> Herbage as poems <em>to be perused afterwards;</em> death and love are the perennial subjects of lovers <em>If you become the aliment and the wet,</em> [roots and leaves] <em>will become flowers, fruits, tall branches and trees.</em> Nonchalance4the universal <em>you</em> as object of addressThe speaker’s use of <em>we</em> 5Standards offered and reformed to feed the soulthat soul aware of death ascending even to <em>the atmosphere of lovers</em> Average cosine.44.74.47.26<br>
These poems excluded from <em>Poems</em> resonate within the rhetorical pattern ofSP13.Rather than invoke a Ma Femme figure of democracy in these poems, Whitman implies he is such a speaker. The subjects of these poems — young and old men, the men and women who go a-Maying, American comrades — number among Ma Femme’s “brood beyond us and of us” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>. Death is the personified counterpart to Ma Femme in “Scented,” or thereal realityawaiting all behind the masks we employ to be perceived (<a href="#whitman1868">33</a>). However, Death is addressed rather than addresses in “Scented.” Whitman’s various poem-level speakers serve as proxies to Ma Femme in this group of poems. The commonality of her brood Whitman finds in our moral condition of lovers’ mixed desires to increase and be relieved from passion ( “Scented” ), and in what should one day be a commonplace exchange of intimacy in the giving and return of a kiss. Thewhat goes forwardof these poems is thatathletic love(<a href="#whitman1868">14</a>), the tendency of all poems to be understood best in retrospect ( “Scented” ), the generative imperative seen in plant life and sensed in love, and the nonchalance of all enabled to express that love ( “Behold” ).</p>
<p>The two rhetorical patterns discussed reveal strengths and weaknesses of the associative reading method punctuated by similarity scoring. First, any pattern is an inference that may or may not fit the sound and sense of a poem. Second, that intuitive sense of fit I came to only by the strength of semantic resonance underscored by similarity scoring. In both Whitman editions considered for the present study, “Calamus” content followsSP.Yet, in asking after the foundational place for the “Calamus” content in Whitman’s work, I had to scroll up on a monitor and turn back pages from the “Calamus” poems to examine their resonance inSP.The structural patterns of Whitman’s evangel-poem preceding even “Song of Myself” simply offer possible expressions of similar content, even while suggesting the merit of a poetic sequence. The four poems excluded from <em>Poems</em> exist in dialogue with one another, by Whitman’s arrangement in the 1860 <em>Leaves of Grass</em> , as much as do the 20 components ofSP.</p>
<h2 id="discussion">Discussion</h2>
<p>This study refused to remain that of an almost quaintly removed drama of a self-styled, self-taught 19th century American poet trying to secure a British readership through a sympathetic critic, editor and advocate. In reviewing the similar concerns — and sticking points — for commentators removed from one another by more than 150 years, I sensed the present relevance of <em>Poems</em> as a study in authorship aided by reception and collaboration.</p>
<p>The author I sensed strode between the very different 1867 <em>Leaves</em> and <em>Poems</em> on two broad pathways. The first is his unconditional egalitarianism; the second is by daring and confessing to the hardships of loving others unrequited. That difficult love perhaps most poignantly surveyed resides in “Calamus.” The love-longings Whitman knew for both his “own dear friends” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>and an adoring reading constituency “escaped … from the pleasures, profits, conformities,/Which too long I was offering to feed my soul” <a class="footnote-ref" href="#whitman1868"> [whitman1868] </a>. He confessed this unrequited love in his career-long wooing of an audience he wished would grant him license him to speak and be read beyond his own span of days. The authorship he desired, however, had to be granted by others.</p>
<p>In his longing for acknowledgment and desire to speak authentically, Whitman keeps company with a radically different, internationally-received and yet equally idealistic Salman Rushdie reflecting on <em>The Satanic Verses</em> (1989). Despite the novelty and importance of their respective projects, each was stymied by the same narrowly moralistic reception that all but throttled authors set apart by a century. In retrospect, telling the story of the life in hiding he bore with the name Joseph Anton, Rushdie came to understand that his troubling and breakthrough novel possessed its own life story:</p>
<blockquote>
<p>When a book leaves its author’s desk it changes. Even before anyone has read it, before<br>
eyes other than its creator’s have looked upon a single phrase, it is irretrievably altered. It<br>
has become <em>a book that can be read,</em> that no longer belongs to its maker. … It will make<br>
its journey through the world and there is no longer anything the author can do about it.<br>
… The book has gone out into the world and the world has remade it<br>
<a class="footnote-ref" href="#rushdie2012"> [rushdie2012] </a>.<br>
That seeming agency of a literary creation, and certainly that of its readers, troubled Whitman from <em>Poems</em> forward. On his deathbed, Whitman eagerly awaited the fourth slimmer volume of <em>Leaves</em> that each of his editors promised would entice and prepare readers for his accretive, ever growing life work published in nine editions from 1855 to 1892. Folsom (1991) recounted how Whitman wanted to call the last sampling selected by Edmund Clarence Stedman’s son, Arthur, <em>Leaves, Junior</em> in ironic resignation to a literary culture dominated by anthologies and textbooks.</p>
</blockquote>
<p>I follow a reception-aided component of authorship into our present hypertextual age. As Rushdie found, <em>Satanic Verses</em> had become became radically separate texts for those who would silence it as heretical and for those who would defend it as an exemplar of free thought advanced in an open society. <em>Leaves</em> as a literary work cannot be understood apart from its various value-laden receptions. While it can be found in various complete editions surveying its development from 1855 to 1892, it also is partitioned in editions of “Calamus” generally faithful to the clusters Whitman oversaw. Simultaneously, “Calamus” annotates and is annotated by a group of contemporary photographers whose common subject matter is manly love<a class="footnote-ref" href="#groff1996"> [groff1996] </a>. Perhaps equally unanticipated by Whitman is the present availability of <em>Walt Whitman’s Whisper: 36 Sex Poems</em> <a class="footnote-ref" href="#whitman2017"> [whitman2017] </a>, which brings together the most explicit material from “Calamus” and “Children of Adam.” Indeed, <em>Leaves</em> has tracked vistas Whitman could only distantly imagine in a future Manhattan, where only “the frequent and swift flash of eyes offering me love” couldrepayhim for his candor<a class="footnote-ref" href="#whitman2017"> [whitman2017] </a>.</p>
<p>I offer the termshypertextandresonancefor another age of reception in which<a class="footnote-ref" href="#greenblatt2005"> [greenblatt2005] </a>observed an inadequacy of descriptives in literary criticism for a way of speaking to the intersection of art and history. Hypertext, that digital device often shaded in blue, disrupts linearity and underscores the intertextuality that Nelson (<a href="#nelson1965">1965</a>) identified in composition. <em>Resonance</em> approximates the relatedness of texts grouped by rhetorical function. However, the relationality I sense among poems represents but a figure of the zodiac made visible not only by the proximity of starry points in the universe of texts of assembled, but also by their dynamic gravitational interactions. Other zodiac formations are surely present.</p>
<p>Any set of corresponding passages may be indexed within the researcher’s concerns by the field of associations believed to be most germane to the constitution of those passages. Because I focused on the selected Whitman that Rossetti presented to a Victorian readership, I restricted the semantic field under consideration to <em>Poems</em> and the 29 poems of “Calamus” excluded. However, if I had asked how germane was <em>Poems</em> to the assemblage of subsequent Whitman editions, then that semantic field would have been radically different, as would each of the proximal weights a term possesses in its relation to other terms. The passage to passage correspondences I report uniformly exist as but singular expressions of a semantic relatedness only within <em>Poem’s</em> space. Accordingly, those statements of greater and lesser resonance can also be understood ashyperlinksthat at once disrupt and enrich a particularly orchestrated reading experience.</p>
<p>The Whitman Archive, curiously, prompts a hypertextual sensibility because its print predecessor imprints the e-edition posted by the Center. The structural trope of book structure argues for its status as a self-contained object<a class="footnote-ref" href="#earhart2012"> [earhart2012] </a>, however proximate are other self-contained entities of e-book editions. Despite all of its archival duty to Whitman’s original print editions, the more dynamic sense ofhypertextthe reader must provide. It is the same that Whitman himself experienced in his various histories as the author of “Live Oak, with Moss,”  “Calamus” and the 1855 <em>Leaves.</em></p>
<p>In tracing the evolution of the computer understood only to relieve humans of the drudgework of thinking to opening up a new sort of thinking in the humanities, McCarty (<a href="#mccarty2012">2012</a>) proposes that the most important question before us is how we can benefit the public imagination with a focus on literature akin to employing telescopes in surveying the heavens. The justification of our work is, then, is how we can contribute to the well-being of a citizenry. Examining the rich semantic dialogue between editions produces its own meta-edition of that enriched encounter that exists outside of thinking of authors as masterminds behind particular print editions. It invites dialogue with present readers, who ultimately can test their guiding assumptions within the radically descriptive terrain of literary texts of interest.</p>
<p>Hypertext is a reader response strategy to the extent it engages with concerns greater than a single reader’s experience with a text. Hypertext, in spirit, delimits and makes possible the interpretive community to which a critical interpretation appeals. However, annotating the mere presence of textual dynamics is only the precursor for making an argument for the utility of doing so. Regardless of the inherent properties deemed to be at work in a literary text, I grant that readers create readerly texts, or opportunities, to comment on those matters prompting interest after Fish (<a href="#fish1980">1980</a>), who I first knew as a Miltonist aware of the various interpretive camps in dialogue with one another through the ages (<a href="#fish1971">1971</a>). That reader-centered text-making I certainly employed by following the literary rationale of a poetic sequence identified within and between Whitman editions.</p>
<p>The hazard of any readerly writing of a literary text realized in interpretation is researcher’s bias, or seeing what we wish to see based on the expectations of inquiry. I argue that the distributed sense attending word usage brings a necessary check to researcher’s bias in its extra-human capacity to index the text created for interpretation, even if the text prompting interpretation springs from one that any reader can encounter — regardless of who reads it and for what purposes. It restores to texts their statuses as objects in the world, however much each is a puzzle to which only the individual reader can respond and however each reader responds as a member of an interpretive community. This much should ease reception of those who believe the physical text of a poem is sacrosanct<a class="footnote-ref" href="#greethan2012"> [greethan2012] </a>. So does the digital humanist in recognizing the plethora of texts so often available. The danger inherent to reading hypertextually is that which attends any method: insisting that the marvel I see is more urgent than those others have seen. I can write whatevertextI wish to see in the star field of word to word associations revealed by cosines. Simultaneously, and to my credit as a reader-researcher, I must follow that associative rationale into the very theory or discourse I believe constitutes the marvels I sense.</p>
<p>The largest stake of the present study is demonstrating a method that permits literary texts to speak within their own assembled star fields of meaning without insisting that they speak only as prescribed by an interpretive community. In that charge I put my understanding of literary indirection to the test. Whitman’s lauds and cautions in the “Calamus” sequence are as likely to motivate some poems as they are to exclusively define the lyricism of others. More important than those mechanics of presentation, however, is the terrain mapped by the word to word proximal semantics. Despite Rossetti excluding most of the “Calamus” sequence, its sometimes laudatory, sometimes cautious take on manly love pervades <em>Poems,</em> if only in the permissible sense of the love of comrades underlying the radical inclusion Whitman expected would be foundational to a new republic. <em>Poems</em> , then, succeeded in “offering the first sample tolerably fair chance [Whitman] has had of making his way with English readers on his own showing” 13 years after Rossetti learned of the 1855 <em>Leaves</em> <a class="footnote-ref" href="#rossetti1868"> [rossetti1868] </a>. It presently succeeds in pointing toward a Whitman larger than a particular edition of his poems. Through <em>Poems</em> I find both the tireless speaker for democratic inclusion and a speaker, at times, exhausted by the indirection required to woo the Beloved.</p>
<ul>
<li id="allen1955">Allen, Gay Wilson (1955). _The solitary singer: A critical biography of Walt Whitman._ New York: Macmillan.
</li>
<li id="anonymous2002">Anonymous review in Brooklyn Daily Times (29 September 1855). 2002. “Leaves of Grass: A volume of poems just published.” In M. Moon (Ed.), _Leaves of Grass and Other Writings_ (793-795). New York: NY: Norton.
</li>
<li id="barney2007">Barney, Brett, Gailey, Amanda, Genoways, Ted, Green, Charles, Morton, Heather, Price, Kenneth M., and Renfro Yelizaveta (2007). “Sixty-Eight Previously Uncollected Reviews of Walt Whitman.”  _Walt Whitman Quarterly Review, 25,_ 1-76.
</li>
<li id="bergman1991">Bergman, David (1991). _Gaiety transfigured: Gay self-representation in American literature_ . Madison, WI: University of Wisconsin Press.
</li>
<li id="bowdler2009">Bowdler, Thomas (2009). _The family Shakespeare: In which nothing is added to the original text, but those words and expression are omitted which cannot with propriety be read in a family._ Cambridge: Cambridge University Press.
</li>
<li id="bradford2008">Bradford, Roger B. (2008). “An empirical study of required dimensionality for large-scale latent semantic indexing applications.” In _Proceeding of the 17 the ACM Conference on Information and Knowledge Management._ New York: 153-162.
</li>
<li id="burroughs1867">Burroughs, John (1867/1971). _Notes on Walt Whitman as Poet and Person._ New York, Haskell House Publishers.
</li>
<li id="cocks2001">Cocks, Harry (2001). “Calamus in Bolton: Spirituality and homosexual desire in late Victorian England.”  Gender & History, 13, 191-224.
</li>
<li id="cohen1992">Cohen, Jacob (1992). “A power primer,”  _Psychological Bulletin_ , 112 , 155-159.
</li>
<li id="collins2017">Collins, Sarah (2017). “Nationalisms, modernisms and masculinities: Strategies of displacement in Vaughan Williams’s reading of Walt Whitman.”  _Nineteenth-Century Music Review_ 14, 65-91.
</li>
<li id="deerwester1990">Deerwester, Scott, Dumais, Susan, Furnas, George, Landauer, Thomas, and Harshman, Richard (1990). “Indexing by latent semantic analysis,”  _Journal of the American Society for Information Science. 41_ (6), 391–407.
</li>
<li id="earhart2012">Earhart, Amy E. (2012). “The Digital Edition and the Digital Humanities.”  _Textual Cultures, 7,_ 18-28.
</li>
<li id="erkkila1989">Erkkila, Betsy (1989). _Whitman the political poet._ New York: Oxford University Press.
</li>
<li id="fern2002">Fern, Fanny (2002). “Fresh Fern Leaves: _Leaves of Grass._ ” Review in _New York Ledger_ (10 May, 1856). In M. Moon (Ed.), _Leaves of Grass and Other Writings_ (795-797). New York: Norton.
</li>
<li id="fish1980">Fish, Stanley Eugene (1980). _Is there a text in this class? The authority of interpretive communities_ . Cambridge, MA: Harvard University Press.
</li>
<li id="fish1971">Fish, Stanley Eugene, and Milton, John (1971). _Surprised by sin: The reader in ‘Paradise Lost._ ’ Berkeley, CA: University of California Press.
</li>
<li id="folsom1991">Folsom, Edward (1991). “Leaves of Grass, junior: Whitman’s compromise with discriminating tastes.”  _American Literature_ , 63(4), 641–663.<a href="https://doi.org/10.2307/2926872">https://doi.org/10.2307/2926872</a>
</li>
<li id="gilchrist2002">Gilchrist, Anne 2002. “An Englishwoman’s estimate of Walt Whitman.” In M. Moon (Ed.), _Leaves of Grass and Other Writings_ (802-806). New York: NY: Norton.
</li>
<li id="greenblatt2005">Greenblatt, Stephen (2005). “Towards a poetics of culture.” In Michael Payne (Ed.) _The Greenblatt Reader_ , Hoboken, NJ: Blackwell Publishing, 18-29.
</li>
<li id="greethan2012">Greethan, David (2012). “Chapter 25: The Resistance to Digital Humanities | David Greetham” in _Debates in the Digital Humanities_ on Debates in the DH Manifold (cuny.edu)
</li>
<li id="grossman1990">Grossman, Jay (1990). “`The evangel-poem of comrades and of love’: Revising Whitman’s republicanism.”  _American Transcendental Quarterly_ , 4, 201-218.
</li>
<li id="guenther2015">Güenther, Fritz, Dudschig, Carolin, and Kaup, Barbara (2015). “LSAfun: an R package for computations based on latent semantic analysis.”  _Behavior Research Methods, 47_ , 930- 44.
</li>
<li id="guenther2016">Güenther, Fritz., Dudschig, Carolin., and Kaup, Barbara (2016). “Latent semantic analysis cosines as a cognitive similarity measure: Evidence from priming studies.”  _Quarterly Journal of Experimental Psychology, 69,_ 626-653.
</li>
<li id="hale2002">Hale, Edward Everett (2002.) Review of 1855 _Leaves of Grass_ in _North America Review, 82._ In M. Moon (Ed.), _Leaves of Grass and other writings_ (795-797). New York: Norton.
</li>
<li id="harris1954">Harris, Zelig (1954). “Distributional structure.”  _Word, 10_ , 146-162.
</li>
<li id="helms1992">Helms, Alan (1992). “Live Oak, with Moss” (191-192). In Robert K. Martin (Ed.) _The continuing presence of Walt Whitman_ . Iowa City: University of Iowa Press.
</li>
<li id="killingsworth2007">Killingsworth, M. Jimmie (2007).  _The Cambridge introduction to Walt Whitman._ Cambridge University Press.<a href="https://doi.org/10.1017/CBO9780511610981">https://doi.org/10.1017/CBO9780511610981</a>
</li>
<li id="kintsch2014">Kintsch, Walter (2014). “Similarity as a function of semantic distance and amount of knowledge.”  _Psychological Review, 121,_ 559-561.
</li>
<li id="kulkarni2014">Kulkarni, Shailesh S., Apte, Uday, M. A., and Evangelopolous, Nicholas (2014). “The use of latent semantic analysis in operations management research.”  _Decision Sciences, 45,_ 971-994.
</li>
<li id="landauer2007">Landauer, Thomas K. (2007). “LSA as a theory of meaning.” In Thomas K. Landauer, Danielle. S. McNamara, Scott Dennis, and Walter Kitsch (Eds.) _Handbook of Latent Semantic Analysis,_ Mahwah, NJ: Lawrence Erlbaum Associates, 3-32.
</li>
<li id="landauer1997">Landauer, Thomas. K., and Dumais, Susan (1997). “A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge.”  _Psychological Review,104,_ 211 — 240.
</li>
<li id="lund1996">Lund, Kevin, and Burgess, Curt (1996). “Producing high-dimensional semantic spaces from lexical co-occurrence.”  _Behavior Research Methods, Instruments, & Computers_ , 28,203-208.
</li>
<li id="mandera2017">Mandera, Paweł, Keuleers, Emmanuel, and Brysbaert, Marc (2017). “Explaining human performance in psycholinguistic tasks with models of semantic similarity based on prediction and counting: A review and empirical validation.”  _Journal of Memory and Language, 92,_ 57-78.
</li>
<li id="mardsen2006">Mardsen, Steve (2006). “’A Woman Waits for Me’: Anne Gilchrist’s Reading of _Leaves of Grass._ ”  _Walt Whitman Quarterly Review_  23(3-4), 95-125. doi: <a href="https://doi.org/10.13008/2153-3695.1796">https://doi.org/10.13008/2153-3695.1796</a>
</li>
<li id="martin2007">Martin, Dian. I., and Berry, Michael W. (2007). “Mathematical foundations behind latent semantic analysis.” In Thomas Landauer (Ed.) _Handbook of Latent Semantic Analysis,_ Mahwah, NJ:Erlbaum, 33-55.
</li>
<li id="mccarty2012">McCarty, Willard (2012). “A Telescope for the Mind?”  _Debates in the Digital Humanities._ Ed. Matthew K. Gold. Minneapolis, MN: University of Minnesota Press.
</li>
<li id="muthasima2019">Muthasima, Rochma, Surya, Sumpeno, and Yoyon Kusnendar Suprapto (2019). “Twitter sentiment analysis of juvenile behaviour deviations using LSA (latent semantic analysis).”  _Journal of Physics_ 1201:012026.<a href="https://www.researchgate.net/publication/333588572_Twitter_Sentiment_Analysis_of_Juvenile_Behaviour_Deviations_using_LSA_Latent_Semantic_Analysis">https://www.researchgate.net/publication/333588572_Twitter_Sentiment_Analysis_of_Juvenile_Behaviour_Deviations_using_LSA_Latent_Semantic_Analysis</a>.
</li>
<li id="nelson1965">Nelson, Theodore Holm (1965). “Complex information processing: A file structure for the complex, the changing, and the indeterminate.” In _Association for Computing Machines Proceedings_ . Cleveland, OH.
</li>
<li id="oconner2021">O’Connor, William Douglas (1866/2021). _The good gray poet, a vindication._ New York: Bunce and Huntington.
</li>
<li id="parker1984">Hershel Parker, Hershel (1996). “The Real ‘Live Oak, with Moss’: Straight Talk about Whitman’s ‘Gay Manifesto,’”  _Nineteenth-Century Literature, 51_ , 145-160.
</li>
<li id="peterson1998">Peterson, David James (1998). “Beyond the body: Walt Whitman’s lavender language and ‘Out of the Cradle Endlessly Rocking’.”  _ World Englishes_ , 17, 239-248.
</li>
<li id="peattie1986">Peattie, R. W. (1986). “Whitman, Charles Aldrich and W. M. Rossetti in 1985: Background to the Whitman subscription.”  _American Literature, 58_ , 413-421.
</li>
<li id="prettejohn2012">Prettejohn, E. (Ed.) (2012). _The Cambridge companion to the Pre-Raphaelites_ . Cambridge: Cambridge University Press.<a href="http://doi.org.ezproxy.baylor.edu/10.1017/CCOL9780521895156">http://doi.org.ezproxy.baylor.edu/10.1017/CCOL9780521895156</a>
</li>
<li id="ramsey1997">Ramsey, Julianne (1997). “A British view to an American war: Whitman’s ‘Drum-Taps’ cluster and the editorial influence of William Michael Rossetti.”  _Walt Whitman Quarterly Review_ , 14, 166-175.
</li>
<li id="reynolds2010">Reynolds, David S. (2010). “‘Affection shall solve every one of the problems of freedom’: “Calamus,” love and the antebellum political crisis.”   _Huntington Library Quarterly_ , 73(4), 629–642.
</li>
<li id="rossetti1868">Rossetti, William Michael (1868). “Prefatory notice.”  _Poems by Walt Whitman_ , London, England: John Camden Hotten, 1-27.
</li>
<li id="rushie1989">Rushdie, Salman (1989). _The satanic verses._ New York: Viking.
</li>
<li id="rushdie2012">Rushdie, Salman (2012). _Joseph Anton: A memoir._ New York: Random House.
</li>
<li id="rstudio2020">Rstudio Team (2020). _RStudio: Integrated Development Environment for R._ Boston, MA.<a href="http://www.rstudio.com/">http://www.rstudio.com/</a>
</li>
<li id="salton1975">Salton, G. (1975). “A vector space model for automatic indexing.”  _Communications of the ACM_ , 18(11), 613-620.
</li>
<li id="scholnick2004">Scholnick, R. J. (2004). “The texts and contexts of 'Calamus': Did Whitman censor himself in 1860?”   _Walt Whitman Quarterly Review_  21(3/4), 109-130. doi: <a href="https://doi.org/10.13008/2153-3695.1724">https://doi.org/10.13008/2153-3695.1724</a>
</li>
<li id="sherman1992">Sherman, Nancy. (1992). “`Eligible to burst forth’: Whitman and the art of reticence.”   _Massachusetts Review_ , 33, 7-15.
</li>
<li id="">Thomas, M. W. (2010). “’Till I hit upon a name’: 'Calamus' and the language of love.”   _Huntington Library Quarterly_ , 73, 643–657.<a href="https://doi-org.ezproxy.baylor.edu/10.1525/hlq.2010.73.4.643">https://doi-org.ezproxy.baylor.edu/10.1525/hlq.2010.73.4.643</a>
</li>
<li id="wheat1990">Wheat, Edward. M. (1990). “Walt Whitman’s political poetics: The therapeutic function of Children of Adam and Calamus.”   _Midwest Quarterly_ , 31, 236–251.
</li>
<li id="whitley2020">Whitley, Edward. (2020). “Introduction to the British editions of Leaves of Grass.”  “The Walt Whitman Archive” . Retrieved from<a href="https://whitmanarchive.org/published/books/other/british/intro.html">https://whitmanarchive.org/published/books/other/british/intro.html</a>.
</li>
<li id="whitman1977">Whitman, Walt (1961-1977). _The correspondence_ . Edwin Haviland Miller (Ed.) 6 vols. New York: New York University Press.
</li>
<li id="stedman2008">Whitman, Walt (1892/2008). Ed. Arthur Stedman. _Selected Poems by Walt Whitman._ Whitefish, MT: Kessinger Publishing.
</li>
<li id="whitman1868">Whitman, Walt (1868). _Poems by Walt Whitman_ . William M. Rossetti (Ed.). London, UK: Hotten. Retrieved from<a href="https://whitmanarchive.org/">https://whitmanarchive.org/</a>
</li>
<li id="whitman1867">Whitman, Walt (1867). _Leaves of Grass_ . New York, NY: Chapin & Co. Retrieved from<a href="https://whitmanarchive.org/">https://whitmanarchive.org/</a>.
</li>
<li id="rossetti1867">Rossetti, William Michael (6 July 1867). “Walt Whitman’s poems.”  _The (London) Chronicle_ .
</li>
<li id="groff1996">Whitman, Walt (1996). (Eds. David Groff and Richard Berman). _Whitman’s men: Walt Whitman’s ‘Calamus’ poems celebrated by contemporary photographers._ New York: Universe.
</li>
<li id="whitman2017">Whitman, Walt and Gardner, M. C. (2017). _Walt Whitman’s whisper: 36 sex poems: Enfans D’Adam, “Calamus,” & a “Calamus,” quartet._ Another America Press -<a href="https://www.anotheramerica.net/">ANOTHERAMERICA.NET</a>.
</li>
<li id="wild2020">Wild, Fridolin (2020). _lsa: Latent Semantic Analysis._ R package version 0.73.2.<a href="https://CRAN.R-project.org/package=lsa">https://CRAN.R-project.org/package=lsa</a>
</li>
<li id="womack2016">Womack, Kenneth, and Decker, James M. (2016). (Eds.) _Victorian Literary Cultures: Studies in Textual Subversion_ . Madison, NJ: Fairleigh Dickinson University Press.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>In all commentary to follow I employ the 1867 label for each poem.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>1=Sing, 2=Asong, 3=Record, 4=Stranger, 5=Yearn, 6=Pen, 7=Dreamed, 8=Full; labels refer to the fully named poems reported in Table 1.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Excluded “Calamus” content: 1=Paths, 2=Scented, 3=RootsLeaves, 4= NotHeat, 5=Orgies, 6=Behold, 7=Louisiana, 8=Charged, 9=Prairie, 10=Clinging, 11=Glimpse, 12=Promise, 13=Sailor, 14=Machine, 15=EastWest, 16=Leaf, 17=Eternal, 18=Shadow, 19=Silently&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Italicized passage represent poem quotes.## Bibliography&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry></feed>