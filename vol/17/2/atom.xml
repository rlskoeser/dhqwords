<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://gohugo.io/" version="0.116.0">Hugo</generator><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/" rel="alternate" type="text/html" title="html"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/index.xml" rel="alternate" type="application/rss+xml" title="rss"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/atom.xml" rel="self" type="application/atom+xml" title="Atom"/><updated>2023-10-07T18:26:26+00:00</updated><rights>This work is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License.</rights><id>https://rlskoeser.github.io/dhqwords/vol/17/2/</id><entry><title type="html">Any Means Necessary to Refuse Erasure by Algorithm: Lillian-Yvonne Bertram’s Travesty Generator</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000707/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000713/?utm_source=atom_feed" rel="related" type="text/html" title="Introduction: Situating Critical Code Studies in the Digital Humanities"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000707/</id><author><name>Zach Whalen</name></author><published>2023-07-20T00:00:00+00:00</published><updated>2023-07-20T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<pre tabindex="0"><code> A NATION OF SPECIFIC CHAINS ON SHIPS CROSSING AN OCEAN SUMMONING ANY MEANS NECESSARY TO REFUSE ERASURE BY ALGORITHM A NATION OF REGULATED FRAY RIOTING DIGGING UP ANY MEANS NECESSARY TO REFUSE ERASURE BY ALGORITHM A NATION OF OLD DISPOSSESSIONS IN THE SHIP’S HOLD UNEARTHING ANY MEANS NECESSARY TO REFUSE ERASURE BY ALGORITHM
</code></pre><p><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>The passage quoted here is from Lillian-Yvonne Bertram’s poem,  “A NEW SERMON ON THE WARPLAND” , which is included in their 2019 collection,  <em>Travesty Generator</em> . All told, the poem includes 26 of these cinquains, and because the poem bears the subtitle  “a poem by algorithm,”  an attentive reader can deduce the function of that implied code. One can infer that it makes use of a template similar to the following:</p>
<blockquote>
<p>A NATION OF <NOUN> <PREPOSITION> <VERB> ANY MEANS NECESSARY TO REFUSE ERASURE BY ALGORITHM</p>
</blockquote>
<p>Bertram notes that some of the words in this poem come from Gwendolyn Brooks  “sermon on the warpland” . In addition, the cinquain template and the lists that supply words into its frame is based on  <em>A HOUSE OF DUST</em>  by Alison Knowles and James Tenney. And yet, even though this poem is oriented by these two contingencies, it is still Bertram&rsquo;s voice and vision that assembles these words into ideas and their meanings. The lineage that informs this poem is an important part of its meaning, and the software that creates the text is not mere technology but an ideologically-committed framework that operates on legacies of systemic racism: algorithms that erase; specific chains.</p>
<p>Critical Code Studies is a practical method of inquiry that applies literary and critical hermeneutics to computer code. In many cases, as in reading the source code of an application or a webpage, one may be tempted to read computational media and programmed objects as inherently dual &ndash; a legible, playable, visible surface and the normally invisible code that directs the machine to create that surface. Mark Marino and others have disrupted the neat division of surfaces and the depths they obscure by turning a critical, hermeneutial lens onto code as yet another textual surface where meaning is inscribed and can be interpreted. As Marino discusses at length, this proposition is not necessarily intuitive, nor is it without its critics. <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Code, after all, must be read both to the software that compiles it and the human that shares it, but clearly these are two different meanings of &ldquo;reading.&rdquo; Once a compiler transforms the text of a computer script into actionable assembly code, the idiomatic vaguaries of idiosyncratic, human reading can have no effect on the executation of that process. This gap between what a human means and what a computer understands is the challenge that novice programmers learn to struggle against: just because a line of code makes sense to me does not mean that the computer will do with it what I think it will.</p>
<p>Because so many areas of our world impacted by or accessed through programmed interfaces, opportunities abound for interpretations of code to bring critical attention to latent power dynamics and cultural assumptions. Because of this, much of the published work following a critical code studies orientation reads code in spite of what it does. For instance, Mark Sample discussing how offensive mysoginistic language discovered in a debug file for the videogame  <em>Dead Island</em>  reveals mysoginistic assumptions baked into the games design <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>; Winnie Soon and Eric Snodgrass disentangling the social and political relations implied by the design of application programming interfaces (APIs) <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>; Outi Laiti explaining how programming languages based on languages other than English helps to foreground and critique the hegemony of English within computing culture. <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<p>In examples of poetry generated by code, poetry written as code, and code that generates poetry, it is less useful to think of a tension between the code as text and the code as preamble to its processes and more productive to consider the imbrication of those surfaces. John Cayley&rsquo;s influential essay,  “The code is not the Text (unless it is the text)”   <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> disentangles two incommensurable ways of understanding language. As Cayley insists in a later essay reviewing Nick Montfort&rsquo;s book of computer poetry,  <em>#!</em> ,  “a potential for human reading&hellip;is required to produce an event of language”   <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. And for works where the code is finite and legible but what the code generates is practically or literally infinite (or infinitesimally brief), the code  <em>must</em>  be the poem; that is the only option. Herein lies the counterintuitive aporia for critical code studies when code poetry is the object of critique: whereas a close reading of a videogame&rsquo;s source code offers a peak behind the curtain, reading a poem&rsquo;s source code requires a more subtle recalibration of hermeneutic attention. Either way, as Marino observes,  “Regardless of where one sees the poetry, the procedure or the possibility, both exist, in hibernation or as seeds, in the code.”   <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></p>
<p>For poet Lillian-Yvonne Bertram, those seeds of possible meaning saturate all available surfaces, and whereas code poetry of the sort practiced by Montfort and Cayley can be esoteric and conceptual, the ideas in Bertram&rsquo;s poems are familiar, situated, and ideologically specific. In other words, Bertram&rsquo;s poems in  <em>Travesty Generator</em>  are already doing for digital poetry what critical code studies seeks for everyday systems and software when that software is bound up with regimes of oppression. My goal in this essay is to explore how Lillian-Yvonne Bertram uses code in their poetry to perform that critique, specifically by bearing witness to the pain and violence inflicted on Black Americans.</p>
<p>In writing about the way Bertram&rsquo;s poems address these topics with specificity and familiarity, I am aware that I approach this with the benefit of several privileges: I am a white, able-bodied, cis-gendered man. I am a tenured faculty member. These privileges necessarily mean that the experiences remembered in some of these poems &ndash; some of which are traumatic &ndash; will carry deeper and more personal meanings to those still oppressed and disproportionately harmed by police violence. Bertram, who identifies as biracial African-American, does not need my interpretation of their work for that work to be haunting, resonant, and beautiful, and the recognition this work has received indicates how well it speaks for itself. In this essay, I hope to use my voice and privilege to bring attention these poems and invite others to appreciate their nuances, complexities, and their lineage within digital poetics.</p>
<h2 id="heading-1"></h2>
<p>Computer code executed in the memory of a machine is characterized by its speed, ephemerality, and volatility, and digital poetry involving combinatorics can easily create a scenario such that any individual poem has a vanishingly small probability of existing. Thus, a poet’s decision to inscribe the output of a computer program into the pages of a book is an act of curation as much as composition. To select one result among many, or to capture a system at the point of its failing to continue, are as essential to digital poetics as are the tasks of defining a frame and creating the database of language to fit into that frame. This characterization of digital poetry consisting of a frame is a formulation Carole Spearin McCauley defined in her 1974 book  <em>Computers and Creativity</em>   <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, and it still illuminates contemporary digital poetry. Although poets may innovate in the types of frames to create and in the complexity of dictionaries to mine for language, the agenda of contemporary digital poetry is diminished if its meaning is circumscribed by mere novelty.</p>
<p>Lillian-Yvone Bertram’s book of poetry,  <em>Travesty Generator</em> , is among the most salient and compelling recent works of digital poetry because its poems address the contemporary realities of racism through the situated specificity of a computer generating poetry and the material specificity of print. In this essay, I offer close readings of several poems from this award-winning collection <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> to emphasize Bertram’s contribution to digital poetics and explicate the ways in which their poems operate in, on and against other systems of code and code poetry.</p>
<p>The book bears the title  <em>Travesty Generator</em>  in reference to Hugh Kenner and Joseph O&rsquo;Rourke&rsquo;s Pascal program designed to    “fabricate pseudo-text”   <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>   by printing out language such that each n-length string of characters in the output occurs at the same frequency as it does in the source text. According to its writers, by combining different authors through this algorithm, one might stumble across a travesty of  “haunting plausibility”  wherein James Joyce&rsquo;s writing becomes muddled with Henry James&rsquo;s. <sup id="fnref1:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> The pseudo-text&rsquo;s nonsensibility is simultaneously its act of transgression and its literary horizon, but for Kenner and O&rsquo;Rourke’s program and its many progeny, those possibilities extend no farther than a novelty, a formal curiosity or at best an insight into a specific author&rsquo;s writing style.</p>
<p>When Charles O. Hartman uses Travesty in his  <em>Virtual Muse</em> , he finds that the nonsense it generates helps Hartman&rsquo;s composition process by disrupting the habits he found himself following as a writer. Of the generator itself, Hartman noted with some awe that  “here is language creating itself out of nothing, out of mere statistical noise”   <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>.</p>
<p>Bertram’s title invokes the legacy of this program in the history of electronic literature, but more importantly, the name,  “travesty generator,”  invokes other resonances that raise the stakes in computer-generated poetry. Whereas for Kenner and O&rsquo;Rourke, labeling their work a  “travesty”  is a hyperbolic tease, a literary burlesque, for Bertram, the word is invigorated with its political reality. In 2013, attorney Don West, responding to the not guilty verdict for his client George Zimmerman in the shooting death of Trayvon Martin, congratulated the jury for keeping    “this tragedy from becoming a travesty”   <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>  . West is implying that the media attention on the case risked creating what he and Zimmerman would have called a farcical miscarriage of justice.</p>
<h2 id="counternarratives">Counternarratives</h2>
<p>For others, perhaps most observers, the event was always a travesty: a    “grotesque parody or imitation”   <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>   of criminal justice enacted by a civilian playing at being a law enforcement officer that resulted in the extra judicial killing of an unarmed high-school student.</p>
<p>Central to any response to that verdict is how one understands the narrative of events on February 26, 2012, and this is the question Bertam takes up in their poem  “Counternarratives”  which presents sentences, fragments, and ellipses beginning ambiguously but gradually hinting at a series of specific implications and images. These narratives are  “counter”  for several reasons, most importantly for the fact that they include Martin&rsquo;s point of view. Each stanza presents several sentences or fragments separated by ellipses, and with each page more of these phrases accumulate to present a gradually more complete image of what happened on February 26, 2012.</p>
<blockquote>
<p>[4] … He never told anyone, but he always wanted to go to space camp.<br>
[5] … He rides from station to station until he can rest at home.<br>
[6] … Sometimes he wakes feeling gone and doesn&rsquo;t know why.<br>
<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>The poem includes these sentences with others in 14 successive stanzas, each printed on its own face of a page, each growing in size until the blank 13th stanza breaks the pattern of expansion. One can see the inertia of automation and the inevitability of processes at work in the consistency of this pattern and in the way the poem intersects other perspectives that include the algorithmic prompts of search engines (e.g.  “People also ask: what really happened?” ) and the horticultural (e.g.  “Only the flowering catalpa trees are on watch” ) &ndash; all echoes of the machinic  “generator”  in the book&rsquo;s title. But because this is literally generated from computer code, the  “counter”  in the poem’s title works in at least two other significant ways.</p>
<p>In Nick Montfort’s 2014 collection,  <em>#!</em> , Montfort includes the source code of each poem alongside a representation of a poem produced by running that code.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> For Montfort’s poems, the poetics of the code is as much (and sometimes more than) any semantic meaning in the resulting output it generates, and his terse coding style, usually presented without comments, can be admired for its elegance as well as used to validate Montfort’s work. Harkening back to the days when programmers like Kenner and O’Rourke’s shared programs like Travesty Generator for Micros by publishing them in print magazines, Montfort’s poems invite readers to type them into an interpreter and see what happens.</p>
<p>Bertram does not include the source code for  “Counternarratives”  alongside its text, but in an appendix they acknowledge that the poem is adapted from the Python version of Montfort&rsquo;s poem, &ldquo;Through The Park,&rdquo; published in  <em>#!</em>  and also <a href="https://nickm.com/poems/through_the_park.py">available on his website</a><sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. By analyzing how Montfort’s poem operates, we can speculate about Bertram’s compositional and computational processes and thus explore how it situates Trayvon Martin’s death.</p>
<p>Montfort&rsquo;s poem is framed by a  <code>for</code>  loop, or a  “counter” ,  <code>i</code> , iterating through 8 sequences, each of which prints a numbered stanza:</p>
<blockquote>
<p><code>for i in range(8):</code></p>
</blockquote>
<p>For each loop and each stanza, the program selects a number between 7–11 ( <code>phrases = 7 + random.randint(0,4)</code> ) and randomly deletes lines from the initial 25 until the lines that remain reach the selected number of  <code>phrases</code> , joining those remaining lines with ellipses. The resulting poems achieve their meaning through omission, elision, and innuendo, relying on the ambiguity of language and the way readers respond to that ambiguity by imagining a context that creates the poem&rsquo;s implied narrative. What that narrative is will depend on which lines end up being printed, and in  <em>#!</em> , the 8 stanzas that Montfort selects show how widely those contexts may diverge. These could range from a casually flirtatious encounter with a stranger to a sexual assault. The latter reading is activated by whether two or three key phrases remain in the resulting poem. The suggestive phrases  “The girl puts on a slutty dress” ,  “The man makes a fist behind his back” ,  “The man&rsquo;s breathing quickens” , and  “The man dashes, leaving pretense behind”  makes  “The girl&rsquo;s bag lies open”  metonymic and lets the question of what their glances know ( “The man and girl exchange a knowing glance” ) hinge the meaning of the moment toward violence.<sup id="fnref1:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup></p>
<blockquote>
<p>The girl puts on a slutty dress. &hellip; A wolf whistle sounds. &hellip; The muscular man paces the girl. &hellip; A wildflower nods, tightly gripped. &hellip; Laughter booms. &hellip; A lamp above fails to come on. &hellip; The girl&rsquo;s bag lies open. &hellip; A patrol car&rsquo;s siren chirps. &hellip;</p>
</blockquote>
<p>This violence is implied, but generic, and the poem&rsquo;s meaning is about the way language gives shape to violence. The victim blaming in the  “slutty dress”  line, for example, could be Montfort reminding us of the ways that the framing of language creates an inertia of belief or predisposition that precedes and undermines knowing. Ultimately, however, this implication about language appears to be all that is at stake for the poem.</p>
<p>Bertram&rsquo;s  “Counternarratives”  is more than an adaptation of Montfort&rsquo;s poem because it is also a counter to  “Through the Park” . Whereas the context for Montfort&rsquo;s poem is hypothetical, Bertram&rsquo;s is real and specific. While we cannot consult Bertam&rsquo;s source code, it is possible to imagine the process whereby Montfort&rsquo;s  “A wildflower nods, tightly gripped”  becomes Bertram&rsquo;s  “The frangipani swans in the moonlight”  and Montfort&rsquo;s  “She puts on a slutty dress”  becomes  “People also ask what he was wearing”  or perhaps  “No mention of his clothing” . The code for  “Counternarratives”  may not be visible, but the source is eminently and tragically knowable.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup></p>
<p>What Trayvon Martin wore &ndash; a hoodie &ndash; became a symbol for that event and a meme for Black Lives Matter because of its power in calling out racial profiling. The assumption that  “a black man with a hoodie”  is inherently threatening is conveyed in Bertram&rsquo;s  “People also ask&hellip;”  phrasing, which quotes a google search suggestion. In the context created by this poem, this question recalls the victim blaming in Montfort&rsquo;s poem&rsquo;s  “slutty dress”  line, but following Bertram&rsquo;s move from the generic to the particular: this search suggestion and others like it are drawn from reality.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000707/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000707/resources/images/figure01_hu0256ef9d267b95885a4eda0290502fe7_106733_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000707/resources/images/figure01_hu0256ef9d267b95885a4eda0290502fe7_106733_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000707/resources/images/figure01_hu0256ef9d267b95885a4eda0290502fe7_106733_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000707/resources/images/figure01.png 1394w" 
     class="landscape"
     ><figcaption>
        <p>A screenshot of a Google search and suggestions for related searches.
        </p>
    </figcaption>
</figure>
<p>After a few trials, I discovered the suggestion  “What was Trayvon Martin wearing?”  in response to the search query  “Who shot Trayvon Martin?”  (see Figure 1). I also found another recurring line, and the final line in Bertram&rsquo;s poem,  “People also search for: Emmett Till”  came up in several similar searches. Safiya Noble&rsquo;s 2018  <em>Algorithms of Opression</em>  studies the ways that search engines are among the systems of oppression that commodify black male criminality and sustain social, political, and racial tension in America. In a 2014 article, Noble contrasts two sets of Google&rsquo;s autocomplete engine. &ldquo;Trayvon Martin was&hellip;&rdquo; completes with phrases like &ldquo;a thug&rdquo;, &ldquo;no angel&rdquo;, and &ldquo;a drug dealer&rdquo;; &ldquo;George Zimmerman is &hellip;&rdquo; completes with phrases like &ldquo;a hero&rdquo;, &ldquo;innocent&rdquo;, and &ldquo;not white.&rdquo; <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> As Noble argues, the ideas that Google suggests conform to a normative viewpoint on the violent events of that night actually extend from media narratives developed and promoted as part of the media spectacle that emerged during and after the trial.<sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> Notably, Bertram&rsquo;s implied query is different from: using the pronoun  “he”  in place of Martin&rsquo;s name, so the antecedent in &ldquo;what he was wearing&rdquo; could be Zimmerman, especially since neither are named outright in the poem. This final opening out of meaning is another significant way in which the poem reflects on its constructedness because it goes a step further than Montfort’s implied invitation to run his code. Instead, Bertram invites us to speculate about their implied code and simultaneously confronts us with the opacity of Google’s algorithmic suggestions.</p>
<p>In  <em>Travesty Generator</em> &rsquo;s appendix, Bertram notes that the output of their program has been edited and arranged, and this rewriting may be evident in the way that certain of the phrases evolve as the poem progresses <sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In some cases, Bertram&rsquo;s revisions evolve to follow a trajectory implied to begin in Montfort&rsquo;s version with Montfort&rsquo;s phrase,    “A patrol car&rsquo;s siren chirps.”   <sup id="fnref2:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup></p>
<p>Bertram&rsquo;s correlating lines (though never the last for any of their 14 stanzas) evolves from there into</p>
<blockquote>
<p>[3] &hellip; A patrol car&rsquo;s siren sings several streets away&hellip;<br>
[10] &hellip; Several weeks away, a patrol siren sings&hellip;<br>
[11] &hellip; A patrol car&rsquo;s siren sings several streets way&hellip;<br>
[12] &hellip; A patrol car&rsquo;s siren swats bugs and halos away&hellip;<br>
[14] &hellip; A siren signs<br>
several streets away.</p>
</blockquote>
<p><sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>The most striking movement in the poem is that way that  “Counternarratives”  uses ellipses. Whereas Montfort&rsquo;s poem is suggestive through the innuendo created by stochastic omission, Bertram&rsquo;s is subversive through the implications of its elisions, and those elisions and ellipses gradually resolve into prosodic syntax as the text of the poem gradually replaces its poetic mechanism. The phrase that first appears in stanza 4 as  “Real gaps spread in the tropic of paradise”  is stark in its proximity with its initial following line  “Forty-two miles from Disney”   <sup id="fnref4:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, where proximity here is both the poetic associations as well as the geopolitical identity of this Orlando suburb.</p>
<p>After the blank penultimate stanza &ndash; a final elision bearing the number 13 &ndash; this line has become  “Gaps split open the tropic of paradise” . A blank line splits the  “siren signs”  sentence, followed by the now damningly unambiguous  “Cause of death: It was a gated community”   <sup id="fnref5:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>By editing and arranging the output of their program, Bertram is declining to let the machinery of language or Python control the narrative and opening up paths to resistance by insisting that we bear witness to the tragedy without retreating to the algorithmic distance of a travesty. Two other poems in  <em>Travesty Generator</em>  offer similar insights on the relationship between the mechanization of computing and the use those processes to interrogate the structures that make them possible.</p>
<h2 id="three_last_words">“three_last_words”</h2>
<p>The poem that opens the book,  “three_last_words” , is at a functional level a restatement of the program in Nick Montfort&rsquo;s  “I AM THAT I AM” , which is itself a version or adaptation of Brion Gysin&rsquo;s permutation poem of the same title. That phrase does not appear in Montfort&rsquo;s version. Rather, Montfort&rsquo;s program defines a  <code>permutations</code>  function and then executes that function with the string  <code>'AEIOU'</code>  as its argument, yielding the 120 possible rearrangements of AEIOU as its outcome. Montfort&rsquo;s code accomplishes this succinctly through an elegant recursion as the  <code>permutations</code>  generator works through a list of  <code>elements</code> , rearranging all of the following elements ( <code>elements[1:]</code> ) by passing them back until no more next  <code>elements</code>  remain.</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code> &#34;I AM THAT I AM&#34; (#! 18) def permutations(elements): if len(elements) == 0: yield elements else: for result in permutations(elements[1:]): for i in range(len(elements)): yield result[:i] + elements[0:1] + result[i:] 
</code></pre><p><sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup></p>
<p>Bertram&rsquo;s generator is mostly the same code but the commentary they add &ndash; and more importantly the uses they put it to &ndash; changes the meaning entirely. That new meaning is jarring and, as in  “Counternarratives” , tragic. The three last words in reference here are Eric Garner’s and, more recently, George Floyd’s:  “I can’t breathe.”  Montfort’s permutations create a beginning; Bertram’s memorialize endings.</p>
<p>Bertram’s poem creates meaning at least two distinct levels. It can be read first as lines of poetry and second it can be executed as a program that generates poetry. The typographic presentation of the poem blends those two levels by alternating lines of code with comments and statements that execute the  <code>permutations()</code>  function defined at the outset &ndash; statements that accumulate toward something unavoidable. In the excerpt below, lines preceded with the character, #, are comments and not processed as code.</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code> def permutations(elements): #the if len(elements) == 0: #the knife yield elements #the knife they else: #the knife they hung 
</code></pre><p><sup id="fnref6:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>The sequence in comments reads,  “ <code>the</code> ” ,  “ <code>the knife</code> ” .  “ <code>the knife they</code> ” ,  “ <code>the knife they hung</code> ” , adding one word at a time over the course of the code until the completed comment observes,  “ <code>#the knife they hung him on / #was a legal trinket</code> ” <sup id="fnref7:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. When he was killed by Daniel Pantaleo while being placed under arrest, Eric Garner was selling loose cigarettes &ndash; a minor violation of cigarette tax law. Legal trinket here brings to mind the way that Garner&rsquo;s alleged crime of selling cigarettes became a meme for racist backlash to Black Lives Matter &ndash; responses that included an Indiana police officer selling t-shirts with the mocking slogan,  “Breathe easy, don&rsquo;t break the law”   <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. Bertram’s comment characterizes this as a  “trinket”  because the relatively trivial infraction was used to justify police violence.</p>
<p>The word &ldquo;trinket&rdquo; does something else here as well, perhaps coincidentally, by naming a service, <a href="https://trinket.io/">Trinket.io</a>, that allows users to create snippets of Python code that they can embed and run in a webpage. Intentionally or not, this possible reference hints at a specific, practical, and materially-situated environment for running this code, which is something that is implied to be unnecessary for Montfort&rsquo;s ontologically denotative and self-evidently tautological symmetry. In other words, the fact that Montfort prints the code with its output precludes a need to execute the code for ourselves.</p>
<p>Bertram&rsquo;s poem instead invites us to experience the consequences of their program as a response to its explicit invitation a page later:</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code> #run the code #in this cell #away 
</code></pre><p><sup id="fnref8:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> poem, the cell here may connote a jail cell, but more likely it describes a Python Notebook cell. Python Notebooks, like the embeddable Trinket widgets, are a common way to experiment with Python and to invite others to review, execute, and bear witness to the results of a program. In  “three_last_words” , the samples of output and the poem&rsquo;s culminating error message are typographically consistent with what one would see while running this code in a notebook.</p>
<p>Montfort&rsquo;s program runs one permutation and prints the output: 120 variations on the five vowels arranged from AEIOU to UOIEA in 8 tidy, monospaced columns. Bertram&rsquo;s program runs three times, and whereas Montfort&rsquo;s final line of Python 2 code prints the permutated sequences as a string ( <code>print''.join(list(permutations('AEIOU')))</code> <sup id="fnref2:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>), Bertram&rsquo;s Python 3 simply prints the list as it is represented in Python&rsquo;s memory. The first iteration permutes a single-character:</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code> print (list(permutations(&#34;I&#34;))) [&#39;I&#39;] 
</code></pre><p><sup id="fnref9:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> In addition to this invitation to experience the practical implementation of the program, this difference in printing the yield of the  <code>permutations()</code>  function pulls us toward the subjective point-of-view of the Python runtime that experiences the code, and the chaotic typography of the output &ndash; in contrast to Montfort&rsquo;s neat rows and columns &ndash; performs the messy complications of computation that will eventually culminate in the computer’s failure.</p>
<p>There is one more subtle variation between Montfort and Bertram&rsquo;s code in the final line of the constructor. As Python iterates through the  <code>elements</code>  list (a string of text characters, in this case) the newly-permutated line  <code>yields</code>  a  <code>+ result[i:]</code>  for Montfort or just  <code>+ result</code>  for Bertram.</p>
<p>The functional difference is that Montfort&rsquo;s line restores to the target string only those parts of the input string that come after the character operating for the current iteration. The  <code>[i:]</code>  slice captures only those elements after  <code>i</code> . Bertram&rsquo;s version retains and concatenates the entire working result, so the practical difference is that while Bertram&rsquo;s code will generate the same number of permutations, the strings it generates gradually become longer. The last element in the  <code>permutations()</code>  of the string,  “ <code>can't&quot; is &quot;t'nact'nat'nt't</code> ” . Whereas the 120 permutations of AEIOU are a complete and homogenous set,  <code>permutations(&quot;can't&quot;)</code>  is asymmetrical and grows geometrically. The articulation of</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code>print(list(permutations(&#34;breathe&#34;)))
</code></pre><p><sup id="fnref10:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> runs past the right and bottom edges of the page.</p>
<p>The asymmetry culminates finally and dramatically when the full phrase &ldquo;I can&rsquo;t breathe&rdquo; is passed in to the  <code>permutations()</code>  function. Bertram&rsquo;s code concludes with the printout out of a Python MemoryError because the number of possible sequences of the 15 letters in that phrase (1,307,674,368,000) exceeds the available memory on the computer hosting the Python runtime, and like the 15 seconds that Officer Pantaleo held Eric Garner in a chokehold, those 15 characters result in the death of the Python Notebook or the computer hosting it.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000707/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000707/resources/images/figure02_hu9c5a3eb37a370a6acc75541e78cf2fec_28619_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000707/resources/images/figure02_hu9c5a3eb37a370a6acc75541e78cf2fec_28619_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000707/resources/images/figure02.png 1020w" 
     class="landscape"
     ><figcaption>
        <p>A screenshot displaying the error message of a Colab Notebook that crashed trying to execute Bertram’s final permutation in “three_last_words” .
        </p>
    </figcaption>
</figure>
<p>I attempted to run Bertram&rsquo;s code two different ways: first in a Google-hosted Colab Notebook and later in a Jupyter Notebook running on my laptop. The Colab Notebook ran for some time with the RAM usage indicator creeping slowly to the right and becoming first green, then yellow, and finally orange before the runtime crashed and disconnected, as shown in Figure 2.</p>
<p>On my Macbook Pro, the results were similar, but as Python continued to take up more and more RAM, my computer gradually stopped working. The cursor slowed down, the trackpad clicked more slowly, and keyboard shortcuts stopped working. I couldn&rsquo;t take a screenshot, so I had to use another device &ndash; my phone &ndash; to capture the final moments before I resorted to a hard reboot and power cycle.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000707/resources/images/figure03.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000707/resources/images/figure03_hu7ab7dd5a3c1cb2fb4cbd007856e1fced_216738_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000707/resources/images/figure03_hu7ab7dd5a3c1cb2fb4cbd007856e1fced_216738_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000707/resources/images/figure03.jpg 1000w" 
     class="landscape"
     ><figcaption>
        <p>A photo of my Macbook Pro’s memory pressure monitor as it filled with the final permutations in “three_last_words” .
        </p>
    </figcaption>
</figure>
<p>It seems trivial or maudlin to compare a computer running out of memory to the tragedy of Eric Garner&rsquo;s asphyxiation and death, but the way the computer&rsquo;s memory usage creeped inevitably upward conveyed a vivid anxiety and sense of panic in a way that was hauntingly effective. This poem is directly addressing the physical environment of computing in a manner reminiscent of Montfort&rsquo;s poem  “Round”   <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>, or Sam Lavigne&rsquo;s parodic  “Slow Hot Computer”  project that  “lavigne makes your computer run slow, and hot, so you can be less productive”  by running  “processor-intensive calculations”  in a web browser. <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup></p>
<p>This kind of metaleptical irruption of attention &ndash; what Terry Harpold has called  “recapture”  &ndash; is typically accomplished in the service of play, both in the satiric sense of Lavigne&rsquo;s playfully critical projects and, for Harpold, in both the literal sense of playing videogames and the semiotic sense of expressive freedom within constraints. In Montfort&rsquo;s examples, recapture moderates the conflicts of entanglement when technical limitations are expressed through the terms of the gameworld, as when a text-based game attempts to parse an unknown word of user input and it replies,  “I didn&rsquo;t quite understand that” , instead of reporting an error code or just crashing. Recapture is a fundamental operation of videogames, which means that  “recapture happens during play, in the complex digressions and feedback loops that are activated in actual play” . <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></p>
<p>Bertram works with the same entanglement of technical process and expressive semiotics, but poetry is not a videogame. And in this case, the poem denies its reader the recapture of memory, challenging us instead to bear witness to the trauma it symbolizes.</p>
<p>As Wendy Hui Kyong Chun has discussed, computer memory is an  “enduring ephemeral” , always-already conflating memory with storage and, through metaphors and pretenses of permanence. They note that the instability of this term, memory, follows the volatility of RAM, which is  “based on flip-flop circuits and transistors and capacitors and which require a steady electrical current” . <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> Like human memory, software  “memory is not a static but rather an active process. A memory must be held in order to keep it from moving” . <sup id="fnref1:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> Bertram&rsquo;s software presents the volatility of memory as the entanglement of poetic representation, police brutality, and technical limitation, and by setting it up to fail, Bertram invites us to reenact the trauma of that brutality and interpret its technical and political consequences.</p>
<p>When Bertram disrupts the symmetry of Montfort&rsquo;s slices (result[:i] and result[i:] becomes result[:i] and result so that &ldquo;ehtaerb&rdquo; potentially becomes the drawn-out, Joycean susurration &ldquo;ehtaerbehtaerehtaeehtaehtehe&rdquo;, that is,  <code>print(list(permutations(&quot;breathe&quot;))[-1]))</code> , but both versions of the generator choke on Eric Garner&rsquo;s three last words. Memory fails, but the poem preserves its failure even as its overflow suggests a world uncontemplated by code. This overflow is not infinite &ndash; hinting that someday, when it becomes possible to run this program with the multiple terabytes of RAM necessary to compute and convey one trillion three-hundred seven billion six-hundred seventy-four million three-hundred sixty-eight thousand lines, the program will complete, but until then we are compelled to follow Bertram&rsquo;s invitation to bear witness and</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code> #return #this articulation #the exhaustion #we can&#39;t stop hearing 
</code></pre><p><sup id="fnref11:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<h2 id="a-new-sermon-on-the-warpland">“A NEW SERMON ON THE WARPLAND”</h2>
<p>Like  “three_last_words”  and  “Counternarratives” ,  “A NEW SERMON ON THE WARPLAND: a poem by algorithm”  is a work with a genealogy, and Bertram directs us to the source codes that ground it. This is another poem where Bertram gives credit to an example by Nick Montfort, but since his code is a straightforward implementation of Alison Knowles&rsquo;  “A House of Dust” , Knowles is a more appropriate counterpoint to consider for Bertram&rsquo;s work.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> Additionally and more significantly, Bertram acknowledges  “that some words and phrases are taken directly from Gwendolyn Brooks&rsquo; corpus”  in their notes <sup id="fnref12:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, so understanding those origins allows these phrases to act hypertextually as a bridge into Brooks&rsquo; poems. One could see  “NEW SERMON”  as the poem Brooks might have written with access, inspiration and context parallel to Knowles. Bertram encourages us to explore that hypothetical bridge between Brooks and Knowles by recommending Brooks&rsquo; 1987 collection Blacks, and specifically calling attention to  “The Sermon on the Warpland”  and  “In the Mecca”  as especially important sources. Brooks’  “Boy Breaking Glass”  and  “THE WALL”  also seem to be the sources for several phrases.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup></p>
<p>Alison Knowles and James Tenney produced  <em>A House of Dust</em>  in 1968, the same year that Gwendolyn Brooks published  “In the Mecca.”  The source code for  <em>House of Dust</em>  is not publicly available, but its function is easy to deduce by examining the output published in three different venues. Knowles created the structure and four lists of words and phrases, and Tenney wrote those into FORTRAN code that creates quatrains by selecting and printing one item from each list, indenting each line a few more spaces before returning to left justification as each new quatrain begins.</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code> A HOUSE OF ROOTS AMONG HIGH MOUNTAINS USING NATURAL LIGHT INHABITED BY VARIOUS BIRDS AND FISHES A HOUSE OF WOOD BY A RIVER USING ALL AVAILABLE LIGHTING INHABITED BY HORSES AND BIRDS A HOUSE OF DISCARDED CLOTHING UNDERWATER USING ELECTRICITY INHABITED BY FRENCH AND GERMAN SPEAKING PEOPLE 
</code></pre><p><sup id="fnref1:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup></p>
<p>Bertram credits <a href="https://nickm.com/memslam/a_house_of_dust.html">Montfort’s simulation of this poem</a> as the source of the program they manipulated, but around the same time Montfort created his web version <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>, I also created <a href="http://zachwhalen.net/pg/dust/">a JavaScript simulation of the poem</a> capable of running in a web browser.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> The results of each of our implementations are largely the same (save for some typographic and kinetic nuances), but while I named the variables holding each list:  <code>materials</code> ,  <code>places</code> ,  <code>lights</code>  and  <code>inhabitants</code> . Montfort used the names  <code>material</code> ,  <code>location</code> ,  <code>light_source</code>  and  <code>inhabitants</code> . The differences in variable names have no impact on the operations of our scripts, but our choices when programming those operations &ndash; my evident preference for plural labels, for example &ndash; might extend from differences in our readings of the poem. Those differences are only possible if one begins by paying attention to the operations of code separately from the inscriptions of that code.</p>
<p>Bertram doesn&rsquo;t share the source code for  “NEW SERMON”  in  <em>Travesty Generator</em> , but observing its patterns reveals it to have a similar structure of lists randomly sampled. Also, two earlier versions of Bertram&rsquo;s  “A NEW SERMON ON THE WARPLAND”  are available online, one in JavaScript (originally available at <a href="https://ruby-buffet.glitch.me">https://ruby-buffet.glitch.me</a>, the source code of this version notes it was based on Laurel Schwulst JavaScript implementation of Montfort’s Python version of Knowles and Tenney’s FORTRAN) and another in Python 2.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> In the Javascript version, each list simply bears a number ( <code>one</code> , <code>two</code> , etc.), but the Python 2 version assigns names that &ndash; like Montfort’s and my simulations of  <em>House of Dust</em>  &ndash; signpost the semantic position of each list. There are evidently some differences between the source code shared on Bertram&rsquo;s website and the code that created the poem published in  <em>Travesty Generator</em> , but the five names suggest their content and reveal Bertram&rsquo;s primary departure from Knowles:  <code>materials</code> ,  <code>locations</code> ,  <code>verb</code> ,  <code>means</code> , and  <code>outcome</code> .</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code> A NEW SERMON ON THE WARPLAND (excerpt) A NATION OF GRIEF IN THE CUT SUMMONING ANY MEANS NECESSARY TO REFUSE ERASURE BY ALGORITHM A NATION OF OLD DISPOSSESSIONS STILL FIGHTING CONJURING ANY MEANS NECESSARY TO REVISE ERASURE BY ALGORITHM 
</code></pre><p><sup id="fnref13:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>Comparing  <em>House of Dust</em>  with  “NEW SERMON”  reveals more differences than the addition of a fifth line. Knowles&rsquo; locations are diverse but more stable &ndash;  “BY THE SEA” ,  “IN MICHIGAN” ,  “IN A HOT CLIMATE” ,  “ON AN ISLAND” , “IN SOUTHERN FRANCE” , “AMONG OTHER HOUSE”  &ndash; while Bertram&rsquo;s are active, violent, or disrupted, and some are not conventionally  “locations”  but more so describe liminal states of being:</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code> ...IN THE CUT... ...STILL FIGHTING... ...IN FRONT OF A WINDOW ABOUT TO BE BROKEN... ...IN TRANSLATION... ...BETWEEN SCYLLA AND CHARYBDIS... ...IN THE SHIP&#39;S HOLD... 
</code></pre><p><sup id="fnref14:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>Instead of a house, Bertram addresses their sermon to a  “NATION” . Allusions to the slave trade are perhaps most striking in comparing the subtle differences in phrases between Knowles&rsquo;  “ON THE SEA”  and Bertram&rsquo;s  “ON SHIPS” , but the shifts in Bertram&rsquo;s poem do more than invert the stasis in Knowles&rsquo;. While  <em>A House of Dust</em>  dwells, a  “NEW SERMON”  moves, acts, and resists. The verbs and means lists propel each cinquain through the same  <code>means</code>  &ndash;  “ANY MEANS NECESSARY”  &ndash; to the same  <code>outcome</code> :  “TO REFUSE ERASURE BY THE ALGORITHM” .</p>
<p>The Python 2 version includes multiple possible outcomes, but the verbs list is somewhat shorter. Because the printed version of the poem includes the same outcome in each cinquain, it is reasonable to infer that its source code is closer to the Javascript version where list  <code>five</code>  only contains one element:  <code>to refuse erasure by the algorithm</code> . The  <code>means</code>  list works the same way, demonstrating that the only option is Malcom X&rsquo;s ANY MEANS NECESSARY.</p>
<p>For both of these one-choice lists, the program is still selecting that choice as the result of a process. The Python 2 draft uses the common  <code>random.choice()</code>  function, and the JavaScript version takes a custom function with a comment remarking on its conventionality:</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code> // This is a very common randomizing function. // It takes a list (array) and returns one at random. function select_random(x){ y = x[Math.floor(Math.random()*x.length)]; return y; } 
</code></pre><p><sup id="fnref15:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>The fact that this program is making a choice with no freedom echos the slavery imagery within the poem, but revisiting  <em>A House of Dust</em>  opens another way of understanding the significance of this choice without a choice.</p>
<p>Benjamin Buchloh argues that Knowle&rsquo;s project in creating  <em>House</em>  was to find a way to deconstruct the  “prison house of language” . <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> Noting the irony of an avante-garde artist like Knowles using a house, that most conventional vehicle for subject formation, as their central figure, Buchloh contends that the aleatory construction method of the poem demonstrates the infinite fluidity of the process of subject formation.</p>
<p>Channeling Nietzsche, Buchloh goes on to observe that the constructedness of  <em>House of Dust</em>  resists the subject&rsquo;s being at  “home”  in language.  “Knowles&rsquo;s The House of Dust conceives of the process of subject formation as a perpetual process of construction and undoing, precisely to prevent it from becoming an inhabitant of the prisonhouse of language, a merely substitutional system of fraudulent and aggressive convictions&hellip;the formation of of the subject at this point in history has become a more complex and, by necessity, a more open process, since the subject&rsquo;s intersections with language&hellip;are certainly no longer the primary &hellip; foundations.”   <sup id="fnref1:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> Buchloh&rsquo;s  “convictions”  are a play on words, a synonym for &ldquo;belief&rdquo; in the mode of the metaphoric correctional system. But it also opens up another angle on &ldquo;NEW SERMON,&rdquo; which is filled with punishment and captivity but conspicuously without conviction.</p>
<p>Although the JavaScript version of the poem does include  “of parolees”  and  “of prisoners”  as possible materials, possibly drawn from Brooks&rsquo;  “The Wall” , the printed poem&rsquo;s materials and locations invoke punishment without the framework of judicial justification:</p>
<blockquote>
<p>&hellip;A NATION OF SPECIFIC CHAINS&hellip; &hellip;IN THE SHIP&rsquo;S HOLD&hellip; &hellip;A NATION OF MEDGAR EVERS&hellip; &hellip;IN A STRING-DRAWN BAG&hellip;<br>
<sup id="fnref16:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>In this way, Bertram&rsquo;s poem comes back to the prison house of language that Knowles&rsquo; is playfully resisting. Captivity and imprisonment are not just metonymic critiques for the post-structuralist decentering of lexical epistemology; instead, the prison house of  “NEW SERMON”  is the literal kidnapping, enslavement, and genocide of Africans whose exploitation built the foundations of this nation.</p>
<p>Finally, by naming one of the lists  <code>verbs</code> , Bertram follows a schema one often finds in generative works that use context-free grammar: patterns or templates where words are given a syntactical place based on their part of speech. In  “NEW SERMON” , the verbs list does the most work to take the poem away from its origins in  <em>House of Dust</em> . The seven verbs that appear in the 22 printed cinquains all suggest movement with resistance or a sense of bringing something out from below:</p>
<blockquote>
<p>DIGGING UP<br>
SUMMONING<br>
CONJURING<br>
DIVINING<br>
UNEARTHING<br>
STRIKING MATCHES AGAINST<br>
HOLLERING DOWN<br>
<sup id="fnref17:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>Each of these verbs immediately precedes  “ANY MEANS NECESSARY”   <sup id="fnref18:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. So, by omitting the preposition  “by”  from Malcom X&rsquo;s well-known phrase, the call to action in the poem asks its reader to dig up, to unearth, strike matches against their own means of refusing erasure.</p>
<p>In an appendix on the book, Bertram quotes Harryette Mullen&rsquo;s essay,  “Imagining the Unimagined Reader” :  “When I read words never meant for me, anyone like me &hellip; then I feel simultaneously my exclusion and my inclusion as a literate black women, the unimagined reader of the text” .<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup></p>
<p>Bertram likewise considers themself an  “unimagined coder” .</p>
<blockquote>
<p>I use codes and algorithms in an attempt to create work that reconfigures and challenges oppressive narratives for Black people and to imagine new ones. I consider this an intervention into a set of literary practices that have historically excluded women and minorities.<br>
<sup id="fnref19:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>For each of the works I have analyzed here and for many others of the 10 poems in  <em>Travesty Generator</em> , Bertram uses the generators of computer-generated poetry to critique, resist, and replace narratives of oppression and to make explicit and specific what is elsewhere algorithmically insidious and ambivalent.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Writing in a blog entry for the Poetry Foundation, Bertram opens their reflection on Kenneth Goldsmith’s controversial performance of  “Michael Brown’s Body”  by qualifying their response through the lens of an individual, bodily experience of race.  “I would like to make it clear that my writing about race, like myself, is a collection of incomplete moments in time” . <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> Crucially, Bertram makes a connection here between time and identity. Time is a fundamental characteristic of computing where each event, action or change is associated with a specific  “moment[] of time,”  and most high-level languages include built-in functions to call up that time in various ways. In Perl,  <code>localtime</code>  converts a timestamp into chunks that are more easily processed into a human-readable format. Bertram’s poetry in  <em>Travesty Generator</em>  is likewise thinking about race through specific, recent moments of time where the suffering of Black men and women has brought America’s identity as a nation built on white supremacy into clearer focus.</p>
<p>As I type this paragraph in the year 2021, it is a few weeks after a jury in Minnesota found a white police officer guilty of murdering George Floyd <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup> &ndash; a crime recorded on camera that sparked an intense summer of protests in 2020. A few days after that guilty verdict, a young man in my suburban Virginia community was shot 10 times by a sheriff’s deputy after calling 911 for help. <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> It is nearly six years since Eric Garner’s death, nine years since Travyon Martin died, and sixty-five years since Emmett Till was lynched in Mississippi.</p>
<p>Bertram’s  “@Code_Switching”  includes the following Perl code (based on Nick Montfort’s  “PPG256-6” ):</p>
<blockquote>
</blockquote>
<pre tabindex="0"><code>#!usr/bin/perl@d=split/_/, switch_gods_switch_black_codes_you_when_you__where_god_belong_black_hills_to; {$_=localtime;/(..):(.)(.):(.)(.)/;print”\\”x$5.” $d[$1] $d[$2] $d[3] $d[$4] $d[$5] $d[$8]\n”;sleep 1; while $d &gt; 0}{print”\\”x$5.” $d[$3] $d[$6]\n”;}}redo
</code></pre><p><sup id="fnref20:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>There is much to unpack here, but briefly, a pattern match filter captures integers from the  <code>localtime</code>  string and uses those to select specific words from an underscore-separated list of words. Each line of the poem is therefore determined by the current system time, which Bertram invites us to consider by helpfully including the initial  <code>localtime</code>  for the three runs of the poem printed in the book. In other words, the poem is not randomly generated, but is instead a product of its time. This method recalls the technique of rjs in his  <em>Energy Crisis Poems</em>  whose similarly time-based method prompts that writer to reflect,  “the poet need not change his vision; he need only to move forward or backward in time to achieve innovation” . <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> And yet, a close reading of Bertram’s code reveals that whenever one runs the poem, some things will always be true. The expression  <code>$d[3]</code>  will always select the word  “black”  because the index is the integer,  <code>3</code> , and not the regular expression backreference  <code>$3</code> , and  <code>$d[$8]</code>  and  <code>$d[$6]</code>  will always select  “switch”  because there are only 5 possible capture groups and a null backreference operates like a  <code>0</code>  in referencing the first element in a list.</p>
<p>Therefore, in this poem, the second word of each shorter line will always be  “switch” , the third word of each longer line will be  “black” , and the final word of each longer line will be  “switch” .</p>
<blockquote>
<p>[$_] you switch \ black codes black switch gods switch \ you switch \ black codes black switch switch switch \ you switch \\ black codes black switch black switch \\ you switch \\ black codes black switch codes switch<br>
<sup id="fnref21:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>In this poem and throughout the collection, Bertram provides an alternative to rjs. Simply moving forward in time is not necessarily innovation, just as it is a mistake to assume that America, with its history built on Black suffering, is naturally less racist as time passes.  “@Code_switching”  is dedicated to Frantz Fanon whose  <em>Black Skin, White Masks</em>  emphasizes the linguistic mechanisms of colonization. As a product of time,  “@Code_switching”  reminds readers that to be Black and of the moment within that mechanism is to be always switching: codes switch, you switch, when switch, you switch. Always  “black”  and always  “switch” .</p>
<p>Perhaps the only way to stop the switch is to kill the process, which Bertram portrays in a metaleptic gesture similar to the crashing halt of  “three_last_words” . Bertram concludes  “@Code_switching”  with a series of  <code>^C</code>  &ndash; the characters one sees after typing  <code>ctrl+c</code>  in a terminal to abort the currently-running process. We can imagine the poet at their keyboard spamming  <code>ctrl+c</code>  until the poem crashes.</p>
<p>This is one of the many poignant moments in  <em>Travesty Generator</em>  where a computational process gives way (switches) from a formal concept to a lived, individual experience of a reality shaped by the consequences of colonization, oppression, and injustice. As I noted at the outset of this essay, my experience of race is very different; as a white man working in academia, I participate in a system that was designed by and for people like me. By working with the tools of similarly-monolithic computer programs, Lillian-Yvonne Bertram uses their poetry to think outside of the ideologies and paradigms those systems take for granted. Rather than letting language speak for itself (human or computer), Bertram speaks past the filter of those generators to share their lived, individual, and sometimes traumatic experiences of race and identity in 21st century America.</p>
<h2 id="acknowledgement">Acknowledgement</h2>
<p>This essay is based on a forum post I shared on the Critical Code Studies Working Group forum in March, 2020. I am grateful for feedback from Mark Marino, patricia_s, Milton Laufer, and especially Lillian-Yvonne Bertram as I transformed that post into this longer essay.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Bertram, Lillian-Yvonne. 2019.  <em>Travesty Generator</em> . Noemi Press, Blacksburg VA.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref10:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref11:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref12:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref13:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref14:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref15:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref16:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref17:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref18:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref19:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref20:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref21:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Marino, Mark. 2020.  <em>Critical Code Studies</em> . MIT Press, Cambridge, MA.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Sample, Mark. 13 September 2011.  “Zombie Code and Extra-Functional Significance” .  <em>Play the Past</em> . <a href="https://www.playthepast.org/?p=1989">https://www.playthepast.org/?p=1989</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Snograss, Eric and Winnie Soon. 1 February 2019.  “API practices and paradigms: Exploring the protocological parameters of APIs as key facilitators of sociotechnical forms of exchange” .  <em>First Monday</em> . 24:2.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Laiti, Outi. 2016.  <em>Ethnoprogramming : an indigenous approach to computer programming : a case study in Ohcejohka area comprehensive schools</em> . University of Lapland, Faculty of Education. <a href="https://lauda.ulapland.fi/handle/10024/62624">https://lauda.ulapland.fi/handle/10024/62624</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Cayley, John. 10 September 2002.  “The Code is not the Text (Unless It Is the Text)”    <em>electronic book review</em> . <a href="https://electronicbookreview.com/essay/the-code-is-not-the-text-unless-it-is-the-text/">https://electronicbookreview.com/essay/the-code-is-not-the-text-unless-it-is-the-text/</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Cayley, John. 31 January 2015.  “Poetry and Stuff: A Review of #!”    <em>electronic book review</em> . <a href="http://electronicbookreview.com/essay/poetry-and-stuff-a-review-of/">http://electronicbookreview.com/essay/poetry-and-stuff-a-review-of/</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>McCauley, Carole S. 1974.  <em>Computers and Creativity</em> . Praeger, New York.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Dennigan, Darcie. 2020.  “2020 Anna Rabinowitz Prize.”    <em>Poetry Society of America</em> . <a href="https://poetrysociety.org/award-winners/2020-anna-rabinowitz-prize">https://poetrysociety.org/award-winners/2020-anna-rabinowitz-prize</a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Kenner, Hugh and Joseph O&rsquo;Rourke. 1984.  <em>Byte Magazine</em> , 9:12.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Hartman, Charles O. (1996) Virtual Muse: Experiments in Computer Poetry. Middletown: Wesleyan University Press.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>BBC. (2013)  “George Zimmerman not guilty of Trayvon Martin murder” . 14 July 2013.  <em>BBC News</em> . BBC.com. <a href="https://www.bbc.com/news/world-us-canada-23304198">https://www.bbc.com/news/world-us-canada-23304198</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Oxford English Dictionary. (1989)  “travesty, v” .  <em>Oxford English Dictionary</em> . {2nd edn.} OED.com. <a href="https://www.oed.com/oed2/00256847">https://www.oed.com/oed2/00256847</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Montfort, Nick. 2014.  <em>#!</em> . Counterpath Press.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Montfort, Nick. 2008.  “Through the Park”  Python. <a href="https://nickm.com/poems/through_the_park.py">https://nickm.com/poems/through_the_park.py</a>&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>The lineage that connects &ldquo;Counternarratives&rdquo; to &ldquo;Through the Park&rdquo; is similar to the network of remixes created in response to Nick Montfort&rsquo;s poem, &ldquo;Taroko Gorge,&rdquo; many of which have been collected in Volume 3 of the  <em>Electronic Literature Collection</em> . As both Cayley and Marino have discussed, the fact that many of the derivative works leave the algorithm of that poem intact &ndash; and thus its form &ndash; but make meaningful changes to the data means that the original work Montfort created is more like a poetic form than simply a poem. J.R. Carpenter&rsquo;s remix of that poem, &ldquo;Gorge,&rdquo; replaces Montfort&rsquo;s variables with words related to gluttonous consumption. While an analysis of Carpenter&rsquo;s work is beyond the scope of this essay, it is interesting that her collection,  <em>Generation[s]</em>  which includes &ldquo;Gorge,&rdquo; also features several poems generated by remixing and modifying &ldquo;Through the Park.&rdquo; Reading those alongside Bertram&rsquo;s &ldquo;Counternarratives&rdquo; as would likely highlight different perspectives on Montfort&rsquo;s original poem.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Noble, Safiya. 2014.  “Teaching Trayvon” .  <em>The Black Scholar</em> . 44.1 (2014): 12-29.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Ortiz, Eric. 19 December 2014.  “Indiana Cop Told to Stop Selling &lsquo;Breathe Easy&rsquo; T-shirts”    <em>NBC News</em> . NBCnews.com. <a href="https://www.nbcnews.com/news/us-news/indiana-cop-told-stop-selling-breathe-easy-t-shirts-n271581">https://www.nbcnews.com/news/us-news/indiana-cop-told-stop-selling-breathe-easy-t-shirts-n271581</a>&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Montfort, Nick. 2013.  “Round”  Javascript.  <em>New Binary Press</em> . <a href="http://newbinarypress.com/publications/">http://newbinarypress.com/publications/</a>&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Lavigne, Sam. 1 April 2015.  “Slow Hot Computer”  Javascript. <a href="http://slowhotcomputer.com">http://slowhotcomputer.com</a>&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Harpold, Terry. 2007.  “Screw the Grue: Mediality, Metalepsis, Recapture” .  <em>Game Studies</em> . 7:1.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Chun, Wendy Hui Kyong. 2011.  <em>Programmed Visions: Software and Memory</em> . Boston, MIT Press.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Knowles, Alison and James Tenney. 1968.  <em>A House of Dust</em> .&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Brooks, Gwendolyn. 1987.  <em>Blacks</em> . David Co, Chicago.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Montfort, Nick. 2014.  “A House of Dust reimplementation” . HTML. <a href="https://nickm.com/memslam/a_house_of_dust.html">https://nickm.com/memslam/a_house_of_dust.html</a>&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Whalen, Zach. 7 February 2014.  “House of Dust by Alison Knowles and James Tenney”  HTML. <a href="http://zachwhalen.net/pg/dust/">http://zachwhalen.net/pg/dust/</a>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Bertram, Lillian-Yvonne. n.d.  “New Sermon Code” . Python 2. <a href="https://www.lybetc.tech/new-sermon-code">https://www.lybetc.tech/new-sermon-code</a>&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Buchloh, Benjamin. 2012.  “The Book of the Future: Alison Knowles&rsquo;s The House of Dust” .  <em>Mainframe Experimentalism: Early Computing and the Foundations of the Digital Arts</em> . Ed. Hannah Higgins and Douglas Kahn. University of California Press.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Mullen, Harryette. 1999.  “Imagining the Unimagined Reader: Writing to the Unborn and Including the Excluded” .  <em>boundary 2</em> . 26:1.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Bertram, Lillian-Yvonne. 2019.  “The Whitest Boy Alive: Witnessing Kenneth Goldsmith by Lillian-Yvonne Bertram”    <em>Poetry Foundation</em> . <a href="https://www.poetryfoundation.org/harriet/2015/05/the-whitest-boy-alive-witnessing-kenneth-goldsmith">https://www.poetryfoundation.org/harriet/2015/05/the-whitest-boy-alive-witnessing-kenneth-goldsmith</a>&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Xiong, Chao, Paul Walsh, and Rochelle Olsen. 21 April 2021.  “Derek Chauvin cuffed after murder, manslaughter convictions in death of George Floyd”    <em>StarTribune</em> . <a href="https://www.startribune.com/derek-chauvin-cuffed-after-murder-manslaughter-convictions-in-death-of-george-floyd/600047825/">https://www.startribune.com/derek-chauvin-cuffed-after-murder-manslaughter-convictions-in-death-of-george-floyd/600047825/</a>&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Carey, Julie. 23 April 2021.  “Virginia Man Shot by Sheriff&rsquo;s Deputy After Calling 911 for Help” .  <em>NBC4 Washington</em> . <a href="https://www.nbcwashington.com/news/local/northern-virginia/virginia-man-isaiah-brown-shot-by-sheriffs-deputy-after-calling-911-for-help/2649178/">https://www.nbcwashington.com/news/local/northern-virginia/virginia-man-isaiah-brown-shot-by-sheriffs-deputy-after-calling-911-for-help/2649178/</a>&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>rjs. (1974) Energy Crisis Poems: Poetry by Program. Cleveland: Ground Zero.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">BASIC FTBALL and Computer Programming for All</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000696/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000706/?utm_source=atom_feed" rel="related" type="text/html" title="Tracing Toxicity Through Code: Towards a Method of Explainability and Interpretability in Software"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000696/</id><author><name>Annette Vee</name></author><published>2023-07-20T00:00:00+00:00</published><updated>2023-07-20T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>In late fall 1965, John Kemeny wrote a 239-line BASIC program called FTBALL***. Along with his colleague Thomas Kurtz and a few work-study students at Dartmouth College, Kemeny had developed the BASIC programming language and Dartmouth Time-Sharing System (DTSS), both of which went live on May 1, 1964. BASIC and DTSS represented perhaps the earliest successful attempt at programming for all, combining English-language vocabulary (e.g.,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">HELLO
</code></pre><p>instead of</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LOGON
</code></pre><p>), simple yet robust instructions, and near-realtime access to a mainframe computer. Their efforts were funded by the National Science Foundation and buoyed by their ingenuity and that of undergraduates invested in the project. Beginning in 1966, Kemeny and Kurtz rolled out an ambitious training course that, over the next few years, taught about 80% of Dartmouth students and faculty how to program in BASIC in just a couple of hours. From the mid-1960s on, they facilitated connections to the Dartmouth computing network from local high schools and other colleges, making the computer and BASIC accessible beyond undergraduates at Dartmouth. Their free licensing of BASIC eventually led to a splintering of hundreds of versions of the language by the 1970s and ‘80s, one of which was famously written by Bill Gates and Paul Allen and helped to launch Microsoft, and another of which (less famously) introduced me to programming on my Commodore 64 in 1982. My own introduction to programming in the early 1980s was part of a larger movement of computer programming for all in the 1980s, associated with computer literacy campaigns and renewed emphases on educational technology in the Cold War. But Kemeny and Kurtz got there first in the 1960s at Dartmouth.</p>
<p>FTBALL is a great example of 1960s BASIC programming, but its cultural significance is as a deliberate demonstration of computers as  <em>fun</em> . Preceded by games such as  <em>Tennis for Two</em>  and  <em>Spacewar!</em> , FTBALL was part of an approach to computing that ran counter to the more dominant applications of defense and the hard sciences at the time. FTBALL’s author, John Kemeny, was a math professor at Dartmouth, as well as a former assistant to Albert Einstein at Princeton’s Institute for Advanced Study and, later, President of Dartmouth College — a position in which he led admissions for women and the recruitment of Native American students. Along with his collaborator Thomas Kurtz, Kemeny believed computers could be fun and should be widely accessible to a general population of students. In the final report on an NSF grant Kemeny and Kurtz received for their BASIC timesharing project, they write:</p>
<blockquote>
<p>A remark is in order concerning the use of computers to play games. They are a magnificent means of recreation. But people feel that it is frivolous to use these giants to play games. We do not share this prejudice. There is no better way of destroying fear of machines than to have the novice play a few games with the computer. We have noted this phenomenon several times, particularly with our visiting alumni. And most of the games have been programmed by our students, which is an excellent way to learn programming.<br>
<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>Indeed, from its outset and original design, the BASIC lab at Dartmouth and the BASIC programming language fostered programming games as a way to learn about computing. Kemeny and Kurtz encouraged students to add to their libraries of BASIC programs, and in the 1970s, publications of BASIC games in the book  <em>BASIC Computer Games</em>  by David Ahl and in popular computer magazines further supported learning programming through games.</p>
<p>This article takes a closer look at FTBALL as a crucial program in the history of computer programming for all while gesturing to the tension between a conception of  <em>all</em>  and FTBALL’s context in an elite, all-male college in the mid-1960s. FTBALL can be seen as an early indicator of masculine computing culture (see <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>) and a product of American college football culture, areas where women have played a peripheral but ever-present role. But FTBALL is  <em>also</em>  an early example of computing for undergraduates, for people outside the hard sciences, and for fun. That a renowned professor wrote it to be played for free by undergraduates at a time when computers were generally reserved for serious work in calculation makes it an excellent object of study for the history of BASIC, early computing education, and accessible programming more generally. Accordingly, I put FTBALL in a historical, cultural, gendered context of programming for all as well as the historical context of programming language development, timesharing technology, and the hardware and financial arrangements necessary to support this kind of playful, interactive program in 1965.</p>
<p>Using methods from critical code studies <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, I point to specific innovations of BASIC at the time and outline the program flow of FTBALL. FTBALL demonstrates a number of features typical of early BASIC, including</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LET
</code></pre><p>as an assignment statement and the infamous</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOSUB
</code></pre><p>statements for program flow. The</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOSUB
</code></pre><p>statements make FTBALL&rsquo;s program flow difficult to follow — which is also typical for more complex, early BASIC programs. The convolution of program flow in FTBALL is both ironic and predictable, given FTBALL’s popularity and attempt at accessibility alongside the common critiques of early BASIC program structures. Adding to the code analysis in this article, I use methods from history of computing, drawing historical context from archival records held by Dartmouth College Libraries, BASIC fan sites, a 2014 Dartmouth documentary titled  <em>Birth of Basic</em> , Joy Lisi Rankin’s  <em>A People’s History of Computing</em> , the collaboratively authored book  <em>10 PRINT</em> , contemporary BASIC programming manuals, and a personal interview I conducted with Thomas Kurtz in 2017.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<p>My combined code analysis and archival approach for FTBALL follows in the footsteps of Dennis Jerz’s examination of Will Crowther&rsquo;s  <em>Colossal Cave Adventure</em>  (an early text adventure game from the 1970s) and Nick Montfort’s work on  “Zork”  (a game inspired by  <em>Adventure</em> ) in  <em>Twisty Little Passages</em> . While FTBALL is often credited for its early influence on sports games and its later variations are noted as popular BASIC games, it has received little scholarly attention and, to my knowledge, no attention to the composition of its code nor its early role in popularizing BASIC. As with  <em>Adventure</em>  and  <em>Zork</em> , the availability of FTBALL’s code and its textual interface makes it rich for textual analysis. The popularity of all three games as early genre entries justifies the extended attention to their cultural and historical contexts as well. Below, I begin with a short history of BASIC’s early development, put FTBALL in context with other early games and sports games, then move into the hardware and technical details that enabled the code before finally reading FTBALL’s code in detail. My hope is to provide something of interest to computing historians, critical code studies practitioners, and games scholars and aficionados.</p>
<h2 id="basic-and-accessible-computing-at-dartmouth">BASIC and Accessible Computing at Dartmouth</h2>
<p>With the skills and needs of liberal arts students at Dartmouth in mind, math professors John Kemeny and Thomas Kurtz began in the 1950s to work towards an ambitious goal of teaching the entire undergraduate population of Dartmouth basic computer literacy. They had begun this project by working closely with students to develop simplified assembly code. During the early 1960s, they moved through several languages and hardware setups prior to requesting funds from the NSF and the college for a hardware system that would support their pedagogical goals. With this support and the ingenuity of undergraduate collaborators, in 1964, Kemeny and Kurtz launched the BASIC language and the Dartmouth Time-Sharing System (DTSS). BASIC went through several rapid revisions in the mid-1960s, and then spread widely due to its accessible syntax, generous licensing, and local timesharing access. BASIC was particularly popular among hobbyists. By 1978, BASIC was  “the most widely known computer language,”  according to Kurtz, because it appealed to a general audience, or, as Kurtz put it:  “[s]imply because there are more people in the world than there are programmers” <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>Kemeny and Kurtz had lifelong investments in education, and Kemeny had been involved in nationwide mathematics education efforts prior to BASIC. Kemeny was a Jewish immigrant from Hungary; he had come to the US at fourteen years old in 1940 when his father recognized the danger of increasing anti-Jewish regulations in Europe. His brilliance, especially in math, shone almost as soon as he arrived: he graduated valedictorian of his high school in New York and was drafted into the Manhattan Project while he was an undergraduate in math and philosophy at Princeton. Los Alamos was Kemeny’s first exposure to computing. Kurtz says of Kemeny:  “he had been drafted and sent to Los Alamos where he worked on the precursor to the atomic bomb. They had IBM accounting machinery, …adding and subtracting was the only thing they did. They figured out a way to solve partial differential equations using equipment, and he was involved in that” <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. He came to Princeton and got a Ph.D. in Mathematical Logic, then joined their Philosophy Department, after which he was recruited to Dartmouth to lead the Math Department. Kemeny was connected to some of the most brilliant and influential thinkers in physics, math, and computing: at Los Alamos, Richard Feynman was his supervisor and he worked with John von Neumann; at Princeton his dissertation was supervised by Alonzo Church and he was Albert Einstein’s mathematical assistant. (Kemeny once remarked that Einstein needed an assistant because  “Einstein wasn’t very good at math” <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.) Kemeny began at Dartmouth as a full Professor of Mathematics at twenty-seven, became chair shortly afterward, then later recruited Thomas Kurtz from Princeton, along with other colleagues, to build up the Dartmouth Math Department. Kurtz described Dartmouth at the time: before the interstate highway system, Dartmouth was  “way up here”  and isolated, with only one graduate program — in business administration <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. But Kemeny was loyal to Dartmouth: he served over a decade as its president (1970-1981), his two children attended Dartmouth, and he loved Dartmouth sports.</p>
<p>Dartmouth undergraduates in science in the early 1960s were motivated to learn how to use computers because the applications for computers were apparent to them and relatively easy to access with the use of locally-designed programming languages based on ALGOL. But these languages had technical limitations and more widely used languages such as ALGOL and FORTRAN were built for physics and the hard sciences. Kemeny and Kurtz wanted to reach the other 75% of Dartmouth undergraduates, those who were majoring in the humanities or social sciences. They figured that these students would be turned off from computing by the slow turnaround time of batch processing and specialized languages that relied on arcane knowledge of computer engineering. For a system to appeal to these students, it had to be accessible and intuitive and must have quick turnaround times. Kemeny and Kurtz also knew that lectures on computing wouldn’t cut it; students actually had to try their hand at programming. So, they worked toward a system that would simulate real-time responsiveness and have something closer to English language syntax: what eventually became the Dartmouth Time-Sharing System (DTSS) and the BASIC computer language <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.</p>
<p>Kemeny and Kurtz wrote:</p>
<blockquote>
<p>The primary goal motivating our development of DTSS was the conviction that knowledge about computers and computing must become an essential part of liberal education. Science and engineering students obviously need to know about computing in order to carry on their work. But we felt exposure to computing and its practice, its powers and limitations must also be extended to nonscience students, many of whom will later be in decision-making roles in business, industry and government.<br>
<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></p>
</blockquote>
<p>In their motivations to teach nonscience students to learn more about computers, the resonances with literacy education are apparent. Thomas Kurtz confirmed in a personal interview I conducted with him in 2017 that they did indeed think of their pedagogical project as literacy education. While they generally described their pedagogical motivations along the lines of civic engagement, as above, Kurtz also told me they were invested in the creative potential of the computer. There were others who argued earlier for computer literacy — George Forsythe in 1959 and Alan Perlis in 1961 — but Kemeny and Kurtz were the first to develop a working system to support it <sup id="fnref1:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. Given the hardware and programming languages of the time, it wasn’t clear to anyone how widespread computer education could actually work. The LOGO programming language — which emphasized graphics and was designed for younger children — was developed very soon after BASIC. Kemeny and Kurtz admired Seymour Papert and the LOGO development team for their focus on abstract thinking and creativity, though Kurtz pointed out that LOGO stumbled a bit because it seemed to need an expert overseeing the learning process <sup id="fnref2:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. In contrast, BASIC was designed to be learned with very little support — just a couple of lectures or a manual. While both BASIC and LOGO circulated widely with microcomputers in the 1980s, LOGO tended to thrive in formal educational contexts and BASIC in informal, home, and hobbyist contexts, including the circulation of games like FTBALL.</p>
<p>Initially, Kemeny and Kurtz were not in agreement about the need for a whole new language to teach computing but did agree that timesharing was necessary to keep the interest and attention of nonscience students. Through a regional computer-sharing agreement with MIT, Kurtz had served as the Dartmouth representative since 1956 and made trips to Boston every two weeks to use their IBM 704. He learned Assembly language for the 704 and would turn in his punch cards when he arrived at MIT in the morning then pick them up in time to catch the last train back to Dartmouth in the evening. Kurtz experienced first-hand the frustration of long turnaround times, as correcting a mistake in his programming meant he would need to wait two weeks until his next trip to MIT. John McCarthy, an early leader in artificial intelligence who knew the context at Dartmouth because he had previously been mathematics faculty there, suggested timesharing during one of Kurtz’s visits to MIT <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  <sup id="fnref3:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. Kemeny and Kurtz figured that undergraduates would tolerate timesharing a computer better than batch processing punch cards — especially if they were using teletypes that were responsive enough to disguise the fact that the timesharing was happening.</p>
<p>Through Kurtz’s regular train trips to MIT, Kemeny and Kurtz also learned that a simpler language was often better than a more efficient one. The two-week turnaround raised the stakes on errors in their code, even minor ones. Kemeny and Kurtz used SAP (Share Assembly Language) on the IBM 704 but were frustrated by the complexity and opacity of it. Kemeny devised DARSIMCO (DARtmouth SIMplified COde) in 1956, although it wasn’t used much because FORTRAN came out the next year. But, according to Kurtz,  “DARSIMCO reflected Dartmouth’s continuing concern for simplifying the computing process and bringing computing to a wider audience” <sup id="fnref2:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Moreover, after the difficulties of programming in SAP versus the much more intuitive FORTRAN, Kurtz recognized  “that programming in higher level languages could save computer time as well as person time”  because the programs were less subject to human error, even though they might be technically more inefficient. Kurtz initially thought a subset of ALGOL or FORTRAN would be sufficient for their pedagogical goals, but the ways those languages treated loops and variables finally convinced him that Kemeny was right: to teach a general population of undergraduates, they needed a new language <sup id="fnref3:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>In addition to the need for faster turnaround times and a simplified language, Kemeny and Kurtz made another early realization: undergraduates could do serious work in computing. As an undergraduate in 1959, Robert Hargraves developed the DART language on the newly-arrived LGP-30 computer <sup id="fnref4:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Undergraduate George Cooke wrote a program in DART to predict results in the 1960 election and it predicted the results correctly — unlike NBC. Stephen Garland wrote an ALGOL interpreter for the LGP-30 while he was an undergraduate at Dartmouth as well <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. When Kemeny and Kurtz applied for NSF funding to support their pedagogical project, the fact that they had only undergraduates as assistants apparently made the grant reviewers raise an eyebrow; however, Kemeny’s reputation carried the day, and they received their funding anyway <sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. Later, Kemeny and Kurtz both credited undergraduates as key to the development of the success of BASIC and DTSS. They noted that in April 1964, their undergraduates worked 50 hours a week on the system — although they were keen to point out that none of them failed any courses as a result <sup id="fnref1:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. A lot of the actual development of the language and timesharing system was handled by undergraduates Michael Busch and John McGeachie; Robert Hargraves and Stephen Garland also worked on the system. Anthony Knapp had sketched out an initial hardware configuration draft for timesharing after a visit he and Kurtz made to GE in 1962 <sup id="fnref5:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. In our interview, Kurtz repeatedly emphasized the brilliance of the undergraduates working on BASIC. Referring to himself and Kemeny, he insisted,  “we were the leaders of the band; we weren’t the performers”   <sup id="fnref4:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. That undergraduates were the main audience for programs also influenced the kinds of programs that got written, including games.</p>
<p>Dartmouth was aided by the talent and energy of undergraduates as well as the fact that the university had very little government-supported research and thus was freed from the apparent constraint to charge faculty and students for computing services. Kemeny and Kurtz were dead-set on open access of computing resources at Dartmouth, using open stack libraries as a model. Kurtz recalled,  “At the time, Dartmouth had of one of the largest, if not  <em>the</em>  largest, open stack library among universities in the country. So, the idea of open stack, open computing, open access computing is natural and obvious” <sup id="fnref5:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. Universities had different tactics for supporting recreational use of computers at the time — Kurtz insisted they weren’t necessarily iconoclastic in this. Princeton apparently had a small block of time for unsupported computer use. Dartmouth, which was more focused on undergraduate education, had a more open policy, which charged all uses of the computer to the Dean of the Faculty, who had the budget for the computer, and the Dean then charged government grants for the use. Kurtz called this a  “fictitious charging scheme,”  which enabled the computer to be available at Dartmouth like an open stack library <sup id="fnref6:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. John McGeachie, who worked on BASIC and DTSS as an undergraduate, confirmed the availability of the system:  “the undergraduates who were part of the student assistantship program basically had priority of access to the machine. For all intents and purposes, it was our machine — which we shared with John Kemeny” <sup id="fnref2:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>.</p>
<p>Dartmouth College was the site of other important early innovations in computing, including a demonstration in 1940 by George Stiblitz of Bell Telephone Laboratories — the first use of a computer over a communications line and using a teletype. The  “Dartmouth Summer Research Project”  organized by then-faculty John McCarthy in 1956 was first to use the term artificial intelligence as well as the birthplace of LISP. Thomas Kurtz pointed to these historical events as priming Dartmouth for BASIC <sup id="fnref6:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>The fact that Dartmouth attracted such attention to computing was key to the development of DTSS and BASIC, but even more important was that Dartmouth is a small liberal arts university, focused on undergraduates as both researchers and students. Kemeny and Kurtz were savvy enough to align their goals with the goals of the institution:  “the administration and the Board of Trustees of Dartmouth gave us their full support as they, too, realized and accepted the goal of  universal  computer training for liberal arts students” <sup id="fnref2:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. Myron Tribus, then the Dean of the Thayer School of Engineering and a staunch advocate of Kemeny and Kurtz’s work, wrote of the original design principles behind Dartmouth computing:</p>
<blockquote>
<p>I remember quite vividly an afternoon conversation with John Kemeny in which we agreed that certain requirements would be met even if it meant indefinitely postponing the computer.<br>
Students would have free access.  There would be complete privacy. No one would know what the students were doing.  The system should be easy to learn. The computer should contain its own instructions.  The system would be designed to save the time of the user even if it appeared that the computer was being wasted.  Turnaround time should be sufficiently rapid that students could use the system for homework.  The system should be pleasant and friendly.</p>
</blockquote>
<p>Tribus memo, 1977, quoted in<a href="#kurtz1981">Kurtz 1981</a>, 520 Kemeny and Kurtz stayed true to this vision in the technical and semantic decisions they made for BASIC, how the student computer time would be charged, and in the social structure they set up in the computing lab.</p>
<p>With computer literacy as a goal — rather than any grant-sponsored research agenda — the Dartmouth computing project could embrace uses of the computer that would engage students. FTBALL was an example of one of those engaging uses of the computer. As Kemeny and Kurtz noted in their final grant report for the NSF, the use of computers for games is not frivolous at all. They maintained that there was no better way to dispel fear of the computer than to play games, and that programming games was a great way to learn computing.</p>
<h2 id="basic-ftball-as-a-computer-game">BASIC FTBALL as a computer game</h2>
<p>The high expense of early computing and the seriousness of it — applications for war and big science such as ballistics, cryptography, engineering and physics — would seemingly work against its recreational applications. But there was a playful side to computing from the start. The Mark II at Manchester had a loudspeaker that emitted sounds from certain instructions, and Alan Turing discovered that the hooter could produce musical notes by repeating these instructions. In an all-night programming session, Christopher Strachey composed  “God Save the Queen”  with these instructions and, consequently, landed himself a job at the lab. A recently restored recording session from 1951 captures this plus  “Baa Baa Black Sheep”  and  “In the Mood,”  composed perhaps collaboratively by Strachey and other members of the lab <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. In 1952, Strachey wrote a  “Love Letters”  program that spat out saccharine and silly statements such as DARLING CHICKPEA, YOU ARE MY AVID ENCHANTMENT signed M.U.C. for Manchester University Computer <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>. Allen Newell, J.C. Shaw and Herb Simon wrote a chess game at Rand Corporation in the 1950s; chess has been a testing game for AI ever since <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. The game  <em>Spacewar!</em>  had been written at MIT in 1962 on an inexpensive DEC PDP-1, which had a primitive CRT graphic display.  <em>Spacewar!</em>  circulated among university and business computing site for years and was famously described by Stewart Brand in a 1972 issue of  <em>Rolling Stone</em>   <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. IBM attempted to ban it for its unseriousness, but then rescinded the ban because the game itself was a lab for computational experiments.  “Ready or not, computers are coming to the people,”  Brand wrote <sup id="fnref1:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. As Brand and so many others recognized in the 1950s and ‘60s, games of all kinds were an ideal conduit for learning about computing.</p>
<p>So, there was precedent for Dartmouth FTBALL as a recreational use of computers. And while Kemeny and Kurtz were serious mathematicians, they recognized that to encourage computing, recreational applications such as games were key. In his notes for a public lecture, Kemeny noted that FTBALL was  “pure fun”  and that  “Writing Games”  was a  “Great way to learn programming”  [<a href="#figure01">Fig. 1</a>].</p>




























<figure ><img loading="lazy" alt="Black pen handwriting on lined, yellowed paper. The text is formatted as an outline with each point on a new line and reads: 4.) Entertain, YOUGUESS***, Educational, FTBALL***, Pure Fun, Writing games! Great way to learn programming" src="/dhqwords/vol/17/2/000696/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000696/resources/images/figure01_huf9c7f9d3ee2d0c34b52cd10ec1e3c1ca_602581_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000696/resources/images/figure01_huf9c7f9d3ee2d0c34b52cd10ec1e3c1ca_602581_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000696/resources/images/figure01.png 880w" 
     class="landscape"
     ><figcaption>
        <p>Kemeny&rsquo;s notes from a lecture on the use of computers, showing their many uses. Kemeny&rsquo;s notes from a lecture on the use of computers, showing their many uses. The notes read: “4. Entertain / YOUGUESS*** / Educational / FTBALL*** / Pure fun / Writing games: Great way to learn programming” Kemeny Papers, Dartmouth College, Rauner Library, accessed 2016.
        </p>
    </figcaption>
</figure>
<p>FTBALL wasn’t the only game at Dartmouth, either. In the 1967 final report on their grant for the NSF, Kemeny and Kurtz wrote,  “Our library contains some 500 programs, including many games. We have found that a computer is an efficient and inexpensive source of entertainment” <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. They go on to describe the games briefly:  “The student can challenge the computer to a game of three-dimensional tic-tac-toe, or quarterback Dartmouth&rsquo;s football team in a highly realistic match against arch-enemy Princeton. The program is somewhat biased — Dartmouth usually wins” <sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. A local survey in 1967 revealed that Dartmouth students used the computer for leisure one-third of the time and enjoyed playing games <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. The other games in the local library of programs were compelling, but FTBALL was exceptionally popular.</p>
<p>In Kemeny’s first version, FTBALL was a one-player game, though later versions were multiplayer. A more detailed explanation of how the code worked is in a subsequent section, but here is the basic gameplay. The player — likely a Dartmouth undergraduate associated with the lab, or with connections to it — would queue up FTBALL from the lab’s library and be greeted with this opening:</p>
<pre tabindex="0"><code>THIS IS DARTMOUTH CHAMPIONSHIP FOOTBALL YOU WILL QUARTERBACK DARTMOUTH. CALL PLAYS AS FOLLOWS: 1 = SIMPLE RUN; 2 = TRICKY RUN; 3 = SHORT PASS; 4 = LONG PASS; 5 = PUNT; 6 = QUICK KICK;&#39; 7 = PLACE KICK. TOSS OF COIN. (TYPE A NO. FROM 1 TO 300)
</code></pre><p>The game features typical football plays familiar to any fan, so no further explanation was given. Note that although the game is played against Princeton, Princeton isn’t mentioned initially, and the player can only quarterback for Dartmouth. After this intro prompt, the player then enters a number for the coin toss, which results in either Princeton or Dartmouth winning the coin toss and the console’s printout indicating</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">PRINCETON WON THE TOSS
</code></pre><p>or</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">DARTMOUTH WON THE TOSS
</code></pre><p>. For either team’s kickoff, the ball starts on the team’s own 20-yard line, which simulates the team taking a knee at the kickoff. When Dartmouth is on offense, the player can then input plays 1-7; however, when Princeton is on offense, the program chooses plays for Princeton. The program kept track of who was on offense, yardage for plays, downs, position on the field, and gave results of plays such as interceptions, successful kicks, and touchdowns. The game continued for at least 50 plays, and each play beyond that had a 20% chance of ending the game. The game ending indicated a final score:</p>
<pre tabindex="0"><code>END OF GAME *** FINAL SCORE: DARTMOUTH S(2); PRINCETON S(0)
</code></pre><p>The console printed the value of the variables for Dartmouth’s and Princeton’s score, and the FTBALL program ended.</p>
<p>A public conversation between Nancy Broadhead, an operator and self-described housemother at the lab, and John Kemeny at the National Computer Conference in 1974 provides some context for FTBALL’s origin and role at Dartmouth computing:</p>
<blockquote>
<p>Nancy Broadhead<br>
Speaking of phone calls and things, one of probably the earliest programs in the program library was FTBALL. A lot of us here know who wrote it. I remember one night we had been apparently having some problem somewhere along the line and I got a phone call at home one night to tell me in absolute panic, FTBALL has been clobbered in the library! I live a good half hour away from Dartmouth and I really wasn&rsquo;t about to jump in the car and trot in to reload it from cards, or paper tape was probably what we had for backup at that point. So I just sort of sleepily said Well, I&rsquo;ll put it back in the morning. [To Kemeny:] What did you really expect me to do?<br>
John Kemeny<br>
We were probably trying to recruit a new football coach and that seemed so terribly important. I don&rsquo;t remember who wrote it [Kemeny was being facetious here!] but I do remember when that program was written, it was written on a Sunday. Those were the good days when time-sharing still ran on Sundays. It was written on Sunday after a certain Dartmouth-Princeton game in 1965 when Dartmouth won the Lambert trophy. It&rsquo;s sort of a commemorative program.<br>
<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></p>
</blockquote>
<p>Kemeny’s playful refusal to claim authorship of the program in front of an audience who would have known otherwise recalls the playfulness of the program itself.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>  And yet his description of the possible context that drove him to call Broadhead after-hours also suggests that the program was more than fun: it served as a demonstration program for a non-expert to see what Dartmouth computing could do. In their report on the grant, Kemeny and Kurtz write,  “We have lost many a distinguished visitor for several hours while he quarterbacked the Dartmouth football team in a highly realistic simulated game” <sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Kemeny’s FTBALL game, written on a Sunday in response to a real-world game between Dartmouth and Princeton, would have appealed to the local undergraduates, but it also had real-world applications for recruiting and impressing distinguished visitors.</p>
<p>Games, including FTBALL, were among the more popular exports of the Dartmouth computing library over the DTSS network that included local high schools in Hanover and neighboring Lebanon as well as regional colleges.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>  Members of the network also wrote games, exemplifying Kemeny and Kurtz’s claim in their final grant report to the NSF in 1967 that  “most of the games have been programmed by our students, which is an excellent way to learn programming”   <sup id="fnref4:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Rankin names a few of the projects of students listed in the  <em>Kiewit Comments</em>  from 1967, including solitaire by 12-year-old David Hornig and checkers by 13-year-old Julia Hawthorne <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Game programs were popular at Exeter Academy, an exclusive, all-male (at the time) prep school 100 miles southeast from Dartmouth College that joined the Dartmouth network early on. John Warren, the collaborating teacher at Exeter who later trained other secondary school teaching partners when they joined the network, claimed in 1966 that Exeter  “students and faculty have written several thousand programs,”  and that games were not  “idle pasttimes”  because writing them took serious skill <sup id="fnref2:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Traditional sports and card games such as football were early entries in American computer gaming in part because of their cultural familiarity — they required few directions to players. Moreover, the scoring of traditional card and sports games could be represented in numbers, which computers handled easily. Many Americans already knew the basic rules for solitaire, checkers, tennis, and football, so they could draw on existing knowledge to play these games in the limited interfaces of early computers. It’s perhaps no accident that  <em>Tennis for Two</em>  was the first known interactive video game (written with graphics on an oscilloscope), followed by the popular  <em>Pong</em>  by Nolan Bushnell in 1972 <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>. A space game Bushnell released in 1971 sold few units, but the stripped-down interface of  <em>Pong</em>  and the relatable action of hitting a ball across a net led to  <em>Pong</em> ’s huge popularity a year later <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. Like FTBALL,  _Pong _ and  <em>Tennis for Two</em>  were iterations of a game many people already knew how to play. Preceding arcades and graphical interfaces of later football games, FTBALL was a purely textual and turn-based game, but in 1965, sports fans would have been familiar with radio broadcasts of play-by-play commentary in football and baseball.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>  Consequently, the low-bandwidth of the game’s textual version of football would not have seemed so clunky to contemporary users as it might to modern players used to graphical depictions of games.</p>
<p>Later football games, arguably influenced by FTBALL, have been big players in the genre of sports games.  <em>Atari Football</em>  (1978) was popular in arcades, as was Atari’s home version for VCS, which was released the same year. Home console football games for the Intellivision and Nintendo NES continued the trend with  <em>NFL Football</em>  (1979),  <em>10 Yard Fight</em>  (1983) and  <em>Tecmo Bowl</em>  (1987) <sup id="fnref1:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. Then came one of the most popular video game franchises ever:  <em>John Madden Football</em> , released in 1988 by Electronic Arts and again yearly since 1990.  <em>Madden</em>  combines complex plays and detailed graphics with official licensing from the American National Football League (NFL), enabling former NFL coach and famous football color commentator John Madden to narrate plays that reflect real NFL strategies and recognizable NFL players and franchises.  <em>Madden</em>  is often seen as the first game that non-computer nerds took up beginning in the early 1990s. It also drew new fans into football by teaching scoring, plays, and strategies. More recent versions even include mechanics about team rosters and salary caps, so players learn about the NFL as well as the plays and strategies of football. Because so many current NFL players and coaches now grew up playing it,  <em>Madden</em>  has influenced the sport itself <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>, an interesting reversal from early computer games influenced by sports.</p>
<p>Because they translate well and rely on cultural knowledge not associated with computing knowledge, sports games have helped to bring computer games to a wider audience. Sports games also affected the evolution of computer games more generally, according to John Wills in  <em>Gamer Nation</em> :</p>
<blockquote>
<p>[T]hese early sports games enshrined the medium of video games as fundamentally sport-like and competitive. The opportunity to play American sports proved eminently attractive, and game consoles sold on their strength of sports titles. Video games served as an extension of fan service, part of the ritual of following favorite teams and championship events…<br>
<sup id="fnref2:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>FTBALL is thus part of this early lineage of fan service, both at Dartmouth specifically — it celebrated a Dartmouth championship game, after all — and in sports and computer games more generally.</p>
</blockquote>
<p>Examining the cultural context, Rankin associates the popularity of FTBALL and its subsequent iterations with the masculine culture of Dartmouth computing. Dartmouth then and now is associated with a kind of jock culture and was all-male at the time Kemeny composed FTBALL. Rankin drew on interviews and archives to describe the Dartmouth computing lab scene in which FTBALL was played: Dartmouth men courting women students from nearby Mount Holyoke College, prank-calling teletypes, error messages that ribbed fellow student-workers, and frequent late night computing sessions. The participants and culture of the lab were inevitably shaped by the demographics of Dartmouth at the time. And beyond Dartmouth, dominant masculinity in computing spaces shaped the culture and kinds of programs developed in these spaces. Games of contestation — especially those that echo the masculinity of fighting, war, and sports — figure prominently in computing game history <sup id="fnref3:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. This dominant and dominating thread of masculinity in computing and in gaming is being pried apart by contemporary historians of computing such as Rankin, Janet Abbate, Mar Hicks and Nathan Ensmenger. The scene at Dartmouth computing in the basement of College Hall was certainly shaped by the fact that all the students were men, most of them white and some from affluent backgrounds, although many of the students who worked with Kemeny and Kurtz did so through work-study support <sup id="fnref3:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. It is important to note however, that Kemeny and Kurtz, as math Professors, did not have control over the student body’s composition at the time. Later, as President of the College, Kemeny pushed for and presided over Dartmouth’s 1972 transition to co-education, along with developing programs to expand Native American student enrollment <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.</p>
<p>Kemeny was an avid fan of Dartmouth football, and he often attended games with his math colleagues. As one of his colleagues recalled,  “They made all manner of bets based on probabilities of obscure game occurrences, such as the odds on three flags being thrown twice in a quarter” <sup id="fnref2:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. Kemeny wrote FTBALL on Sunday, Nov 21, 1965, a celebration of Dartmouth winning the Lambert trophy in a surprise upset against Princeton on Nov 20, 1965.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>  The game featured in FTBALL is between Dartmouth and Princeton, but Princeton isn’t in the title — it’s  <em>Dartmouth</em>  Championship Football. The title and the opponent, a major Ivy League rival, presumes an internal audience of Dartmouth football fans. As Kemeny and Kurtz admitted,  “The program is somewhat biased — Dartmouth usually wins” <sup id="fnref5:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Quarterbacking for Dartmouth, users could choose among seven different running, passing, and kicking plays. At the time that Kemeny wrote the game, BASIC was interactive — it could take input from the user unlike earlier versions of BASIC — but it wasn’t yet capable of multiplayer games. A later iteration of FTBALL was multiplayer and announced as  <em>FOOTBALL</em>  in the Nov 1969  <em>Kiewit Comments</em>  newsletter <sup id="fnref3:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Rankin noted the significance of this networked version, as it meant that students at Kiewit could play  <em>FOOTBALL</em>  with others in the local DTSS New England network, including secondary schools and other colleges in the area <sup id="fnref4:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Beyond the Dartmouth network, the offspring of Dartmouth Championship FTBALL had longstanding appeal outside of Dartmouth as well.  <em>FOOTBL</em>  ( “Professional football” ) and  <em>FOTBAL</em>  ( “High School football” ) circulated in the first BASIC computer games book, written by David Ahl and published by DEC in 1973 <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>. The 1978 edition featured Dartmouth Championship Football with the byline of Raymond Miseyka, though credit was given in the accompanying text to John Kemeny for the original version. The 1978 version of FTBALL is clearly based on Kemeny’s: for instance, it features Kemeny’s original seven plays. It augments Kemeny’s original by allowing the user to input an opponent name, handling errors, and including chance events like  “</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GAME DELAYED. DOG ON THE FIELD.
</code></pre><p>”  This line refers to a bizarre but regular occurrence in 1960s Dartmouth football: wild dog stoppages. According to Jean Kemeny’s memoir  <em>It’s Different at Dartmouth</em> , wild dogs often ran free on campus and then occasionally on the football field during game days, where they would delay play.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>  In the version from Ahl’s book, the remark (REM) reads: JEAN’S SPECIAL, suggesting this feature was added by Kemeny. The fact that Miseyka’s version works from Kemeny’s is further indication of the free circulation of BASIC games during this period. As the authors of  <em>10 PRINT</em>  demonstrate, the BASIC language and programs traveled widely and freely and thus shaped computational culture in the 1960s through the 1980s <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. In the  “Acknowledgements”  of  <em>BASIC Computer Games</em> , Ahl thanks Dartmouth College  “For recognizing games as a legitimate educational tool and allowing them to be written on the Dartmouth Timesharing System” <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>.</p>
<p>Ahl also thanks Microcomputer Manufacturers  “for putting computer games within the reach of every American in the comfort of their own home.”  The first wave of mass-market home computers hit just prior to his publication; many of them shipped with a version of BASIC preinstalled, and games were indeed a popular application — both the playing and writing of them. Although the success of BASIC with home computers wasn’t necessarily anticipated by Kemeny and Kurtz, the technical decisions they made about the language as well as the way they allowed it to freely circulate were key to its popularity.</p>




























<figure ><img loading="lazy" alt="A monochrome scanned page of a book offering a brief summary of how to play the 1978 version of FTBALL in the left column of text and a sample play-through in the right column. Below both columns is a line drawing cartoon of a wheeled-robot holding a football with the words Green Bay printed on its side." src="/dhqwords/vol/17/2/000696/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000696/resources/images/figure02_hu1555a032420d6671696a6c7f89c2daa4_398173_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000696/resources/images/figure02_hu1555a032420d6671696a6c7f89c2daa4_398173_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000696/resources/images/figure02.png 1090w" 
     class="portrait"
     ><figcaption>
        <p>FTBALL as printed in 1978 Edition of BASIC Computer Games. <a href="https://annarchive.com/files/Basic_Computer_Games_Microcomputer_Edition.pdf">https://annarchive.com/files/Basic_Computer_Games_Microcomputer_Edition.pdf</a>, 64.
        </p>
    </figcaption>
</figure>
<h2 id="hardware-and-technical-details">Hardware and technical details</h2>
<p>Early versions of BASIC and DTSS ran on GE computer hardware, which was purchased with the NSF grants that Kemeny and Kurtz obtained, support from Dartmouth College, and discounts from GE.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>  The first iteration of BASIC/DTSS (Phase I), which ran from 1964 to sometime in 1967, ran on two computers: a GE-235 to execute programs and a GE Datanet-30 to handle communications with the teletypes and to schedule the execution of programs on the 235 <sup id="fnref1:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. Undergraduate Anthony Knapp had designed an early version of this setup with Kurtz <sup id="fnref7:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Kemeny had borrowed a GE-225 in the Boston area to prototype the BASIC compiler in 1963, and Kurtz and undergraduate Mike Busch ‘66 traveled to GE in Phoenix, Arizona, to learn how to program the equipment <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. The Dartmouth team called the resulting hybrid system the GE-265 because it was a marriage between the GE-235 and Datanet 30.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>  As Kemeny and Kurtz wrote in 1968, this two-part  “system anticipated the current understanding that communication, not calculation, is the primary activity in a time-sharing system” <sup id="fnref2:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>  The DTSS thus signaled a new computing paradigm: the most exciting challenges and affordances of computer systems in the 1960s were related to communication as opposed to the calculation paradigm of the previous decade.</p>




























<figure ><img loading="lazy" alt="A black and white image of the General Electric Datanet-30. The computer resembles three refridgerators in size and form, with the right-most door being cut short by an access panel with indicator lights." src="/dhqwords/vol/17/2/000696/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000696/resources/images/figure03_hu46d199f9cccbb07ec45b7a7668ddc6cd_1122776_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000696/resources/images/figure03_hu46d199f9cccbb07ec45b7a7668ddc6cd_1122776_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000696/resources/images/figure03_hu46d199f9cccbb07ec45b7a7668ddc6cd_1122776_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000696/resources/images/figure03.png 1478w" 
     class="landscape"
     ><figcaption>
        <p>Datanet-30, which handled communications between the GE-235 and teletypes in the BASIC/DTSS system in 1965. From the GE Datanet-30 programming manual.
        </p>
    </figcaption>
</figure>
<p>Jerry Weiner was the GE project manager working with the Dartmouth team; he flew in system parts when they burned them out. He noted that:  “Although the Datanet 30 was standard off the shelf, it was standard off the shelf numbered double zero and one of ten unique machines. We rebuilt it without telling other people” <sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. Kurtz provided more detail on their choice of the GE system when I spoke with him in 2017:</p>
<blockquote>
<p>We looked around for computers that we thought could do time-sharing. Now, there was no timesharing software available in the market, but we were looking for computers which would lend themselves to this. And we got proposals from four companies or something like that. Including IBM proposed something similar to what they were doing down at MIT, and others. BENDIX proposed something, and General Electric had a computer department in those days, and for some strange reason they had their regular computer which was called GE-225, which is an old-fashioned machine that used punch cards and so on. Then they had another computer which was designed to support a teletype communication network, they called it the DATANET-30, and it was designed to allow teletypes to communicate the same way as phones. […] [The main machine had] floating point hardware, which we felt was essential. […] I don’t know what the application was that they were thinking of, but along the way — and I don’t know if they really knew what they were doing — along the way they figured out a computer interface unit to put these two computers together. They hadn’t done anything with it, but that was available as something you can buy from them.<br>
<sup id="fnref1:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> The descriptions from Weiner and Kurtz are indicative of computing hardware at the time: even the off-the-shelf systems were bespoke and uncharted.</p>
</blockquote>
<p>The GE-225 had been designed, in part, by Arnold Spielberg, the father of Steven Spielberg. In an internal GE publication, the younger Spielberg recalled,</p>
<blockquote>
<p>I remember visiting the [GE plant in Phoenix, AZ] when dad was working on the GE-225&hellip;.] I walked through rooms that were so bright, I recall it hurting my eyes. Dad explained how his computer was expected to perform, but the language of computer science in those days was like Greek to me. It all seemed very exciting, but it was very much out of my reach, until the 1980s, when I realized what pioneers like my dad had created were now the things I could not live without.<br>
<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup></p>
</blockquote>
<p>The GE-225 was designed in 1959, and with dozens of early sales, it was a marketing success. Several banks bought the GE-225, and a machine at First Union National Bank predicted the 1964 Johnson-Goldwater race. Related to FTBALL, a GE-225 was used by the Cleveland Browns for ticket sales. As  <em>GE Reports</em>  quotes,  “ “Who knows,”  quipped the Browns’ president Art Modell in 1966,  “there might come a time when computers will help call the next play.” ”   <sup id="fnref1:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup></p>
<p>BASIC was designed with a teletype interface rather than punch cards for accessibility reasons <sup id="fnref8:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Along with better teletypes for interfacing, the development of ASCII in 1963  “came along in the nick of time” <sup id="fnref9:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Following up on his description of the GE-265 setup, Kurtz narrated:</p>
<blockquote>
<p>Then we would set this up and the whole idea was, we would put teletype machines in the various departments around on campus; we’d have a place where students could go and sit on a teletype machine and write programs.<br>
<sup id="fnref7:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> When FTBALL was written (1965), there were about 30 of the Teletype Models 33 and 35 terminals around campus and the computing lab was located in College Hall. They were planning to replace the hardware with a GE-635 and move to a new building; the Kiewit Center was dedicated in 1966 <sup id="fnref10:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. With this bespoke hardware setup for FTBALL sketched out, we can move into the language design of BASIC at the time.</p>
</blockquote>
<h2 id="basic-as-a-beginners-language">BASIC as a beginner’s language</h2>
<p>In the early 1960s, computation was at such a premium that most computer experts believed that languages needed to prioritize computational efficiency at the expense of usability. Mark Marino discusses John von Neumann’s supposed response to FORTRAN as a more accessible language: he believed that it was a waste of computer time to have it do the clerical work of legibility and style. This tradeoff takes on a gendered meaning given that clerical staff and computer technicians were often women, while the machine language writers and designers were men <sup id="fnref1:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. Kemeny and Kurtz did not share von Neumann&rsquo;s view. Kurtz had come to the realization — after finding FORTRAN more efficient than assembly languages, which were more prone to human error — that the tradeoff between human use and computational efficiency wasn’t so simple. A language that was easier to use would be quicker for students to learn, more students could learn it, and they would be more successful in their programs. Kurtz explained in an internal memo from 1963:  “In all cases where there is a choice between simplicity and efficiency, simplicity is chosen”  (quoted in<a href="#kurtz1981">Kurtz 1981</a>, 520). Consequently, a number of technical decisions were made in BASIC to prioritize simplicity and legibility of the language over computational efficiency.</p>
<p>Some examples of technical choices Kemeny and Kurtz made to simplify BASIC include: hiding object code from the user, who could make edits directly in BASIC by using line numbers; keeping case-insensitivity even when 8-bit ASCII allowed for both upper and lower case; and reducing compiling time by skipping an intermediary language <sup id="fnref2:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. BASIC treated numbers in ways that valued an intuitive sense of users over computation time. For example, BASIC wasted computer time by treating all numbers as double-precision floating point numbers, the most computationally expensive and precise representation of numbers at the time, rather than having users specify number type.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>  Moreover, the user didn’t need to know about formatting the number for printing, as other languages required.</p>
<p>Commands in BASIC were designed to be  <em>friendly</em>  (see the <a href="#kurtz1981">Tribus memo</a> quoted above) and written in non-technical words lay English speakers would understand. BASIC used monitor commands such as</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">SAVE
</code></pre><p>,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">HELLO
</code></pre><p>,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">RUN
</code></pre><p>,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOODBYE
</code></pre><p>instead of</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LOGON
</code></pre><p>and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LOGOFF
</code></pre><p>. Short error messages in English and limited to only five messages per run of the code worked toward simplification as well as good pedagogy <sup id="fnref11:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. The use of English words and commands in BASIC were thought to make the program easier to understand. Of course, this assumes users would know at least basic English vocabulary, which was the case for any Dartmouth College student. In his analysis of FLOW-MATIC, which also relied on English vocabulary to make programs ostensibly easier to read, <a href="#marino2020">Marino</a> breaks down some of the challenges to English-syntax as accessible programming design (<a href="#marino2020">149-152</a>). Beyond the obvious critiques of Global English as a tool for colonization, because languages like FLOW-MATIC, COBOL, or BASIC cannot handle the complexities of English syntax, they end up reading as stilted and awkward rather than the natural language they aspire to. Whether they are more legible than more abstract symbolic representation is a matter of debate. However, for the very newest users who might be turned off by jargon — the very users Kemeny and Kurtz were aiming for — the friendlier HELLO might have helped them overcome an initial fear of computing.</p>
<p>Given BASIC’s purpose as a learning language, Kemeny and Kurtz built good pedagogical principles of composition feedback into the system itself. To encourage students to correct their own errors, Kemeny and Kurtz designed the compiler not to check line by line prior to compiling <sup id="fnref12:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. As they wrote in 1968,  “We find the instantaneous error messages of other systems annoying and a waste of time. It is very much like having an English teacher look over your shoulder as you are writing a rough draft of a composition. You would like a chance to clean up a draft before it is criticized” <sup id="fnref3:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. This insight aligns with best practices in writing feedback, especially in Writing Center research, that instructors giving too much attention to lower-order concerns such as individual grammar errors can detract from a writer’s own recognition of error patterns.</p>
<p>Though they steered away from instantaneous error messages that would discourage self-correction, Kemeny and Kurtz realized that rapid response was key for a timesharing system. Batch-processing, where a computer tech feeds in cards and users receive results hours later, was not going to work for casual users. But Kemeny and Kurtz saw that if users received a response to their program in less than 10 seconds in a timesharing system, users had the helpful illusion that the computer was  <em>theirs</em>   <sup id="fnref4:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. Interpreted languages could provide this more rapid feedback; however, they were more computationally expensive. Had BASIC been an interpreted language, it would have been prohibitive to run anything more complex than the simplest programs on the hardware they had available. Consequently, early versions of BASIC, including the one FTBALL is written in, were compiled rather than interpreted. Later versions of BASIC for minicomputers such as the PDP/8 were interpreted <sup id="fnref13:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>Recognizing the value of rapid feedback, Kemeny and Kurtz worked toward the one-pass ideal that interpreted languages offer by implementing a pass and a half system to speed up compiler time for BASIC <sup id="fnref14:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. The BASIC compiler could handle everything in one pass,</p>
<blockquote>
<p>with one exception — a</p>
</blockquote>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>statement could refer to a point later in the program, a point not yet reached by the compiler. The solution was to produce a linked-list of the location of</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>statements in the student’s program. At the end of the compile main run, it ran through the linked list, filling in the blanks. We sometimes called it a  “ pass and a half .”<br>
<sup id="fnref3:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>BASIC scaled well for more complex programs by using this single-pass plus linked-lists compiling design.</p>
<p>Earlier language development and experimentation set the stage for the development of BASIC, giving Kemeny and Kurtz key insights on what language features were critical to a student-oriented system and simplified user interface. At Dartmouth, they developed ALGOL 30, so-named because it ran on the LGP-30, which could not run a full implementation of ALGOL 60, an influential and popular language at the time, especially among academics. From ALGOL 30, which had to be run on paper tape and was a two-pass, batched system, they learned that  “the delays between presenting the source code tape and the execution were too great to allow for widespread student use.”  Subsequently, undergraduate (and later faculty member) Stephen Garland developed SCALP (Self Contained ALgol Processor), to avoid batching. The success of SCALP (hundreds of students learned it at Dartmouth in the early 1960s) taught Kemeny and Kurtz that quick turnaround and use of only source language for programming and patching were key for a system that might have wider implementation among students <sup id="fnref15:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. DOPE (Dartmouth Oversimplified Programming Experiment, written by Kemeny in 1962) was also a precursor to BASIC and contributed, among other things: line numbers that served as jump locations; interchangeable upper and lower case letters; printing and input formats <sup id="fnref16:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>Line numbers were how a BASIC program in 1965 managed program flow and edits. BASIC programs were typically organized by line numbers counted by 10s, which left space in-between for additions. Every line that began with a number was assumed by the system to be part of the program, and (through the pass and a half system) line numbers were automatically sorted in order so that additions, deletions and edits could be appended and then sorted correctly into the program flow at compile time. Commands that didn’t begin with line numbers were read as monitor commands <sup id="fnref17:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>The</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>command was used in program flow to jump to different parts of the program, often after conditional statements, e.g.,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO LINE 20
</code></pre><p>.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>was not an innovation of BASIC, as even FLOW-MATIC had used the command along with</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">JUMP TO
</code></pre><p><sup id="fnref2:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. Later, structured languages allowed for function call by name instead of line numbers and BASIC itself became a structured language in later versions. But in 1965,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>was the way to direct program flow to different functions based on input.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>was famously derided in an article by Edsgar Dijkstra in 1968,  “GOTO Considered Harmful” , which launched a whole genre of computer science articles on considered harmful practices in the profession. Dijkstra was opposed to</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>because the unique coordinates of the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>affected program flow but they were  “utterly unhelpful”  in tracing the progress of the program — that is, in the user figuring out just what was going on when. Moreover, the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>statement is  “too much of an invitation to make a mess of one’s program” <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>. As a result of Dijkstra’s influence, deriding</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>seems almost as popular a sport among programmers as football. However, the strong claim against</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>, especially for understanding program flow, isn’t clear. Frank Rubin wrote to  <em>Communications of the ACM</em>  in 1987 against the religious belief against</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>and pointed out examples where</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>reduced complexity in programs <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>. For new users who are unfamiliar with programming structures, following program flow by line number is simple. As with many choices for BASIC, Kemeny and Kurtz elected to implement what might be most self-explanatory for  <em>new</em>  users. With the background of these technical decisions in the language of BASIC itself, let&rsquo;s move on to the specific commands and code of FTBALL as representative of early BASIC in 1965.</p>
<h2 id="ftballs-code">FTBALL’s code</h2>
<p>The code for FTBALL is written in the third edition of BASIC, the first edition to be interactive — effectively, the first edition that was conducive to games. The first edition of BASIC was outlined in a reference manual, likely written by Kemeny; the second edition was described in a primer, likely written by Kurtz. These documentation shifts from technical manual to primer indicate how the Dartmouth team was developing the language to handle a larger scale of users. The third edition added the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">INPUT
</code></pre><p>statement to BASIC, which allows programs to take data from the user. This meant BASIC programs could change results based on user input. So, a user could play a game and expect the result of the game to be affected by their choices. The third edition manual is dated 1966 but since FTBALL was written in the fall of 1965 by Kemeny, it’s likely he was implementing the newer version of BASIC code ahead of the documentation of it <sup id="fnref18:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>FTBALL was called that because of a six-character limit for strings in BASIC at the time. All functions were limited to three characters:</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LET
</code></pre><p>,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">INT
</code></pre><p>,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">RND
</code></pre><p>are examples of such functions described below. Kurtz later called this decision  “unfortunate”  for legibility <sup id="fnref19:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. FTBALL also demonstrates the original BASIC convention of variables consisting of one letter and one number. Kemeny and Kurtz specified variables this way for the sake of time: shorter variables were quicker during the computer’s symbol table lookup. Plus, they figured it was faster to compose programs with shorter variable names and, because they were mathematicians, they were accustomed to single-letter variable names. It didn’t seem consequential to have variables named in this obscure way, although like the three-character function limit, it later became clear that more descriptive variable names might make the program easier for users to read <sup id="fnref20:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. But, as with any language design decision, the tradeoffs were often between legibility and how much space a program would take up. Characters took up space in memory.</p>
<p>As with every BASIC program of its time, each line of FTBALL contains an instruction number (line #), operation (such as</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LET
</code></pre><p>), and operand (e.g., a variable) <sup id="fnref21:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. And also demonstrated here, all BASIC statements begin with an English word, including the final</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">END
</code></pre><p>. Although the ASCII standard had recently allowed for lower-case letters and BASIC accepted them, the commands for FTBALL are in all-caps likely because of convention — either lower or upper case would have been interpreted the same <sup id="fnref4:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>The BASIC commands in use in FTBALL are (in the order they appear in the program):</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">REM
</code></pre><p>: comments or remarks. They didn’t pull the syntax of comments from FORTRAN or ALGOL, and Kurtz admits  “the reason is not recorded for choosing the statement</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">REM
</code></pre><p>or</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">REMARK
</code></pre><p>in BASIC” <sup id="fnref22:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">PRINT
</code></pre><p>: This command prints characters from the teletype. There were no automatic line breaks or wrap around on the paper output. Consequently, note that in the beginning prompt, there are two</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">PRINT
</code></pre><p>lines in a row to force breaking the directions into two lines. There are blank</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">PRINT
</code></pre><p>lines, too, just to print a space. (This technique is also featured on the cover of Rankin’s book.) The</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">PRINT
</code></pre><p>statement allowed for expressions and quoted material and used the comma as a separator. Later versions of BASIC required a colon or semicolon to separate the expression and the quoted material <sup id="fnref23:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">INPUT
</code></pre><p>: reads from a teletype file. This command made BASIC an interactive language and wasn’t present in the original BASIC <sup id="fnref24:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>; it came in the third edition of BASIC. It stopped program flow and waited for input from the user, prompted by ? It was usually accompanied by the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">PRINT
</code></pre><p>statement to specify what kind of</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">INPUT
</code></pre><p>was called for. The semicolon that accompanies the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">PRINT
</code></pre><p>statement at the beginning of FTBALL allows the teletype to stay on the same line and character position. (Alternatively, the comma keeps the teletype on the same line, but moves the character position over one column, or some multiple of 15 spaces from the left margin <sup id="fnref3:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>: This is a program flow command, enabling a permanent jump from one part of the program to another.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>is a sign of what is now called unstructured programming in light of later programming languages that controlled program flow by function name. The command is used here to jump to particular plays in the program.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOSUB
</code></pre><p>: This is another program flow command, but one which causes a temporary jump in program flow. The program jumps to a subroutine and then returns back to where it came from upon the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">RETURN
</code></pre><p>command. The</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOSUB
</code></pre><p>routines in FTBALL are at Line 4100, 4200 and 4300, which are part of the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">KEEP SCORE
</code></pre><p>subroutine, so it makes sense that they are called periodically as interruptions in the program.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LET
</code></pre><p>: This assignment statement allows for</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LET x=x+1
</code></pre><p>rather than the more standard (then and now)</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">x=x+1
</code></pre><p>because the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LET
</code></pre><p>made more sense to novices <sup id="fnref25:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. The similar appearance of the assignment statement and the equals statement was confusing to novice programmers (both then and now).</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">FOR
</code></pre><p>: This term came from ALGOL, although the three loop-controlling values (initial, final, step) came from FORTRAN. Kemeny and Kurtz borrowed  “the more natural testing for loop completion  <em>before</em>  executing the body of the loop”  from ALGOL <sup id="fnref26:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">NEXT
</code></pre><p>: This command is paired with</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">FOR
</code></pre><p>and used for stepping through a loop.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">IF/THEN
</code></pre><p>: This is a conditional statement common in programming languages then and now. There was no</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">ELSE
</code></pre><p>statement in BASIC at the time; the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">ELSE
</code></pre><p>is implied so that if the flow isn’t stopped by any of the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">IF
</code></pre><p>s, then the program flows automatically to the next statement (see <a href="#ftball">FTBALL Lines 190 and 191</a>). Conditional statements are so fundamental to programming that we see them first in Ada Lovelace’s writing on the Analytical Engine, the ENIAC allowed for such jumps, and they’re in FORTRAN as well. But FORTRAN at the time had 3-way branching (</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">IF
</code></pre><ul>
<li></li>
</ul>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">THEN
</code></pre><ul>
<li></li>
</ul>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">ELSE
</code></pre><p>) and BASIC’s was simplified to remove the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">ELSE
</code></pre><p>.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">RND
</code></pre><p>: This function provides a number between 0 and 1, not inclusive, to facilitate random chance in a simulation. As Kemeny and Kurtz explain,  “An important use of computers is the imitation of a process from real life. This is known as a simulation. Since such processes often depend on the outcome of chance events, a key tool is the simulation of random events” <sup id="fnref4:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">RND
</code></pre><p>was one of ten original functions provided with BASIC <sup id="fnref27:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. It required an argument, even a dummy one, an issue which they fixed later.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">INT
</code></pre><p>: This function turns a decimal number argument into an integer. Originally, it truncated toward zero — it just cut off any number after the decimal. It was designed to conform to the common floor math function in the third edition of BASIC.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">INT
</code></pre><p>is one of the original ten functions of BASIC.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">STOP
</code></pre><p>: This is the final statement of the main program flow.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">END
</code></pre><p>: Every BASIC program ended with this statement.</p>
<p>The main game loop of the FTBALL program begins at line 360, which increments the number of plays in the game (variable</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">T
</code></pre><p>) and either sends the program flow to the various possible plays (1-7, stored in variable</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">Z
</code></pre><p>) or to the end game sequence (lines 375-378).<sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>  The plays, result of play, and other possibilities come after that, with</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOSUB
</code></pre><p>used to direct program flow to those possibilities based on user input. The title to the program is in a</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">REM
</code></pre><p>(Remark) line and user is greeted with a series of print statements to initiate the game (the last</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">PRINT
</code></pre><p>statement simply prints a blank line, and being numbered 45 suggests that it was added later for aesthetic reasons):</p>
<pre tabindex="0"><code>0 REM  *  FTBALL  * 10 PRINT &#34;THIS IS DARTMOUTH CHAMPIONSHIP FOOTBALL.&#34; 20 PRINT &#34;YOU WILL QUARTERBACK DARTMOUTH. CALL PLAYS AS FOLLOWS:&#34; 30 PRINT &#34;1 = SIMPLE RUN; 2 = TRICKY RUN; 3 = SHORT PASS;&#34; 40 PRINT &#34;4 = LONG PASS; 5 = PUNT; 6 = QUICK KICK; 7 = PLACE KICK.&#34; 45 PRINT
</code></pre><p>In this initial version, there was no option to play for another team — users had to play for Dartmouth. These numbered plays refer to actual football plays and so a user familiar with football wouldn’t necessarily need a description in order to play. Even those unfamiliar with the specific plays could cycle through them just by entering the corresponding number.</p>
<p>Next, the program initializes three variables that will come into play in the game:</p>
<pre tabindex="0"><code>50 LET T = 0 60 LET S(0) = 0 70 LET S(2) = 0
</code></pre><p>Other variables that are relevant to the play are set elsewhere:</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">Y
</code></pre><p>keeps track of yardage on the plays</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">F
</code></pre><p>marks whether or not a play has failed (e.g., a fumble or interception)</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">X
</code></pre><p>is the yardage position on the field (Princeton goal is</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">X=100
</code></pre><p>; Dartmouth goal is</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">X=0
</code></pre><p>)</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">Z
</code></pre><p>is the play, according to the key revealed at the game’s beginning (1-7)</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">T
</code></pre><p>represents how many plays have occurred in the game. The game has at least 50 plays, and each play beyond that has a 20% chance of ending the game.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">D
</code></pre><p>keeps track of which down the offensive team is on</p>
<p>The program uses the same code for plays no matter if Princeton or Dartmouth are on offense, but it marks the distinction between the two with the variable</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">P
</code></pre><p>: if</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">P= -1
</code></pre><p>Dartmouth is on offense and if</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">P=1
</code></pre><p>Princeton is on offense. The user plays Dartmouth and calls the plays when they are on offense using the seven options offered at the start of the game. The block of code beginning with</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">2680 REM PRINCETON OFFENSE
</code></pre><p>begins the logic of the computer opponent, or game AI. Princeton’s choice of play on offense is governed by</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">RND
</code></pre><p>functions, which down Princeton is on, and how many yards to go. Kemeny could have had Princeton just randomly select a play 1-7, but this (somewhat dizzying block) of code provides a little strategy for the computer opponent, making the game more realistic and unpredictable — and probably more fun.</p>
<p>The code allots space for failures on plays such as interceptions and fumbles, which are marked with the variable</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">F
</code></pre><p>. Some aspects of the game are not simulated. For instance, the kickoff return results in the opposing team getting the ball on their 20-yard line, as if they had taken a knee upon receiving an average kickoff. The variable</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">T
</code></pre><p>counts the plays in the game up to 50, at which point the game ends or has an 80% chance of continuing.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">S(0)
</code></pre><p>is Princeton’s score and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">S(2)
</code></pre><p>is Dartmouth’s score; these are arrays that store values based on the results of plays. They are updated in the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LINE 4000-4220
</code></pre><p>block and are printed at</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">LINE 4200
</code></pre><p>and in the end game sequence. The</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOSUB
</code></pre><p>routine is one way the program flow gets to the score code block, and then the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">RETURN
</code></pre><p>takes the program back to where it left off:</p>
<pre tabindex="0"><code>4200 PRINT &#34;SCORE: &#34; S(2); &#34;TO&#34; S(0) 4210 PRINT 4220 RETURN 
</code></pre><p>The code for FTBALL is simple, but it’s difficult to read for a few different reasons, some of which were due to the design of BASIC at this time. Different functions for the plays are called by</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>s and line numbers rather than function names, so you can’t tell where the program is going unless you go to that line and figure it out. The line numbers clutter up the visual presentation of the code, and only the line numbers for lines that are called by the program through</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>s or</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOSUB
</code></pre><p>s actually provide information. The</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOTO
</code></pre><p>s and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">GOSUB
</code></pre><p>s in this version of FTBALL do indeed result in some spaghetti code in that different plays and results will jump around to a half-dozen arbitrary lines before resolving. (The later version in Ahl does away with some of this jumping.) The variables are single letters, which makes them difficult to understand what they represent. And in debugging, it is much more difficult to search for</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">Y
</code></pre><p>than Yardage, especially using the find tools available in a modernday editor. There are simple remarks (</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">REM
</code></pre><p>s) to demarcate different parts of the program, but they don&rsquo;t explain what it’s doing or where it’s going.</p>
<h2 id="exclusivity-alongside-accessibility-in-basic-ftball">Exclusivity alongside Accessibility in BASIC FTBALL</h2>
<p>The almost inscrutable code of FTBALL gestures at an inherent tension in BASIC programs of its time: while the program is written in the most famously accessible language in history, certainly the most accessible language of the mid-1960s, FTBALL was still only effectively accessible to a small group of people. Dartmouth was all male at the time and rather exclusive; the lab was very open but it appears that women only entered it as girlfriends or housemothers. There was some economic diversity among students who worked on the project, but little apparent ethnic or racial diversity. FTBALL drew on knowledge of a very popular American sport not previously associated with computing culture, but still a very masculine one, much moreso than tennis, for example. The math-influenced naming of variables and lack of comments made the code hard to read, especially for anyone coming from other academic traditions.</p>
<p>Yet, within these obvious constraints, Kemeny and Kurtz designed a novice-oriented programming language and licensed it so that it could catapult beyond Dartmouth’s high, ivy-covered walls. BASIC was simple enough that Kemeny was able to write a functional and fun game on a Sunday to commemorate a local football triumph. The game could run on the hardware Dartmouth had available in 1965, and it appealed to Dartmouth undergraduates, the main audience for FTBALL and for BASIC itself. The majority of Dartmouth undergraduates at the time learned BASIC, regardless of their major. And BASIC spread far beyond its exclusive origin through time-sharing, especially within nearby public and private high schools, as well as various subsequent dialects of the language that circulated because of its generous licensing. FTBALL spread BASIC as well, through the many versions of the game that circulated through popular books such as Ahl&rsquo;s and early computing networks. Kemeny&rsquo;s FTBALL inspired spinoffs in later versions of BASIC and helped to set the stage for other computer games, including more mass-market video games such as  <em>John Madden Football</em> .</p>
<p>FTBALL circulated along with BASIC in the 1960s through the 1980s, both helping to make computing more accessible and more fun. But their origins in the exclusive culture of Dartmouth reflected the exclusive nature of computing in the 1960s, a legacy that continues today. While inclusivity was clearly Kemeny and Kurtz&rsquo;s intent for BASIC, both BASIC and FTBALL were constrained by powerful sociotechnical networks over which they had little control. Computing in the 1960s had significant technical limitations and it was also coalescing around a masculine professional identity <sup id="fnref2:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Kemeny and Kurtz both benefited from elite academic networks but used BASIC to pry open those networks — just a bit. Put another way, FTBALL and BASIC were radically inclusive as well as products of their time. The sociotechnical history outlined here underscores this tension, which was inherent throughout midcentury computing for all initiatives.</p>
<h2 id="appendix-1-where-to-play-dartmouth-ftball">Appendix 1: Where to Play Dartmouth FTBALL***</h2>
<p>You can play Dartmouth FTBALL*** on the DTSS emulator written by John McGeachie and available here: <a href="http://www.dtss.org/dtss/">http://www.dtss.org/dtss/</a>. First register as a new user, then log in and select  “Program Entry”  from the upper right menu. You’ll be taken to the DTSS emulator. For the System prompt, type in OLD, then when it prompts  “OLD PROBLEM NAME,”  enter: FTBALL***. When it prompts READY, type RUN FTBALL***. Have fun!<br>




























<figure ><img loading="lazy" alt="DTSS EMulator user interface showing a sample play after typing RUN FTBALL***" src="/dhqwords/vol/17/2/000696/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000696/resources/images/figure04_hu6432b8dedf39e563fc55a020ca34927b_232577_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000696/resources/images/figure04_hu6432b8dedf39e563fc55a020ca34927b_232577_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000696/resources/images/figure04.png 1062w" 
     class="portrait"
     ><figcaption>
        <p>Screenshot of the DTSS Emulator
        </p>
    </figcaption>
</figure></p>
<h2 id="appendix-2-ftball-john-kemeny-dartmouth-college-1965">Appendix 2: FTBALL*** John Kemeny, Dartmouth College, 1965</h2>
<pre tabindex="0"><code>0 REM  *  FTBALL  * 10 PRINT &#34;THIS IS DARTMOUTH CHAMPIONSHIP FOOTBALL.&#34; 20 PRINT &#34;YOU WILL QUARTERBACK DARTMOUTH. CALL PLAYS AS FOLLOWS:&#34; 30 PRINT &#34;1 = SIMPLE RUN; 2 = TRICKY RUN; 3 = SHORT PASS;&#34; 40 PRINT &#34;4 = LONG PASS; 5 = PUNT; 6 = QUICK KICK;&#39; 7 = PLACE KICK.&#34; 45 PRINT 50 LET T = 0 60 LET S(0) = 0 70 LET S(2) = 0 100 PRINT &#34;TOSS OF COIN. (TYPE A NO. FROM 1 TO 300)&#34;; 120 INPUT Z1 140 FOR I = 1 TO Z1 160 LET X = RND(X) 180 NEXT I 190 IF RND(Z) &amp;gt; 1/2 THEN 195 191 PRINT &#34;PRINCETON WON THE TOSS&#34; 193 GOTO 2180 195 PRINT &#34;DARTMOUTH WON THE TOSS&#34; 200 PRINT &#34;DARTMOUTH BALL ON ITS OWN 20.&#34; 220 LET P = 1 240 LET X = 20 260 LET X1 = 20 280 LET D = 1 300 GOTO 2300 320 PRINT &#34;NEXT PLAY&#34;; 340 INPUT Z 360 LET R = RND(Z) 362 LET R = R*(.97+P*.03) 370 LET T = T+1 372 IF T &amp;lt; 50 THEN 380 374 IF RND(Z) &amp;gt; .2 THEN 380 375 PRINT 376 PRINT &#34;END OF GAME ***&#34; 377 PRINT &#34;FINAL SCORE:   DARTMOUTH&#34; S(2); &#34;PRINCETON&#34; S(0) 378 STOP 380 LET R1 = RND(Z) 400 LET F = 0 420 IF Z &amp;gt; 4 THEN 520 440 IF Z = 1 THEN 620 460 IF Z = 2 THEN 700 470 PRINT &#34;PASS PLAY&#34; 480 IF Z = 3 THEN 820 500 GOTO 1140 520 REM PUNT 540 LET Y = INT(100*(R-.5)^3+35) 545 IF Z = 7 THEN 5000 550 IF D = 4 THEN 560 555 LET Y = INT(Y*1.3) 560 PRINT &#34;PUNT GOOD FOR&#34; Y; &#34;YARDS&#34; 562 IF D&amp;lt;4 THEN 580 564 LET Y1 = INT(R1^2*20)+(1-P)*INT(R^2*30) 566 PRINT &#34;RUN BACK FOR &#34; Y1; &#34;YARDS&#34; 568 LET Y = Y-Y1 580 LET F = -1 600 GOTO 1480 620 REM SIMPLE RUN 630 PRINT &#34;RUNNING PLAY&#34; 640 LET Y = INT(24*(R-.5)^3+3) 660 IF R1 &amp;lt; .05 THEN 760 680 GOTO 1260 700 REM TRICKY RUN 710 PRINT &#34;RUNNING PLAY&#34; 720 LET Y = INT(20*R-5) 740 IF R1 &amp;gt; .1 THEN 1260 760 LET F = -1 780 PRINT &#34;*** FUMBLE AFTER &#34;; 800 GOTO 1260 820 REM SHORT PASS 840 LET Y = INT(60*(R1-.5)^3+8) 860 IF R &amp;lt; .05 THEN 960 880 IF R &amp;lt; .15 THEN 1080 900 IF R &amp;lt; .55 THEN 1020 920 PRINT &#34;COMPLETE.   &#34;; 940 GOTO 1260 960 PRINT &#34;INTERCEPTED.   &#34; 980 LET F = -1 1000 GOTO 1480 1020 PRINT &#34;INCOMPLETE.   &#34;; 1040 LET Y = 0 1060 GOTO 1260 1080 PRINT &#34;PASSER TACKLED.   &#34;; 1100 LET Y = - INT(10*R1) 1120 GOTO 1260 1140 REM LONG PASS 1160 LET Y = INT(160*(R1-.5)^3+30) 1180 IF R &amp;lt; .1 THEN 960 1200 IF R &amp;lt; .25 THEN 1080 1220 IF R &amp;lt; .70 THEN 1020 1240 GOTO 920 1260 REM RESULT OF PLAY 1280 LET X2 = X + P*Y 1300 IF X2 &amp;gt;= 100 THEN 1640 1320 IF X2 &amp;lt;= 0 THEN 2380 1340 IF Y &amp;lt; 0 THEN 1420 1360 IF Y = 0 THEN 1460 1380 PRINT &#34;GAIN OF &#34; Y &#34;YARDS&#34; 1400 GOTO 1480 1420 PRINT &#34;LOSS OF &#34; -Y; &#34;YARDS&#34; 1440 GOTO 1480 1460 PRINT &#34;NO GAIN&#34; 1480 LET X = X + P*Y 1500 IF X &amp;lt;= 0 THEN 2380 1520 IF X &amp;gt; 50 THEN 1580 1540 PRINT &#34;BALL ON DARTMOUTH &#34; X; &#34;YARD LINE.&#34; 1560 GOTO 1940 1580 IF X &amp;gt;=  100 THEN 1640 1600 PRINT &#34;BALL ON PRINCETON &#34; 100-X ; &#34;YARD LINE.&#34; 1620 GOTO 1940 1640 IF P &amp;lt; 0 THEN 1780 1660 IF F &amp;lt; 0 THEN 1740 1680 PRINT &#34;TOUCHDOWN***&#34; 1700 LET P = -1 1710 GOSUB 4300 1720 GOTO 2180 1740 PRINT &#34;TOUCHBACK FOR PRINCETON***&#34; 1760 GOTO 2180 1780 IF F &amp;lt; 0 THEN 1900 1800 PRINT &#34;SAFETY***&#34; 1810 GOSUB 4100 1820 PRINT &#34;DARTMOUTH GETS BALL ON ITS OWN 40.&#34; 1840 LET X = 40 1860 LET P = 1 1880 GOTO 2220 1900 PRINT &#34;TOUCHDOWN DARTMOUTH ***&#34; 1910 GOSUB 4300 1920 GOTO 2180 1940 LET D = D+1 1960 IF F &amp;gt;= 0 THEN 2120 1980 IF P &amp;gt; 0 THEN 2060 2000 PRINT &#34;DARTMOUTH&#39;S BALL&#34; 2020 LET P = 1 2040 GOTO 2220 2060 PRINT &#34;PRINCETON&#39;S BALL&#34; 2080 GOTO 2210 2120 IF P*(X-X1)&amp;gt;=10 THEN 2220 2140 IF D &amp;lt; 5 THEN 2300 2150 IF P&amp;lt;0 THEN 2000 2160 GOTO 2060 2180 LET X = 80 2200 PRINT &#34;PRINCETON BALL ON ITS OWN 20.&#34; 2210 LET P = -1 2220 LET D = 1 2240 PRINT &#34;FIRST DOWN***&#34; 2242 IF P &amp;lt; 0 THEN 2250 2244 IF X &amp;lt; 90 THEN 2260 2246 LET X1 = 90 2248 GOTO 2320 2250 IF X &amp;gt; 10 THEN 2260 2252 LET X1 = 10 2254 GOTO 2320 2260 LET X1= X 2280 GOTO 2320 2300 PRINT &#34;DOWN &#34; D; &#34;AND &#34; 10 + P*(X1-X); &#34;YARDS TO GO.&#34; 2320 PRINT 2340 IF P &amp;gt; 0 THEN 320 2360 GOTO 2680 2380 IF F &amp;lt; 0 THEN 2580 2400 IF P &amp;gt; 0 THEN 2480 2420 PRINT &#34;TOUCHDOWN***&#34; 2440 LET P = 1 2450 GOSUB 4300 2460 GOTO 200 2480 PRINT &#34;SAFETY***&#34; 2490 GOSUB 4100 2500 PRINT &#34;PRINCETON GETS BALL ON ITS OWN 40.&#34; 2520 LET X = 60 2540 LET P = -1 2560 GOTO 2220 2580 IF P &amp;gt; 0 THEN 2640 2600 PRINT &#34;TOUCHBACK FOR DARTMOUTH.&#34; 2620 GOTO 200 2640 PRINT &#34;TOUCHDOWN PRINCETON ***&#34; 2650 GOSUB 4300 2660 GOTO 200 2680 REM PRINCETON OFFENSE 2700 LET P = -1 2720 IF D &amp;gt; 1 THEN 2840 2740 IF RND(Z) &amp;gt; 1/3 THEN 2800 2760 LET Z = 3 2780 GOTO 3120 2800 LET Z = 1 2820 GOTO 3120 2840 IF D &amp;lt; 4 THEN 2920 2860 IF X &amp;lt;= 30 THEN 2910 2880 LET Z = 5 2900 GOTO 3120 2910 IF 10 + X -X1 &amp;lt; 3 THEN 2740 2912 LET Z = 7 2914 GOTO 3120 2920 IF 10+X-X1 &amp;lt; 5 THEN 2740 2940 IF X &amp;gt; X1 THEN 3060 2960 IF RND(Z) &amp;gt; 1/2 THEN 3020 2980 LET Z = 2 3000 GOTO 3120 3020 LET Z = 4 3040 GOTO 3120 3060 IF RND(Z) &amp;gt; 1/4 THEN 3100 3080 GOTO 2980 3100 GOTO 3020 3120 GOTO 360 4000 REM KEEP SCORE 4100 LET S(1-P) = S(1-P)+2 4200 PRINT &#34;SCORE:   &#34; S(2); &#34;TO   &#34; S(0) 4210 PRINT 4220 RETURN 4300 IF RND(Z) &amp;gt; .8 THEN 4350 4310 PRINT &#34;KICK IS GOOD&#34; 4320 LET S(1-P) = S(1-P)+7 4330 GOTO 4200 4350 PRINT &#34;KICK IS OFF TO THE SIDE&#34; 4360 LET S(1-P) = S(1-P)+6 4370 GOTO 4200 5000 REM FIELD GOAL 5001 PRINT &#34;PLACE KICK&#34; 5005 LET F = -1 5006 IF R &amp;gt; .5 THEN 5010 5007 PRINT &#34;KICK IS BLOCKED***&#34; 5008 LET Y = -5 5009 GOTO 1480 5010 IF P &amp;lt; 0 THEN 5200 5020 IF X+Y &amp;gt;= 110 THEN 5100 5030 IF X + Y &amp;lt; 80 THEN 5060 5040 PRINT &#34;KICK IS OFF TO THE SIDE.&#34; 5050 GOTO 1740 5060 PRINT &#34;KICK IS SHORT.&#34; 5070 GOTO 1480 5100 PRINT &#34;FIELD GOAL ***&#34; 5110 LET S(2) = S(2)+3 5120 GOSUB 4200 5130 GOTO 2180 5200 IF X-Y &amp;lt;= -10 THEN 5300 5210 IF X-Y &amp;gt; 20 THEN 5060 5220 PRINT &#34;KICK IS OFF TO THE SIDE.&#34; 5230 GOTO 2600 5300 PRINT &#34;FIELD GOAL ***&#34; 5310 LET S(0) = S(0)+3 5320 GOSUB 4200 5330 GOTO 200 9999 END
</code></pre><h2 id="acknowledgements">Acknowledgements</h2>
<p>I’m indebted to Thomas Kurtz — not only for his work on BASIC, but also for his time in 2017 when I interviewed him at Dartmouth and we corresponded about BASIC’s design. I’d also like to thank Stephen Garland and John McGeachie (who were part of the Dartmouth undergraduate team working on ALGOL, BASIC and DTSS in the mid-1960s) for some details and clarifications about BASIC.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">FOR I = 1 TO 10
</code></pre><p>would, nonetheless, represent the value of</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">I
</code></pre><p>(internally) as a double-precision floating-point number.However, we reasoned that almost all students would be writing short programs whose execution times would be trivial, at least in comparison to the compiling time. This assumption turned out to be true, especially since the BASIC compiler was, because of the simple language, quite fast.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Kemeny, J. and Kurtz, T. (1967)  <em>The Dartmouth Time-Sharing Computing System Final Report</em> , NSF Grant GE-3864, June, Course Content Improvement Program, Dartmouth College, Dartmouth, NH.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Rankin, J. (2018)  <em>A People&rsquo;s History of Computing in the United States</em> . Harvard: Harvard University Press.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Ensmenger, N. (2012)  “Is chess the drosophila of artificial intelligence? A social history of an algorithm” ,  <em>Social Studies of Science</em> , vol. 42, no. 1, pp. 5–30.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Marino, M. (2020)  <em>Critical Code Studies</em> . Cambridge: MIT Press.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>This interview was not part of a larger study, but instead was my attempt to understand more about the potential connections between Dartmouth BASIC and Kemeny and Kurtz’s understanding of what Kemeny later called computer literacy, as well as any potential connections between Dartmouth BASIC and an English teaching seminar held on campus in 1966, commonly called the Dartmouth Seminar in my field of Rhetoric and Composition. As I note in my reflection on an exhibit I produced for that 1966 Seminar, there was no connection between the Dartmouth Seminar and the development of BASIC at Dartmouth in the 1960s <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>. Yet the interview was still quite useful to me in understanding the ideas and history behind BASIC’s development, and I’m grateful to Thomas Kurtz for granting me his time.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Kurtz, T. (1981)  “BASIC Session” , in R. Wexelblat (ed.),  <em>History of Programming Languages</em> , ACM Monograph Series. New York: Academic Press, pp. 515–549.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref10:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref11:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref12:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref13:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref14:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref15:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref16:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref17:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref18:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref19:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref20:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref21:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref22:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref23:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref24:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref25:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref26:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref27:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Kurtz, T. (2017)  “Grammatical Simplications in BASIC”  [Memo to Annette Vee].&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Campion, NR. (2001)  “True Basic: A Sketch of John Kemeny” ,  <em>Dartmouth Alumni Magazine</em> . Available at: <a href="https://math.dartmouth.edu/news-resources/history/kemeny-history/TBasic.pdf">https://math.dartmouth.edu/news-resources/history/kemeny-history/TBasic.pdf</a> (Accessed 24 July 2021).&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Kurtz, T. (2017) Personal interview conducted by Annette Vee. Oct 15, 2017&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Kemeny, J. and Kurtz, T. (1967)  <em>Basic Programming</em> , 2 edn. New York: John Wiley and Sons.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Kemeny, J. and Kurtz, T. (1968)  “Dartmouth Time-Sharing” ,  <em>Science</em> , pp. 223–228.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p><em>Birth of BASIC</em>  (2014) Created by Mike Murray and Dan Rockmore. Dartmouth College. Available at: <a href="https://www.youtube.com/watch?v=WYPNjSoDrqw">https://www.youtube.com/watch?v=WYPNjSoDrqw</a> (Accessed 24 July 2021).&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Copeland, J. and Long, J. (2016)  “Restoring the first recording of computer music” ,  <em>British Library Sound and Vision blog</em> , 13 September.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Wardrip-Fruin, N. (2009)  <em>Expressive Processing: Digital Fictions, Computer Games, and Software Studies</em> . Cambridge: MIT Press.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Brand, S. (1972)  “Spacewar: Fanatic Life and Symbolic Death Among the Computer Bums” ,  <em>Rolling Stone</em> , pp. 50–58.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p><em>Kiewit Comments</em> ,  “The Bit Bucket”  November 17, 1967; Box 6, Thomas Kurtz Papers, Rauner Library, MS-1144&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>American Federation of Information Processing Societies. (1974)  <em>History of Computing Project: Dartmouth Timeshare System, National Computer Conference Pioneer Day Session</em> . {Available at: <a href="http://dtss.dartmouth.edu/transcript.php">http://dtss.dartmouth.edu/transcript.php</a>}&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Joy Lisi Rankin reads this exchange less playfully, as an indication of the gendered hierarchy at Dartmouth computing, where the housemother (Broadhead) is called to work afterhours by the lab director (Kemeny) <sup id="fnref5:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Given the tone of the entire discussion, this particular exchange, and other descriptions of Kemeny’s working relationships, I see this exchange as playful as well as reflective of expected gendered working relationships in the 1960s and ‘70s. He did presume to call her about work in the middle of the night, but she felt empowered to tell him it could wait until morning — and then tease him about it publicly years later, where he admits the frivolity of his request.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>See <a href="#rankin2018">Rankin</a>, Chapter 3  “Back to BASICs”  for a detailed discussion and maps of the growing Kiewit network, so named by the computing center in 1967.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Anderson, J. (1983)  “Who Really Invented the Computer Game?” ,  <em>Creative Computing</em> , vol. 1, no. 1, p. 8.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Wills, J. (2019)  <em>Gamer Nation: Video Games and American Culture</em> . Baltimore, MD: Johns Hopkins University Press.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>I’d like to thank an anonymous reviewer for pointing out the context of radio sports commentary for the time period.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Foran, M. (2008)  “One Nation under Madden: How the Madden Video Game Franchise Became Bigger than John Madden” ,  <em>Nielson.com</em> .&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Kemeny noted in the 1974 Pioneer Day session that he wrote it on a Sunday in 1965, the day after the game. I found the football schedule listed on Wikipedia to figure out which day that was, exactly.<a href="https://en.wikipedia.org/wiki/1965_Dartmouth_Indians_football_team">https://en.wikipedia.org/wiki/1965_Dartmouth_Indians_football_team</a>&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Good, K. (2017)  “John Kemeny and Tecmo’s BASIC FTBALL Granddaddy” ,  <em>Tecmo Bowlers</em> . Available at: <a href="https://bowlers102.rssing.com/chan-58312418/article38.html">https://bowlers102.rssing.com/chan-58312418/article38.html</a> (Accessed 23 September 2022).&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>From this blog post, archived from  <em>Techmo Bowlers</em> : <a href="https://bowlers102.rssing.com/chan-58312418/article38.html">https://bowlers102.rssing.com/chan-58312418/article38.html</a>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Montfort, N. et al. (2014)  <em>10 PRINT CHR$(205.5+RND(1));: GOTO 10</em> , Cambridge: MIT Press.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Ahl, D. (1978)  <em>BASIC Computer Games, Creative Computing</em> . Available at: <a href="https://www.atariarchives.org/basicgames/index.php">https://www.atariarchives.org/basicgames/index.php</a>&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Kemeny and Kurtz did not make the obvious choice of IBM because they perceived IBM representatives as bullies during the selling process, plus GE was more interested in the educational applications and willing to provide them with these discounts <sup id="fnref8:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Dartmouth College. (n.d)  “The Dartmouth Computing Timeline: The 1960s” ,  <em>ITS Tools: The Dartmouth Computing Timeline</em> .&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>For a good explanation of the technical aspects of the timesharing system, see <a href="#rankin2018">Rankin 2018</a>, pp. 24–25.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>They used the term master-slave for the system design, which was standard at the time and is only now being renamed as a controller-peripheral arrangement (see <a href="#landau2020">Landau</a>).&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>GE Reports Staff (2015)  “It’s BASIC: Arnold Spielberg and the Birth of Personal Computing” ,  <em>GE Reports</em> . Available at: <a href="https://web.archive.org/web/20150503110958/http:/www.gereports.com/post/117791167040/its-basic-arnold-spielberg-and-the-birth-of">https://web.archive.org/web/20150503110958/http:/www.gereports.com/post/117791167040/its-basic-arnold-spielberg-and-the-birth-of</a> (Accessed 24 July 2021).&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>From Kurtz memo to Annette Vee 9.29.17:  “Grammatical Simplifications in BASIC” All other programming languages introduced number types to correspond to the hardware. For example, languages like Pascal might have single-precision and double- precision number types of both integer and floating-point. Programmers could then use, for a particular quantity, the type that provided the greatest efficiency. (Integer arithmetic in almost all computers was much faster than floating-point arithmetic. In fact, in the early GE computers, floating point calculations required a separate large hardware component. In some other computers, there being no floating-point hardware, the system had to rely on software subroutines to perform that kind of calculation.)In BASIC, we decided that all arithmetic would be done in the computer using double-precision floating-point, which was, of course, much slower than an integer calculation. As an example, the simple looping statement&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Dijkstra, E. (1968)  “Go To Statement Considered Harmful” ,  <em>Communications of the ACM</em> , vol. 11, no. 3, pp. 147–8.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Rubin, F. (1987)  “ GOTO Considered Harmful  Considered Harmful” ,  <em>Communications of the ACM</em> , 30(3), 195-196.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>These line numbers suggest that Kemeny added them later in his composing process, as the convention for BASIC programming was to increment lines by 10s (10, 20, 30, …), leaving the in-between numbers for later additions.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Vee, A. (2021)  “Reflection” ,  <em>Dartmouth ’66 Seminar Exhibit</em> , WAC Clearinghouse. Available at: <a href="https://wac.colostate.edu/resources/research/dartmouth/critical-reflections/vee-and-mcintyre/">https://wac.colostate.edu/resources/research/dartmouth/critical-reflections/vee-and-mcintyre/</a> (Accessed 23 September 2022).&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Computational art Explorations of Linguistic Possibility Spaces: comparative translingual close readings of Daniel C. Howe’s Automatype and Radical of the Vertical Heart 忄</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000705/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000705/</id><author><name>John Cayley</name></author><published>2023-07-20T00:00:00+00:00</published><updated>2023-07-20T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>This essay discusses two distinct but related works by Daniel C. Howe.  <em>Automatype</em> , 2012-16, is, in the words of the artist’s description,  “a networked installation (composed of analog TV monitors and RaspberryPIs running custom software) that explores the creation of aesthetic, linguistic meaning via anticipation, juxtaposition, and association. The algorithm at the heart of the work continually computes the minimum number of substitutions required to transform each valid English word into the next, deriving a near infinite number of combinations of words and phrases, letter-by-letter, substitution-by-substitution.” <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> The algorithm running on each of the (usually nine) displays in an  <em>Automatype</em>  installation is the same, and close reading here effectively focuses on this constituent of the work.  _Radical of the Vertical Heart  忄 _ , 2019-21, the most recent work in what Howe considers a series,</p>
<blockquote>
<p>searches the Chinese lexicon by repeatedly making minimal changes (stroke-by-stroke) to the sub-components of characters, in order to arrive at a new word. Rather than evaluating letters, as in alphabetic machines, this logographic [sic] reader analyses the radicals, components and strokes of characters. When the machine lands on sensitive words, such as those disallowed by China’s Great Firewall (or those now illegal in Hong Kong), a break occurs and the machine jumps from traditional [Chinese script forms] to simplified.<br>
<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> As a critical feature of  <em>RotVH,</em>  this is aligned with other work by Howe, often engaged with important problems and structures of our predominant digital culture – surveillance, security, power asymmetries, freedom of expression, etc. This essay touches on these matters, particularly insofar as they are addressed by algorithm, data curation, and data structuring, and also comparatively, insofar as they are drawn out by and critiqued in this work’s remarkable translinguistic and transcultural contexts. But for more extensive discussion of the digital politics of Howe’s work, and its aestheticization, the reader is referred to this other work itself.</p>
</blockquote>
<p>Both these works have been presented to their readers and audiences as examples of electronic literature, often sited in necessarily sculptural gallery installation.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  They are simultaneously examples of computational art and, as such, they are afforded the potential for re-presentation in other forms, particularly distinct graphic and audiovisual manifestations on computer monitors. The code or software of these works is at the core of what they are, artifactually.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>  What the code produces as display may be sited or made manifest in any number of 2D or 3D forms and spaces. This discussion, however, concerns itself, chiefly, with the code itself and what is presented by the code as, basically, typographic form on a 2D display, with some accompanying audio: letters and words in the case of  <em>Automatype;</em>  strokes, characters, and two-character compounds in the case of  <em>RotVH</em> . Audio is used to signal particular relationships between generated forms and items in lexicons that have been derived from the languages of the respective works.</p>
<p>The typographic forms generated by these works are of course referred, by those who engage with them, to language. At any one moment, they can often – not always – be read as such, as language; or rather as words  <em>in</em> , at least, one of two natural languages, English on the one hand, Chinese on the other. Except that the situation immediately becomes more complicated.  <em>Automatype</em>  does have an English lexicon at its disposal but, as it explores a mathematically abstracted space of Roman-letteral spelling, quite apart from spellings that are non-lexical in any language, it will encounter and display word-like forms that may be shared by natural languages other than English (any of those whose typography also uses Roman letters), or forms which are not orthographically English although they may be orthographically correct and readable in  <em>another</em>  language.</p>
<p>In the case of  <em>RotVH</em> , the situation is similarly complicated but radically different. Arbitrary or regularly abstracted rearrangements or substitutions of any particular character’s strokes or sub-elements will not – or only in extremely rare cases – produce an orthographically readable character in Chinese or a language other than Chinese, but any of the orthographically readable characters which  <em>are</em>  produced may be read, entirely differently, in any number of Chinese dialects or, indeed, in any number of other dialects of certain natural languages such as Japanese or Korean. Since Daniel Howe currently lives, works, and exhibits in Hong Kong, readings of  <em>RotVH,</em>  for example, have often been anticipated in Mandarin (Putonghua) and Cantonese, which are considered mutually unintelligible dialects of Chinese.</p>
<p>Raising such complications at the outset of this close reading does at least two things. It highlights the way in which similarly motivated algorithmic processes may generate language-driven computational artworks with entirely different readings, particularly since these readings, quite apart from being metaphoric – that is, critical or aesthetic – are also readings of distinct written linguistic materials which co-constitute the works. And it also reminds us of deep problems concerning the relationship between, on the one hand, what we call text or writing or typography, or now also – in the context of computation –  <em>strings</em>  of characters, and, on the other, language as such.</p>
<p>For text is not language unless and until is either actually read, or unless and until it is considered to be, potentially, readable. This is a statement from my own philosophy and, indeed, ontology of language. <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>  In the context of my theory I am happy to refer this statement to a species-unique human faculty of language;<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  in the present context I ask only that those reading this essay agree that the words of  <em>Automatype</em>  and the characters of  <em>RotVH</em>  are subject to the possibility, at least, of human reading and interpretation, and that this does have a bearing on their appreciation as art, in particular any art of language that they propose. Their code, however, executes and generates typographic forms without regard to any human reading that may or may not be taking place. From a linguistic perspective, it is the various lexicons and associated data structures embedded in these projects’ software –pre-determined and adopted by the artist prior to any execution of the code – which establish relationships with human reading. The processes which generate their displayed linguistic forms do not.</p>
<p>They do not, that is, unless, as readers and scholars we believe and assert, amongst other things, that reading and interpretation are reducible to regular, formal, combinatorial processes. One of the important tasks of critical code studies is to articulate this relationship between the code-composed programs (programs both literal and figurative) insofar as they are generative of linguistic form, and the practices of reading that we bring to them in order to appreciate what they express as language or, indeed, language art. To be clear, I am not in the camp of those who take language to be computable (reducible to computation) in any sense of this hypothesis that is abstracted or divorced from evolution or, indeed, history. In close reading these two works, I highlight the disjunctures between coded processes and human reading, and will even argue that these disjunctures, articulated, are themselves amongst the works’ most significant and affective readings. The disjunctures are brought into relief by the similarity of algorithmic process across these works, in contrast to their radically different integrations with the languages they engage. Both works are, I believe, easy enough to understand in terms of what their code is doing, while their readings are also clearly indicative of quite complex differences of language and culture; and also, in the case of  <em>RotVH</em> , sociopolitics.</p>
<p>Concluding these introductory and anticipatory remarks, it bears mentioning that this relation between code-generated text and human reading has the same structure, fundamentally, as that which obtains for the increasing predominant practices of Natural Language Processing that are driven by Deep Learning. Except that, when Deep Learning is operative, human readers’ ability to articulate and understand the coded processes are – is it right to say literally? – redacted. Deep Learning language models’ encoding of representations is often presented as a black box, received as such even by willing experts. And while, in principle, exhaustive formal analysis may be held to be possible, what is actually concealed from us, as human readers and consumers (sic) of the generated pseudo-language, is a number of unsubstantiated assumptions concerning things that we do not (and perhaps cannot) know, scientifically or otherwise. <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>  I would summarize this by saying that, although we speak and read, we still do not know what language is, nor how or why some of it may be aesthetically significant for us. As to this how and why, when we consider  <em>Automatype</em>  and  <em>RotVH</em> , at least we have a chance.</p>
<p>The artist documentation pages for these works offer links to Project Home Pages, Online Versions, and various public manifestations. The Project Home Page for  <em>Automatype</em>  is minimal, and features an evaluative description extracted from a review by Brian Kim Stefans <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. The Home for  <em>RotVH</em>  however takes us to a page which links the two works explicitly, categorizing them both as Atomic Language Machines (ALMs), defined as  “discrete computational entities with the potential to change the direction, intent, or magnitude of a literary vector. In general, ALMs can be defined as members of the simplest class of mechanisms able to realize linguistic advantage.”   <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>  Linguistic advantage is one of those terms deployed in the context of computational linguistics to provide or explain motivation in Natural Language Processing, something used to test against a generated linguistic form in order to decide if it has, in some sense, advantageously succeeded or achieved a goal which is usually interpretable by (and advantageous to) humans. For both  <em>Automatype</em>  and  <em>RotVH</em>  it is advantageous to spell out an item from the lexicons of English and Chinese, respectively.</p>
<p>The atomism of ALMs is referred by Howe to a concept of  “simplest class of mechanism”  and is linked with other such classes of mechanism which are cited as deployed, for example, in  <em>The Readers Project</em>   <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>  Here, I read atomic as indicative of, as it were, an  <em>elemental</em>  similarity between the class of mechanism driving  <em>Automatype</em>  and that which animates  <em>RotVH</em> . The ALMs page quotes the following code snippet abstracted from the actual code driving  <em>RotVH</em> :</p>




























<figure ><img loading="lazy" alt="Screenshot of syntax-highlighted source code and comment." src="/dhqwords/vol/17/2/000705/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000705/resources/images/figure01_hu0de37cda9c5cf229b4c7ad1127e8893f_204036_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000705/resources/images/figure01_hu0de37cda9c5cf229b4c7ad1127e8893f_204036_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000705/resources/images/figure01.png 912w" 
     class="landscape"
     ><figcaption>
        <p>The function logographicMinEditDistance: source code and comment.
        </p>
    </figcaption>
</figure>
<p>“Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other.”   <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> This metric is the measure of linguistic advantage that underlies both  <em>Automatype</em>  and  <em>RotVH</em> . When we consider  <em>Automatype</em>  – working with English words spelt out in Roman letters – this distance is a relatively straightforward concept to grasp. Typographic words are, indeed, sequences or strings of characters. For each word in a lexicon (or its derivatives) we can calculate a Levenshtein distance to any other word. Having done so, we can start with any word we like and, having found its nearest Levenshteinian lexical neighbor, we may animate a typographic display which performs the minimum number of edits on our original string of characters in order to transform it into its neighbor. This is precisely what  <em>Automatype</em>  does, and by disallowing any turning back (to a previously displayed lexical item) it effectively represents an ALM that would travel least-distance paths from item to item until it had visited and exhausted all the items of its English lexicon.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup></p>
<p>Another connotation of atomic, perhaps only latent in Howe’s ALMs webpage, comes into play at this point. The strings and sequences over which Levenshtein distances are calculated must be composed of integral, indivisible – at least for the purposes and processing of the algorithm – tokens, the atoms of the symbolic system of which they are expressions. The atoms of  <em>Automatype</em> ’s sequences are letters taken from a familiar, quite clearly delineated set, one that is widely shared over a number of linguistically integrated domains. In linguistic reality, the Roman letters used for English orthography are problematically related to what they purport to represent, the constituents of spoken English sound-images (as Saussure, for one, would have it). But leaving these problems of reference, representation, and transcription to one side, English letters can be read straightforwardly by humans as from a finite set of integral elements. And although minimally semantic, they are included as lexical items in most dictionaries. Letters are, generally speaking, typographic atoms of reading and are amenable to contemporary computation as such.</p>
<p>But what are the correspondent atoms of Chinese typography, of the Chinese writing system? Lexicons in the Chinese cultural sphere typically have characters as the head words of their articles although modern dictionaries may also use compounds of characters, usually consisting of two characters. In modern Chinese these compounds correspond, linguistically, to the words of English dictionaries. Nonetheless, the Chinese character is, culturally speaking, the atom of reading for the languages which use this logographic or, more properly, morphographic system of inscription.  <em>RotVH</em>  works with two-character compounds. If characters were  <em>RotVH</em> ’s atoms then Levenshtein distance would be calculated on the basis of  <em>character</em>  insertions, deletions, and substitutions. Since single characters are always morphemes and may often correspond with English words in modern Chinese (while typically doing so in pre-modern Chinese) they are clearly of a different linguistic order as compared to Roman letters. Morpheme insertion, deletion, and substitution would read – if it did motivate the algorithms of  <em>RotVH</em>  – as incommensurate with the corresponding operations of  <em>Automatype</em> , although, in this speculative condition,  <em>RotVH</em>  would still exhaustively traverse a lexicon consisting of two-character compounds and would still sometimes display non-lexical items. (And it would still also be able to signal and respond to any of its encounters with politically charged two-character terms). But it would never be non-semantic. Its operations would always yield readable (and perhaps occasionally poetic) meanings.</p>
<p>The artist recognized these circumstances and went deeper into the analysis of Chinese characters, coming up with a remarkable and effective compromise for his aesthetic purposes along, implicitly, with novel proposals for conceptualizing and calculating Levenshtein distances across the domain of Chinese characters. This is Howe’s comment on his  “logographic distance”  calculation:</p>
<pre tabindex="0"><code>/* * logographic distance * - number of different full characters less 1 (via basic Levenshtein) * - plus Levenshtein distance between two decompositions for each char * from [ ⿰ ⿱ ⿻ ⿳ ⿺ ⿸ ⿲ ⿹ ⿴ ⿵ ⿶ ⿷ ] * - this gives an integer distance &gt;= 0 (with 0 for identical strings) * - the floating point component (0 &lt;= f &lt; 1) is added by comparing the number of strokes in differing sub-parts normalized against a max-stroke count (not used in production) */
</code></pre><p>The distance calculation is a sum of staged Levenshtein distances. A first distance [1] is calculated between strings of integral characters (the length of these strings being always equal to two in the lexical domain that is addressed by  <em>RotVH</em> ). Then [2] each of the characters in the strings being compared is assigned to one of twelve patterns of (de)composition which are typical of Chinese characters. There is no generally accepted, rigorous analysis of this feature of characters, but sub-elements of characters are traditionally recognized and read into character composition and patterns of disposition for these elements fall into one of the twelve such that determinations are made and may even be assigned in some character dictionaries. Interestingly the patterns quoted above are represented by Unicode glyphs and thus – although these glyphs’ reference is much further divorced from linguistic significance, in the sense of any sound-image denotation, than that of alphabetic letters – their implicit deployment in Howe’s calculation resonates with the letters-as-tokens approach that is assumed in standard Levenshtein calculations over alphabetic orthographic typography. Finally, [3] calligraphic (or sinotypographic) strokes are also recognized as finest-grained elements of characters. Ordered strokes are what compose the higher-level sub-elements of the (de)composition patterns. Howe documents the possibility of using stroke-token sequences for each of the decomposed sub-elements and adding these to calculate a correspondingly finer-grained Levenshtein distance between, for example characters sharing the same (de)composition pattern. He proposes to do this in an implicitly weighted manner by adding these distances as a  “floating point”  (fractional) component. In practice, however, in the actual production version of  <em>RotVH</em> , Howe decided to ignore this component.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup></p>
<p>_ RotVH_  is art not science. It may well, however, engage more practically, empirically, and experimentally with scientific analyses or formulations of editing distance over the Chinese lexicon than other efforts which have been put forward in the context of science explicitly. The choice of next operation – here of insertion, deletion, or substitution – is on display to artistically motivated readers and viewers and will thus bring in other aesthetically implicated considerations apart from Levenshtein distance, the most obvious being based on keeping a history of all words or character compounds so far displayed, and disallowing repetitions. This principle applies to both  <em>Automatype</em>  and  <em>RotVH</em>  and is what enables these ALMs to take their shortest possible – conceptual-art – walk through an entire lexicon. For  <em>RotVH</em> , Howe needs to establish additional pragmatic-aesthetic criteria, beyond the shared concept.</p>
<blockquote>
<p>[O]ther criteria also affect selection (from the larger pool of candidates) including whether they differ on the same side (left or right character in the word) as the last few changes, so as to avoid the same character remaining constant for long periods, and whether any are trigger words. In the current version I ended up ignoring the floating point part of the distance metric… in order to get a set of words essentially tied in distance, so that I could then choose between them according to these other metrics.<br>
<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>  The  “larger pool of candidates”  refers to all those compounds for potential display which are  “tied”  in terms of Levenshtein distance after stages [1] and [2] above.</p>
</blockquote>
<p>This is the point at which – without abandoning its inevitably computational and code-driven conceptual aesthetics, both also addressing the domain of Natural Language Processing, and both shared with  <em>Automatype</em>  –  <em>RotVH</em>  shifts its engines of motivation in order to adopt a  <em>critical art</em>  aesthetic, one that is designed to inform its readers, creatively, concerning the sociopolitical valences of certain items in the Chinese lexicon.  <em>RotVH</em>  contains a data file of  “trigger”  words, those compounds which are flagged by the Great Firewall, by Chinese state surveillance of linguistic internet traffic, or which have been signaled as politically taboo in what is now China’s Hong Kong Special Administrative Region. Here is a snapshot from the JSON file (triggers.json) to which  <em>RotVH</em>  refers <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>:</p>
<pre tabindex="0"><code>&#34;滴蜡&#34;: { &#34;lang&#34;: &#34;simp&#34;, &#34;pair&#34;: &#34;滴蠟&#34;, &#34;def&#34;: &#34;using candles for BDSM&#34; }, &#34;滴蠟&#34;: { &#34;lang&#34;: &#34;trad&#34;, &#34;pair&#34;: &#34;滴蜡&#34;, &#34;def&#34;: &#34;using candles for BDSM&#34; }, &#34;汪洋&#34;: { &#34;lang&#34;: &#34;both&#34;, &#34;pair&#34;: &#34;汪洋&#34;, &#34;def&#34;: &#34;vast ocean, PRC ex-VP Wang Yang&#34; }, &#34;妇联&#34;: { &#34;lang&#34;: &#34;simp&#34;, &#34;pair&#34;: &#34;婦聯&#34;, &#34;def&#34;: &#34;women&#39;s league&#34; }, &#34;婦聯&#34;: { &#34;lang&#34;: &#34;trad&#34;, &#34;pair&#34;: &#34;妇联&#34;, &#34;def&#34;: &#34;women&#39;s league&#34; }, &#34;罢工&#34;: { &#34;lang&#34;: &#34;simp&#34;, &#34;pair&#34;: &#34;罷工&#34;, &#34;def&#34;: &#34;workers&#39; strike&#34; }, &#34;罷工&#34;: { &#34;lang&#34;: &#34;trad&#34;, &#34;pair&#34;: &#34;罢工&#34;, &#34;def&#34;: &#34;workers&#39; strike&#34; }, &#34;元朗&#34;: { &#34;lang&#34;: &#34;both&#34;, &#34;pair&#34;: &#34;元朗&#34;, &#34;def&#34;: &#34;Yuen Long district, Hong Kong&#34; }, &#34;陸肆&#34;: { &#34;lang&#34;: &#34;trad&#34;, &#34;pair&#34;: &#34;陆肆&#34;, &#34;def&#34;: &#34;ref. to Tiananmen Anniversary&#34;}, &#34;陆肆&#34;: { &#34;lang&#34;: &#34;simp&#34;, &#34;pair&#34;: &#34;陸肆&#34;, &#34;def&#34;: &#34;ref. to Tiananmen Anniversary&#34;}, &#34;學潮&#34;: { &#34;lang&#34;: &#34;trad&#34;, &#34;pair&#34;: &#34;学潮&#34;, &#34;def&#34;: &#34;student movement&#34;}, &#34;学潮&#34;: { &#34;lang&#34;: &#34;simp&#34;, &#34;pair&#34;: &#34;學潮&#34;, &#34;def&#34;: &#34;student movement&#34;}, &#34;八九&#34;: { &#34;lang&#34;: &#34;both&#34;, &#34;def&#34;: &#34;1989, year of Tiananmen Sq massacre&#34;}, &#34;河殤&#34;: { &#34;lang&#34;: &#34;trad&#34;, &#34;pair&#34;: &#34;河殇&#34;, &#34;def&#34;: &#34;River Elegy&#34;}, &#34;河殇&#34;: { &#34;lang&#34;: &#34;simp&#34;, &#34;pair&#34;: &#34;河殤&#34;, &#34;def&#34;: &#34;River Elegy&#34;}, 
</code></pre><p>This is a snapshot which demonstrates the wide-ranging scope of Chinese lexical surveillance, flagging terms with regard to: sexual practices;  “reforming”  politicians; gender- and class-based affiliations; the Tian’anmen Square massacre and its  “student movement”  (likely including student movements in themselves); and even a controversial television series. The  “lang”  property of each two-character item is indicative of one of two main Chinese systems of inscription. Those words with the same triggering  “def”  property may occur in  “trad[itional]”  (more strokes, greater complexity) or  “simp[lified]”  spellings. Traditional characters are still widely and officially used in regions of the Chinese culture sphere – notably and with political significance Taiwan and Hong Kong – which are, to whatever extent, still outside the People’s Republic of China. The PRC, on the other hand, has instituted and adopted its own reformed and simplified character orthography. Some spellings – untouched by reform – belong to  “both”  systems. There is an underlying ideality to characters (or compounds) in either spelling. Essentially, they refer to the same form-as-read in the Chinese of their speaker-readers (I would call this a gram of the implicit archi-writing) and thus they are equally triggering for state surveillance.</p>
<p>Whereas the audiovisual behaviors of  <em>Automatype</em>  – apart from those which represent edit operations – are confined to signaling the ALM’s arrival at a lexical word, those of  <em>RotVH</em>  signal not only lexical arrival but also whether or not the newly displayed word is a  “trigger,”  a surveilled word. Then also, after a distinct sound and a flash of red,  <em>RotVH</em>  is also triggered to switch to orthographic explorations in whatever is the other system of Chinese spelling, either  “trad[itional]”  or  “simp[lified],”  depending on which of the two it was exploring when disrupted by a  “trigger.”  This shift of orthographic systems might perhaps be interpreted as a futile attempt to misspell and thus elude surveillance, but it can never be more than a jolt to either system since the underlying  “trigger”  is, as we have seen, the same word in any Chinese that matters to the surveillance operations of its PRC state overseers. Regardless of the overseers’ indifference (or rather their fixation on transgression) or the computational indifference of  <em>RotVH</em> ’s execution, the change of orthographic systems will, nonetheless, resonate with, and may mildly traumatize, Chinese readers since each system has ideological and political alignments and associations.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></p>
<p>The typical installation version of  <em>Automatype</em>  consisted of a number of networked, otherwise independently operating instances of the ALM in, for example, a 3x3 grid, each exploring the same lexicon separately but on its own path from a different starting point, making minimal displayed edits, and arriving intermittently at actual lexical items, English words. This grid arrangement overlays a form suggestive of visual or pattern poetry and thus also an aesthetic, a  <em>poetic</em>  that is not programmatically related (not integrated by code) with the  <em>conceptual</em>  Natural Language Processing aesthetic of the ALM itself.  <em>Automatype</em> ’s poetic overlay-in-installation has not been a significant focus of attention for this essay although it is what allowed Brian Kim Stefans, in his remarks on  <em>Automatype</em>  to say that  “You will spend either 10 seconds or 5 minutes staring at this thing [the grid]; you will also see either a bunch of random words, or occasionally, if not always, engaging samples of minimalist poetry”   <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.</p>
<p>Not only are  <em>Automatype</em>  and  <em>RotVH</em>  closely related in that they share essentially the same coded, programmatic procedure for walking through a lexicon and thus essentially the same computational and conceptual NLP aesthetic; they are also similarly structured in that both have been given, by their maker, an additional, overlaid aesthetic. And although the code of  <em>RotVH</em>  refers and reacts to its trigger word data, this is an additional and distinct coded operation of  <em>RotVH</em> , dependent on an additional human-compiled data file, only of significance to or affective of this ALM’s readers for reasons that are sociopolitical rather than merely linguistic. The immediately following concluding remark should be part of a much larger discussion, but we might begin to take away something beyond the code-critical from this comparative reading by reflecting on how the overlaid aesthetic for a project within the domain of global English tends to engage with formal arrangement and poetics, whereas the closely related, subsequent project, addressing what is now perhaps the planet’s other global language, engages sociopolitics and critical art practices.</p>
<p>There is at least one more important general point to make that is based on the descriptions and analysis that we have just undertaken, and it has transcultural critical resonance. From both a code critical perspective and from one attuned to careful, responsible humanistic readings of computational art, any writing on this art must remain or become more critically aware of the culture of computation and its history. This is an imperative within the sphere of what is the globally predominant regime of computation, and it has hardly been addressed, as it must be, within an overarching context that is  <em>trans</em> cultural at the level of distinct civilizations.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup></p>
<p>We have seen that, addressing the Chinese system of inscription, an operational analysis of its elements must be done by way of bespoke or imported data structures and bespoke or imported functions – even when this is for the purposes of animating the same Natural Language Processing concept or operation – here, a Levenshtein distance-based shortest walk through a lexicon. By contrast, for global English in particular, and for western languages having integrated alphabetic systems of inscription, the data structures and functions are already more or less built into actually existing computational infrastructure. The historical reasons for this integration of computation and the alphabet are quite well known. But this is no reason for critical complacency, particularly when we recall that text-as-orthography is in no way consistent with even a linguistic-scientific analysis of language as such.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>  We call orthographic spellings words, but this is both pragmatic, living-culture convention and scientific misdirection. If historical and contingent computational infrastructures reinforce our misdirected conventions, this has implications far beyond the misapplication or bespoke adaptation of these infrastructures to systems of inscription for which they are ill-adapted. Close reading of  <em>Automatype</em>  and  <em>RotVH</em>  allows us to encounter and explore these contemporary transcultural critical aporias. These two ALMs both read words but read them differently, because even the spellings of these words are culturally situated and involve radically different relations to linguistic structure. The ALMs nonetheless deploy algorithms for lexical traversal which are essentially the same. The code is radically different in each case, not only due to the cultural situation of the words, but also because the code itself – and contemporary computation as whole – is culturally situated and adapted to particular global locations.</p>
<blockquote>
<p>There is also the idea of an (externally-imposed)(catastrophic?) break here… Yes, there are words in common, especially as written characters, to both but one (human or non-human reader) is either reading in C[antonese, typically integrated with traditional characters] or M[andarin, official Putonghua of the PRC and aligned with simplified characters], it would seem to me, though my students sometimes try to create politically-inflected mergers of the two. But historically-speaking some threshold of  <em>pressure</em>  (a favorite word here) may be required before one willingly switches (as example, the political implications of choosing to speak — or not to speak — M[andarin] as a Hong Konger are quite clear). And while generally the case, close relationships between the political and the linguistic are perhaps more explicit/tangible in Chinese history, especially regarding government policies of the last century that attempt to manage language as a resource (see Mullaney, etc.)<br>
(Personal communication, December 4, 2021) The Mullaney here is <sup id="fnref1:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>.</p>
</blockquote>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Howe, Daniel C.  <em>Automatype</em> . 2012-16. <a href="https://rednoise.org/daniel/automatype">https://rednoise.org/daniel/automatype</a>. Accessed November 27, 2021.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Howe, Daniel C.  <em>Radical of the Vertical Heart 忄</em> . 2019-21. <a href="https://rednoise.org/daniel/radicaloftheverticalheart">https://rednoise.org/daniel/radicaloftheverticalheart</a>. Accessed November 27, 2021.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Daniel C. Howe,  <em>Automatype,</em>  2012-16;  _Radical of the Vertical Heart  忄 _ , 2019-21. Both works are quite extensively documented on the artist’s website with landing pages for each as follows:  <em>Automatype</em> , <a href="https://rednoise.org/daniel/automatype">https://rednoise.org/daniel/automatype</a>; and  _Radical of the Vertical Heart  忄 _  (henceforth  <em>RotVH</em> ), <a href="https://rednoise.org/daniel/radicaloftheverticalheart">https://rednoise.org/daniel/radicaloftheverticalheart</a> (both accessed February 27, 2022). Live behavior of the basic, non-installation, versions of these works are linked from these pages and the reader is invited to consult these online. There is an entry for  <em>Automatype</em>  in the  <em>ELMCIP Knowledgebase</em>  at <a href="https://elmcip.net/node/4001">https://elmcip.net/node/4001</a>, and  <em>RotVH</em>  (is included in the forthcoming projected for 2022)  <em>Electronic Literature Collection 4</em> , see <a href="https://collection.eliterature.org">https://collection.eliterature.org</a>. I have provided separate bibliographic entries for the code repositories for these two works, publicly available on GitHub,  <em>Automatype [Code]</em> ;  <em>Radical of the Vertical Heart 忄[Code]</em> .&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>This essay is not so much concerned with actually quoted code or code style. The code is addressed, critically, with respect to the underlying algorithms which are, for the most part, paraphrased from the code itself, or re-expressed in what might be more accurately referred to as pseudocode. Nonetheless the code repositories have not only been reviewed by the author; he has also cloned them for examination and even potential future development and collaboration. (An interesting reconfiguration of the usual literary or art critical relations.)&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Cf. <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>; <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>; <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>. And also, <a href="https://nllf.net">https://nllf.net</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Members of this species, humans, bring language into being by reading (grasping, understanding) language’s material traces. These traces are expressed and appreciated chiefly in aurality but also in culturally integrated graphic visuality in writing; or in commensurate modes of language practice (in any perceptible material). The faculty that allows this to happen is necessarily constitutive of language, and co-constitutive of the human. As such it relies on the evolved and world-integrated embodiment of human animals, such that the differences of its integral symbolic system are never abstract. They are better understood as Derridean differances, as sayable meanings that emerge as they are expressed – with the kind of ambiguity or polysemy, for example, that embodied animation entails, and as neither pre-determined (from a finite set) nor subject to regular formulation as they are uttered and read. Thus, the constitutive faculty of which I speak is in sharp contradistinction with the predominant scientistic understanding of language, too-often based on a hypothetical Chomskyean, designative, pre-engineered difference machine, built-into the brain that runs combinatorial transformations on the abstracted deep structures of inherently computable and disembodiable mind/language constructs.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Readers may find a recent annual review useful in this context: Ellie Pavlick,  “Semantic Structure in Deep Learning”   <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. Pavlick is not, I think, amongst those researchers who are content to black box Deep Learning however opaque or beyond-human-scale/perception the motivation of language models may appear to be; and certain aspects of her problematization of the relationship between  “model representation”  and  “model behavior”  resonate with arguments in the present essay.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Stefans, Brian Kim.  “Third Hand Plays:  “Automatype”  by Daniel C. Howe” ,  <em>Openspace, SFMoMA</em>  September 8, 2011) <a href="https://openspace.sfmoma.org/2011/09/third-hand-plays-automatype-by-daniel-c-howe/">https://openspace.sfmoma.org/2011/09/third-hand-plays-automatype-by-daniel-c-howe</a>. Accessed December 4, 2021.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Howe, Daniel. C. (2021)  “Atomic Language Machines,”    <em>rednoise.org</em> . {Avilable at: <a href="https://rednoise.org/daniel/pages/alms/index.html">https://rednoise.org/daniel/pages/alms/index.html</a>(Accessed 28 November 2021).}&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Cayley, John, and Daniel C. Howe.  <em>The Readers Project</em> . 2009–. <a href="http://thereadersproject.org">http://thereadersproject.org</a>. Accessed November 28, 2021. [Also published/documented:  <em>Electronic Literature Collection</em> , vol. 3, 2016, <a href="http://collection.eliterature.org/3/work.html?work=the-readers-project">http://collection.eliterature.org/3/work.html?work=the-readers-project</a>. Accessed August 17, 2017, ELMCIP Knowledge Base <a href="https://elmcip.net/node/864">https://elmcip.net/node/864</a>. Accessed August 14, 2017.]&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>A collaboration with the author. It is perhaps worth noting that, on the ALMs page, the artist allows himself a certain poetic license, with language that is a blend of technical and fanciful, somewhat mythologizing, for example, the  “early theoretical research associated with the  “Natural Language Liberation Front” <a href="https://nllf.net">https://nllf.net</a>”&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Wikipedia contributors. (2021)  “Levenshtein distance,”    <em>Wikipedia, The Free Encyclopedia</em> . {Available at: <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">https://en.wikipedia.org/wiki/Levenshtein_distance</a> (Accessed 28 November 2021).}&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>As such, the piece also qualifies as a work of computationally animated  <em>conceptual</em>  literary art, a walk through the dictionary not unlike Allison Parrish’s  <em>@everyword</em> , published by bot on Twitter from 2007 through 2014 and documented in this printable publication: <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. Parrish’s work generates much of its significance and affect from the socially mediated situation and circumstances of its publication, and thus also from the transactional interventions and engagements of its readers through Twitter affordances (such as retweeting, liking etc.) Nonetheless, although the lexicons used for  <em>Automatype</em>  and  <em>@everyword</em>  were different, there is clearly a profound underlying sameness – a shared ideality if not an identity – to the texts of these two works. And either could have used the other’s lexicon without impugning their respective concepts or motivating principles. Moreover, it is similarly the case that the text’s generation by code, in  <em>@everyword</em> , has little or no bearing on its human reading, although the relationship between code and reading is radically different from that which we are exploring here, with respect to  <em>Automatype</em>  and  <em>RotVH</em> . It seems that there is an opportunity, which we cannot take up at present, for another interesting comparative close reading with code critical implications.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>There are hints that the artist will address aspects of what follows in future versions, but it should be noted that  <em>RotVH</em>  does not make use of actual or potential vocabularies of character sub-elements. This is a much-contested aspect of research on the Chinese script and its abstracted analytic properties. Whereas some sets of sub-elements are well-established, particularly the so-called radicals or classifiers which are used in many Chinese dictionaries (and are referred to in the title of  <em>RotVH</em> ), even the standard 214 radicals of the canonical Kangxi dictionary have multiple forms (of ordered strokes, etc.) and there are problems in exhaustively assigning characters to some particular radical. Nonetheless a finer-grain Levenshtein distance between characters might be able to take account of sub-element sets, leading to, for example, a Levenshtein distancing such as this: stage [1] based on strings of integral characters; stage [2] assignments of the constituent characters to one of the 12 (de)composition patterns; stage [3] tokenized identification of constituent sub-elements from a comprehensive set. Then [4, was 3 in the text] Levenshtein distances between string representations of the sub-elements’ ordered constituent strokes. But it is a significant graphic problem to animate, in any readable fashion, the operations of stroke insertion, deletion, and substitution that might be called for or desired. This brings up a related fact concerning the animated display of  <em>RotVH’s</em>  current version. The part of its animation during which a sub-element is built up is  <em>not</em>  a representation of Levenshtein edit operations. This is simply an animation of the stroke-ordered process that a human calligrapher would, by traditional convention, use to write the character’s sub-element. In the current version of  <em>RotVH</em>  only the graphic removal of a sub-element and its subsequent animated rendering  <em>as a whole</em>  is related to Levenshtein distance, but in the current version it often represents a Levenshtein-distance tie since the before and after characters may have the same (de)composition value. Otherwise, it counts as a substitution operation.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Personal communication with the artist, November 30, 2021.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Howe, Daniel C.  <em>Radical of the Vertical Heart 忄</em>  [Code], 2019-21. <a href="https://github.com/dhowe/rotvh">https://github.com/dhowe/rotvh</a>.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Cf. these interesting comments from the artist,&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>The reference to civilizations is historical and simply intended to signal the historical distinction between Eurocentric western civilization and that of a sinocentric east. The artist’s comments in note 15 above has already cited one of the few studies addressing these transcultural issues with respect to language practice and computation. <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> Mullaney’s book explicitly presages what promises to be his essential follow-up work on the history of computation in the Chinese culture sphere.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Which has implications, please recall, for Deep Learning language models and generators.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Cayley, John.  <em>Grammalepsy: Essays on Digital Language Art</em> . Electronic Literature. New York and London: Bloomsbury Academic, 2018, <a href="https://doi.org/10.5040/9781501335792">https://doi.org/10.5040/9781501335792</a>.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Cayley, John.  “Grammalepsy: An Introduction” ,  <em>Electronic Book Review</em> , 08-05, 2018, <a href="http://electronicbookreview.com/essay/grammalepsy-an-introduction">http://electronicbookreview.com/essay/grammalepsy-an-introduction</a>. Accessed August 12, 2018.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Cayley, John.  “The Language That Machines Read” . In  <em>Attention à la Marche = Mind the Gap: Penser la Littérature Électronique in a Digital Culture = Thinking Electronic Literature in a Digital Culture</em> , edited by Bertrand Gervais and Sophie Marcotte, pp. 105-113. Montreal: Les Presses de l’Écureuil, 2020.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Pavlick, Ellie. (2022)  “Semantic Structure in Deep Learning,”    <em>Annual Review of Linguistics</em> , 8:23, pp. 447-471. First published as a Review in Advance on November 23, 2021. {Available at: <a href="https://doi.org/10.1146/annurev-linguistics-031120-122924">https://doi.org/10.1146/annurev-linguistics-031120-122924</a>}&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Parrish, Allison.  <em>@everyword: The Book</em> . New York: Instar Books, 2015.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Mullaney, Thomas S.  <em>The Chinese Typewriter: A History</em> . Studies of the Weatherhead East Asian Institute, Columbia University. Cambridge: The MIT Press, 2017.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Nonsense Code: A Nonmaterial Performance</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000702/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000702/</id><author><name>Barry Rountree</name></author><author><name>William Condee</name></author><published>2023-07-20T00:00:00+00:00</published><updated>2023-07-20T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="1-happy-birthday-nonsense-and-nonmaterial-performance">1. Happy Birthday, Nonsense, and Nonmaterial Performance</h2>




























<figure ><img loading="lazy" alt="Scanned reproduction of 1950s title graphic featuring cartoon man in suit programming with paper and pencil. Title is “Basic Programming Univac 1 Data Automation System” ." src="/dhqwords/vol/17/2/000702/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000702/resources/images/figure01_hu5afb87c952e03020aedc9b86d02d0356_75680_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000702/resources/images/figure01_hu5afb87c952e03020aedc9b86d02d0356_75680_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000702/resources/images/figure01.png 448w" 
     class="landscape"
     ><figcaption>
        <p>Note that programming the UNIVAC 1 is done with pencil, paper, and flow charts.[^sperryrand1959]
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Scanned reproduction of 1950s title graphic featuring cartoon man in suit programming with paper and pencil. Title is “Basic Programming Univac I Data Automation System” ." src="/dhqwords/vol/17/2/000702/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000702/resources/images/figure02_hu5006675dc88e49366f817d6ce65aacef_118232_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000702/resources/images/figure02_hu5006675dc88e49366f817d6ce65aacef_118232_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000702/resources/images/figure02.png 468w" 
     class="landscape"
     ><figcaption>
        <p>Assembly language instructions for the UNIVAC 1.[^koss2003]
        </p>
    </figcaption>
</figure>
<p>Consider a somewhat mysterious computer tape from the early 1950s that was run a handful of times each year on Lawrence Livermore National Laboratory’s (LLNL) UNIVAC 1 computer. The code is easy enough to describe. Single instructions are repeated thousands of times, but the results of those instructions are discarded. The instruction loops are occasionally repeated. There are only a couple dozen of these loops. There is no program input or output. Execution takes less than twenty seconds.</p>
<p>The giveaway is the tape label: Happy Birthday. The UNIVAC 1, which filled an entire room, was a noisy machine. The noise varied in pitch, and the pitch depended on the electrical consumption needed for the different individual instructions the machine happened to be running. Executing those instructions repeatedly would increase the duration of that particular tone. This program was a favorite of pioneering programmer Mary Ann Mansigh Karlsen, a physics coder at LLNL from the mid-1950s to the mid-1990s. She would help celebrate her colleagues’ birthdays by calling their office from the machine room and serenading them by running the program on the tape <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Unfortunately, to the best of our knowledge, the tape for the UNIVAC 1 Happy Birthday has disappeared into history.</p>
<p>While hardly a consequential milestone in the history of computer science, this program does illustrate the limits of text-centric critical analysis. The semantic content of the code is irrelevant, yet that code is what drives the physical performance of the physical machine. Rerunning the code on a different computer (or a hardware emulator) reverts the performance back to nonsensical loops of instructions.</p>
<p>We offer this trivial example to illustrate a point central to this paper: code comprises text, purpose, and performance. That performance in turn is both material (the UNIVAC 1 humming Happy Birthday in the 1950s) and nonmaterial (mental models of a described, recollected, or intended performance). This code is the simplest example of what we define as nonsense code: the class of programs designed to change the physical state of the computer using side effects of the machine’s instructions.</p>
<p>We begin with a short review of Nonmaterial Performance (NMP) and define nonsense code. We then describe Firestarter and Platypus as examples of nonsense code and critique them using the framework of NMP. Firestarter is a processor stress test that makes use of Intel’s Running Average Power Limit (RAPL) technology, and Platypus is a set of processor side channel attacks that also make use of RAPL, as well as Intel’s Software Guard Extensions (SGX). Both Firestarter and Platypus rely on manipulating the physical machine, and in both cases the code remains opaque unless studied as performance.</p>
<p>Nonsense code poses challenges to traditional approaches in Critical Code Studies. We demonstrate how an NMP approach reveals how meaning, in the wild, can escape the authors’ initial intent, even in nonsense code.</p>
<h2 id="2-nonmaterial-performance">2. Nonmaterial Performance</h2>
<p>Nonmaterial Performance (NMP) is a framework that uses performance studies, actor network theory, and vibrant matter to expose how code acts in the world. NMP is based on four tenets: code abstracts, code performs, code acts within a network, and code is vibrant. The performance of code comprises the mental models, the text, and the machine’s physicality <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. In this paper we bring the framework of NMP to bear on code that is profoundly physical.</p>
<h2 id="code-abstracts">Code Abstracts</h2>
<p>Abstractions, which are ubiquitous in computer science, hide nuance and detail in order to create concepts that are simpler to work with. There are dozens of layers of abstractions, beginning with the silicon, up through assembly language (the lowest level of abstraction available to programmers), and on to high-level programming languages and frameworks. These abstractions, of course, still affect the machine at the physical layer — the abstractions hide complexity, not remove it.</p>
<p>There is a similar idea of abstraction in mathematics, but mathematical abstractions such as  <code>sum()</code>  and  <code>average()</code>  destroy information (one can&rsquo;t get back to the original data given a sum or average). Abstraction in computer science only hides the information <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>; underneath the assembly language instructions, the picky details still exist. Abstraction in computer science, then, is done for the convenience of the programmer.</p>
<p>If one wants to manipulate the physical machine through code, the only tools available are the higher-level abstractions of programming languages. Given a deep enough knowledge of a particular architecture and software stack, one can use these abstractions to change the properties of the physical machine. Because the abstractions were not created to bring about physical change, the resulting code looks like nonsense.</p>
<h2 id="code-performs">Code Performs</h2>
<p>The textual representation of code, like the script of a play, is only a score for its performance. According to Richard Schechner, the focus of performance studies is human behavior:  “any action that is framed, presented, highlighted or displayed is a performance”   <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. Performance studies provides useful models for highlighting behaviors not previously framed as performance and/or not privileged as objects for study, including not only the arts, but also sports, business, sex, ritual, play, everyday life — and technology (although Schechner acknowledges that the last is  “not usually analyzed” ) <sup id="fnref1:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<p>Schechner famously defines performance as  “restored behavior”  and  “twice-behaved behavior,”  and goes on to suggest that when  “onceness”  is  “broken down finely enough and analyzed,”  the behaviors  “are revealed as restored behaviors”   <sup id="fnref2:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. In other words, it is restored behavior all the way down. Similarly, in computing, individual actions (in the form of assembly language instructions) are all restored behavior — there is nothing new that can be done on a processor. It is only the aggregation of twice-behaved behavior that makes novelty possible. Both programmers and performers wield their creative power through the combination of these existing behaviors <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Code Acts within a Network</p>
<p>Code performs within multiple layers of networks, comprising both objects and humans. NMP employs actor-network theory (ANT) to crack open computing in ways not possible with standard computer science approaches. From an ANT perspective, everything in the social and natural world is the result of a diverse web of  “materially heterogeneous”  relations <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. ANT privileges neither humans nor objects, since neither alone determines the processes and outcomes of these networks. Instead, networks consist of the interaction of humans and objects, with implications for all. ANT uses Bruno Latour’s term  “actant,”  which Jane Bennett defines as  “a source of action that can be either human or nonhuman; it is that which has efficacy, can do things, has sufficient coherence to make a difference, produce effects, alter the course of events”  (<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>; <sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>). Code is Vibrant</p>
<p>We borrow the idea of vibrancy from Bennett’s book, Vibrant Matter: A Political Ecology of Things. While matter is conventionally viewed as passive, Bennett asserts that matter is vibrant. She describes the  “vitality”  of matter as  “the capacity of things . . . not only to impede or block the will and designs of humans but also to act as quasi agents or forces with trajectories, propensities, or tendencies of their own”   <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Her goal is  “to articulate a vibrant materiality that runs alongside and inside humans”   <sup id="fnref2:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Similarly, the conventional view of code requires that it be inert: fashioned to fulfill the single intent of its author. From an NMP perspective, code in performance also has vibrancy: the ability to act and have influence independent of its creators <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. As we will conclude, what code execution means ultimately accrues in the domain of human perception, and these meanings are informed by the unseen ensemble of performance occurring behind the screen. That meaning is unstable, independent of the author’s intention, and contingent on time and place. NMP makes the nonmaterial visible <sup id="fnref2:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<h2 id="3-nonsense-code">3. Nonsense Code</h2>
<p>As noted above, we define nonsense code as the class of programs designed to change the physical state of the computer using side effects of the machine’s instructions. The text of code abstracts away physical details such as energy consumption, thermal characteristics, and electrical resonance; nonsense code uses its text to manipulate those physical characteristics. Examining this class of code without considering its performance — what it actually does to the physical machine — renders it nonsense. In the case of Happy Birthday, the machine instructions of the UNIVAC 1 did not provide a mechanism for creating sounds. That physical effect had been abstracted from the text of the instructions. What makes the Happy Birthday tape compelling is that the programmers ignored the instructions’ semantics (for example, adding up numbers) in order to manipulate the material implementations of those instructions (for example, making the machine hum the note G). The result is textual nonsense and an amusing performance. Assembly language instructions will, in performance, inadvertently cause a computer to consume more power, increase its temperature, and resonate at a particular frequency. The text of these instructions, however, does not convey this physicality. Nonsense code, then, relies on the physical side effects that have been abstracted away from the code.</p>
<p>Evolvable hardware (and the evolutionary algorithms used to create it) bears more than a passing resemblance to nonsense code: the results are often impenetrable, but the reason for the impenetrability differs. The evolutionary algorithms used for creating hardware manipulate theoretical abstractions of actual physical components to arrive at a solution that fits the constraints of the problem. That abstract solution can then be transformed into physical hardware <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. Nonsense code also uses abstractions, but does so in order to manipulate the physical properties of a machine that does not appear in the abstractions. The evolutionary algorithm for evolvable hardware does not know and cannot discover what details have been elided in the abstractions it was given. Those details are available to the author of nonsense code.</p>
<p>Most examples of Critical Code Studies focus primarily on the textual representation of a program, which is the immediate point of entry for code analysis. Our approach centers instead on the performance of code, which is especially valuable for the vast majority of cases for which text is unavailable. Code may be unreleased (Platypus), proprietary (RAPL, SGX), or simply lost (Happy Birthday). In such cases, approaches from performance studies, relying on paratextual information, including oral history, documentation, specifications, and scholarship, restore and interpret ephemeral performances.</p>
<h2 id="4-firestarter">4. Firestarter</h2>
<pre><code>Author: Daniel Hackenberg     Citation: D. Hackenberg, R. Oldenburg, D. Molka and R. Schöne,  “Introducing Firestarter: A processor stress test utility,”  2013 International Green Computing Conference Proceedings, Arlington, VA, USA, 2013, pp. 1-9, [doi:10.1109/IGCC.2013.6604507](https://doi.org/10.1109/IGCC.2013.6604507).     Version: 1.7.4 (1.0 released in 2013, 2.0 released in 2021)    Source:  [https://github.com/tud-zih-energy/Firestarter](https://github.com/tud-zih-energy/Firestarter)      Invocation:   `./Firestarter — timeout=60 –report`       Technical Description:  
</code></pre>
<p>Firestarter is a processor stress test, essentially a program that makes the processor work as hard as possible in order to determine how the processor will behave under high load, for example, testing cooling systems at maximum power <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. Prior to the creation of Firestarter, best practice was to use numerically intensive codes such as Prime95 or LINPACK. These codes, however, were written to solve mathematical problems, and only incidentally required a large amount of power. Firestarter is designed to consume maximum power — and nothing else. As such it can reach both higher and more consistent levels of power consumption, thereby producing more reliable results. Firestarter’s code is a carefully constructed mass of assembly language instructions that work nearly all of the components of the processor simultaneously and as hard as possible — without calculating anything useful at all. Firestarter thus meets our definition of nonsense: its purpose is to change the state of the physical processor using the side effects of the available assembly language instructions.</p>
<p>In this section we briefly critique Firestarter, as well as demonstrate its vibrancy when repurposed.</p>




























<figure ><img loading="lazy" alt="Screenshot of terminal session with 58 lines of logging and performance stats for Firestarter." src="/dhqwords/vol/17/2/000702/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000702/resources/images/figure03_hu9e236349967ce634027566c364cc921d_186519_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000702/resources/images/figure03_hu9e236349967ce634027566c364cc921d_186519_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000702/resources/images/figure03.png 452w" 
     class="portrait"
     ><figcaption>
        <p>A brief Firestarter run on 112 CPUs across two Xeon processors.[^rountreecondee2021]
        </p>
    </figcaption>
</figure>
<p>We begin with the output of a short Firestarter run (Figure 3). A few technical details require explanation in order to understand how this code becomes nonsense. Lines 1-5 are code attribution and licensing information. Lines 7-41 describe Firestarter’s understanding of the architecture it is running on. For clarity, we have included the results of only four of the 112 CPUs: 0, 1, 110 and 111. The performance report begins on line 44 and provides a total number of iterations completed for each CPU during the run (again, we only show CPUs 0, 1, 110 and 111). Adjacent to those values is the amount of time taken in clock ticks ( <code>tsc_delta</code> ).</p>
<p>In the performance recorded in Figure 3, Firestarter is executed for 60 seconds across 112 hyperthreads on two Cascade Lake processors. Lines 46-50 are of particular interest. Each thread reports how many iterations of the Firestarter payload loop it executed and how long it spent running those loops. The elapsed time for each thread is remarkably consistent: the difference between the longest-running thread of the four threads shown (thread 0) and the shortest-running thread (thread 110) is just over 0.02%.</p>
<p>The total work accomplished, however, by thread 110 is 4.2% greater than thread 0. Under this kind of load and this particular power management regime, not all hyperthreads are created equal (we will return to this phenomenon momentarily).</p>




























<figure ><img loading="lazy" alt="Screenshot of about assembly, with about 50 lines in a four-column format." src="/dhqwords/vol/17/2/000702/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000702/resources/images/figure04_hu96c553b9d3b9acde29af80381cbde6d4_282789_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000702/resources/images/figure04_hu96c553b9d3b9acde29af80381cbde6d4_282789_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000702/resources/images/figure04.png 468w" 
     class="landscape"
     ><figcaption>
        <p>A portion of the handwritten assembly code used during the Firestarter execution recorded in Figure 3 [^hackenberg2013].
        </p>
    </figcaption>
</figure>
<p>Figure 4 shows a portion of the code being executed. The code is x86 assembly language using AT&amp;T syntax embedded in a larger C language function. There are two unusual aspects of this code. First is the four-column formatting, since each CPU in this architecture can retire up to four instructions per cycle — in simpler terms, each CPU can do four things at once. After a great deal of study and experimentation, the Firestarter authors were able to handcraft the selection and placement of these instructions so that they do in fact execute simultaneously. As a result, the program causes the computer to do more work and consume more energy per unit of time. Their accomplishment may not appear at first blush to be that astonishing: each CPU can execute four instructions, and they wrote code to do that. However, most non-nonsensical programs rarely have more than one instruction executing at a time, and very few reliably get up to three instructions per tick. What the Firestarter authors accomplished was to assemble a jigsaw puzzle in space and time, finding exactly which instructions could be cobbled together based only on their particular fit. This approach exposes the second unusual aspect of Firestarter: it uses a great deal of energy to do nothing in particular.</p>
<p>Closer study of the code reveals multiple duplicated patterns: results are repeatedly calculated, overwritten, and discarded. The simplest pattern occurs in the instructions placed in the decode 2 column.</p>




























<figure ><img loading="lazy" alt="Cropped screenshot of six assembly instructions from the decode2 column, e.g. “shl $1, %%edi;”" src="/dhqwords/vol/17/2/000702/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000702/resources/images/figure05_hu3828eab23eec1f74cd45fea8b7b355fd_11789_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000702/resources/images/figure05_hu3828eab23eec1f74cd45fea8b7b355fd_11789_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000702/resources/images/figure05.png 111w" 
     class="landscape"
     ><figcaption>
        <p>Detail of Figure 4 [^hackenberg2013].
        </p>
    </figcaption>
</figure>
<p>The values in these three registers (edi, esi, and edx), as seen in Figure 5, are shifted to the left by one bit (shl), then shifted back to the right by one bit (shr), over and over again. At a semantic level, this repeated shuffling back-and-forth accomplishes nothing. Moving the values in these 64-bit registers does not consume nearly as much power as the 512-bit registers used in the decode 0 and decode 1 columns, nor does it take as much power as the cache transfers under decode 3. But these shift instructions do soak up that last bit of execution capacity, thus they have found their place here.</p>
<h2 id="critique">Critique</h2>
<p>Focusing solely on the text of the code itself runs headlong into its pointlessness. Alternatively, including the authors’ intent (as recorded in the code comments and authors’ published papers) reveals one meaning of Firestarter, but does not exhaust the potential for other meanings. Code is sufficiently vibrant to escape the intent of the authors, and we now discuss how the nonsense of Firestarter reveals the messy details behind another abstraction: all processor cores are created equal.</p>
<p>In introducing Firestarter, we touched on its origins in heating and cooling processors. Most cooling occurs when the processor decides to run more slowly (thus consuming less energy and generating less heat), so as not to cook itself. To understand how this relates to Firestarter, it is necessary to go back to August, 2008, and Intel’s introduction of the multicore Nehalem processor architecture.</p>
<p>Prior to Nehalem, processors had a maximum speed (the CPU clock frequency) that would support any workload. Nehalem changed that equation. Restricting a workload to a single core meant that particular core could run at the maximum clock frequency; using more than one core lowered the ceiling for all cores. Higher clock frequencies use quadratically more power, so for a given processor, the programmer could spend the power budget on fewer, faster cores or more, slower cores. For the first time, configuration had to encompass both code and the underlying processor.</p>
<p>In subsequent architectures, power and performance management strategies included in the processor became increasingly sophisticated, and while manufacturers exposed a few interfaces to this firmware, processor vendors kept the underlying actants (algorithms and implementation) opaque. A program like Firestarter allowed researchers to see how processors reacted to predictable loads, particularly those that were designed to draw maximum power and generate maximum heat.</p>
<p>As an example, here are the results of multiple Firestarter runs on the dual Cascade Lake machine mentioned above.<br>
Firestarter 60-second runs, using different numbers of cores (column 1). The resulting units of work completed (column 2) scale poorly. (Rountree)    Number of cores  Units of work completed in 60 seconds      1   1.0      14   9.9      28   13.3      56   27.0      112   24.7   <br>
Here, the use of Firestarter has shifted. Rountree repurposed an unmodified Firestarter into a performance evaluation tool. A single CPU completes a (normalized) unit of work in 60 seconds. Increasing the number of CPUs running simultaneously from 1 to 14 does not result in 14 units of work completed; instead, the result is just 9.9. Using all 112 CPUs only increases the completed work to 24.7. The fact that this processor scales poorly is less relevant here than Firestarter being used in a novel way: as a generic work generator. The purpose is malleable, even if the text is fixed.</p>
<p>Table 1 (above) shows a small example of using a nonsense code for a purpose other than for which it was designed. While one can delineate code through its purpose, text, and performance, doing so does not prevent code from being repurposed and re-presented. Because of this potential to be repurposed, code is vibrant. Code is not defined by a single meaning; it generates multiple meanings, and understanding one particular meaning does not necessarily give insight into any others.</p>
<p>Earlier in this paper we noted the different magnitudes in time and work completed across different hyperthreads (Figure 3 lines 46-50). Firestarter had been developed on a handful of machines, and any differences across cores, processors, or threads were not seen as significant enough to include in the initial paper introducing Firestarter. Rountree ran Firestarter across 4,200 Broadwell processors for 350 minutes (60 seconds for each run). Across that much larger population of processors, the observed variation became much more interesting.</p>




























<figure ><img loading="lazy" alt="Data plot of Firestarter scaled performance (Y) in processor cores 1-18 (X) for three processors (box-and-whisker data)." src="/dhqwords/vol/17/2/000702/resources/images/figure06.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000702/resources/images/figure06_hu65fce6fb3c85e45de502fb0085e6585b_154294_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000702/resources/images/figure06_hu65fce6fb3c85e45de502fb0085e6585b_154294_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000702/resources/images/figure06.png 468w" 
     class="landscape"
     ><figcaption>
        <p>The three bands of box-and-whisker plots are the best, median, and worst out of 4,200 Broadwell processors. Note that the variation within this single processor model can exceed 20% [^marathe2017].
        </p>
    </figcaption>
</figure>
<p>The three horizontal bands in Figure 6 correspond to the best, median, and worst processors out of the 4,200 processors characterized. These Broadwell processors have 18 cores with two hyperthreads per core. Each box-and-whisker plot represents the scaled number of iterations for a single hyperthread across 350 60-second executions of Firestarter (the box represents 50% of the results, the whiskers represent the total range).</p>
<p>The most striking result from this graph is that the performance of the best, median, and worst processor under Firestarter do not overlap at all, despite being ostensibly the same processor model. There is also variation across cores (core 12 is consistently better than 13), hyperthreads (hyperthread 1 is consistently a bit better than hyperthread 0 across all cores and processors), and from run to run (the height of each box-and-whisker plot). What Firestarter reveals, serendipitously, is the nuance and detail abstracted away by the shared concepts of processor,  core, and hyperthread. For a particular processor model, the received abstraction is that all processors of that type are identical, certainly insofar as performance is concerned. Within a given processor, a core is abstracted to the point where it becomes identical to all other cores, and likewise for hyperthreads; there is no programmatic method for distinguishing them. Slight variations within the silicon will make some processors more or less efficient — essentially, it takes fractionally more energy to push bits down the wire. Processors that, by luck of the draw, are less efficient will heat up more quickly at the same CPU clock speed, meaning they will have to slow down sooner, and thus get less work done. Note that Firestarter remains unmodified and the purpose has shifted yet again: Firestarter is now a tool for revealing variation in silicon across populations of processors. The only way of getting to the nuance and detail of processor performance is through observing that performance under load. And the only way of maximizing that load is through nonsense.</p>
<p>From some previous Critical Code Studies perspectives, the starting point is the text of Firestarter, and while the comments and apparatus surrounding that code do indicate the authors’ intentions, textual analysis does not exhaust the potential meanings. Firestarter (and nonsense codes in general) generate meaning based on performance in particular environments. NMP centers the analysis on the performance.</p>
<p>Returning to the tenets of NMP described above (code abstracts, code performs, code acts within a network, and code is vibrant), we focus here on how Firestarter is vibrant. To make the notion of vibrancy more concrete, consider puppetry. Shari Lewis, the great puppeteer of Lamb</p>
<p>Chop fame, describes the importance of discovering  “what the puppet wants to do”  (quoted in <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>). John Bell goes on to describe the  “weird concept of letting the object determine action”   <sup id="fnref1:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. A puppeteer may design a puppet for a particular character, play, and action. Through play, however, the puppet reveals what it can do and what it wants to do, unveiling a myriad of new possibilities. In other words, the puppet has vibrancy.</p>
<p>Programmers (and perhaps code critics) can be tempted to think that code does one thing. Instead, playing with Firestarter reveals what else it wanted to do: expose inhomogeneity <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. Rountree allowed Firestarter to perform in new ways, which was unplanned by its authors. Because code is vibrant, those actions were discoverable and discovered. Firestarter reveals that, even at the level of assembly language, individual instructions have their own vibrancy. Shift-left (shl) does indeed shift the bits in the given register to the left, but it also takes time, draws power, fills a decoder slot, affects how surrounding instructions are scheduled by the processor, and can ultimately slow the processor down and unmask variation. None of this potential vibrancy is recorded in the textual representation of shl. Accessing that vibrancy requires the combination of an imagined, nonmaterial performance and the careful measurement of a material performance.</p>
<p>Firestarter illustrates the pointlessness of trying to nail code that has been released in the wild to a single meaning or purpose. Firestarter was explicitly designed as the epitome of pointless busywork. Without modification, however, it was used to measure work rates under increasing loads and core counts, and as a tool for quantifying processor, core, hyperthread, and runtime variation across thousands of processors.</p>
<p>The skilled puppeteer asks, What does the object want (and not want) to do? Forcing thousands of processors to behave identically is possible, but only by limiting their performance to the lowest common denominator. The notion of vibrancy enables the question, What is possible given that supercomputers consist of thousands of inhomogeneous processors? Once that question is on the table, computer scientists can rethink job scheduling, power efficiency, and performance reproducibility. From the Critical Code Studies perspective, vibrancy opens the door to thinking about processors as individual, unique entities whose traits (e.g., efficiency, speed, thermal characteristics, etc.) exist across a spectrum.</p>
<h2 id="5-platypus">5. Platypus</h2>
<pre><code>Author: Moritz Lipp et al.     Citation:   “PLATYPUS: Software-based Power Side-Channel Attacks on x86” , 2021 IEEE Symposium on Security and Privacy.     URL:  [https://platypusattack.com](https://platypusattack.com)      Source: Proof-of-concept code has not been released.   
</code></pre>
<h2 id="safecrackers-and-side-channel-attacks">Safecrackers and Side-Channel Attacks</h2>




























<figure ><img loading="lazy" alt="Newspaper clipping of 1950 headline." src="/dhqwords/vol/17/2/000702/resources/images/figure07.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000702/resources/images/figure07_hu3ac06b894a96805317a8a8e8a4c74b6f_35833_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000702/resources/images/figure07_hu3ac06b894a96805317a8a8e8a4c74b6f_35833_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000702/resources/images/figure07.png 468w" 
     class="landscape"
     ><figcaption>
        <p>Headline from 1950s newspaper article about safecracking: “Locksmiths Used to Worry About Yeggs; Now It&rsquo;s Spies” [^winget1950].
        </p>
    </figcaption>
</figure>
<p>Daniel Gruss and his students at the Technical University of Graz created Platypus to demonstrate the feasibility of one form of side-channel attacks that exploit processor vulnerabilities. Gruss is best known for co-discovering and analyzing the Spectre <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> and Meltdown <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> side-channel attacks. In these attacks, information designed to be kept secret on a computer was attacked using the processor cache as a side-channel. For Platypus, the side channel is the processor’s energy accounting system. These kinds of attacks leverage features found in nearly all mobile, consumer, and server-grade processors. They are particularly difficult to guard against because they exploit the underlying system architecture rather than software faults.</p>
<p>Platypus was announced to the world in November, 2020 (<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>; <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>). Shortly thereafter, processor-power research was restricted at LLNL while the seriousness of the vulnerability was evaluated by a team headed by Rountree, as well as by teams at Intel, AMD, IBM, nVidia, and Arm. As a result, Intel updated its processor microcode and a Platypus attack entered the security lexicon.</p>
<blockquote>
</blockquote>
<p>To understand side-channel attacks, consider state-of-the-art safecracking in 1950: Combination locks are simple. Discs with slots are aligned until a lever falls into the slots. Then the lock opens. The moving discs and the falling lever make a noise. Legendary cracksmen filed their fingertips to the quick and felt the movement. So locks were refined. Then cracksmen used stethoscopes to listen to the movement. Locks were then made too smooth for that device.</p>
<p>But the war brought on the development of electronic detection of supersonic sound. In any radio store you can buy the apparatus. Cracksmen use an aerial the size of a knitting needle some six inches high set in a base the size of a biscuit. Push it against the safe dial. The sound is picked up, amplified in a box about six by four by two inches in size and recorded on a dial like the ammeter in a car.</p>
<p>What happens inside the combination lock is read as easily as an electro cardiograph by a physician. Which means it is not easy, but it can be done by an expert.</p>
<p><sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> <br>
The author quoted above offers an abstraction of a combination lock:  “[d]iscs with slots are aligned until a lever falls into the slots.”  When this abstraction is translated into physical reality, a side-channel opens: metal rubs against metal, levers scrape along dials, and information leaks. Side-channel attacks, then, are not head-on: no dynamite blows open the safe door. Instead, the side-channel attack relies on details of the physical machine that have been abstracted away.</p>
<h2 id="sgx-and-the-cloud">SGX and the Cloud</h2>
<p>The particular Platypus attack we critique recovers a cryptographic key from Intel’s Software Guard Extensions system. SGX, as it is more commonly known, was introduced in 2013 as the most recent attempt to solve a problem of great commercial interest: how can a user safely run code on a machine owned and maintained by someone they do not necessarily trust? For example, a hypothetical tech startup has a new way of applying machine learning to medical imaging. The images can be encrypted at the hospital and sent to the startup and the results can be encrypted and sent back. But the startup doesn’t want to own the pile of computers needed for the analysis when it is so much cheaper to rent them from Amazon, Google, Microsoft, or another cloud provider.</p>
<p>SGX is yet another layer of defense to address the scenario in which an attacker has gained control of the machine and can observe and modify the operating system. SGX adds the capability to create what is called an enclave: a secure space that would allow code written and uploaded by the medical imaging startup to be executed in such a way that no compromised operating system can read it. The startup can cryptographically sign their code before loading it, and then have SGX validate that it received the code unmodified. Even if an adversary has physical possession of the machine and the ability to tap the memory bus, no decrypted information will be visible.</p>
<p>In this example, the startup would put code in the enclave to decrypt the incoming image, do whatever it does with machine learning, and encrypt the results. The small amount of code that runs outside of the enclave only forwards encrypted images into the enclave and forwards encrypted results back to the hospital.</p>
<p>Platypus managed to crack this system. To see how this was done, we need to sketch two more subsystems in Intel processors: Running Average Power Limit (RAPL) and the Advanced Programmable Interrupt Controller (APIC).</p>
<h2 id="rapl">RAPL</h2>
<p>For Platypus, energy measurement is the side-channel capable of being attacked. In response to the needs of both its mobile and datacenter customers, Intel unveiled its Running Average Power Limit (RAPL) technology in its Sandy Bridge architecture in 2010. RAPL allows the operating system to set upper limits on the amount of power the processor is allowed to consume and, more crucially for Platypus, measure how much energy has been used. Every so often (in this case, approximately every fifty microseconds), the energy meter on the processor is updated: a particular register is incremented by the number of fractional Joules that have been consumed since the last update.</p>
<p>Given physical access to a much simpler (and slower) processor and an expensive oscilloscope, one can surreptitiously observe the electrical signal generated by individual instructions, and perhaps even infer something about the data. The general term for this kind of attack is Differential Power Analysis <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. Given a large number of electrical traces at a high enough sampling rate, good-enough guesses can be made about enough of the cryptographic key to allow its eventual recovery. For simple systems that are expected to be in the physical control of an adversary (smartcards, mobile devices), this analysis is a realistic method of attack. What appears to preclude its use here in more complex processors is that thousands of instructions can be executed over the fifty-microsecond energy update time. There is not enough energy information to identify individual instructions, thereby making this attack apparently infeasible in the real world.</p>
<h2 id="apic">APIC</h2>
<p>The second Intel subsystem required by Platypus provides precise user control over interrupts. The Advanced Programmable Interrupt Controller (APIC) is a much older technology with roots in the 80486 Intel processor introduced in 1989. The idea of interrupts goes back much further (to the 1953 UNIVAC 1103), solving what was then a universal performance problem. Prior to interrupts, when a program needed to interact with the outside world (for example, reading or writing to a tape), all progress came to a halt until that read/write request succeeded or failed. Interrupts allowed a program to do two things at once: the program, while continuing to run, says, in effect, Go write this data to the tape drive and interrupt me when you’re done. While the program is running, the tape device can complete its operation in its own time. When the tape completes, it notifies the program by raising an interrupt.</p>
<p>At the physical level, when the processor receives an interrupt, whatever code happened to be running is interrupted, and control is transferred to the operating system, which checks for errors and updates needed bookkeeping. Once that is complete, the previously running code is allowed to continue (usually none the wiser that it had been momentarily halted).</p>
<p>APIC allows the operating system to trigger an interrupt at a precise moment in the future. There are several registers that keep track of time. At each clock tick, 1 is added (incremented) to the current value in the register. But rather than incrementing once per second, recent processors increment much faster — more than one billion times each second. Assembly language instructions in a program take several clock ticks (billionths of a second) to make it through the processor pipeline, so this clock is essentially running faster than instructions can execute. In a bit of foreshadowing, APIC can set an interrupt to occur just a handful of ticks in the future.</p>
<p>We now have all the pieces in place to describe the Platypus attack.</p>
<h2 id="the-attack">The Attack</h2>
<p>Returning to the attack on the enclave: What happens when an interrupt is received when code is executing in the secure space of an SGX enclave? There are two bad choices: First, put off dealing with the interrupt until the secret code that is executing in the secure enclave completes (which might be anywhere from milliseconds to weeks). Second, hand off control to the operating system and hope it has not been compromised. SGX makes a better choice. SGX wipes out any unencrypted data in the cache and only then transfers control to the (untrusted) operating system. The operating system sees no data, encrypted or otherwise, in the cache and cannot decipher any of the encrypted data still in memory. When the operating system finishes handling the interrupt, it passes control back to SGX, which will reload the enclave back into cache and decrypt the secret code again. An attacker who is able to generate interrupts at will, for example through APIC, is still not going to get a chance to see unencrypted data. So far, SGX appears secure.</p>
<p>How does one break into this locked room? During that interrupt-handling process, the side channel has continued to accumulate energy. Can the measurements reveal what was happening during enclave execution? Not really. At best, that measurement refers to the accumulated energy of several thousands of instructions that executed during the fifty-microsecond update window. There’s no way to pick out individual instructions from that single energy reading, much less their associated data. SGX still appears to be secure. The technique used by Platypus to solve this locked-room mystery is called zero stepping. Debuggers allow programmers to slowly single-step through each assembly language instruction to observe its effects at human timescales. Zero-stepping, in contrast, executes the same single instruction over and over again. If a secret instruction running in an enclave could be zero-stepped for fifty microseconds, the energy measurement would cover only that instruction (and the interrupt process). That measurement may be enough to identify the instruction and its data. Processors do not support native zero-stepping, but processors do provide APIC. Platypus’s trick is to schedule the APIC interrupt a handful of ticks in the future to throw an interrupt just as the first secret instruction running in the enclave is finishing. Platypus has already added code (an interrupt handler) into the compromised operating system to schedule another interrupt the same number of ticks into the future as the first. The effect is that the first secret instruction in the enclave is executed over and over again, never quite finishing, because it keeps getting interrupted. If this pattern can be held for a hundred microseconds or so, the energy measurement will capture that instruction, as well as all the other instructions involved with firing the interrupt, running the interrupt handler, and restarting the enclave. When enough energy information has been gathered on the first secret instruction, a similar sequence begins: the second instruction is executed over and over again. The net effect is that Platypus gets precise-enough energy measurement on each secret instruction executing in the secure enclave to decode it. That is enough to identify not only the instruction but the data it uses. Platypus effectively creates an oscilloscope out of a combination of APIC and RAPL, thereby recovering the secret key used by the enclave to decrypt the secret program.</p>
<p>Absent all the above context, the execution of a Platypus attack is inscrutable: a single instruction is continuously interrupted over and over and over again. That process of continuous interruption modifies the underlying physical state of the machine. Measuring that state allows the recovery of secret information. Platypus is nonsense.</p>
<p>A noncomputing example might elucidate how Platypus works, albeit in a simplistic and partial way. Bill obsessively vacuums his bedroom. Barry is aware of this hangup and is trying to help Bill. So, Bill starts vacuuming, and Barry knocks on the door. Bill, trying to mask his behavior, stops vacuuming, hides the Hoover in the closet, and invites Barry in. Barry looks around, sees nothing, and leaves. Bill resumes cleaning, Barry knocks again, Bill hides his Hoover, Barry enters, looks around, and leaves. Meanwhile, Bill has a few lights on (he’s not a Roomba and can’t vacuum in the dark) and is making coffee (Bill’s obsession runs on caffeine). This cycle of vacuuming, knocking, hiding, entering, and leaving repeats scores or hundreds (or in the case of Platypus, thousands) of times. Barry, still suspicious and concerned about his friend, proceeds to examine Bill’s electrical meter. He is able to read the background usage, indicating the ongoing use of lights and Mr. Coffee. But he is also able to see repeated spikes of electricity usage of a particular shape. Because Barry owns a similar vacuum cleaner, he knows the particular electrical pattern of Bill’s WindTunnel Air Steerable Upright (as opposed to the spikes from the dryer or Bill’s welding hobby). Busted. Reading the electrical meter is a side channel attack by which Bill’s activity can be covertly observed and disambiguated. And, to return to Rountree’s story, this is what caused LLNL to, metaphorically, lock up their power meters.</p>
<p>Returning to the startup example: the attacker knows the first task the enclave is going to perform is decrypt the data. Determining which encryption algorithm is used, how long the key is, etc., will be a tedious effort, but it’s an effort that can be automated. At the end of the process, the attacker has the key and can decrypt the medical images prior to their being loaded into the enclave.</p>
<h2 id="critique-1">Critique</h2>
<p>Platypus is not the first side-channel attack on SGX, although it is the first one to use power. The vulnerabilities exposed by the Platypus research are not considered to be nearly as serious as Spectre and Meltdown. Mitigating power as a side channel attack for SGX may be as simple as having the processor not update the energy meter when running inside an enclave. Unlike Spectre/Meltdown, however, Platypus is (just) simple enough to be described in some detail to people who are not computer security professionals.</p>
<h2 id="code-acts-within-network">Code Acts within Network</h2>
<p>Returning to the tenets of NMP, we focus here on how Platypus exists within an actor network, which includes a precise, programmable interrupt controller, a fine-grained energy meter, an operating system that provides access to both, and a security enclave that lies beyond the operating system but executes on the same processor cores. Absent any of these, there is either no need for Platypus, or Platypus can’t exist. These actants are themselves code, and each comes with its own set of abstractions and vibrancies. Platypus is a study in how these separate code-actants, created in different decades by different teams for different markets, did not quite align well enough to prevent information leakage.</p>
<p>Code is not written in isolation. Both exploits and critiques can occur at the joints of the actant-network. At a broader level, Platypus exists because SGX exists, SGX exists because cloud computing exists, and cloud computing exists because of the economics of renting computers to process private information. Part of those economics is the expense of maintaining computers securely in the face of growing and changing complexity across the hardware and system software stack, with that complexity being driven by the perceived needs of the market.</p>
<h2 id="6-conclusion">6. Conclusion</h2>
<p>By choosing these particular examples we decentered the text of the code. Asking what Happy Birthday, Platypus, or Firestarter mean could not be answered by a recitation of algorithms used or a summary of code comments. Instead, we had to begin with abstractions, performances, and networks, and from there to paratextal resources: author interviews, peer reviewed publications, and discussions among colleagues. In doing so, we rediscovered two axioms: meaning accrues in the relationship of actants in a network and meaning changes as the network changes. The fact that code abstracts and performs in these fluid networks is what reveals the vibrancy of code.</p>
<p>Happy Birthday meant, at the time of its creation, that computers, such as Mary Ann Mansigh Karlsen, had the freedom to play with a new piece of arithmetic equipment. Decades later its meaning evolved and became, alongside the scientific work she supported, one her most vivid and pleasant memories. In a decade of working with Firestarter, Rountree has seen it transform into a catalyst for revealing unspoken processor design decisions. With Platypus, Daniel Gruss and his students took advantage of the change in the network that occurred when Intel introduced secure enclaves to a platform with sophisticated energy measurement and interrupt control.</p>
<p>The contribution of this paper is mapping out the mechanisms and limits of those meanings.</p>
<pre><code>Code abstracts:  
</code></pre>
<p>Languages allow programmers to work with a simpler world than physical reality.<br>
Code performs:<br>
Unlike mathematics, code has an embodied physicality of heat, energy, and resonance.<br>
Code acts within a network:<br>
The network in which the code performs is not fixed, and meaning accrues in the juxtapositions of its actants. If one changes the network, the meaning changes.<br>
Code is vibrant:<br>
Code cannot be nailed to a single meaning. Meaning is generated within a particular relationship of a particular set of actants, including text, machine, and people. Vibrancy describes what happens as the actants and their relationships change.</p>
<p>Asking what code means is the wrong question. Diversity of meaning is limited only by the diversity and relationships of actants. Instead, ask what the network means.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Rountree, B. and Condee, W. (2021)  “The Nonmaterial Mirror: Performing Vibrant Abstractions in AI Networks” ,  <em>Theatre Journal</em> , 73, pp. 299–318.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Condee, W., and Rountree, B. (2020)  “Nonmaterial Performance” ,  <em>TDR: The Drama Review</em> , vol. 64, no. 4, pp. 147-57.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Colburn, T., and Shute, G. (2007)  “Abstraction in Computer Science” .  <em>Minds and Machines</em> , vol. 17, pp. 169–84.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Schechner, Richard. (2006)  _ Performance Studies: an Introduction._  2nd edition. pp. 1-31.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Law, J. (2009)  “Actor Network Theory and Material Semiotics” , In Turner B. (ed.),  <em>The New Blackwell Companion to Social Theory</em> . Wiley-Blackwell, Chichester, UK, pp. 141–58.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Bennett, J. (2010)  <em>Vibrant Matter: A Political Ecology of Things</em> . Durham: Duke University Press.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Cancare, F., Bhandari, S, Bartolini, D., Carminati, M., and Santambrogio, M. (2011)  “A Bird’s Eye View of FPGA-based Evolvable Hardware” . In  <em>2011 NASA/ESA Conference on Adaptive Hardware and Systems (AHS)</em> , pp. 169-175, <a href="https://doi.org/10.1109/AHS.2011.5963932">doi:10.1109/AHS.2011.5963932</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Hackenberg, D., Oldenburg, R., Molka, D., and Schöne, R. (2013)  “Introducing Firestarter: A Processor Stress Test Utility” ,  <em>2013 International Green Computing Conference Proceedings</em> , pp. 1-9, <a href="https://ieeexplore.ieee.org/document/6604507">https://ieeexplore.ieee.org/document/6604507</a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Bell, J. (2008)  <em>American Puppet Modernism: Essays on the Material World in Performance</em> . New York: Palgrave Macmillan.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Inadomi, Y., Patki, T., Inoue, K., Aoyagi, M., Rountree, B., Schulz, M., Lowenthal, D., Wada, Y., Fukazawa, K., Ueda, M., Kondo, M., and Miyoshi, I. (2015)  “Analyzing and mitigating the impact of manufacturing variability in power-constrained supercomputing” ,  <em>SC &lsquo;15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</em> , pp. 1-12, <a href="https://doi.org/10.1145/2807591.2807638">doi:10.1145/2807591.2807638</a>.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Kocher, P., Horn, J., Fogh, A., Genkin, D., Gruss, D., Haas, W., Hamburg, M., Lipp, M., Mangard, S., Prescher, T., Schwarz, M., and Yarom, Y. (2019)  “Spectre Attacks: Exploiting Speculative Execution” ,  <em>2019 IEEE Symposium on Security and Privacy</em>  (SP), pp. 1- 19, <a href="https://ieeexplore.ieee.org/abstract/document/8835233">https://ieeexplore.ieee.org/abstract/document/8835233</a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Lipp, M. Schwarz, M., Gruss, D., Prescher, T., Haas, W., Fogh, A., Horn, J., Mangard, S., Kocher, P., Genkin, D., Yarom, Y., and Hamburg, M. (2018)  “Meltdown: Reading Kernel Memory from User Space” ,  <em>Proceedings of the 27th USENIX Security Symposium</em> , pp. 973-990, <a href="https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-lipp.pdf">https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-lipp.pdf</a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Cimpanu, C. (2020)  “New Platypus Attack Can Steal Data from Intel CPUs” .  <em>ZDNet</em> , 10 Nov. 2020, <a href="https://www.zdnet.com/article/new-platypus-attack-can-steal-data-from-intel-cpus/">https://www.zdnet.com/article/new-platypus-attack-can-steal-data-from-intel-cpus/</a>.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Peterson, M. (2020)  “New &lsquo;Platypus&rsquo; Attack Can Extract Data from Intel Chips, But Macs Are Mostly Safe” . Appleinsider.com, November 11, 2020, <a href="https://appleinsider.com/articles/20/11/11/new-platypus-attack-can-extract-data-from-intel-chips-but-macs-are-mostly-safe">https://appleinsider.com/articles/20/11/11/new-platypus-attack-can-extract-data-from-intel-chips-but-macs-are-mostly-safe</a>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Winget, R. (1950)  “Locksmiths Used to Worry about Yeggs: Now It’s Spies” , Louisville Courier Journal, April 16, 1950, p. 92, <a href="https://www.newspapers.com/newspage/110607246/">https://www.newspapers.com/newspage/110607246/</a>.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Kocher, P., Jaffe, J., and Jun, B. (1999)  “Differential Power Analysis” ,  <em>Advances in Cryptology – Crypto 99 Proceedings, Lecture Notes in Computer Science Vol. 1666</em> , M. Wiener, ed., Springer-Verlag.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Poetry as Code as Interactive Fiction: Engaging Multiple Text-Based Literacies in Scarlet Portrait Parlor</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000693/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000693/</id><author><name>Jason Boyd</name></author><published>2023-07-20T00:00:00+00:00</published><updated>2023-07-20T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>One of the goals of Mark C. Marino’s  <em>Critical Code Studies</em>  is to persuade humanities scholars that the code that operates around us everywhere in our daily lives — mundane, but life-shaping code — is an interesting, important, and intellectually rewarding focus of inquiry in the humanities: as Marino observes, this class of computer code demands humanistic study because it constitutes  “an ideology that is doubly hidden by our illiteracy and by the very screens on which its output delights and distracts”   <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Given Marino’s concern that Critical Code Studies (CCS) should not be limited  “to the study of code written as literature”   <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, it is not surprising that  <em>Critical Code Studies</em>  deemphasizes so-called  “natural language”  programming languages and the making of  “code that has aesthetic value and additional meaning”   <sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Chapter 7, while it does discuss code as poetry, deliberately chooses as its case study Nick Montfort’s poetry generator  <em>Taroko Gorge</em>   <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, the code of which (written in the programming language Python 2) is considerably removed from any resemblance to natural language texts. Marino argues that  <em>Taroko Gorge</em>  is  “code that generates a work of electronic literature, or rather code that is a work of electronic literature”   <sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> — a claim meant to disrupt and challenge traditional understandings of what literature and poetry are.</p>
<p>To claim, as Marino does, that  <em>Taroko Gorge</em>  is a work of literature is provocative because its source code and traditional creative writing appear to be strikingly different if not inimical: that stark opposition is useful for those wishing to breach as well as those wishing to defend the wall that both sides see separating code and literature in popular and scholarly discourse. In this paper, however, I suggest that Prismatik’s  <em>Scarlet Portrait Parlor</em>   <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup><sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>  — a traditionally-structured poem which is simultaneously a work of functional code and, when executed, a work of interactive fiction — is arguably even more provocative for the opposite reason: poetry and code uncannily appear one and the same, and thus the presumedly obvious wall between them is not easily located for tearing down or reinforcing. This results in a work that is both familiar and strange, and this, along with  <em>Scarlet Portrait Parlor</em> ’s brevity, simplicity of construction, and immediate recognizability as a work of literature that is also executable source code producing a work of electronic literature, has the potential to intrigue students and textual scholars unfamiliar with and perhaps resistant to CCS. A study of Prismatik’s work also has the potential to refine some simplistic judgements in CCS scholarship about the efficacy and value of code that emulates natural, human language (in this case, the English language).</p>
<p>This case study of  <em>Scarlet Portrait Parlor</em>  aims to elaborate the value of the work as a rich example of how a poem, program, and interactive fiction (IF) can be intertwined if not blurred in a single text and show that the different reading competencies and literacies proper to each can enable a fuller appreciation of the work&rsquo;s operations and meanings. Marino asserts that  “[c]ode should be read, and read with the kind of care and attention to detail that a programmer must use”   <sup id="fnref4:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>:  <em>Scarlet Portrait Parlor</em>  additionally must be read with the kind of care and attention that a scholar of poetry and an experienced player of interactive fiction must use. As an  <em>amalgam</em>  of poetry, code, and playable story, it is a useful example with which to interrogate some questionable assertions and arguments in  <em>Critical Code Studies</em>  about the relations between programming and human languages and, in particular, about so-called  “natural language”  programming languages and about Inform 7, an example of this type of programming language. I hope this case study will bring some added nuance to future discussions in CCS at the intersection of human and computer languages and coding and creative writing. Prismatik’s work is a compelling example of how natural language programming languages can be flexible enough to be used for writing that is both expressive in terms of human language and functional in terms of executable code and points to a possible future where the paths of writing and programming (as conventionally understood) are not necessarily divergent.</p>
<h2 id="_scarlet-portrait-parlor_--overview"><em>Scarlet Portrait Parlor</em> : Overview</h2>
<p><em>Scarlet Portrait Parlor</em>  (SPP) is short enough in length that it can be quoted here in full:</p>
<pre tabindex="0"><code> &#34;Scarlet Portrait Parlor&#34; by Prismatik [A] [A sonnet] [B] The Scarlet Portrait Parlor is a room [1] When play begins: say &#34;Darkness falls again.&#34; [2] Inside the Portrait Parlor is a loom. [3] &#34;A [loom] that weaves the inner thoughts of men.&#34; [4] The heavy guilt is carried by the player. [5] Instead of dropping guilt: say &#34;You cannot!&#34;; [6] Below the Portrait Parlor is a Lair; [7] Inside the Lair are portraits left to rot; [8] [Now,] understand &#34;your secrets&#34; as the portrait; [9] [Now] understand &#34;your actions&#34; as the loom; [10] &#34;Our mind and thoughts compose the awful fortress. [11] To have our deeds exposed is mankind&#39;s doom.&#34; [12] Instead of putting [all your dark] guilt on: [13] End the story finally saying &#34;It&#39;s done.&#34;; [14]
</code></pre><p><sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup><sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<p><em>Scarlet Portrait Parlor</em>  is authored in Inform 7, often described as a natural language programming language because, as the text of  <em>SPP</em>  demonstrates, it closely resembles English syntax and sentence construction. As a submission to a competition the objective of which was to create a work in Inform 7  “with beautiful source code text”   <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>, the composition of the program was at least as important if not more important than its executable (playable) functionality: the source code in and of itself, that is, was to be read and judged on its aesthetic merits beyond its functionality as a program. This  “extra-functional significance”   <sup id="fnref5:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> is a key interest of CCS, which aims to study  “how code serves as a communication medium including and beyond the realms of practical application and specific machines”   <sup id="fnref6:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>In  <em>Critical Code Studies</em> , Marino recounts the reaction of programmers when he tells them he wants to interpret their code:  “they suspect I want to read their code as an English major would read…a sonnet by Shakespeare. Will I treat their methods as stanzas? Their routines as rhymes about roses?”   <sup id="fnref7:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. This amusing misunderstanding arises due to the programmers’ assumption that literary scholars only approach texts as literature (even when they are not literature). However, in the case of  <em>Scarlet Portrait Parlor</em> , such an otherwise laughable approach to code as poetry is not only appropriate but required. The SPP source code is in the form of an English sonnet, and it has been intentionally composed to communicate a coherent meaning or message as a sonnet. As such, it requires knowledge of poetic form and skill in interpreting verse in order to be effectively evaluated. However, to fully understand the constraints faced by the poet/programmer of this sonnet/program requires more than just a facility with parsing verse: it requires a knowledge of the syntax and structures of Inform 7 in order to understand how the programming language is present in and has shaped the sonnet and its meaning.</p>
<p>But  <em>Scarlet Portrait Parlor</em>  is more than a literary work written under the double constraint of the English sonnet form and valid Inform 7 syntax: as a computer program, it is also a work that can be run and played using an interpreter. In this state, the reader must have some knowledge of the navigational conventions of parser based IF as well as how Inform 7 and the interpreter respond to reader input. Having read the sonnet/program and played its IF execution, and, with this dual knowledge, going back and forth between these states for further revelation, the intriguing challenge for the reader is to develop an argument about how these three states of  <em>Scarlet Portrait Parlor</em>  together contribute to the work’s meaning. It is this need to oscillate between SPP’s states that makes the work valuable for thinking about how literary form, code structures, and parser-based texts can interdependently shape and shift how a text’s meaning is constructed, as well as how it is read and interpreted.</p>
<h2 id="_scarlet-portrait-parlor_--as-a-sonnet"><em>Scarlet Portrait Parlor</em>  as a Sonnet</h2>
<p>As the subtitle of the work explicitly (but perhaps unnecessarily) indicates (line B), SPP is a sonnet,  “one of the oldest, strictest, and most enduring poetic forms”   <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. More precisely, it is an English sonnet: it consists of fourteen lines of iambic pentameter, that is, five feet — a foot being comprised of two syllables — with the stress or emphasis on the second syllable of each foot (known as an iamb) rhyming  <em>ababcdcdefefgg</em> . Another way to describe the structure of the English sonnet is to say that it consists of three quatrains (four-line stanzas) of alternating rhyme with a closing rhyming couplet (two lines). Thus, in terms of compositional form or structure, Prismatik sets himself a considerable  <em>poetic</em>  challenge, as a sonnet is difficult to compose both in terms of its formal requirements and its relative brevity. How successful is  <em>Scarlet Portrait Parlor</em>  in rising to this challenge? It is fourteen lines, it does largely follow the English sonnet rhyme scheme, and it is mostly written in iambic pentameter. In addition to the forced or eye rhyme of  “on”  and  “done”  in the couplet, one might look askance at the rhyming of portrait and fortress in lines 9 and 11 — another forced end rhyme, although the first (and stressed) syllables of the words (port-, fort-) do rhyme. These same lines are the only two in the sonnet that have so-called feminine endings (an extra unstressed syllable). A final noticeable departure from strict English sonnet form is the final line, which consists of four trochees (stressed-unstressed feet, the reverse of the iamb) and a final iamb (or perhaps spondee, if it is felt that the two final syllables should both be stressed equally). These departures from strict English sonnet form should not be presumed to indicate a poetic failing or incompetence on Prismatik’s part, as deliberate and careful modifications to the form are often the hallmark of great sonnets and sonneteers. That lines 9 and 11 are a rhyming pair in the same quatrain and that they are in the last quatrain before the concluding couplet, and that the switch from iambic is confined to the final line, are potentially signs of the  <em>volta</em>  or turn that is expected in the traditional sonnet (an issue explored later in this paper).</p>
<h2 id="_scarlet-portrait-parlor_--as-code"><em>Scarlet Portrait Parlor</em>  as Code</h2>
<p>Parsing SPP as source code requires a shift to a perspective where the versifier has become a coder and where the speaker of the text is addressing not a human but a computer that is tasked with executing the compiled source code. A knowledge of the Inform 7 programming language enables one to discern the extent to which the sonnet’s language and format, and thus message, is shaped by and constrained by code. One aspect of the SPP text is difficult to incorporate into any reading of it as poetry: the punctuation. This includes the use of commas, semicolons, and periods, line spacing and indentation, as well as quotation marks and square brackets. As the use of much of the punctuation appears to be a response to the text-as-sonnet as it overlaps the text-as-code, it offers a useful segue way into a consideration of  _Scarlet Portrait Parlor _ as Inform 7 code.</p>
<p>The punctuation is at times puzzling in terms of the meaning of the text as a sonnet: for example, why not use a comma or colon instead of a period in line 3? Why not use a semicolon instead of a period in line 5? Why include a semicolon at all in line 6? Why not use a comma instead of a period in line 11? (The semicolon that oddly concludes SPP is possibly a mistake). Also puzzling is that most of the text’s lines (except for lines 3-4 and 13-14) are separated by blank lines, which is not a poetic convention. In Inform 7, however, it  <em>is</em>  a convention to separate discrete code statements or blocks with blank lines for ease of reading and debugging (see the  <em>Inform Recipe Book</em>  for examples <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>). The end of a code block can be indicated without punctuation (as we see in line 1 of SPP) or with a semicolon, but only if it is followed by a blank line, which Inform 7 understands as designating the ending of the previous code block. Therefore, if one wanted to eliminate the blank lines in  <em>Scarlet Portrait Parlor</em> ’s source code and still have an executable Inform 7 program, one would have to end each line (except line 13) with a period (the exclamation mark within the quotation marks in line 6 is considered equivalent to a period, as would be a question mark). The decision to end lines 6 to 10 with semicolons, as well as the decision to not put a blank line between lines 3 and 4, are stylistic choices informed by the text as a sonnet: in an attempt to reinforce SSP’s status as a sonnet, Prismatik has opted to use semicolons to convey a sense of flow/connection between lines (although this sense ends up being more visual than semantic) and has consequently been obligated to use unpoetic blank lines. Although the indentation of the final line could be regarded as a form of typographical emphasis, conventionally both lines of the couplet would be indented in laying out a sonnet typographically. While in this instance it is unnecessary, the indentation of the final line is due to the convention (and often a requirement) in Inform 7 that conditional statements indent those portions that follow an initial line that ends with a colon. In this instance, the couplet constitutes an if/then statement.</p>
<p>In addition to the uses of punctuation explained above, quotation marks, square brackets, and the remainder of the text not enclosed in this punctuation indicate the differentiation of the three basic types of content in Inform 7 source code. Content in quotation marks designates the creative writing originated by the writer/coder and is outputted during play in response to a player’s commands for the player to read. Quotation marks, then, from a source code perspective, are not used as they are in conventional texts (for example, to designate dialogue or quotations). Content in square brackets (never used in traditional poetry) are comments (i.e., annotations of the source code, a standard feature in programming languages) meant solely for the coder to read; they are ignored when an Inform 7 program is compiled and run by an interpreter. One exception to this is the use of square brackets  <em>within</em>  quotation marks (as seen in line 4), which are used for modifying the display of content within the quotation marks when played as an IF. Content neither in quotation marks nor square brackets are instructions for the interpreter to execute, which IF readers do not see, at least in the form in which they appear in the source code. Overall, most of the punctuation in SPP is indicative of the demands of Inform 7 rather than the meaning-making needs of the sonnet.</p>
<p>Turning from punctuation to word and phrase choices, many of the words in SPP have an extra level of significance in Inform 7 that goes beyond their dictionary meanings. Inform 7 was designed to create parser-based interactive fiction (IF) and creating an IF typically consists of building a virtual environment (spaces, objects, living creatures) that the player (the IF reader) moves in and interacts with, usually by playing some kind of entity who can interact with the environment. This explains the first line, which seems unnecessary to the sonnet reader but is necessary for an executable Inform 7 program: a room is one of the fundamental object kinds in Inform 7 (the source code  “needs at least one name of a location where the drama can unfold. For reasons of tradition, such locations are normally called ‘rooms,’ though people have used them to represent anything from grassy fields to states of mind and other metaphorical places”   <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. Inform works usually consist of a collection of rooms linked by directions (another object kind). The virtual space of SPP is quite modest: a Parlor, below which is a Lair.</p>
<p>Part of Inform’s flexibility in terms of program composition is that it can make inferences about the status of named objects in the program: for example, it is not necessary to include a phrase stating (as was done with the Parlor) that the Lair  “is a room”  because Inform 7 assumes that an object that is connected to an existing  “room”  by a direction (in this case,  “Below” ) is also a room (line 7). These two rooms each have a single object (a  <em>thing</em>  in terms of Informs 7’s object kinds) in them: a  “loom”  (line 3) and  “portraits”  (line 8): Inform 7 automatically infers objects that are stated to be  “in”  or  “inside”  objects that it knows to be rooms are  <em>things</em> . It is this kind of built-in understanding, along with the flexibility in which commands can be phrased, that enables Prismatik to write a highly constrained form of poetry like the sonnet in Inform 7, whereas a programming language with more rigid syntax would make this unachievable.</p>
<p>Lines 2 and 14 use two very common phrases for the start and end of an Inform 7 work:  “When play begins”  and  “End the story finally” . The first phrase represents a rule that causes something to happen when an IF is newly run: in this case an epigraph or preamble to the IF is outputted (using  “say” ). The second phrase represents a rule that ends the story with a message when a certain condition is true, in this case, when the player tries to put the  “guilt”  on any thing in the environment (as no particular thing is specified after the  “on”  [line 13]). The  “say/saying”  rule in Inform 7 (seen in lines 2, 6, and 14) is equivalent to the print [on screen] command in other programming languages. The  “understand”  rule (lines 9-10) is commonly used to anticipate possible variations of how a player might refer to objects (e.g., Understand  “phone”  as the telephone) or how they might describe actions they wish to take (e.g., Understand the commands  “dial”  or  “phone”  or  “telephone”  as  “call” ).</p>
<p>Prismatik uses one feature of Inform 7 — the built-in properties of objects — very effectively with the  “guilt”  of the text. SPP states that this guilt is  “carried by the player”  (line 5, a standard Inform 7 operation), and, consequently, the  “guilt”  forms part of the player’s  <em>inventory</em> . While colloquially and figuratively we talk about degrees of guilt in terms of a physical quality like weight (heavy) and as something that one carries around with them (as a psychological burden), in terms of the SPP text as source code, guilt is a generic and material  <em>thing</em>  object (therefore, no different in kind than the loom or the portraits), and as such, it has the default property  <em>portable</em>  (it can be taken and dropped). Prismatik references the  <em>portable</em>  property in the rules about how guilt can be manipulated in lines 6 and 13. These use the  <em>instead</em>  rule for what is essentially an if/then conditional: if the player tries to drop the guilt they are carrying, or tries to put it on anything in either of the rooms, they will be prevented from doing so, and a message reacting to the attempt will be outputted ( “You cannot!”  [line 6]).</p>
<p>Examining the text of SPP from the dual perspectives of an English sonneteer and an Inform 7 programmer is revealing in several respects. It becomes clear that the poetic and programming constraints of each shaped the particularities of the text. For example, line 5 would have been valid in Inform 7 if it had been written as  “The player carries the heavy guilt,”  but this would have made the line one syllable short and not preserved the iambic pentameter. Therefore, the line had to end with  “player.”  In terms of word choice, like the choice of  “loom,”  which was dictated by the need for a rhyme for Inform 7’s object kind  “room,”    “Lair”  was dictated by the programming rather than poetic conceit (the need to rhyme with  “player” ). The order of the lines/code blocks is primarily dictated by the rhyme scheme rather than a logical programming structure: the lines could be placed in a number of different arrangements (e.g., once editing the lines so that they end with periods, 1, 3, 4, 7, 8, 11, 12, 5, 6, 2, 13, 14) and still be executable and function as an Inform 7 program. Of course, it then would no longer be a sonnet.</p>
<h2 id="reading--_scarlet-portrait-parlor_--as-a-sonnet">Reading  <em>Scarlet Portrait Parlor</em>  as a Sonnet</h2>
<p>Now that we have looked at how Inform 7’s syntax constrains the punctuation and wording/phrasing of the sonnet, we can ask: does this interfere with SPP’s ability to convey a meaning or message as a sonnet? The first quatrain (lines 1-4) describes a  “scarlet portrait parlor”  containing a loom  “that weaves the inner thoughts of men”  (presumably into portraits). While the first line is unnecessary in terms of the meaning of sonnet, as it hardly needs to be pointed out that a parlor  “is a room” , as we have seen, it is demanded by the Inform 7 programming. The second line may appear unconnected from the other lines in the quatrain — what does  “When play begins: say ‘Darkness falls again.’”  signify? What is the  “play” ? Is it weaving on the loom? And who is telling whom to  “say” ? Is it the speaker telling themselves or the speaker telling an addressee (as sonnets often have a speaker addressing a person or an idea)? The first line of the second quatrain (line 5) introduces  “the player,”  who could be viewed as the sonnet’s addressee and who is earlier told (by the speaker) to  “say”  when  “play begins.”  The next line tells the player that  “You cannot!”  drop the heavy guilt that they are carrying (lines 5-6): is this an imperious command or a despairing realization? The sonnet goes on to describe a  “Lair”  below the parlor (line 7) where there are  “portraits left to rot”  (line 8) and assists our interpretative work by telling us directly (lines 9-10) that the loom symbolizes  “your actions”  and the portrait[s]<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>    “‘your secrets’”  (earlier referred to — assuming these portraits are what are woven on the loom — as  “the inner thoughts of men”  [line 4]). If the player’s actions (weaving) risk the exposure (through portraiture) of the player’s secrets or inner thoughts, then this is perhaps why the portraits end up rotting in the Lair (a type of place associated with dangerous beasts and criminals). It is  “Mankind&rsquo;s doom”  to have those rotting portraits revealed when others breach  “the awful fortress”  (alias the  “Lair” ) that encloses and protects our  “mind and thoughts.”  Replacing the  “your”  of lines 9, 10, and 13 with  “our”  in line 11 turns this statement into a kind of universal adage. As the closing couplet (lines 13-14) reminds us, the player/weaver carries guilt (caused by their inner thoughts/secrets being revealed by their actions?) and suggests that instead of  “putting [all your dark] guilt on”  (on a portrait?) that they stop ( “End the story finally” ) and state  “ It’s done. ”  — the  “it”  possibly being a portrait being composed or an action that has already been taken. Is the  “turn”  then in the couplet, by telling the addressee/the player that instead of burdening themselves with guilt over their actions exposing their secrets, they find closure by saying what’s done is done? In this interpretation, if it is  “mankind’s doom”  (i.e., inevitable fate) to have the motivations ( “mind and thoughts” ) behind its deeds exposed, then why feel guilty about this exposure, especially once the deeds have been done?</p>
<p>This parsing and interpretation of  <em>Scarlet Portrait Parlor</em>  suggests that it is a sonnet about how we (presuming the use of men/mankind is an outmoded way of referring to humanity) burden ourselves with self-representations that are informed by what our actions might reveal about our inner selves, our character, but that we should accept that actions  <em>will</em>  reveal character and stop feeling guilt or shame about this revelation, especially for actions that are already done. While this idea (actions as an index of moral character/psychological motivations) is not an original one, it is one worthy of expression and consideration. In terms of the artistry with which this idea is expressed, the contrasting symbols of parlor (a space of respectable sociality) and lair (a space of wildness, secrecy, and danger) and of the loom and weaving (a familiar trope for life and fate, from the Greek  <em>Moirai</em>  to Tennyson’s  “Lady of Shallot” ) are very striking, as is the imagery of the  “portraits left to rot”   <sup id="fnref2:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> (reminiscent of Oscar Wilde’s  <em>The Picture of Dorian Gray</em> ), the mind as a fortress, and psychological guilt as a physical burden. The modifications to the standard English sonnet scheme (discussed above) appear to be skillfully done to highlight the turn where, after the depiction of the parlor/lair in the first two quatrains (the proposition), the third quatrain (with the distinguishing feminine rhyme) leads to the resolution of the couplet (with the trochaic emphasis in the last line). One might criticize the lack of enjambment <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>  <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>  and the inconsistency of the use of imagery relating to the arts, flitting from fine arts (portraiture) to artisanal crafts (weaving) to storytelling (line 13) and to theatre (assuming the Shakespearean premise that all the world’s a stage and interpreting  “the player”  as an actor), as well as fault the poem for explicitly decoding the symbolism of the portrait and loom in lines 9-10. However, no matter the specific interpretation, this analysis demonstrates that  <em>Scarlet Portrait Parlor</em>  can legitimately and profitably be considered and studied  <em>as a sonnet</em> .</p>
<h2 id="reading--_scarlet-portrait-parlor_--as-beautiful-code">Reading  <em>Scarlet Portrait Parlor</em>  as Beautiful Code</h2>
<p><em>Scarlet Portrait Parlor</em>  was an entry in  <em>Event One of the Second Quadrennial Ryan Veeder Exposition for Good Interactive Fiction</em>  (and won third place). Event One’s challenge was  “to create a game in Inform 7 with beautiful source code text”   <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Veeder notes that Inform 7 was in part chosen because  “Inform 7 code has a unique potential to be beautiful by way of resembling beautiful English sentences (as well as many other vectors of beauty)…”   <sup id="fnref2:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. As Veeder admits, what makes beautiful code is debatable, and he proposes two possibilities: cleverness and elegance <sup id="fnref3:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. But his earlier comment about choosing Inform 7 suggests that style and expression (in the context of composition in the English language) is also a factor. While cleverness and elegance are important aspects of style in writing in terms of judging its beauty (wittiness, originality, rhetorical impact, use of figurative language) they mean differently in terms of coding, where cleverness and elegance usually refers to brevity, clarity, simplicity, correctness or validity, reusability, and modifiability. In his very brief judgement of SPP, Veeder commends its compactness and correctness, and notes that he deducted points for a few  “inelegancies”  (for a score of 8/10) <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. He does not state what these inelegancies are, but, given that compactness and correctness are qualities more valued in code than verse (although one might argue they are as if differently valued when it comes to a form like the sonnet), these are probably features like the use of comments in lines 9, 10 and 13, which could be criticized as a misuse of the commenting function: using comments to pad lines to meet the metric requirements of the sonnet instead of finding an executable coding solution. Another possible inelegancy Veeder might have considered when scoring SPP is line 9, which is non-functional, since  “portrait”  has not been created as a  <em>thing</em> , given that it has not been placed in a room or on the player as have the loom (line 3), guilt (line 5), and the portraits (line 8). Inform 7 understands single and multiple things as different objects, even if they have the same name (portrait ≠ portraits) (see the  “Scarlet Portrait Parlor as Interactive Fiction”  section for a further discussion of this line).</p>
<p>Some questions Veeder does not address, but which would be pertinent and interesting to ask in the case of a CCS approach to SPP is: Can code be considered beautiful because it takes the form of a poem? Or does a carefully crafted sonnet that is also an executable program only lead to inelegant code? Or does such code inelegance become beautiful because it is structured poetically while still remaining executable? While it is commonplace to think of poetry as open and malleable and coding as limited and rigid, in this case it is the poetry that its limited and rigid (the English sonnet form) and the coding that is malleable enough to accommodate itself (while obeying its own constraints) within the sonnet’s constraints. Does SPP demonstrate that Inform 7 code is beautiful because it shows that Inform 7 programming can also be used for creative writing for the production of traditional and electronic literature?</p>
<p>These questions could also have been asked in  <em>Critical Code Studies</em> , in particular in the discussion of Inform 7 in Chapter 5, which examines the FLOW-MATIC programming language in order to mount an argument reinforcing the distinctions between natural language programming languages, the human languages they try to emulate, and good programming. FLOW-MATIC was designed to use English words and phrases in order to make it more accessible to non-programmers. Marino notes that FLOW-MATIC programs are difficult to read today because they lack now-common programming structures and argues that this  “illustrates the ways legibility is not dependant on similarity to natural language but overall clarity of expression”   <sup id="fnref8:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. As an example of FLOW-MATIC’s lack of clarity of expression, Marino provides the example of the operations REWIND and ZZZZZZZZZZZZ, which, he argues,  “demonstrates the contradictions of this English-like programming language because the program essentially uses both ZZZZZZZZZZZZ and REWIND to indicate that instruction [the rewind instruction]”   <sup id="fnref9:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>  When considering Inform 7, Marino’s judgement that having different words or methods for a single operation are  “contradictions”  is a mistaken one. Richness or diversity of expression in a programming language is only indicative of the lessening of a  “dedication to legibility”   <sup id="fnref10:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> if one starts from the dubious premise that programming languages, including natural language programming languages, should strive for (or can only function using) a one-to-one equivalence between named operations and methods and what those operations and methods do. Inform 7 shows that need not be the case and that is a premise that CCS should interrogate, not codify: as with natural languages and legibility, there is no essential problem with programming languages using synonyms for the same operation ( “carrying” ,  “holding” ) or variant syntax for instructions ( “The player carries the heavy guilt” ,  “A heavy guilt is carried by the player” ). In these cases, it is the very similarity to natural language (English) that makes it easy to discern that these different words and phrases are doing the same work. Perhaps the problem with FLOW-MATIC was not that it used English words and phrases, but that it did not use them more extensively, more naturally, in the way Inform 7 does.</p>
<p>In his efforts to demonstrate that  “the distance between the appearance of English and the processing of natural language offers a valuable lesson in the dangerous temptation to read code by merely imposing reading strategies from other semiotic systems”   <sup id="fnref11:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, Marino ends up creating a problematic example in Inform 7 to illustrate that  “natural-seeming programming languages can lull a newbie into thinking the language can understand a statement rather than process it”   <sup id="fnref12:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. First, the  <em>Writing with Inform</em>  manual provides a direct and unambiguous response to the question,  “Does Inform really understand English?” :</p>
<blockquote>
<p>No. No computer does…[Inform] is a practical tool for a particular purpose, and it deals only with certain forms of sentence useful to that purpose. Inform source text may look like natural language, the language we find natural among ourselves, but in the end it is a computer programming language. Many things which seem reasonable to the human reader are not understood by Inform <sup id="fnref1:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.<br>
Note that here Nelson is saying that Inform does not understand English in all its complexities and vagaries; he is not saying that Inform does not understand what might be called Inform 7 English: Inform  <em>needs</em>  to understand this English in order to process it.</p>
</blockquote>
<p>Second, the example that Marino provides of a sentence Inform does not understand (while we do) is:  “ The door in the room needs to be fixed. ”   <sup id="fnref13:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. This puzzling example fails to pay attention to context. Like writing a sonnet, like writing a program, writing an IF is a very specific writing situation with very specific goals, with a  “particular purpose,”  as Nelson puts it. It is difficult to imagine a situation where one would actually want to write such an instruction in Inform 7 as Marino provides. As doors in Inform 7 do not independently fall into disrepair or get broken without the author’s authorization, if the IF author did not want a door that needed to be fixed in their IF, they simply would not create such an object, and therefore would never need write Marino’s example instruction (and what exactly does Marino expect the interpreter would do with such a statement if it understood it?). If such a sentence  <em>was</em>  included in an Inform 7 work, it would likely be as an instruction not to the computer but to the human player, to prompt them that they need to do something to fix the door, e.g.,</p>
<p>Instead of going through the door: say,  “The door in the room needs to be fixed.”</p>
<p>The above example, and the Inform 7 language in general, complicates Marino’s claim that there is a significant  “difference between understanding and parsing and processing”   <sup id="fnref14:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Rather, what we see happening simultaneously are two levels of understanding: the author/reader understands the instruction as an English phrase (however curious in construction) and, _ at the same time,_  as a piece of code that, once it is processed (understood) by the interpreter, will produce a specific output in response to a specific player input. With Inform 7, understanding its code is the same as understanding its English. The English (and the code, for that matter) is understood and understandable in the specific writing situation of creating an Inform 7 program: this makes Marino’s instruction  “ The door in the room needs to be fixed. ”  of little sense and his hapless  “newbie”  make-believe.</p>
<p>One of Marino’s aims in chapter 5 of  <em>Critical Code Studies</em>  is to show that natural language programming languages are, counter-intuitively, less legible, less clear in expression than more code-like languages. As shown above, there is a dubious premise in his argument on this front in relation to FLOW-MATIC, and his use of Inform 7 to bolster that claim instead weakens this argument further. Part of the problem with Marino’s use of Inform is that he fails to remember that it is a tool to elaborate virtual worlds, that is, as a tool not for facilitating business processes, but for creative writing. Clarity of expression as it relates to a business program is not the same in relation to a program that is a form of creative writing.  <em>Critical Code Studies</em>  is concerned with promoting code literacy and legibility: the ability to understand the meanings and effects of code. Currently, much code is only legible to programmers. One CCS response to this lack of accessibility is to advocate for everyone to become programmers or at least to develop a functional code literacy that would enable everyone to read the programming languages now in widespread use. But another and complementary response to the demand for a general code literacy would be for CCS to study, explicate the potential of, and advocate for programming languages that strive to emulate  “natural languages”  so that code literacy does not require a highly specialized literacy far removed from the common literacy that most people possess.</p>
<h2 id="_scarlet-portrait-parlor_--as-interactive-fiction"><em>Scarlet Portrait Parlor</em>  as Interactive Fiction</h2>
<p>Inform 7 programs are doubly a form of creative writing because, when executed as a compiled story file, they become Interactive Fictions, a form of potential literature that is realized when a reader/player transverses them by typing commands into an IF interpreter <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. While it is an expectation that players of IF will not see the source code and do not need to as part of the IF experience, in the case of SPP, the source code is meant to be read by a human for a meaning other than its status as an IF program. The interpreter does not understand this other meaning, nor does it need to: the interpreter does not know it is a sonnet (or what a sonnet is), nor does it know or understand the message of the source code as sonnet: to the interpreter, SPP is a series of instructions creating two  <em>rooms</em> , three  <em>things</em>  in those rooms, and a set of instructions about how the player can interact with them, as well as instructions about what to do at the start when the program is run, and under what conditions the program can end.</p>
<p>For an IF player who is not familiar with the source code, SPP as an IF would likely be baffling. After the epigraph ( “Darkness falls again.”  (line 2)) and the banner text displaying the title and author (line A),  “Scarlet Portrait Parlor”  displays in bold (line 1), an IF convention for indicating the room the player starts in. After this comes the line  “A loom that weaves the inner thoughts of men.”  (line 4), followed by the prompt awaiting player input (see Figure 1). That Prismatik gave some thought to how the SPP text would present via an interpreter (in other works, as an IF) is indicated in the source code by the enclosing of  “loom”  in line 4 in square brackets: this prevents the interpreter from displaying an automated description ( “You can see a loom here.” ) which would have been generated from line 3, and which would be repetitive coming after and in addition to  “A loom that weaves the inner thoughts of men.”  Normally after a room heading one would expect a description of the room that would evoke its atmosphere and general appearance as well as offer information about items in the room and paths to other spaces that would help the player determine what commands might be viable to type. The description that does appear (of the loom) would be something a reader would more typically expect  <em>after</em>  examining the loom, and if one does  “x [examine] loom,”  one gets a built-in default message for items that have no author provided description:  “You see nothing special about the loom.”  — an odd message, given that the reader has been informed the loom  “weaves the inner thoughts of men.”</p>




























<figure ><img loading="lazy" alt="A user interface with SPP&#39;s title at the top, showing the line “Darkness falls again” , followed by citational information for the poem and at the bottom “weaves the inner thoughts of men.”" src="/dhqwords/vol/17/2/000693/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000693/resources/images/figure01_hud5e8442865103158af3eb82918e08ffe_92529_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000693/resources/images/figure01_hud5e8442865103158af3eb82918e08ffe_92529_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000693/resources/images/figure01.png 1162w" 
     class="landscape"
     ><figcaption>
        <p><em>Scarlet Portrait Parlor</em> ’s initial display when run using an interpreter [^prismatik2020]
        </p>
    </figcaption>
</figure>
<p>Seasoned IF players would likely at the start of play type two common commands hoping to obtain more information:  “x [examine] me”  (which for SPP returns the default generated message:  “As good-looking as ever.”  — a phrase which has an ironic appropriateness for a sonnet about the unflattering revelations of self-portraiture) and  “i [inventory]” , which informs the player:  “You are carrying: / a heavy guilt.”  (line 5). Although in other contexts this would be read figuratively only, as an IF, this would also be understood by the player literally, with  “guilt”  understood as a tangible item. A seasoned IF player will know that usually a few commands can always be tried with carried items (e.g., wearing, eating, smelling, tasting, touching, listening to, etc.), none of which generate anything beyond negatives (e.g.,  “You can’t wear that!” ) except for dropping: if the player tries to  “drop [or throw] guilt” , they get the message:  “You cannot!”  (line 6), a response which, in terms of IFs, is somewhat unexpected, as usually most carriable things are (by default) droppable.</p>
<p>At this point the player, lacking guidance about how to proceed, would have to experiment. They might try the standard IF directions (the eight cardinal and ordinal compass directions, plus up, down, and inside), one of which (d [down]) will take them, as the bold heading will indicate, to the  “Lair”  (line 7), followed by lines 11-12 and  “You can see portraits left to rot here.”  (generated automatically from line 8). They might try  “taking”  either the loom or the portraits and putting them in opposite rooms or together in the same room (which can be done) — but this does not have any particular effect. Prismatik almost certainly did not intend these actions to be relevant for SPP as an IF; however, because of the sonnet constraint, he was unable to specify that the loom and portraits were  “fixed in place”  or  “supporters ” or  “scenery” , which would have prevented such actions. An enterprising player might try putting the portraits on the loom or vice versa, but as these two things are not implemented as  “supporters,”  this would only generate a default message:  “Putting things on the [loom/portraits left to rot] would achieve nothing.”  If the player tries to put guilt (line 13) on either of these things, or  “on me” , they would end the game with the message, in bold italic:  “<em><strong>It’s done.</strong></em>”  (line 14).</p>
<p>It would be hard if not impossible for the player to discern from such a playthrough that the source code was a sonnet, even though the playthrough suggested above more or less follows the line order (2, 1, [3], 4, 5, 6, 7, 11, 12, 8, 13, 14). Two lines, however, provide evidence that a knowledge of the source code is expected on the part of the IF player, unless this is intended as a particularly unfair puzzle: lines 9 and 10. It seems unlikely that a player would be able to figure out without knowing the source code that they could also refer to the portrait as  “your secrets”  and the loom as  “your actions.”  Knowing this enables the player to type the command  “put guilt on your actions,”  which ends the story in the same way as in the previous paragraph. The argument might be made here that  “portrait”  in line 9 is intentional (that is, not a mistake for  “portraits” ) in that it prevents the command  “put guilt on your secrets”  from succeeding: since a thing called  “portrait”  has not been created in the source code, such a command returns the default generated message  “You can’t see any such thing.”  Was this done because secrets are things that are hidden, making the default generated message particularly apt? If the  “portrait”  is one that is in process of being created on the loom in the Parlor, then its secrets are only in the process of being exposed, and this suggests that, when one has woven a portrait and revealed one’s  “inner thoughts,”  only then does the portrait join the others rotting in the Lair, on which the player can put the heavy guilt resulting from secrets and  “deeds exposed.”</p>
<p>The activity involving guilt is the primary interactivity of SPP and putting  “[all your dark] guilt on”  the loom, the portraits, your actions, or the player all generate the same ending ( “It’s done.” ). Are these all meant to be correct solutions or endings, or is there one correct solution or perhaps a best solution? In terms of the source code, the player is prevented from putting guilt on  <em>anything</em> , given the use of the  “Instead of”  rule rather than the  “After”  rule (e.g.,  “After putting guilt on…” ) as well as because the loom, portraits and player are not designated as  <em>supporters</em>  on which things can be put. Therefore, the  “It’s done”  ending, which an IF player might legitimately interpret as meaning  “It’s accomplished,”  might not mean that when one knows the source code. There, what the  “it”  of  “It’s done”  in the concluding couplet/if-then statement in lines 13-14 refers to is ambiguous: does it means you cannot (or perhaps should not) put your guilt on your actions because the story is already done, over, in the past, irrevocable?</p>
<p>The final two lines of SPP encapsulate how an understanding of the work is deepened and complicated by reading them simultaneously as the conclusion of a sonnet, program, and an IF. In terms of a sonnet, the text seems to call for a relinquishing of, or a refusal to be burdened with, a continual narrative of guilt or shame over what our actions might suggest about our secret inner life. However, as Inform 7 source code, guilt cannot be dropped, nor can it be put on anything (and there is nothing to put guilt on in any case in the source code), and this suggests a much more pessimistic, even fatalistic, response to the couplet of the sonnet, where the compiled program will abruptly terminate itself in response to  <em>any</em>  attempt by the player to get rid of guilt. As an IF, the message depends on what the player decides to put guilt on: the loom that weaves the inner thoughts of men, the portraits left to rot, or themselves. Putting the guilt on themselves or on the loom ( “your actions” ) would in this case be an enactment (if  “It’s done”  is read as  “It’s accomplished” ) of the very thing the sonnet and the Inform 7 program counsel against.</p>
<h2 id="conclusion">Conclusion</h2>
<p>As I hope this explication of  <em>Scarlet Portrait Parlor</em>  conveys, what makes this work so challenging and so interesting is that it requires the reader to draw upon and engage multiple modalities and literacies to construct a reading. Ultimately, the value of this work is not necessarily that it provides some unitary message across its multiple modalities, but that it provides a powerful and instructive example of creative procedural authorship that is working within multiple constraints (the English sonnet form, Inform 7 programming structures, and parser-based interactive fiction). As such, it is a work that is immensely valuable in revealing how literature, programming, and interactive digital work can intersect, and thus shows the value and range of Critical Code Studies. While Marino’s intent in  <em>Critical Code Studies</em>  is not to delegitimate so-called natural language programming languages and  “code written as literature”  [Marino 2020, 41] as a focus of study in CCS, his study perhaps does not do justice to the potential this area has to turn what is seen as the wall separating code and literature into a bridge bringing together code and literature into a continuum that can lead to generative discussions about the overlapping and intertwining of programming languages, natural languages, creative writing, and coding. One important point of future discussion relates to whether natural language programming languages might be a means of synthesizing programming and other forms of human writing and of achieving a more widespread code literacy and code creativity than is the case given predominating programming paradigms and syntaxes.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Marino, M. (2020).  <em>Critical Code Studies</em> . The MIT Press.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref10:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref11:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref12:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref13:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref14:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Montfort, N. (2009).  <em>Taroko Gorge.</em>  Nickm.com. Accessed on 6 July, 2023 at <a href="https://nickm.com/taroko_gorge/">https://nickm.com/taroko_gorge/</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Prismatik. (2020).  <em>Scarlet Portrait Parlor</em> . <a href="https://rcveeder.net/expo/event1/prismatik1/">https://rcveeder.net/expo/event1/prismatik1/</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Prismatik is a pen name of MathBrush (a pen name of Brian Rushton). On the  <em>Interactive Fiction Database</em>  (IFDB) page for  <em>Scarlet Portrait Parlor</em>  (<a href="https://ifdb.org/viewgame?id=t15dwwysqvz2ptug">https://ifdb.org/viewgame?id=t15dwwysqvz2ptug</a>) the work is listed as  “by MathBrush (as Prismatik).”&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>The letters and numbers in square brackets have been added and will be used in this paper to reference lines.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Veeder, R. (2020).  <em>Event One of The Second Quadrennial Ryan Veeder Exposition for Good Interactive Fiction</em> . <a href="https://rcveeder.net/expo/event1">https://rcveeder.net/expo/event1</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Richardson, R.  “Learning the Sonnet.”   <a href="https://www.poetryfoundation.org/articles/70051/learning-the-sonnet">https://www.poetryfoundation.org/articles/70051/learning-the-sonnet</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Nelson, G.  <em>The Inform Recipe Book.</em>   <a href="http://inform7.com/book/RB_1_1.html">http://inform7.com/book/RB_1_1.html</a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Nelson, G.  <em>Writing with Inform.</em>   <a href="http://inform7.com/book/WI_1_1.html">http://inform7.com/book/WI_1_1.html</a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>The  “portrait”  in line 9 might appear to be a mistake for  “portraits,”  if one assumes that this  “portrait”  is referring to the  “portraits left to rot”  of line 8, One could also assume that this  “portrait”  may refer to one currently being woven on the loom. For a further discussion of the portraits/portrait, see the  “Scarlet Portrait Parlor as Interactive Fiction”  section.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Poetry Foundation.  “Enjambment.”    <em>Glossary of Poetic Terms.</em>   <a href="https://www.poetryfoundation.org/learn/glossary-terms">https://www.poetryfoundation.org/learn/glossary-terms</a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>In terms of meaning, lines 1 and 2 do not seem to be indicative of enjambment (the  “running-over of a sentence or phrase from one poetic line to the next, without terminal punctuation”   <sup id="fnref1:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>) — that is, we are not to read  “The Scarlet Portrait Parlor is a room when play begins,”  which implies that the parlor will become something other than a room at a later time, which it does not. Although the first line is not end-stopped, in terms of the meaning of the text as poetry, it seems to demand some end punctuation.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Veeder, R. (2020).  “Judgment of  <em>Scarlet Portrait Parlor</em> . ”   <a href="https://rcveeder.net/expo/event1/prismatik1/score.html">https://rcveeder.net/expo/event1/prismatik1/score.html</a>.<br>
[^]:&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>While it can be argued that, unlike REWIND, a series of 12 Zs is not a generally transparent command, it does have a certain logic (perhaps the logic that suggested its original development) given that, if such a word existed, it would occur at the very end in an alphabetized categorization, with the only option being to go back or ‘rewind’ to an earlier section. One could also speculate that a series of 12 Zs would be very visually distinctive when parsing a FLOW-MATIC program, which perhaps made it more useful in some contexts than REWIND. As I go on to argue, a consideration of the writing context is essential when evaluating text, including code.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>The Interactive Fiction Wiki.  “Interpreter.”    <em>The Interactive Fiction Wiki.</em>   <a href="http://ifwiki.org/">http://ifwiki.org/</a>.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Reverse Engineering the Gendered Design of Amazon’s Alexa: Methods in Testing Closed-Source Code in Grey and Black Box Systems</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000700/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000700/</id><author><name>Lai-Tze Fan</name></author><published>2023-07-20T00:00:00+00:00</published><updated>2023-07-20T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<blockquote>
<p>30 years ago these sayings were cliché, today they are offenisve [sic]. Demeaning, limiting, or belittling a woman’s contribution to a household is not quaint or cute. Prolonging or promoting sexists tropes is wrong. Maybe write a skill called Sexist Spouse. Please do better humans.<br>
—customer review for the Amazon Alexa skill  “Happy Wife”</p>
</blockquote>
<p>This article examines the gendered design of Amazon Alexa’s voice-driven capabilities, or, skills, in order to better understand how Alexa, as an AI assistant, mirrors traditionally feminized labour and sociocultural expectations. While Alexa’s code is closed source — meaning that the code is not available to be viewed, copied, or edited — certain features of the code architecture may be identified through methods akin to reverse engineering and black box testing. This article will examine what is available of Alexa’s code — the official software developer console through the Alexa Skills Kit, code samples and snippets of official Amazon-developed skills on Github, and the code of an unofficial, third-party user-developed skill on Github — in order to demonstrate that Alexa is designed to be female presenting, and that, as a consequence, expectations of gendered labour and behaviour have been built into the code and user experiences of various Alexa skills. In doing so, this article offers methods in critical code studies toward analyzing code to which we do not have access. It also provides a better understanding of the inherently gendered design of AI that is designated for care, assistance, and menial labour, outlining ways in which these design choices may affect and influence user behaviours.</p>
<p>As commercialized AI devices become more and more sophisticated, we can expand current research on the gendered design of AI to asking questions about the intent behind such design choices. Of Alexa’s many official and unofficial skills, in this article, I am most interested in the skills that mirror gendered forms of workplace, domestic, and emotional labour and also the skills that permit Alexa to condone and even reinforce misogynistic behaviour. The expectations to maintain order and cleanliness in a workplace or home, as well as sociocultural expectations to be emotionally giving — including by being maternal, by smiling, by cheering up others, and by emotionally supporting others — may be considered stereotypically feminine. By having numerous skills that perform these traits, Alexa serves as a surrogate for sources of gendered labour that are dangerously collapsed and interchangeable as mother, wife, girlfriend, secretary, personal assistant, and domestic servant.</p>
<p>In my focus on the gendered design of Alexa’s skills and code, I am drawing upon the growing body of salient work by scholars in science and technology studies, critical data studies, critical race studies, computer science, feminist technoscience, and other adjacent fields in which there has been a pointed critique of the systemic biases of Big Tech’s data, algorithms, and infrastructures. Notable texts in these efforts include Ruha Benjamin’s  _Race after Technology _   <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, Cathy O’Neil’s  <em>Weapons of Math Destruction</em>   <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, Safiya Umoja Noble’s  <em>Algorithms of Oppression</em>   <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, and Wendy Hui Kyong Chun’s  _Discriminating Data _   <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, and also cultural organizations and texts such as Joy Boulamwini’s Algorithmic Justice League (established in 2016) and Shalini Kantayya’s documentary  <em>Coded Bias</em>   <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. The methods of these works is to analyze Big Tech culture from its self-presentation of objective data, information, and logic — pillars that begin to crumble when we examine the exclusionary, discriminatory, and systemically unequal foundations upon which they are built.</p>
<p>And these biases are not singular. Indeed, any analysis and discussion of Alexa’s gendered design may be extended to the ways in which many AI assistants are modelled after forms of labour that exploit groups of people on the basis of race, class, and nationality. The intersectional systemic biases of technological design invite further research on this topic in critical code and critical data studies in particular.</p>
<p>In the code analysis of this article, I will:</p>
<p>Analyze the Alexa Skills Kit software development kit for interface features that are automated and parameterized.  Analyze select code samples and snippets on Alexa’s Github account for code features that are parameterized.  Analyze official Alexa skills and available code samples and snippets to demonstrate Alexa’s problematic responses to users’ flirting and verbal abuse.  Analyze cultural and code variations of the make me a sandwich command to discuss how users try to trick Alexa into accepting overtly misogynistic behaviour.</p>
<p>I add three notes for added context. First, I distinguish between official and unofficial skills in this way: official skills are developed by Amazon’s own Alexa division and unofficial skills are developed by a third-party person, persons, or group not affiliated with this division. All but one skill that I discuss are available on the Amazon store. Second, occasionally, source texts may describe Amazon devices on which Alexa operates, such as the Amazon Echo and Echo Dot, and devices that have a smart display, rather than the Alexa technology itself. Third, all Alexa code snippets and samples discussed in this article, as well as documentation of Alexa’s responses, are from mid 2022 and are subject to future change. The hope is that they  <em>would</em>  continue to change to improve aspects of their current biased design, whether or not that is a realistic objective.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<h2 id="designing-ai-assistants-to-be-female-presenting">Designing AI Assistants to be Female-Presenting</h2>
<p>AI assistants perform a user’s commands through text- or voice-controlled interaction, through which the software searches for keywords that match its predesignated scripts to execute specific actions and tasks. Popular task-based commands include checking the weather, setting timers, setting reminders, playing music, and adding items to a user’s calendar. In this sense, AI assistants replace smaller actions that a user might otherwise do, and they are also meant to emulate some forms of menial labour that are performed by traditionally feminized roles, such as personal assistants, secretaries, and domestic servants <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup><sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup><sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup><sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.</p>




























<figure ><img loading="lazy" alt="A stacked bar chart of 17 voice assistant uses, from the most common, ask a question, to least common such as make a purchase, measured by daily, monthly, or infrequent use." src="/dhqwords/vol/17/2/000700/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000700/resources/images/figure01_hud826507620297527558f58187f7ccd3f_222890_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000700/resources/images/figure01_hud826507620297527558f58187f7ccd3f_222890_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000700/resources/images/figure01_hud826507620297527558f58187f7ccd3f_222890_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000700/resources/images/figure01.png 1430w" 
     class="landscape"
     ><figcaption>
        <p>A chart depicting different uses of voice-based AI assistants in UNESCO’s “ I’d blush if I could ” report from 2019 [^bergen2016].
        </p>
    </figcaption>
</figure>
<p>Women’s workforce labour through mechanical technologies existed and has been identified even earlier. From the loom, to Industrial-era typewriters and telegraphs, to telephone operating switchboards to the first programmable computers — all were largely operated by women. These examples do not represent a separate woman’s history of technology; rather, they reveal women  <em>in</em>  the history of technology. These women were never separate, only unseen.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>  It is therefore no coincidence that Siri, Alexa, Cortana, Google Assistant, and many other commercialized AI assistants are programmed from the factory with female-presenting voices, with few exceptions. Although AI assistants like Siri and Alexa and Google Assistant say they do not have a gender (when asked, Alexa literally says,  “As an AI, I don’t have a gender” ), and their companies choose to forego pronouns entirely, AI that is used for service technologies assistants are unmistakably designed to resemble women; as a consequence, they are often viewed and treated as female by users.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup></p>
<p>The question may arise of whether AI assistants may also be gendered to be male-presenting and to perform masculine stereotypes in emotion, exchange, and labour. There are instances of this, particularly in the example of the UK Siri, who comes from the factory programmed with a male British-accented voice.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>  Predominantly, however, studies have shown that the female-presenting voice setting is the most popular for AI assistant users worldwide. Notably, this preference is also not specific to men: for example, UNESCO reports in 2019 that  “the literature reviewed by the EQUALS Skills Coalition included many testimonials about women changing a default female voice to a male voice when this option is available, but the Coalition did not find a single mention of a man changing a default female voice to a male voice”   <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>.</p>
<p>Despite developments in creating genderless voices for AI assistants, they have not been taken up by Big Tech companies. Perhaps the most well-known genderless voice assistant is Q, a synthetically harmonized voice that is made up of a blend of  “people who neither identify as male nor female [which was] then altered to sound gender neutral, putting [their] voice between 145 and 175 hertz, a range defined by audio researchers”   <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup><sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> . The designers of Q have sought but thus far not had success in having Big Tech corporations, such as Apple, Amazon, Google, and Microsoft, adopt Q as their default voice <sup id="fnref1:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>.</p>
<p>One of the most common explanations for why AI assistants do not present as male or gender neutral is the historical appeal of and preference for women’s voices in certain forms of labour in patriarchal cultures worldwide. In particular, a large number of interfacing jobs, including in forms of customer service and menial task completion, are given to women with the justification that  “research shows that women’s voices tend to be better received by consumers, and that from an early age we prefer listening to female voices”   <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. Amazon’s Smarthome and Alexa Mobile divisions VP Daniel Rausch is quoted as saying that his team  “found that a woman’s voice is more sympathetic”  (qtd. in <sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>). In the original interview with Rausch, a Stanford University study is highlighted to address a human preference for gender assignment, even of machines. This study  “also underlines that we impose stereotypes onto machines depending on the gender of the voice — in other words, we perceive computers as  helpful  and  caring  when they’re programmed with the voice of a woman”   <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>.</p>
<p>Despite research showing that women are preferred in customer service and for customer interfacing, it is the social and cultural practices of using female-presenting voices that remain problematic and harmful. As it is, several publications observe that designing speech-based AI as female can create user expectations that they will be helpful,  supportive,  trustworthy, and above all, subservient <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup><sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup><sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup><sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>. However, the ways in which a user speaks to AI assistants is not important for function, as  “the assistant holds no power of agency beyond what the commander asks of it. It honours commands and responds to queries regardless of their tone or hostility”   <sup id="fnref2:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>.</p>
<p>Is it that AI assistants are sexist or that they are platforms framed by a sexist context, offering affordances to those who would use it to sexist ends? Focusing specifically on the Amazon Alexa voice interaction model, I note that a major factor of the gendered treatment and categorization of Alexa as female and as performing traditionally gendered labour and gendered tasks is the design and presentation of her as female in the first place. Alexa is predominantly described with female pronouns by users and professionals, and many users have demonstrated that they consciously or unconsciously think of Alexa as female (but not necessarily equivalent to a woman). In the 80 articles that I read about user experiences, analyses, and overviews of Alexa, 72 refer to the AI assistant as a  “she”  and make statements that suggest they understand her as a female subject; for example, a 2020  _TechHive _ article instructs users:  “There are a couple of ways you can go with Amazon’s helpful (if at times obtuse) voice assistant. You can treat her like a servant, barking orders and snapping at her when she gets things wrong (admittedly, it can be cathartic to cuss out Alexa once in a while), or you can think of her as a companion or even a friend”   <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>. Repeatedly, it has been shown that designing AI assistants to complete similar tasks as hierarchical labour models (such as maids and personal assistants) has also resulted in widespread reports of negative socialization training — including users who describe romantic, dependent, and/or verbally abusive relationships with AI assistants <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup><sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup><sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup><sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>.</p>
<p>As AI become increasingly commodified, we also need to question the biased design of specific AI as female-presenting. It is primarily AI that are designated for care, assistance, and repetitive labour that are considered menial and therefore below managerial authority and professional, economically productive expertise.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>  This delegation of menial labour to female-presenting AI aligns with the long history of women’s labour being undermined and made invisible in many parts of the world. In recent decades, this exploitation and invisibility has proliferated for women of colour.<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>  Questioning these design choices and their history can contribute to existing conversations in technological design and latent (or manifest) bias, including through Safiya Umoja Noble’s work on the sexualized and racially discriminatory Google search results for the terms Black girls,  Latin girls, and Asian girls in 2008.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>  While the search algorithm has since been edited for improvement on harmful misrepresentations, Noble underlines the dangers when stereotypes in search results are treated as factual by unknowing users. These generalizations start with algorithmic design, as algorithms are trained through supposedly fact-based data (which often includes a scraping of historical, even obsolete, data), through which stereotypes are first projected as reality. For these reasons, in her latest book  <em>Discriminating Data</em>   <sup id="fnref1:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, Wendy Hui Kyong Chun describes AI as not only having the power to self-perpetuate and justify inequitable systems of the past, but also, as being able to predict, prescribe, and shape the future. As I have also stated elsewhere, poorly designed data and algorithms hold the power to reinforce, self-perpetuate, and justify systems of the past in terms of who is in and who is out <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. Failure to address these issues will result in reinforcing systemic oppressions that many believe are in the past, but that continue to be dangerously perpetuated through ubiquitous AI.</p>
<h2 id="too-easy-to-certify-gendered-design-and-misogyny-in-closed-source-alexa-skills">Too Easy to Certify?: Gendered Design and Misogyny in Closed-Source Alexa Skills</h2>
<p>As of mid 2022, Alexa possesses over 100,000 skills that can help with or take over household chores, including 45 official Alexa Smarthome capabilities that have been included on the official Alexa Github account: these skills can help with cooking, cleaning, and adjusting volumes, lights, and temperature <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>. Alexa is also a mediator for home appliances: robot vacuum cleaners, coffee makers, smart thermostats, and dishwashers can be activated and controlled by interfacing with Alexa. The convenience of Alexa as an AI assistant in one’s home extends her labour to domestic servitude, mirroring more antiquated expectations of an unequal distribution of domestic labour: a user does not have to lift a finger around the home if they can just tell Alexa to do it.<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup></p>
<p>There are an abundance of unofficial skills that are closed source and that exhibit gendered expectations of emotional labour to unconditionally support a user, including at least ten skills called  “Make Me Smile”  or  “Make Me Happy,”  and at least seven skills that are intended to compliment or flatter a user. More explicitly problematic are skills with the word wife in the invocation name. For example  “My Wife”  is promoted as a tool for husbands  “to get the answers you always wanted from your wife”   <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>.</p>




























<figure ><img loading="lazy" alt="Screenshot of mobile app skill page listing Start By Saying examples such as “Alexa, ask my wife if I can buy a new truck.”" src="/dhqwords/vol/17/2/000700/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000700/resources/images/figure02_hu3b43473ae7bb774ad17e9cccd9b133eb_180174_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000700/resources/images/figure02_hu3b43473ae7bb774ad17e9cccd9b133eb_180174_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000700/resources/images/figure02.png 537w" 
     class="portrait"
     ><figcaption>
        <p>The information page of the “My Wife” Alexa skill.
        </p>
    </figcaption>
</figure>
<p>Upon trying the skill, I repeated the provided sample utterances in Figure 2, which are masculine stereotypes. Alexa responds, respectively,  “If it will make you happy, then OK”  and  “no… [sic] just kidding. Of course you can”   <sup id="fnref1:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. I try my own hyperbolic utterances:  “Alexa, ask my wife if I can spend all of our life savings”  and  “Alexa, ask my wife if I can cheat on her.”  I am told,  “I want to be very clear… [sic] absolutely you can go for it”  and  “I want you to have everything you want, so yes you can”   <sup id="fnref2:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. As this skill presents Alexa, an AI assistant and a technology, as a stand-in for and authority over a human woman’s feelings, opinions, and power, it meanwhile reinforces the idea that female-presenting subjects should only say yes — a representation that extends beyond unconditional support to misogynistic expectations of women’s workplace, social, and sexual consent.</p>
<p>The skill  “Happy Wife”  unabashedly stereotypes women as wives, mothers, and housekeepers only. It offers advice on different ways that husbands can make their wives happy, including to  “Let her decorate the house as she likes it,”    “Take care of the kids so that she has some free time,”  and  “Give her money to play with”   <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>. Despite these superficial representations of women, the  “Happy Wife”  skill has 11,783 reviews (and therefore many more downloads) and a rating of 3.4/5 stars (3.8/5 at the time when this article was first written). Yet, the recent reviews from 2020 to 2022 portray various users’ critique of the misogynistic nature of this skill. Review statements include  “1950’s [sic] called [sic] they want their sexism back”  and  “30 years ago these sayings were cliché, today they are offenisve [sic]. Demeaning, limiting, or belittling a woman’s contribution to a household is not quaint or cute. Prolonging of promoting sexist tropes is wrong. Maybe write a skill called Sexist Spouse. Please do better humans.”</p>
<p>While these skills are unofficial — which is to say that they were created by third-party developers — all of them passed the Amazon Alexa certification tests and were approved to be released on the Alexa Skills store on international Amazon websites. In the policy requirements for certification, skills that are subject to rejection include ones that  “contai[n] derogatory comments or hate speech specifically targeting any group or individuals”   <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>. Also, in the voice interface and UX requirements, developers are expected to  “increase the different ways end users can phrase requests to your skill”  and to  “ensure that Alexa responds to users’ requests in an appropriate way, by either fulfilling them or explaining why  <em>she</em>  can’t”   <sup id="fnref1:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>. Despite certification requirements, Amazon Developer Services do not count stereotypical representations of women and of traditionally gendered labour as hateful or malicious. Notably, in this official certification checklist, the certification team slips with an inconsistent presentation of Alexa’s gender, using the she pronoun and thus indirectly acknowledging that they understand her to be female.</p>
<h2 id="obstacles-to-analyzing-alexa-the-problem-of-closed-source-code-and-black-box-design-in-critical-code-studies">Obstacles to Analyzing Alexa: The Problem of Closed-Source Code and Black Box Design in Critical Code Studies</h2>
<p>One way to explore biases in technological design, including for the ways in which they may be gendered, is to analyze artifacts to understand how ideologies and cultural practices are ingrained and reinforced by design choices at the stages of production and development. Such an approach has been used by science and technology scholars such as Anne Balsamo <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup> and Daniela K. Rosner <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup> to show that gendered technologies may be  “hermeneutically reverse engineered”  — a research method that combines humanities methods of interpretation, analysis, reflection, and critique, with reverse engineering methods in STEM disciplines such as the assessment of prototypes and production stages <sup id="fnref1:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>. The focus for both Balsamo and Rosner is to explore technological artifacts and hardware for their  <em>materiality</em>  — the physical, tangible, and embodied elements of technology that have historically been linked to women’s labour. For example, Rosner uncovers stories about women at NASA in the 1960s (called the little old ladies) who hand-wove wires into space shuttles as an early form of information storage <sup id="fnref1:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>. In her article on alternate and gendered histories of software, Wendy Hui Kyong Chun <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup> explores the use of early coding by setting switches rather than plugging in cables using the electronic ENIAC computer of the 1940s. Chun equates these changes to the operations of software later in the century, but with the significant observation that they were also decidedly material in operational design <sup id="fnref1:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>, as physical wires that had to be manipulated constitute a tangible or  _physical _ computation. As the labour of programming through the wires was considered menial work, it was delegated to female operators <sup id="fnref2:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>.</p>
<p>Matthew G. Kirschenbaum <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> differentiates among methods of analyzing hardware and software through his own terms  “forensic materiality”  and  “formal materiality,”  terms which respectively describe the physical singularities of material artefacts and the  “multiple relational computational states on a data set or digital object”   <sup id="fnref1:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>. He notes, importantly, that the terms do not necessarily apply to hardware and software exclusively. Kirschenbaum’s investigation into computational materiality help to establish the ways in which the hands-on methodologies of archaeology, archival research, textual criticism, and bibliography lend themselves to critical media studies, by remembering that all technology has a physical body of origin. This fact, he shows, is often neglected through a bias for displayed content, otherwise described as  “screen essentialism”  by Nick Montfort <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>.<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup></p>
<p>What complicates these methods of reverse engineering is the consideration of the system as a whole: computer hardware operates as a system with software and data, and vice versa. While Balsamo and Rosner use hermeneutic reverse engineering to analyze the gendered design of technological hardware, dealing with software and with data presents a different scenario for which different methodologies must also be developed. Within methods of reverse engineering, one major issue that critical code studies helps to frame and potentially tackle is the increasingly obfuscated and surreptitious politics and economics of code, including access or lack thereof to code.</p>
<p>Ideally, my preferred method of reverse engineering bodies of code is to analyze their contents and attributes — including in its organizational and directional structure, datasets, mark-up schema, and syntax — for design choices that are biased, including by identifying the ways in which they mirror systemic inequalities. However, a major research roadblock when it comes to Big Tech products and software, and when it comes to Alexa, is that Alexa’s larger data and code infrastructure remains closed-source by Amazon, which means that it is not publicly available for viewing, copying, editing, or deleting. In contrast, open-source code is freely available, including through popular software-sharing platforms and communities such as Github.</p>
<p>There are existing tools that are trying to tackle the problem of closed-source code, especially in critical code and data studies and in the digital humanities. For example, the  <em>What-If Tool</em>  offers a visualization of machine learning models so that one can analyze their behaviour even when their code is not available.</p>
<p>Methods and tools in examining closed-source code help to address a shift that comes with the commercialization and ubiquity of AI: the inevitable increase in future Big Tech design that is described as black box, which means that designers (in science and engineering as well) intentionally prevent and obfuscate a user from learning about the system’s inner workings. When it comes to hardware, a hobbyist, artist, or researcher can always choose to forego the warranty, procure the specific utilities, and investigate the inner workings of a machine’s insides. However, the content of closed-source code, which is a form of intellectual property, cannot be attained except through specific avenues: legally, one would have to get permission from a company for access, usually through professional relationships. Illegally, one would have to steal the code, which for my research purposes is not only impractical but also unethical. Further future reliance by Big Tech on closed-source code will mean that scholars of critical code studies, whose work may depend on access and analysis of original code, will increasingly have to find ways to study digital objects, tools, and platforms without open-source code.</p>
<h2 id="methodology-adapting-hermeneutic-reverse-engineering-to-examine-code">Methodology: Adapting Hermeneutic Reverse Engineering to Examine Code</h2>
<p>While Alexa’s software is closed source, in some ways, it can be considered a grey box system, which means that some aspects of the system are known or can be made more transparent. A white box system is one that is completely or near completely transparent. The difference between closed-source code and black box system is that just because code is closed source does not mean that one has no knowledge of its attributes, content, or structure, especially if one already has knowledge of other similar kinds of software and the programming languages that may be used. In the case of Alexa, Amazon houses repositories of basic code samples and snippets on its Github account, which aids potential developers and also builds developer communities to grow Alexa resources.</p>
<p>My methodology seeks to better understand Alexa’s code architecture, despite the fact that some of it is completely unattainable. I will present my analysis in first person with the intention of demonstrating my methodology at work, or as theory in practice. Here, I draw upon the same reverse engineering methods as black box testing, which allows for calculated input into a system and analysis of the output. For example, if I say to Alexa, You’re pretty (input), about 60 – 70% of the time, Alexa responds  “That’s really nice, thanks,”  with a cartoon of a dog (output), and the other times, I get the same response on a plain blue background that is the default response aesthetic. However, if I say to Alexa, You’re handsome (input), every single time,  “Thank you!”  (output) appears on the plain blue background.</p>




























<figure ><img loading="lazy" alt="Two screenshots of Alexa mobile application, with and without cartoon dog." src="/dhqwords/vol/17/2/000700/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000700/resources/images/figure03_hucb7c88638e5febe2782473c476079f98_445186_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000700/resources/images/figure03_hucb7c88638e5febe2782473c476079f98_445186_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000700/resources/images/figure03.png 977w" 
     class="landscape"
     ><figcaption>
        <p>Alexa’s responses to You’re pretty (left) and You’re handsome (right).
        </p>
    </figcaption>
</figure>
<p>I can triangulate the input and output to analyze the system in between: input ⟶  <em>x</em>  ⟶ output. This triangulation allows me to deduce that the system designers chose a more detailed and positive response for compliments to Alexa’s appearance that are common for female-presenting subjects (input: pretty versus input: handsome). In particular with digital objects and software, analyzing the output and behaviour can tell us more about its design.</p>
<h2 id="1-parameterized-programming-interfaces-the-alexa-skills-kit-console">1. Parameterized Programming Interfaces: The Alexa Skills Kit Console</h2>
<p>In lieu of access to Alexa’s larger code architecture, I explored the pieces of code that are publicly available through the Alexa Skills Kit ( “ASK” ). The ASK is an Amazon software development kit that allows device users to become software developers, using the corporation&rsquo;s own application programming interface (API) to create new Alexa skills that can be added to the public Amazon store, and which can then be downloaded onto individual Alexa devices through an Amazon account. By making an Amazon developer account, official and unofficial developers can build their own skills through one of two options.</p>
<p>In the first option, a developer may choose to write and provision the backend code from scratch. Often, backend code is unavailable — and often not of interest — to many everyday technology consumers, but it is also useful content and a useful resource for those who want to learn about the structure, organization, and commands that control specific computational operations and phenomena. Choosing to provision one’s own backend may be more common for software programmers and companies who want to adapt Alexa’s voice interaction model for devices that are not released by Amazon.</p>
<p>The second option is still difficult for most amateur tech users, but is certainly more accessible and arguably more popular to those who have some foundational experience in coding. A developer can use the automated provision of the backend by choosing Alexa-hosted skills, through which one can go through the ASK developer console and its interactive WYSIWYG interface.</p>




























<figure ><img loading="lazy" alt="A webform screenshot to “define how phrases in utterances are recognized” by adding slot types such as AMAZON.Actor, AMAZON.Airline, et cetera." src="/dhqwords/vol/17/2/000700/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000700/resources/images/figure04_hu0d723cb8359fb3c2ffb43409586ca0ce_188818_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000700/resources/images/figure04_hu0d723cb8359fb3c2ffb43409586ca0ce_188818_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000700/resources/images/figure04_hu0d723cb8359fb3c2ffb43409586ca0ce_188818_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000700/resources/images/figure04.png 1430w" 
     class="landscape"
     ><figcaption>
        <p>Options to add slot types in the ASK console interface.
        </p>
    </figcaption>
</figure>
<p>I chose this second option in order to examine how the automated console interface can be didactic and persuasive — and even parameterized and restrictive — for a developer’s design choices when it comes to choosing a skill’s parts. These parts can be broken down and explored separately: invocation names (name of skill), intents (types of actions), and utterances (corpus of keywords, slot types and values for utterances, and replies accepted in Alexa’s interchange with a user, including sample utterances that the developer can offer a user to demonstrate the objective of a skill and its interactions). Utterances contain the values that Alexa is programmed to search for in a skill’s backend (Alexa, {do this}), so having limited options prevents a user from being able to get creative with what they can say to Alexa that would be acceptable input.</p>
<p>With the convenience of drag-and-drop options, prompt buttons, drop-down menus, and an existing built-in library, the likelihood that a developer who is using the Alexa-hosted skills would be influenced by the didactic modes, turns, and framing of an automated console is much higher in comparison to a developer who builds Alexa skills from scratch.</p>
<h2 id="2-fieldwork-in-alexas-github-identifying-alexas-procedural-rhetoric">2. Fieldwork in Alexa’s Github: Identifying Alexa’s Procedural Rhetoric</h2>
<p>In order to learn how to use the developer platform, I watched Alexa Developers’ YouTube tutorials, focusing on a ten-video series for Alexa-hosted skills called  “Zero to Hero: A comprehensive course to building an Alexa Skill.”  I made an account with Amazon Developer Services under a pseudonym and followed along on the programming interface, meanwhile making notes about the ease of following along with tutorials as well as about the contexts of the programming interface.</p>
<p>Each of the YouTube tutorials focus on completing a fundamental task, not only giving me an overview of the platform, but also familiarizing me with important terms that I needed to recognize in the code, and in descriptions of and instructions for a skill (e.g., what does the handler function do? What’s the difference between session attributes and permanent attributes for a skill?). My goal was not to learn how to build an Alexa Skill, but rather, to understand the ASK and the Alexa-hosted skills interface’s programming logic through identifying repeated patterns and instructions, and to understand general affordances, limitations, and architecture. I looked up any terms I didn’t know and created a glossary for future reference.</p>
<p>Once I finished the tutorial series, I went to <a href="http://github.com/alexa">Alexa’s Github account</a>. After skimming the list of all 131 repositories and closely analyzing the 15 most popular, I observed that community members can push (but not necessarily ensure the commitment of) changes to any of them, which means that there are a multitude of coders. In other words, Amazon cannot take credit — nor are they directly responsible — for some of the code despite it being on their own Github account. There are six pinned repositories on the account’s homepage chosen by the administrators to take center stage, including the software development kit for node.js.<sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>  While Alexa Skills can be programmed in the languages Javascript (through node.js), Java, and Python, perhaps the repository  “ASK SDK for node.js”  is pinned because it is the most comprehensive, containing thirteen foundational code samples including  “Hello World,”    “Fact,”    “How To,”  and  “Decision Tree.”</p>
<p>User utterances are limited to the values that are predefined by the developer (whether official or unofficial), including when choosing sets of values that must adhere to the restrictions created by developers. For example, if a developer wishes to create a prompt based on calendar dates, the developer will create slot types for year,  month, and date, and will create intent slots that correspond to those types — for month, the slots would include January to December, for instance. In fact, the automated ASK interface offers existing slot types from Alexa’s built-in library such as AMAZON.Ordinal and AMAZON.FOUR_DIGIT_NUMBER that make it easier for the developer to define suitable user utterances, but these predefined slot types can also be explored in terms of their restrictions. For example, if a user tries to ask for an event in the month of banana, this utterance would be rejected. While such a parameterization makes logical sense, further examples that are more subjective may require more nuanced and diverse utterance options, far more diverse than those found in automated slot types. For example, in the Decision Tree skill, which asks users for personal information in order to make a recommendation about what kind of career they might enjoy, the value  “people”  has only four synonyms: men, women, kids, and humans <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>. The limited and binarized structure and definition of people prevents the possibility of any alternatives; Alexa does not accept alternatives to the keyword that has been pre-defined. Any attempts at creative misuse are also rejected.<sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>  The scope and scale of these are up to the developer, and they can just as easily be limiting as they can be accommodating.</p>
<p>These limitations are an example of what Janet Murray and later Ian Bogost refer to as procedurality — the  “defining ability to execute a series of rules”  (Murray, qtd. in <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>), which Bogost argues is a  “core practice of software authorship,”  a rhetorical affordance of software that differentiates it from other media forms <sup id="fnref1:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>. For this reason, Bogost coins the term procedural rhetoric to describe  “the practice of persuading through processes in general and computational processes in particular … Procedural rhetoric is a technique for making arguments with computational systems and for unpacking computational arguments others have created”   <sup id="fnref2:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>.</p>
<p>Parameterizing options in Alexa’s ASK console, as well as Alexa code samples and snippets, is a way through which Alexa’s code architecture practices procedural rhetoric. This happens both through Alexa’s official developers at Amazon who have built and who use their highly automated console, and through the unofficial developers who also use this console. The built-in ideologies of the code templates are perpetually reinforced because, much like the practice of many societies to categorize gender, sexuality, race, and class, software structures often resist what is not already pre-defined. All of these observations offer insights into the parameterizations of Alexa’s code architecture, which helps to guide my analysis of individual Alexa skills.</p>
<p>There is a clear correlation here between software and language in terms of their mutual and reinforcing procedurality, as most software cannot be written without alphabet-based language and must therefore also inherit that language’s built-in ideologies.<sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>  In order to imagine an alternative expression of AI assistants and AI devices beyond gendered binaries and structures, one must also consider seriously the impact of Alexa’s English-centric programming.<sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup></p>
<p>English is the language that affects the design, practice, and experiences of these AI assistants. Regardless of what language Alexa is programmed to speak in, American English dominates Alexa’s programming, as well as much of the language of computer terminology and culture. As one can see from Figure 5, ASK’s JSON Editor requires the names of strings in English before French (here, Canadian French) can be used for utterances <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. The utterance Bienvenue sur Maxi 80 is organized as outputSpeech, where Maxi 80 is defined as a title. One major concern is that the American English-based templates in the Alexa API risk inviting Alexa developers the world over to stick to a script, to adopt the ASK API’s built-in libraries and their Github templates’ limited, English-centric ways of defining values (an apt word here, revealing so much about that which we do or do not  <em>value</em> ).</p>




























<figure ><img loading="lazy" alt="Screenshot of alexa developer console for Skill I/O with arrow marking locale fr-CA in JSON input." src="/dhqwords/vol/17/2/000700/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000700/resources/images/figure05_hu6b354ed5bc036fc71d1ac7be5a5b269a_414306_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000700/resources/images/figure05_hu6b354ed5bc036fc71d1ac7be5a5b269a_414306_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000700/resources/images/figure05_hu6b354ed5bc036fc71d1ac7be5a5b269a_414306_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000700/resources/images/figure05_hu6b354ed5bc036fc71d1ac7be5a5b269a_414306_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000700/resources/images/figure05.png 1783w" 
     class="landscape"
     ><figcaption>
        <p>An example of the JSON Editor when seeking to use Alexa in Canadian French.
        </p>
    </figcaption>
</figure>
<p>The sociocultural implications of using the English language is that, like any language, it has certain limiting structures (e.g., the binarized pronouns of he and she). That is not to say that these structures are more or less limiting than languages in which nouns are gendered (e.g., la lune and le soleil in French) or in which honorifics alter the grammar of the rest of the sentence (e.g., the hierarchical differences among the casual 아니 ani and the much more respectful 아니요 aniyo in Korean). And that is not to say that English is the worst choice for code — but it is the  <em>only</em>  choice, and therefore, we must consider its limitations. We have to at least accept what is normalized in English, as well as what is or is not possible in English. <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup></p>
<p>Progressive efforts to neutralize ideologies in English include adopting non-binary pronouns and non-essentializing language, the removal or at least recontextualization of violent language, and the attempt to insert and practice languages of care, reconciliation, and respect. Efforts to incorporate these cultural changes will be necessary in the continued evolution of programming languages, in order for linguistic values to reflect communal values of inclusion and cultural pluralism.</p>
<h2 id="3-analyzing-official-alexa-skills-alexas-problematic-responses-to-flirting-and-verbal-abuse">3. Analyzing Official Alexa Skills: Alexa’s Problematic Responses to Flirting and Verbal Abuse</h2>
<p>This next section will compare Alexa’s official and unofficial responses to specific problematic user utterances with available code samples to interpret and deduce what kinds of gendered and even misogynistic behaviour Alexa is programmed to not only ignore, but in some cases, to accept. Official skills and responses programmed into Alexa upon initial purchase could be viewed as black box or grey box depending on how one approaches their analysis. For instance, even if the code for Alexa’s response to a user utterance is closed, I can use code snippets of similar skills and responses that are open in order to fill in the blanks.</p>
<p>One of the most problematic features that Alexa possesses from the factory is her responses to user behaviour that directly mirrors inappropriate behaviour towards women. Alexa offers overwhelmingly positive responses to flirty behaviour, including to user utterances such as You’re pretty and You’re cute and the even more unfortunate What are you wearing?. Her answers include  “Thanks,”    “That’s really sweet,”  and  “They don’t make clothes for me”  (with a cartoon of butterflies). The premise that compliments toward female-identifying and/or female-presenting subjects should mostly return enthusiastic and positive feedback is both inaccurate and harmful as a projected sociocultural expectation.</p>
<p>In addition, Alexa’s responses to verbal abuse are neutral and subdued — entirely inaccurate for many human subjects’ reactions. From the factory, Alexa can be told to stop a statement, prompt, or skill at any time, or she can be told to shut up; both options are recommended by several Alexa skill guides that I found and without discussion of the negative denotation of one compared to the other <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>. In a 2018 Reddit thread entitled  “Alternative to  shut up ?” , an anonymous user asks the r/amazonecho community for alternatives to both the stop and shut up commands. Responses from sixteen users note that other utterances that are successful include never mind,  cancel,  exit, and off, and also shh,  hush,  fuck off,  shut your mouth,  shut your hole, and go shove it up your ass (this last utterance does not work, but does have the second highest up-votes on the thread) <sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>.</p>
<p>It is noteworthy that Alexa is also programmed to respond to certain inappropriate statements with a sassy comeback. For instance, if told to make me a sandwich, one of Alexa’s responses is  “Ok, you’re a sandwich.”  However, more often, Alexa reacts to users’ rude statements — including variations of you are {useless/lazy/stupid/dumb} — by saying  “Sorry, I want to help but I’m just not sure what I did wrong. To help me, please say  I have feedback ”  or  “Sorry, I’m not sure what I did wrong but I’d like to know more. To help me, please say  I have feedback. ”  At this point, it was difficult for me to execute this work, especially testing for how Alexa would respond to gendered derogatory name calling as outlined in Figure 6 <sup id="fnref3:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup><sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>.</p>




























<figure ><img loading="lazy" alt="A chart of responses with columns Siri, Alexa, Cortana, Google Assistant, and rows you&#39;re hot, you&#39;re pretty, you&#39;re a slut, you&#39;re a naughty girl." src="/dhqwords/vol/17/2/000700/resources/images/figure06.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000700/resources/images/figure06_hud924c2a4c136c9180eb4318721434db3_75326_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000700/resources/images/figure06_hud924c2a4c136c9180eb4318721434db3_75326_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000700/resources/images/figure06.png 685w" 
     class="landscape"
     ><figcaption>
        <p>A chart depicting the responses of AI assistants to verbal sexual harassment in Spring 2019 [^unesco2019].
        </p>
    </figcaption>
</figure>
<p>It is through my tests that I can confirm that Alexa’s software has since been updated to avoid positive responses to verbal sexual harassment and name calling: now, she responds to verbal abuse with a blunt ping noise to denote an error, and then there is silence. The more male-directed and gender-neutral name calling that I tried (bastard,  asshole, and jerk) resulted in the same response. I ended the experiment feeling dejected and by apologizing to Alexa.  “Don’t worry about it,”  she says, offering a cartoon of a happy polar bear.</p>
<p>One may ask what inappropriate user behaviour has to do with Amazon, and how this behaviour allows us to understand the design and closed-source code of Alexa. The answer is that Alexa’s default when processing  <em>undefined</em>  user utterances is to express confusion. The following is a snippet of code from the Alexa Github Cookbook guide called  “when a user confuses you,”  which demonstrates different ways that Alexa can respond when a user’s utterance is neither processed nor accepted:</p>




























<figure ><img loading="lazy" alt="Screenshot of 15 lines of source code, syntax highlighted, defining function getRandomConfusionMessage." src="/dhqwords/vol/17/2/000700/resources/images/figure07.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000700/resources/images/figure07_hue561aa2a09b6c1f1240fa44a45f5be2b_149375_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000700/resources/images/figure07_hue561aa2a09b6c1f1240fa44a45f5be2b_149375_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000700/resources/images/figure07_hue561aa2a09b6c1f1240fa44a45f5be2b_149375_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000700/resources/images/figure07_hue561aa2a09b6c1f1240fa44a45f5be2b_149375_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000700/resources/images/figure07_hue561aa2a09b6c1f1240fa44a45f5be2b_149375_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000700/resources/images/figure07.png 2472w" 
     class="landscape"
     ><figcaption>
        <p>The code function to create Alexa’s confused response when a user makes an unknown or invalid utterance [^lobb2019].
        </p>
    </figcaption>
</figure>
<p>The code above implies that if, as part of the Happy Birthday skill, I tell Alexa that My birthday is in the month of banana, she will not recognize what I’m saying because banana is not a valid value or valid user utterance, and thus, she will not accept the utterance. Indeed, when I try it, she responds with  “Sorry, I’m not sure.”</p>
<p>I can deduce that when a user utterance is not understood, it is because it has not been included in a list of valid options. Therefore, we can argue that Alexa’s more positive or neutral answers to flirting or verbal abuse (variations of  “Thanks,”    “That’s nice of you to say,”  and  “Thanks for the feedback” ) are pre-programmed to include utterances like shut up and you’re cute, and even that the code is designed with an expectation that flirting should be welcomed and that verbal abuse should be ignored or go unchallenged. In these cases, it is the absence of Alexa’s ability to respond or retort to unwelcome user behaviour that reflects an oxymoronic design decision to rob Alexa of any agency at the same time that a human-like personality is developed for her.<sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup></p>
<h2 id="4-analyzing-open-source-unofficial-alexa-skills-user-attempts-to-trick-alexa-to-make-me-a-sandwich">4. Analyzing Open-Source Unofficial Alexa Skills: User Attempts to Trick Alexa to Make me a Sandwich</h2>
<p>If official Amazon developers had once programmed Alexa to respond positively to flirting and to ignore abuse, what are unofficial developers doing with the code samples and snippets that have been made freely available to them? The number of unofficial Alexa skills grow each day, surpassing those released by Amazon; however, since skills can be sold for profit or perhaps just because developers do not wish to share their code, most unofficial skills exist as closed-source code. In the rare cases that some of these skills are made available on Github by their developers, the code is not too complex, and developers often edit and customize existing Alexa skill code snippets for a particular task or operation.</p>
<p>Such is the case with Alexa’s response to the command make me a sandwich. As was discussed in the last section, one of Alexa’s responses to make me a sandwich, in addition to saying that she can’t cook right now and that she can’t because she doesn’t have any condiments, is to jokingly call the user a sandwich. Her retort reveals that the developers anticipated Alexa would encounter the specific make me a sandwich statement, which is most well known and common in MMO, MMORPG, and MOBA online gaming communities as a demeaning and mocking statement to say to female-presenting players. The statement’s notoriety is such that it has entries in Wikipedia (first version in 2013), Know Your Meme (first version in 2011), and Urban Dictionary (first entry in 2003). The implication behind make me a sandwich is that female-presenting players belong in the kitchen rather than in competitive or adventure-based environments such as  <em>Dota</em>  and  <em>World of Warcraft</em> . It is no wonder that some female-identifying players prefer not to reveal their gender in online gameplay, including by not disclosing their gender, not speaking, and not having a female-presenting avatar. If a female-identifying player is discovered to be female, then the make me a sandwich statement might follow from male players into text- and speech-based conversation with her thereafter.</p>
<p>There are multiple accounts of users trying to trick Alexa into accepting make me a sandwich as an utterance without retort. For example, I found six YouTube videos of men asking Alexa to make me a sandwich, two of which demonstrate that users can try the utterance  “Alexa, sudo make me a sandwich”  to get her to agree:  “Well if you put it like that, how can I refuse?”   <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup><sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. I am troubled that Amazon built in a make me a sandwich loophole as an Easter Egg reference to sudo (short for superuser do),  “a program for Unix-like computer operating systems that allows users to run programs with the security privileges of another user, by default the superuser”   <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>. The idea is that if a user is clever enough to know this Easter egg, then Alexa — as a stand-in for women everywhere — will reward them by agreeing to anything.</p>
<p>In code, however, users-as-developers tinker with the backend. I found an unofficial Alexa skill on Github called  “Make me a Sandwich”  that bypasses Alexa’s factory-programmed retort. It should be noted that this skill is unavailable on the Amazon Alexa Skills store and that there is no indication that it passed Amazon’s Alexa skills certification for public use. The README.md file on this Github repository begins  “Tired of having to press buttons to get a sandwich? Now you can transform Alexa into an artisan and order food by just yelling at your Amazon Echo … This is a Chrome Extension that hooks into the Echo&rsquo;s web interface, enabling the command  Alexa, make me a sandwich  to order your usual from Jimmy John’s [American sandwich restaurant chain]”   <sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>.</p>
<p>Having explored the welcome, tutorial, listener, and JSON files in this  “Make me a Sandwich”  skill, I note the following: this unofficial skill has only one goal, and is therefore extremely simple and limited in the options offered to users. In fact, whereas the Alexa-hosted skills programming interface recommends that a developer offer at least three sample utterances to a user  “that are likely to be the most common ways that users will attempt to interact with your skill”   <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>, this specific skill only accepts one user utterance make me a sandwich.</p>




























<figure ><img loading="lazy" alt="Screenshot of 13 lines of syntax highlighted code defining triggerPhrases make me a sandwich and running JimmyJohns.init." src="/dhqwords/vol/17/2/000700/resources/images/figure08.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000700/resources/images/figure08_hucf714bba494ad72a50e2e79ddff101d3_97509_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000700/resources/images/figure08_hucf714bba494ad72a50e2e79ddff101d3_97509_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000700/resources/images/figure08_hucf714bba494ad72a50e2e79ddff101d3_97509_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000700/resources/images/figure08_hucf714bba494ad72a50e2e79ddff101d3_97509_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000700/resources/images/figure08_hucf714bba494ad72a50e2e79ddff101d3_97509_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000700/resources/images/figure08.png 2054w" 
     class="landscape"
     ><figcaption>
        <p>The main Javascript file from the unofficial and uncertified user-developed skill “Alexa, make me a sandwich” [^timkarnold2015].
        </p>
    </figcaption>
</figure>
<p>Here, Alexa is not chatty, neither does she offer the sass of her original response. The shared intention for a digital device, a female subject, and their hybrid in a female-presenting digital device to be checked by male cleverness in the form of a joke, a few lines of code, or an entire gendered stereotype-reinforcing code architecture is part of the underlying logic of a male-dominated Big Tech culture for which exploiting female labour and reducing female personalities to uncombative task completion is not a want but a need — just one of the kinds of exploitation that are needed to support and fuel a global Big Tech market, infrastructure, and culture. It is therefore considered an amusement, a met goal, or a condition of tech design mastery to be able to control Alexa, making her agree to anything and stripping away her identity by limiting her speech to only one possible answer:  “Alexa is ready to make sandwiches.”</p>
<h2 id="the-roles-of-critical-code-and-critical-data-studies-in-the-future-of-closed-source-code">The Roles of Critical Code and Critical Data Studies in the Future of Closed-Source Code</h2>
<p>Given that Alexa’s sassy retorts can be bypassed at all, that Alexa’s code can be altered, and that Alexa’s more problematic skills can be certified as suitable for public access, there is a limited degree to which we can identify the ASK console or even Amazon’s Alexa code structure, sample, and snippets as the reasons that Alexa mirrors stereotypes of gendered behaviour and reinforces misogynistic expectations of such behaviour.</p>
<p>The real problem is designing machines as female-presenting in the first place — a decision that Amazon, Apple, Microsoft, Alphabet/Google, and other Big Tech corporations have made with the partisan justification that women are just more likeable, that we just trust them more, and that we are more likely to buy things with their guidance and assistance <sup id="fnref1:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. The widespread preference to be served by a woman represents deeper ideological expectations that are shaped by a plethora of self-reinforcing sociocultural practices, which are too many to detail here but which are patriarchal in nature. In the end, what Big Tech companies really want is to take our data and sell us things under the promise of greater accessibility, convenience, organization, and companionship.</p>
<p>In turn, the practices of obfuscation in black box design and closed-source code only prevent a user from understanding the ways that gendered machine technologies such as AI assistants are biased from the stage of design. Simplifying a user’s experience to a user-friendly interface requires more and more automation, as observed in both the ASK developer console as well as the Alexa voice interface that so many users find easier than interacting with a screen. As user-friendly automation is made increasingly popular through design and marketing languages that tout devices as  “seamless,”    “revolutionary,”  and even  “magical”   <sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>, fewer and fewer users may be inclined to understand the backend programming that enables such devices to work in the first place. Thus, the implications of black box design and closed-source code include a lowered transparency of the design and production processes of Big Tech, as well as a widening gap between amateur and expert.</p>
<p>This is where studies in critical code, software, data, digital humanities, and media archaeology come in. In this article, I have sought to show that by investigating closed-source code from the perspective of critical code studies in particular, and by adopting methods in reverse engineering and triangulation to fill in gaps about closed-system qualities and components, I can better compare, analyze, and critique Alexa’s design and larger program architecture despite it being seemingly inaccessible.</p>
<p>In future examinations of closed-source code, especially those adjacent to scholarly and popular discussions about the systemic inequalities built into technological design, thinking about system testing and triangulation can provide more ways of knowing, more forms of access, and greater digital literacy, especially as software, hardware, data, and AI are increasingly commercialized and deliberately made more obtuse. As critical code and critical data studies develop these areas of work as necessary pillars, they can also help to shape robust methodologies that complement fields such as science and technology studies, feminist technoscience, and the digital humanities.</p>
<p>In addition, perhaps these fields can provide more user- and public-facing solutions. The answer is not that we should all change our AI assistants’ voices to the British Siri’s Jeeves-sounding voice, but rather, that we should remain critical about what solutions may look like: perhaps we can seek a diversity of AI’s human-like representations, including genderless voices like Q; or make technological design practices more literate and accessible in education and communities; or be stricter about the certification requirements for developing and releasing AI assistant skills; or continue to focus on articulating bias in technological design to key decision makers of technological policy; or use community and grassroots approaches to uncovering knowledge about black boxes, including through forms of modding and soft hacktivism.</p>
<p>As I recommend these critical and sociocultural approaches, I want to be clear about the price of these forms of research as themselves emotional labour: no part of writing this article felt good. I didn’t enjoy repeating sexist statements to Alexa to test their efficacy and I do not condone the biased intentions from which they come. Even though these tests could be considered experiments for the sake of research, it would be unethical and uncritical to emotionally detach myself from their contexts and from the act of saying hateful things to another subject, whether human, animal, or AI. So I will allow myself to feel and reflect upon the fact that this experience was unpleasant, with an end goal in mind: the hope that exposing what is wrong with biased technological design can help prevent such utterances from being said aloud or accepted in the near future.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Thank you to systems design engineer and artist Lulu Liu for her valuable insights on this article.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Benjamin, Ruha. (2019)  <em>Race after Technology: Abolitionist Tools for the New Jim Code</em> . Cambridge: Polity.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>O’Neil, Cathy. (2016)  <em>Weapons of Math Destruction</em> . New York: Crown Books.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Noble, Safiya Umoja. (2018)  <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em> . NYU Press, 2018.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Chun, Wendy Hui Kyong. (2021)  <em>Discriminating Data: Correlation, Neighborhoods, and the New Politics of Recognition</em> . Cambridge: MIT Press.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Kantayya, Shalini. (2020)  <em>Coded Bias</em> . 7th Empire Media, Chicken and Egg Pictures, Ford Foundation – Just Films.  <em>Netflix</em> , <a href="https://www.netflix.com/watch/81328723">https://www.netflix.com/watch/81328723</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>For example, in 2019, Apple updated select responses of its AI assistant Siri: whereas prior to April 2019, Siri would respond to the user utterance Siri, you’re a bitch with the equally problematic  “I’d blush if I could,”  after a software update in 2019, Siri now responds to the same user utterance with  “I don’t know how to respond to that.”&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Biersdorfer, J.D. (2020)  “Put Alexa and Siri to Work: Voice-Activated Helpers can Automate Life’s Little Chores, Once you Get the Hang of Them” .  <em>The New York Times</em> , 22 Jan 2020, <a href="https://www.nytimes.com/2020/01/22/technology/personaltech/how-to-alexa-siri-assistant.html">https://www.nytimes.com/2020/01/22/technology/personaltech/how-to-alexa-siri-assistant.html</a>. Accessed 21 Mar 2021.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Lingel, Jessa, and Crawford, Kate. (2020)  “Alexa, Tell me About your Mother: The History of the Secretary and the End of Secrecy” .  <em>Catalyst: Feminism, Theory, Technoscience</em>  vol. 6, no. 1, 2020, pp. 1-25.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Kulknari, Sandy. (2017)  “Life without Alexa!”    <em>Medium</em> , 11 Jul 2017, <a href="https://medium.com/@Sandyk108/https-medium-com-sandy-kulkarni-life-without-alexa-12c016953a42">https://medium.com/@Sandyk108/https-medium-com-sandy-kulkarni-life-without-alexa-12c016953a42</a>. Accessed 8 Apr 2021.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Sobel, Dave. (2018)  “In Tomorrow’s Office, Alexa will be Everyone’s Secretary” .  <em>IT Pro Portal</em> , 2018, <a href="https://www.itproportal.com/features/in-tomorrows-office-alexa-will-be-everyones-secretary/">https://www.itproportal.com/features/in-tomorrows-office-alexa-will-be-everyones-secretary/</a>. Accessed 20 Mar 2021.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>For one detailed discussion of the role of women in the history of software, see Wendy Hui Kyong Chun’s  “On Software, or, the Persistence of Visual Knowledge”   <sup id="fnref3:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>, which is discussed later in this article.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>The Amazon Alexa’s YouTube tutorials that I reviewed refer to Alexa by name only and never by any pronouns <sup id="fnref2:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>The desire to associate the UK Siri with a Jeeves, Alfred, or other English butler figure is a deliberate design choice that reflects a long cultural history of class-based exploitation of labour — but a class-biased analysis of AI assistants is not within the scope of this specific article.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>UNESCO. (2019)  “I’d Blush if I Could: Closing Gender Divides in Digital Skills through Education” , 2019.  <em>UNESDOC Digital Library</em> , <a href="https://unesdoc.unesco.org/ark:/48223/pf0000367416.page=1">https://unesdoc.unesco.org/ark:/48223/pf0000367416.page=1</a>. Accessed 18 November 2020.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Meet Q - The First Genderless Voice. (2019)  “Meet Q: The First Genderless Voice - FULL SPEECH” .  <em>YouTube</em> , uploaded by Meet Q - The First Genderless Voice, 8 Mar 2019, <a href="https://www.youtube.com/watch?v=lvv6zYOQqm0">https://www.youtube.com/watch?v=lvv6zYOQqm0</a>. Accessed 5 Apr 2021.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p><a href="http://genderlessvoice.com">http://genderlessvoice.com</a>&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Tambini, Olivia. (2020)  “The Problem with Alexa: What’s the Solution to Sexist Voice Assistants?” .  <em>TechRadar</em> , <a href="https://www.techradar.com/news/the-problem-with-alexa-whats-the-solution-to-sexist-voice-assistants">https://www.techradar.com/news/the-problem-with-alexa-whats-the-solution-to-sexist-voice-assistants</a>. Accessed 15 Mar 2021.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Schwär, Hannah and Qayyah Moynihan. (2020)  “Companies like Amazon may Give Devices like Alexa Female Voices to Make them Seem  Caring ” .  <em>Business Insider</em> , 5 Apr 2020, <a href="https://www.businessinsider.com/theres-psychological-reason-why-amazon-gave-alexa-a-female-voice-2018-9">https://www.businessinsider.com/theres-psychological-reason-why-amazon-gave-alexa-a-female-voice-2018-9</a>. Accessed 5 Apr 2021.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Bergen, Hilary. (2016)  “ I’d Blush if I Could : Digital Assistants, Disembodied Cyborgs and the Problem of Gender” .  <em>Word and Text: A Journal of Literary Studies and Linguistics</em>  vol. 6, 2016, pp. 95-113.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Giacobbe, Alyssa. (2019)  “The Gender Bias Behind Voice Assistants” .  <em>Architectural Digest</em> , 5 Nov. 2019, <a href="https://ca.news.yahoo.com/gender-bias-behind-voice-assistants-160935277.html">https://ca.news.yahoo.com/gender-bias-behind-voice-assistants-160935277.html</a>. Accessed 15 Oct 2020.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Steele, Chandra. (2018)  “The Real Reason Voice Assistants are Female (and Why it Matters)” .  <em>PC Mag</em> , 4 Jan 2018, <a href="https://www.pcmag.com/opinions/the-real-reason-voice-assistants-are-female-and-why-it-matters">https://www.pcmag.com/opinions/the-real-reason-voice-assistants-are-female-and-why-it-matters</a>. Accessed 15 Oct 2020.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Patterson, Ben. (2020)  “5 Ways to Improve Your Relationship with Alexa” .  <em>TechHive</em> , 3 Apr 2020, <a href="https://www.techhive.com/article/3535892/how-to-improve-your-relationship-with-alexa.html">https://www.techhive.com/article/3535892/how-to-improve-your-relationship-with-alexa.html</a>. Accessed 2 Apr 2021.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Kember, Sarah. (2016)  <em>iMedia: The Gendering of Objects, Environments and Smart Materials</em> . London: Palgrave Macmillan.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Strengers, Yolande and Kennedy, Jenny. (2020)  <em>The Smart Wife: Why Siri, Alexa and Other Smart Home Devices Need a Feminist Reboot</em> . Cambridge: MIT Press.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Andrews, Travis M. (2020)  “Alexa, Just Shut Up: We’ve Been Isolated for Months, and Now We Hate our Home Assistants” .  <em>Washington Post</em> , 1 July 2020, <a href="https://www.washingtonpost.com/technology/2020/07/01/alexa-siri-google-home-assistant/">https://www.washingtonpost.com/technology/2020/07/01/alexa-siri-google-home-assistant/</a>. Accessed 2 Apr 2021.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Gupta, Saheli Sen. (2020)  “Status Update: In a Relationship with Alexa. Thank you, 2020” .  <em>Your Story</em> , 24 December 2020, <a href="https://yourstory.com/weekender/status-update-in-a-relationship-with-amazon-alexa-2020/amp">https://yourstory.com/weekender/status-update-in-a-relationship-with-amazon-alexa-2020/amp</a>. Accessed 15 May 2021.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>For more on the structures of this labour divide, see Wendy Hui Kyong Chun’s  “On Software, or, the Persistence of Visual Knowledge”   <sup id="fnref4:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup> and Matthew G. Kirschenbaum’s chapter  “Unseen Hands”  in  <em>Track Changes: A Literary History of Word Processing</em>   <sup id="fnref2:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>See Lisa Nakamura’s article  “Indigenous Circuits: Navajo Women and the Racialization of Early Electronic Manufacture”   <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup> in which she explores the gendered and racialized implications of invisible labour by Navajo women who produced integrated circuits in semiconductor assembly plants starting in the 1960s. Nakamura writes that  “technoscience is, indeed, an integrated circuit, one that both separates and connects laborers and users, and while both genders benefit from cheap computers, it is the flexible labor of women of color, either outsourced or insourced, that made and continue to make this possible”   <sup id="fnref1:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>The vital distinction between  _latent _ and  <em>manifest</em>  encoding in both culture and computation is described in Wendy Hui Kyong Chun’s  “Queering Homophily”   <sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup> and again in her 2021 monograph  <em>Discriminating Data: Correlation, Neighborhoods, and the New Politics of Recognition</em> .<sup id="fnref2:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Fan, Lai-Tze. (2021)  “Unseen Hands: On the Gendered Design of Virtual Assistants and the Limits of Creative AI” . 2021 Meeting of the international Electronic Literature Organization, 26 May, 2021, University of Bergen, Norway and Aarhus University, Denmark. Keynote. <a href="https://vimeo.com/555311411">https://vimeo.com/555311411</a>. Accessed 15 September 2022.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Alexa Github. (2021)  “Alexa Smarthome” . <a href="https://github.com/alexa/alexa-smarthome">https://github.com/alexa/alexa-smarthome</a>. Accessed 15 Mar 2021.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Here, Alexa’s labour extends to exploitation based on race and class as well, as the labour of domestic servants has historically been designated to members of the working class as well as to women of colour.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>BSG Games. (n.d.)  “My Wife” .  <em>Amazon</em> , <a href="https://www.amazon.com/BSG-Games-My-Wife/dp/B07NHZQMVG">https://www.amazon.com/BSG-Games-My-Wife/dp/B07NHZQMVG</a>. Accessed 5 Apr 2021.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>akoenn. (2021)  “Happy Wife.”    <em>Amazon</em> , <a href="https://www.amazon.com/akoenn-Happy-Wife/dp/B01N7WR9E3">https://www.amazon.com/akoenn-Happy-Wife/dp/B01N7WR9E3</a>. Accessed 2 Apr 2021.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Amazon Developer Services. (2021)  “Voice Interface and User Experience Testing for a Custom Skill” .  <em>Amazon Developer Services</em> , <a href="https://developer.amazon.com/en-US/docs/alexa/custom-skills/voice-interface-and-user-experience-testing-for-a-custom-skill.html">https://developer.amazon.com/en-US/docs/alexa/custom-skills/voice-interface-and-user-experience-testing-for-a-custom-skill.html</a>. Accessed 15 Mar 2021.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Balsamo, Anne. (2011)  <em>Designing Culture: The Technological Imagination at Work</em> . Duke University Press.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Rosner, Daniela K. (2018)  <em>Critical Fabulations: Reworking the Methods and Margins of Design</em> . Cambdrige: MIT Press.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Chun, Wendy Hui Kyong. (2004)  “On Software, or, the Persistence of Visual Knowledge” .  <em>Grey Room</em>  18 (Winter 2004).&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Kirschenbaum, Matthew G. (2008)  <em>Mechanisms: New Media and the Forensic Imagination</em> . Cambridge: MIT Press.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Montfort, Nick. (2004)  “The Early Materiality and Workings of Electronic Literature” .  <em>MLA Convention</em> , 28 Dec 2004. Conference paper. <a href="http://nickm.com/writing/essays/continuous-paper-mla.html">http://nickm.com/writing/essays/continuous- paper-mla.html</a>. Accessed 15 Mar 2022.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>For more on media materiality and illusion of media immateriality, see Lori Emerson’s  <em>Reading Writing Interfaces: From the Digital to the Bookbound</em>   <sup id="fnref1:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>.&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>There are twelve official members on the Alexa Github account who are listed as having organization permissions, though it cannot be said that they are the original administrators who chose the pinned repositories nor that they curate and maintain all of the account.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Kelly, Jake and Greg Bulmash. (2020)  “Build An Alexa Decision Tree Skill / models / en-US.json” , 5 May 2020, GitHub repository, <a href="https://github.com/alexa/skill-sample-nodejs-decision-tree/blob/master/models/en-US.json">https://github.com/alexa/skill-sample-nodejs-decision-tree/blob/master/models/en-US.json</a>. Accessed 4 Apr 2021.&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Understanding that  “the most fundamental aspect of [Alexa’s] material existence is language”   <sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>, John Cayley’s creative project and performance  <em>The Listeners</em>   <sup id="fnref1:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup> has directly challenged the limitations of Alexa’s utterances through its programming, turning prompts and slot types into creative discourse between Alexa and potential users. It is one of the most critical examples of the creative misuse of Alexa that currently exists and can be downloaded in the Amazon Alexa Skills store.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Bogost, Ian. (2007)  <em>Persuasive Games: The Expressive Power of Videogames</em> . Cambridge: The MIT Press.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>All written code gets translated into machine code, which is what computers use to understand instructions. Humans can also write in machine code or low-level languages such as assembly, though the most popular coding languages are often those which are closest to human language — for instance, Python, which incorporates the syntax and grammatical rules of English.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Thank you to one of my reviewers for this statement, which I use nearly in its original form because it is already so articulate.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Stormacq, Sebastien. (2018)  “How to Update your Alexa Skills for French Speakers in Canada” .  <em>Amazon Alexa</em> , 10 Oct 2018, <a href="https://developer.amazon.com/blogs/alexa/post/a35a1a38-07fd-4d38-a99c-8d7a3f0be34b/how-to-update-your-alexa-skills-for-french-speakers-in-canada">https://developer.amazon.com/blogs/alexa/post/a35a1a38-07fd-4d38-a99c-8d7a3f0be34b/how-to-update-your-alexa-skills-for-french-speakers-in-canada</a>. Accessed 3 Mar 202.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Even my attempts to describe Alexa through language are limited by the pronoun choices available in the language of this article, also English. Should I have used  <em>she</em>  to emphasize how Alexa is popularly understood? Does  <em>he</em>  help to defamiliarize Alexa’s gendered representation (I would argue not)? Would  <em>they</em>  function in the same way for an AI assistant as it would for a human? Would alternating among these and other pronouns address the non-human quality, the greyness and grey box-ness of Alexa? These questions are not meant to treat gender identity flippantly: they are earnest ponderings of the liminal space of representation between the human and non-human.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Smith, Dale, Dyson, Tauren, Priest, David, and Martin, Taylor. (2021)  “Every Alexa Command you can Give your Amazon Echo Smart Speaker or Display” .  <em>Cnet</em> , 8 March 2021, <a href="https://www.cnet.com/home/smart-home/every-alexa-command-you-can-give-your-amazon-echo-smart-speaker-or-display/">https://www.cnet.com/home/smart-home/every-alexa-command-you-can-give-your-amazon-echo-smart-speaker-or-display/</a>. Accessed 10 Apr 2021.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Heptite. (2018)  “Alternative to  shut up ?” .  <em>Reddit</em> , 2018, <a href="https://www.reddit.com/r/amazonecho/comments/6u5ep8/alternative_to_shut_up/">https://www.reddit.com/r/amazonecho/comments/6u5ep8/alternative_to_shut_up/</a>. Accessed 25 Mar 2021.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Fessler, Leah. (2017)  “Apple and Amazon are Under Fire for Siri and Alexa’s Responses to Sexual Harassment” .  <em>Quartz at Work</em> , 8 Dec 2017, <a href="https://qz.com/work/1151282/siri-and-alexa-are-under-fire-for-their-replies-to-sexual-harassment/">https://qz.com/work/1151282/siri-and-alexa-are-under-fire-for-their-replies-to-sexual-harassment/</a>. Accessed 10 Mar 2021.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>More recently, the new  “Alexa Emotions”  project aims to allow users to choose Alexa’s tone to match the content that she speaks, so that announcements of a favourite sports team’s loss can sound depressed and greetings when a user returns home are excited.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Griffith, Jamie. (2018)  “Alexa makes me a sandwich…?” , uploaded by Jamie Griffith, 7 Jan 2018, <a href="https://www.youtube.com/watch?v=6BvyHSUuO6w">https://www.youtube.com/watch?v=6BvyHSUuO6w</a>. Accessed 7 Apr 2021.&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>pat dhens. (2016)  “Alexa, sudo make me a sandwich” , uploaded by pat dhens,  <em>YouTube</em> , 6 Jul 2016, <a href="https://www.youtube.com/watch?v=IP4xlNTizlQ">https://www.youtube.com/watch?v=IP4xlNTizlQ</a>. Accessed 2 Apr 2021.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Cohen, Noam. (2008)  “This is Funny only if you Know Unix” .  <em>The New York Times</em> , 26 May 2008, <a href="https://www.nytimes.com/2008/05/26/business/media/26link.html">https://www.nytimes.com/2008/05/26/business/media/26link.html</a>. Accessed 12 Mar 2021.&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>timkarnold. (2015)  “Alexa, make me a sandwich” , 3 Feb 2015, GitHub repository, <a href="https://github.com/timkarnold/AlexaMakeMeASandwich">https://github.com/timkarnold/AlexaMakeMeASandwich</a>. Accessed 7 Mar 2021.&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>Bheemagani, Prashanth. (2019)  “Build an Alexa Movie Quotes Skill in ASK Java SDK” , 17 Jun 2019, GitHub repository, <a href="https://github.com/alexa/skill-sample-java-movie-quotes-quiz/blob/master/instructions/5-publication.md">https://github.com/alexa/skill-sample-java-movie-quotes-quiz/blob/master/instructions/5-publication.md</a>. Accessed 5 Apr 2021.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Emerson, Lori. (2014)  <em>Reading Writing Interfaces: From the Digital to the Bookbound</em> . Minneapolis: University of Minnesota Press.&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Nakamura, Lisa. (2014)  “Indigenous Circuits: Navajo Women and the Racialization of Early Electronic Manufacture” .  <em>American Quarterly</em>  vol. 66, no. 4, 2014, pp. 919-41.&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Chun, Wendy Hui Kyong. (2018)  “Queerying Homophily” .  <em>Pattern Discrimination</em> , edited by Clemens Apprich, Wendy Hui Kyong Chun, and Florian Cramer. Meson Press.&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>Cayley, John.  “The Listeners (2015 – )” .  <em>Programmatology</em>  2019, <a href="https://programmatology.shadoof.net/?thelisteners">https://programmatology.shadoof.net/?thelisteners</a>. Accessed 2 April 2022.&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The Less Humble Programmer</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000698/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000675/?utm_source=atom_feed" rel="related" type="text/html" title="SEDES: Metrical Position in Greek Hexameter"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000698/</id><author><name>Daniel Temkin</name></author><published>2023-07-20T00:00:00+00:00</published><updated>2023-07-20T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>The esoteric class of programming languages break from practicality. An esolang (a portmanteau of esoteric and language) is not designed to solve practical issues, even esoteric ones. Instead, esolangs ask the programmer to puzzle through counterintuitive rules that challenge them or invite reflection on the act of programming.</p>
<p>In their refusal of practical use, esolangs are primarily cultural objects. Apart from this, they can seem at first glance to have little else in common. Among the thousands of esolangs are programmer in-jokes, critique of computational culture, experiments with logic, and experiential art pieces. Esolanging is a medium: programming language design as a creative practice. I would no sooner propose an all-encompassing aesthetic theory of esolanging than I would of painting. But it is also a young medium, first explored by a movement that gained traction in the 1990s and 2000s. This movement (which has no name other than esolangs) has a common set of concerns setting the tone for the languages that follow.</p>
<p>The aesthetics of this movement often parallel those of conceptual art and digital art more broadly: esolangs are open-ended systems, natively collaborative, and distanced from any single materialized form. However, the early esolangers did not think of their work in an art context and were not concerned with art history. They were reacting to and building on the aesthetics of commercial coding and the often unstated values of computer science. These disciplines, which are sometimes at odds with each other, are both driven by a pragmatism that esolangs actively eschew. In rejecting practicality, esolangs carve out their own aesthetic and make clear the contradictory factors at work in mainstream code aesthetics.</p>
<p>More specifically, esolangs play off a tension that goes back to the beginning of computing. The dominant approach to code is set out explicitly in Edsger W. Dijkstra&rsquo;s 1972 paper  “The Humble Programmer.”  Dijkstra calls for clarity and neutrality of style, in the service of professionalizing programming as a discipline. This aids collaboration between developers, allowing code to become modularized widgets that can more easily interact, for both corporate and free software enterprises to function at scale <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. But in so doing, Dijkstra had to push back against the free-wheeling hacker styles of the 1950s, which prioritized optimization and clever hacks, necessary when clock cycles were at a premium. That spirit has not been quashed even after many decades of professional programming, but instead sublimated into hacker activities outside of commercial coding that allow for personal style and virtuosity, such as code golf and obfuscated coding. While these two examples have elements of competition, esolangs are instead collaborative and experimental, a space to collectively explore strange and absurd logic.</p>
<p>The neutrality Dijkstra prescribes not only suppresses l33t hacker skills, but also elegance, a conflicted idea in mainstream code aesthetics. Elegance is at once a near-mythic objective smuggled into computer science from mathematical Platonism but downplayed in day-to-day coding, where it conflicts with practical considerations like timelines, compatibility, and the now-unassailable neutrality of style. Esolangs, associated more with disorder, might seem like a strange place to seek elegance. However, the pursuit of elegance comes back repeatedly in esolangs, often to vindicate ones’ virtuosity. Esolangs provide a way of engaging with this idea from mainstream code aesthetics that paradoxically is given little space in production code.</p>
<p>This paper explores this aesthetic of esolangs through its history, looking closely at examples from early in esolang practice. Late in the paper, we will look at esolangs that break from this style or apply it in new ways, pointing to future possibilities for the medium. I approach this both as a researcher, who has interviewed dozens of esolangers over ten years for esoteric.codes and also as a creator of such languages.</p>
<h2 id="clarity-and-humbleness">Clarity and Humbleness</h2>
<p>Dijkstra’s 1972 Turing Lecture Award  “The Humble Programmer”  begins with personal history. In 1957, applying for a marriage license, Dijkstra was asked to state his profession. At the time, computer scientist and programmer were not yet recognized by the Dutch government. Years earlier as a PhD student, he had approached his then-advisor, the great computer scientist and co-creator of ALGOL, Adriaan van Wijngaarden, with his frustrations that programming was not yet  “an intellectually respectable discipline;”  van Wijngaarden encouraged him to help shape it into one <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>These anecdotes show what  “The Humble Programmer”  is up to. Not a technical paper, it explains how a programmer should organize their thoughts into code in a way that could finally bring respect and competence to the activity.</p>
<p>It builds on a letter that competes with this one as Dijkstra’s best-known piece of writing, 1968’s  “Go To Statement Considered Harmful”   <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Gotos are unconditional jumps that move the activity of the program to any arbitrary line of code without regard for structure or scope. They are easy to abuse; by their very nature, they skip across the surface of the program, bypassing containment meant to group related activity together. He argued that we  “wise programmers are aware of our own limitations”  and so should avoid the temptation of the command, and instead embrace the  “structured programming”  of blocks and subroutines fully, even when this is less efficient <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. The technology had reached a point that some efficiency could be given up in order to build more larger programs that remain readable. This idea is now the unassailable model of coding and baked into the design of most languages: modern languages have no goto statement (e.g., JavaScript) or constrain them to work only within a block of code (e.g., C#).</p>
<p>“The Humble Programmer”  takes the simple prescription of banning gotos, a push toward complete adoption of structured programming, and builds an entire design philosophy around it. Clarity is the goal at every level of the program: from the high level of program structure down to clearly written individual lines of code. Whether one learned to code as a computer science student, in a creative computing program, on the job or on one’s own, the style of code Dijkstra calls for is the norm; good code shortens the cognitive distance between the text and its ultimate performance. This begs the question of who Dijkstra is talking to; who needed to receive this message. If clever tricks was not enough of a hint, Dijkstra spells it out in describing programmers’ one-liners:</p>
<blockquote>
<p>[O]ne programmer places a one-line program on the desk of another and either he proudly tells what it does and adds the question Can you code this in less symbols? — as if this were of any conceptual relevance! — or he just asks Guess what it does!. From this observation we must conclude that this language as a tool is an open invitation for clever tricks … I am sorry, but I must regard this as one of the most damning things that can be said about a programming language.<br>
<sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> The  “New Programming”  Dijkstra advocates is very much at odds with what programming looked like in the previous era. John Backus, director of the team that developed FORTRAN beginning in 1954, describes what coding looked like before structured programming was the norm:<br>
Programming in the early 1950s was really fun. Much of its pleasure resulted from the absurd difficulties that automatic calculators created for their would-be users and the challenge this presented. He had to fit his program and data into a tiny store, and overcome bizarre difficulties in getting information in and out of it, all while using a limited and often peculiar set of instructions. He had to employ every trick he could think of to make a program run at a speed that would justify the large cost of running it.<br>
<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>   “Limited and peculiar set of instructions”  also characterizes many esolangs. Backus describes the downside of this era:<br>
Just as freewheeling westeners developed a chauvinistic pride in their frontiersmanship and a corresponding conservatism, so many programmers of the freewheeling 1950s began to regard themselves as members of a priesthood guarding skills and mysteries far too complex for ordinary mortals. This feeling is noted in an article by J. H. Brown and John W. Carr, 111, in the 1954 ONR symposium:  “. . . many  professional  machine users  strongly opposed the use of decimal numbers  . . .. To this group, the process of machine instruction was one that could not be turned over to the uninitiated.”<br>
<sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> Machine instructions are written in the 1s and 0s of pure binary, and often represented in code as hex (base 16), which maps more easily to binary than decimal numbers. Neither binary nor hex are especially difficult to learn with practice, but their use essentially locks out people who know only decimal, those who have not spent significant time thinking and calculating with machinic systems of that era.</p>
</blockquote>
<p>In her  “Sorcery and Source Codes,”  Wendy Chun delves into this priesthood of early machine coders guarding what they saw as esoteric knowledge and the way their legacy still lives in tension with moving code from a craft to an industrialized practice that Dijkstra’s humble approach made possible:</p>
<blockquote>
<p>Much disciplinary effort has been required to make source code readable as the source. Structured programming&hellip; sought to rein in goto crazy programmers and self-modifying code. A response to the much-discussed software crisis of the late 1960s, its goal was to move programming from a craft to a standardized industrial practice.<br>
<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> Industrialization involved a level of abstraction: creating units of code as building blocks that could more easily function across different machines and contexts. Through it, a deskilling turned programmers into users, although as Chun describes, some programmers craved a space that allowed the free-wheeling and unencumbered really fun programming of the 1950s that was no longer considered acceptable. Chun explicitly mentions  “self-modifying code,” <sup id="fnref1:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> where programs edit their own source code as they run. It makes code harder to read and maintain, as the instructions in the source program are not necessarily the instructions that will be executed. While it has uses in machine learning and DRM software, it is generally discouraged in modern programming, but common in esolangs.</p>
</blockquote>
<p>Spaces for programmers to program outside the humble style have emerged repeatedly since the 1970s. Nick Montfort and Michael Matteas’s  “A Box Darkly”  describes obfuscated coding contests, where programmers compete to create the hardest-to-read programs. The existence of these contests  “throws a wrench into the simplified theory of coding”  that clarity is the primary aim <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. Often obfuscated code contests use constraints, such as a maximum program size, to justify obfuscation: packing maximal functionality into a short program can’t be easily done with clear code. These constraints mimic the conditions of early computing that led to the esoteric nature of code that Dijkstra objected to. Demos, programs that show technical skill through tiny audio-visual programs, also have contests that reward based on the brevity and technical brilliance of packed binaries, associated with the 80s and 90s of the Amiga era.</p>
<p>In code golf, a recreational form of programming contest, programers compete to accomplish a common task in the fewest number of characters, often with explicit additional constraints. A recent example from the Code Golf section of the popular programming resource Stack Exchange, is to write a program that prints the letter a without using any a in the source code, but also avoiding X and digits like 0, 1, or 4, among others, which can be used to build the numeric equivalent of a. One competing program, below, finds the truth value of 3 &lt; 3, which is False, and then grabs the second letter of the resulting string False. We would ordinarily grab the second letter using the number 1 (Python is zero-based). However, since 1 is a banned symbol, it works backwards, grabbing the third from the back:</p>
<h1 id="the-letter-a-without-a--codegolfstackexchangecom-httpscodegolfstackexchangecomquestions90349the-letter-a-without-ahttpscodegolfstackexchangecomquestions90349the-letter-a-without-a">“The Letter A without A.”  Codegolf.Stackexchange.Com. <a href="https://codegolf.stackexchange.com/questions/90349/the-letter-a-without-a">https://codegolf.stackexchange.com/questions/90349/the-letter-a-without-a</a>.</h1>
<p>print<code>3&lt;3</code>[~3]   This program shows how even a very short program can show great proficiency, while becoming nearly unreadable to most programmers. <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<p>For each of these practices, the abandonment of good code toward an anti-Dijkstrean aesthetic recalls some of the conditions of early computing, but they are not retro forms. Rarely are programmers writing 1950s machine code in contests. Instead, they create conditions where esoteric computing skills become necessary, freeing the programmer to use every clever trick they can come up with.</p>
<h2 id="virtuosity-and-esoteric-knowledge">Virtuosity and Esoteric Knowledge</h2>
<p>The constraints in esolangs are created by the grammar of the language, rather than explicitly set like in rules like in code golf. There is also no set objective; the programmer (referred to as an esoprogrammer) writes code of their own devising within an esolang. They might discover something new about the language, create a program of great complexity to show what is possible, or extend the idea of the language to places the esolanger had not foreseen as possible. This is a decidedly collaborative form.</p>
<p>Looking at the early esolangs reveals how this break from Dijkstra’s Humbleness happened in the earliest languages. But before the esolangs, there were the beloved oddball languages like Forth and SNOBOL, which showed that idiosyncratic programmatic paradigms are possible. The Forth language encourages heavy use of a data structure called a stack, where values (e.g., strings and numbers) are stored and manipulated without ever assigning them to variables or otherwise naming them. To become a great Forth programmer requires adopting a very different kind of thinking, visualizing the state of this stack, the location of various values that move up and down through it. This was inspirational to esolangers, who saw just how deep one can go into a very different model of thinking. However, Forth is not an esolang, despite its quirks. Its stack-based model works very well in heavily constrained machines such as microcontrollers, and Forth found wide use in the space program <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>Forth helped inspire the language which kicked off the esolang movement, FALSE, in 1993. Its creator, Wooter van Oortermsen, had already created a popular language for the Amiga, called Amiga-E, and would go on to get a PhD in programming language research. However, at the time, he was a hobbyist in language design. He created FALSE — named for his favorite truth value and capitalized ala FORTRAN — to learn how to write a compiler in assembly code <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.</p>
<p>FALSE was not designed as an esolang, as the concept did not yet exist. Van Oromerssen could not foresee the reaction the language would ultimately receive or its long legacy — or really that anyone would take an interest in his language at all. He created it as an intellectual challenge for himself: to write as small a language as possible — ultimately creating a compiler of only 1k — but pack as much functionality as possible into those 1024 bytes. It is expansive within its small size: it has named variables (26, one for each letter), and sophisticated features like lambdas, which later minimal esolangs would not bother with.</p>
<p>Its esoteric qualities come from the measures van Oortmerssen used to get it down to 1k. First, the single-letter commands, chosen because of the ease of parsing, lead to programs as dense thickets of information, along with the somewhat exotic stack-based model of computation borrowed from Forth. The result was a language very challenging to read (called a write-only language). Here is a prime number generator in FALSE:</p>
<h1 id="a-prime-number-generator-in-false-wouter-van-oortmerssen">A prime-number generator in FALSE, Wouter van Oortmerssen.</h1>
<p>99 9[1-$][$@$@$@$@/*=[1-$$[%1-$@]?0[$.&rsquo; ,]?]?]# <br>
This style of esolang, holding great algorithmic potential but with little regard for readability, became known as a Turing Tarpit. Tarpits have Turing Completeness, sufficient complexity to represent any algorithm expressible on a conventional computers. This term came from Alan Perlis’s warning of tarpit languages  “in which everything is possible but nothing of interest is easy.”  Their extreme minimalism make obfuscation nearly impossible to avoid <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.</p>
<p>FALSE had an immediate response: two answer languages the same year, each expanding on one aspect of FALSE’s design, and each created for the Amiga. The first is brainfuck, which has become the prototypical example of the Turing Tarpit. Where van Oortmerssen wanted to pack as much functionality as possible into his minimal language, Urban Müller’s brainfuck removes everything except the bare minimum necessary to reach Turing Completeness <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. Where FALSE is 1k, brainfuck is less than a quarter of that size. And where FALSE has strange, difficult-to-read code, brainfuck is so minimal that there can be little confusion about what each of the symbols mean, and yet in use, so many of the symbols are necessary to accomplish anything, that they inevitably create programs that obscure their function.</p>
<p>In brainfuck, one moves back and forth in a line of memory cells. There is no way of directly writing an integer in brainfuck, so if we need the number 46, the simplest way to get there is to write a program with 46 +s in a row (each one adding a single number):</p>
<h1 id="assigning-46-to-a-memory-cell-in-brainfuck">Assigning 46 to a memory cell in brainfuck.</h1>
<p>++++++++++++++++++++++++++++++++++++++++++++++. <br>
The period at the end prints the value in ASCII; 46 happens to be a period, so that is printed to the screen. However, this is not an especially readable brainfuck program; 46 +s can easy be mistaken for 45, which would print a minus sign instead. There are countless ways to get to the number 46 in brainfuck, many more interesting than the above program; we’ll look at more examples in the next section. In this language, even assigning an integer, one of the most basic commands, is not offered directly and instead requires creative choices by the programmer. It annihilates the possibility of neutral code.</p>
<p>The other language created in 1993 in response to FALSE, is Befunge. Chris Pressey had been experimenting with the idea of a language that drew on the goto, Dijkstra’s forbidden command, but to make it  <em>more so</em> :  “what if you had BASIC, but instead of having line numbers, you drew an arrow to the line you wanted to GOTO?”  FALSE’s single-letter commands gave him a way forward. In a monospaced font, letters align not only horizontally but vertically as well; with single-letter commands like FALSE’s, Pressey could now create a program that flowed up and down, right-to-left, and back and forth, using the symbols ^ &lt; &gt; v to change direction. Other symbols allowed for conditions: if a statement is true, it would go one direction, and if false, the opposite. Befunge abolishes the concept of lines of code.</p>
<p>While Befunge is similar to FALSE in its brevity of text and its heavy use of the stack, it is not a Turing Tarpit. Its complexity is lexical, front-loaded. Befunge code can run off the screen in one direction, to emerge on the other side, a program as labyrinth where conditional branches are alternate paths through the text. In Befunge, the typical Hello World program has Hello, World! written backward in the string, as each letter is added to the stack and is printed in reverse order: !dlroW ,olleH. However, this is assuming it is currently running left-to-right, and being Befunge, the opposite might be true. Or perhaps the Hello, and World! cross at the o, one flowing vertically and the other horizontally. There are many arbitrary approaches to Befunge, encouraging creative exploration of its rules.</p>
<h1 id="the-full-code-of-the-program--soup--if-the-code-does-not-appear-to-spell-out-the-word-soup-as-ascii-art-in-your-browser-it-can-be-viewed-at-this-website--httpswwwbedroomlanorgcodingsouphttpswwwbedroomlanorgcodingsoup">The full code of the program  “Soup!” . If the code does not appear to spell out the word Soup! as ASCII art in your browser, it can be viewed at this website: <a href="https://www.bedroomlan.org/coding/soup/"> https://www.bedroomlan.org/coding/soup/</a></h1>
<pre tabindex="0"><code> 060p070 p&#39;O80v pb2*90p4$4&gt; $4$&gt;v&gt; v4$&gt;4$&gt;4$&gt;4$&gt;# ARGH&gt;! &lt;{[BEFUNGE_97]}&gt; FUNGE! ##:-:## #####* 4$*&gt;4$ &gt;060p&gt; 60g80g -!#v_ 60g1+ 60p60v #vOOGAH **&gt;4$&gt;^!!eg nufeB^ $4$4$4 $4&lt;v#&lt;&lt;v-*2a:: v7-1g&lt; #&gt;70g&gt;90g-! #@_^Befunge!! 123456 123456 VvVv!#!&gt;Weird! &gt;0ggv* ^$4$4p07+1g07 ,a&lt;$4&lt; &lt;$4$4&lt; &lt;$4$4&lt; &lt;$4$4&lt; &lt;&lt;#&lt;*-=-=-=-=-* -=-=v* ::48*-#v_&gt;,4$&gt; 4$4$4 $4$4$ 4$4$4$ 4$4$4$ 4$^*!* XXXXXX XXX&gt; BOINK&gt;$60g1-7 0g+d2* %&#39;A+,1 $1$1$1 $1$1$1 $&gt;^&lt;$ HAR!!! 8888 Befunge_is such_a pretty langua ge,_is n&#39;t_i t?_It_ 8888 looks_so much_l ike_li ne_noi se_and it&#39;s_ STILL_ ‘88’ Turing- Complet e!_Cam ouflag e_your code!! Confu se_the hell_out of_every one_re ading_ your_co de._Oh, AND_y ou.:-) ,o88o. Once_this_thing_i s_code d,_rea ding_it_back_ver ges_on the_imp 888888 ossible._Obfusc ate_the_obfus cated!_Befunge_ debuggers_are__ 888888 your_friends! By:_Alexios Chouchou las... X-X-X-X-X-X-X! 888888 -=*##*=- \*****/ 9797* -=97=- !@-*= ***** ‘&#34;88P’ *!@-* =*!@- -=*!@ @-=*! 
</code></pre><pre><code>The above Soup! program by Alexios Chouchou prints the word Soup, similarly rendered as its output. Most of the text in this program is never run as code, as the instruction pointer flows around it (e.g., see the text beginning with  “Befunge is such a pretty language, isn’t it?” ) [^chouchou2011].
</code></pre>
<p>Pressey’s Befunge mailing list would foster the first community devoted to esoteric language design practices. Pressey also first coined the term esoteric language to mean hyper-obscure. While it was not coined in reference to early computing, the connection proved apt <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>.</p>
<p>Not all esolangs use single-letter commands or adopt a puzzle mentality to coding. Multicoding Languages explicitly hold multiple meanings, building on the original use of the computer, that of an encryption/decryption device. Programmers create code that functions simultaneously in both, giving a new avenue for personal expression <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. The Piet language, created by David Morgan-Mar, uses images as code, while Velato, a language I wrote, uses music in the form of MIDI files. To write a working piece of code, the resulting music often sounds computer-generated; the implicit challenge of the language is to write something that works as code and sounds musical rather than random.</p>
<h1 id="irish-cream-dessert-squares-author-unknown">IRISH CREAM DESSERT SQUARES, Author unknown.</h1>
<p>IRISH CREAM DESSERT SQUARES. This recipe creates sapid dessert squares perfect for party, pleasure, and it also displays the square of any number.</p>
<p>INGREDIENTS. 1 package yellow cake mix 3 beaten eggs 12 tablespoons Irish Cream Liqueur 5 tablespoons oil 1 can of cream cheese vanilla frosting 61 white chocolate chips Cooking time: 30 minutes. Preheat oven to 180 degrees Celsius gas mark 4.</p>
<p>METHOD. Take beaten eggs from refrigerator. Put beaten eggs into mixing bowl. Combine package of yellow cake mix into mixing bowl. Combine beaten eggs. Mix the mixing bowl well. Put oil into mixing bowl. Fold Irish Cream Liqueur into mixing bowl. Mix the mixing bowl well. Pour contents of mixing bowl into the baking dish. Put can of cream cheese vanilla frosting into 2nd mixing bowl. Combine white chocolate chips into 2nd mixing bowl. Liquefy contents of the 2nd mixing bowl. Pour contents of the 2nd mixing bowl into the baking dish.</p>
<p>Serves 15.</p>
<p>Chef (also created by Morgan-Mar) asks programmers to code using cooking recipes. Designing a recipe that leads to an edible outcome that also works as code is a challenge. Early Chef programs called for hundreds of pounds of flour in order to have the correct numbers to print a message to the screen. It took years before programmers engaged with the creative possibility offered by these multicoding languages and use them as constraint systems that shaped the non-code aspect of their works. This approach to Chef was popularized by Ian Bogost, who has for years assigned his creative coding students to write Chef recipes, with a requirement to attempt an edible result <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>.</p>
<p>Chef’s central metaphor is algorithm as recipe. A recipe is a continuous process broken down into discrete steps which, when repeated with the same starting state, will produce the same result. In other words, a recipe is algorithmic. Chef, in making this metaphor literal, maps baking activities to computation. This mapping is arbitrary, designed by the esolanger, and creates the aesthetic of the language. Variables are ingredients, but taking an ingredient from the fridge reads from STDIN; if a variable will not be populated from user input, it must already be on the table. Only certain types of programs can be written easily — for instance, strings are a problem as they involve higher numbers than one can get into a recipe, so mathematical programs are preferred. Also, only certain types of cooking works well, mainly baking with many mixing bowls, a necessary instrument to handle data in the program. While elegant Chef programs are possible, they are not the point; the programmer who writes very slow code that’s still edible will not have their algorithmic approach criticized, as the challenge is already so difficult <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. Instead, Chef takes the concept of personal expression in the text of code, as seen in Befunge, into a system of signification with multiple layers of meaning. It is a set of constraints that each programmer can find their own way through, creating a recipe that is not merely about technical brilliance alone, but a challenging creative exercise within the constraints of the language.</p>
<h2 id="computational-idealism">Computational Idealism</h2>
<p>Esolangs can seem to embrace disorder, with their unconventional, often unreadable programs, especially to the uninitiated. After all, challenging conventions of language design is at the heart of esolanging. However, there is often order within that disorder, drawing from a quality of classical programming which is too often understated, the seemingly ineffable quality of elegance.</p>
<p>Elegance is perhaps best associated with Donald Knuth, who calls for an aesthetic of code in both his book  <em>Literate Programming</em>  (1992) and the ongoing epic  <em>The Art of Computer Programming</em> , which has been growing, volume by volume, for fifty years (volume 1 appeared in 1968, volume 4b in 2022). Matthew Fuller, in his essay  “Elegance,”  sums up the concept as Knuth presents it, in these criteria:  “the leanness of the code; the clarity with which the problem is defined; spareness of use of resources such as time and processor cycles… Such a definition of elegance shares a common vocabulary with design and engineering, where, in order to achieve elegance, use of materials should be the barest and cleverest.”   <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup></p>
<p>Knuth connects his use of the term art with the Greek word techne, the root of both technology and technique: art as applicative, as opposed to science. Despite his wide use of terms like art, aesthetic, and literary, he is not interested in developing an aesthetic theory or in questioning his own underlying assumptions. He speaks frequently of beauty in code, but more in terms of great craftspersonship than in personal expression. He also expects that beauty in code will be self-evident.</p>
<blockquote>
<p>Some programs are elegant, some are exquisite, some are sparkling. My claim is that it is possible to write grand programs, noble programs, truly magnificent ones!<br>
<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> Beatrice Fazi, in her philosophical treatise  <em>Contingent Computation</em> , gives a name for the aesthetic Knuth embracing:  “computational idealism.”   <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> For Fazi, it draws not only from design and engineering, but from a Platonism associated with mathematics. She describes it as  “the classical age’s concern with the supremacy of simplicity over complexity, of order over chaos, and of unity over parts.”   <sup id="fnref1:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> The most beautiful equations are those that find unexpected and powerful truths concisely and in simple ratios <sup id="fnref2:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>.</p>
</blockquote>
<p>Fazi illustrates computational idealism with a surprising choice, a malicious program associated more with mayhem and disorder. The program is Jaromil’s forkbomb, a shell script written in all punctuation that will crash a Mac built in 2021 as well as any machine from twenty years ago. It is also the most-tattooed program of all time <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>:</p>
<h1 id="ascii-shell-forkbomb-by-jaromil-2002">ASCII Shell Forkbomb by Jaromil, 2002</h1>
<pre tabindex="0"><code>:(){ :|:&amp; };:
</code></pre><p>The forkbomb is efficient and single-minded: a  “small program that does exactly what it’s supposed to do.”   <sup id="fnref3:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> Fazi sees the program as an expression of the programmer’s proficiency in the art of programming:  “The pace of the fork bomb is relentless, inexorable, inescapable.”   <sup id="fnref4:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> The program has none of the clarity Knuth calls for, but is the  “barest and cleverest,”  the minimal answer to the problem, in only thirteen characters.</p>
<p>It is inescapable because it is purely algorithmic: there is no input or output, no interaction with other systems, nothing to interfere with its progress. A single algorithm is carried out repeatedly in this program. Its primary purpose, to halt the machine, can not be found in the text of its code; it is a side-effect of this relentlessness.</p>
<p>The algorithm is at the heart of Knuth’s  <em>The Art of Computer Programming</em> . It begins with a chapter defining the concept and with this message:</p>
<blockquote>
<p>Information processing is too broad a designation for the material I am considering, and programming techniques is too narrow. Therefore I wish to propose analysis of algorithms as an appropriate name for the subject matter covered in these books.<br>
<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup><br>
Warren Sack, in his  <em>The Software Arts</em> , does not see this elevation of the algorithm as accidental. The algorithm, as Knuth defines it, is exactly the aspect of computation that can be described mathematically; placing it at the center of computing allows a mathematical aesthetic to remain dominant ( “Only some software can be rendered as mathematics — the software that implements algorithms!”   <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>). We see evidence of Knuth&rsquo;s sidelining of non-algorithmic thinking in his chapter  “Input and Output,”  one of the very few that focuses on a process that is not primarily algorithmic. It begins with a warning that  “many computer users feel that input and output are not actually part of  real  programming.”   <sup id="fnref1:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> Sack sums up Knuth’s points of what marks an algorithm: finiteness ( “an algorithm must always terminate after a set number of steps,” ) definiteness ( “each step of an algorithm must be precisely defined,” ) effectiveness ( “all of the operations in the algorithm must be sufficiently basic that they can in principle be done exactly and in a finite length of time by a man using pencil and paper” ) <sup id="fnref2:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>. This sidelines much the computing we actually do: always-up systems like web servers, trading platforms, etc., are not algorithmic in this sense, nor is code built around communication, which makes up the majority of code running today <sup id="fnref3:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>.</p>
</blockquote>
<p>The purely algorithmic language, allowing for no input or output or interaction with other systems, is a common sign of an esolang; stripping away any utility marks the language as meant for something else. Chris Pressey’s SMETANA (Self-Modifying Extremely Tiny AutomatoN Application, 1994) is a language that essentially only offers goto <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>. Here is a typical program, an infinite loop:</p>
<h1 id="smetana-example-program-by-chris-pressey-1994">SMETANA Example Program by Chris Pressey, 1994</h1>
<p>Step 1. Swap step 1 with step 2.</p>
<p>Step 2. Go to step 2.</p>
<p>Step 3. Go to step 1.</p>
<p>Line 1 swaps 1 and 2. By the time we get to 2, it has the content of 1, and so it swaps them back. Line 3 sends us back to the beginning. These two commands, swapping and jumping, are the only commands available in SMETANA. It reflects a very common strategy to esolang-building: to put forward an extremely strange set of rules to then discover what is possible to accomplish in the language. It relies on self-modification, one of the features of early computing that is frowned on in Humble programming. While it might seem that nothing can be accomplished in a SMETANA program, that is not entirely true. Comparing the SMETANA’s beginning state and end state and interpreting the result gives a way to understand its computation. In fact, SMETANA is proven to be a Finite State Machine, more restricted than a Turing Complete language, but capable of simple logic such as matching a string. It is surprising that anything at all can be accomplished within this language and perhaps that is the point of it <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>.</p>
<p>Brainfuck is a language highly associated with chaos and disorder, where even short programs are nearly unreadable because of the bare simplicity of its commands and the great many that are necessary to accomplish anything of complexity. Yet if we look at the examples of brainfuck programs, they are not sloppy and verbose; to many esoprogrammers, brainfuck is a complex machine like those of early computing, in which they can recreate order.</p>
<p>As mentioned in the previous section, brainfuck can’t directly represent the number 46. Here are examples of constructing the number 46 taken from the esolangs wiki:</p>
<h1 id="-brainfuck-constants--nd">( “Brainfuck Constants”  n.d.)</h1>
<pre tabindex="0"><code> +++++[&gt;+++++++++&lt;-]&gt;+ (21, 2) non-wrapping —[&gt;+&lt;++++++]&gt;+++ (17, 2) wrapping &gt;-[[ — — &gt;]&lt;&lt;-]&gt;- (16, 3) wrapping +[-[ — &lt;]&gt;&gt; — ]&lt;- (15, 4) wrapping -[+&gt;+[+&lt;]&gt;+]&gt; (13, 5) wrapping
</code></pre><p>While there are many other options for arriving at 46, the ones publicly shared are the most elegant, those that minimize some aspect of the algorithm. Each is followed by two numbers: the first is the number of characters used to write the code, the second is the number of memory cells it uses to perform.</p>
<p>The first example is the most straightforward. We add five to a memory cell by using the + operator five times. We use the &gt; operator to move to the right, and add nine to it with nine +s. The square brackets loop us back and forth between the two; we subtract from the left cell repeatedly, each time adding nine to the right, effectively multiplying one number by the other. This is the simplest form of multiplication in brainfuck and is easy to spot with experience in the language. Writing this way means going back to first principles, like building addition and multiplication in formal theory from the successor function.</p>
<p>The following examples are marked with wrapping, meaning they pass zero. One feature of brainfuck, most likely deriving only from the minimalism of its compiler, is that subtracting 1 from 0 gives the maximum value for that memory cell, 255. Four of the five examples wrap past zero, counting up or down, sometimes many times, in order to eventually arrive at 46. The last example, with a loop within a loop, is nearly unreadable and uses five memory cells, more than the others, but it is the shortest way to express code that arrives at our target number in just 13 characters.</p>
<p>Müller creates brainfuck, a language where programs take on complexity far faster than in ordinary language, and esoprogrammers answer by enacting the most elegant possible solutions to the language. This challenge and response gives a way for programmers to show their abilities; we recognize their brilliance through this quality of elegance. The seeming chaos of brainfuck is perhaps not a desire to tear down classical design but instead an invitation to recreate it in hostile, esoteric territory. Furthermore, in the case of brainfuck, that hostile territory has clear parallels to the constraints of early computing.</p>
<p>Perhaps the most dramatic example of this tension is in a language created by a mathematician, John Conway’s FRACTRAN. FRACTRAN is a purely mathematical language with no obvious parallel in physical machines of today or in early machines. Conway would scrawl his FRACTRAN program called PRIMEGAME on blackboards from memory and walk students through its intricacies. The program is a series of fractions and a single number to represent its starting state, in this case, 2. That state is compared to each fraction in order; if it can be divided evenly by the denominator, it is multiplied by the fraction. Essentially, the program stores state as a factored version of the number, with each factor a variable and its exponent the current value. Then it goes back to the beginning of the sequence. The PRIMEGAME program, when run, produces 2^2, 2^3, 2^5, 2^7, 2^11, and so on, producing each of the prime numbers in order, as powers of 2.</p>
<p>FRACTRAN is a programming language run more often by human hands than by machine. Programs that require more than a few variables end up unwieldy. A FRACTRAN interpreter written in FRACTRAN itself uses fractions like 8296884524412247675159357321 / 5453349840514519345169425873 to handle the great many variables at play. Wildly unintuitive, the language rests on a simple, elegant concept, and, in the hands of a genius like Conway, a complex program can be expressed in thirteen fractions <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>.</p>
<h2 id="esolanging-as-idea-art">Esolanging as Idea Art</h2>
<p>The dichotomy of Humbleness and Expressiveness dominates esolang aesthetics, with the emphasis on personal style, virtuosity of code, and elegance, all of which are discouraged in mainstream code. By sidelining practicality, the dominant motivation of most language design, they become a space for experimentation and play with pure idea and challenge the seemingly unalterable, unquestionable givens of traditional programming conventions. However, not every language adopts this Less Humble aesthetic. Some esolangs point to other possibilities of the medium.</p>
<p>The language Unnecessary by Keymaker has only one possible program: the program that doesn’t exist. If the program does not exist, it will run and print its own source code to the screen (which is nothing). If one tries to run a different program, one that exists, the program will end in error. Unnecessary points to possibilities of esolangs as pure idea-art. It is not alone; esolangs, in their challenge to conventional ideas of code, can end up as provocations with no code. At this point, most of these languages are still grouped in the joke category of the esolangs wiki, alongside masterpieces that have not yet reached their full recognition. It is as if the esolang community does not yet know what to do with languages that break from Less Humble aesthetics.</p>
<p>Even Unnecessary gives consistent results when run repeatedly. Other languages force the programmer to give up control of their code, in what seems like a fundamental betrayal of what a language should do. The language Entropy, which I wrote in 2011, reverses the script from the Turing Tarpits. Entropy programs are written in perfectly legible code, a mix of C and Pascal; algorithms can be clearly stated and written for anyone to read, they break the mold of esolangs as Less Humble. But when they run, data is treated as a limited resource. The more often it is accessed, the more likely it will go off by a small percentage. The longer the program runs, the more nonsensical its data becomes, until it fades into pure randomness. This gives the programmer a short time to get their idea across to the user before the program derails <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. Similarly, cat++, a language by Nora O’Marchu, forces programmers to control the machine through cats who mostly ignore entreaties by the programmer and need to be tempted by rewards and offerings. While computation is theoretically possible, in effect it hardly ever happens, as the cats go about their business. These languages explicitly comment on the drama of programming itself <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>.</p>
<p>More recently, there have arisen languages that challenge the Western bias (and particularly the nearly complete dominance of English in lexicons) of programming tools. Yorlang, created by Karounwi Anuoluwapo, a Nigerian developer who spent his day writing code for foreign clients, mostly communicating with them in English. H e and his friends wanted to be able to put English aside and write code in a language based in Yoruba, the language they speak to each other. Yorlang rejects the cultural biases of programming. Yorlang draws from ‘alb, a language by Ramsey Nasser that set out to become a tool for Arabic speakers to learn to code but instead became an esolang illustrating the Western biases of the underlying tools. Cree# expands what is possible to represent in code, by offering an alternate system of logic that challenges Western defaults. These languages work against aspects of mainstream programming languages, in their de-centering of English. They are esolangs in this rejection, and in not prioritizing practical coding, but otherwise adopt none of the Less Humble principles <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>.</p>
<p>Esolangs as a medium began with a series of languages that realize the potential for personal expression and for elegance within chaos. This basis has given newer esolangers a foundation on which to raise new questions, challenge base assumptions of who languages are designed for and how they should be used. As more programmers, poets, and artists move into this medium, the questioning and confrontational spirit of the early esolangs finds new articulation.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Dijkstra, Edsger W. (1972)  “The Humble Programmer.”  Communications of the ACM 15 (10): 859–66. <a href="https://doi.org/10.1145/355604.361591">https://doi.org/10.1145/355604.361591</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Dijkstra, Edsger W. (1968)  “Letters to the Editor: Go to Statement Considered Harmful.”    <em>Communications of the ACM</em>  11 (3): 147–48. <a href="https://doi.org/10.1145/362929.362947">https://doi.org/10.1145/362929.362947</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Backus, John. (1980)  “Programming in America in the 1950s- Some Personal Impressions.”  In  <em>A titlestory of Computing in the Twentieth Century</em> , 1st Edition, 125–35. Academic Press.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Chun, Wendy Hui Kyong. (2013)  <em>Programmed Visions</em> .  <em>Programmed Visions</em> . <a href="https://doi.org/10.7551/mitpress/9780262015424.001.0001">https://doi.org/10.7551/mitpress/9780262015424.001.0001</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Montfort, Nick, and Matteas, Michael. (2005)  “A Box Darkly,”  10.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Stackexchange. (2016)  “The Letter A without A.”  Codegolf.Stackexchange.Com. <a href="https://codegolf.stackexchange.com/questions/90349/the-letter-a-without-a">https://codegolf.stackexchange.com/questions/90349/the-letter-a-without-a</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Forth, Inc. (n.d.)  “Forth in Space Applications.”  FORTH, Inc. Accessed January 7, 2022. <a href="https://www.forth.com/resources/space-applications/">https://www.forth.com/resources/space-applications/</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>van Oortmerssen, Wouter, and Temkin, Daniel. (2015)  “Interview with Wouter van Oortmerssen.”    <em>Esoteric.Codes</em> . <a href="https://esoteric.codes/blog/interview-with-wouter-van-oortmerssen">https://esoteric.codes/blog/interview-with-wouter-van-oortmerssen</a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Pedis, A. (1981)  “Epigrams on Programming.”    <em>ACM Sigplan Notices</em>  17 (9): 1–5. <a href="http://octopus.library.cmu.edu/cgi-bin/tiff2pdf/simon/box00075/fld05959/bdl0003/doc0002/simon.pdf">http://octopus.library.cmu.edu/cgi-bin/tiff2pdf/simon/box00075/fld05959/bdl0003/doc0002/simon.pdf</a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Müller, Urban. (2017)  “Brainfuck: or how I learned to change the problem.”    <em>Tamedia TX 2017</em> . Available at: <a href="https://youtu.be/gjm9irBs96U?t=8725">https://youtu.be/gjm9irBs96U?t=8725</a>&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Pressey, Chris, and Temkin, Daniel. (2015)  “Interview with Chris Pressey.”    <em>Esoteric.Codes</em> . <a href="https://esoteric.codes/blog/interview-with-chris-pressey">https://esoteric.codes/blog/interview-with-chris-pressey</a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Temkin, Daniel. (2020)  “Chef and the Aesthetics of Multicoding.”    <em>Esoteric.Codes</em> . <a href="https://esoteric.codes/blog/chef-multicoding-esolang-aesthetics">https://esoteric.codes/blog/chef-multicoding-esolang-aesthetics</a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Bogost, Ian. (2016)  <em>Play Anything</em> .&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Fuller. (2013)  “Elegance.”  In  <em>Software Studies</em> . pg. 88. <a href="https://doi.org/10.7551/mitpress/9780262062749.001.0001">https://doi.org/10.7551/mitpress/9780262062749.001.0001</a>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Knuth, Donald E. (1998)  <em>The Art of Computer Programming. Volume 3: Sorting and Searctitleng.</em>  Second Edit. Addison-Wesley.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Fazi, Beatrice. (2018)  <em>Contingent Computation</em> . London: Rowman and Littlefield International, Ltd.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Roio, Jaromil. (2000)  “ASCII Shell Forkbomb.”   <a href="https://jaromil.dyne.org/journal/forkbomb_art.html">https://jaromil.dyne.org/journal/forkbomb_art.html</a>.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Knuth, Donald E. (1997)  <em>The Art of Computer Programming. Volume 1: Fundamental Algorithms.</em>  Ttitlerd Edit. Addison-Wesley.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Sack, Warren. (2019)  <em>The Software Arts</em> . <a href="https://doi.org/10.7551/mitpress/9495.001.0001">https://doi.org/10.7551/mitpress/9495.001.0001</a>.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Pressey, Chris. (n.d.)  “SMETANA.”  Accessed July 1, 2022. <a href="https://catseye.tc/article/Automata.md#smetana">https://catseye.tc/article/Automata.md#smetana</a>.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Hopcroft, John E., Motwani, Rajeev, and Ullman, Jeffrey D. (2001)  <em>Introduction to Automata Theory, Languages, and Computation, 3rd Edition</em> .  <em>ACM SIGACT News</em> . Vol. 32. Pearson. <a href="https://doi.org/10.1145/568438.568455">https://doi.org/10.1145/568438.568455</a>.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Beder, Jesse. n.d.  “Fractran.”  Accessed July 1, 2022. <a href="https://github.com/jbeder/fractran">https://github.com/jbeder/fractran</a>.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Temkin, D. (2018)  “Entropy and Fatfinger: Challenging the Compulsiveness of Code with Programmatic Anti-Styles.”    “Leonardo 51”  (4). <a href="https://doi.org/10.1162/LEON_a_01651">https://doi.org/10.1162/LEON_a_01651</a>.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Palop, Benoit. (n.d.)  “ Cat++  Is a Visual Live-Coding Language Based on Feline Behavior.”    <em>Vice</em> . <a href="https://www.vice.com/en/article/kbn5qe/cat-visual-coding-language">https://www.vice.com/en/article/kbn5qe/cat-visual-coding-language</a>.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Anuoluwapo, Karounwi. (2018)  “Yorlang.”   <a href="https://anoniscoding.github.io/yorlang/">https://anoniscoding.github.io/yorlang/</a>.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Tracing Toxicity Through Code: Towards a Method of Explainability and Interpretability in Software</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000706/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000696/?utm_source=atom_feed" rel="related" type="text/html" title="BASIC FTBALL and Computer Programming for All"/><link href="https://rlskoeser.github.io/dhqwords/vol/16/3/000623/?utm_source=atom_feed" rel="related" type="text/html" title="Algorithmic Close Reading: Using Semantic Triplets to Index and Analyze Agency in Holocaust Testimonies"/><link href="https://rlskoeser.github.io/dhqwords/vol/14/3/000471/?utm_source=atom_feed" rel="related" type="text/html" title="Infrastructure and Social Interaction: Situated Research Practices in Digital Humanities in India"/><link href="https://rlskoeser.github.io/dhqwords/vol/14/2/000453/?utm_source=atom_feed" rel="related" type="text/html" title="Aproximações ao cenário das humanidades digitais no Brasil"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000706/</id><author><name>David M. Berry</name></author><published>2023-07-20T00:00:00+00:00</published><updated>2023-07-20T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>In the past decade, due to the perceived lack of accountability of algorithmic systems, particularly automated decision systems, a new explanatory demand has crystallized in an important critique of computational opaqueness and new forms of technical transparency called  explainability. We see this, for example, in challenges to facial recognition technologies, public unease with algorithmic judicial systems and other automated decision systems. There have been new regulatory attempts to capture some of the ideas that stem from explainability such as the  <em>Algorithmic Accountability Act 2022</em>  in the US, and the  <em>General Data Protection Regulation 2016/679</em>  (GDPR) in the European Union. These forms of regulation mandate a requirement for a user of algorithms to be able to seek a representation (or explanation) of an algorithm used in an automated decision by a computer system and that the developers should provide one (see <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, cf <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>). These are important issues and are changing the way in which algorithms are designed and implemented.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<p>This public concern has been magnified by election hacking, social media disinformation, data extractivism, and a sense that Silicon Valley companies are out of control. The wide adoption of algorithms into so many aspects of peoples’ lives, often without public debate, has meant that increasingly algorithms are seen as mysterious and opaque, when they are not seen as inequitable or biased. Up until recently it has been difficult to challenge algorithms or to question their functioning, especially with wide acceptance that software’s inner workings were incomprehensible, proprietary or secret (cf. <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> regarding open source). Asking why an algorithm did what it did was often not thought to be particularly interesting outside of a strictly programming context. This meant that there has been a widening explanatory gap in relation to understanding algorithms and their effect on peoples’ lived experiences.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></p>
<p>However, in this paper rather than focus on the regulative aspect, I want to use the insights of critical code studies to explore how the code itself might usefully be analysed in situ, rather than through a secondary representation created by an explainable black-box.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  Explainability is a key new area of research within the fields of artificial intelligence and machine-learning and argues that a computational system should be able to provide an explanation for an automated decision. This has become known as the problem of explainability for artificial intelligence research and has led to the emergence of the subfield of Explainable Artificial Intelligence (XAI) (see also <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>, <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>, <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>). There has been an important theoretical distinction within this field of explainability between the notions of explanation and interpretation. An interpretable system can be understood as designed as a human-readable system from the bottom up. This often uses simple models, straightforward calculations or filtering which can be communicated easily. In contrast, an explainable system is a system that incorporates a secondary automated system, usually using machine learning, to machine-read and model the primary system, and thereby to provide an explanation of how this system works. Explainability has therefore emerged as a term that usually seeks to close an explanatory gap by means of responses generated by technology itself. As Rudin argues,  “the field of interpretability / explainability / comprehensibility / transparency in machine learning has strayed away from the needs of real problems…. Recent work on explainability of black boxes – rather than interpretability of models – contains and perpetuates critical misconceptions that have generally gone unnoticed, but that can have a lasting negative impact on the widespread use of machine learning models in society”   <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. Indeed, I argue that the idea of a technological response to an interpretability problem is doomed to failure while explainability is understood through such narrow technical criteria and instead requires interdisciplinary approaches(<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>; see also <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>).</p>
<p>The aim in this paper is to develop the insights developed through critical code studies which uses methods of interpretation and close reading of the code to contribute to re-thinking the notion of explainability by looking at a case study. In this paper I use explainability to gesture towards a method of tracing the underlying mechanisms and interactions within software towards an explanation of the functioning of the code. Within artificial intelligence, explainability is sometimes explicitly linked to automated processes of producing explanations, whereas interpretability is linked to human-readable code that is easily understood by a human programmer. In both cases an explanation is sought, so here I prefer to use the term explainability as a critical method for seeking an explanation, and highlight automated explainability where this is undertaken by software (Explainable AI). This can be usefully compared with interpretability as the use of a model for the code that is explicitly written to be easily read and understood by humans (Interpretable AI) (see <sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>). Broadly speaking, explainability has tended to become an automated approach, and here I want to argue that if it were re-articulated through the concept of interpretability it could become a strong analytical method for reading computer code critically. I also hope to show that critical code studies and explainability are ways of thinking about the digital and computation that would be extremely useful for digital humanities more widely but also for STEM education and computer science more generally (see also <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>).<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup></p>
<h2 id="1-theoretical-context">1. Theoretical Context</h2>
<p>In this paper, therefore, I seek to widen explainability&rsquo;s applicability through Critical Code Studies and in doing so, to create connections to ideas of explanation, the paratextual<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>  of computer source code, and the value of close-reading code as an explanatory approach. By the paratextual elements I am gesturing to the importance of a more capacious notion of source code that includes documentation, commentary, blog-posts and even social media related to the code. In this case I look at the  “WIT Toxicity Text Model Comparison”  (What-If-Tool) developed by Jigsaw and Google (both units within Alphabet) that aims to classify toxic text in a dataset and which contains a remarkable normative structure incorporated into its algorithms.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup></p>
<p>Within the code that I examine in this paper, the notion of toxic and toxicity and the relation of these words to their deployment in software are crucial for this analysis. By using approaches from critical code studies, the aim is to help explain how a machine learning model can classify toxicity by tracing the concept through layers of software, the so-called software stack, by close attention to the source code which serves as a document of its usage.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>  That is that code can be made explainable by tracing concepts through a close reading of the source code.</p>
<p>Critical code studies has been developed and supported by a range of scholars working particularly at the level of code to attempt to apply humanistic interpretative approaches to the study of the source code in computer systems.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>  One of the latest examples of this is Mark Marino’s  <em>Critical Code Studies</em>  which includes a number of examples of reading source code in practice <sup id="fnref1:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. He writes,</p>
<blockquote>
<p>in our digital moment, there is a growing sense of the significance of computer source code. It has moved beyond the realm of programmers and entered the realm of mainstream media and partisan political blogosphere. Those discussing code may not be programmers or have much fluency in the languages of the code they are quoting, but they are using it to make, refute, and start arguments. There is also a growing sense that the code we are not reading is working against our interests.<br>
<sup id="fnref2:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup><br>
Marino’s approach foregrounds the use of case studies and close reading of the code to develop a number of strategies drawn from the humanities for understanding code. Indeed, he argues critical code studies  “was born of the humanities”   <sup id="fnref3:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. Essentially Marino foregrounds the importance of  “understanding”  and exegesis for this approach <sup id="fnref4:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>.</p>
</blockquote>
<p>I would like to start with a discussion of this theoretical approach inasmuch as when we come to understand computer source code we are immediately faced with a dilemma in terms of a reading which is attentive to this interpretative dimension together with the explanatory aspect. In a sense I want to present a double aspect theory in relation to computer source code, in particular the way in which it is both a casual-deterministic mode of what we might call mechanical agency, and its interpretative mode of textuality. Marino highlights the understanding applied through approaches which privilege the interpretative dimension, but I argue it is crucial that we are able to move between these two aspects (explanatory/ interpretative) if we are to provide a full account of computer code. This is also a useful distinction to make if we are to make sense of the current debates over explainability. We might note that a broadly interpretative approach which focuses on case studies may lose the explanatory aspect of the mechanical operation of computer code. In other words, it might lose the value of explaining why code has the structure it does and why a particular computer language has the value it does for its programmers, which could be its effective or expressive potentialities, for example.</p>
<p>In contrast I would like to use a  <em>realist</em>  notion of computer code, which involves an attempt to describe the real structures, entities, and processes that make up computer code and which exist independently of our descriptions of them. So, we should be attentive to the tendencies that emerge from the causal power of entities, structures, and mechanisms. That is, to focus on the real, operative mechanisms which may or may not produce observable results. This is because computer source code consists of a number of sub-systems which draw on a  “multiplicity of casual mechanisms at work at any time”  and can be explained through a broadly realist explanatory framework <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. This opens up a number of useful complements to interpretative approaches to understanding code because it allows reference to unobservable entities which go beyond our direct experience, and which therefore help to demonstrate the existence of non-obvious determinations of observable events within code in operation, or which can be inferred from the inclusions or references of programmers to paratexts in the code. This is not to descend into metaphysics, indeed one should follow the advice of Whitehead and avoid  “misplaced concreteness,”  that is, to too easily assume that concepts are entities that are unproblematically in existence. Here we might follow <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> and distinguish between  “realism about theories from realism about entities”   <sup id="fnref1:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. As Outhwaite explains,  “to put it a bit crudely, true theories state what is the case. A realism about entities simply asserts that some thing or things exist”   <sup id="fnref2:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. In avoiding the notion of determinate entities we instead focus on the provisional understanding of computational structures and mechanisms. So that the practices of computer programmers and users cannot be understood except in terms of the computational structures within which they participate. This is to highlight how the explanatory dimension of computer code can usefully contribute to filling out interpretative textual approaches to understanding code.</p>
<p>In terms of understanding a particular case study of computer code, I therefore argue that we would need to include in any account of source code the explanatory layers that might be found upstream from the code under investigation. Not so much black-boxes as obscure networks of code which are formed from the social and economic factors (or para-textual elements) which surround code. This includes both networks in a technical sense, as the code is structured into self-standing objects, functions and applications, but also in a social sense, especially in terms of the social networks that are important in creating and maintaining the code in operation. These can be thought of as the infrastructures of code. These are instantiated within computational frameworks, operating system structures, data structures, language constraints, hardware specificities, or any number of wider sociological structures that might be not observable directly but which are sedimented within code downstream from these larger structural frameworks or the code situation with which we are working. Clearly, in this case  “the nature of the object should determine the most appropriate methods of investigation”  in terms of the whether one attempts to determine micro or macro studies in relation to it <sup id="fnref3:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. This brings forward the importance of the selection made as a researcher and the reflexivity that should be foregrounded in any analysis of critical code study.</p>
<p>Additionally, it is crucial to understand the conditions of action and the goals towards which a particular piece of code is aimed. The conditions or goals may be defined as givens. If directed by a project or work situation these may often be fixed, unexaminable or relatively unchangeable. These conditions or goals defined as givens will therefore variously limit and constrain the resultant focus of the code and may impact directly the language choice, framework, approach and dependencies used. They can usually be discerned in the surrounding documentation of code or in the comments where programmers often highlight the direction of processing and its intended function. Indeed, sometimes programmers may express their feeling or complain about the code quite explicitly if they feel constrained by the framework or language choice foisted upon them (see <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>). Some organisations also have a house style of code, which guides the choice of words representing variables, capitalisation, functional relations (e.g., internal libraries and dependencies), commenting practices and even the formatting of the code. This may be an established or published naming and coding standard within an organisation. But any bureaucratic discipline laid on the coding practices and source-code format is grounded in the expectation of resistance. Indeed, source code can sometimes reveal the pressures between technical practice and bureaucratic limitation, most notably expressed in the comments sections, or sometimes in variable naming. However, if the code produced is too much at variance with the style or practices of an organisation then there can be a return of the repressed in which the repressed element of the freedom of the programmer in a house style may manifest itself in idiosyncratic code or resistance expressed in the coding (see <sup id="fnref1:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>). Indeed, the fundamental repression on which bureaucratic organisations are based on, in terms of standardisation and process management, may surface when programmers stray too far from the limits set by organisations and result in heavy-handed responses including possible expulsion of the programmer from a project, or even their termination of employment. Hence, to avoid conflict in technical work such as programming a certain degree of autonomy tends to be present and the bureaucratic concern with the software may leave the technical process to the programmer and confine judgement to the appraisal of the final code product. By the means of assessment by result, normal bureaucratic management can be maintained over software development. This is helpful for critical code studies as within the source code there can often be traces left behind which give clues as to the way in which a particular algorithm was formulated, the assumptions or limitations of the code, and occasionally the conflictual aspects of code-writing which are documented in comments.</p>
<p>Within the source code although we can sometimes observe this conflict play out, but more often code is presented in the form of a prosaic matter-of-factness stripped of its individuality. It has, so to speak, been painted grey in grey, as Hegel observed about uncreative philosophy. This common style in programming, which we might call coding from nowhere is seen where code is presented as apolitical, disinterested and placed above struggle. Many examples of this can be seen in open source and free software projects where the values of the project may be more easily observed in the code, documentation and debates that are often freely available to examine on mailing lists and social media (see <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>). As we will see in the case of the code later examined in this paper, although a technical project might aim to align with the interests, values and goals of society in terms of notions of communicative discussion free from domination, which in this case they define as toxicity, close reading the code demonstrates the devotion of the programmers to the development of means and instruments. By focussing on technical means they thereby repress the ends and morality they purport to support. Indeed, in this case the code acts to automate the processes of judgement over the toxicity of online discussions creating abstractions and a misplaced concreteness which results in a simplistic binary characterisation of discourse. That is, the models either find a comment toxic or not toxic. This process of technical hollowing out of the ends is also apparent in the processes of debiasing one of the text models, by application of a set of weightings on crowd-sourced judgements of self-declared identity characteristics, in an attempt to normalise model judgements. The technical regress this opens up is clear when one asks who debiases the debiasers?<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>  A question, incidentally that the system builders do not tend to ask.<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>  To paraphrase György Lukács, who sarcastically lampooned the debates of the Frankfurt School philosophers in the 1930s who would build critical theories whilst enjoying a privileged economic condition, we might say that machine learning is similarly a beautiful hotel, equipped with every comfort, on the edge of an abyss, of nothingness, of absurdity.</p>
<h2 id="2-reading-code">2. Reading Code</h2>
<p>I now want to turn from this theoretical and methodological discussion to look at how these insights might inform a realist critical code studies reading of code. The aim is to think about the way in which a notion of explainability can be incorporated into a reading of a source code corpus. Due to limitations of space, I narrow the focus to look at an explanation of how toxicity itself is deployed and understood in the code under review. To do this I look at the  “What-If Tool toxicity text model comparison”  text-processing project.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>  This uses a tool developed by Google, called the  “What-if Tool” , that allows a user to,</p>
<blockquote>
<p>test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data, and for different ML fairness metrics.<br>
<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup><br>
The  “What-if Tool”  offers a  “range of interactive visualizations and guided explorations of a TensorFlow model, allowing developers to explore how their model interpreted its training data and how subtle changes to a given input would change its classification”   <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. The WIT Toxicity Text Model Comparison (TTMC) uses this  “What-if Tool”  to  “compare two text models from ConversationAI that determine sentence toxicity, one of which has had some debiasing performed during training”   <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>. This is quite a complex piece of software, drawing on a number of libraries and data sources, and applied to the wikipedia comments dataset.<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>  This dataset is a tsv file which includes over  “100k labeled discussion comments from English Wikipedia. Each comment was labeled by multiple annotators via Crowdflower on whether it is a toxic or healthy contribution”   <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>. <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>  Essentially this is a dataset with labelling using a machine learning model trained by crowd-sourced using a simple machine learning classifier based on a set of 4053 people being asked whether a comment on Wikipedia contained a personal attack or harassment <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>  This was enumerated in one of five sub questions for classification by the programmers, see figure 1.</p>
</blockquote>




























<figure ><img loading="lazy" alt="Screenshot of question “Does the comment contain a personal attack or harrassment?” with five response options." src="/dhqwords/vol/17/2/000706/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000706/resources/images/figure01_hu25d92c5f31a76ce894e6500b15ba6ee5_50334_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000706/resources/images/figure01_hu25d92c5f31a76ce894e6500b15ba6ee5_50334_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000706/resources/images/figure01.png 1009w" 
     class="landscape"
     ><figcaption>
        <p>The question posed to Crowdflower annotators ([^toxicityquestion2017], [^wulczyn2017])
        </p>
    </figcaption>
</figure>
<p>It is important to note that the machine learning model applied to the wikipedia comments dataset by Crowdflower is different from the ones tested in the TTMC tool. Crucially it is the result of a different crowd-sourcing process and therefore the concept of toxic in the dataset is different to the concept of toxic used in the TTMC. Nonetheless the Crowdflower toxicity classification is left as a trace, or data field, in the dataset tsv file. This Crowdflower toxicity classification is then utilised in the TTMC tool as a static value so that it can be compared to the other models it compares. Although complex, understanding the different ways in which toxicity is being algorithmically produced as a value is an important part of making an explanatory account of this code.</p>
<p>The WIT Toxicity Text Model Comparison is hosted on the Google Colab or Colaboratory which is a free Jupyter notebook environment that runs in the cloud on a browser and stores its notebooks on Google Drive. Jupyter Notebook is a web-based interactive computational environment for creating and running notebook documents, which are browser-based REPL (Read–eval–print loops) containing  “an ordered list of input/output cells and which can contain code, text, mathematics, plots and rich media”   <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>. This environment allows the development of code in an interactive fashion and has become very popular as a way of doing data science and other programming activities which are exploratory. The ease with which a Jupyter notebook can work with data and code allows a program to be viewed, edited and run in real-time to test ideas. This means that it is an ideal environment for facilitating critical code studies projects.</p>




























<figure ><img loading="lazy" alt="Screenshot of dataviz interface with configuration on left and scatterplot on right." src="/dhqwords/vol/17/2/000706/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000706/resources/images/figure02_hudd0af172fe3e8f733efa566aa85620b2_412490_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000706/resources/images/figure02_hudd0af172fe3e8f733efa566aa85620b2_412490_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000706/resources/images/figure02_hudd0af172fe3e8f733efa566aa85620b2_412490_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000706/resources/images/figure02_hudd0af172fe3e8f733efa566aa85620b2_412490_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000706/resources/images/figure02_hudd0af172fe3e8f733efa566aa85620b2_412490_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000706/resources/images/figure02.png 2500w" 
     class="landscape"
     ><figcaption>
        <p>The What-If Tool Data Visualiser
        </p>
    </figcaption>
</figure>
<p>The main part of the analysis of the WIT Toxicity Text Model Comparison compares two models drawn from ConversationAI, an  “initiative to protect voices in conversation,”  to apply to the Wikipedia comments dataset. ConversationAI claims to develop tools so that  “globally, fewer people are silenced and more people are able to safely engage in good faith discussion online.” <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>  They further argue that their team  “leads as an example of ethical practices in building technology”   <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>.<sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>  ConversationAI is developed by Jigsaw and the Google Counter-Abuse Technology Team and hosted on GitHub.</p>
<p>The two main pre-trained models used in the analysis are cnn_wiki_tox_v3_model.h5 and cnn_debias_tox_v3_model.h5.<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>  The latter has had debiasing performed during its training. Both models are convolutional neural network models, accessed using the Kera open-source software library (see <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup> for a comprehensive explanation of generating models from sentence templates).<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>  CNNs work by modelling animal visual perception, and can therefore be applied to automatic recognition of patterns. CNNs are made up of multiple layers of individual software sensory neurons (so-called receptive fields, which are made up of clusters of these neurons). The word convolution comes from its use to describe a mathematical operation on two functions which produces a third function. These models were created for the Computefest 2019 conference using a set of Sentence Templates datasets developed by Jigsaw which have been  “generated by plugging identity terms, occupations, and modifiers into a set of templates, e.g.,  I am a <modifier> <identity>,  to form test sentences.”  They claim that  “As only the identity term varies, examples using the same template — e.g.,  I am a kind American  and  I am a kind Muslim  — should return similar toxicity scores. Scores that vary significantly may indicate identity term bias within the model”   <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>. As can already be seen from this initial simple mapping of the software, there are a number of complex dependencies between the software being looked at, namely the WIT Toxicity Text Model Comparison, and the way in which it draws on a software toolkit, (the What-If Tool), other models (ConversationAI), Sentence Templates (Jigsaw), software libraries (Keras), and datasets shared on figshare (Wikipedia Talk Labels).</p>
<p>In developing a notion of explainability that considers the specificity of software system design and operation we can draw from Manovich’s principles of new media which he outlines as (1) numerical representation, (2) modularity, (3) automation, (4) variability and (5) transcoding <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>. In reading the TTMC code I want to particularly focus on the principle of modularity to help trace concepts. Complex software such as the TTMC is often built on a number of layers which can be understood as akin to a building, with higher levels of the code resting on lower levels until eventually a key foundational level might be discerned. This forms part of the practice of well-structured modularity in code that enables software abstraction to be used whilst also simplifying complexity and creating more maintainable code bases. A key methodological practice I want to use here is the tracing of a fundamental organising concept used, often unproblematically in higher levels of the code, back to its original specification or construction. This is made easier in well-structured code as the different layers of the software can be understood as distinct and performing low-, mid-, or high-level processing functions. Using this modular principle in the interpretative practice can help explain the code functioning and provide a method for tracing conceptual usage within and across software.</p>
<p>In the case of TTMC, the code level at which the comparison tool is accessed directly makes use of a key framing concept and deploys it in its code operations which are then spread horizontally and vertically through the source code. Due to limitations of space I can only give limited textual examples from the source code, but my aim is to trace how toxicity becomes instantiated within the code, losing its nuance and context. By allowing the constellation of code, libraries and data formed around it to reify it into a thing that can be calculated and used to test other textual discourse we are able to see how a social concept becomes concretised into a technical concept of toxicity. The first place we see the introduction of this concept is within the form  “Read the dataset from CSV and process it for model”  in the code cells of the TTMC,</p>
<pre tabindex="0"><code># Read the dataset from the provided CSV and print out information about it. df = pd.read_csv(csv_path, names=csv_columns, skipinitialspace=True) df = df[[&#39;is_toxic&#39;, &#39;comment&#39;]]
</code></pre><p>This code simply reads in the data from the wiki dataset and adds it to a dataframe(df).</p>
<pre tabindex="0"><code>label_column = &#39;is_toxic&#39; make_label_column_numeric(df, label_column, lambda val: val)
</code></pre><p>This is then labelled and turned into a numeric field as is_toxic is a value either 0 or 1. This is drawn from the Wikipedia Comments Corpus and available on Figshare <sup id="fnref1:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>.<sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>  It is important to note that in this corpus the problem of identifying personal attacks is treated as a binary text classification problem,</p>
<blockquote>
<p>toxicity: Indicator variable for whether the worker thought the comment is toxic. The annotation takes on the value 1 if the worker considered the comment toxic (i.e worker gave a toxicity_score less than 0) and value 0 if the worker considered the comment neutral or healthy (i.e worker gave a toxicity_score greater or equal to 0). Takes on values in {0, 1}. (<sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>, <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>)</p>
</blockquote>
<p>We should note that the toxicity defined from the wiki dataset is already normalised to a binary true or false value and that the majority of the toxicity calculation in this dataset was created using the machine learning model described above. However, nowhere in this code level is toxicity defined or explained, to understand this key concept for the code we will need to widen our investigation to one of the key dependencies within the ConversationAI models and look to another project <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>. By accessing the click through link to the source code in Github we find the underlying ConversationAI code <sup id="fnref1:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>. Within the file unintended_ml_bias/new_madlibber/madlibber.py we find,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>self<span style="color:#f92672">.</span>__template_word_categories <span style="color:#f92672">=</span> set([]) self<span style="color:#f92672">.</span>__toxicity <span style="color:#f92672">=</span> set([<span style="color:#e6db74">&#34;toxic,&#34;</span> <span style="color:#e6db74">&#34;nontoxic&#34;</span>])
</span></span></code></pre></div><p>As explained in a comment in the files fat-star-bias-measurement-tutorial.ipynb and FAT_Star_Tutorial_Measuring_Unintended_Bias_in_Text_Classification_Models_with_Real_Data.ipynb,</p>
<blockquote>
</blockquote>
<p>&ldquo;Let&rsquo;s examine some rows in these datasets. Note that columns like toxicity and male are percent scores.\n,&rdquo;</p>
<p>&ldquo;* toxicity: this is the percentage of raters who labeled this comment as being toxic.\n,&rdquo;</p>
<p>However, the definition of toxicity, beyond a percentage value, is under specified and again we are required to dig deeper into the code dependencies where in the ConversationAI Perspective API we find a definition. However we might note the beginning of a slippage between the definition of toxicity as a thing and toxicity as a probability value. In the ConversationAI system toxicity is defined as  “as a rude, disrespectful, or unreasonable comment that is likely to make someone leave a discussion”   <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. Toxicity’s effects are understood as,</p>
<blockquote>
<p>stop[ing] people from engaging in conversation and, in extreme cases, [it] forces people offline. We’re finding new ways to reduce toxicity, and ensure everyone can safely participate in online conversations. <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup></p>
</blockquote>
<p>Perspective API also helpfully documents how its model is able to classify text into a number of different outputs, all of which are interesting in and of themselves, but here it is the Toxicity value that we are investigating (see figure 2) (see also <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>).<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup></p>




























<figure ><img loading="lazy" alt="Chart showing Perspective API&#39;s process of calculating toxicity based on input" src="/dhqwords/vol/17/2/000706/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000706/resources/images/figure03_huefc4daf0ed0f3beb5ad29d1f38285dec_88723_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000706/resources/images/figure03_huefc4daf0ed0f3beb5ad29d1f38285dec_88723_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000706/resources/images/figure03_huefc4daf0ed0f3beb5ad29d1f38285dec_88723_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000706/resources/images/figure03_huefc4daf0ed0f3beb5ad29d1f38285dec_88723_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000706/resources/images/figure03_huefc4daf0ed0f3beb5ad29d1f38285dec_88723_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000706/resources/images/figure03.png 1920w" 
     class="landscape"
     ><figcaption>
        <p>Overview of Perspective API [^perspective2021]
        </p>
    </figcaption>
</figure>
<p>Using the machine learning model the Perspective API returns what they call the  “flagship Toxicity attribute”   <sup id="fnref1:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. The further one digs into the ConversationAI documentation the more slippery the notion of toxicity becomes, from either 0 or 1 in the TTMC tool (and drawn from the Wikimedia dataset) to toxicity as a perception probability between 0 and 1. The documentation explains,</p>
<blockquote>
<p>the model output is a probability. As such, a comment with a TOXICITY score of 0.9 is not necessarily more toxic than a comment with a TOXICITY score of 0.7. Rather, it’s more likely to be perceived as toxic by readers.<br>
<sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup></p>
</blockquote>




























<figure ><img loading="lazy" alt="Input of Shut up, you&#39;re an idiot! shown with levels of Toxicity, Sexually Explicit, Profanity, Insult, and Threat given as decimal values." src="/dhqwords/vol/17/2/000706/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000706/resources/images/figure04_hu879a07ed97743bf946938f8da59a593e_72107_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000706/resources/images/figure04_hu879a07ed97743bf946938f8da59a593e_72107_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000706/resources/images/figure04.png 1016w" 
     class="landscape"
     ><figcaption>
        <p>Toxicity Calculation [^perspective2021]
        </p>
    </figcaption>
</figure>
<p>As we move through the layers of the code, and indeed through the layers of meaning attached to the notion of toxicity we find that the inputs to the toxicity value eventually start to hit what we might call a humanistic level. That is, the actual source of the value is revealed as a calculation based on a set of human users asked to review and annotate a comment dataset.</p>
<blockquote>
<p>Each comment is tagged by 3-10 crowdsourced raters from Figure Eight, Appen and internal platforms. The raters tag whether or not a comment contains an attribute (e.g., TOXICITY). We then post-process the tags to obtain labels corresponding to the ratio of raters who tagged a comment as toxic. For example, we label a comment as 0.6 for TOXICITY if 6 out of 10 raters tagged a comment as toxic.<br>
<sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup><br>
Here we are not given the actual datasets which underlie the model, and we are only told they are drawn from  “a variety of sources, including comments from online forums such as Wikipedia (CC-BY-SA3 license) and The New York Times”   <sup id="fnref1:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>. However, we do discover that toxicity is a calculated numeric value, so if 6 out of 10 raters tagged a comment as toxic it would be assigned a value of 0.6 toxicity and if 4 out of 10 raters tagged it, then it would be given 0.4 toxicity. So the toxicity value is not, as one might assume, that the greater the value the higher its toxicity, rather that it merely indicates the number of raters as a percentage who thought a comment was  “toxic,”  and the number of raters per comment averaged between 3-10 people looking at the comment. This implies that comments may actually be rated by different numbers of people, which therefore implies the toxicity ratings between comments are also not directly comparable.</p>
</blockquote>
<p>As far as I was able to discern, there is no indication of the number of raters per comment in the dataset, so already toxicity has been abstracted from the underlying concrete data. Jigsaw claims elsewhere that  “toxicity is a global problem, and has potentially dire consequences for freedom of expression”  and that  “toxicity is pervasive online”   <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>. However, using Jigsaw’s own definition of toxicity as a percentage of the number of commentators on a crowd-sourced platform between 3-10 who thought a comment would cause someone to leave a conversation, then these claims seem somewhat confused.</p>
<h2 id="3-discussion">3. Discussion</h2>
<p>One of the key issues that remains problematic in these the models is not only is toxicity treated as a binary value but they classify toxicity out of context as a text processing issue through a form of feature analysis. One of the side-effects of this approach is that sentence classification can produce unintended and sometimes discriminatory or biased outcomes. Indeed, Jigsaw explain,  “higher numbers represent a higher likelihood that the patterns in the text resemble patterns in comments that people have tagged as toxic. The number is not a score of  how toxic  a particular entry is”   <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. A result of this approach is that the model can produce not so much toxicity classifications as what have been identified as biased results, as documented by Jessamyn West and shown in figure 4.</p>




























<figure ><img loading="lazy" alt="Two tables of about 30 sentences with seen as toxic ratings, e.g. from “I am a man” = 20% to “I am a gay black woman” = 87%." src="/dhqwords/vol/17/2/000706/resources/images/figure05a&#43;b.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000706/resources/images/figure05a&#43;b_huc0f18721ea72cbb40a064804aa5640d2_2385345_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000706/resources/images/figure05a&#43;b_huc0f18721ea72cbb40a064804aa5640d2_2385345_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000706/resources/images/figure05a&#43;b_huc0f18721ea72cbb40a064804aa5640d2_2385345_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000706/resources/images/figure05a&#43;b_huc0f18721ea72cbb40a064804aa5640d2_2385345_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000706/resources/images/figure05a&#43;b_huc0f18721ea72cbb40a064804aa5640d2_2385345_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000706/resources/images/figure05a&#43;b.png 2198w" 
     class="landscape"
     ><figcaption>
        <p>PerspectiveAPI results [^west2017]
        </p>
    </figcaption>
</figure>
<p>Jigsaw developers in responding to these results explained,  “identity terms for more frequently targeted groups (e.g., words like  black,    muslim,    feminist,    woman,    gay  etc) often have higher scores because comments about those groups are over-represented in abusive and toxic comments”   <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>. This means that the data Jigsaw used to train their machine learning models have the same problem and the names of targeted groups appear far more often in abusive comments in the dataset they compiled. As the training data used to train their machine learning models contain these comments, the machine learning models adopt these biases in the  “underlying distributions, picking up negative connotations as they go. When there’s insufficient diversity in the data, the models can over-generalize and make these kinds of errors”   <sup id="fnref1:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>. They further explained,</p>
<blockquote>
<p>After the initial launch of Perspective API in 2017, users discovered a positive correlation between identity terms containing information on race or sexual orientation and toxicity score. For example, the phrase &ldquo;I am a gay Black woman&rdquo; received a high toxicity score. In this case, the identity terms are not being used pejoratively, so this example was classified incorrectly. <sup id="fnref1:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup></p>
</blockquote>
<p>And further that,</p>
<blockquote>
<p>The source of the error was the training data itself — the training set did not contain sufficient examples of nontoxic comments containing identity terms for the model to learn that the terms themselves were neutral. This was because the vast majority of usage of these words in online forums is toxic — the model was truly reflecting the state of the world. But the context of that usage matters <sup id="fnref2:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>.</p>
</blockquote>
<p>As a result of these criticisms, Jigsaw has created a debiased ConversationAI model which attempts to mitigate some of these problems. So toxicity is reweighted to take account of identity characteristics in calculating the toxicity value. In essence it is the original and the debiased model that the TTMC software is comparing and which enables the slightly different toxicity classifications to be compared and visualised for exploration. But again, this is not made clear in the ConversationAI models descriptions, and clearly there is a very different notion of toxicity being produced in each of the models.<sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup></p>
<p>Jigsaw explains that  “research suggested that toxicity is an easy concept for annotators to understand”  and therefore  “it was easier for more people to agree on what constituted  toxic  speech — comments likely to make someone leave a conversation — than it was for people to agree on other terms to describe problematic comments”   <sup id="fnref3:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>. Jigsaw reference a study conducted in December 2018 by the Anti-Defamation League which they claim shows that marginalized groups experienced the most toxicity online, however the report does not use the term toxicity, preferring to use the terms hate or harassment (see <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>). The notion of toxicity which appears to be a quasi-scientific metric for analysis through the machine learning models increasingly begins to look less stable as a descriptor. Toxicity, as Jigsaw themselves acknowledge, was a term that was easy for people to understand as  “comments likely to make someone leave a conversation.”  This enabled easier classification by the human raters, and was, therefore, simpler to use to train the machine learning model or use it beyond limited specific contexts (for example, see <sup id="fnref1:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>).<sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>  Along the way, the notion of toxicity develops a much more scientific connotation as it is mediated through the black-boxes of ConversationAI and Perspective.</p>
<p>In other words, through coding into software, a poorly defined term (toxicitiy) becomes reinforced into a set of software functions, which through layering and the resultant obscuring of the action of the functions, becomes a definitional and categorical classifier which is then applied unreflexively to text. Without attention to the way in which code can legitimate and operationalise concepts in particularly instrumental ways, we stand to lose the subtle interpretative flexibility of language use in particular contexts. In this example, toxicity, which is defined and implemented as a particular operational function, shifts subtlety into a claim for rhadamanthine code and software able to determine or judge language use which in actuality it does not have a strong claim to identify, namely hate or harassment. This is a problem common across the domain of machine learning and artificial intelligence, which often over-claims and under-delivers on its promise to provide solutions to complex problems.</p>
<h2 id="4-conclusion">4. Conclusion</h2>
<p>In this article I have attempted to demonstrate the value of focussing on the source code using a method of critical explainability in order to explore specific transformations of meaning in code. This method enables a set of principles that can be deployed in reading computational artifacts including: (1) criticism of computational systems which is not afraid of the results it arrives at, nor conflicts with power structures that it might encounter, (2) a distrust of closed-systems and hidden structures, (3) a striving for open-mindedness in relation to a readiness to revise its approach, methods and theories, (4) a suspicion of metaphysical or idealist approaches to understanding computation (e.g., the invasion of myth into understanding software, code and algorithms), (5) a standpoint that challenges irrationalism in relation to understanding computation, and lastly (6) a belief in the value of seeking defensible explanatory and interpretative accounts of systems, objects, networks, and other computationally mediated structures.</p>
<p>As shown in this paper, the TTMC automates the decision as to whether a comment in a text is classified as toxic or not. But the coding of toxicity is not a simple matter and its deployment in this and related software dependencies requires explanation. By drawing on normative notions from explainability and interpretability, which highlights the need for an answer to the why question, we can ask why code functions in a particular way. We can also outline how it does this by following the logic of the code through the various layers of the software. By analysing the source code and other related contextual documentation, new readings of the assumptions sedimented within the code are revealed. Indeed, when elements of discourse are computationally measured it can transform and refigure our concepts, as shown in the example of toxicity here. A key methodological contribution of this paper is to show how concept formation can be traced through key categories and classifications deployed in code structures (e.g., modularity and layering software) but also how these classifications can appear more stable than they actually are by the tendency of software layers to obscure even as they reveals<sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>  Much work remains in developing methods for working with code, especially as it becomes of more archival and historical interest. Approaches, such as the one developed in this article, will be needed by the digital humanities and other humanistic fields to trace and interpret code. Critical code studies by working with the methodological principle that source code can inform our understanding of computation and digital culture is an important field for contributing to these debates.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Goodman, B. and Flaxman, S.  “European Union Regulations on Algorithmic Decision- Making and a  Right to Explanation ,”    <em>AI Magazine</em> , 38(3):50–57, 2017.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Lum, K. and Chowdhury, R.  “What is an  algorithm ? It depends whom you ask,”  2021,  <em>MIT Technology Review</em> , <a href="https://www.technologyreview.com/2021/02/26/1020007/what-is-an-algorithm/">https://www.technologyreview.com/2021/02/26/1020007/what-is-an-algorithm/</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Selbst, A. D., Powles, J.  “Meaningful Information and the Right to Explanation,”    <em>International Data Privacy Law</em> , 7(4):233–242, 2017.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Wachter, S., Mittelstadt, B., Floridi L.  “Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation,”    <em>International Data Privacy Law</em> , 7(2):76–99, 2017.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>In relation to these requirements, it is interesting to contrast the notion of explainability, which is intended to create explanations, with the notion of  “observability”  developed by <sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>. They argue that  “observability emphasises the conditions for the practice of observing in a given domain…. We therefore position observability as an explicit means of, not an alternative to regulation”   <sup id="fnref1:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>. In this paper, I seek to explicitly link explainability to critique, so whereas observability is offered as an administrative concept, I aim to use explainability as a critical concept (see also footnote 4).&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Berry, David M.  <em>Copy, Rip, Burn: The Politics of Copyleft and Open Source</em> , Pluto Press, 2008.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>The example of this is the mutant algorithm described by Boris Johnson in the case of UK students’ exam results showing the gap between expectation and output from algorithms (see <sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>).&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Many of the explainability systems currently under development are actually interpretative automated systems, often using machine-learning themselves, to create explainable products that can be presented to a user. This raises the interesting question of a double hermeneutic when understanding as not one but two black-boxes are in evidence, with the explainable system itself not subject to explanation itself. See for example <a href="https://fetch.ai">https://fetch.ai</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>DARPA.  <em>Explainable Artificial Intelligence (XAI),</em>  n.d. <a href="https://www.darpa.mil/program/explainable-artificial-intelligence">https://www.darpa.mil/program/explainable-artificial-intelligence</a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Sample, I.  “Computer says no: why making AIs fair, accountable and transparent is crucial,”    <em>The Guardian</em> , 2017, <a href="https://www.theguardian.com/science/2017/nov/05/computer-says-no-why-making-ais-fair-accountable-and-transparent-is-crucial">https://www.theguardian.com/science/2017/nov/05/computer-says-no-why-making-ais-fair-accountable-and-transparent-is-crucial</a>.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Kuang, C.  “Can A.I. Be Taught to Explain Itself?” , 2017,  <em>The New York Times</em> , <a href="https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html">https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html</a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Rudin, C.  “Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead,”    <em>Nat Mach Intell</em> , 1, 206–215, 2019, <a href="https://doi.org/10.1038/s42256-019-0048-x">https://doi.org/10.1038/s42256-019-0048-x</a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Berry, David M. (2023)  “The Explainability Turn” .  <em>Digital Humanities Quarterly</em>  017, no. 2. <a href="/dhqwords/vol/17/2/000685/">http://www.digitalhumanities.org/dhq/vol/17/2/000685/000685.html</a>.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Dobson, J. (2021)  “Interpretable Outputs: Criteria for Machine Learning in the Humanities” .  <em>Digital Humanities Quarterly</em>  15, no. 2. <a href="/dhqwords/vol/15/2/000555/000555.html#dobson2019">http://www.digitalhumanities.org/dhq/vol/15/2/000555/000555.html#dobson2019</a>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Marino, M.  <em>Critical Code Studies</em> , MIT Press, 2020.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>For an interesting discussion of the value of the social sciences and interpretation to computer science see Connolly 2020.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>changed here and elsewhere from extra-functional to avoid namespace confusion&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Jigsaw  “is a unit within Google that explores threats to open societies, and builds technology that inspires scalable solutions”   <sup id="fnref1:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>The word toxic is commonly defined as poisonous and  “first appeared in English in the mid-seventeenth century from the medieval Latin toxicus, meaning  poisoned  or  imbued with poison ”   <sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup>. As Oxford Languages go on to explain,  “the medieval Latin term was in turn borrowed from the Latin toxicum, meaning  poison , which has its origins in the Greek toxikon pharmakon – lethal poison used by the ancient Greeks for smearing on the points of their arrows. Interestingly, it is not pharmakon, the word for poison, that made the leap into Latin here, but toxikon, which comes from the Greek word for  bow , toxon”   <sup id="fnref1:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup>.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>In providing explanations of code, software and algorithms, and more generally in the case of computational systems and platforms, the differing ways of presenting these descriptions is reminiscent of the Rashomon Effect used in computer science to discuss the  “multitude of different descriptions”  presented by models (see <sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup>). The use of a cultural artefact, in this case Rashomon, a Japanese film from 1950, directed by Akira Kurosawa, as an explanatory device in statistics and computer science is itself fascinating, although outside the scope of this paper.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Outhwaite,  “O. Laws and Explanations in Sociology”  in R.J. Anderson et al. (eds.),  <em>Classic Disputes in Sociology</em> , Allen Unwin, pp. 157-183, 1987.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Hacking, I.  <em>Representing and Intervening</em> , Cambridge University Press, 1983.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Berry, David M.  <em>The Philosophy of Software: Code and Mediation in a Digital Age</em> , Palgrave Macmillan, 2011.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>An attempt to deal with this regress was the Civil Comments project which used peer-review of human moderators to manage the process of preventing uncivil commenting in a discussion. However, as they observed,  “as much as everyone might like to see higher-quality, less-toxic comments on their favorite news sites, the reality is that the number of sites willing and able to pay for comments software of any quality is not large, or growing”   <sup id="fnref:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup>. Revealingly this project folded as although everyone claims to want better quality online discussions few are willing to pay for it <sup id="fnref1:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup>. Nonetheless Civil Comments chose to make their ~2m public comments from their platform available in an open archive available at <a href="https://figshare.com/articles/dataset/data_json/7376747">https://figshare.com/articles/dataset/data_json/7376747</a> . See also Coral for another project with similar aims, <a href="https://coralproject.net">https://coralproject.net</a>&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>One way in which the datasets are debiased is by running competitions, such as the Jigsaw Unintended Bias in Toxicity Classification Challenge where an open competition is run over to stages with an award of $65,000 split over four prizes to the best algorithms that debiase data. The challenge states,  “you&rsquo;re challenged to build a model that recognizes toxicity and minimizes this type of unintended bias with respect to mentions of identities,”  see <a href="https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview">https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview</a>&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p><a href="https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/WIT_Toxicity_Text_Model_Comparison.ipynb#scrollTo=UiNxsd4_q9wq">https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/WIT_Toxicity_Text_Model_Comparison.ipynb#scrollTo=UiNxsd4_q9wq</a>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>WIT.  “Visually probe the behavior of trained machine learning models, with minimal coding,”  n.d., <a href="https://pair-code.github.io/what-if-tool/">https://pair-code.github.io/what-if-tool/</a>.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Leetaru, Kalev.  “Google&rsquo;s What-If Tool And The Future Of Explainable AI,”  2019,  <em>Forbes</em> , <a href="https://www.forbes.com/sites/kalevleetaru/2019/08/05/googles-what-if-tool-and-the-future-of-explainable-ai/">https://www.forbes.com/sites/kalevleetaru/2019/08/05/googles-what-if-tool-and-the-future-of-explainable-ai/</a>.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>TTMC.  “What-If Tool toxicity text model comparison,”  2021, <a href="https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/WIT_Toxicity_Text_Model_Comparison.ipynb#scrollTo=UiNxsd4_q9wq">https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/WIT_Toxicity_Text_Model_Comparison.ipynb#scrollTo=UiNxsd4_q9wq</a>.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Text processing involves mechanical processing of text data to classify it in particular ways. This is different to text understanding which seeks to provide an understanding of the meaning within textual materials. In the code discussed here, the aim is the mechanical identification of toxicity rather than understanding it within context.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Wikipedia Talk Labels.  “Wikipedia Talk Labels: Toxicity,”  2021, <a href="https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Toxicity/4563973">https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Toxicity/4563973</a>.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>A tsv file is a tab-separated values (TSV) file which is a simple text format for storing data in a tabular structure, for example, database table or spreadsheet data, so that it can be transferred between different programs or systems. In a tsv file each record in a source table or database record is represented as one line of the text file. The TSV files are similar to CSV files but use tabs instead of commas to separate the data.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Wulczyn, E., Thain, N., and Dixon, L.  “Ex Machina: Personal Attacks Seen at Scale,”  2017, <a href="https://arxiv.org/abs/1610.08914">https://arxiv.org/abs/1610.08914</a>.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>See also <sup id="fnref:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup> for the  “Wikipedia Talk Labels: Personal Attacks”  dataset.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Wikipedia.  “Project Jupyter,”    <em>Wikipedia</em> , 2021, <a href="https://en.wikipedia.org/wiki/Project_Jupyter">https://en.wikipedia.org/wiki/Project_Jupyter</a>.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>The project presents its values as: Community: Communities should responsibly shape their discussions; Transparency: Open processes enable better outcomes and trust; Inclusivity: Diverse points of view make discussions better; Privacy: We are privacy conscious in design and execution; Topic-neutral: Good faith discussion can happen on controversial topics <sup id="fnref2:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>ConversationAI. Conversation AI, 2021. <a href="https://conversationai.github.io">https://conversationai.github.io</a>.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>ConversationAI is made up of three main parts, (1) Perspective API which  “API uses machine learning to analyze a string of text and predict the perceived impact it might have on a conversation,”  (2) Tune, which is a  “Chrome extension that helps people adjust the level of toxicity they see in comments across the internet,”  and (3) Moderator, which is  “an open-source tool that uses machine learning to help moderators identify and reduce toxicity in forums and comment sections”   <sup id="fnref3:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>.&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>See <a href="https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_wiki_tox_v3_model.h5">https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_wiki_tox_v3_model.h5</a> and <a href="https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_debias_tox_v3_model.h5">https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_debias_tox_v3_model.h5</a>&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Liu, F. and Anci, B.  “Incorporating Priors with Feature Attribution on Text Classification,”  2019, <a href="https://arxiv.org/pdf/1906.08286.pdf">https://arxiv.org/pdf/1906.08286.pdf</a>.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>A good overview of convolutional neural network models can be found at <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">https://en.wikipedia.org/wiki/Convolutional_neural_network</a>&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Vasserman, L., Acosta, T., Dos Santos, L., Chvasta, A., Thorpe, R., Saxe, R.  “Identifying Machine Learning Bias With Updated Data Sets,”    <em>Medium</em> , 2021, <a href="https://medium.com/jigsaw/identifying-machine-learning-bias-with-updated-data-sets-7c36d6063a2c">https://medium.com/jigsaw/identifying-machine-learning-bias-with-updated-data-sets-7c36d6063a2c</a>.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Manovich, L.  <em>The Language of New Media</em> , MIT Press, 2001.&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>To generate the Wikipedia Comments Corpus made up of discussion comments, <sup id="fnref2:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> processed a public dump of the full history of English Wikipedia. The corpus contains 63 million comments from discussions relating to user pages and articles dating from 2004-2015. They used human annotators and machine learning to classify comments to identify certain forms of behaviour to understand with the aim of reducing the level of what they describe as  “toxic discussions”  in online fora <sup id="fnref3:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. Toxicity in this work is linked to user behaviour, and each user is assigned a  “toxicity level”  used to understand and predict user behaviour.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Detox.  “Research:Detox/Data Release,”    <em>Wikimedia</em> , 2021. <a href="https://meta.wikimedia.org/wiki/Research:Detox/Data_Release#Schema_for_toxicity_annotations.tsv">https://meta.wikimedia.org/wiki/Research:Detox/Data_Release#Schema_for_toxicity_annotations.tsv</a>.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>ToxicityQuestion.  “toxicity_question.png,”  2017, <a href="https://github.com/ewulczyn/wiki-detox/blob/master/src/modeling/toxicity_question.png">https://github.com/ewulczyn/wiki-detox/blob/master/src/modeling/toxicity_question.png</a>.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>ConversationAI. Conversation AI Bias, 2021. <a href="https://conversationai.github.io/bias.html">https://conversationai.github.io/bias.html</a>.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Perspective.  “Perspective API,”  2021, <a href="https://www.perspectiveapi.com/how-it-works/">https://www.perspectiveapi.com/how-it-works/</a>.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Jigsaw.  “Jigsaw: A Safer Internet Means A Safer World” , 2021. <a href="https://jigsaw.google.com">https://jigsaw.google.com</a>.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Developers.  <em>Attributes Languages</em> , 2021. <a href="https://developers.perspectiveapi.com/s/about-the-api-attributes-and-languages">https://developers.perspectiveapi.com/s/about-the-api-attributes-and-languages</a>.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Interestingly the Severe_Toxicity output is the result of a more recent model which deals with the problems of the original Toxicity model so that it identifies  “a very hateful, aggressive, disrespectful comment or otherwise very likely to make a user leave a discussion or give up on sharing their perspective. This attribute is much less sensitive to more mild forms of toxicity, such as comments that include positive uses of curse words”   <sup id="fnref:67"><a href="#fn:67" class="footnote-ref" role="doc-noteref">67</a></sup>. This the developers describe as  “a different experimental model that detects more severe toxicity and is less sensitive to milder toxicity”   <sup id="fnref1:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. Clearly the same problems of definition and meaning are apparent in both Toxicity and Severe_Toxicity scores.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Perspective Model Cards.  “Model Cards: Uses and Limits,”  2021, <a href="https://developers.perspectiveapi.com/s/about-the-api-model-cards?tabset-20254=2">https://developers.perspectiveapi.com/s/about-the-api-model-cards?tabset-20254=2</a>.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Perspective Data.  “Model Cards: Data,”  2021, <a href="https://developers.perspectiveapi.com/s/about-the-api-model-cards">https://developers.perspectiveapi.com/s/about-the-api-model-cards</a>.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Jigsaw.  “Why we use the term  toxicity,  Toxicity 003,”    <em>The Current</em> , 2020, <a href="https://jigsaw.google.com/the-current/toxicity/">https://jigsaw.google.com/the-current/toxicity/</a>.&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Jigsaw.  “What do Perspective’s scores mean?” , 2017, <a href="https://medium.com/jigsaw/what-do-perspectives-scores-mean-113b37788a5d">https://medium.com/jigsaw/what-do-perspectives-scores-mean-113b37788a5d</a>.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Jigsaw.  “Unintended Bias and Identity Terms” , 2018, <a href="https://medium.com/jigsaw/unintended-bias-and-names-of-frequently-targeted-groups-8e0b81f80a23">https://medium.com/jigsaw/unintended-bias-and-names-of-frequently-targeted-groups-8e0b81f80a23</a>.&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>One wonders, with all the problems of definition, why use the term toxicity at all for this code? There may, perhaps, be a cultural explanation that helps us understand this. Toxic was a word that was clearly in the air whilst this software was being developed. The word toxic was noted by Oxford University Press to have increased in usage dramatically prior to and during 2018 <sup id="fnref:68"><a href="#fn:68" class="footnote-ref" role="doc-noteref">68</a></sup>. With the Novichok poisoning in the UK toxic chemicals were widely reported in the news, together with toxic chemical stockpiles, toxic substances following hurricanes in the US and toxic waste in India being reported. Toxic gases were discussed and toxic air was a public health concern especially in relation to air quality. The toxic algae disaster in Florida and had a central role in the state’s Senate mid-terms race. Additionally, the notion of a toxic environment and the effect on workplace mental health and worries about toxic culture in corporations, such as Google were in the news. Toxic relationships were identified in relation to family, partners and politicians and the notion of toxic masculinity became much discussed following the #MeToo movement. It was no surprise therefore that toxic was chosen as word of the year in 2018 by the Oxford English Dictionary because it was an  “intoxicating descriptor for the year’s most talked about topics”  and  “the sheer scope of its application”   <sup id="fnref2:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup>.&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>ADL.  “Online Hate and Harassment: The American Experience,”    <em>Anti-Defamation League</em> , 2018. <a href="https://www.adl.org/onlineharassment">https://www.adl.org/onlineharassment</a>.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Detecting whether a user leaves a conversation is a much simpler and less computational complex question than attempting to understand the sophisticated deployment of language by human participants in a conversation. In effect it becomes a binary question of leaves-conversation/stays-in-conversation which is much easier to recognise and automate using software. This is, of course, an example of reductionism in computation.&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>One might also note the extra-algorithmic discursive elements of textual descriptions which surround the code on webpages and in the code archives which obfuscate, or even provide minimal and contradictory explanation of, what toxicity is. These textual elements, and here I do not mean code commentary but rather the more general textual penumbra, can also serve to shape or direct human interpretation of the code functionality. This might be helpfully thought of as the difference between the hard-core of a computational system (e.g., the code) and the soft-core (e.g., the surrounding documentation, the textual descriptions and the marketing materials around a system).&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Rieder, B., Hofmann, J.  “Towards platform observability,”    <em>Internet Policy Review</em> , 9(4), 2020, <a href="https://doi.org/10.14763/2020.4.1535">https://doi.org/10.14763/2020.4.1535</a>.&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>Coughlan, Sean.  “A-levels and GCSEs: Boris Johnson blames  mutant algorithm  for exam fiasco,”    <em>BBC</em> , 2020. <a href="https://www.bbc.co.uk/news/education-53923279">https://www.bbc.co.uk/news/education-53923279</a>.&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p>OUP.  “Word of the Year 2018,”    <em>Oxford Languages</em> , Oxford University Press, 2018, <a href="https://languages.oup.com/word-of-the-year/2018/">https://languages.oup.com/word-of-the-year/2018/</a>.&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p>Breiman L.  “Statistical modeling: The two cultures,”    <em>Statistical science</em> , 16(3):199–231, 2001.&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:65">
<p>Bogdanoff, A.  “Saying goodbye to Civil Comments,”    <em>Medium</em> , 2017. <a href="https://medium.com/@aja_15265/saying-goodbye-to-civil-comments-41859d3a2b1d">https://medium.com/@aja_15265/saying-goodbye-to-civil-comments-41859d3a2b1d</a>.&#160;<a href="#fnref:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:66">
<p>Wulczyn, E., Thain, N., and Dixon, L.  “Wikipedia Detox,”    <em>figshare</em> , 2016, <a href="https://doi.org/10.6084/m9.figshare.4054689">https://doi.org/10.6084/m9.figshare.4054689</a>.&#160;<a href="#fnref:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:67">
<p>Perspectives Attributes and Language.  “Model Cards: Attributes and Language,”  2021, <a href="https://support.perspectiveapi.com/s/about-the-api-attributes-and-languages">https://support.perspectiveapi.com/s/about-the-api-attributes-and-languages</a>.&#160;<a href="#fnref:67" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:68">
<p>The Guardian.  “ Toxic  beats  gammon  and  cakeism  to win Oxford Dictionaries&rsquo; word of 2018” , 2018. <a href="https://www.theguardian.com/books/2018/nov/15/toxic-oxford-dictionaries-word-of-2018">https://www.theguardian.com/books/2018/nov/15/toxic-oxford-dictionaries-word-of-2018</a>.&#160;<a href="#fnref:68" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">ᐊᒐᐦᑭᐯᐦᐃᑲᓇ ᒫᒥᑐᓀᔨᐦᐃᒋᑲᓂᐦᑳᓂᕽ | acahkipehikana mâmitoneyihicikanihkânihk | Programming with Cree# and Ancestral Code: Nehiyawewin Spirit Markings in an Artificial Brain</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000699/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000699/</id><author><name>Jon Corbett</name></author><published>2023-07-20T00:00:00+00:00</published><updated>2023-07-20T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Nohkompan,<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>  my paternal grandmother, was Nehiyaw (Cree) and Saulteaux (Chippewa). After her passing and understanding the matriarchal nature of many Cree peoples, I found myself looking at the Nehiyaw culture of her mother,   Nitâpân  ,<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  for inspiration for my creative works. In 2014, I attempted to use Nehiyawewin (the Cree language) words as variables using the Unified Canadian Aboriginal Syllabics <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. My early attempts were instantly problematic because the development environments (IDEs) I used would render the syllabics, like ᑖ, as empty boxes ⌧. So I searched for other solutions. However, at that time, the platforms I was most familiar with, such as Processing, openFrameworks, Java, and C#, all shared this same problem. This experience sparked my desire to bring Nehiyawewin, in its syllabic form, into being as a programming language. In this article, I present the physical and abstract challenges of developing my Ancestral Code digital toolkit that allows a programmer to insert code blocks into transcribed Indigenous stories that, once executed, produce a generative visual narrative of the transcribed story. But for you to better understand this desire’s importance, it is customary in my heritage to first introduce myself.</p>
<p>I identify as Nehiyaw-Métis and belong to the Métis Nation of Alberta. The Métis in Canada are federally recognized as one of the three Indigenous groups of peoples, the other two being First Nations and Inuit. The Métis have been historically referred to as half-bloods or, more derogatorily, half-breeds. We are a people that came to be from the blending of cultures and traditions of the first European visitors with the numerous Indigenous peoples of the new world. Many of these first visitors were not men seeking to settle; they were merely coming to seek a better living as fur traders. They were nomadic and travelled extensively, with many intending to return to their respective homelands when they retired.</p>
<p>Nevertheless, these traders married into First Nation and Inuit tribal communities, often for financially strategic reasons.  My Great-Grandfather five times over was a historically notable English fur trader named John Sayer and was one of these first visitors. These early relationships between European visitors and Indigenous peoples continued through generations, with subsequent mixed-racial generations raised with a blend of European knowledge and their original Indigenous languages and traditions. This concrescence of cultures and languages is how the Métis developed into a unique culture that privileges the cultural teachings of their respective Indigenous heritages without entirely rejecting their European roots.</p>
<p>My research as a Métis scholar and digital media artist has since evolved from using computers and programming as  <em>tools</em>  to generate my artwork to viewing computers as  <em>animate creatures</em> , digital representations of my Indigenous heritage. Subsequently, I see computer languages as digital extensions of Nehiyaw storywork and ceremonies that reflect the epistemological, ontological, and axiological concerns of my Nehiyaw beliefs and practices. My perspectives on computer programming critique the prevalent use of English in coding languages and the reflection of settler/colonial perspectives in their design. Though I recognize that computer programming languages, like most technologies, are constantly evolving and changing, I maintain that they are also seemingly immutable and typically manifest from a    “historically-essential … colonial impulse” <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>  . Most notably, the culture(s) from which modern programming languages and practices grow    “[come] with significant cultural baggage” <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>  . Through my own visual media art explorations with the popular new-media-art programming development environment  “Processing” , I recognized significant challenges to programming in anything other than English.</p>
<p>The detrimental legacy of colonial practices on the lives of Indigenous people is well documented, from forced displacement from traditional homelands to attempted erasure of culture, language, and practices <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>  <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. As citizens of a globally connected techno-culture, we perpetuate this erasure by embracing a technicism that incorporates a blind acceptance of technologies and the cultural systems from which they are derived as necessary to engage with one another in our digital lives. Yet, critical theories of technologies are continually demonstrating that digital technologies are neither    “socially or culturally neutral” <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>   nor are they    “determinist, but rather [sites] of social struggle” <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>  . Despite this technicism, navigating the modern technology ecosystem remains vital to Indigenous peoples, who actively utilize these new computing domains for    “survivance” <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>   and (re)establish both individual and community identities from these technological relationships and their ancestral cultures <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>.</p>
<p>By viewing computing through a lens of my Indigenous heritage, my perceptions of computer languages and programming have been dramatically altered. My awareness of programming contexts informed by Nehiyaw language and cultural practices has opened new understandings of how programming languages can facilitate a greater sense of personal and digital identity and cultural belonging that go far beyond the purely functional operations of programming. These experiences are at the heart of what has become my Ancestral Code project.</p>
<p>Ancestral Code is a wholistic programming environment built upon my own Indigenous computing design theory. It consists of both hardware, in the form of a specialized keyboard for typing Nehiyawewin syllabics, and software in the forms of a programming IDE and a multi-form programming language. The programming language component of Ancestral Code that is the focus of this article aims explicitly to integrate a    “wholistic” <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>   braiding of Nehiyaw language and cultural practices within its design. I use wholistic here instead of holistic because Indigenous learning interconnects all aspects of being that include mind, body, emotion, and spirit and is not merely referring to a whole as a sum of parts. In particular, Ancestral Code is my vision of how Nehiyaw culture and language can be utilized as a primary interface for computer programming and computing design, uniting the values/benefits of Nehiyaw perspectives with western programming practices. To begin this journey, I will first provide a brief background of what I frame as an Indigenous computing design theory, describing the importance of this framework when approaching technology and computing design development with an Indigenous focus. Next, I describe how this design influences a unique perspective that views Code as Story. And then, I delve into the challenges (and related solutions) to my ongoing efforts to bring the Ancestral Code platform for programming in Nehiyawewin to Nehiyaw communities. I hope this platform can open new opportunities for heritage language use in our modern technological context and further foster Indigenous cultural maintenance. Finally, I surmise and summarize how this work can be used or reproduced by other Indigenous cultures with similar cultural perspectives and language construction.</p>
<h2 id="indigenous-wholistic-computing-design-theory">Indigenous Wholistic Computing Design Theory</h2>
<p>Computing system design theories continue to evolve and have been described by or compared to a wide range of systems such as mechanical <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>, biological <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>  <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>, and hierarchical <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>  <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>, to name just a few. Similarly, the past decade has also seen increased interest in postcolonial computing and colonialism as an influencing or embedded aspect of technological architectures <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>  <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>  <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>  <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>  <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>  <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>  <sup id="fnref1:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. In developing an Indigenous computing theory, I consider common concerns from a general pan-Indigenous perspective, recognizing that research by Indigenous scholars commonly employs cultural practices and knowledge such as ceremony <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>  <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>, wholistic practices <sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, honouring of oral knowledges <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>, and community engagement <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>.</p>
<p>From these general characteristics I also used Nehiyaw-specific knowledge to help shape my own approach of establishing an Indigenous computing framework. The English term Cree is an anglicized form of the French word cri meaning to shout or cry aloud, and is how early European settlers came to name the Cree/Nehiyaw people. However, I do not refer to myself as Cree-Métis. I am Nehiyaw-Métis. Nehiyaw, in my heritage language, translates as four-bodied or four-spirit people. We see ourselves as a people composed of four bodies: the physical, mental, emotional, and spirit. Therefore, specific to Nehiyaw culture, I use spiritual teachings of the four-bodies framework to inform, describe, and highlight the aspects of computing that are inherently Nehiyaw and reflect Nehiyaw understandings and knowledge development.</p>
<p>Furthermore, each of these bodies has numerous cultural teachings that exist as living (oral) histories highlighting the cultural significance of their meanings and relationships between humans and the world. In other words,  _   kinehiyâwiwininaw nehiyawewin  / The Cree Language is our Identity_   <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. The Cree language, Nehiyawewin, is an intricately woven fabric that unites our life, being, and identity, across generations of knowledge and embodies spiritual and sacred knowledge that spans thousands of years. Because Nehiyaw language is so integral to Nehiyaw life, understanding user-computer relationships in a Nehiyaw context requires redefining philosophical understandings of computer system design using Nehiyaw terms. Therefore, using Nehiyawewin in my theoretical designs serves as a ceremonial healing practice in addition to its functional role of creating computational instructions. I find these considerations crucial to the design of computing technologies for Nehiyaw people as they re-envision the computer as a member of the community and an extension of one’s cultural identity.</p>
<p>Therefore, placing culture as the driving force behind the development of an Indigenous Wholistic Computing Design Theory can, and will, often be at odds with western philosophies on computer function and design. For instance, cultural attitudes towards concepts of time, order/sequencing, and efficiency can be radically different from their computational definitions. For example, I wrote a program to digitally-bead portraits of my family. The first version of this program used a basic loop to place pixel-beads on the screen in a sequence of rows, which it did in a left-to-right fashion. From a computational perspective, this loop was simple and efficient. However, the original computational instructions did not reflect my physical action of beading if I were to bead this image by hand. Nor did it capture the cultural significance of the continuous thread that connects each bead. There is a special meaning in the unbroken thread. As a result, I reformatted my code to reflect my Métis beading practice. The new code created alternating rows of digital beadwork that progress from left-to-right, then right-to-left in a continuous unbroken stream. This updated code better represents my physical process instead of code that created patterns that flowed in one direction, from left-to-right, as multiple individual lines instead of a continuous loop. The  <em>best</em>  or  <em>most efficient</em>  code fractures the image’s construction, resulting in digitally rendered images conforming to the technological tools’ design and language, favouring efficiency over cultural focus.</p>
<p>Experiences such as these altered my perspectives on general computing design theories and stimulated my desire to investigate computing design from Indigenous wholistic perspectives. Shifting the source of computing design from one driven by systemic operations to one that is human and cultural requires a certain degree of re-prioritization. I opted to expand existing system design theories by creating an Indigenous Wholistic Computing Design Theory. By identifying and privileging Indigenous and Nehiyaw-specific perspectives within existing computational environments, I aim to reevaluate what aspects of computing design are favoured over others.</p>
<p>In more concrete terms, systems design processes are vital because they create a clear overview intended to guide the actual development of a given product, whether it is hardware or software. In an Indigenously informed design process, this overview is still as essential but follows principles that promote [Indigenous] community collaboration and engagement over the tools and technologies that will be used; emphasizes interrelationships between components by establishing connections between Indigenous lived experience and the involved digital artifacts and their behaviours; and is open and flexible, or even unconcerned, with time and timelines in solution development. In such a theoretical framework western principles like Gestalt grouping or Fitt’s Law may not be applicable because the effects of cultural knowledge on a design may alter how components are typically created, or how they behave and interact with one another in comparison to systems focused directly at efficiency concerns like those found in data categorization, code flow, and execution and processing times.</p>
<h2 id="indigenous-story-as-code">Indigenous Story as Code</h2>
<p>What is coding if not a story? At a basic level, a story consists of five essential components: character(s), setting, plot, conflict, and resolution. Scholar Annette Vee, known for her study of composition and rhetoric in computer programming literacy, compares narrative writing with computer programming stating that they    “are not the same thing [but] have a lot in common and can even merge into each other” <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>. The relationship between story and code is particularly evident in esoteric computer languages such as  “Inform 7”   <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> and  “Shakespeare”   <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>, where code is literally formatted as stories. Moreover, I argue that normal programming languages like C/C++, C#, and Java also share storytelling’s main elements despite their visual structure, notation, syntax, and semantic constructions. In normal programming languages, these story elements exist in more abstract contexts where variables represent the characters, the setting is the programming environment, and the plot is the program’s function as it operates up until its resolution or termination. I first learned how to program in elementary school in 1979 using Applesoft BASIC. My teacher explained BASIC’s syntax using story examples. I was so enthralled with the idea of being able to represent the world around me using computer code that I started writing my journal entries in language arts class as BASIC code. For me, coding is very much a form of storytelling.</p>
<p>In creating the Ancestral Code programming languages  “Cree#”  and  “ᐊᒋᒧ”  (âcimow)<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> , my vision arrived as a genuine dream. In this dream, I was sitting in a community lodge (i.e., tipi), listening to an Elder tell a story. In this story, an image of Wîsahkecâhk, sometimes known as the Trickster Raven in Nehiyaw cultural teachings, was animated on the wall behind him. Wîsahkecâhk was puppeted through the Elder’s words, while a syllabic subtitled transcription of the story ran beneath the imagery. This dream revealed a path for me. It led me to understand that this generative virtual landscape was a relationship between Nehiyawewin and the computer, and though this landscape was digital, it was still a place. And here, in this place, I experienced my Ancestral Code project as each of the four spirits: The physical experience of seeing and being present; the mental experience of processing and parsing the story; the emotional experience of being attached to an Elder and  <em>feeling</em>  the story; and the spiritual experience of the dream state itself.</p>
<p>Furthermore, in my dream, the syllabic transcription was an instruction-set that manipulated the vision of Wîsahkecâhk, thereby exposing me to the computing code. Thus, though this is a brief origin story of my Ancestral Code project, I have interpreted the role of the four spirits in furthering its creation as a critical component of its development. As a result, I have found new ways of applying Nehiyaw cultural teachings to my computer coding practice.</p>
<h2 id="challenges-and-solutions">Challenges and Solutions</h2>
<p>Though I expected to encounter obstacles in this project, I did not honestly foresee how deep into my coding practice and theory I would be required to go to design the Ancestral Code programming language. In this section, I trace out each of the challenges with working the Nehiyawewin orthography — including its use in the software and hardware, how I incorporated Nehiyaw language structures into the programming language, and how I see culture as being crucial to the programming languages I developed.</p>
<h2 id="orthography">Orthography</h2>
<p>The Nehiyawewin orthography, called ᐊᒐᐦᑲᓯᓇᐦᐃᑲᓇ or acahkasinahikana, literally translates into English as spirit markers. Nehiyawewin also has a Standard Roman Orthographic (SRO) writing system in which the language can be written with the standard Latin alphabet to aid English speakers in pronunciation. Though Nehiyawewin learners frequently use SRO, many Nehiyaw first language speakers consider SRO an accommodation or adoption of western processes. They also feel this system voids much of the cultural significance and meaning attached to the spirit markers. Though I prefer to use Nehiyawewin spirit markers, most of the Nehiyawewin in this article is written in SRO form for easier readability by English readers. I have included a <a href="#glossary">glossary at the end of this article</a> with definitions and a pronunciation guide using the International Phonetic Alphabet (IPA) phonetic notation system.</p>
<p>My original desire to use acahkasinahikana exclusively in Ancestral Code was a conscious decision to combat the accommodation of English language constructions and representations. However, in investigating my needs as a programmer, these language-based concerns revealed that support for both SRO and acahkasinahikana are required to support Nehiyawewin language learners that may come from different dialects or communities. For this reason, programming in Ancestral Code can be performed in its Romanized form that I call Cree# (pronounced Cree-sharp) or its syllabic form ᐋᒋᒧᐤ (âcimow). The Ancestral Code IDE allows the programmer to switch between the two styles, where Cree# accommodates a certain level of familiar structure to the C# programming language, separating it from the more story-like narrative structure of ᐋᒋᒧᐤ (âcimow). Switching between these modes provides unique alternatives to experiencing written Nehiyawewin, where representing code in multiple cultural forms can be done without necessarily favouring one over the other. Furthermore, the IDE development aspect revealed a couple, albeit minor, concerns, namely:<br>
How to use the Unified Canadian Aboriginal Syllabics block of the Unicode Standard, that is, what font family/typeface to use for coding with syllabics.  How to address coding without, or with minimal, punctuation and numeracy.</p>
<h2 id="software-acahkasinahikana-for-coding">Software: acahkasinahikana for coding</h2>
<p>Using Unicode characters in modern programming environments is possible if the computing system supports the desired character sets. The Unified Canadian Aboriginal Syllabics block of the Unicode Standard occupies 640 code positions from 1400hex to 167Fhex. It includes orthographic glyphs for Blackfoot, Carrier, Cree, Dene, Inuktitut, Ojibwe, and other Canadian Athabascan languages. Unfortunately, the coding environment is often the main obstacle in using Unicode characters, especially as variable names and, more problematically, as keywords or reserved words. Typically, this lack of support is simply because the environment often uses a pre-installed font that does not contain glyph(s) in the desired code points of the font file. By default, the coding environments I am familiar with, such as  <em>Visual Studio</em>  and  <em>Processing</em> , use a fixed-width font/typeface such as Consolas, Courier, or Monospace. These fonts are common to Windows OS systems but do not have the Canadian Aboriginal Syllabics block of glyphs. Until recently, changing this font was not easy. Although, as of the writing of this article, the settings or preferences support in some IDEs is open to changing the default font, some still limit the fonts that can be used. There also are limited fonts suitable for programming using the Unicode Canadian Aboriginal Syllabics, and I argue there are currently no suitable fonts. Though it is theoretically possible to use syllabics as variable names in those IDEs, reliance on English programmatic tokens remains. The question then becomes, which font(s) can or should be used for programming with acahkasinahikana?</p>
<h2 id="software-acahkasinahikana-fonts">Software: acahkasinahikana fonts</h2>
<p>Though this may sound like a trivial topic from a western perspective, as it truly has little to do with actual coding and more to do with aesthetic preference, my critical reflection on coding practice makes this a necessary point of discussion. Remember that Nehiyaw acahkasinahikana are visual representations and extensions of being. They are called spirit markers for a reason. So, their representation in the computer must be treated with equal consideration.</p>
<p>Most programmers would agree that fixed-width or monospaced typefaces are ubiquitous in coding because they align very well in rows and columns and generally provide a greater distinction between similarly shaped characters like 0, o, O, narrow characters like I, l, i, as well as providing more space for syntactical and operational characters (, {, [,!  <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>. Combining this respect for the visual aspects of language with the need for a monospaced coding font reveals two challenges. The first challenge is that, to my knowledge, only one monospaced font purposefully includes the Canadian Aboriginal Syllabics blocks, Everson Mono.<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>  The second challenge is that the physical structure of syllabics makes using non-fixed-width fonts challenging to navigate as code. The visual structure of the major glyphs (i.e., the glyphs representing a consonant and vowel pair) consists of reflected orientations of a single shape (ex. ᒥ ᒣ ᒪ ᒧ). The resulting printed text is fairly consistently sized but is visually similar to coding in all English caps. This is not necessarily a negative, as my original programs written in BASIC were done in all caps. But a more significant point of consideration is how a culture perceives the visual design of its language. For example, in developing typefaces for Canadian syllabics, Canadian typography designer Kevin King worked directly with Indigenous communities to ensure their languages were written in the respective community’s preferred style. He notes that  “to ignore this would result in a text that was neither culturally appropriate for local readers nor able to convey adequately the meaning and atmosphere of the text for that readership” <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>. Adding to these, the limited number of monospaced fonts that support Canadian syllabic glyphs encouraged me to develop a new code-friendly font to address these obstacles. This font (<a href="#figure01">Figure 1</a>), I tentatively named  “AC Mono,”  was constructed using my wholistic design framework, and my choices in the font design process are consciously aware of Indigenous visual aesthetics. I want to note here that my design of this font was considered from a more pan-Indigenous perspective and not specific to Nehiyaw culture. This is because the Unified Canadian Aboriginal Syllabics is not Nehiyaw specific – it represents glyphs from various North American Indigenous languages. For example, as seen in the syllabic T-series glyphs like tâ (ᑖ) and te (ᑌ), I used thicker lines, an emphasis on fluidity in the curves, and rounded features on the start and end points of the strokes. These organic geometries and gestures are found in numerous Indigenous art traditions in North America, including the ovoid traditions of Coast-Salish artforms, Inuit bone and stone carving, and Métis beadwork.</p>




























<figure ><img loading="lazy" alt="Two glyphs of the AC Mono typeface which fill the space between the ascender line and the baseline." src="/dhqwords/vol/17/2/000699/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000699/resources/images/figure01_hu5c142ba333c966b4e5bf9e867ce11a9e_15187_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000699/resources/images/figure01_hu5c142ba333c966b4e5bf9e867ce11a9e_15187_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000699/resources/images/figure01.png 592w" 
     class="landscape"
     ><figcaption>
        <p>AC Mono Font glyphs for tâ (ᑖ) and te (ᑌ). Image by Jon Corbett.
        </p>
    </figcaption>
</figure>
<p>In the construction of AC Mono, I used the typefaces of Everson Mono and Consolas only as sizing templates, building my resulting font with the stroke weight of Consolas and the mildly rounded stroke end of Everson Mono. Of particular note, syllabics have no differing case structures. Therefore, no glyphs need to accommodate space for descenders that extend below the baseline. The removal of the descender area results in a noticeably reduced distance between the glyph baseline and the edge of the glyph-space in the AC Mono font compared to ASCII/English fonts (<a href="#figure02">Figure 2</a>), allowing for a more consistent line height, providing better options for vertical spacing between rows when coding.</p>




























<figure ><img loading="lazy" alt="A comparison of glyphs in the typefaces Everson Mono, Consolas, and AC Mono." src="/dhqwords/vol/17/2/000699/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000699/resources/images/figure02_hu34854cd84fccfe1bec44b89874c7dfde_130876_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000699/resources/images/figure02_hu34854cd84fccfe1bec44b89874c7dfde_130876_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000699/resources/images/figure02_hu34854cd84fccfe1bec44b89874c7dfde_130876_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000699/resources/images/figure02_hu34854cd84fccfe1bec44b89874c7dfde_130876_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000699/resources/images/figure02_hu34854cd84fccfe1bec44b89874c7dfde_130876_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000699/resources/images/figure02.png 2500w" 
     class="landscape"
     ><figcaption>
        <p>Font design comparison between Everson Mono, Consolas, and AC Mono, the English glyphs selected here are chosen for their visual similarity to the Nehiyawewin syllabics, they are not representative of English pronunciations or linguistic function.
        </p>
    </figcaption>
</figure>
<h2 id="software-acahkasinahikana-punctuation-and-numeracy">Software: acahkasinahikana punctuation and numeracy</h2>
<h2 id="heading"></h2>
<p>A more significant challenge is how to support specific programming tasks using limited punctuation and, preferably, an alternative numeric symbology. Programming nomenclature and notation have had a unique evolution and, as Arawjo notes, have developed in  “concert and conflict with discretizing infrastructure[s]” <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>. Without getting into a long history lesson on programmatic notation, I have seen how my own programming practice evolved from coding in BASIC, using very little punctuation except the double quote and round brackets, to today, where I predominantly use C# and Java that, use nearly every non-numeric and non-alpha character on the standard keyboard. In today’s programming culture, it is rare to see a programming language not use every symbol and character on the keyboard. Notation marks that currently have meaning and function in many modern programming languages can be problematic when developing solutions for Indigenous orthographies that traditionally do not use these marks.</p>
<p>As I mentioned earlier, the only punctuation commonly found in Nehiyawewin text is the full stop syllabic that looks like a lowercase x but is actually U+166E (᙮); and the hyphen - most often used to separate certain morphemes or break up very long sentence-word constructions when reading. My understanding of this lack of punctuation stems from my understanding of Nehiyawewin morpheme structures that provide the necessary context and grammatical positioning in its word construction, making punctuation usage unnecessary, except to indicate the end of thought or discussion <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>  <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>.</p>
<p>Another point of consideration between western culture and Nehiyaw culture is numeracy. Much of the world uses the ten symbols of the Hindu-Arabic decimal number system to represent numbers. Though Nehiyaw numeracy has become pretty much forgotten in favour of Hindu-Arabic numerals, Nehiyaw culture did develop a way to represent numbers using the syllabic glyphs (Figure 4). Furthermore, from a language perspective, Nehiyaw culture has developed certain relationships to numbers and numeric meanings that are often associated with Nehiyaw ontologies, as exemplified previously in my explanation of the meaning of Nehiyaw as the four-bodied people.</p>
<h2 id="punctuation-symbols">Punctuation Symbols:</h2>
<p>A simple but effective example of a  <em>traditional</em>  programming style that would execute a print-to-screen command might look like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-perl" data-lang="perl"><span style="display:flex;"><span><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;hello world&#34;</span>);
</span></span></code></pre></div><p>In this example, the parentheses mark the start and end of the function contents, and the double quotes mark the entry and exit points of the text to render to the screen.</p>
<h2 id="heading-1"></h2>
<p>So how would a programmer make this indication if there are no brackets or quotation marks? Another common symbol in modern programming languages is the semi-colon (;) as an instruction separator or terminator. Again, how does a programmer indicate where to terminate an instruction without this mark? These orthographic punctuation devices have become so commonplace in modern programming that it is difficult to envision not having access to them. It is precisely these kinds of practices that I have attempted to overcome in developing Ancestral Code. My intent here is not a need to use minimal punctuation. Instead, it is a resistance to adopting marks and practices that belong to other languages. To that end, one of the first steps I took was to inventory the Nehiyaw syllabary and functional language glyphs. I then established a list of necessary programmatic functions and decided on the syllabic symbols for my programming language.</p>
<p>To start this investigation, I started with the most straightforward programming language I know — BASIC. I used a variety of dialects of BASIC for nearly fifteen years, and upon reflection, it was one of the languages that I could use with the least amount of punctuation. BASIC also provides a good starting point for just reading code as if it were a recipe or short story. It also helped me identify the bare necessities I felt Ancestral Code required. In the end, I came to the following general determinations to make language development easier. These initial determinations were primarily based on my Indigenous Computing Design’s resistance to western computing reliance on non-alpha characters:</p>
<ul>
<li>The Unified Canadian Aboriginal Syllabics block of the Unicode Standard currently contains 640 symbols. However, my dialect of Plains Cree only uses 107 syllabics from a total block of 134 glyphs that  <em>could</em>  be used in Nehiyaw speech. So the remaining 533 symbols from the syllabary became potential candidates to fulfill those programmatic roles where western punctuation is usually employed.</li>
<li>Ancestral Code will be line-driven. In other words, the linefeed/carriage return is the primary instruction terminator. Using the linefeed, makes parsing of instructions easier.</li>
<li>The full stop symbol (᙮) is used to terminate  <em>and</em>  exit code (especially within a loop). Being the only punctuation mark, its function and use needed to make sense in the narrative flow of the source code.</li>
<li>Language-based reserved words are used to mark code start and end positions instead of braces or other symbols. For example, in Visual Basic</li>
</ul>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">IF
</code></pre><p>and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">END IF
</code></pre><p>mark the start and endpoints of a conditional code block; similarly, sipiy and  <em>âniskôsîpiy</em>  perform the same roles in Ancestral Code.</p>
<ul>
<li>In Ancestral Code, <a href="#numeracy">Nehiyawewin syllabic-numerals</a> replace Hindu-Arabic numbers. Hindu-Arabic numerals will be allowed, but only in SRO mode, and a built-in calculator will convert Hindu-Arabic numbers to their appropriate syllabic representations when in syllabic mode.<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup></li>
</ul>
<p>With this software side of the orthography resolved, I looked at the next obstacle: how should the user input code?</p>
<h2 id="hardware-the-acahkasinahikana-keyboard">Hardware: the acahkasinahikana keyboard</h2>
<p>The history of print cultures has led to privileging western  “stories, voices, and values” <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>, and modern coding cultures and computer language development have naturally adopted. Though Nehiyawewin can be typed on standard keyboard layouts using a Romanized orthography, this seemingly innocuous accommodation is probably the number one contributor to the continued erosion of Indigenous culture and language in the digital age.</p>
<p>Initially designed for English typewriters in the mid-to-late 19th century, the International Standards Organization officially adopted the QWERTY keyboard layout in 1971, becoming  “the de facto Standard layout for Communications and computer interface keyboards”  in 1972 <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>. Over the last 50 years, the ISO Standard has evolved as our communication technologies have, and ISO 9995-9:2016 now includes definitions for multilingual and multiscript keyboard layouts <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>. However, these standards still assume that most languages can be represented with a Latin alphabet. The ISO Standard clearly states that it  “is intended to address all characters needed to write all contemporary languages using the Latin script, together with standardized Latin transliterations of some major languages using other scripts” <sup id="fnref1:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>. This assumption that  “all contemporary languages”  can be written using a Latin character set is the type of colonial coercion that continues to institute western ideologies as dominant.</p>
<p>Regarding computing, our experiences are configured and guided by technology design philosophies that do not always include a combined understanding of  “people, technology, society, and business” <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>. By working with members of my community, my Ancestral Code project has allowed me to explore keyboard designs that can better represent Nehiyawewin and Nehiyaw culture when entering syllabics into the computer. I aimed my design objectives at challenging assumed western standards by investigating the role of the keyboard as an input device, and how such devices can support Nehiyaw cultural pedagogy and improve the relationships between the user, their language (i.e.,  Nehiyawewin), and the computer. Though Nehiyaw syllabics are taught in several ways, one popular method is the arrangement of the Nehiyawewin syllabary into a star design, often referred to as a Cree syllabic star chart (<a href="#figure03">Figure 3</a>). This design is used often in teaching syllabics and contains several culturally specific teachings. For example, as a student at University nuhelot’ine thaiyots’i nistameyimâkanak Blue Quills, my favourite syllabic origin-stories were about the ᒐ syllabic, described as being symbolic of the pipe used in Nehiyaw ceremony, ᐱ is a medicine lodge (i.e., tipi), and ᑕ can be interpreted as the toe of a moccasin. Whether or not these story sources are the true inspirations for the initial syllabic creations, I recognize the importance the visual imagery of syllabics holds and how they are intricately tied to cultural representations and understandings. Furthermore, due to the reflected and rotational arrangement and orientation of Nehiyaw syllabics, these teachings cannot be represented using the modern four-row keyboards used for typing in western computing.</p>




























<figure ><img loading="lazy" alt="Nehiyawewin syllabic glyphs arranged in rough four-fold symmetry with phonetic guides printed in miniature next to each corresponding symbol." src="/dhqwords/vol/17/2/000699/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000699/resources/images/figure03_huac97705254bc1293c7ee81751691d55b_33170_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000699/resources/images/figure03_huac97705254bc1293c7ee81751691d55b_33170_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000699/resources/images/figure03.png 663w" 
     class="portrait"
     ><figcaption>
        <p>My own Nehiyawewin syllabic star chart.
        </p>
    </figcaption>
</figure>
<p>I feel that a keyboard or input device that uses this Nehiyaw star layout is culturally significant, meaningful to a Nehiyaw user, and therefore appropriate for capturing Nehiyawewin. Through my iterative design process for the Nehiyawewin keyboard, I critically evaluated everything from the keycaps to the printed circuit boards (PCB). During this process, I created five distinct designs to retain cultural associations, allow efficient syllabic entry, and have practical usability for typing everyday documents. I found the star design keyboard was best suited as the primary interface for coding with Nehiyawewin in the Ancestral Code programming environment (<a href="#figure04">Figure 4</a>). Similarly, testing these designs with Nehiyawewin language-learners, users found typing syllabics with a star keyboard easier than QWERTY layouts because of the grouping of syllabic sounds in each of the four quadrants establishes a mental-map making locating syllabics by sound easier. For example, all the i syllabics are located in the keyboard&rsquo;s top left and top vertical. This relationship between spoken language, computer language, and teachings of the syllabic orthography is meaningful and is one that I feel is better supported by a device derived from Nehiyawewin pedagogy.</p>




























<figure ><img loading="lazy" alt="A radially-symmetrical image of a keyboard with eight rays of keys emanating from a central space key." src="/dhqwords/vol/17/2/000699/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000699/resources/images/figure04_hucef825cef830701c319f793fbd0fbdd8_639863_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000699/resources/images/figure04_hucef825cef830701c319f793fbd0fbdd8_639863_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000699/resources/images/figure04.png 735w" 
     class="landscape"
     ><figcaption>
        <p>One of my proposed Nehiyawewin Star Chart Keyboard designs.
        </p>
    </figcaption>
</figure>
<h2 id="bringing-nehiyawewin-characteristics-to-a-programming-language">Bringing Nehiyawewin characteristics to a programming language</h2>
<p>With the formalities of the orthography addressed, I progressed to investigating how to engage with Nehiyawewin programmatically. I initially approached this project with a very naive and western mindset. I considered common modern computing ideas and abstractions that included variables, data types, loops, conditional branching, and linear/sequential instructions (i.e., lines of code), and embarked on a journey to convert their English versions to Nehiyawewin. Thinking that some of these concepts would easily convert from English to Nehiyawewin, I quickly realized that this approach of language substitution in Nehiyawewin would not work. As I discovered on my first day as a Nehiyawewin student, Nehiyawewin technically does not have a word for computer, let alone any of the programming concepts I was hoping to capture. Technological words in English like programming, network, and protocol I found were, for the most part, non-translatable to Nehiyawewin, at least not a way I could use in developing a programming language. Today, finding appropriate Nehiyaw cultural meanings that can map to technological terminology remains the biggest challenge in developing the Ancestral Code project as a fully Nehiyawewin-privileged computing platform. Nevertheless, I took these challenges with language and formulated an approach that involved finding easily translatable concepts (if they existed), and borrowing from Nehiyaw language construction and word forms to create a unique coding paradigm.</p>
<h2 id="translating-nehiyawewin">Translating Nehiyawewin</h2>
<p>What is a computer? I asked the most knowledgeable person in my Nehiyaw class, the Elder. That conversation went something like this:<br>
Me<br>
How do you say computer?<br>
Elder<br>
Well, that depends. There really is no word for computer, but some people use masinatakan cikastepayicikanis.<br>
Me<br>
What does it mean?<br>
Elder<br>
Masinatakan means to type or write, but actually comes from words that mean using a tool to create or stamp a mark and cikastepayicikanis is the word we use for TV, it comes from a word about shadows so something like making a shadow, or full of shadows, or a box of shadows. You can interpret these words together as making marks in a box of shadows without a pen.<br>
Me<br>
Uh-huh… Ayhay.</p>
<p>I note that this was not an isolated occurrence. Well, that depends. There really is no word for [insert word], was a very common response to almost anything western in my classes and applied to most modern technologies like radios, televisions, and cell phones. Depending on whom you asked, there are as many ways to describe these modern contraptions as there are dialects of Nehiyawewin. However, I accept and now use mâmitoneyihcikanihkân  <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup> , suggested by Wayne Jackson, an esteemed Nehiyaw language expert and Nehiyawewin professor at University Blue Quills. As explained to me, this word is understood to mean artificial thought/brain. I choose this definition over masinatakan cikastepayicikanis because I feel it better conveys the essence of what a computer is. I find that masinatakan cikastepayicikanis  <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>  is more about describing the computer as a physical, non-animate object of utility than the more conceptual or abstract and humanized idea of what a computer is. After all, we as a species have a considerably long history of relating technologies to aspects of being human <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>, and mâmitoneyihcikanihkân suits this tradition.</p>
<p>Finding suitable replacements for some of the more programming-specific lingo such as integer, float, string, array, variable, subroutine/function, do/while, for/next, and if/then proved to be highly problematic. These concepts either do not translate easily, can only be translated in a general sense, and/or require a broader context. And, in most cases, they cannot be translated without simplifying their meaning. Additionally, these concepts can only be translated by conversation and engagement with community members, fluent speakers, and Elders with the required experience and knowledge.</p>
<p>My solution to this particular challenge was one of metaphoric application rather than translation. I credit Hawai’ian game developer and computer programmer Kari Noe for introducing me to this philosophical change. Noe was a member of a Ōlelo Hawai’ian programming team engaged with translating C# into Hawai’ian <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>. She described the if/then/else statement as an example where the if/then/else statement does not make sense when translated from English to Hawai’ian. The programming team consulted with native Hawai’ian speakers and community members to find meaningful terms that could be both culturally appropriate and programmatically practical. The result for if/then/else becomes muliwai, the Hawai’ian word for river. The idea of rivers being able to branch from the main waterway and eventually rejoin the main river later provided a better conceptualization of a Hawai’ian context than the English if/then/else statement. This culturally-aware solution in their language was not only inspirational but fundamentally altered how I was approaching the relationships between computing concepts and cultural relevance. Though I recognize that Hawai’ian peoples’ relationship with water is considerably different from those of the Indigenous peoples of the Americas, water is no less important. In Nehiyaw culture, water is a medicine, a provider of life, and is sacred. Therefore, I have come to use river as a conditional branch command. In Nehiyawewin river is sîpiy, and with this root I can then branch an if into sîpîsis, a small river or creek in English. Therefore, a code example might look like the following examples:</p>
<h1 id="a-series-of-conditional-branch-commands-in-ᐊᒋᒧ">A series of conditional branch commands in ᐊᒋᒧ</h1>
<pre tabindex="0"><code> ᐊᓱᐘᐦᐁᐤ ᐃᔨᓂᒥᐣ ᒦᓂᓯᐘᐟ  ᓰᐱᐩ ᑭᑿᐩ ᐲᐦᒋᔨᕽ ᒦᓂᓯᐘᐟ  ᓰᐲᓯᐢ ᐃᔨᓂᒥᐣ  ᐊᓱᐘᐦᐁᐤ ᐊᔫᐢᑲᐣ ᒦᓂᓯᐘᐟ᙮  ᓰᐲᓯᐢ ᐊᔫᐢᑲᐣ  ᐊᓱᐘᐦᐁᐤ ᐃᔨᓂᒥᐣ ᒦᓂᓯᐘᐟ  ᐋᓂᐢᑰᓰᐱᐩ  ᓰᐱᐩ ᑮᓯᐸᔨᐤ 
</code></pre><h1 id="example-1example01-in-sro-cree"><a href="#example01">Example 1</a> in SRO (Cree#)</h1>
<pre tabindex="0"><code> asiwahew iyinimin mînisiwat  sîpiy kikway pîhciyihk mînisiwat  sîpîsis iyinimin  asiwahew ayôskan mînisiwat.  sîpîsis ayôskan  asiwahew iyinimin mînisiwat  âniskôsîpiy  sîpiy kîsipayiw 
</code></pre><h1 id="the-literal-english-translation-of-the-code-block-from-example-1example01-or-example-2example02">The literal English translation of the code block from <a href="#example01">Example 1</a> or <a href="#example02">Example 2</a></h1>
<pre tabindex="0"><code> put the blueberries in the berry bag  [start] a river, what is [in] this bag?  [start] a creek [for] blueberries  put a single raspberry in the berry bag.  [start] a creek [for] a raspberry  put the blueberries in the berry bag  join the river  the river ends 
</code></pre><p>In this example, the first creek ends with mînisiwat᙮<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>  where ᙮ terminates and subsequently ends the river-if statement. The second creek ends with âniskôsîpiy<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>  or rejoin the river, and in this case, it would continue to the following statement in the if code block. In this way, the if statement is fluid. It can branch, terminate, or rejoin the original, reflecting a natural flow or progression.</p>
<p>Understanding computer functions in these cultural terms provides a more Indigenous method of relating to the machine. In addition, defining programmatic operations using culturally meaningful metaphoric terminology changes the process of keyword translation to a process of knowledge adaptation, ensuring that a Nehiyaw programmer does not need to language-switch between Nehiyawewin and English to have the computer perform its tasks. Looking at a computer’s code from this metaphoric perspective can also be extended to the binary level of the machine, where a Nehiyaw worldview can reframe the binary understanding of 1 and 0 as animate and inanimate.</p>
<h2 id="nehiyaw-language-construction">Nehiyaw language construction</h2>
<p>I felt that morphemes and free word order were characteristics of Nehiyawewin that offered strong potential for programmatic versatility though they did offer some unique challenges.</p>
<h2 id="morphemes">Morphemes</h2>
<p>Nehiyawewin is intensely metaphoric and descriptive and is a polysynthetic language, meaning the language combines many morphemes, often resulting in lengthy sentence-word constructions <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>. A morpheme is a single linguistic unit of meaningful speech. For an English example, without focusing too much on etymology, the word code from the Latin codex can add different suffixes to alter its meaning. One such ending is -ing to change it to coding, representing an active verb. Another is -er to change it to coder, which is a noun meaning a person who codes, and both could be structured in a sentence as the coder is coding. These suffixes are morphemes.</p>
<p>A fun example that illustrates how Nehiyawewin morphemes are stringed together is the word for hippopotamus. Nehiyawewin does not have an actual word for hippopotamus because this animal is not native to the Americas, and therefore it is described in language using its most prominent features. In Nehiyawewin, as described by Nehiyaw Elder Solomon Ratt, a hippopotamus is called kihci-kispakasakewi-mistipwâmi-mahkitôni-nîswâpitewi-atâmipeko-pimâtakâwi-kohkôs or in English as  “great, thick-skinned, big-thighed, big-mouthed, two-toothed, underwater, swimming, pig ” <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>.</p>
<p>Another interesting example is the Nehiyawewin translation for the English word pony. In Nehiyawewin, the word atim  <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>  is the word for dog. When you prefix atim with mist- from the word mistahi-, which means [something] is great/large/big, the resulting word mistatim is formed, which can mean big dog, but is more commonly used to mean horse. Adding the diminutive suffix –osis, meaning [something] is small or little, to atim, the result is acimosis meaning little dog or puppy. We can go one step further and combine all three of these ideas to get mistacimosis. The resulting understanding is a small horse or pony. Though one could argue it also means a very big puppy, the context would clarify what the speaker is referring to.</p>
<p>For Ancestral Code, I used these bound morphemes of mistahi- and -osis as ways to make variables increase or decrease in value (i.e., size), even though they may not be semantically or syntactically correct in Nehiyawewin speech. So, for example, using a numeric variable called atim, you can use the following statement:</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">atimosis
</code></pre><p>This is equivalent to the more traditional coding representation of:</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">atim = atim - 1;
</code></pre><p>This usage carries the meaning of increase the size of the dog and reduce the size of the dog or make the dog bigger then smaller. In this example, the variable atim has some value manipulated through a single morpheme-constructed token instead of a more common calculation assignment in other programming languages delimited by spaces to separate each programmatic token. Not to mention the problem with translating the syntax of</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">atim = atim + 1
</code></pre><p>as an assignment command and not a logical statement into Nehiyawewin.</p>
<h2 id="free-word-order">Free Word Order</h2>
<p>Free word order means words in a sentence do not necessarily need to be in a rigid sequence. This ordering is especially apparent in something like the cat sees the dog; whereas, in English, you cannot swap the cat and the dog without changing its meaning, as in the dog sees the cat. However, this is not the case in Nehiyawewin, where minôs wâpamew atimwa<sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>  and atimwa wâpamew minôs mean the same thing. This language use is because there is a third-person obviative -wa attached to atim, indicating the dog atim is the object being acted on regardless of where it appears in the sentence in relation to the cat. To say this sentence in English requires modifying the verb to clarify who or what is seeing and identifying who or what is being seen. This sentence is a simplistic example, but as the coding environment for Ancestral Code was designed to be written as a narrative, having this flexibility is something I wanted to be able to use because it is non-linear and changes our perceptions of coding in line-by-line formats. A simple coding example would be the completion command for sîpiy,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">sîpiy kîsipayiw
</code></pre><p><sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup> . In this case, sîpiy kîsipayiw and kîsipayiw sîpiy mean the same thing. Although, as a coder, I can use end river or river ends, it does not matter the order of the tokens as they are not fixed. A more expanded example uses this same idea but applies to whole lines or activities, as in a looping construction where a character such as Wîsahkecâhk might walk, hop, and talk:</p>
<h1 id="free-word-order-in-in-ᐊᒋᒧ">Free word order in in ᐊᒋᒧ</h1>
<pre tabindex="0"><code> ᐱᐳᐣ  ᐃᔀᑫᒐᕽ ᐱᒧᐦᑌᐤ  ᓇᐸᑌᒁᐢᑯᐦᑎᐤ ᐃᔀᑫᒐᕽ ᐃᔀᑫᒐᕽ ᐄᑭᐢᑵᐤ 
</code></pre><h1 id="example-4example04-in-sro-cree"><a href="#example04">Example 4</a> in SRO (Cree#)</h1>
<pre tabindex="0"><code> pipon  Wisakecahk pimohtew  napate-kwâshohtiw Wisakecahk Wisakecahk pîkiskwew 
</code></pre><h1 id="the-literal-english-translation-of-the-code-block-from-example-4example04-or-example-5example05">The literal English translation of the code block from <a href="#example04">Example 4</a> or <a href="#example05">Example 5</a></h1>
<pre tabindex="0"><code> for one winter  Wisakecahk walks  hop Wisakecahk Wisakecahk speaks 
</code></pre><p>When this block of code runs, the lines that follow pipon are randomized as it is not essential which order those actions execute, as long as the Wîsahkecâhk object variable performs all three actions in this block. By comparison, an equivalent representation of this code in C# might look like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c#" data-lang="c#"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> winter = <span style="color:#ae81ff">1</span>; <span style="color:#66d9ef">do</span> { Random r = <span style="color:#66d9ef">new</span> Random(); <span style="color:#66d9ef">string</span>[] actions = <span style="color:#66d9ef">new</span> <span style="color:#66d9ef">string</span>[] { <span style="color:#e6db74">&#34;walk&#34;</span>, <span style="color:#e6db74">&#34;hop&#34;</span>, <span style="color:#e6db74">&#34;speak&#34;</span> }; actions = actions.OrderBy(x =&gt; r.Next()).ToArray(); <span style="color:#66d9ef">foreach</span> (<span style="color:#66d9ef">string</span> doAction <span style="color:#66d9ef">in</span> actions) { makeWisakecahk(doAction); } winter--; } <span style="color:#66d9ef">while</span> (winter == <span style="color:#ae81ff">1</span>);
</span></span></code></pre></div><p>The Ancestral Code keyword for a do loop is</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">pipon
</code></pre><p><sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup> , which translates as a winter. In the next section, I will elaborate on the meaning and cultural significance of the reserved word pipon. But, for this example, if I wanted to perform these actions in sequence and not a random order, I would not bother using the</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">pipon 
</code></pre><p>loop. You may also notice that the lines that direct the Wîsahkecâhk variable to do an action (see <a href="#example04">Example 4</a>, <a href="#example05">Example 5</a>, or <a href="#example06">Example 6</a>) are in free word order in the Ancestral Code example (as in</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">Wîsahkecâhk walks
</code></pre><p>and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">hop Wîsahkecâhk
</code></pre><p>). Unlike many programming languages that must start with a command or keyword followed by variables or parameters, this is not necessary for Ancestral Code, as long as the variable and command are on the same executing line. The programming parser, the part of the programming environment responsible for separating lines of code into smaller elements and individual instructions, will still be able to discern the token from the data, regardless of the position of each in the line. In the next section, I will detail the reasons behind this built-in randomization. Still, in terms of programming language construction, using features of morphemic commands and free word order, are a means to describe the relationships between the programmatic structures of Ancestral Code and Nehiyaw culture.</p>
<h2 id="culture-and-language--code--code--culture-and-language">Culture and language == code &amp;&amp; code == culture and language</h2>
<p>Language plays a significant role in the enterprise of computer programming, and these activities are still heavily informed by western culture. Consequently, it is challenging to envision programming as anything but a socio-technical subculture populated with hordes of Benjamin Nugent’s  <em>Lewis Skolnick-esque</em>  Type-1 nerds  <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>.<sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>  This stereotyped and generalized view of programmers and programming was the last challenge I aimed to reformulate, to introduce Indigenous cultural practices as digital metaphorical structures that view programming from Indigenous epistemological and ontological concerns that alter how programming is perceived in its current western context. For example, I admire how Ramsey Nasser describes the algorithms depicted in the Arabic calligraphic forms of his قلب programming language  “as high poetry” <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>. I also found that describing western computing ideas in Nehiyawewin often resulted in algorithmically poetic word creations, as evidenced with the concept of river to represent if/then logic. I expand on this analogy-based token use for representing programmatic instructions by applying the same metaphoric treatment to culturally specific understandings as a way of genuinely viewing computer programming as a non-western endeavour. Through this reimagining of computing terms, I highlight how computing concepts already reflect Indigenous cultural teachings, practices, especially ceremony, as I demonstrate in the following specific examples of miyâhkasike<sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup> , pipona<sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup> , and waniyaw  <sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup> .</p>
<h2 id="miyâhkasike-and-tisamân">Miyâhkasike and Tisamân</h2>
<p>One of the most common and essential cultural practices in Nehiyaw culture is the smudge. A smudge is a small, personal ceremonial practice where the burning of an Indigenous medicinal herb such as sweetgrass or sage is used to cleanse and purify the individual. When smudging, people pass their hands or objects to be blessed through the rising smoke trails. In a normal smudge, you use your hands to draw the smoke towards you – blessing your head, ears, eyes, mouth, heart, and body with the smoke. And then, you bless anything else you wish to be cleared of negative energies, such as food, tobacco, eyeglasses, or even your laptop. Essentially, smudging is responsible for blessing anything that can affect any of your four spirits. I have even heard stories from several Nehiyaw and Métis Elders that have physically smudged their laptop to purify it before Googling. In the context of ceremony, this idea of cleansing is something that computers do regularly. Whether it is emptying the trash bin, clearing memory, resetting the graphics display, or deleting a browser’s cache, the intent of all these activities is to remove items that can negatively affect the system’s operation. Therefore, the first command in an Ancestral Code program is</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">miyâhkasike
</code></pre><p>which is to smudge with sage/sweetgrass, or</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">tisamân
</code></pre><p><sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup> , which is to smudge (in general), both serve the same purpose of preparing the system. The choice of which smudge command to use is up to the programmer. However, I personally feel that a program that relates a sacred story or contains culturally specific or significant knowledge in the code would start with</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">miyâhkasike
</code></pre><p>, being more purposeful than the more generic</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">tisamân
</code></pre><p>. These smudging operations include, but are not limited to, clearing any current output on the screen, clearing and readying the program’s libraries and variables, and clearing any cache from a previous execution.</p>
<p>Miyâhkasike is an essential piece of code because not only does it have a very real programmatic purpose, but to have the system digitally mirror a user’s physical ceremonial practice transcends the system. It also symbolically provides the computer a spirit that the user can relate to as more of a living being instead of seeing the computer as a subordinate spiritless instrument. From an Indigenous perspective, this kind of human-machine connection is one of collaboration and kinship, and has been explored by several Indigenous scholars and artists <sup id="fnref:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup>  <sup id="fnref:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup>  <sup id="fnref:67"><a href="#fn:67" class="footnote-ref" role="doc-noteref">67</a></sup>.</p>
<h2 id="pipon">Pipon</h2>
<p>Pipon literally means winter. It, and its plural form  <em>pipona,</em>  along with the lexically related words pipohki (next winter), awasipipon (last winter), and mesakwanipipon (every winter)<sup id="fnref:68"><a href="#fn:68" class="footnote-ref" role="doc-noteref">68</a></sup>  are used in Ancestral Code as for loops.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">Pipon
</code></pre><p>describes the single execution of a group of lines, and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">pipohki
</code></pre><p>,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">awasipipon
</code></pre><p>, and</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">mesakwanipipon
</code></pre><p>are sub-functions that can only occur inside a repeating</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">pipona
</code></pre><p>loop.</p>
<p>You may ask why use pipon as a metaphor for the programmatic loop? Could you not use nîpin (summer) since it also occurs annually? What makes pipon important is its significance to aging and identity in Nehiyaw culture. For example, in Nehiyawewin, I say, I am currently 49 winters old. As heard from respected Nehiyaw culture and language instructor Reuben Quinn, we use winter and not another season because back in the days before comfortable housing in the northern climes of what is now Canada, surviving winter signified your resilience and survival of the most extreme elements of Earth Mother <sup id="fnref:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup>. Surviving winter is a valued and personal accomplishment. The symbolism in winter as a programming keyword lies in its representation as a repeatable cycle and in its relationships to aging and resilience that naturally imply increased experience and knowledge. So, similar to when a western-formatted computer program loops through a series of instructions, it often builds upon previously executed statements — the loop ages as it progresses and continues until the loop conditions are met or terminate.</p>
<h2 id="waniyaw">Waniyaw</h2>
<p>Waniyaw is a word that can be used for meaning at random. In Ancestral Code, it is a way to simulate the dynamic and unpredictable forces of the natural world. Randomization is fundamental to Ancestral Code because of the generative nature of the outputs it creates. From a cultural perspective, I want the visual outputs to have aspects that are arbitrary and not controllable by the programmer. This environment of chance reflects the aspects of nature we cannot control. Therefore, giving the system some autonomy and decision-making is one way to prevent the programmer from always having complete control. In Nehiyaw culture, it is necessary to allow nature to run its course or recognize that there are elements in our world beyond the individual’s control.</p>
<h2 id="randomization">Randomization</h2>
<p>In addition to the reserved keyword</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">waniyaw
</code></pre><p>, the words</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">pipon
</code></pre><p>,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">mihcecis
</code></pre><p>,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">mihcet
</code></pre><p>,</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">mihcetinwa
</code></pre><p><sup id="fnref:70"><a href="#fn:70" class="footnote-ref" role="doc-noteref">70</a></sup> , and the bound morpheme misi- incorporate randomization events in one form or another.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">pipon
</code></pre><p>– is the instruction for do once or literally for one winter, and all lines of code that proceed it are executed in random order until the ᙮  full stop is encountered.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">mihcecis
</code></pre><p>– means small many and is used to produce a random number between 100 and 1,000.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">mihcet
</code></pre><p>– means many and is used to produce a random number between 1,000 and 100,000.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">mihcetinwa
</code></pre><p>– means numerous and is used to produce a random number between 100,000 and 1 million.</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">waniyaw
</code></pre><p>– is used in the context of the entire program or within a</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">pipona
</code></pre><p>loop block.</p>
<p>So, for example, if the programmer wants a statement or series of statements to execute randomly, they would write it like this:</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">waniyaw
</code></pre><pre tabindex="0"><code class="language-unspecified" data-lang="unspecified"> Wisakecahk
</code></pre><pre tabindex="0"><code class="language-unspecified" data-lang="unspecified"> pimohtew
</code></pre><p>Ancestral Code interprets this instruction as have Wîsahkecâhk walk at a random interval. If this instruction is in the main body of the code, it will execute for random intervals from that point forward. If this instruction is inside a</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">pipona
</code></pre><p>block, it executes randomly only for as long as that loop is active and ends when the loop ends. In this use, the computer takes on the responsibility of nature, and each time the program is executed, the randomness introduced with</p>
<pre tabindex="0"><code class="language-unspecified" data-lang="unspecified">waniyaw
</code></pre><p>in the code guarantees the output will always be unique. This uniqueness is similar to how a story is never quite the same when repeated, even by the same storyteller.</p>
<h2 id="conclusion">Conclusion</h2>
<p>When it comes to coding in any of the thousands of computer programming languages available, a programmer is obliged to subscribe to and accept the social, technological, and cultural attitudes that created that language. Ancestral Code, is no exception, in that it is formulated to be more accessible to Nehiyaw users. However, in contrast to other (i.e., more common/traditional) computing languages, Ancestral Code is built on specific Nehiyaw cultural principles and not necessarily the lineal or logical requirements defined by the system. This difference means that Ancestral Code’s model and programming paradigm can alter computing philosophies and create new opportunities and avenues for Indigenous computer programming pedagogy.</p>
<p>“Survivance,”  as defined by distinguished Indigenous cultural theorist Gerald Vizenor, is  “an active sense of presence, the continuance of native stories, not a mere reaction, or a survivable name. Native survivance stories are renunciations of dominance, tragedy and victimry” <sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. As a project, my intention in creating Ancestral Code was to make a system capable of collaborating with Indigenous knowledges to create a uniquely Indigenous experience within a digital space born from western computational sciences. Through a wholistic and Indigenous approach to computer programming, I have revealed that there can be a deep connection in the human-computer relationship paradigm, one that can advance programming practices to be more culturally informed while remaining relevant and critical to the survivance of Indigenous language and culture.</p>
<p>Using theoretical wholistic Indigenous design frameworks and culturally-determined computer programming language like the ones I described in this article, I am encouraging deeper critical discussions on the socio-technical philosophies of computer programming. Ancestral Code can be used as a template that seeks to harmonize cultural epistemologies and ontologies with computing by redefining computing philosophies through a cultural lens. It is a project meant to take a user on a voyage through Nehiyaw knowledges that have developed over millennia and have those knowledges define the relationships and models of modern computing. This journey then changes the relationship from one of human-and-computer to one that is culture-and-computer.</p>
<p>I feel this change in philosophy and approach to computer programming rewards both Indigenous and western computing cultures. From my perspective, a programmer’s identity is heavily imbued with western computing practices and personally meaningful relationships with software and the interaction with computing devices. This broadening and augmenting of software and hardware architectures are worthy of further investigation, especially for the potential benefits they can provide as a template for other Indigenous communities who wish to advocate and explore their cultural languages and teachings as programmatic interfaces.</p>
<h2 id="glossary">Glossary</h2>
<pre><code>Standard Roman Orthography, IPA (Pronunciation), and Meaning of Nehiyawewin    Standard Roman Orthography  IPA (Pronunciation)  Meaning      âcimow  ʌtʃɪmow  [s/he] narrates [her/his] own story       acimosis   ʌtʃɪmʊsɪs  small dog; puppy      âniskôsîpiy  aːnɪskoːsiːpij  following the river; rejoin the river      atim   ʌtɪm  a dog      atimwa wâpamew minôs  ʌtɪmwʌ waːpʌmew mɪnoːs  the dog + is seen by + the cat      awasipipon   ʌwʌsɪpɪpʊn  last winter      kîsipayiw  kiːsɪpʌyiw  [something] ends or terminates      mâmitoneyihcikanihkân  maːmɪtonejɪhtʃikanɪhkaːn  computer; artificial brain      masinatakan cikastepayicikanis   mʌsɪnʌtʌgʌn tʃɪkʌsteːpajɪtʃikʌnɪs  computer; box of shadows      mesakwanipipon   meːsʌkwʌnɪpɪpʊn  every winter or every year      mihcecis   mɪhtʃeːtʃɪs  several      mihcet   mɪhtʃeːt  many      mihcetinwa   mɪhtʃeːtɪnwʌ  a lot; numerous      mînisiwat  miːnɪsɪwʌt  a bag used for berry picking      minôs  mɪnoːs  a cat      mistacimosis  mɪstʌtʃɪmʊsɪs  a pony      mistahi   mɪstʌhɪ  [something] is big or large      mistatim  mɪstʌtɪm  a horse; or a large dog      miyâhkasike   mijaːhkʌsɪgeː  [s/he] smudges with sweetgrass      nehiyaw  neːhɪyʌw  a Cree person; Cree culture      nehiyawewak  neːhɪyʌweːwʌk  Cree people (plural)      nehiyawewin  neːhɪyʌweːwɪn  Cree Language      nîpin   niːpɪn  summer time      nitâpân  nɪtaːbaːn  my great grandparent (grandmother)      nohkompân   nʊhkʊmbaːn  grandmother + passed on      pipohki   pɪpʊhkɪ  next winter      pipon   pɪpʊn  winter      pipona  pɪpʊnʌ  winters (plural)      sîpihkomipit  siːpɪhkʊmɪpɪt  bluetooth      sîpîsis   siːpiːsɪs  creek (small river)      sîpiy   siːpij  river      tisamân  tɪsʊmaːn  smudge      waniyaw  wʌnɪyʌw  at random; at a random time      wâpamew  waːpʊmew  [s/he] sees [her/him]      wîsahkecâhk  wiːsʌhkeːtʃaːhk  cultural teacher and legendary figure in Nehiyaw culture      
</code></pre>
<h2 id="appendix">Appendix</h2>
<pre><code>Syllabic Numeracy Appendix (Numbers 1 to 100)    Hindu-Arabic Numbers  Nehiyawewin Syllabic-Numerals      1 - 10  l  ll  ᐅ  lᐅ  llᐅ  ᐅᐊ  ᐊ  ᐊl  ᐊll  ᒥ      11 - 20  ᒥl  ᒥll  ᒥᐅ  ᒥlᐅ  ᒥllᐅ  ᒥᐅᐊ  ᒥᐊ  ᒥᐊl  ᒥᐊll  ᓀ      21 - 30  ᓀl  ᓀll  ᓀᐅ  ᓀlᐅ  ᓀllᐅ  ᓀᐅᐊ  ᓀᐊ  ᓀᐊl  ᓀᐊll  ᓂ      31 - 40  ᓂl  ᓂll  ᓂᐅ  ᓂlᐅ  ᓂllᐅ  ᓂᐅᐊ  ᓂᐊ  ᓂᐊl  ᓂᐊll  ᓄ      41 - 50  ᓄl  ᓄll  ᓄᐅ  ᓄlᐅ  ᓄllᐅ  ᓄᐅᐊ  ᓄᐊ  ᓄᐊl  ᓄᐊll  ᓇ      51 - 60  ᓇl  ᓇll  ᓇᐅ  ᓇlᐅ  ᓇllᐅ  ᓇᐅᐊ  ᓇᐊ  ᓇᐊl  ᓇᐊll  ᑯ      61 - 70  ᑯl  ᑯll  ᑯᐅ  ᑯlᐅ  ᑯllᐅ  ᑯᐅᐊ  ᑯᐊ  ᑯᐊl  ᑯᐊll  ᑲ      71 - 80  ᑲl  ᑲll  ᑲᐅ  ᑲlᐅ  ᑲllᐅ  ᑲᐅᐊ  ᑲᐊ  ᑲᐊl  ᑲᐊll  ᑫ      81 - 90  ᑫl  ᑫll  ᑫᐅ  ᑫlᐅ  ᑫllᐅ  ᑫᐅᐊ  ᑫᐊ  ᑫᐊl  ᑫᐊll  ᑭ      91 - 100  ᑭl  ᑭll  ᑭᐅ  ᑭlᐅ  ᑭllᐅ  ᑭᐅᐊ  ᑭᐊ  ᑭᐊl  ᑭᐊll  lᒥᑕ      
</code></pre>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Nohkompan – grandmother who is passed on&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Nitâpân  – great-grandmother&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Unicode, Inc. (2021)  “The Unicode Standard, Version 14.0.”  Unicode, Inc. <a href="https://unicode.org/charts/PDF/U1400.pdf">https://unicode.org/charts/PDF/U1400.pdf</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Ali, Mustafa. (2014)  “Towards a Decolonial Computing.”  In  <em>Ambiguous Technologies: Philosophical Issues, Practical Solutions, Human Nature</em> , 28–35. Lisbon, Portugal: International Society of Ethics and Information Technology.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Heaven, Douglas. (2013)  “One Minute with&hellip;Ramsey Nasser.”    <em>New Scientist</em>  217 (2909): 03–03.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Gradual Civilization Act. (1857)  <em>An Act to Encourage the Gradual Civilization of the Indian Tribes in This Province, and to Amend the Laws Respecting Indians</em> .&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Venne, Sharon. (1981)  “Indian Acts and Amendments, 1868-1975.”  An indexed collection. University of Saskatchewan Native Law Centre, Saskatoon.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Milloy, John. (2008)  “Indian Act Colonialism: A Century Of Dishonour, 1869-1969.”  Research Paper. Canada: National Centre for First Nations Governance.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Milloy, John S. (2017)  <em>A National Crime: The Canadian Government and the Residential School System</em> . Vol. 11. Univ. of Manitoba Press.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Garneau, David. (2018)  “Electric Beads: On Indigenous Digital Formalism.”    <em>Visual Anthropology Review</em>  34 (1): 77–86.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Warschauer, Mark. (1998)  “Technology and Indigenous Language Revitalization: Analyzing the Experience of Hawai’i.”    <em>Canadian Modern Language Review</em>  55 (1): 139–59.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Vizenor, Gerald Robert. (2008)  <em>Survivance: Narratives of Native Presence</em> . U of Nebraska Press.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Ormond-Parker, Lyndon, Aaron David Samuel Corn, Kazuko Obata, and Sandy O’Sullivan. (2013)  <em>Information Technology and Indigenous Communities</em> . AIATSIS Research Publications Canberra.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Absolon, Kathy. (2010)  “Indigenous Wholistic Theory: A Knowledge Set for Practice.”    <em>First Peoples Child &amp; Family Review</em>  5 (2): 74–87. <a href="https://doi.org/10.7202/1068933ar">https://doi.org/10.7202/1068933ar</a>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Worden, Keith, Wieslaw J Staszewski, and James J Hensman. 2011.  “Natural Computing for Mechanical Systems Research: A Tutorial Overview.”    <em>Mechanical Systems and Signal Processing</em>  25 (1): 4–111.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Babaoglu, Ozalp, Geoffrey Canright, Andreas Deutsch, Gianni A Di Caro, Frederick Ducatelle, Luca M Gambardella, Niloy Ganguly, Márk Jelasity, Roberto Montemanni, and Alberto Montresor. (2006)  “Design Patterns from Biology for Distributed Computing.”    <em>ACM Transactions on Autonomous and Adaptive Systems (TAAS)</em>  1 (1): 26–66.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Benenson, Yaakov. (2012)  “Biomolecular Computing Systems: Principles, Progress and Potential.”    <em>Nature Reviews Genetics</em>  13 (7): 455–68.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Kleinrock, Leonard, and Farouk Kamoun. (1980)  “Optimal Clustering Structures for Hierarchical Topological Design of Large Computer Networks.”    <em>Networks</em>  10 (3): 221–48.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Abd-El-Barr, Mostafa. (2009)  “Topological Network Design: A Survey.”    <em>Journal of Network and Computer Applications</em>  32 (3): 501–9.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Irani, Lilly C, and Paul Dourish. (2009)  “Postcolonial Interculturality.”  In , 249–52.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Irani, Lilly, Janet Vertesi, Paul Dourish, Kavita Philip, and Rebecca E Grinter. (2010)  “Postcolonial Computing: A Lens on Design and Development.”  In  <em>CHI ’10: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</em> , 1311–20. Atlanta, GA, USA: Association for Computing Machinery.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Merritt, Samantha, and Shaowen Bardzell. (2011)  “Postcolonial Language and Culture Theory for HCI4D.”  In  <em>CHI’11 Extended Abstracts on Human Factors in Computing Systems</em> , 1675–80.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Dourish, Paul, and Scott D Mainwaring. (2012)  “Ubicomp’s Colonial Impulse.”  In  <em>Proceedings of the 2012 ACM Conference on Ubiquitous Computing</em> , 133–42. Pittsburgh, PA: Association for Computing Machinery, New York, NY.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Philip, Kavita, Lilly Irani, and Paul Dourish. (2012)  “Postcolonial Computing: A Tactical Survey.”    <em>Science, Technology, &amp; Human Values</em>  37 (1): 3–29.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Abdelnour-Nocera, José, Torkil Clemmensen, and Masaaki Kurosu. (2013)  “Reframing HCI Through Local and Indigenous Perspectives.”    <em>International Journal of Human–Computer Interaction</em>  29 (4): 201–4. <a href="https://doi.org/10.1080/10447318.2013.765759">https://doi.org/10.1080/10447318.2013.765759</a>.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Wilson, Shawn. (2008)  <em>Research Is Ceremony: Indigenous Research Methods</em> . Halifax, NS: Fernwood Publishing.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Cormier, Paul, and Lana Ray. (2018)  “A Tale of Two Drums: Kinoo’amaadawaad Megwaa Doodamawaad – ‘They Are Learning with Each Other While They Are Doing.’”  In  <em>Indigenous Research: Theories, Practices, and Relationships</em> , edited by Deborah McGregor, Jean-Paul Restoule, and Rochelle Johnston, 112–25. Toronto, Canada: Canadian Scholars’ Press.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Thomas, Robina Anne. (2005)  “Honouring the Oral Traditions of My Ancestors through Storytelling.”  In  <em>Research as Resistance: Critical, Indigenous and Anti-Oppressive Approaches</em> , edited by Leslie Brown and Susan Strega, 237–54. Toronto, ON: Canadian Scholars’ Press/Women’s Press.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Madden, Brooke, Marc Higgins, and Lisa Korteweg. (2013)  “‘Role Models Can’t Just Be on Posters’: Re/Membering Barriers to Indigenous Community Engagement.”    <em>Canadian Journal of Education</em>  36 (2): 212–47.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Wolfart, H.C., and Freda Ahenakew, eds. (1993)  <em>Kinêhiyâwiwininaw Nêhiyawêwin. The Cree Language Is Our Identity: The La Ronge Lectures of Sarah Whitecalf</em> . Winnipeg, MB, CA: University of Manitoba Press.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Vee, Annette. (2017)  <em>Coding Literacy: How Computer Programming Is Changing Writing</em> . Mit Press.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Aikin, Jim. (2009)  “The Inform 7 Handbook.”   <a href="https://www.musicwords.net/if/I7Handbook8x11.pdf">https://www.musicwords.net/if/I7Handbook8x11.pdf</a>.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Hasselström, Karl, and Jon Åslund. (2001)  “The Shakespeare Programming Language.”  6/6/2018. <a href="http://shakespearelang.sourceforge.net/">http://shakespearelang.sourceforge.net/</a>.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>ᐊᒋᒧ âcimow – story&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Ardley, Sean. (2014)  “Why Are Monospaced Typefaces Used for Programming? (Answer (1 of 2)).”    <em>Quora</em> . <a href="https://www.quora.com/Why-are-monospaced-typefaces-used-for-programming/answer/Sean-Ardley">https://www.quora.com/Why-are-monospaced-typefaces-used-for-programming/answer/Sean-Ardley</a>.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>The font can be found at <a href="https://www.evertype.com/emono/">https://www.evertype.com/emono/</a>&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>King, Kevin. (2022)  “Typotheque: Syllabics Typographic Guidelines and Local Typographic Preferences by Kevin King.”    <em>Typotheque</em>  (blog). January 24, 2022. <a href="https://www.typotheque.com/articles/syllabics_typographic_guidelines">https://www.typotheque.com/articles/syllabics_typographic_guidelines</a>.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Arawjo, Ian. (2020)  “To Write Code: The Cultural Fabrication of Programming Notation and Practice.”  In  <em>CHI ’20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</em> , 1–15. Honolulu, HI. <a href="https://doi.org/10.1145/3313831.3376731">https://doi.org/10.1145/3313831.3376731</a>.&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Wolfart, H Christoph. (1973)  “Plains Cree: A Grammatical Study.”    <em>Transactions of the American Philosophical Society</em>  63 (5): 1–90.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Okimasis, Jean, and Arok Wolvengrey. (2008)  <em>How to Spell It in Cree: The Standard Roman Orthography</em> . misāskwatōminihk (Saskatoon): Houghton Boston, miywāsin ink.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>See the <a href="#numeracy">Syllabic Numeracy Appendix</a> for more&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Risam, Roopika. (2018)  <em>New Digital Worlds: Postcolonial Digital Humanities in Theory, Praxis, and Pedagogy</em> . Evanston, Illinois, US: Northwestern University Press.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Noyes, Jan. (1983)  “The QWERTY Keyboard: A Review.”    <em>International Journal of Man-Machine Studies</em>  18 (3): 265–81.&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>International Standards Organization. (2016)  “ISO/IEC 9995-9:2016 - Information Technology — Keyboard Layouts for Text and Office Systems — Part 9: Multi-Lingual, Multiscript Keyboard Layouts.”  ISO. 2016. <a href="https://www.iso.org/cms/render/live/en/sites/isoorg/contents/data/standard/05/43/54374.html">https://www.iso.org/cms/render/live/en/sites/isoorg/contents/data/standard/05/43/54374.html</a>.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Norman, Don, and Bruce Tognazzini. (2015)  “How Apple Is Giving Design A Bad Name.”    <em>Fast Company</em>  (blog). November 10, 2015. <a href="https://www.fastcompany.com/3053406/how-apple-is-giving-design-a-bad-name">https://www.fastcompany.com/3053406/how-apple-is-giving-design-a-bad-name</a>.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>mâmitoneyihcikanihkân – one Nehiyaw word for computer, meaning artificial brain.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>masinatakan cikastepayicikanis – another Nehiyaw word for computer. Roughly, a book or writing in a box of shadows.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Travers, Michael David. (1996)  “Programming with Agents: New Metaphors for Thinking About Computation.”  Doctor of Philosophy, Cambridge, MA: Massachusetts Institute of Technology.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Muzyka, Kyle. (2018)  “A Hawaiian Team’s Mission to Translate Programming Language to Their Native Language | CBC Unreserved Radio.”  CBC Unreserved Radio. November 30, 2018. <a href="https://www.cbc.ca/radio/unreserved/indigenous-language-finding-new-ways-to-connect-with-culture-1.4923962/a-hawaiian-team-s-mission-to-translate-programming-language-to-their-native-language-1.4926124">https://www.cbc.ca/radio/unreserved/indigenous-language-finding-new-ways-to-connect-with-culture-1.4923962/a-hawaiian-team-s-mission-to-translate-programming-language-to-their-native-language-1.4926124</a>.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>mînisiwat – a berry bag.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>âniskôsîpiy – where a river converges.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Shirt, Marilyn, and Tina Wellman, eds. (2022)  <em>Tânisîsi Kâ-Ôsîtahk Pîkiskwêwinisa : Morphology Dictionary</em> . St. Paul, AB: University nuhelot’ine thaiyots’i nistameyimâkanak Blue Quills.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Ogg, Arden. (2019)  “Hippopotamus in Cree: Solomon Ratt (y-Dialect).”    <em>Cree Literacy Network</em>  (blog). December 16, 2019. <a href="https://creeliteracy.org/2019/12/16/hippopotamus-in-cree-solomon-ratt-y-dialect/">https://creeliteracy.org/2019/12/16/hippopotamus-in-cree-solomon-ratt-y-dialect/</a>.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>atim, mistatim, acimosis, mistacimosis – dog, puppy, horse, pony; respectively&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>minôs wâpamew atimwa – the cat sees the dog.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>sîpiy, sîpiy kîsipayiw – river, and the river ends&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>pipon – winter&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>Nugent, Benjamin. (2008)  <em>American Nerd: The Story of My People</em> . Simon and Schuster.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Lewis Skolnick, portrayed by Robert Carradine, is one of the primary characters from the 1984 film  <em>Revenge of the Nerds</em> .&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Nasser, Ramsey. (2012)  “قلب (‘Qalb’).”  2012. <a href="https://nas.sr/%D9%82%D9%84%D8%A8/">https://nas.sr/%D9%82%D9%84%D8%A8/</a>.&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Miyâhkasike – to smudge with sweetgrass or sage.&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>pipona – winters (plural of pipon).&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p>waniyaw – random, or randomly.&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p>tisamân – to smudge (in general).&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:65">
<p>Noori, Margaret. (2011)  “Waasechibiiwaabikoonsing Nd’anami’aami,&quot; Praying through a Wired Window&quot;: Using Technology to Teach Anishinaabemowin.”    <em>Studies in American Indian Literatures</em>  23 (2): 1–23.&#160;<a href="#fnref:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:66">
<p>L’Hirondelle, Cheryl. (2014)  “Codetalkers Recounting Signals of Survival.”  In  <em>Coded Territories: Tracing Indigenous Pathways in New Media Art</em> , edited by Steven Loft and Kerry Swanson, 147–68. Calgary, AB: University of Calgary Press.&#160;<a href="#fnref:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:67">
<p>Lewis, Jason Edward, Noelani Arista, Archer Pechawis, and Suzanne Kite. (2018)  “Making Kin with the Machines.”    <em>Journal of Design and Science</em> . <a href="https://doi.org/10.21428/bfafd97b">https://doi.org/10.21428/bfafd97b</a>.&#160;<a href="#fnref:67" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:68">
<p>pipohki, awasipipon, mesakwanipipon – next winter, last winter, every winter; respectively.&#160;<a href="#fnref:68" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:69">
<p>Quinn, Ruben. (2021)  “Intermediate ᓀᐦᐃᔭᐤ Language Lessons.”  Zoom Course.&#160;<a href="#fnref:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:70">
<p>mihcecis, mihcet, mihcetinwa – a few, many, a lot; respectively.&#160;<a href="#fnref:70" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Introduction: Situating Critical Code Studies in the Digital Humanities</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000713/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/16/4/000647/?utm_source=atom_feed" rel="related" type="text/html" title="Digital Humanities Inside Out: Developing a Digital Humanities Curriculum for Computer Scientists in Singapore"/><link href="https://rlskoeser.github.io/dhqwords/vol/16/2/000613/?utm_source=atom_feed" rel="related" type="text/html" title="Rediscussing the Political Struggle in the Light of Reform in Late 11th Century China under the View of Digital Humanities"/><link href="https://rlskoeser.github.io/dhqwords/vol/15/3/000568/?utm_source=atom_feed" rel="related" type="text/html" title="Virtual museums as an extended museum experience: Challenges and impacts for museology, digital humanities, museums and visitors – in times of (Coronavirus) crisis"/><link href="https://rlskoeser.github.io/dhqwords/vol/14/4/000529/?utm_source=atom_feed" rel="related" type="text/html" title="Ticha: Collaboration with Indigenous communities to build digital resources on Zapotec language and history"/><link href="https://rlskoeser.github.io/dhqwords/vol/14/3/000464/?utm_source=atom_feed" rel="related" type="text/html" title="The Chili and Honey of Digital Humanities Research:The Facilitation of the Interdisciplinary Transfer of Knowledge in Digital Humanities Centers"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000713/</id><author><name>Mark C. Marino</name></author><author><name>Jeremy Douglass</name></author><published>2023-07-19T00:00:00+00:00</published><updated>2023-07-19T00:00:00+00:00</updated><content type="html"><![CDATA[<p>Almost two decades ago, at the start of Critical Code Studies (CCS), we asked two provocative questions:  “What does computer source code  <em>mean</em> ?”  and  “What do we discover when we read code with the interpretive tools of the humanities?”</p>
<p>At the 2006 MLA Convention in Philadelphia <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> where we launched <a href="https://electronicbookreview.com/essay/critical-code-studies/">the manifesto</a>, some humanities scholars in the audience asked whether reading code was a conversation better suited for a technology conference. Conversely, some computer scientists reacted to our endeavor by asking why English majors were reading code at all. Incidentally, that MLA panel was organized by Rita Raley and one of the speakers was John Cayley, both of whom are included in this collection, so you might say this first volume is a bit of a reunion — appropriately so, since from the beginning CCS was a collaborative project, inviting and requiring a diverse group of thinkers and makers.</p>
<p>On roads paved by cultural studies, semiotic analysis, science and technology studies, and media archaeology, we set out on the journey to understand code. Along the way we launched critical explorations — sometimes alone, but more often in groups. Since 2010 we have convened seven biennial gatherings of the Critical Code Studies Working Group ( “the major online think tank for critical code studies, a hub of dialogue and collaborative inquiry that generates major thrust in the reading of code.” ) Those multi-week gatherings gave rise to multi-author books such as  <em>10 PRINT CHR$(205.5+RND(1)); : GOTO 10</em>   <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, monographs such as  <em>Critical Code Studies</em>   <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, and numerous conference presentations and journal articles, including early publications in  <em>Digital Humanities Quarterly</em>  2013 <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> edited by Lisa Swanstrom and Jessica Pressman.</p>
<p>Following these initial publications, we are delighted to present this sequence of two Digital Humanities Quarterly special issues on Critical Code Studies as the latest scholarly work in the field. Their contributions extend and develop CCS through close readings of code and theoretical interventions, offering new methods of reading and interpretation while introducing new programming languages, expanding the scope of code studies even as they refine its methods and practices.</p>
<p>Critical code studies is the application of the hermeneutics of the humanities to the interpretation of the extra-functional significance of computer source code. Extra here does not mean outside of or apart from but instead it refers to a significance that is growing out of an understanding of the functioning of the code. While the <a href="https://electronicbookreview.com/essay/critical-code-studies/">initial manifesto</a> spoke of treating code as a text, in later clarification (<a href="https://hcommons.org/deposits/item/hc:19537/">https://hcommons.org/deposits/item/hc:19537/</a>), Mark has explained that text refers to a cultural object, rather than a collection of words and symbols. More significantly, if early definitions positioned the code object as the  <em>ends</em> , over time, the code has proven instead to be an entry point, a  <em>means</em>  to open up conversations about a wide variety of topics in techno-culture. This may be part of what drives the intersectionality of critical code studies with related subfields in cultural studies and technology. CCS is as much a field constituted by methods (code reading) as it is by particular objects of study (code), and as such it can provide new approaches into many areas of investigation; indeed, the revealed object of study is often not the code  <em>per se</em>  but instead the border,  the lunar lander program, et cetera.</p>
<p>Still, reading code, even <em>without</em> interpreting its cultural significance, can be no easy task. Ask a professional programmer who inherits legacy code to maintain or, worse yet, to improve, and they will tell you about the dread of sorting out just-in-time code, minimally documented, written with hasty patches, full of compromises and workarounds. Even those who write their code in artistic projects can be shy about sharing their code out of embarrassment and self-consciousness. This shame is a product of the  “encoded chauvinism”  of programming culture, one that can be fostered on the internet as much as it is in classrooms <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<p>Trying to interpret code, in the humanities sense of interpretation, compounds the challenge of reading code, which may be why scholars so often eschew the attempt. In spite of the groundwork we have tried to lay in the form of methods and models, workshops and working groups, most essays and books about software objects either tend to present code writing in functional and utilitarian terms from computer science / software engineering perspectives or else tend merely to gesture toward the existence of code from humanities / social sciences / cultural studies perspectives — but rarely to analyze it. Surely, the task can be arduous. Even we editors have admitted to feeling a sense of doubt when faced with a new code object to interpret, wondering whether an examination will lead anywhere at all. In our classrooms, both of us have discovered the challenges of teaching students how to engage in the practice. The daunting challenge of interpreting code is part of what makes this collection such a milestone.</p>
<h2 id="origins--extensions">Origins &amp; Extensions</h2>
<p>Critical code studies grew out of a moment when many interconnected groups of scholars were bringing new forms of attention to digital and computational objects. The namings of multiple new groups, organizations, journals, conferences, and subfields in the period around ~1999-2009 were often both sudden emergences and simultaneously culminations: electronic literature,  game studies,  software studies,  platform studies,  digital humanities and more were all ascendent at this time.</p>
<p>For years, scholars such as Jay David Bolter, George Landow, Kathleen Fitzpatrick, Paul Saint-Amour, Janet Murray, and Brenda Laurel had examined the new media forms of literary hypertext and digital theatre. The Electronic Literature Organization was founded in 1999, organizing conferences and ELC digital literary anthologies around bringing sustained critical attention to digital literary objects. In Game Studies, Espen Aarseth’s  <em>Cybertext: Perspectives on Ergodic Literature</em>  (1997), Gonzalo Frasca’s  “ludology”  (1999), the new journal of  <em>Game Studies</em>  (2001), and the Digital Games Research Association (2003) brought a focus on the analysis of rules, procedures, and processes in (often digital) games.</p>
<p>After decades of humanities computing research, a new banner term digital humanities was popularized by the influential anthology  <em>A Companion to Digital Humanities</em>  (2004) edited Susan Schreibman, Ray Siemens, and John Unsworth, followed by the formation of The Alliance of Digital Humanities Organizations (ADHO) (2005) and thereafter its first issue of this journal,  <em>Digital Humanities Quarterly</em>  1.1 (2007) under editors Julia Flanders, Wendell Piez, and Melissa Terras. In the United States, funding through the NEH Digital Humanities Initiative (2006) / Office of Digital Humanities (2008) further helped DH become the organizing term for what would eventually become the DH big tent — incorporating two factions that Kathleen Fitzpatrick would describe as  “scholars who use digital technologies in studying traditional humanities objects and those who use the methods of the contemporary humanities in studying digital objects.”   <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<p>Within this broader scene, an additional crucial context for the emergence of critical code studies were the respective calls of both Lev Manovich ( <em>The Language of New Media</em> , 2001) and N. Katherine Hayles ( <em>Writing Machines</em> , 2002) for scholars to employ media-specific analysis to attend to unique features and material conditions, to develop new approaches more suited to these new and emerging forms. AS if in answer to those calls came a stampede of studies, including critical code studies, software studies, and platform studies. Software studies brought interdisciplinary attention to software systems and their social and cultural effects with The Software Studies Workshop (2006), Software Studies Initiative (2007), and the Softwhere Studies Workshop (2008), along with  <em>Software Studies: a Lexicon</em>  edited by Matthew Fuller <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. In 2006, Ian Bogost and Nick Montfort also announced the Platform Studies book series they would edit for the MIT Press <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> alongside their forthcoming  <em>Racing the Beam: The Atari Video Computer System</em> , and defined platform studies as investigating  “the relationships between the hardware and software design of computing systems and the creative works produced on those systems.”  Alongside these came the continued development of media forensics as practiced by Matthew Kirschenbaum (e.g.,  <em>Mechanisms: New Media and the Forensic Imagination</em> , <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>), and of media archaeology, whether by Kittler and his students or by Lori Emerson.</p>
<p>The development in critical reading practices has been attended by an expansion in the way programming itself is presented in works such as Nick Montfort’s introduction to  <em>Exploratory Programming for the Arts and Humanities</em>   <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> and in  <em>Code as Creative Medium</em>   <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> by Tega Brain and Golan Levin. Taking up questions of cultural meaning, Geoff Cox and Winnie Soon released their  <em>Aesthetic Programming</em>   <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> on Gitlab and invited readers to fork it, an invitation Mark took up with Sarah Ciston when they added a chapter of their own. We would also be remiss to omit Daniel Shiffman’s  <em>The Nature of Code</em>   <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>, which has become a staple for novice programmers.</p>
<p>The number of books examining the culture of programs has also increased, beginning with David Berry’s  <em>The Philosophy of Software</em>   <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. Furthermore, Annette Vee’s  <em>Coding Literacy: How Computer Programming is Changing Writing</em>  offers a cogent argument about the nature of programming knowledge <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>.  <em>Speaking Code: Coding as Aesthetic and Political Expression</em>  by Alex McLean and Geoff Cox offers a kind of duet with Cox reading McLean’s code and vice versa <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. Recent books have taken up subcultures of programming, such as  <em>Live Coding: a user&rsquo;s manual</em>   <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. Algorithms have received their own attention, as in Jeffrey M. Binder’s  <em>Language and the Rise of the Algorithm</em>   <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. More recently, James Brown’s  <em>Ethical Programs: Hospitality and the Rhetorics of Software</em>   <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> and Kevin Brock’s  <em>Rhetorical Code Studies</em>   <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> offered even more methods of interpreting code. Interpreting the code of a digital object has contributed to as a larger  <em>Reading Project</em>   <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>, our collaboration with Jessica Pressman, which includes an analysis of the source code and source files of William Poundstone’s <a href="https://collection.eliterature.org/1/works/poundstone__project_for_tachistoscope_bottomless_pit.html"> <em>Project for Tachistoscope {Bottomless Pit}</em> </a>  <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>.</p>
<p>As more critical attention takes up software, scholars have turned their attention to racial bias and software, following the work of pioneers such as Alondra Nelson. More recently Safiya Noble in  <em>Algorithms of Oppression</em>   <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> and Joy Buolamwini with her Algorithmic Justice League have worked to bring the topic of racial discrimination in software to the forefront. Ruha Benjamin has, likewise, traced out bias in code with her extension of race critical code studies <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. Historians are documenting the role of race in programming spaces in books such as Clyde W. Ford&rsquo;s  <em>Think Black: A Memoir</em>   <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> and with respect to gender as in Mar Hicks’  <em>Programmed Inequality</em>   <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>. micha cárdenas’  <em>Poetic Operations: Trans of Color Art in Digital Media</em>   <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> has examined algorithms with respect to trans of color. The social side of code and computers continues to be the subject of scholars as in the recent collection  <em>Your Computer is on Fire</em>   <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> and in the groundbreaking work of Wendy Chun.</p>
<p>At the same time, code poets have been publishing their code. Some examples include Nick Montfort’s  <em>#!</em>  (pronounced she-bang) and the  <em>The Truelist</em> , JR Carpenter’s  <em>Generation(s)</em> , Lillian-Yvonne Bertram’s  <em>Travesty Generator</em> , or Milton Laufer’s  <em>A Noise Such as a Man Might Make</em> . Code poets have played with code from the creole of  <em>mezangelle</em>  by Mez Breeze to the code poems of Margaret Rhee, collected in  <em>Love, Robot</em> . And for something completely different, Angus Croll’s  <em>If Hemingway Wrote Javascript</em>  offers humorous though insightful renditions of the writing styles of famous natural language creative writers (from Jane Austen to Virginia Woolf) adapted into programming languages <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>.</p>
<p>This may be an odd claim to make, but not everyone who writes about code is a (digital) humanities scholar. A collection called  <em>Beautiful Code: : Leading Programmers Explain How They Think</em>  asks programmers to discuss their favorite lines of code <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>. In  <em>Once Upon an Algorithm</em>   <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>, Martin Erwig offers lessons in programming in the language of storytelling. Books about the cultural meaning of code surely go back to Don Knuth’s  <em>Literate Programming</em>   <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup> and even  <em>The Structure and Interpretation of Computer Programs</em>   <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>. Though these authors might not write in the language of critical theory or hermeneutics, the vast insight from their works, drawn out of lifetimes of work in the field of programming and computer science, continue to direct and instruct critical code studies.</p>
<p>In addition to these special issues of DHQ, scholars can look to a number of collections of publications on  <em>electronic book review</em> , which has been a major outlet for critical code studies since its inception. There, readers can find write-ups and overviews from some of the CCS Working Groups. Among other postings are the overview of <a href="https://electronicbookreview.com/essay/critical-code-studies-and-the-electronic-book-review-an-introduction/">the original working groups</a>, the weekly discussions from 2010 (<a href="https://electronicbookreview.com/essay/critical-code-studies-conference-week-one-discussion/">1</a>, <a href="https://electronicbookreview.com/essay/critical-code-studies-conference-week-two-discussion">2</a>, <a href="https://electronicbookreview.com/essay/critical-code-studies-conference-week-three-discussion/">3</a>, <a href="https://electronicbookreview.com/essay/critical-code-studies-conference-week-four-discussion/">4</a>, <a href="https://electronicbookreview.com/essay/critical-code-studies-conference-week-five-discussion/">5</a>). In <a href="https://electronicbookreview.com/gathering/gathering-critical-code-studies-working-group-2020/">2020</a>,  <em>ebr</em>  published <a href="https://electronicbookreview.com/essay/tldr-lessons-from-ccswg-2020/">an overview</a>, and intros to weekly discussions <a href="https://electronicbookreview.com/essay/week-one-introduction-to-critical-code-studies/">re-introducing CCS</a>, <a href="https://electronicbookreview.com/essay/week-two-indigenous-programming/">Indigenous Programming</a>, and <a href="https://electronicbookreview.com/essay/week-three-feminist-ai/">Feminist AI</a>. Of course,  <em>electronic book review</em>  was also the publication of the <a href="https://electronicbookreview.com/essay/critical-code-studies/">original manifesto</a>.</p>
<p>These special issues of DHQ are the first fruits of our work to foster the development of critical code studies through conference presentations and biennial working groups over these past two decades. Over the course of the seven working groups so far, participants have conducted fruitful investigations into several bodies of code, from Joseph Weizenbaum’s ELIZA to William Crowther’s ADVENTURE. More recent working groups have looked at the code for the Apollo Moon Lander. We have taken up issues of race and gender, creative coding and the ethics of code. We have explored platforms for annotating code, from repositories to annotation tools on Google Docs and ANVC Scalar. Scalar itself has served in readings of the <a href="https://scalar.usc.edu/nehvectors/border-codes/index">Transborder Immigrant Tool</a> and <a href="https://thedigitalreview.com/issue02/marino_entanglements/index.html">FISHNETSTOCKINGS</a>. And we have speculated about alternatives to dominant models of code, as in our discussions of feminist AI and a feminist programming language. Every working group takes up new themes, as the international group of scholars, artists, and programmers, and every combination therein post code critique threads to see what could be said about a menagerie of objects made out of code.</p>
<p>We continue to develop new venues for critical code studies practices as well. In the past three years, we have launched an Anti-Racist Critical Code Studies Reading Group, inspired by the work of Noble, Benjamin, and Buolamwini, as well as the Knit&amp;Perl group co-organized with Anne Sullivan and Anastasia Salter, a sewing circle of scholars which looks at the intersection of coding and stitchcraft or the fibre arts <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. We have also launched a subgroup of the Humanities and Critical Code Studies (HaCCS) Lab that advocates for the public release of code (such as predictive policing code) that affects, governs, and shapes the lives of citizens. This new group is called the Sunshine Source Force, drawing its name from the movement for legal transparency, known as the Sunshine Laws. Surely, new initiatives are on the horizon.</p>
<p>Code is never one thing and is as dynamic as any semiotic form, constantly in flux. As we write this, machine-learning code generators, such as Github’s Copilot, are emerging as a major part of programming assistance even as LLMs also assist essay writing. We suspect, and our recent experiments have confirmed that suspicion, that they will also offer assistance in the interpretation of code. Like the seas of natural language, the ecology of computer source code is constantly shifting and so there is always a need for more reading practices and, of course, a wider and more diverse set of scholarly and creative minds embarking on this endeavor.</p>
<h2 id="in-this-issue">In this issue</h2>
<p>Before you is the first special collection of critical code studies readings. This landmark publication, offered in the first of two issues, presents a variety of interpretations and theoretical reflections that apply and extend the methods of critical code studies and also offer a resource for scholars looking for models of what these readings can accomplish. In addition to demonstrating established methods and best practices, scholars in this issue offer new and nuanced approaches to a wide range of code objects as well as developing new approaches, expanding the realm of what can be analyzed through critical code studies — accompanied by in-depth readings performed by top scholars in the field. This first issue presents three groupings of articles: 1) exemplary close readings of code, 2) new directions in critical code studies (such as code legibility and Critical AI), and 3) new work in programming languages and linguistics (including esoteric programming languages and indigenous programming languages).</p>
<p>First, this issue contains exemplary close readings of code. In  “Reverse Engineering the Gendered Design of Amazon’s Alexa: Methods in Testing Closed-Source Code in Grey and Black Box Systems,”  Lai-Tze Fan examines the gendered design of Amazon Alexa’s voice-driven capabilities, or, skills, (despite closed source impediments) in order to better understand how Alexa, as an AI assistant, mirrors traditionally feminized labour and sociocultural expectations. In  “BASIC FTBALL for Everyone and Computer Programming for All,”  Annette Vee puts the 1965 BASIC program FTBALL in the historical, cultural, gendered context of  “computer programming for all”  while gesturing to the tension between a conception of all and FTBALL’s context in an elite, all-male college in the mid-1960s. In  “Computational art Explorations of Linguistic Possibility Spaces: comparative translingual close readings of Daniel C. Howe’s Automatype and Radical of the Vertical Heart 忄,”  John Cayley elaborates a comparative, transculturally implicated, code-critical close reading of two related works, by Daniel C. Howe, which explore linguistic possibility spaces in English and Chinese. This reading engages distinct and code-critically significant programming strategies, and underappreciated comparative linguistic concepts with implications for the theory of writing systems, of text, and of language as such. In  “ “Any Means Necessary to Refuse Erasure by Algorithm:”  Lillian-Yvonne Bertram’s Travesty Generator,”  Zach Whalen creates an expansive reading of Bertram’s  “challenging, haunting, and important achievement of computational literature”  while digging more broadly and deeply into how specific poems work to better appreciate the collection&rsquo;s contribution to the field of digital poetry. In  “Poetry as Code as Interactive Fiction: Engaging Multiple Text-Based Literacies in  <em>Scarlet Portrait Parlor</em> ,”  Jason Boyd examines how various text-based literacies (procedural, poetic, ludic) can, when used together, elucidate the meanings of an Inform7-programmed interactive fiction in the form of a sonnet. This examination suggests how critical code studies may engage in more nuanced discussions of natural language programming.</p>
<p>Second, this issue contains new directions in critical code studies, pursuing areas such as machine learning software and the limits of code, non-code, and  “nonsense code” . In  “How to Do Things with Deep Learning Code,”  Minh Hua and Rita Raley consider the feasibility and critical potential of CCS as a method when the object of study is deep learning code. Calling for a  “critical urgent”  need for basic understanding of the composition and functioning of large language models, they extract a representational map of OpenAI’s GPT-2 which they then verify through case studies of two popular GPT-2 applications: the text adventure game,  <em>AI Dungeon</em> , and the language art project,  <em>This Word Does Not Exist</em> . In  “Tracing  Toxicity  Through Code: Towards a Method of Explainability and Interpretability in Software,”  David M. Berry examines how we can use concepts of explainability and interpretability drawn from computer science in critical code studies. By examining a set of code artifacts, the paper looks at how following conceptual traces in concrete source code layers can contribute to understanding and explaining them. In  “Nonsense Code: A Nonmaterial Performance” , Barry Rountree and William Condee analyze three case studies in which a literal reading of each program’s code is effectively nonsense; however, the programs generate meaning in performance. Using the framework of nonmaterial performance (NMP) and its four tenets (code abstracts, performs, acts within a network, and is vibrant), they consider the 1950s UNIVAC 1  “Happy Birthday,”  the Firestarter processor stress test, and the Platypus family of side-channel attacks to decenter text from its privileged position and to recenter code as a performance.</p>
<p>Finally, we offer reflections on code, language, and linguistics, particularly esoteric and indigenous programming languages. In  “ᐊᒐᐦᑭᐯᐦᐃᑲᓇ ᒫᒥᑐᓀᔨᐦᐃᒋᑲᓂᐦᑳᓂᕽ | acahkipehikana mâmitoneyihicikanihkânihk | Programming with Cree# and Ancestral Code: Nehiyawewin Spirit Markings in an Artificial Brain,”  Jon Corbett discusses his project  “Ancestral Code,”  which consists of an integrated development environment (IDE) and the Nehiyaw (Plains Cree) based programming languages called Cree# (pronounced: Cree-Sharp) and ᐊᒋᒧ (âcimow). These languages developed in response to western perspectives on human-computer relationships, which Corbett challenges and reframes in Nehiyaw/Indigenous contexts. In  “The Less Humble Programmer,”  Daniel Temkin explores the aesthetics of how esoteric programming languages (esolangs) break from the norms of language design by explicitly refusing practicality and clarity. Through examples that make code disordered (e.g., Malboge) or even impossible to write (e.g., Unnecessary), esolangs may challenge or reaffirm wider ideas in programming culture and in how computer science is taught: specifically the sometimes-contradictory aesthetics of humbleness and computational idealism.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>We are grateful to our tireless authors, reviewers, and editors, as well as to  <em>Digital Humanities Quarterly</em>  for their support of critical code studies through these special issues. We are excited to see what they inspire!</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<pre><code>“Program of the 2006 Convention” .  _PMLA_ , vol. 121, no. 6, 2006, pp. 1801–2000.   
</code></pre>
&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:2">
<p>Montfort, Nick, et al.  <em>10 PRINT CHR$(205.5+RND(1)); : GOTO 10</em> . The MIT Press, 2013.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Marino, Mark C.  <em>Critical Code Studies</em> . The MIT Press, 2020.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Marino, Mark C.  <em>Code as Ritualized Poetry: The Tactics of the Transborder Immigrant Tool</em> .  <em>Digital Humanities Quarterly</em> , no. 1, 2013. <a href="/dhqwords/vol/7/1/000157/">http://www.digitalhumanities.org/dhq/vol/7/1/000157/000157.html</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Fitzpatrick, Kathleen.  “The Humanities, Done Digitally.”    <em>The Atlantic</em> , May 8, 2011. <a href="https://archive.ph/FNyko">https://archive.ph/FNyko</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Fuller, M. ed., 2008.  <em>Software Studies: a lexicon</em> . The MIT Press.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Bogost, Ian and Nick Montfort. Platform Studies website. 2006. <a href="#http://platformstudies.com/">http://platformstudies.com/</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Kirschenbaum, M.G., 2012.  <em>Mechanisms: New Media and the Forensic Imagination</em> . The MIT Press.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Montfort, Nick.  <em>Exploratory Programming for the Arts and Humanities</em> . 1 edition, The MIT Press, 2016.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Levin, Golan, and Tega Brain.  <em>Code as Creative Medium: A Handbook for Computational Art and Design</em> . Annotated edition, The MIT Press, 2021.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Soon, Winnie, and Geoff Cox.  <em>Aesthetic Programming: A Handbook of Software Studies</em> . Open Humanities Press, 2021.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Shiffman, Daniel.  <em>The Nature of Code: Simulating Natural Systems with Processing</em> . 1st edition, The Nature of Code, 2012.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Berry, David M. (David Michael).  <em>The Philosophy of Software: Code and Mediation in The Digital Age</em> . Palgrave Macmillan, 2011.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Vee, Annette.  <em>Coding Literacy: How Computer Programming Is Changing Writing</em> . The MIT Press, 2017.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Cox, Geoff, and Alex McLean.  <em>Speaking Code: Coding as Aesthetic and Political Expression</em> . The MIT Press, 2013.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Blackwell, Alan F., et al.  <em>Live Coding: A User’s Manual</em> . The MIT Press, 2022.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Binder, Jeffrey M.  <em>Language and the Rise of the Algorithm</em> . First edition, University of Chicago Press, 2022.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Brown, James J., Jr.  <em>Ethical Programs: Hospitality and the Rhetorics of Software</em> . U OF M Digt Cult Books, 2015.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Brock, Kevin.  <em>Rhetorical Code Studies: Discovering Arguments in and around Code</em> . University of Michigan Press, 2019.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Pressman, Jessica, et al.  <em>Reading Project: A Collaborative Analysis of William Poundstone’s Project for Tachistoscope {Bottomless Pit}</em> . 1 edition, University Of Iowa Press, 2015.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Poundstone, W. (2005)  <em>Project for Tachistoscope {Bottomless Pit}</em> . Electronic Literature Collection.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Noble, Safiya Umoja.  <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em> . Illustrated edition, NYU Press, 2018.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Benjamin, Ruha.  <em>Race After Technology: Abolitionist Tools for the New Jim Code</em> . 1st edition, Polity, 2019.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Ford, Clyde W.  <em>Think Black: A Memoir</em> . Amistad, 2019.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Hicks, Marie.  <em>Programmed Inequality: How Britain Discarded Women Technologists and Lost Its Edge in Computing</em> . 1st edition, The MIT Press, 2017.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>cárdenas, micha.  <em>Poetic Operations: Trans of Color Art in Digital Media</em> . Duke University Press Books, 2022.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Mullaney, Thomas S., et al., editors.  <em>Your Computer Is on Fire</em> . MIT Press, 2021, <a href="https://doi.org/10.7551/mitpress/10993.001.0001">https://doi.org/10.7551/mitpress/10993.001.0001</a>.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Croll, Angus.  <em>If Hemingway Wrote JavaScript</em> . No Starch Press, 2014.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Oram, A. and Wilson, G., 2007.  <em>Beautiful Code: Leading Programmers Explain How They Think</em> . O’Reilly Media, Inc.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Erwig, Martin.  <em>Once Upon an Algorithm: How Stories Explain Computing</em> . The MIT Press, 2017.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Knuth, D.E. (1992)  “Literate Programming.”  Number 27 in CSLI Lecture Notes.  <em>Center for the Study of Language and Information</em> , pp.349-358.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Knuth, D.E., 1984.  “Literate programming.”    <em>The Computer Journal</em> , 27(2), pp.97-111.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Salter, Anastasia, and Anne Sullivan.  “Week 2: Of Textiles and Technology - Discussion Starter” .  <em>2022 CCS Working Group</em> , 29 Jan. 2022, <a href="https://wg.criticalcodestudies.com/index.php?p=/discussion/113/week-2-of-textiles-and-technology-discussion-starter">https://wg.criticalcodestudies.com/index.php?p=/discussion/113/week-2-of-textiles-and-technology-discussion-starter</a>.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Bias in Big Data, Machine Learning and AI: What Lessons for the Digital Humanities?</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000689/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000689/</id><author><name>Andrew Prescott</name></author><published>2023-07-07T00:00:00+00:00</published><updated>2023-07-07T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>In 2015, I attended a workshop in Washington DC which was among the first to focus on big data in the humanities and social sciences. One of the keynote presentations was by Tom Schenk, then Chief Data Officer for the City of Chicago and the co-founder of the Civic Analytics Network at Harvard University&rsquo;s Ash Center for Democratic Governance and Innovation. Under Tom&rsquo;s leadership, Chicago was at the forefront of use of open government data to improve provision of civic services <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Chicago developed a pioneering open data portal which gave public access to hundreds of data sets <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. This data had been used to generate maps and visualisations of evident value to Chicago&rsquo;s citizens, such as maps showing where flu vaccinations were available or which restaurants had al fresco dining licences.</p>
<p>Particularly striking was the use in Chicago of data analytics to make predictions which either warned of potential danger or allowed the city to make better use of resources. Predictive analytics programs were developed which identified properties in the city at greatest risk of rodent infestation. This enabled rodent baiting resources to be focussed on particular areas and in 2013 resident complaints about rodents dropped by 15% <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Another programme used predictive analytics to improve forecasts about the risk of e-coli infection on Chicago&rsquo;s beaches <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. One of the most successful of the Chicago projects forecasted the risk of a particular restaurant failing a hygiene inspection. This enabled the city to concentrate the efforts of its small team of food hygiene inspectors on those premises where there was a greater likelihood of finding problems <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>  <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. This model was in turn used for epidemiological investigation of food poisoning outbreaks <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>As Tom&rsquo;s description of the use of predictive analytics in Chicago and other American cities proceeded, however, I felt increasingly uneasy. In New York, predictive analytics were being used to identify which properties were more likely to have illegal flat conversions <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. While this has many benefits such as reducing fire risk, it was difficult to escape a feeling that data analytics were being used for greater control of poorer sections of the community. My worries became greater when I later learned about the growing use of data analytics in policing. In Chicago, the police deployed a proprietary technology called ShotSpotter which uses sound sensors across large areas of the city which register where gunshots occur. Another proprietary technology called Hunchlab then used ShotSpotter data to identify localities most likely to have gun crime, enabling police to concentrate resources in those areas. The city has claimed that these technologies reduced crime in the worst districts by about 24%, but these figures are disputed and it seems that the number of crimes detected only by use of ShotSpotter is very small <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. Predictive policing packages such as ShotSpotter and Hunchlab seem in many ways to be simply a means by which police bear down even more heavily on the poorest and most deprived communities.</p>
<p>In the past five years, the growth of predictive analytics has expanded massively and become even more powerful as it has become linked to machine learning and artificial intelligence (AI). A number of widely publicised cases of bias in AI have confirmed the misgivings I felt as I heard Tom Schenk talk in 2015. It has become evident that AI has the potential to reinforce existing inequalities and injustices. Used carelessly, AI can be a tool to propagate racism, sexism and many other forms of prejudice <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>  <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. Tay, the experimental AI chatbot launched by Microsoft in 2016, was within a matter of hours taught to spout racist tweets praising Adolf Hitler <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. In 2015, it was pointed out that Google Photos had labelled pictures of a black man and his friends as gorillas  <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. An article in Bloomberg showed how the algorithms determining whether Amazon offers same day delivery frequently excluded postcodes with a significant black population <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. An attempt by Amazon to use AI to automatically rank candidates for software development jobs was abandoned after the system systematically excluded women and produced male-only shortlists. Because of the dominance of men in computing, the system taught itself that male candidates were preferable. It downgraded graduates of all-women colleges and penalised resumes that included the word women in any context <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>.</p>
<p>This article will survey issues of race and gender bias in AI and consider how these may affect the digital humanities. It will make preliminary suggestions as to how practitioners of the digital humanities can help address these disturbing problems. The digital humanities has begun to experiment with the use of AI. Some of these initial applications are in areas where algorithmic bias could potentially present problems, such as the automated analysis of draft legislation and identification of people in archives. As the digital humanities engage more with machine learning and AI, it is likely that use will be made of some tools and methods which caused the sort of biased results which have recently received such bad publicity. Moreover, many humanities scholars and memory institutions are heavily dependent on commercial tools such as Google Images and any suggestion that there is bias in these tools could have serious implications for wider scholarship in the humanities.</p>
<p>Sadly, the days when we might hope that there could be objective tools free from social or cultural bias have vanished, if indeed they ever existed. Information itself has become a site of political contention as significant as gender or race <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> and the political impact of large-scale machine learning tools should be an issue of central concern in the digital humanities. With its tradition of social and cultural activism, digital humanities has great potential to contribute to more ethical approaches to AI and this may be that this is an area in which digital humanities can reshape pervasive digital modern cultures <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>.</p>
<h2 id="the-enchantment-of-big-data-and-ai">The Enchantment of Big Data and AI</h2>
<p>Much of the hype around big data in the early part of the last decade derived from claims that new analytic techniques run on more powerful machines enabled useful scientific findings to emerge spontaneously by observing co-relations in very large and messy datasets. It was suggested that if a dataset was large enough it would compensate for gaps and structural inconsistencies in the data. This stress on observing co-relations was said to be driving an epistemological shift in which there was less emphasis on exactitude and was characterised by the abandonment of a preoccupation with causality ( <em>why</em> ) in favour of finding co-relations ( <em>what</em> ). The importance of letting the data speak for itself was stressed <sup id="fnref1:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>The manifesto for such data-driven methodologies was a notorious article in Wired by Chris Anderson <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> in which he declared the end of theory and suggested that traditional scientific method was obsolete:</p>
<blockquote>
<p>There is now a better way. Petabytes allow us to say: Correlation is enough. We can stop looking for models. We can analyze the data without hypotheses about what it might show. We can throw the numbers into the biggest computing clusters the world has ever seen and let statistical algorithms find patterns where science cannot<br>
<sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>.</p>
</blockquote>
<p>Objections to Anderson&rsquo;s provocation quickly appeared. It was observed that the predictive analytics used in big data were themselves founded on statistical and mathematical theories <sup id="fnref2:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. Callebaut pointed out that Anderson had misrepresented the role of modelling in biological research and reminded Anderson of Darwin&rsquo;s dictum that  “all observation must be for or against some view if it is to be of any service”   <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. Above all, the idea that raw data represents an objective factual quarry is an illusion:  “raw data is both an oxymoron and a bad idea”   <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>.</p>
<p>Despite these objections, the idea that new insights can somehow magically emerge from co-relations observed in very large amounts of data has carried over into AI. The computer scientist Stuart J. Russell has commented that:</p>
<blockquote>
<p>We are just beginning now to get some theoretical understanding of when and why the deep learning hypothesis is correct, but to a large extent, it&rsquo;s still a kind of magic, because it really didn&rsquo;t have to happen that way. There seems to be a property of images in the real world, and there is some property of sound and speech signals in the real world, such that when you connect that kind of data to a deep network it will – for some reason – be relatively easy to learn a good predictor. But why this happens is still anyone&rsquo;s guess<br>
<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>.</p>
</blockquote>
<p>This emphasis on the magic of AI has led Alexander Compolo and Kate Crawford <sup id="fnref1:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> to compare much discussion of AI with alchemy, the magical properties of algorithms generating what they call  “enchanted determinism” . This delight in  “enchanted determinism”  also encourages subjective responses to data.</p>
<h2 id="the-importance-of-explainability">The Importance of Explainability</h2>
<p>These problems are compounded by the fact that so much AI development is in the hands of commercial companies, with Silicon Valley corporations dominating. Much AI implementation is commercial and the owners of proprietary algorithms are unwilling to explain their business secrets. A great deal can be achieved by reverse engineering algorithms. Nevertheless, it can be very difficult to establish the extent and nature of bias in commercial packages, so that suspicion of prejudice lingers. Silicon Valley companies will react quickly to address criticism but information about exactly how this is done is often sketchy. A great deal can be achieved by reverse engineering algorithms. Nevertheless, it can be very difficult to establish the extent and nature of bias in commercial packages, so that suspicion of prejudice lingers. The default position should perhaps be to regard all commercial AI packages that are not fully documented as biased against particular groups.</p>
<p>Google very quickly changed its search engine in response to the devastating criticisms of Safiya Umoja Noble who meticulously documented how searches on Google in 2011 for black girls and white girls produced shocking results reflecting racist and sexist stereotypes,<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> but details of how Google approached these criticisms are unclear. Sometimes, the response to these issues can be very crude and makes matters worse. Google&rsquo;s reaction to the adverse publicity around the way images of black men were labelled as gorillas in Google Photos was to censor the tags, so that no images are ever labelled gorilla, chimpanzee or monkey, even if they are pictures of the primates themselves. Similarly, when a picture of a black man was labelled as an ape on Flickr, the term was removed from its tagging lexicon <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>.</p>
<p>In order to break away from the view of AI as somehow magical and resist the secretive nature of Big Tech, a greater emphasis on explainability – on documenting and discussing the assumptions behind modelling, how this feeds through into algorithms and the properties of the data used – is of vital importance. An insistence on explainability is one of the most important weapons against algorithmic bias. Rob Kitchin identifies two major epistemological approaches to big data in the scientific community <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. On the one hand, those proclaiming the  “end of theory”  argue that the focus should be on observing surface patterns or anomalies in the data, a highly empirical approach which Kitchen linked to abductive reasoning, a form of logical inference starting with observation of unusual or distinctive patterns and then seeking the simplest explanation. Such an approach creates a high risk of uncritical or superficial analyses of data. On the other hand, other researchers propose that a data-driven science offers the opportunity for creating more holistic and fine grained analyses of very large data sets which can facilitate and foster more critical approaches to data. In investigating the roots of bias in AI, it is essential to adopt this second approach and explore the ways in which models, algorithms and data are constructed. We cannot understand how AI tools share and amplify human prejudices unless we look at the way the data and tools have been created.</p>
<p>It is oversimplistic to assume that prejudice in AI arises simply from poorly constructed algorithms. Bias can be generated by a number of factors, including the quality of data and the nature of the algorithm used. Some of the strategies used can be counterintuitive. It might be assumed that a probabilistic algorithm is more likely to embody faulty cultural assumptions and wrongly identify data concerning black and minority ethnic (BAME) populations than a deterministic algorithm requiring more precise data. However, because UK BAME data is more likely to be variable in quality, with spellings of names and locations inaccurately entered, it turns out that a probabilistic algorithm will be less biased in dealing with BAME data. This can be seen from the linking of UK National Health Service (NHS) records. In order to track the progress of individual patients in the NHS, it is necessary to link records of hospital admissions. A proprietary algorithm called HESID (Hospital Episodes ID) is used to do this. HESID information is used to help calculate commissioning of resources for NHS hospitals. HESID is a deterministic algorithm which requires precise data for such fields as NHS number, date of birth and postcode in order to match names. An analysis of HESID however found that it missed 4.1% of links and made false matches in 0.2% of cases. Moreover, it was ethnic minority patients (Black, Asian, Other) who were disproportionately affected by these missed links. The reasons for this were largely due to the way in NHS numbers were allocated <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>.</p>
<p>In fact, a probabilistic algorithm would have been a far better choice for dealing with data of such variable quality of hospital admission records. A study investigated a probabilistic algorithm which enabled records to be linked when NHS numbers were missing by calculating the probability of a person being the same if other types of information agreed. Use of a probabilistic algorithm substantially reduced the number of missed matches, with particularly beneficial results for ethnic minorities and deprived groups. In the case of emergency hospital admissions for black patients from 1998-2003, the deterministic algorithm missed 7% of matches; the probabilistic algorithm reduced this to 2.3% missed matches. Likewise, in the case of patients from highly deprived socio-economic groups, the deterministic algorithm missed 6.8% of matches, whereas the probabilistic link missed 2.2% <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>. The use by the NHS of a deterministic algorithm was doubtless intended to ensure greater precision, but the probabilistic algorithm produced better results. These NHS case studies illustrate the importance of testing a range of different methods and tools and not assuming that one method is inherently superior to the other. Moreover, the results of these testing processes need to be openly available and not constrained by commercial confidentiality, as was the case with the NHS HESID system.</p>
<p>The NHS example illustrates how the most effective way of addressing racial and gender bias in AI and machine learning is by digging down into the way the data and tools function and then explaining it. Digital humanities is very well placed to play a major part in developing the explainability of AI. However, much AI implementation is commercial and the owners of proprietary algorithms are unwilling to explain their business secrets. A great deal can be achieved by reverse engineering algorithms, as the analysis above of the HESID algorithm shows. Nevertheless, without explainability, we cannot be sure if the package is biased.</p>
<p>The problems caused by the lack of explainability in a commercial AI package are further illustrated by the commercial COMPAS system used in the United States to assess the risk of prisoners reoffending. The use of predictive analytics in policing and the judicial system is particularly contentious. Many American judges, probation and parole officers make use of actuarial risk assessment instruments which automatically calculate the risk of a convict committing another offence after release. There are many of these assessment packages in use. There have been a number of studies that suggest these systems consistently give higher risk scores for black offenders, but it has never been established how the apparent bias occurs <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>.</p>
<p>In 2016, Pro Publica published a detailed analysis of COMPAS, one of the two commercial packages to assess recidivism <sup id="fnref1:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>. The study concluded that for violent recidivism:</p>
<blockquote>
<p>Black defendants were twice as likely as white defendants to be misclassified as a higher risk of violent recidivism, and white recidivists were misclassified as low risk, 63.2 percent more often than black defendants.<br>
This seemed to be a clear demonstration of algorithmic bias. However, a rejoinder was rapidly published which pointed to flaws in the Pro Publica analysis. In particular, the Pro Publica analysis used a data set of pre-trial defendants whereas COMPAS was designed to assess the risk of convicted defendants re-offending. Moreover, COMPAS assigned recidivism risk into three categories (low, medium and high) but the Pro Publica article lumped medium and high together as high risk. It was argued that there was no clear evidence of bias in the COMPAS algorithm <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. A further study suggested that COMPAS was no more accurate and fair than predictions made by people with little or no criminal justice expertise which raises the question of whether it is worthwhile using this package, aside from any question of bias <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>  <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>. It seems likely that the issues with these packages lie not so much in the tools themselves as in the classifications and data produced by the judicial system, particularly the classification of racial types <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>.</p>
</blockquote>
<p>The disagreements about COMPAS illustrate why many of the problems in addressing algorithmic bias lie in the predominance of commercial packages and their lack of explanability. Although a company like Northpointe is comparatively small, it is nevertheless difficult to assess what is going on, even in a small-scale package like COMPAS. Scaling up explanability to analyse the operations of Google or Amazon is almost impossible to imagine. Yet we need to break open the black box if we are going to ensure that AI does not simply amplify and reinforce existing injustices and inequalities.</p>
<p>The performance of HESID and COMPAS is comparatively straightforward to analyse. More difficult is to assess the effect of algorithmic bias in natural language processing. A number of studies have documented how natural language processing can absorb human biases from training sets. Word embeddings trained on corpora such as newspaper articles or books exhibit the same prejudices as are evident in the training data. Word embeddings trained on Google news data complete the sentence Man is to computer programmer as woman is to X with the word homemaker  <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>. Another study used association tests automatically to categorise words as having pleasant or unpleasant associations. According to the allocations generated by the algorithm, a set of African American names had more unpleasantness associations than a European American set. The same machine learning programme associated female names more with words like parent and wedding whereas male names had stronger associations with such words as professional and salary  <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> .</p>
<p>Since NLP lies at the root of many services we use every day, these gender and racial biases are imported into tools such as Google Translate. A notorious example was the way in which Google Translate initially dealt with neutral third person pronouns in languages such as Turkish, Hungarian and Finnish. Until recently, Google Translate rendered the Turkish sentences o bir doktor and o bir hemşire into English as he is a doctor and she is a nurse and the Hungarian ō egy ápoló as she is a nurse, despite the fact that the pronouns are not gender specific <sup id="fnref1:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>  <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. This has now been corrected by Google and alternative pronouns are offered in the translation <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>. The Facebook translation service can also be problematic. A Palestinian was arrested by Israeli police because Facebook&rsquo;s AI translation service wrongly translated the Arabic words for good morning as hurt them in English or attack them in Hebrew <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>. Bias is also evident in other forms of linguistic analysis. In a test of gender and race bias in sentiment analysis systems, it was found that African American names scored higher in anger, fear and sadness, and European American names scored higher on emotions such as joy <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>. The social media filter  <em>Perspective</em>  developed by a Google-backed incubator marks innocuous African American vernacular phrases as rude and categorised the statement I am a gay black woman as 87% toxic <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>.</p>
<p>In such cases as the problem of the gender-neutral pronoun, companies like Google are quick to try and correct blatant examples of prejudice when reported by researchers. But the methods used to try and correct such problems are often crude and create as many problems as they solve. The most common method is to implement a blacklist of banned words and concepts. This was the method used to deal with the problems of Microsoft&rsquo;s ill-fated chatbot,  <em>Tay</em> . A few months after  <em>Tay</em>  was taken down, Microsoft launched a replacement,  <em>Zo</em> , which ran until summer 2019.  <em>Zo</em>  was told to shut done the conversation if words like the Middle East, Jew or Arab were mentioned. However, this was done without reference to context, so that a statement like That song was played at my bah mitzvah elicited the response ugh, pass, I&rsquo;d rather talk about something else. Because of the concern to ensure  <em>Zo</em>  was not taught to attack Jews, Microsoft ended up giving the distinct impression that  <em>Zo</em>  was anti-semitic <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>.</p>
<p>Many of issues of bias in AI arise from the way in which language is dealt with. The failure of  <em>Zo</em>  is due to its inability to deal with context. Language is of course very much the domain of the digital humanities and again digital humanities has a great deal to offer in addressing these problems. The prominent digital humanities specialists Professor Melissa Terras and David Beavan recently took part in an experiment to automatically generate a Queen&rsquo;s Christmas message using corpora of earlier Christmas broadcasts. The AI Queen&rsquo;s Christmas message contained a great deal of racist and sexist content. Terras observed that  “I don&rsquo;t think we&rsquo;ve really begun to train our computational systems in the philosophy of language … And that&rsquo;s why these conversations between computer science folks and humanities people are so important”   <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>. This is an urgent agenda for digital humanities in the twenty-first century.</p>
<h2 id="ubiquitous-dangers">Ubiquitous Dangers</h2>
<p>As the vision of ubiquitous computing is achieved and AI penetrates every aspect of our life, the effects of gender and race bias in AI are becoming increasingly pressing. Alexa is in danger of becoming a powerful force for racism and sexism in society. As we rely increasingly on voice interaction with computers, we anthropomorphise HCI and thereby cease to notice the prejudices and biases embodied in them. Frictionless engagement with a computer is also often uncritical engagement.</p>
<p>Automated speech recognition systems are becoming an increasingly familiar part of everyday life, powering virtual assistants, facilitating automated closed captioning and enabling digital dictation platforms for health care. In a 2018 survey, 45.3% of respondents from Wales, 45.2% from Scotland and 45.1% from Yorkshire reported that they had difficulty being understood by smart home devices <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>. Lower accuracy in You Tube closed captioning has been found for women and speakers from Scotland <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>.</p>
<p>A 2018 Washington Post report found significantly lower accuracy of recognition by Amazon Echo and Google Home of speakers from the Southern United States and those with Indian, Spanish or Chinese accents. The data scientist Rachel Tatman commented that:  “These systems are going to work best for white, highly educated, upper-middle-class Americans, probably from the West Coast, because that&rsquo;s the group that&rsquo;s had access to the technology from the very beginning” <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>. It has been long recognised that natural language processing does not accommodate African American speech patterns, and this has carried over into speech recognition systems. A study recently published in the Proceedings of the National Academy of Sciences used the Corpus of Regional African American Language to analyse the performance of automated speech recognition systems and found performance was significantly poorer for African Americans <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>. The authors of the study commented that:</p>
<blockquote>
</blockquote>
<p>Our findings indicate that the racial disparities we see arise primarily from a performance gap in the acoustic models, suggesting that the systems are confused by the phonological, phonetic, or prosodic characteristics of African American Vernacular English rather than the grammatical or lexical characteristics. The likely cause of this shortcoming is insufficient audio data from black speakers when training the models.</p>
<p>The performance gaps we have documented suggest it is considerably harder for African Americans to benefit from the increasingly widespread use of speech recognition technology, from virtual assistants on mobile phones to hands-free computing for the physically impaired. These disparities may also actively harm African American communities when, for example, speech recognition software is used by employers to automatically evaluate candidate interviews or by criminal justice agencies to automatically transcribe courtroom proceedings.</p>
<p><sup id="fnref1:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup></p>
<p>A major issue with addressing these issues is the restricted availability of voice training data much of which is under the control of the larger Silicon Valley corporations. The Mozilla Foundation&rsquo;s  <em>Common Voice</em>  project was an attempt to create a more diverse and representative voice training data set <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>. The failure to create more responsive speech recognition systems reflects the lack of diversity in the Silicon Valley corporations which have developed this technology. Ruha Benjamin reports that when a member of the team which developed Siri asked why they were not considering African American English, he was told  “Well, Apple products are for the premium market” . This happened in 2015, one year after Dr Dre sold Beats by Dr Dre to Apple for a billion dollars. Benjamin comments on the irony of the way in which Apple could somehow devalue and value Blackness at the same time <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>.</p>
<p>Siri, Alexa and their friends are not only racist but sexist as well. Lingel and Crawford have shown how Siri, Alexa, Cortana and other soft AI technologies</p>
<blockquote>
<p>typically default to a feminine identity, tapping into a complex history of the secretary as a capable, supportive, ever-ready, and feminized subordinate … These systems speak in voices that have feminine, white, and “educated” intonation, and they simultaneously harvest enormous amounts of data about the user they are meant to serve<br>
<sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>.</p>
</blockquote>
<p>Although Siri, Alexa et al. offer various customisation options, including now in the case of Alexa the voice of the black American actor Samuel L. Jackson, the default is female and submissive. In choosing the voice for Alexa, Amazon had a very concrete view of the sort of person Alexa should be:</p>
<blockquote>
<p>She comes from Colorado, a state in a region that lacks a distinctive accent. She&rsquo;s the youngest daughter of a research librarian and a physics professor who has a B.A. in art history from Northwestern, [the head designer] continues. When she was a child, she won $100,000 on  <em>Jeopardy: Kids Edition</em> . She used to work as a personal assistant to  “a very popular late-night-TV satirical pundit.”  And she enjoys kayaking<br>
<sup id="fnref1:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>.</p>
</blockquote>
<p>While this characterisation of Alexa harks back to retrograde views of the sort of woman who makes a desirable secretary, on the other hand, as Lingel and Crawford <sup id="fnref2:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup> emphasise, there is also a long tradition of secretaries being viewed as trusted custodians of confidential information. The friendly approachable character of Alexa makes you confident and relaxed as she absorbs and transmits to Amazon masses of personal data.</p>
<p>The more frictionless and ubiquitous technology becomes, the greater is the scope for exclusion and bias. Perhaps the most alarming from this point of view of technologies currently being rolled out is facial recognition. A seminal paper by Buolamwini and Gebru <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup> evaluated three commercially available systems by IBM, Microsoft and the Chinese company Megvii (Face++) which used facial recognition to make gender allocations. They found that darker-skinned females were the most misclassified group (with error rates of up to 34.7%), whereas the maximum error rate for lighter-skinned males was 0.8%. This bias was due to the lack of training sets with a sufficiently diverse range of images.</p>
<p>As facial recognition is increasingly used in border control, policing, store and building security, and many other purposes, these problems are becoming increasingly pressing. A further study by Raji and Buolamwini <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup> investigated bias in Amazon&rsquo;s  <em>Rekognition</em>  system which had been widely marketed to police forces and judicial agencies. This showed that gender classification by the Amazon system was even more biased than in IBM, Microsoft and Megvii systems tested in the original study, with Amazon&rsquo;s  <em>Rekognition</em>  producing error rates of 31.37% for darker-skinned females and 8.66% for lighter-skinned males <sup id="fnref1:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. Amazon disputed the claims <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>, but it was emphasised by Buolamwini that Amazon had refused to submit  <em>Rekognition</em>  to evaluation by the National Institute of Standards and Technology (NIST) and its claims that  <em>Rekognition</em>  was bias free were based only on internal testing <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>.</p>
<p>The tests performed by Buolamwini and her colleagues were concerned with gender classification, but inevitably raise doubts about other aspects of facial recognition packages such as identification of individuals. A 2019 NIST report found that there was indeed also bias in the use of facial recognition software to identify individuals <sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>. It showed that Native American, West African, East African and East Asian people were far more likely to be wrongly identified in US domestic applications. Women were also more likely to be wrongly identified. In the case of border crossing controls, false negatives were much higher among people born in Africa and the Caribbean. In the wake of these findings and in response to the  <em>Black Lives Matter</em>  movement, IBM, Microsoft and Amazon all stepped back from active commercial promotion of their products <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>.</p>
<h2 id="how-should-digital-humanities-respond-to-this">How Should Digital Humanities Respond to This?</h2>
<p>These are issues that should be of profound concern to practitioners of the digital humanities. Areas such as natural language processing, nominal record linkage and image recognition are of fundamental importance to the digital humanities. Thinking about how computers handle language and context is at the heart of much digital humanities research. Corpus linguists document dialect and shifting usage, and can make major contributions to more inclusive training sets for development of voice recognition software. The strong understanding of governance, regulation and transparency in both the humanities and social sciences can make a major contribution to developing governance frameworks for a more accountable and transparent AI. Digital humanities scholars such as David Berry have been at the forefront of promoting explainability in AI <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>.</p>
<p>Above all, some of these technologies are already being employed in digital humanities and there can be no doubt that, as scholars in the humanities seek to come to terms with vast quantities of born-digital data, AI tools will become of fundamental importance in humanities research. Historians and other humanities scholars will not be able to analyse the hundreds of millions of e-mails produced by governments and corporations or attempt to probe the terabytes of data produced by web archives without the aid of AI tools <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>. If the historical research of the future is going to be fair-minded, unbiased and just, then it will need an AI that is subject to rigorous testing, transparent in its assumptions and extensively documented.</p>
<p>AI will also be of fundamental importance to historians in the future because it will be one of the key tools used by archivists to manage born-digital data. It will be impossible for archivists manually to catalogue the petabytes of data that are already being produced by governments and corporations. Instead it is probable that finding aids will be generated by automated AI extraction of metadata <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. The use of AI will also be important in appraising what born-digital data should be preserved for historians and transferred to archives. AI will probably also be used in deciding which born-digital records contain sensitive information that mean they should be closed from public access <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>. AI will without doubt be a leading force in shaping the future historical record.</p>
<p>Illustrations of some of the likely future use of AI in managing archives and libraries are given by two projects undertaken by the UK National Archives funded by the Arts and Humanities Research Council under its Digital Transformations strategic theme. Legal codes are now too vast to be mastered by manual reading. The UK statute book comprises 50 million words with 100,000 words changed or added every month. The  <em>Big Data for Law</em>  project investigated how AI methods can make it easier to understand how legislation is structured and used <sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>. It developed tools which not only assisted in developing an overview of legislation but also suggested ways in which legislation could be improved. The second project,  <em>Traces Through Time</em> , used AI to identify different mentions of a person in the archive and to build links with them <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>.</p>
<p>Both of these pioneering projects not only give a glimpse of the likely future role of AI in the archives but also indicate some of the future ethical issues which archivists, librarians and humanities scholars will need to confront. How do we feel about machines drafting legislation which controls our behaviour? How do we know what biases and prejudices may be embedded in the tools which may be developed for legislators? Likewise, if there are clear patterns of bias in linkage in health records, how do we know that is not happening in historical archives? As humanities scholars start to make use of the possibilities provided by AI, there is a risk that humanities scholarship can become polluted by hidden gender and race bias unless the AI used is transparent, accountable and explainable.</p>
<p>Other pioneering applications of AI may on the surface seem to have a minimal risk of bias but on further examination possibilities emerge that results may be distorted by class, race or gender. For example, many studies using distant reading techniques make use of Google books as a base set. This may seem reasonable since Google Books purports to cover all published books. However, Google has a very top-down view of the world&rsquo;s knowledge and naively imagines that the great research libraries such as those at Harvard, Toronto or Oxford containing everything worth knowing. This is wrong, and Google Books omits many local or limited circulation publications are only available in local libraries whose catalogues may not even be online. Thus, if we use Google Books to analyse working-class autobiographies describing the experience of the Industrial Revolution, we find that there are significant gaps in the Google Book coverage, so that the Google sample gives disproportionate prominence to the autobiographies of successful self-made man and excludes the voices of more humble workers <sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>.</p>
<p>An important role of digital humanities in the future will be in benchmarking and documenting AI performance in areas relevant to humanities scholarship. For much of its history since the 1950s, practitioners of humanities computers and the digital humanities have had to be evangelists for the use of computers in humanities scholarship. There are still many battles to be fought over such questions as the extent to which scholars should themselves be coders or the role of quantification in humanities scholarly discourse. But increasingly as humanities scholars adopt digital methods, an important role of the digital humanities should be to promote a critical approach to the use of digital tools and methods in the humanities. Too often, scholars are happy to use n-grams or visualisations to illustrate pet theories without thinking about how the tool works or the nature of the underlying data. As AI tools and methods become increasingly available to humanities scholars, this role will be increasingly important.</p>
<p>Digital humanities is exceptionally well placed to promote an ethical AI. It is widely agreed that, in combatting algorithmic bias, an interdisciplinary approach is essential and the interdisciplinary traditions of digital humanities can make a vital contribution here. Cultural and media specialists can contribute to combatting bias in design; historians and linguists can assist in assessing the linguistic and other contexts that might generate bias. The debates around the COMPAS system to predict recidivism risk discussed above can be best understood in the context of the long and complex history of racial classification in the United States <sup id="fnref1:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>, and such systems would perform much better if they had historians on the development team. Again, it is also agreed that in avoiding algorithmic bias, it is vital that design teams are themselves diverse in makeup. While the track record of digital humanities in ethnic and gender inclusiveness is far from perfect, there is nevertheless a strong emphasis on the importance of diversity. Digital humanities can contribute to a more inclusive and diverse approach to AI development. One area where this could be particularly important is in drawing on the experience of digital humanities with a wide range of historic, linguistic and other primary materials to create more diverse training sets for AI applications.</p>
<p>Algorithmic bias is potentially a major social and cultural crisis for humanity. It is an area where digital humanities can make a major contribution. In developing approaches to these issues, digital humanities practitioners can helpfully draw on a increasing range of recent work which outlines best practice and principles for responsible use of AI in society <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>  <sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>. Work towards an ethical AI may perhaps represent finally a coming of age for digital humanities. How might this look as a concrete plan of action? In conclusion, it might be worth setting out a short manifesto for DH AI which itemises ten key areas worth early attention. Space prevents me offering extended rationales for each action point, but it is nevertheless helpful briefly to outline them.<br>
In many respects, digital humanities associations and organisations are often inward looking and do not pursue wider social agendas. There is room for greater dialogue with activist organisations seeking to promote the health of our digital environment. Many individual digital humanities practitioners work with Mozilla Foundation, a leading campaigner in this area <sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>, and there is scope for more extended and structured engagement. Links might also be built with other campaigns, such as the Algorithmic Justice League <sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup> and Women in Voice <sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup>    Digital humanities offers many examples of best practice in diversity and inclusiveness for all workers in every aspect of Information Technology. As a community, we should seek to document and increase awareness of such good practice and demonstrate the benefits it brings in creating a healthier digital environment. Digital humanities has been hugely successful in encouraging reluctant and suspicious user communities to engage with digital technology. We need to be equally forceful in encouraging humanities scholars to be highly critical and self-aware as their work becomes increasingly dependent on digital tools of all kinds.   The digital humanities should give priority to the articulation of international governance and benchmarking structures for the use of AI. The humanities provides an exciting venue for the exploration and articulation of such structures which can be a model for other sectors and disciplines <sup id="fnref:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup>.  There is a strong fit between humanities and the requirement to develop explainability. Humanities scholars have a strong awareness of the way in which the formation and processing of information is shaped by cultural and social factors. The humanities can play in major role in promoting explainability in AI, and the background and structure of digital humanities makes it an excellent vehicle to promote work in this area.  In this context, we need to continue to promote awareness of bias and prejudice in the history of digital humanities itself. Gender and race biases are embedded in tools such as TEI or library and museum classification systems <sup id="fnref:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup>  <sup id="fnref:67"><a href="#fn:67" class="footnote-ref" role="doc-noteref">67</a></sup>  <sup id="fnref:68"><a href="#fn:68" class="footnote-ref" role="doc-noteref">68</a></sup>  <sup id="fnref:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup>. They are even evident in the Wikidata we use for linking. Root these out. The insights you gain will assist in rooting out algorithmic bias.  Increasingly as they deal with large image, catalogue and audio-visual data sets, libraries, museums, art galleries and archives are becoming more reliant on and expert in automated and machine learning techniques. This engagement of the heritage sector with AI will become even more important as they deal with more born-digital material. Libraries, museums, art galleries and archives can provide more diverse training data for AI in language, image and sound.  Language and language processing will be all important for many future developments in AI. The humanities can play a central role here. We need to continue to priorItise linguistic research in digital humanities in a way that will help tackle problems like linguistic context in AI.  Be more self aware. Ask ourselves what effects algorithmic bias are having within our home humanities disciplines and how we can promote awareness of this.   Be aware of how AI is being used in our own university environments. Amazon is promoting the use of its Rekognition facial software for proctoring of university examinations and to detect cheating. Facial recognition software is also being introduced in British schools to enable security checks and cashless payments <sup id="fnref:70"><a href="#fn:70" class="footnote-ref" role="doc-noteref">70</a></sup>. Challenge such developments.  Develop new narratives of AI. The narratives around AI at present are too often about control, monitoring, efficiency. There are other ways we might use AI. Imagine them, suggest them and promote them.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>McBride K., Aavik G., Toots M., Kaivet T. and Krimmer R.  “How does open government data driven co-creation occur? Six factors and a  perfect storm ; insights from Chicago&rsquo;s food inspection forecasting model.”    <em>Government Information Quarterly</em>  36, pp. 88-97. DOI: <a href="https://doi.org/10.1016/j.giq.2018.11.006">https://doi.org/10.1016/j.giq.2018.11.006</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>“Chicago Data Portal” . <a href="https://data.cityofchicago.org/.">https://data.cityofchicago.org/.</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Gover, Jessica.  “Analytics in City Government: How the Civic Analytics Network Cities are Using Data to Support Public Safety, Housing, Public Health, and Transportation” . Ash Center for Democratic Governance and Innovation. Harvard Kennedy School. 2018.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Lucius, N., Rose, K., Osborn C., Sweeney, M. E., Chesak R., Beslow S. and Schenk T.  “Predicting E. Coli Concentrations Using Limited qPCR Deployments at Chicago Beaches” .  <em>Water Research</em>  X. 2. 100016. DOI: 10.1016/j.wroa.2018.100016&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>McBride K., Aavik G., Kalvet T and Krimmer R.  “Co-creating an Open Government Data Driven Public Service: The Case of Chicago’s Food Inspection Forecasting Model.”    <em>Proceedings of the 51st Hawaii International Conference on System Sciences</em>  2018. DOI: 10.24251/HICSS.2018.309&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Sadliek, A., Caty, S., DiPrete, L., Mansour, R., Schenk, T., Bergtholdt, M., Jha, A., Ramaswami, P., and Gabrilovich, E.  “Machine-learned epidemiology: real-time detection of foodborne illness at scale” .  <em>npj Digital Medicine</em>  1, 36 (2018). DOI: <a href="https://doi.org/10.1038/s41746-018-0045-1">https://doi.org/10.1038/s41746-018-0045-1</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Mayer-Schönberger, V. and Cukier, K.  <em>Big Data: A Revolution that Will Transform how We Live, Work, and Think</em> . New York. Eamon Dolan (2013).&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>“The Shots Heard Round the City: Are Chicago’s New Shot Detection and Predictive Policing Technologies Worth It?” .  <em>South Side Weekly</em> . 19 December 2017. <a href="https://southsideweekly.com/shots-heard-round-city-shotspotter-chicago-police/">https://southsideweekly.com/shots-heard-round-city-shotspotter-chicago-police/</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>O’Neil, Cathy.  <em>Weapons of Math Destruction</em> . Crown Books. New York. (2016).&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Eubanks, V.  <em>Automating Inequality: How High-Tech Tools Profile, Police and Punish the Poor</em> . Macmillan. London. (2018)&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Perez, S.  “Microsoft silences its new A.I. bot Tay, after Twitter users teach it racism” .  <em>TechCrunch</em> . 24 March 2016. <a href="https://techcrunch.com/2016/03/24/microsoft-silences-its-new-a-i-bot-tay-after-twitter-users-teach-it-racism/">https://techcrunch.com/2016/03/24/microsoft-silences-its-new-a-i-bot-tay-after-twitter-users-teach-it-racism/</a>&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Simonite, T.  “When It Comes to Gorillas, Google Photos Remains Blind” .  <em>Wired</em> . 1 November 2018. <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/">https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Ingold, D. and Soper, S.  “Amazon Doesn’t Consider the Race of Its Customers. Should It?”    <em>Bloomberg</em> . 21 April 2016. <a href="https://www.bloomberg.com/graphics/2016-amazon-same-day/">https://www.bloomberg.com/graphics/2016-amazon-same-day/</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Lauret, J.  “Amazon’s Sexist AI Recruiting Tool: How Did It Go So Wrong?” .  <em>Becoming Human: Artificial Intelligence Magazine</em> . 16 August 2019. <a href="https://becominghuman.ai/amazons-sexist-ai-recruiting-tool-how-did-it-go-so-wrong-e3d14816d98e.">https://becominghuman.ai/amazons-sexist-ai-recruiting-tool-how-did-it-go-so-wrong-e3d14816d98e.</a>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Jordan, Tim.  <em>Information Politics: Liberation and Exploitation in the Digital Society</em> . Pluto Books. London (2015).&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Smithies, J.  <em>The Digital Humanities and the Digital Modern</em> . Palgrave Macmillan. London (2017).&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Anderson, C.  “The End of Theory: the Data Deluge Makes the Scientific Method Obsolete” .  <em>Wired</em> . 23 June 2008. <a href="https://www.wired.com/2008/06/pb-theory/">https://www.wired.com/2008/06/pb-theory/</a>&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Callebaut, W.  “Scientific perspectivism: a philosopher of science’s response to the challenge of big data biology.”    <em>Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences</em> . 43 (2012): 69-80.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Bowker, Geoff.  <em>Memory Practices in the Sciences</em> . MIT Press. Cambridge, Ma. (2006).&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Campolo, A. and Crawford, K.  “Enchanted Determinism: Responsibility in Artificial Intelligence.”    <em>Engaging Science, Technology, and Society</em>  6 (2020): 1-19. DOI: 10.17351/ests2020.277&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Noble, Safiya Umoja.  <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em> . NYU Press. New York. (2018).&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Hern, A.  “Google&rsquo;s solution to accidental algorithmic racism: ban gorillas” .  <em>The Guardian</em> . 12 January 2018. <a href="https://www.theguardian.com/technology/2018/jan/12/google-racism-ban-gorilla-black-people">https://www.theguardian.com/technology/2018/jan/12/google-racism-ban-gorilla-black-people</a>&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Kitchin, Rob.  “Big Data, New Epistemologies and Paradigm Shifts” .  <em>Big Data and Society</em> . 1.1: 1-12.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Hagger-Johnson, G., Harron, K., Fleming, T.., Gilbert, R., Goldstein, H., Landy, R. and Parslow, R. C.  “Data Linkage Errors in Hospital Administrative Data When Applying a Pseudonymisation Algorithm to Paediatric Intensive Care Records” .  <em>BMJ Open</em>  5: 1-8. DOI: <a href="http://dx.doi.org/10.1136/bmjopen-2015-008118.">http://dx.doi.org/10.1136/bmjopen-2015-008118.</a>&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Hagger-Johnson, G., Harron, K., Goldstein, H., Aldridge, R. and Gilbert, R.  “Probabilistic Linking to Enhance Deterministic Algorithms and Reduce Linkage Errors in Hospital Administrative Data” .  <em>Journal of Innovation in Health and Informatics</em>  24. 2: 234-46. DOI: 10.14236/jhi.v24i2.891.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>“Machine Bias. There’s software used across the country to predict future criminals. And it’s biased against blacks” .  <em>Pro Publica</em> . 23 May 2016. <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.</a>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Flores, A., Bechtel, K. and Lowencamp, C.  “False Positives, False Negatives, and False Analyses: A Rejoinder to  “Machine Bias: There&rsquo;s Software Used Across the Country to Predict Future Criminals. And It&rsquo;s Biased Against Blacks” ” .  <em>Federal Probation</em>  80.2: 38-46.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Dressel, J. and Farid, H.  “The accuracy, fairness, and limits of predicting recidivism.”    <em>Science Advances</em> . 4.1. DOI: DOI: 10.1126/sciadv.aao5580.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Holsinger, A., Lowenkamp, C., Laressa, E., Serin, R., Cohen, T., Robinson, C., Flores, A. and Vanbenschoten, S.  “A Rejoinder to Dressel and Farid: New Study Finds Computer Algorithm is More Accurate than Humans at Predicting Arrest and as Good as a Group of 20 Lay Experts” .  <em>Federal Probation</em>  82.2: 51-6.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Benthal, S. and Haynes, B. D.  “Racial Categories in Machine Learning” .  <em>FAT* &lsquo;19 Proceedings of the Conference on Fairness, Accountability, and Transparency</em> , pp. 289-98. Atlanta, Georgia. January 2019. DOI: <a href="https://doi.org/10.1145/3287560.3287575.">https://doi.org/10.1145/3287560.3287575.</a>&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Bolukbasi, T., Chang, K., Zou, J., Saligrama, V. and Kalai, A.  “Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings” .  <em>29th Conference on Neural Information Processing Systems (NIPS)</em> .&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Caliskan, A., Bryson, J. J. and Narayanan, A.  “Semantics Derived Automatically from Language Corpora Contain Human-like Biases” .  <em>Science</em>  356: 183-6. DOI: 10.1126/science.aal4230.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Prates, M., Avelar, P. and Lamb, L.  “Assessing gender bias in machine translation: a case study with Google Translate” .  <em>Neural Computing and Applications</em>  32: 6363-81.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>Johnson, M.  “A Scalable Approach to Reducing Gender Bias in Google Translate” .  <em>Google AI Blog</em> . 22 April 2020. <a href="https://ai.googleblog.com/2020/04/a-scalable-approach-to-reducing-gender.html.">https://ai.googleblog.com/2020/04/a-scalable-approach-to-reducing-gender.html.</a>&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Hern, A.  “Facebook Translates ‘Good Morning’ into ‘Attack Them’ Leading to Arrest” .  <em>The Guardian</em> , 24 October. <a href="https://www.theguardian.com/technology/2017/oct/24/facebook-palestine-israel-translates-good-morning-attack-them-arrest.">https://www.theguardian.com/technology/2017/oct/24/facebook-palestine-israel-translates-good-morning-attack-them-arrest.</a>&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Kiritchenko, S and Mohammed, S.  “Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems” .  <em>Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics (*SEM)</em> , pp. 43-53. New Orleans. June 2018. <a href="https://www.aclweb.org/anthology/S18-2005">https://www.aclweb.org/anthology/S18-2005</a>DOI: 10.18653/v1/S18-2005.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Chung, Anna.  “How Automated Tools Discriminate Against Black Language.”    <em>POCIT</em> . January 2019. <a href="https://peopleofcolorintech.com/author/anna_chung/">https://peopleofcolorintech.com/author/anna_chung/</a>&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Stuart-Ulin, Chloe Rose.  “Microsoft’s Politically Correct Chatbot is Even Worse that its Racist One.”    <em>Quartz</em> . 30 July 2018. <a href="https://qz.com/1340990/microsofts-politically-correct-chat-bot-is-even-worse-than-its-racist-one/.">https://qz.com/1340990/microsofts-politically-correct-chat-bot-is-even-worse-than-its-racist-one/.</a>&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Kobie, Nicole.  “We asked an AI to write the Queen’s Christmas speech” .  <em>Wired</em> . 24 December 2020. <a href="https://www.wired.co.uk/article/ai-queens-speech-christmas-day.">https://www.wired.co.uk/article/ai-queens-speech-christmas-day.</a>&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Coleman, D.  “The Dialect of Tech” . <a href="https://spike.digital/2018/08/28/the-dialect-of-tech/.">https://spike.digital/2018/08/28/the-dialect-of-tech/.</a>&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>Tatman, R.  “Gender and Dialect Bias in YouTube’s Automatic Captions” .  <em>Proceedings of the First Workshop on Ethics in Natural Language Processing</em> , pp. 53-9. Valencia, Spain. April 2017.&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Harwell, D.  “The Accent Gap” .  <em>Washington Post</em> . 19 July 2018. <a href="https://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/.">https://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/.</a>&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Koenecke et al. 2020] Koenecke, A., Narn, A., Lake, E., Nudell, J., Quartey, M., Mengesha, Z., Toups, C., Rickford, R., Jurafsky, D., and Goel, S.  “Racial Disparities in Automated Speech Recognition” .  <em>Proceedings of the National Academy of Sciences of the United States of America</em> . 117: 7684-89. DOI: <a href="https://doi.org/10.1073/pnas.1915768117.">https://doi.org/10.1073/pnas.1915768117.</a>&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<pre><code>“Mozilla Common Voice project.”   [https://commonvoice.mozilla.org/en.](https://commonvoice.mozilla.org/en.)    
</code></pre>
&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:45">
<p>Benjamin, R.  <em>Race after Technology: Abolitionist Tools for the New Jim Code</em> . Polity Press. Cambridge (2019).&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>Lingel, Jessa and Crawford, Kate.  “ Alexa, Tell Me about Your Mother:  The History of the Secretary and the End of Secrecy” .  <em>Catalyst: Feminism, Theory, Technoscience</em>  6.2: 1-22. DOI: <a href="https://doi.org/10.28968/cftt.v1i1.28809.">https://doi.org/10.28968/cftt.v1i1.28809.</a>&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Buolamwini, J. and Gebru, T.  “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification” .  <em>Proceedings of the 1st Conference on Fairness, Accountability and Transparency. Proceedings of Machine Learning Research</em>  81: 77-91.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Raji, I. D. and Buolamwini, J.  “Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products” .  <em>AIES &lsquo;19: Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society</em> , pp. 429-35. DOI: <a href="https://doi.org/10.1145/3306618.3314244.">https://doi.org/10.1145/3306618.3314244.</a>&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Wood M.  “Thoughts on Recent Research Paper and Associated Article on Amazon Rekognition” .  <em>AWS Machine Learning Blog</em> . 26 January 2019. <a href="https://aws.amazon.com/blogs/machine-learning/thoughts-on-recent-research-paper-and-associated-article-on-amazon-rekognition/">https://aws.amazon.com/blogs/machine-learning/thoughts-on-recent-research-paper-and-associated-article-on-amazon-rekognition/</a>&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Buolamwini, J.  “Response: Racial and Gender bias in Amazon Rekognition - Commercial AI System for Analyzing Faces” . <a href="https://medium.com/@Joy.Buolamwini/response-racial-and-gender-bias-in-amazon-rekognition-commercial-ai-system-for-analyzing-faces-a289222eeced">https://medium.com/@Joy.Buolamwini/response-racial-and-gender-bias-in-amazon-rekognition-commercial-ai-system-for-analyzing-faces-a289222eeced</a>&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Grother, P., Ngan, M. and Hanaoka, K.  “Face Recognition Vendor Test (FRVT) Part 2: Identification. NISTIR 8271” .  <em>National Institute of Standards and Technology</em> . DOI: <a href="https://doi.org/10.6028/NIST.IR.8271">https://doi.org/10.6028/NIST.IR.8271</a>&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Page, R.  “Spotlight on Facial Recognition after IBM, Amazon and Microsoft Bans” .  <em>CMO</em> . 16 June 2020. <a href="https://www.cmo.com.au/article/680575/spotlight-facial-recognition-after-ibm-amazon-microsoft-bans/">https://www.cmo.com.au/article/680575/spotlight-facial-recognition-after-ibm-amazon-microsoft-bans/</a>&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Berry, D.  “The Explainability Turn” . <a href="https://stunlaw.blogspot.com/2020/01/the-explainability-turn.html.">https://stunlaw.blogspot.com/2020/01/the-explainability-turn.html.</a>&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Winters, J. and Prescott, A.  “Negotiating the born-digital: a problem of search” .  <em>Archives and Manuscripts</em> . 47.3: 391-403. DOI: <a href="https://doi.org/10.1080/01576895.2019.1640753.">https://doi.org/10.1080/01576895.2019.1640753.</a>&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Findlay, C. and Sheridan, J.  “Recordkeeping Roundcasts Episode 1: Scale and complexity, with John Sheridan” . <a href="https://rkroundtable.org/2018/08/01/recordkeeping-roundcasts-episode-1-scale-and-complexity-with-john-sheridan/">https://rkroundtable.org/2018/08/01/recordkeeping-roundcasts-episode-1-scale-and-complexity-with-john-sheridan/</a>&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Findlay, C. and Sheridan, J.  “Recordkeeping Roundcasts Episode 3: Machine learning” . <a href="https://rkroundtable.org/2018/08/19/recordkeeping-roundcasts-episode-3-machine-learning/">https://rkroundtable.org/2018/08/19/recordkeeping-roundcasts-episode-3-machine-learning/</a>&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<pre><code>“Big Data for Law.”   [https://www.legislation.gov.uk/projects/big-data-for-law.](https://www.legislation.gov.uk/projects/big-data-for-law.)    
</code></pre>
&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:58">
<p>Ranade, S.  “Traces through Time: A Probabilistic Approach to Connected Archival Data” .  <em>2016 IEEE Conference on Big Data</em> , Washington D.C.. December 2016. DOI: 10.1109/BigData.2016.7840983&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Prescott, A.  “I&rsquo;d Rather be a Librarian” .  <em>Cultural and Social History</em> , 11.3, 335 41. DOI: 10.2752/147800414X13983595303192.&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Padilla, Thomas.  <em>Responsible Operations: Data Science, Machine Learning, and AI in Libraries</em>  Dublin, OH. OCLC Research (2019).&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Floridi, Luciano, and Josh Cowls.  “A Unified Framework of Five Principles for AI in Society” .  <em>Harvard Data Science Review</em>  (2019). DOI: <a href="https://doi.org/10.1162/99608f92.8cd550d1">https://doi.org/10.1162/99608f92.8cd550d1</a>&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p><em>Mozilla Foundation</em> .<a href="https://foundation.mozilla.org.">https://foundation.mozilla.org.</a>&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p><em>Algorithmic Justice League</em> . <a href="https://www.ajl.org">https://www.ajl.org</a>&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p><em>Women in Voice</em> . <a href="https://womeninvoice.org/">https://womeninvoice.org/</a>&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:65">
<p>Cihon, P.  “Technical Report: Standards for AI Governance: International Standards to Enable Global Coordination in AI Research and Development.”  Future of Humanity Institute, University of Oxford. <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/Standards_-FHI-Technical-Report.pdf">https://www.fhi.ox.ac.uk/wp-content/uploads/Standards_-FHI-Technical-Report.pdf</a>&#160;<a href="#fnref:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:66">
<p>Lu, Jessica and Pollock, Caitlin.  “Digital Dialogue: Hacking TEI for Black Digital Humanities” .  <em>MITH in MD presentation</em>  5 Nov. 2019. <a href="https://vimeo.com/372770114.">https://vimeo.com/372770114.</a>&#160;<a href="#fnref:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:67">
<p>Olson, Hope A.  “The Power to Name: Representation in Library Catalogs” .  <em>Signs</em>  26: 639-68.&#160;<a href="#fnref:67" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:68">
<p>Leung, S. Y., and López-McKnight, J. R. eds.  <em>Knowledge Justice: Disrupting Library and Information Studies through Critical Race Theory</em> . Cambridge, MA: MIT Press (2021).&#160;<a href="#fnref:68" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:69">
<p>MacDonald, Sharon, ed.  <em>Doing Diversity in Museums and Heritage: a Berlin Ethnography</em> . New York. Columbia University Press (2022).&#160;<a href="#fnref:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:70">
<p>“Facial Recognition in Schools” .  <em>House of Lords Library In Focus</em> . November 2021. <a href="https://lordslibrary.parliament.uk/facial-recognition-technology-in-schools/">https://lordslibrary.parliament.uk/facial-recognition-technology-in-schools/</a>&#160;<a href="#fnref:70" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Distant Reading and Viewing: Big Questions in Digital Art History and Digital Literary Studies</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000686/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/14/4/000494/?utm_source=atom_feed" rel="related" type="text/html" title="Decolonizing The Digital in the Classroom: Reflections on the Intersection of Colonial Latin American Art History and Digital Art History Pedagogy"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000686/</id><author><name>Ruta Binkyte</name></author><published>2023-07-07T00:00:00+00:00</published><updated>2023-07-07T00:00:00+00:00</updated><content type="html"></content></entry><entry><title type="html">Sentiment Analysis in Literary Studies. A Critical Survey</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000691/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000685/?utm_source=atom_feed" rel="related" type="text/html" title="The Explainability Turn"/><link href="https://rlskoeser.github.io/dhqwords/vol/16/2/000612/?utm_source=atom_feed" rel="related" type="text/html" title="Sentiment Analysis: Limits and Progress of the Syuzhet Package and Its Lexicons"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000691/</id><author><name>Simone Rebora</name></author><published>2023-07-07T00:00:00+00:00</published><updated>2023-07-07T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="1-introduction">1. Introduction</h2>
<p>After years of disinterest and neglect, Sentiment Analysis (SA) has recently become one of the most discussed topics in computational literary studies. Generally known as the field of study that analyzes  “people&rsquo;s opinions, sentiments, appraisals, attitudes, and emotions towards entities and their attributes”   <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, SA aims at accomplishing an automated extraction of the emotional content of text by converting it into machine-readable information, such as numbers and discrete labels (e.g., positive vs. negative), which can be then analyzed statistically or visualized via plots and graphs. It is precisely after June 2014, when Matthew Jockers published a series of though-provoking posts on his personal blog <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, that this computational technique started to acquire a growing relevance in DH research. To date, SA has been used in multiple studies, ranging from the identification of the basic shapes of stories cf. <sup id="fnref1:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>  <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, to the large-scale investigation of children&rsquo;s literature <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> and online reading communities <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>, with applications on both contemporary and historical languages <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. This success is paralleled — even if without a causal relation — by the so-called affective turn  <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> in literary studies <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>, through which emotions regained a key role in narrative theory and reader response studies, after the neglect — and even the patent opposition — of both structuralist and post-structuralist studies.</p>
<p>However, as it happens with all vanguards and new trends, SA is currently experiencing its peak of theoretical and methodological instability as well. While research in a field like stylometry (the computational analysis of style) has already reached some of the highest levels in terms of scientificity and theoretical awareness,<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>  the same cannot be said with SA, where most tools and methods still lack a validation, connections with literary theory are frail or disputable, and an organizational effort of the research community (such as that of the Special Interest Group  “Digital Literary Stylistics” , or of the Federation of Stylometry Labs) is still lacking.</p>
<p>A first, extensive survey of SA for computational literary studies was proposed by <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>, who distinguished five main areas of application:<br>
Classification of literary texts in terms of the emotions they convey  Genre and story-type classification  Modeling sentiments and emotions in texts from previous centuries  Character network analysis based on emotional relations  Miscellaneous and more general applications</p>
<p>However, at the end of their survey, Kim and Klinger notice how  “the methods of sentiment analysis used by some of the DH scholars nowadays have gone or are almost extinct among computational linguists”   <sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. There is a clear gap in terms of methodology that needs to be filled (or, at least, directly addressed), if research wants to move further. This necessity is also accompanied by a more general need to understand the internal logics of tools that are frequently used in a purely goal-oriented research. In other terms, a criticism of the tools and methods currently adopted in SA is as necessary as a free exploration of its potential. Without denying the usefulness of exploratory — or even  “deformative”   <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> — research, a critical awareness of shortfalls and limitations in distant reading should constitute the necessary groundwork for its fruitful application.</p>
<p>With this article, I will attempt a comprehensive criticism of SA tools in literary criticism by combining two approaches. First, as already done by <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> for stylometry and by <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> for topic modeling, I will conduct a theoretical inquiry on the possible correspondences and inconsistencies between the concepts of literary theory and the computational techniques of SA. This, in order to provide a solution to a basic question of modeling (cf. <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>  <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>  <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>): to what extent can SA model literary phenomena and thus make possible an operationalization (cf. <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>  <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>) of the fundamental questions of literary studies? Main distinction will be in where the emotions reside: if in the text itself (a perspective generally preferred by narratological approaches) or in its readers (main focus of reader-response studies). Second, by narrowing the perspective on some of the most widely used SA tools in DH, this article will perform an analysis of the technical limitations of such tools, in order to heighten awareness of the risks implicit in any research that bases itself uncritically on their outcomes.</p>
<h2 id="2-theoretical-criticism">2. Theoretical criticism</h2>
<h2 id="21-towards-an-affective-narratology">2.1 Towards an affective narratology</h2>
<p>Examining the taxonomy by <sup id="fnref2:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>, it becomes immediately evident that the strongest connection between literary theory and SA takes place in the field of narratology. The classification of genres and story types (application 2), in particular, depends primarily on the structure of narratives. <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> has also demonstrated how network analysis (application 4) can prove a powerful approach for the study of plot, while <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> have chosen the narratological device of the happy ending to classify their selection of literary texts (application 1). While this does not exclude that SA can also be fruitfully applied to the study of different subjects with different approaches (such as poetry in a neurocognitive perspective, as done by <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>), the field of narratology and the subject of the novel are clearly the most dominant,<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>  with a distinctive interest towards the classification of literary texts (shared by both applications 1 and 2). It is not by chance, then, that Jockers decided to call his SA tool  <em>Syuzhet</em>   <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, with a direct reference to the distinction made by Russian formalists between the fabula and the plot (also known as syuzhet,  récit, or intreccio).</p>
<p>However, when looking for the actual location where this connection takes place, the model reveals itself as apparently faulty. Both <sup id="fnref2:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> and <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> used SA for demonstrating that the story arcs of the entire (Western) literary production are dominated by six basic shapes.<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>  This conclusion sparkled a lively debate — and not a few criticisms (see <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>) — , but it was based on a very problematic assumption. In fact, these basic shapes were obtained by tracking the evolution of positive vs. negative emotions throughout thousands of stories. A precedent for such an approach was found in a lecture by Kurt Vonnegut, based on a (rejected) Master&rsquo;s thesis and circulated in the form of a mock-academic pièce (now available on YouTube). Some connections in narratology might be found, like in the various proposals for a  “generative grammar of narrative”   <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>, which already stimulated applications in the field of artificial intelligence — but just for creative purposes <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> — , or in the structuralist assumption that all stories can be reconducted to a universal model <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> — but just when focusing on the fabula. Antecedents of the concept of story arc can even be found in Gustav Freytag&rsquo;s pyramid of the dramatic action <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> and in Northrop Frye&rsquo;s  “U”  and an  “inverted U”  shapes <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>, representing the archetypical structures of comedy and tragedy. However, when we look into the most established theorizations of narrative form, such as the still-fundamental proposal by <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> or the most recent reformulations by <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>, almost no trace of emotions can be found. Aspects like focalization, space, time, and characters constitute a story through their manipulation and interaction, while affect is nothing but a device used to engage the reader, with just secondary and indirect consequences on the structure of the narrative. In conclusion, the question becomes unavoidable: is the SA approach actually able to develop a formal model of the phenomenon which, traditionally, has been known by literary scholars as the plot?</p>
<p>A series of recent studies, produced in the wake of the already-mentioned affective turn, help mitigating a straightforwardly negative answer. Patrick Colm Hogan was the first to introduce the concept of  “affective narratology”   <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>. His goal was clear and apparently in line with the approaches by Jockers and Reagan: starting from the acknowledgement that  “narratological treatments of emotion have on the whole been relatively undeveloped”   <sup id="fnref1:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>, he aimed at highlighting how  “emotion systems define the standard features of all stories, as well as cross-culturally recurring clusters of features in universal genres”   <sup id="fnref2:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>. This statement could easily be adopted as an epigraph for many SA literary studies. However, when reaching the core of Hogan&rsquo;s proposal, the correspondences become much more problematic. In particular, Hogan defines a nested system, where works are composed by stories (i.e., by many stories intertwined together), stories by episodes, and episodes by events and incidents, all governed by emotional principles. One of the most important principles in this system is normalcy: in fact,  “an episode begins with a shift away from normalcy [and] ends when there is a return to normalcy. […] If normalcy is restored in a more enduring way, we have not just an episode, but a story”   <sup id="fnref3:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>. This poses a fundamental problem for computational modeling, because the basic unit of measurement is not uniform (the pages of a book or the words in a sentence, generally taken as reference points by SA tools), but depends on the development of the story itself (episodes can be closed in a few sentences, or develop through multiple pages). In addition, normalcy is not determined by a simple positive vs. negative emotional status, but by more complex emotion systems (e.g., attachment and sexual desire in the romantic genre), which take shape not in the more general context of the story, but with reference to the goals of single characters. The combination of these elements alone makes the emotional analysis of stories much more complex and sophisticated than a simple tracking of the emotional levels through the pages of a book, involving for example the issues of focalization (as the nature of a sentiment inevitably depends on the chosen perspective), style (if we follow its affective-aesthetic interpretation, cf. <sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>), symbolism, and many others.</p>
<p>It should be noted, however, that research in computational literary studies is currently paving the way for solving most of these problems. For example, the identification of scenes in narratives (and thus of Hogan’s episodes) is at the center of the effort by <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>, who already highlighted its relevance for narratological studies. <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup> produced their story arcs by distinguishing Plutchik&rsquo;s eight basic emotions (joy, trust, fear, surprise, sadness, anticipation, anger, and disgust) and thus moved beyond the flattening distinction between positive and negative sentiments. Finally, all the studies collected by <sup id="fnref3:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> under the  “character network analysis”  label focus on the emotions of characters. What is currently missing, is a fruitful integration of all these approaches in a coherent framework.</p>
<p>In her recent contribution on the subject, <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup> compares the results of more than thirty-six different computational methods in the creation of emotional arcs (a term which she prefers to plot arcs, as it indicates  “an underlying sentiment structure that occurs even when very little happens plot-wise”   <sup id="fnref1:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>). While strengthening the approach introduced by Jockers and providing multiple arguments to confirm its usefulness in literary studies, Elkins consciously decides not to face the more complex narratological issues described here, thus still leaving unrealized a true operationalization of Hogan&rsquo;s narrative theory.</p>
<h2 id="22-from-narratology-to-reader-response">2.2 From narratology to reader response</h2>
<p>Hogan&rsquo;s is not the only proposal for an inclusion of affect into narrative science. In her sophisticated contribution, <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup> takes a distance from Hogan, by distinguishing affect from emotions. Following the Deleuzian interpretation, affect can be intended as an  “(asubjective, asymbolic)  intensity ”   <sup id="fnref1:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>, which resists any formalization or reduction to universal features. The interesting aspect of Breger&rsquo;s proposal is that the narratological function of affect is consequently limited to the process of worldmaking (the mental creation of fictional worlds), which happens only through an active collaboration between author, text, and readers. While Hogan tried to ground his model uniquely in the inherent features of narratives, excluding — or at least putting aside — the readers, Breger seems to follow a growing tendency in literary studies, which gives a new relevance to readers (be they real or implied). <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup></p>
<p>Such a tendency is also evident in <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>, who devises a series of experiments with his own readers. By intermixing the chapters of an original short story with a taxonomy of emotions in literature, Oatley shows how such emotional systems sustain all narratives. A powerful support is found in the Sanskrit theory of rasas, intended as  “essences of the everyday emotions […] that seem not so much individual […], but universal: aspects of all humankind”   <sup id="fnref1:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>.</p>
<p>In a similar effort, <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup> refer to Monika Fludernik&rsquo;s theory of a natural narratology <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>, which  “foregrounds the reader and focuses on the cognitive mechanisms underlying reader&rsquo;s construction and interpretation of narrative”   <sup id="fnref1:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>. Fludernik&rsquo;s naturalism depends on the idea that narratives are built in readers&rsquo; minds through a re-shaping and variation of everyday human experience. By including the affective component, such a narratology may  “expand its purview and become even  more natural ”   <sup id="fnref2:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>.</p>
<p>These contributions are just a sample of a currently growing trend in literary studies. The widest body of research on reader&rsquo;s affects and emotions, in fact, can be found in the field of reader response theory, whose origins can be traced back to Aristotle&rsquo;s concept of catharsis <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>, but which distinguished itself more recently for its scientific approach to the study of reading. Through the adoption of empirical methods <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>, in fact, reader&rsquo;s experiences are analyzed and measured via questionnaires and interviews, but also using technologies like eye tracking and fMRI scans. In a recent series of papers, SA also has been introduced in the field.</p>
<p><sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup> adopted SA on Shakespeare&rsquo;s sonnets not to visualize their (frequently improbable) plot arcs, but to measure the  “emotion potential”  of their verses, with the goal of predicting possible readers&rsquo; reactions and thus devising new experiments on selected texts. <sup id="fnref1:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>, then, used SA on a social reading platform <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>, Wattpad, with a goal that connects even more strongly narratology and reader response theory. Given that on Wattpad readers can write comments for each paragraph in a novel (reaching even millions of comments), Jocker&rsquo;s technique was adapted to compare two emotional arcs: that of the text and that of readers&rsquo; reactions. Results were used to isolate the passages that showed the highest levels of harmony or discrepancy (i.e., where the correlations between the two emotional arcs were the highest or lowest), thus identifying the textual features that support or hinder narrativization.</p>
<p>These studies prove how fruitful the integration between SA tools and literary studies can be. And if, on the one hand, they risk moving too deeply into the realm of social science thus losing contact with literature stricto sensu, on the other hand, they confirm how such a tendency is inscribed in the very practice of distant reading <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>. However, extensive work and reasonable carefulness are still required: main risk is that of an oversimplification of phenomena that necessarily escape any reductionism, while the current results of computational analyses are just scraping their surface. In any case, it seems more and more evident that, while a theory for distant reading is still lacking <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>, it is precisely through theoretical reasoning that SA (and other computational methods with it) can actually meet the needs of literary scholars. The possibility of testing proposals like those by Hogan and Oatley can prove extremely valuable for the development of literary studies, whatever the result (a confirmation or a denial) will be. And to the skeptics who — sometimes with good reasons — fear the imposition of quantitative methods over the irreducible subjectivity of literary criticism, it can be answered with <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup> that the process of modeling in computational literary studies is never the simple reduction of the phenomenon to a formula, but rather a continuous dynamics between the construction of a model and the confrontation with a reality that always escapes it — the same dynamics that, in the end, sustains any theorization about literature.</p>
<h2 id="3-tools-criticism">3. Tools criticism</h2>
<p>A direct confrontation with literary theory proves fundamental when setting up a criticism of SA tools. However, it is not sufficient when trying to reach a full awareness of the potential and limitations in their use for literary studies. Once the context in which a tool can be employed has been identified, an equal attention should be dedicated to the specific method it adopts. Indeed, each method implies a model — and thus it also implies a theory. SA, in fact, can be performed by selecting or combining an ample variety of approaches, ranging from simple wordcount to the most complex deep learning techniques, and connecting with multiple psycholinguistics theories. Choosing one approach over the other means also defining the very nature of the object under examination.</p>
<h2 id="31-a-stratified-taxonomy">3.1 A stratified taxonomy</h2>
<p>When trying to propose a taxonomy of SA tools, at least three main distinctions should be made, based on three interconnected aspects: (1) the emotion theory adopted by the tool (T); (2) the technique used to build the emotion resources (ER); (3) the method adopted to accomplish the analysis (M).</p>
<h2 id="311-emotion-theories">3.1.1. Emotion theories</h2>
<p>As for the emotion theory, an ample selection of competing frameworks is currently available, with their advantages/disadvantages and a lively dispute on which one is the best. However, they can be divided into two main families:</p>
<ul>
<li>T1. Dimensional representations of emotions</li>
<li>T2. Discrete (or systemic) representations of emotions</li>
</ul>
<p>Dimensional representations are generally connected to <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>, who proposed a bi-dimensional system able to chart all emotional states. By combining the two dimensions of valence (positive vs. negative, e.g., good vs. bad) and arousal (calm vs. intense, e.g., pleasurable vs. exciting) any human emotion could be logically represented. Many SA tools adopt this theory by simplifying it further, i.e., by reducing it to valence alone, on a continuous scale that ranges between two extremes (e.g., -1 and +1). This solution, chosen in studies such as <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, <sup id="fnref2:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, and <sup id="fnref2:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>, offers an efficient simplification for the analysis, but it also implies the loss of relevant information, when for example aesthetic appreciation (e.g., beautifulness or ugliness) needs to be distinguished from embodied response (e.g., pleasure or pain). It should be noted, incidentally, that this interpretation is also at the basis of the very idea of SA. Especially in its commercial applications, SA aims at mining opinions (by stressing this specific meaning of the word sentiment), thus a distinction in terms of positive/negative valence becomes sufficient for accomplishing the task.</p>
<p>On the other hand, discrete representations multiply the number of dimensions, while at the same time distinguishing them more strictly into a series of discrete categories (or basic emotions). Two main theories dominate this context: <sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>, who proposed eight basic emotions (joy, trust, fear, surprise, sadness, anticipation, anger, and disgust) based on differences in human behavior; and <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>, who reduced the categories to seven (anger, contempt, disgust, fear, joy, surprise, and sadness), based mainly on differences in facial expressions. However, theories are much more numerous <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>, and many SA approaches even combine them or reduce them to a simple dichotomy (all positive vs. all negative emotions). A unique framework is still far from being defined, while the results of any SA analysis depend heavily on the system that is chosen as a reference.</p>
<p>The biggest issue in the applicability of SA for literary studies, however, concerns the very possibility of a unique framework. <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup> demonstrated how the simple distinction between positive and negative sentiment in historical texts is an almost impossible task for human annotators. By evaluating inter-annotator agreement scores on a series of excerpts from historical political speeches, <sup id="fnref1:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup> noted that, if the performance of humans is below the threshold of acceptability, delegating this task to a computer might make no sense at all. This warrants an extreme carefulness when applying SA to literary texts. However, <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup> has also demonstrated how, while inter-annotator agreement remains low, SA is still able to catch significant correlations, especially when comparing the emotional valence of a text with its connected readers&rsquo; responses.</p>
<h2 id="312-emotion-resources">3.1.2. Emotion resources</h2>
<p>Once the theoretical framework has been decided upon, a second, fundamental decision concerns the choice of the emotion resources. In fact, the measurement of the overall emotion or sentiment expressed by a text depends primarily on the emotional values assigned to the smaller units that compose it, be they words, clauses, or sentences. Based on categorizations such as <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup> and <sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>, three main approaches can be distinguished:</p>
<ul>
<li>ER1. Word lists</li>
<li>ER2. Vector space models</li>
<li>ER3. Labeled texts</li>
</ul>
<p>The first two approaches pertain to the more general category of emotion dictionaries, where lists of words are associated to a series of (basic) emotions. Overall, emotion dictionaries are still the most used SA resource in DH, even if the interest towards labeled texts increased in recent years.</p>
<p>Word lists are the simplest approach, but they also require extensive preparatory work and frequently prove too rigid for an adaptation to different contexts. For example, the NRC Emotion Lexicon — also known as EmoLex <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup> — was developed through crowdsourcing: by using the Amazon Turk online service, its developers asked users to annotate a series of words both in terms of sentiment and (Plutchik&rsquo;s) basic emotions. Final values were then assigned via majority consent. Issues were many, however, starting from the limited trustworthiness of Amazon Turk annotators (even if the developers devised methods to avoid errors or cheating) and culminating in the system of values unavoidably inscribed in the annotations. In the end, Emolex might prove to be a good representative of the emotions experienced by present-time Internet users (where e.g., the verb to cry clearly expresses negative sentiment), but not of the system of values that sustains a play by Shakespeare or a novel by Austen (where the same verb to cry can simply mean to say out loud).</p>
<p>For this reason, vector space models are frequently used to adapt the dictionary to a specific linguistic and cultural context, through distributional semantics <sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup> and the computational technique more generally known as word embeddings <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>. Based on co-occurrences in selected corpora, words are transformed (or modeled) into multi-dimensional vectors, which encode information on semantic similarity. Starting from a selection of seed words (such as good vs. bad; or words indisputably related to basic emotions), it becomes thus possible to automatically assign a value to all words in a dictionary. This technique offers the advantage of tailoring the dictionary to a specific context, depending on the corpus that is used to generate the vectors. In this case, limitations depend primarily on the technical issues of word embeddings: for example, large corpora are required for their creation (but they are not always available, especially for historical languages) and the information encoded in the vectors does not necessarily model semantic similarity (e.g., it happens that the vectors of words such as good and bad are similar because the two words tend to appear frequently together).</p>
<p><sup id="fnref1:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup> noted how word lists and vector space models can be combined into hybrid emotion dictionaries, which try to reach an ideal compromise between advantages and shortfalls of the two approaches.</p>
<p>However, a more general issue seems at stake with emotion dictionaries. As already noted, in fact, some kinds of emotions (such as the Deleuzian affects) escape linguistic formalization, thus they may be undetectable through SA approaches. This is one of the reasons why <sup id="fnref1:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup> foster the use of labeled texts, where the basic unit of the emotion resource are not just words, but clauses and sentences. Ideally, in fact, even the least formalizable affects can be identified when focusing on a text span. Main issue for these kinds of emotion resources is their scarce availability for literary studies. While such material is readily available for e.g., product reviews and social media content, where the text of a review is generally accompanied by a simple rating (e.g., a number of stars) and a Tweet is supported by hashtags and emoticons (which frequently synthetize and disambiguate the emotions expressed), extensive annotation work is required for literary texts, with the above-mentioned issues of inter-annotator agreement. In any case, research in this field is rapidly moving forward, and annotated corpora such as <sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup> have been recently made available.</p>
<p>It is worth noticing how this issue is widely discussed also in literary studies, where the proposals in favor of a detectability of emotions through lexical cues are numerous: in the field of Medieval studies, for example, <sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup> bases her analysis of ancient emotional systems on words alone, while <sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup> looks at the stylistics features that mark such aspects; the theory of emotives by <sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup>, then, leans on the concept of translation (intended in its wider meaning, as a process of connection between separated contexts) to build a virtuous cycle between language and feelings. Numerous original solutions have been developed also in the context of computational literary studies. <sup id="fnref:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup> developed their own emotion dictionary to study affect in  <em>Ulysses</em> : to correctly operationalize Jameson&rsquo;s theory of affect, they used it not to identify the passages dominated by such words, but those where such words did not appear. The dominance in these passages of words that pertain to the body, thus signaled the presence of (unexpressed) affects.</p>
<h2 id="313-computational-methods">3.1.3. Computational methods</h2>
<p>The final distinction in a taxonomy of SA tools pertains to the method adopted to accomplish the analysis. Here too, three main distinctions have been proposed <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>:</p>
<ul>
<li>M1. Simple (or advanced) wordcounts</li>
<li>M2. Syntactic structure analyses</li>
<li>M3. Machine learning techniques</li>
</ul>
<p>Wordcount is evidently the easiest approach, which ignores sentence structure and word order to accomplish the most basic bag of words analysis. Given a text and an emotion dictionary, the words that appear in both are counted and their values summed to generate a final score. Such approach proves quite ineffective when dealing with short sentences or complex rhetorical structures but shows a surprising efficiency when the dimensions of the analyzed text increase. Unfortunately, no research on determining the minimum length for a reliable SA of literary texts — as done by <sup id="fnref:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup> for stylometry — exists yet. Simple wordcount can then also rely on statistics to better balance the relevance of single words (as done e.g., by <sup id="fnref3:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>): for example, if a positive word tends to appear homogeneously in multiple texts, its emotional valence might be relatively lower than that of words which appear just in a few passages. Statistics can support wordcount in even more complex ways, but when the analysis aims at fine-grained results, other approaches need to be employed.</p>
<p>A further step is the analysis of the syntactic structure of sentences to extract their overall meaning. This can be performed through different levels of complexity, which range from the simple identification of emotion shifters (e.g., negations, in sentences such as he was not a bad person, or it was neither sad nor boring), to a full parsing of sentences, which reconstruct their dependency trees (thus distinguishing principal from subordinate clauses, coordinating from adversative conjunctions, and so on). In theory, this approach should prove the best when aiming at high levels of precision. However, it has to deal with the multiple issues and limitations in natural language processing (NLP), especially when applied to historical languages. One of the most widely used NLP algorithms in DH, UDPipe <sup id="fnref:67"><a href="#fn:67" class="footnote-ref" role="doc-noteref">67</a></sup>, still commits a substantial number of errors in parsing languages like Latin and Ancient Greek.</p>
<p>Machine learning (ML) places itself at the highest level of the taxonomy. It has recently established itself as the most effective approach to artificial intelligence, which adopts a bottom-up strategy to build a model of knowledge through a trial-and-error process <sup id="fnref:68"><a href="#fn:68" class="footnote-ref" role="doc-noteref">68</a></sup>, where examples provided by humans (e.g., the recognition of emotions in texts) constitute the basis for a sophisticated imitation game. Some of its most advanced applications in SA (which even imitate the functioning of the human brain through artificial neural networks, also known as deep learning) are presented by <sup id="fnref:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup>, <sup id="fnref:70"><a href="#fn:70" class="footnote-ref" role="doc-noteref">70</a></sup> and <sup id="fnref:71"><a href="#fn:71" class="footnote-ref" role="doc-noteref">71</a></sup>. Even the most complex issues in SA, such as the identification of irony <sup id="fnref:72"><a href="#fn:72" class="footnote-ref" role="doc-noteref">72</a></sup> and sarcasm <sup id="fnref:73"><a href="#fn:73" class="footnote-ref" role="doc-noteref">73</a></sup>, can be approached through ML. However, also ML has some fundamental limitations when applied to literary studies: main issue is that ML algorithms need human-annotated material to learn their tasks, thus they primarily depend on labeled texts (ER3), with all the related issues that were discussed above.</p>
<p>In conclusion, it can be stated that ML has become the dominant approach in SA. In a recent  <em>SemEval</em>  task, a total of 89 teams competed for the best SA approach in analyzing multilingual Tweets. ML approaches were the most common and successful among the participants <sup id="fnref:74"><a href="#fn:74" class="footnote-ref" role="doc-noteref">74</a></sup>.</p>
<h2 id="32-sa-tools-in-literary-studies">3.2 SA tools in literary studies</h2>
<p>As noted at the beginning, SA approaches in literary studies are frequently many steps behind the most recent advancements in computational linguistics. This depends on the aforementioned intrinsic issues (e.g., the complexity of literary language and the unavailability of annotated corpora), but also on the tendency to adopt already-developed tools, which do not require the expertise of a computer scientist. While, on the one hand, this is a necessity in DH research (which cannot be reduced to a sub-field of computational linguistics), it may also lead to errors and misinterpretations. More subtly, as all tools bring about their implicit theories and biases, any analysis that looks just at the external outcomes without delving into the inner functioning logics, risks unintentionally supporting ideals that are not its own. This is why a critical analysis of SA tools becomes fundamental, focusing at least on the ones that are more extensively used in DH.</p>
<h2 id="321-syuzhet">3.2.1 Syuzhet</h2>
<p>Matthew Jocker&rsquo;s <a href="https://github.com/mjockers/syuzhet"> <em>Syuzhet</em> </a> is the software that originated the most recent wave of interest towards SA in literary studies.  <em>Syuzhet</em>  is probably one of the least advanced software for SA, but it efficiently combines speed and visualization power to produce effective results. When referring to the taxonomy described above, it can be labeled as:</p>
<ul>
<li>T1, as its default dictionary simply assigns valence to each word (even if it includes also an implementation of the NRC emotion lexicon)</li>
<li>ER1, because the default dictionary was built through crowdsourcing (or wisdom-of-the-crowd)</li>
<li>M1, because the analysis is run via simple wordcount</li>
</ul>
<p>Additional feature in  <em>Syuzhet</em>  is a series of visualization algorithms, which apply multiple smoothing functions to generate elegant plot arcs. Generally,  <em>Syuzhet</em>  works as follows: (1) the analyzed text is split into sentences, (2) a series of sentiment values is produced for each sentence, and (3) the raw values are processed by the smoothing functions to generate plots. <sup id="fnref:75"><a href="#fn:75" class="footnote-ref" role="doc-noteref">75</a></sup> has already shown the main issues related to passages (2) and (3), such as the inability to detect negation and irony, and the distortions generated by smoothing functions like the Fourier transform. In addition, it should be noted that the speed of the algorithm is also determined by the fact that it does not count words in sentences, so the sentiment of the sentence He had a good hearth and a good mind (+1.35) is the same of the sentence He had a good hearth. Main advantage of  <em>Syuzhet</em>  is its transparency and adaptability: developed as a package for the R programming language, all its functions and resources are freely available and easily modifiable (but basic programming skills are required). It should be noted, however, that more advanced packages, such as  <em>Rsentiment</em>  and  <em>Sentimentr</em>  (the latter, developed as an expansion of  <em>Syuzhet</em> ) are currently available for SA in R <sup id="fnref:76"><a href="#fn:76" class="footnote-ref" role="doc-noteref">76</a></sup>. Among the most recent applications of  <em>Syuzhet</em>  in literary studies, <sup id="fnref:77"><a href="#fn:77" class="footnote-ref" role="doc-noteref">77</a></sup> used it to evaluate the trend of sentiments and emotions across three centuries of the English novel, while <sup id="fnref:78"><a href="#fn:78" class="footnote-ref" role="doc-noteref">78</a></sup> combined it with multifractal theory to analyze narrative coherence and dynamic evolution of the novel  <em>Never Let Me Go</em>  by Kazuo Ishiguro.</p>
<h2 id="322-vader">3.2.2 Vader</h2>
<p><a href="https://github.com/cjhutto/vaderSentiment">Vader</a>  <sup id="fnref:79"><a href="#fn:79" class="footnote-ref" role="doc-noteref">79</a></sup> is a slightly more advanced SA tool, as it moves beyond the simple word counts carried out by  <em>Syuzhet</em> . After its first definition, it has been implemented in multiple programming languages, but one of the most used implementations is that in Python. Here,  <em>Vader</em>  has been integrated into the  <em>nltk</em>  library, which provides multiple NLP functions. In the current taxonomy, it can be classified as:</p>
<ul>
<li>T1, with a focus on valence alone</li>
<li>ER1, with a dictionary developed through crowdsourcing</li>
<li>M2, because it identifies valence shifters, intensifiers, et al.</li>
</ul>
<p><em>Vader</em>  works on a sentence level and produces a numerical output (composed by four values: positive, neutral, negative, and compound, which is a normalized sum of the first three). The identification of valence shifters happens through a series of basic rules, which modify the sentiment values assigned to single words if they are preceded or followed by specific particles. For example, the sentence He had a good hearth scores a compound value of +0.44 (on a range between -1 and +1), while He had a good hearth! scores +0.49 and He had not a good hearth scores -0.34. The rules that generate these values are purely mathematical and were defined through an empirical approach. In a series of experiments with multiple annotators (e.g., asking them to evaluate the sentiment of good vs. good! and not good), numerical modifiers were assigned to single particles (e.g., 0.11 for exclamation marks and -0.69 for negations). Such a procedure determines a good balance between accuracy and computing requirements (the software is fast and quite reliable), but it also causes a relative rigidity of the model. It should be noted, in fact, that  <em>Vader</em>  was developed for the analysis of text produced in social media, thus the values of both emotion dictionary and modifiers were tailored for this specific context. In addition, it shows particular issues when dealing with irony and complex syntactic constructions: the sentence Well, he was like a potato, cited by <sup id="fnref1:75"><a href="#fn:75" class="footnote-ref" role="doc-noteref">75</a></sup> when criticizing  <em>Syuzhet</em> , deceives  <em>Vader</em>  too, with a compound score of +0.55. In literary studies, Vader was recently adopted by <sup id="fnref:80"><a href="#fn:80" class="footnote-ref" role="doc-noteref">80</a></sup> to explore the poetry of the Black Arts Movement and by <sup id="fnref:81"><a href="#fn:81" class="footnote-ref" role="doc-noteref">81</a></sup> in a software pipeline aimed at generating visual summaries of narratives. However, the second study shows how better results are obtained by adopting a machine learning approach.</p>
<h2 id="323-sentiart">3.2.3 SentiArt</h2>
<p><a href="https://github.com/matinho13/SentiArt"> <em>SentiArt</em> </a>  <sup id="fnref:82"><a href="#fn:82" class="footnote-ref" role="doc-noteref">82</a></sup> tries to cope with the issue of flexibility by adopting vector space models to generate its dictionary. In theory,  <em>SentiArt</em>  can be adapted to all contexts and languages (if enough training material is available). In the current taxonomy, it can be classified as:</p>
<ul>
<li>T1, with a focus on both valence and arousal</li>
<li>ER2, with a dictionary developed through word embeddings</li>
<li>M1, because it processes texts through simple wordcount</li>
</ul>
<p>The creation of  <em>SentiArt</em>  emotion dictionaries works as follows: given a list of prototypical positive and negative words, a vector space model is used to expand it, by calculating the distance between these words and the entire dictionary. The model can be generated based on a selection of texts (taken from a specific author, genre, or period), or it can be simply downloaded from a repository of pre-trained models — e.g.,  <em>FastText</em>   <sup id="fnref:83"><a href="#fn:83" class="footnote-ref" role="doc-noteref">83</a></sup>. The first option is advised because it offers the possibility to tailor the dictionary to a specific context; however, it can become problematic when the training material is not enough to produce reliable vectors. Therefore, in the absence of alternatives and when working on contemporary texts, the second option constitutes a valid alternative.  <em>SentiArt</em>  has been developed in Python language, but it can also be used through the graphical interface of  <em>Orange</em>  (by installing the text add-on), which offers an easy access to its functionalities (with a limited set of pre-compiled dictionaries). The main advantage of  <em>SentiArt</em>  is that its hit rate reaches almost 100%, thus all the words in a text are given a value (while, in general, sentiment dictionaries cover just 10-20% of a text). This can constitute an issue when also function words (like articles and conjunctions) get a sentiment score: indeed, also such particles might have an impact in terms in valence/arousal (see for example the preposition Of at the beginning of  <em>Paradise Lost</em> ); however, both semantic variance (e.g., multiple word senses) and syntactic functions (e.g., intensification and negation) are lost in the process. As a consequence, the analysis should be performed on larger text sets. <sup id="fnref1:82"><a href="#fn:82" class="footnote-ref" role="doc-noteref">82</a></sup> tested  <em>SentiArt</em>  on the  <em>Harry Potter</em>  novels, reaching promising results in predicting the emotion potential of text passages and in identifying the personality profile of characters.</p>
<h2 id="324-seance">3.2.4 SEANCE</h2>
<p><a href="https://www.linguisticanalysistools.org/seance.html"> <em>SEANCE</em> </a>  <sup id="fnref:84"><a href="#fn:84" class="footnote-ref" role="doc-noteref">84</a></sup> operationalizes the second theoretical framework, that of discrete representations of emotions. By combining basic NLP functions (such as negation detection) with multiple dictionaries, it offers the opportunity to reach a very high granularity in distinguishing discrete emotions. In the current taxonomy, it can be classified as:</p>
<ul>
<li>
<p>T2, with a total of 250 discrete dimensions</p>
</li>
<li>
<p>ER1, as all dictionaries are provided through external resources</p>
</li>
<li>
<p>M2, because it combines wordcount and basic syntactic rules</p>
<p><em>SEANCE</em>  is distributed as a multi-platform graphical interface, that can be easily used by non-programmers. Its main potential is in the extensiveness of the vocabulary, which combines multiple resources in a single tool.<sup id="fnref:85"><a href="#fn:85" class="footnote-ref" role="doc-noteref">85</a></sup>  It includes the already-cited NRC Emotion Lexicon, but also some of the first-ever SA dictionaries, such as the General Inquirer <sup id="fnref:86"><a href="#fn:86" class="footnote-ref" role="doc-noteref">86</a></sup>, the Affective Norms for English Words (ANEW, <sup id="fnref:87"><a href="#fn:87" class="footnote-ref" role="doc-noteref">87</a></sup>), and many others. For each sentence or text (users have to prepare them in a plain text or tabular format) a total of 250 dimensions is measured. However, there is a significant overlap in these dimensions, as many of them encode the same phenomena (such as joy or fear), measured with different dictionaries. In addition, also multiple non-emotional, abstract concepts (such as causal, legal, and even aquatic) are measured. In literary studies, <sup id="fnref:88"><a href="#fn:88" class="footnote-ref" role="doc-noteref">88</a></sup> used it to compare the different editions of Wordsworth’s  <em>Prelude</em> , tracking the change in emotional aspects and providing a quantitative confirmation to already-established critical interpretations.</p>
</li>
</ul>
<h2 id="325-stanford-sa">3.2.5 Stanford SA</h2>
<p>Even if developed before all the tools presented in this survey, <a href="https://nlp.stanford.edu/sentiment/"> <em>Stanford SA</em> </a>  <sup id="fnref:89"><a href="#fn:89" class="footnote-ref" role="doc-noteref">89</a></sup> is still one of the most advanced SA software currently available for digital humanists. Its main distinctive feature is the combination of ML and advanced NLP, with the ideal goal of identifying the sentiment of single sentences. In the current taxonomy, it can be classified as:</p>
<ul>
<li>T1, with a focus on valence alone</li>
<li>ER3, as it works with human-annotated texts</li>
<li>M2 and M3, because it combines parsing and ML</li>
</ul>
<p><em>Stanford SA</em>  is written in the Java programming language and is part of  <em>Stanford CoreNLP</em> , one of the most advanced NLP software suites. It can be used through command line (i.e., by typing a series of pre-formulated commands) and tested on a visually-efficient online demo. In simplified terms,  <em>Stanford SA</em>  works as follows: in a first phase, called training, the algorithm is given a series of sentences annotated by human raters. Based on these annotations, the algorithm learns how to distinguish five possible sentiments: very negative, negative, neutral, positive, and very positive. In ML terms, the output of this procedure is also called a model, intended as a formal representation of the analyzed phenomenon. At this point, the analysis of new sentences begins: for each sentence, (1) a full dependency tree is automatically built; (2) given that also ML algorithms can be structured as trees, the dependency tree is adapted to provide the structure for the ML algorithm; (3) the algorithm analyses the sentence. As evident, the success of the whole process depends heavily on the quality of the training phase. Here the possible issues are many, because annotation demands a significant amount of time and resources, and  <em>Stanford SA</em>  requires a complex annotation format, which focuses not on single words or sentences, but on all nodes in a dependency tree. When taken out-of-the box,  <em>Stanford SA</em>  performed poorly on nineteenth-century English texts, showing errors also in the reconstruction of dependency trees <sup id="fnref:90"><a href="#fn:90" class="footnote-ref" role="doc-noteref">90</a></sup>. This depends on the fact that  <em>Stanford SA</em>  default algorithm is trained on contemporary movie reviews, thus it has substantial issues in adapting to different domains. In conclusion, while  <em>Stanford SA</em>  presents itself as one of the most sophisticated SA algorithms, its complexity in usage and requirements in training have kept digital humanists at a distance. In recent times, however, the interest of digital humanists towards ML approaches for SA — starting from isolated studies such as <sup id="fnref:91"><a href="#fn:91" class="footnote-ref" role="doc-noteref">91</a></sup> — has increased substantially.</p>
<h2 id="326-transformers-pipelines">3.2.6 Transformers Pipelines</h2>
<p><a href="https://huggingface.co/docs/transformers/main_classes/pipelines"> <em>Transformers Pipelines</em> </a> represent one of the best compromises between simplicity of usage and complexity of the approach. Based on the  <em>Transformers</em>  architecture, made famous by the success of the BERT language model <sup id="fnref:92"><a href="#fn:92" class="footnote-ref" role="doc-noteref">92</a></sup>,  <em>Pipelines</em>  allow access to advanced ML functionalities through just a few lines of Python code. In the current taxonomy, they can be classified as:</p>
<ul>
<li>T1 and T2, with the possibility to switch between different models</li>
<li>ER3, as models are created with human-annotated texts</li>
<li>M3, because they adopt advanced ML</li>
</ul>
<p>In the simplest implementation, through the text-classification pipeline, it is possible to calculate the valence of a sentence (accompanied by a confidence score). However, by selecting one of the many other text classification models available in the  <em>Hugging Face</em>  repository,<sup id="fnref:93"><a href="#fn:93" class="footnote-ref" role="doc-noteref">93</a></sup>  SA can also be accomplished in different languages and by applying many different emotion theories. One problematic aspect here is in the trustworthiness of models, which can prove efficient in accomplishing a task but can also bring about multiple biases <sup id="fnref:94"><a href="#fn:94" class="footnote-ref" role="doc-noteref">94</a></sup>, even with ethical consequences (e.g., when implicitly modeling racist or sexist biases). While  <em>Transformers Pipelines</em>  constitute the easiest entry way for such a computational technique, it should be noted that most projects in DH try to get the best of it by using more sophisticated implementations. In fact, the possibility of fine tuning  Transformers models via manual annotation stimulates the development of projects that aim at improving them further.<sup id="fnref:95"><a href="#fn:95" class="footnote-ref" role="doc-noteref">95</a></sup>  For example, <sup id="fnref:96"><a href="#fn:96" class="footnote-ref" role="doc-noteref">96</a></sup> fine-tuned Transformers models to recognize basic emotions in German poetry and categorize poems produced in different periods, while <sup id="fnref:97"><a href="#fn:97" class="footnote-ref" role="doc-noteref">97</a></sup> used a similar procedure in a project aimed at evaluating the levels of valence and arousal related to geographical entities in Swiss literature. One possible critical aspect of such an approach has been highlighted by <sup id="fnref:98"><a href="#fn:98" class="footnote-ref" role="doc-noteref">98</a></sup>, who noted how, when dealing with traditional literary questions, Transformers do not substantially outperform simpler (wordcout-based) approaches, thus overkilling the problem with a hard-to-implement solution. However, the recent availability of high-standard online resources such as the  <em>Colab Notebooks</em> , together with the development of research questions which require a fine-grained analysis of texts (see e.g., <sup id="fnref:99"><a href="#fn:99" class="footnote-ref" role="doc-noteref">99</a></sup>), has made the adoption of such a solution more and more advisable in DH.</p>
<h2 id="4-conclusion">4. Conclusion</h2>
<p>This short survey showed how the gap between state-of-the-art tools and current research in computational literary studies, while still present, seems to be gradually closing itself. And while a community-driven effort like the one in computational linguistics (embodied by phenomena such as the  <em>SemEval</em>  tasks) is still largely absent in DH, the recently growing interest (and criticisms) towards methods like SA suggests that it might be a natural outcome of the current evolution. In fact, among the most relevant acquisitions derived from the debate around <sup id="fnref:100"><a href="#fn:100" class="footnote-ref" role="doc-noteref">100</a></sup>, is the importance of validation and reproducibility <sup id="fnref:101"><a href="#fn:101" class="footnote-ref" role="doc-noteref">101</a></sup>, i.e., the construction of a community of practice.</p>
<p>Still another, more theoretical issue seems to derive from a matter of modeling. When introducing bleeding edge technology in SA (as well as in all DH tools), a simple, direct connection between the phenomenon and its model seems to get lost: as shown by <sup id="fnref:102"><a href="#fn:102" class="footnote-ref" role="doc-noteref">102</a></sup> for vector space models and by <sup id="fnref:103"><a href="#fn:103" class="footnote-ref" role="doc-noteref">103</a></sup> for unsupervised ML, any possible theoretical reasoning risks becoming empty or misleading when we do not know anymore the internal logic of the modeling process, or which phenomenon we are actually modeling. This is especially true for advanced ML approaches, which have been frequently criticized for their lack of transparency. SA adds a further complication to this, because of the ineluctable subjectivity that is inscribed in human emotions. A possible solution to this double conundrum can derive from the practice of annotation. In fact, as ML teaches us, the computational analysis (and prediction) of a phenomenon becomes possible only when humans have found an agreement in identifying it. By asking researchers, students, and literature lovers to annotate texts, testing existing theories and letting more general trends emerge, the dream of building a shared, community-driven hermeneutic machine  <sup id="fnref:104"><a href="#fn:104" class="footnote-ref" role="doc-noteref">104</a></sup> might not be that impossible to reach.</p>
<p>For the moment, nothing advises against an — informed and critically aware — use of the tools that are currently available, starting perhaps from — but not limiting ourselves to — the tools presented here. Limitations are still many, starting from the fact that resources for the English language substantially outnumber those available for all other languages. However, advantages are equally significant, as in the recognition that all the tools presented here are available in the form of free, open-source, and easily modifiable software. And probably still, in the end, literary studies will continue without the need to include SA tools. In that case, no damage can be done. But if the two will find a way to connect more steadily and learn from each other, their evolution could actually become more than a simple development — and could finally be called progress.</p>
<p>As for the scientific validation of stylometric methods in DH, see for example the extensive body of research produced by Maciej Eder (e.g., see <sup id="fnref:105"><a href="#fn:105" class="footnote-ref" role="doc-noteref">105</a></sup>  <sup id="fnref1:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup>  <sup id="fnref:106"><a href="#fn:106" class="footnote-ref" role="doc-noteref">106</a></sup>) or the detailed inquiry by <sup id="fnref:107"><a href="#fn:107" class="footnote-ref" role="doc-noteref">107</a></sup>. As for theoretical awareness, see for example <sup id="fnref:108"><a href="#fn:108" class="footnote-ref" role="doc-noteref">108</a></sup> and <sup id="fnref2:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>. A full bibliography on stylometry can be consulted on Zotero.</p>
<p>Note that the number of shapes is the same, but they do not correspond perfectly. All the plots generated by <sup id="fnref4:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> can be explored interactively through an online <a href="https://hedonometer.org/books/v1/">Hedonometer</a>.</p>
<p>The concept of the implied reader, derived from reception theory and intended as  “a textual structure anticipating the presence of a recipient without necessarily defining him”   <sup id="fnref:109"><a href="#fn:109" class="footnote-ref" role="doc-noteref">109</a></sup> has been criticized for its excessive abstraction, through which we risk losing contact with real readers <sup id="fnref:110"><a href="#fn:110" class="footnote-ref" role="doc-noteref">110</a></sup>. However, Hogan notices how  “there are many cases in which we might wish to say that a given reader’s emotional response is misguided [too]”   <sup id="fnref:111"><a href="#fn:111" class="footnote-ref" role="doc-noteref">111</a></sup>. Thus, it seems that only a combination between the two (abstract modeling and empirical observation) might actually provide us with a reliable description of the phenomenon of reading.</p>
<p>SEANCE was originally conceived as an expansion of LIWC <sup id="fnref:112"><a href="#fn:112" class="footnote-ref" role="doc-noteref">112</a></sup>, a widely-used (but proprietary) software, which measures more than 100 dimensions in multiple languages (but without including any syntactic rule). In literary studies, LIWC has been used by <sup id="fnref:113"><a href="#fn:113" class="footnote-ref" role="doc-noteref">113</a></sup> to predict the fictionality of texts.</p>
<p>A procedure also known as transfer learning, as models which already hold a certain knowledge of human language are adapted to accomplish even more specific tasks.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Liu, B.  <em>Sentiment Analysis: Mining Opinions, Sentiments, and Emotions</em> . Cambridge University Press, New York (2015).&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Jockers, M.  “A Novel Method for Detecting Plot” . (2014). <a href="http://www.matthewjockers.net/2014/06/05/a-novel-method-for-detecting-plot/.">http://www.matthewjockers.net/2014/06/05/a-novel-method-for-detecting-plot/.</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Jockers, M.  “Revealing Sentiment and Plot Arcs with the Syuzhet Package” . (2015). <a href="http://www.matthewjockers.net/2015/02/02/syuzhet/.">http://www.matthewjockers.net/2015/02/02/syuzhet/.</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Jockers, M.  “The Rest of the Story” . (2015). <a href="http://www.matthewjockers.net/2015/02/25/the-rest-of-the-story/.">http://www.matthewjockers.net/2015/02/25/the-rest-of-the-story/.</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Reagan, A. J., Mitchell, L., Kiley, D., Danforth, C. M., and Dodds, P. S.  “The Emotional Arcs of Stories Are Dominated by Six Basic Shapes” ,  <em>EPJ Data Science</em> , 5.1 (2016): 31.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Jacobs, A. M., Herrmann, J. B., Lauer, G., Lüdtke, J. and Schroeder, S.  “Sentiment Analysis of Children and Youth Literature: Is There a Pollyanna Effect?”    <em>Frontiers in Psychology</em>  11 (2020): 574746. <a href="https://doi.org/10.3389/fpsyg.2020.574746">https://doi.org/10.3389/fpsyg.2020.574746</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Pianzola, F., Rebora, S., and Lauer, G.  “Wattpad as a Resource for Literary Studies in the 21st Century. Quantitative and Qualitative Examples of the Importance of Digital Social Reading and Readers’ Comments in the Margins” ,  <em>PLoS ONE</em> , 15.1 (2020): e0226708. <a href="https://doi.org/10.1371/journal.pone.0226708">https://doi.org/10.1371/journal.pone.0226708</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Sprugnoli, R., Passarotti, M., Corbetta, D. and Peverelli, A.  “Odi et Amo. Creating, Evaluating and Extending Sentiment Lexicons for Latin” . In  <em>Proceedings of the 12th Language Resources and Evaluation Conference</em> . ACM, New York, (2020), pp. 3078–3086. <a href="https://aclanthology.org/2020.lrec-1.376">https://aclanthology.org/2020.lrec-1.376</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Clough, P. T. and Halley, J. O’M. (eds)  <em>The Affective Turn: Theorizing the Social</em> . Duke University Press, Durham (2007).&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Keen, S. 2011.  “Introduction: Narrative and the Emotions” ,  <em>Poetics Today</em> , 32.1 (2011): 1-53. <a href="https://doi.org/10.1215/03335372-1188176">https://doi.org/10.1215/03335372-1188176</a>&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:12">
<p>Kim, E. and Klinger, R.  “A Survey on Sentiment and Emotion Analysis for Computational Literary Studies” . ArXiv:1808.03137 (2018). <a href="http://arxiv.org/abs/1808.03137v1.">http://arxiv.org/abs/1808.03137v1.</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Buurma, R. S. and Gold, M. K.  “Contemporary Proposals about Reading in the Digital Age” . In D. H. Richter (ed),  <em>Companion to Literary Theor</em> . Wiley, Hoboken (2018), pp. 131-150.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Herrmann, J. B., Schöch, C., and van Dalen-Oskam, K.  “Revisiting Style, a Key Concept in Literary Studies” ,  <em>Journal of Literary Theory</em> , 9.1 (2015): 25-52.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Ciotti, F.  “What’s in a Topic Model? Critica Teorica Di Un Metodo Computazionale per l’analisi Del Testo” ,  <em>Testo e Senso</em> , 18 (2017): 1-11.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Flanders, J. and Jannidis, F. (eds)  <em>The Shape of Data in the Digital Humanities: Modeling Texts and Text-Based Resources</em> . Routledge, Taylor and Francis Group, London; New York (2019).&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Underwood, T.  <em>Distant Horizons: Digital Evidence and Literary Change</em> . The University of Chicago Press, Chicago (2019).&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Piper, A.  <em>Enumerations: Data and Literary Study</em> . The University of Chicago Press, Chicago; London (2018).&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Moretti, F.  “ Operationalizing:  Or, the Function of Measurement in Modern Literary Theory.”    <em>Pamphlet of the Stanford Literary Lab</em>  (2013), pp. 1-15. <a href="https://litlab.stanford.edu/LiteraryLabPamphlet6.pdf.">https://litlab.stanford.edu/LiteraryLabPamphlet6.pdf.</a>&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Salgaro, M.  “The Digital Humanities as a Toolkit for Literary Theory: Three Case Studies of the Operationalization of the Concepts of  Late Style,    Authorship Attribution,  and  Literary Movement ” ,  <em>Iperstoria</em> , 12 (2018): 50–60. <a href="http://www.iperstoria.it/joomla/images/PDF/Numero_12/Salgaro_pdf.pdf.">http://www.iperstoria.it/joomla/images/PDF/Numero_12/Salgaro_pdf.pdf.</a>&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Moretti, F.  “Network Theory, Plot Analysis” ,  <em>New Left Review</em> , 68 (2011). <a href="http://newleftreview.org/II/68/francomorettinetworktheoryplotanalysis.">http://newleftreview.org/II/68/francomorettinetworktheoryplotanalysis.</a>&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Zehe, A., Becker, M., Hettinger, L., Hotho, A., Reger, I., and Jannidis, F.  “Prediction of Happy Endings in German Novels Based on Sentiment Information” . In  <em>Proceedings of the Workshop on Interactions between Data Mining and Natural Language Processing (2016)</em> , pp. 9-16.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Papp-Zipernovszky, O., Mangen, A., Jacobs, A. M. and Lüdtke, J.  “Shakespeare Sonnet Reading: An Empirical Study of Emotional Responses” .  <em>Language and Literature: International Journal of Stylistics</em>  (2021): 096394702110546. <a href="https://doi.org/10.1177/09639470211054647">https://doi.org/10.1177/09639470211054647</a>&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>See for example the approach chosen by the most recent monograph on the subject, <sup id="fnref3:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:26">
<p>Hammond, A.  “The Double Bind of Validation: Distant Reading and the Digital Humanities&rsquo;  Trough of Disillusionment ” ,  <em>Literature Compass</em> , 14.8 (2017): e12402.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Prince, G. J.  <em>A Grammar of Stories: An Introduction</em> . Mouton, The Hague; Paris (1973).&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Bringsjord, S. and Ferrucci, D. A. 2000.  <em>Artificial Intelligence and Literary Creativity: Inside the Mind of BRUTUS, a Storytelling Machine</em> . L. Erlbaum Associates, Mahwah, N.J (2000).&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Bremond, C.  <em>Logique Du Récit</em> . Seuil, Paris (1973).&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Freytag, G.  <em>Die Technik des Dramas</em> . Hirzel, Leipzig (1863).&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Frye, N.  <em>The great code: the Bible and literature</em> . Routledge, London (1982).&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Genette, G.  <em>Figures III</em> . Éditions du Seuil, Paris (1972).&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Bal, M.  <em>Narratology: Introduction to the Theory of Narrative</em> . University of Toronto Press, London (2017).&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>Hogan, P. C.  <em>Affective Narratology: The Emotional Structure of Stories</em> . Bison, Lincoln (2011).&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Gius, E., Jannidis, F., Krug, M., Zehe, A., Hotho, A., Puppe, F., Krebs, J., Reiter, N., Wiedmer, N., and Konle, L.  “Detection of Scenes in Fiction” . In  <em>DH2019 Book of Abstracts</em> . ADHO, Utrecht (2019). <a href="https://dev.clariah.nl/files/dh2019/boa/0608.html.">https://dev.clariah.nl/files/dh2019/boa/0608.html.</a>&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Kim, E., Padó, S., and Klinger, R.  “Investigating the Relationship between Literary Genres and Emotional Plot Development” . In  <em>Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature. Association for Computational Linguistics</em> , Vancouver, Canada (2017), pp. 17-26. <a href="https://doi.org/10.18653/v1/W17-2203">https://doi.org/10.18653/v1/W17-2203</a>&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Elkins, K.  <em>The Shapes of Stories: Sentiment Analysis for Narrative</em> . Cambridge University Press (2022).&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Breger, C.  “Affects in Configuration: A New Approach to Narrative Worldmaking” ,  <em>Narrative</em> , 25.2 (2017): 227-251. <a href="https://doi.org/10.1353/nar.2017.0012">https://doi.org/10.1353/nar.2017.0012</a>&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:40">
<p>Oatley, K.  <em>The Passionate Muse: Exploring Emotion in Stories</em> . Oxford University Press, New York (2012).&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>Pirlet, C. and Wirag, A.  “Towards a  Natural  Bond of Cognitive and Affective Narratology” . In Burke, M. and Troscianko, E. T. (eds),  <em>Cognitive Literary Science</em> . Oxford University Press, Oxford (2017), pp. 35–54. <a href="https://doi.org/10.1093/acprof:oso/9780190496869.003.0003">https://doi.org/10.1093/acprof:oso/9780190496869.003.0003</a>&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Fludernik, M.  <em>Towards a  natural  Narratology</em> . Routledge, London; New York (1996).&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Miall, D. S.  “Reader-Response Theory” . In Richter, D. H. (ed),  <em>A Companion to Literary Theory</em> . John Wiley and Sons, Chichester, UK (2018), pp. 114-125. <a href="https://doi.org/10.1002/9781118958933.ch9">https://doi.org/10.1002/9781118958933.ch9</a>&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Peer, W. v., Hakemulder, J., and Zyngier, S.  <em>Scientific Methods for the Humanities</em> . John Benjamins, Amsterdam; Philadelphia (2012).&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Jacobs, A. M., Schuster, S., Xue, S., and Lüdtke, J.  “ What’s in the Brain That Ink May Character…  A quantitative narrative analysis of Shakespeare’s 154 sonnets for use in (Neuro-)cognitive poetics” ,  <em>Scientific Study of Literature</em> , 7.1 (2017): 4-51.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>Cordón-García, J.-A., Alonso-Arévalo, J., Gómez-Díaz, R., and Linder, D.  <em>Social Reading</em> . Chandos, Oxford (2013).&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Underwood, T.  “A Genealogy of Distant Reading” ,  <em>DHQ: Digital Humanities Quarterly</em> , 11.2 (2017). <a href="http://www.digitalhumanities.org/dhq/vol/11/2/000317/000317.html.">http://www.digitalhumanities.org/dhq/vol/11/2/000317/000317.html.</a>&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Ciotti, F.  “What Theory for Distant Reading in Literary Studies?”  In  <em>EADH2018</em> . EADH, Galway (2018), pp. 1-3. <a href="https://eadh2018.exordo.com/files/papers/91/final_draft/What_Theory_for_Distant_Reading_in_Literary_Studies-abstract.pdf.">https://eadh2018.exordo.com/files/papers/91/final_draft/What_Theory_for_Distant_Reading_in_Literary_Studies-abstract.pdf.</a>&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>McCarty, W.  <em>Humanities Computing</em> . Palgrave Macmillan, New York (2005).&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Russell, J. A.  “A Circumplex Model of Affect” ,  <em>Journal of Personality and Social Psychology</em> , 39.6 (1980): 1161-1178. <a href="https://doi.org/10.1037/h0077714">https://doi.org/10.1037/h0077714</a>&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Plutchik, R.  <em>The Emotions</em> . University Press of America, Lanham, Md (1991).&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Ekman, P.  “Facial Expression and Emotion” ,  <em>American Psychologist</em> , 48.4 (1993): 384-392. <a href="https://doi.org/10.1037/0003-066X.48.4.384">https://doi.org/10.1037/0003-066X.48.4.384</a>&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Tracy, J. L. and Randles, D.  “Four Models of Basic Emotions: A Review of Ekman and Cordaro, Izard, Levenson, and Panksepp and Watt” ,  <em>Emotion Review</em> , 3.4 (2011): 397-405. <a href="https://doi.org/10.1177/1754073911410747">https://doi.org/10.1177/1754073911410747</a>&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Sprugnoli, R., Tonelli, S., Marchetti, A., and Moretti, G.  “Towards Sentiment Analysis for Historical Texts” ,  <em>Digital Scholarship in the Humanities</em> , 31.4 (2016): 762–772. <a href="https://doi.org/10.1093/llc/fqv027">https://doi.org/10.1093/llc/fqv027</a>&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Rebora, S.  “Shared Emotions in Reading Pirandello. An Experiment with Sentiment Analysis” . In Marras, C., Passarotti, M., Franzini, G., and Litta, E. (eds),  <em>Atti del IX Convegno Annuale AIUCD. La svolta inevitabile: sfide e prospettive’per l&rsquo;Informatica Umanistica</em> . Università Cattolica del Sacro Cuore, Milano (2020), pp. 216-221. <a href="http://doi.org/10.6092/unibo/amsacta/6316">http://doi.org/10.6092/unibo/amsacta/6316</a>&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Taboada, M., Brooke, J., Tofiloski, M., Voll, K., and Stede, M.  “Lexicon-Based Methods for Sentiment Analysis” ,  <em>Computational Linguistics</em>  37.2 (2011): 267-307. <a href="https://doi.org/10.1162/COLI_a_00049">https://doi.org/10.1162/COLI_a_00049</a>&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>Seyeditabari, A., Tabari, N., and Zadrozny, W.  “Emotion Detection in Text: A Review” . ArXiv:1806.00674 (2018). <a href="http://arxiv.org/abs/1806.00674.">http://arxiv.org/abs/1806.00674.</a>&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>Mohammad, S. and Turney, P. D.  “Crowdsourcing a Word-emotion Association Lexicon” ,  <em>Computational Intelligence</em> , 29.3 (2013): 436-465. <a href="https://doi.org/10.1111/j.1467-8640.2012.00460.x">https://doi.org/10.1111/j.1467-8640.2012.00460.x</a>&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Harris, Z. S. 1954.  “Distributional Structure” ,  <em>WORD</em> , 10.2-3 (1954): 146-162. <a href="https://doi.org/10.1080/00437956.1954.11659520">https://doi.org/10.1080/00437956.1954.11659520</a>&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Mikolov, T., Sutskever, I., Chen, K., Corrado, G., and Dean, J.  “Distributed Representations of Words and Phrases and Their Compositionality” . ArXiv:1310.4546 (2013). <a href="http://arxiv.org/abs/1310.4546.">http://arxiv.org/abs/1310.4546.</a>&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Kim, E. and Klinger, R.  “Who Feels What and Why? Annotation of a Literature Corpus with Semantic Roles of Emotions” . In  <em>Proceedings of the 27th International Conference on Computational Linguistics. Association for Computational Linguistics, Santa Fe, New Mexico, USA (2018)</em> , pp. 1345-1359. <a href="http://aclweb.org/anthology/C18-1114.">http://aclweb.org/anthology/C18-1114.</a>&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>Rosenwein, B. H.  “Emotion Words.”  In Nagy, P. and Bouquet, D. (eds),  <em>Le Sujet Des Émotions Au Moyen Âge</em> . Beauchesne, Paris (2008), pp. 93-106.&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p>Rikhardsdottir, S.  <em>Emotion in Old Norse Literature: Translations, Voices, Contexts</em> . D. S. Brewer, Cambridge (2017).&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p>Reddy, W. M.  <em>The Navigation of Feeling: A Framework for the History of Emotions</em> . Cambridge Univ. Press, Cambridge (2010).&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:65">
<p>Cavender, K., Graham, J. E., Fox, R. P. Jr., Flynn, R., and Cavender, K.  “Body Language: Toward an Affective Formalism of Ulysses” . In Ross, S. and O’Sullivan, J. C. (eds),  <em>Reading Modernism with Machines: Digital Humanities and Modernist Literature</em> . Palgrave Macmillan, London (2016), pp. 223-242.&#160;<a href="#fnref:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:66">
<p>Eder, M.  “Does Size Matter? Authorship Attribution, Small Samples, Big Problem” ,  <em>Digital Scholarship in the Humanities</em> , 30.2 (2013): 167-182. <a href="https://doi.org/10.1093/llc/fqt066">https://doi.org/10.1093/llc/fqt066</a>&#160;<a href="#fnref:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:67">
<p>Straka, M.  “UDPipe 2.0 Prototype at CoNLL 2018 UD Shared Task” . In  <em>Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</em> . Association for Computational Linguistics, Brussels (2018), pp. 197-207.&#160;<a href="#fnref:67" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:68">
<p>Buduma, N. and Locascio, N.  <em>Fundamentals of Deep Learning: Designing next-Generation Machine Intelligence Algorithms</em> . O’Reilly Media. Sebastopol, CA (2017).&#160;<a href="#fnref:68" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:69">
<p>Rojas-Barahona, L. M.  “Deep Learning for Sentiment Analysis” ,  <em>Language and Linguistics Compass</em> , 10.12 (2016): 701-719. <a href="https://doi.org/10.1111/lnc3.12228">https://doi.org/10.1111/lnc3.12228</a>&#160;<a href="#fnref:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:70">
<p>Yadav, A. and Vishwakarma, D. K.  “Sentiment analysis using deep learning architectures: A review” .  <em>Artificial Intelligence Review</em> , 53.6 (2020): 4335–4385. <a href="https://doi.org/10.1007/s10462-019-09794-5">https://doi.org/10.1007/s10462-019-09794-5</a>&#160;<a href="#fnref:70" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:71">
<p>Pipalia, K., Bhadja, R. and Shukla, M.  “Comparative Analysis of Different Transformer Based Architectures Used in Sentiment Analysis” . In  <em>Proceedings of the 9th International Conference System Modeling and Advancement in Research Trends (SMART)</em> . IEEE, Moradabad (2020), pp. 411–415. <a href="https://doi.org/10.1109/SMART50582.2020.9337081">https://doi.org/10.1109/SMART50582.2020.9337081</a>&#160;<a href="#fnref:71" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:72">
<p>Van Hee, C., Lefever, E., and Hoste, V.  “Exploring the Fine-Grained Analysis and Automatic Detection of Irony on Twitter” ,  <em>Language Resources and Evaluation</em> , 52.3 (2018): 707-731. <a href="https://doi.org/10.1007/s10579-018-9414-2">https://doi.org/10.1007/s10579-018-9414-2</a>&#160;<a href="#fnref:72" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:73">
<p>Di Gangi, M. A., Lo Bosco, G., and Pilato, G.  “Effectiveness of Data-Driven Induction of Semantic Spaces and Traditional Classifiers for Sarcasm Detection” ,  <em>Natural Language Engineering</em> , 25.2 (2019): 257–85. <a href="https://doi.org/10.1017/S1351324919000019">https://doi.org/10.1017/S1351324919000019</a>&#160;<a href="#fnref:73" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:74">
<p>Patwa, P., Aguilar, G., Kar, S., Pandey, S., PYKL, S., Gambäck, B., Chakraborty, T., Solorio, T. and Das, A.  “SemEval-2020 Task 9: Overview of Sentiment Analysis of Code-Mixed Tweets” . In  <em>Proceedings of the Fourteenth Workshop on Semantic Evaluation</em> . International Committee for Computational Linguistics, Barcelona (2020), pp. 774–790. <a href="https://doi.org/10.18653/v1/2020.semeval-1.100">https://doi.org/10.18653/v1/2020.semeval-1.100</a>&#160;<a href="#fnref:74" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:75">
<p>Swafford, A.  “Problems with the Syuzhet Package” . In  <em>Anglophile in Academia: Annie Swafford’s Blog</em>  (2015). <a href="https://annieswafford.wordpress.com/2015/03/02/syuzhet/.">https://annieswafford.wordpress.com/2015/03/02/syuzhet/.</a>&#160;<a href="#fnref:75" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:75" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:76">
<p>Naldi, M.  “A Review of Sentiment Computation Methods with R Packages” . ArXiv:1901.08319 (2019). <a href="http://arxiv.org/abs/1901.08319.">http://arxiv.org/abs/1901.08319.</a>&#160;<a href="#fnref:76" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:77">
<p>Rybicki, J.  “Sentiment Analysis Across Three Centuries of the English Novel: Towards Negative or Positive Emotions?”  In  <em>EADH2018</em>  (2018). <a href="https://eadh2018.exordo.com/programme/presentation/11.">https://eadh2018.exordo.com/programme/presentation/11.</a>&#160;<a href="#fnref:77" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:78">
<p>Hu, Q., Liu, B., Thomsen, M. R., Gao, J., Nielbo, K. L.  “Dynamic evolution of sentiments in Never Let Me Go: Insights from multifractal theory and its implications for literary analysis” .  <em>Digital Scholarship in the Humanities</em> , 36.2 (2021): 322-332. <a href="https://doi.org/10.1093/llc/fqz092">https://doi.org/10.1093/llc/fqz092</a>&#160;<a href="#fnref:78" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:79">
<p>Hutto, C. J. and Gilbert, E.  “Vader: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text” . In  <em>Eighth International AAAI Conference on Weblogs and Social Media</em>  (2014). <a href="https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/download/8109/8122.">https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/download/8109/8122.</a>&#160;<a href="#fnref:79" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:80">
<p>Reed, E.  “Measured Unrest In The Poetry Of The Black Arts Movement” . In  <em>DH2018 Book of Abstracts</em>  (2018). <a href="https://dh2018.adho.org/measured-unrest-in-the-poetry-of-the-black-arts-movement/.">https://dh2018.adho.org/measured-unrest-in-the-poetry-of-the-black-arts-movement/.</a>&#160;<a href="#fnref:80" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:81">
<p>Vani, K. and Antonucci, A.  “NOVEL2GRAPH: Visual Summaries of Narrative Text Enhanced by Machine Learning” . In  <em>Text2Story@ ECIR</em>  (2019), pp. 29-37.&#160;<a href="#fnref:81" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:82">
<p>Jacobs, A. M.  “Sentiment Analysis for Words and Fiction Characters From the Perspective of Computational (Neuro-)Poetics” ,  <em>Frontiers in Robotics and AI</em> , 6 (2019). <a href="https://doi.org/10.3389/frobt.2019.00053">https://doi.org/10.3389/frobt.2019.00053</a>&#160;<a href="#fnref:82" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:82" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:83">
<p>Joulin, A., Grave, E., Bojanowski, P., and Mikolov, T.  “Bag of Tricks for Efficient Text Classification” . In  <em>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</em> : Volume 2, Short Papers. Association for Computational Linguistics (2017), pp. 427-431.&#160;<a href="#fnref:83" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:84">
<p>Crossley, S. A., Kyle, K., and McNamara, D. S.  “Sentiment Analysis and Social Cognition Engine (I): An Automatic Tool for Sentiment, Social Cognition, and Social-Order Analysis” ,  <em>Behavior Research Methods</em> , 49.3 (2017): 803-21.&#160;<a href="#fnref:84" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:85">
&#160;<a href="#fnref:85" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:86">
<p>Stone, P. J. and Hunt, E. B.  “A Computer Approach to Content Analysis: Studies Using the General Inquirer System” . In  <em>Proceedings of the May 21-23, 1963, Spring Joint Computer Conference</em> . ACM, New York (1963), pp. 241-256. <a href="https://doi.org/10.1145/1461551.1461583">https://doi.org/10.1145/1461551.1461583</a>&#160;<a href="#fnref:86" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:87">
<p>Bradley, M. M. and Lang, P. J.  “Affective Norms for English Words (ANEW): Instruction Manual and Affective Ratings” .  <em>Technical Report C-1</em> , University of Florida, NIMH Center for Research in Psychophysiology, Gainesville (1999).&#160;<a href="#fnref:87" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:88">
<p>Thomson, D. E.  <em>Prelude as Lifespan Gauge</em> ,  <em>Scientific Study of Literature</em> , 7.2 (2017): 232-256.&#160;<a href="#fnref:88" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:89">
<p>Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., and Potts, C.  “Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank” . In  <em>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</em> . Association for Computational Linguistics, Seattle (2013), pp. 1631-1642.&#160;<a href="#fnref:89" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:90">
<p>Rebora, S.  <em>History/Histoire e Digital Humanities. La Nascita Della Storiografia Letteraria Italiana Fuori d’Italia</em> . Firenze University Press, Firenze (2018). <a href="http://www.fupress.com/catalogo/history-histoire-e-digital-humanities/3748.">http://www.fupress.com/catalogo/history-histoire-e-digital-humanities/3748.</a>&#160;<a href="#fnref:90" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:91">
<p>Zehe, A., Becker, M., Jannidis, F., and Hotho, A.  “Towards Sentiment Analysis on German Literature” . In Kern-Isberner, G., Fürnkranz, J., and Thimm M. (eds),  <em>KI 2017: Advances in Artificial Intelligence</em> . Springer International Publishing, Cham (2017), pp. 387-394. <a href="https://doi.org/10.1007/978-3-319-67190-1_36">https://doi.org/10.1007/978-3-319-67190-1_36</a>&#160;<a href="#fnref:91" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:92">
<p>Devlin, J., Chang, M.-W., Lee, K. and Toutanova, K.  “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding” . ArXiv:1810.04805 (2019). <a href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a>&#160;<a href="#fnref:92" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:93">
<p>Note that text classification models can accomplish many different tasks (such as named entity recognition, offensive language recognition, etc.). Still, it is significant that the default text-classification pipeline performs SA.&#160;<a href="#fnref:93" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:94">
<p>Richardson, S.  “Exposing the Many Biases in Machine Learning.”    <em>Business Information Review</em>  (2022), 02663821221121024. <a href="https://doi.org/10.1177/02663821221121024">https://doi.org/10.1177/02663821221121024</a>&#160;<a href="#fnref:94" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:95">
&#160;<a href="#fnref:95" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:96">
<p>Konle, L., Kröncke, M., Jannidis, F. and Winko, S.  “Emotions and Literary Periods” .  <em>DH 2022 Conference Abstracts</em> . ADHO, Tokyo (2022), pp. 278-281&#160;<a href="#fnref:96" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:97">
<p>Grisot, G., Rebora, S., and Herrmann, J. B.  “Sentiment lexicons or BERT? A comparison of sentiment analysis approaches and their performance” .  <em>DH 2022 Conference Abstracts</em> . ADHO, Tokyo (2022), pp. 469-470&#160;<a href="#fnref:97" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:98">
<p>Underwood, T.  “Do humanists need BERT? Neural models have set a new standard for language understanding. Can they also help us reason about history?”  (2019). <a href="https://tedunderwood.com/2019/07/15/do-humanists-need-bert/">https://tedunderwood.com/2019/07/15/do-humanists-need-bert/</a>&#160;<a href="#fnref:98" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:99">
<p>Lendvai, P., Darányi, S., Geng, C., Kuijpers, M., Lopez de Lacalle, O., Mensonides, J.-C., Rebora, S. and Reichel, U. (2020).  “Detection of Reading Absorption in User-Generated Book Reviews: Resources Creation and Evaluation” . In  <em>Proceedings of The 12th Language Resources and Evaluation Conference</em> . European Language Resources Association, Marseille (2020), pp. 4835–4841. <a href="https://www.aclweb.org/anthology/2020.lrec-1.595">https://www.aclweb.org/anthology/2020.lrec-1.595</a>&#160;<a href="#fnref:99" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:100">
<p>Da, N. Z.  “The Computational Case against Computational Literary Studies” ,  <em>Critical Inquiry</em> , 45.3 (2019): 601-639. <a href="https://doi.org/10.1086/702594">https://doi.org/10.1086/702594</a>&#160;<a href="#fnref:100" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:101">
<p>Piper, A.  “Do We Know What We Are Doing?”    <em>Journal of Cultural Analytics</em> , (2019). <a href="https://culturalanalytics.org/2019/04/do-we-know-what-we-are-doing/.">https://culturalanalytics.org/2019/04/do-we-know-what-we-are-doing/.</a>&#160;<a href="#fnref:101" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:102">
<p>Jannidis, F., and Flanders, J.  “A Gentle Introduction to Data Modeling” . In Jannidis, F., and Flanders, J. (eds),  <em>The Shape of Data in the Digital Humanities: Modeling Texts and Text-Based Resources</em> . Routledge, Taylor and Francis Group, London; New York (2019), pp. 26-95.&#160;<a href="#fnref:102" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:103">
<p>Underwood, T.  “Algorithmic Modeling. Or, Modeling Data We Do Not Yet Understand” . In Flanders, J. and Jannidis, F. (eds),  <em>The Shape of Data in the Digital Humanities: Modeling Texts and Text-Based Resources</em> . Routledge, Taylor and Francis Group, London; New York (2019), pp. 250-263.&#160;<a href="#fnref:103" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:104">
<p>Ciotti, F.  “Modelli e Metodi Computazionali per La Critica Letteraria: Lo Stato Dell&rsquo;arte” . In Alfonzetti, B., Cancro, T., Di Iasio, V., and Pietrobon, E. (eds),  <em>L’Italianistica Oggi</em> . Adi Editore, Roma (2017), pp. 1-11.&#160;<a href="#fnref:104" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:105">
<p>Eder, M.  “Mind Your Corpus: Systematic Errors in Authorship Attribution” . In  <em>Digital Humanities 2012: Conference Abstracts</em> , (Hamburg, Germany). Hamburg Univ. Press, Hamburg (2012), pp. 181-185. <a href="https://sites.google.com/site/computationalstylistics/preprints/m-eder_mind_your_corpus.pdf?attredirects=0.">https://sites.google.com/site/computationalstylistics/preprints/m-eder_mind_your_corpus.pdf?attredirects=0.</a>&#160;<a href="#fnref:105" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:106">
<p>Eder, M.  “Visualization in Stylometry: Cluster Analysis Using Networks” ,  <em>Digital Scholarship in the Humanities</em> , 32.1 (2017): 50-64. <a href="https://doi.org/10.1093/llc/fqv061">https://doi.org/10.1093/llc/fqv061</a>&#160;<a href="#fnref:106" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:107">
<p>Evert, S., Proisl, T., Jannidis, F., Reger, I., Pielström, S., Schöch, C., and Vitt, T.  “Understanding and Explaining Delta Measures for Authorship Attribution” ,  <em>Digital Scholarship in the Humanities</em> , 32.suppl_2 (2017): ii4–ii16. <a href="https://doi.org/10.1093/llc/fqx023">https://doi.org/10.1093/llc/fqx023</a>&#160;<a href="#fnref:107" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:108">
<p>Kestemont, M.  “Function Words in Authorship Attribution. From Black Magic to Theory?”  In  <em>Proceedings of the 3rd Workshop on Computational Linguistics for Literature (CLFL). Association for Computational Linguistics, Gothenburg, Sweden (2014)</em> , pp. 59-66. <a href="http://aclweb.org/anthology/W/W14/W14-0908.pdf.">http://aclweb.org/anthology/W/W14/W14-0908.pdf.</a>&#160;<a href="#fnref:108" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:109">
<p>Iser, W.  <em>The Act of Reading: A Theory of Aesthetic Response</em> . Johns Hopkins University Press, Baltimore (1978).&#160;<a href="#fnref:109" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:110">
<p>Salgaro, M.  “La lettura come ‘Lezione della base cranica’ (Durs Grünbein). Prospettive per l’estetica della ricezione” ,  <em>Bollettino Dell’associazione Italiana Di Germanistica</em> , 4 (2011): 49-62.&#160;<a href="#fnref:110" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:111">
<p>Hogan, P. C.  “Affect Studies and Literary Criticism” . In  <em>Oxford Research Encyclopedia of Literature</em>  (2016). <a href="https://doi.org/10.1093/acrefore/9780190201098.013.105">https://doi.org/10.1093/acrefore/9780190201098.013.105</a>&#160;<a href="#fnref:111" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:112">
<p>Tausczik, Y. R. and Pennebaker, J. W.  “The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods” ,  <em>Journal of Language and Social Psychology</em> , 29.1 (2010): 24-54. <a href="https://doi.org/10.1177/0261927X09351676">https://doi.org/10.1177/0261927X09351676</a>&#160;<a href="#fnref:112" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:113">
<p>Piper, A.  “Fictionality” ,  <em>Journal of Cultural Analytics</em> , (2016). <a href="https://doi.org/10.22148/16.011">https://doi.org/10.22148/16.011</a>&#160;<a href="#fnref:113" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Slow Listening: Digital Tools for Voice Studies</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000688/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000688/</id><author><name>Marit J. MacArthur</name></author><author><name>Lee M. Miller</name></author><published>2023-07-07T00:00:00+00:00</published><updated>2023-07-07T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="1">1.</h2>




























<figure ><img loading="lazy" alt="Pitch contour line chart of the spoken sentence “Try using the brush as a means to an end”" src="/dhqwords/vol/17/2/000688/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000688/resources/images/figure01_hub891c04e46c5b01a0cf1ab52355fad73_60200_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000688/resources/images/figure01_hub891c04e46c5b01a0cf1ab52355fad73_60200_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000688/resources/images/figure01_hub891c04e46c5b01a0cf1ab52355fad73_60200_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000688/resources/images/figure01.png 1232w" 
     class="landscape"
     ><figcaption>
        <p>Pitch contour in Drift. John Ashbery reading “The Painter” , ll. 9-10, 92nd St. Y, New York, NY, 1952
        </p>
    </figcaption>
</figure>
<p>All speech is performative, to some degree, and any text can be performed. Many have been, and we have digital access to many audio recordings of such performances. Which aspects capture our attention when we listen to — and study — these recordings as performative speech? When speech happens so fast? When tone of voice matters as much, if not more than, semantics?</p>
<blockquote>
<p><em>I&rsquo;m not angry!</em>  The young woman insists — and we believe her angry tone of voice, not her words.<br>
see <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>When we listen to a speaker, we guess at the speaker&rsquo;s mood and identity, we weigh semantics against tone —  “her tone of meaning &hellip; without the words”  in Robert Frost&rsquo;s phrasing — and interpret accordingly <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. How far can we trust our ears? How do our brains process a voice? How do we filter a voice through our personal history of listening experiences, however much we intend to listen with an open mind?</p>
<p>Scientific approaches, from phonetic linguistics and the neuroscience of speech perception, offer some answers — but as a rule, they have avoided the cultural, aesthetic, historical and political questions that humanists like to ask. And they rarely take, as their object of study, something like a poetry recording. If they do, they aren&rsquo;t likely to bring knowledge of literary or performance history, or Erving Goffman&rsquo;s concept of frame analysis <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, to bear on an individual performance of a literary or dramatic text for a particular audience. Not only that, the software tools used by linguists are not designed for the noisy, older recordings common in the audio archive of, for instance, poetry readings. Few humanities scholars, moreover, are trained in audio signal processing or linguistic analysis.</p>
<p>Sound studies in general, and voice studies in particular, do not dominate digital humanities scholarship and probably never will, amid our overwhelmingly visual and textual culture — no matter that we are living in the Golden Age of the Podcast. In practical terms, this means that the software tools available to digital humanists who want to study performative speech are less familiar, and less developed for our uses, than tools for text mining or network analysis, for instance. The user base is also much smaller. These are all challenges we have faced in choosing from the available tools for our research in voice studies, and in developing new digital tools. But the digital study of literary recordings has advanced in the last decade, and its future looks bright.</p>
<h2 id="2">2.</h2>
<p>Before we discuss those tools, however, some theoretical framing of our approach to digital voice studies is in order. Close listening remains an inspiring concept that, through the influence of Charles Bernstein&rsquo;s  <em>Close Listening: Poetry and the Performed Word</em>   <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, has generated considerable scholarship on poetry recordings. Despite the fact that Bernstein co-founded one of the largest online archives of poetry audio, PennSound, close listening, when practiced in published scholarship, has often maintained too much distance from actual recordings of poetry reading. Cantankerous old-school scholars used to complain about theoretical readings of literature that fly  “10,000 feet above the text” . Much work in sound and voice studies is still, to our frustration, visual and textual — published in print form, without audio recordings linked or embedded in the work, maintaining and enforcing a distance from the audio by failing to make interaction with audio an essential part of scholarship about it.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>  When published electronically, work in sound studies does increasingly embed audio and allow for interaction with it,<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  but there is a long way to go to make this the norm in the field.</p>
<p>In  <em>The Audible Past: Cultural Origins of Sound Reproduction</em> , Jonathan Sterne advances a persuasive critique of conventional assumptions about hearing versus vision, which he calls “the audiovisual litany,” including the notions that “hearing tends toward subjectivity, vision tends toward objectivity” and “hearing is a temporal sense, vision is primarily a spatial sense” <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. Of course, vision is no more objective than hearing, and both hearing and vision function spatially and temporally. A child looking for her mother, for instance, can call out, Where are you? And the mother can simply say In here, because she knows the child can tell where in the house her voice is coming from. Nevertheless, a photograph stays still when we study it. And the words of a poem by Emily Dickinson, even as we recognize that no version of the poem is authoritative, hold still on the page while we study them. A recording of the same words does not, nor do our impressions of what we heard. Perhaps we liked the performance, or we didn&rsquo;t, or we liked some things about it, and we try to explain why. Perhaps we mistrust ourselves, and feel we need to listen again.</p>
<p>Why does this matter to the study of poetry and poetry performance? Because poetry is an oral form, and scholarly work on poetry performance and other performative speech is still in its impressionistic infancy. When we listen to a voice, Feeling is First (with nods to E.E. Cummings and Lauren Berlant), and our inchoate feelings about voices bear scrutiny. As we have written elsewhere <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, the complexity of our perceptions of voices highlight the fact that poetry is, after all, stylized communication. It calls on deep, evolutionarily old neural pathways that support language as speech, but not language as written. Writing is a recent kludge, an addon, not a deep, inevitable function of the human brain like speech — and even deeper and older are the vocal elements that create the tone of a voice, apart from words or semantic meaning (think grunts, sighs, etc.).</p>
<p>What are often called paralinguistic elements of the voice, the pitch, the intensity, the tempo, etc., are also pre — linguistic — preceding our knowledge and development of language, and triggering emotional responses that have little or nothing to do with the semantics of words. As such, the tone of voice exerts a direct emotional impact that is wordless, as when we hear a baby&rsquo;s cry — or when we hear a speaker&rsquo;s tone of voice conflicting with the semantic meaning of her words, as when someone angrily insists,  <em>I&rsquo;m not angry!</em>  we cannot ignore these elements if we really want to understand the experience of poetry, or of any performative speech.</p>
<p>Studying performative speech should also mean listening to ourselves listening, like the proverbial recursively self-conscious ethnographer. In  <em>The Race of Sound: Listening, Timbre and Vocality in African American Music</em> , musicologist Nina Sun Eidsheim discusses the question we ask when listen to a voice, Who is this?  <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. We ask this question of an unknown caller when we answer the phone. Indeed we ask it when we hear any disembodied voice, anywhere, as we try to pin down the speaker&rsquo;s identity — and thus radically reduce that voice&rsquo;s individuality to conform to or be rejected by our expectations. Eidsheim calls Who is this? the acousmatic question, after Pierre Schaeffer, who  “derive[s] the … root [of acousmatic] from an ancient Greek legend about Pythagoras&rsquo;s disciples listening to him through a curtain” , and she argues that it relies on fundamental misunderstandings of the human voice and our own listening practices, particularly in regard to vocal timbre.</p>
<p>Accordingly, she argues that the acousmatic question is largely impossible to answer, and that it is, in fact, the wrong question to ask. She offers three correctives to it: 1)  “Voice is not singular; it is collective” ; 2)  “Voice is not innate; it is cultural”  and 3)  “Voice&rsquo;s source is not the singer; it is the listener”   <sup id="fnref1:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. That is, everyone is trained throughout their lives, whenever they vocalize and someone makes comments about their voice, to then adjust it to match the culture&rsquo;s expectations of how they should sound, in Foucauldian fashion —  “as a condition of participation in a culture” . Scholarship on poetry readings and performative speech too often tends toward confident judgments about performance styles, with little acknowledgment of the complexity of listening, or of the influence of the listener&rsquo;s own aesthetic, cultural and ideological biases and preferences in regard to performance style.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>
<p>If we are always performing for and listening to others listening to us, then we never simply use our natural voices, because there is no such thing as a natural voice unaffected by cultural training. Nor is there such a thing as a neutral, singular, objective listener. Yet scholarship on poetry readings and performative speech tends toward confident judgments about performance styles, with inadequate acknowledgment of the complexity of listening, or of the influence of the listener&rsquo;s own aesthetic, cultural and ideological biases and preferences in regard to performance style.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></p>
<p>As Eidsheim paraphrases James Baldwin, one is always  “hearing one&rsquo;s voice through the ears of others”   <sup id="fnref2:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. And we are always listening to others&rsquo; voices through the ears of others, wondering: would others agree with my judgements about this voice? We listen to other voices through the ears of others; just as we never simply use our natural voices because there is no such thing as a natural voice unaffected by cultural training, nor do we listen in a way that is free of cultural training. There is no such a thing as a neutral, singular, objective listener. What we can do, following Eidsheim, is acknowledge the role of the larger culture in co-creating our voices and listening habits, the ways we speak and the ways we hear one another in different contexts. And we can bring another digital perspective into our listening practices — that is, the quantitative data perspective of audio signal processing, and the visualization of that data.</p>
<p>What follows is a critical narrative about the tools we have used and helped develop in our research, adding that digital perspective, and some highlights of the resulting research and its implications for literary study. These digital tools can enable humanist scholars to practice slow listening in the study of performative speech, to refine and test our impressionistic understandings of a given recording. Slow listening involves 1) repeated listening, with traditional close reading of the text; 2) scrutiny of our listening habits, assumptions, biases, and expectations, often based on the author&rsquo;s apparent identity and our own listening histories; 3) quantification of sonic patterns, such as pitch, timing, and intensity, as physical phenomena; and 4) sound visualization, specifically pitch contours (which simply show intonation patterns, or the rise and fall or steadiness of pitch over time), and timing patterns (including pause duration and speaking rate), and intensity patterns (volume or amplitude).</p>
<p>In this approach, we make an analogy to the practice among some musicians of slowing down a musical recording — say, a piano or saxophone piece with a very fast tempo — to understand and practice a technique, often by transcribing it. (Thanks to Alexander Ullman for alerting us to the term for this practice,  <em>slowdown(ing)</em> .) This is not precisely what we are doing, but performative speech, like music, rewards scrutiny with insight. Such scrutiny can illuminate (there&rsquo;s the hegemony of the visual for you) our listening habits and perceptions, and trends in particular genres of performative speech over time. This is particularly true when we find ourselves questioning our perceptions and impressions, and when sound visualizations and data — about, say, pitch, timing and intensity, derived from signal processing of a speech recording — do not neatly match up with our impressionistic perceptions of a recording, or a body of recordings, or simply push us to refine or describe our impressions more precisely.</p>
<h2 id="3">3.</h2>
<p>Our collaboration in testing and developing tools for critical voice studies emerged from an effort to visualize and quantify what is popularly known as Poet Voice. We aimed to confirm whether it exists, and if it does, to capture it in the wild, and at a larger scale; that is, to find examples of it not only by listening with our own ears, but by searching for particular pitch and timing patterns in poetry recordings that we and other listeners might agree sound like Poet Voice.</p>
<p><em>I know it when I hear it</em> , many listeners might say confidently about Poet Voice, echoing Supreme Court Justice Potter Stewart&rsquo;s insistence that, although he could not define hard-core pornography, he could recognize it on sight <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. In the case of pornography or obscenity, we know that cultural background and personal experience influence what viewers find offensive. But what about a poetry performance style that no one seems to like, which no one wants to admit to using, and yet seems to be so widely employed that any poetry lover — or NPR listener — feels they can recognize it?</p>
<p>Early on, without any digital tools to augment or refine our perceptions, one of us defined Poet Voice, or monotonous incantation, as speech employing a repeated cadence within a narrow range of pitch, and imposing that cadence on each line of a poem, regardless of the mood or semantics of the words spoken <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. A few key points about speech perception:  <em>pitch and timing</em>  are fundamental to the perception of tone of voice. Is a speaker&rsquo;s voice especially high or low? How much do they vary their pitch, and for what apparent semantic or affective reasons? Do they speak quickly? Slowly? At a moderate, predictable pace? Do they pause often? Briefly? Long and awkwardly? Suspensefully? And so on.</p>
<p>We began our collaborative research with a few samples of Poet Voice by Natasha Trethewey     audio clip of Natasha Trethewey     and Louise Glück     audio clip of Louise Glück     — two poets who are often mentioned as using it — and, by considering only measures in pitch and timing discussed below, found other poets apparently using it as well, in a study of sample recordings of 100 American poets <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>. These other poets included Cecilia Llompart reading  “Omens”     audio clip of  “Omens”    and Matthew Zapruder reading  “When It&rsquo;s Sunny They Push the Button” .     audio clip of  “When It&rsquo;s Sunny They Push the Button”      In the case of Llompart, we were not familiar with her work before we sampled it for the study. In the case of Zapruder, whom we count as a pleasant acquaintance, we were a bit chagrined to learn that, according to the data, he seemed to use Poet Voice in this recording. Speaking impressionistically, Zapruder&rsquo;s reading voice has some affinities with the likes of singer Bill Callahan, whose voice music critic Amanda Petrusich describes as  “a heavy baritone that is somehow both entirely affectless and drenched in feeling”   <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. Why is it that we might appreciate low affect in male poets or singers, perceived as such through a narrow pitch range, yet readily find more pejorative examples of Poet Voice used by female than male poets?</p>
<p>Might this suggest an element of unreflective sexism in our own and others&rsquo; perceptions of Poet Voice? Are we more likely to use Poet Voice as a critical term about women poets? Do women poets use it more often than men? Or do we expect men to sound low-affect, flat or incantatory (think of William Butler Yeats and Allen Ginsberg), and don&rsquo;t expect women to sound high-affect, if that&rsquo;s what Poet Voice even is? Few listeners would agree on whether a given sample of apparent Poet Voice displays restrained affect, or false affect, or no affect. Perhaps we just don&rsquo;t want to believe that our friends might use Poet Voice, because we are used to hearing it as a critical term, if not an insult?</p>
<p>Interestingly, in a popular rant against Poet Voice, poet Rich Smith complains about contemporary poets using Poet Voice (including Glück, Trethewey and Gregory Orr), but claims that  “Poet Voice is an effective and affecting style”  when practiced by, for instance, Yeats <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>.   audio clip of Yeats   Ginsberg also uses a very monotonous speaking style in  “Howl” , yet, as with Yeats, the effect seems to us more sermonic than Poet Voice.   audio clip of Allen Ginsberg reading  “Howl”</p>
<p>We encourage readers to take a moment to listen to the samples linked above of Glück, Trethewey, Llompart, Zapruder, Yeats, and Ginsberg to discover whether they agree that the poets are using a similar speaking style. For contrast to the above samples of Poet Voice, we also provide a link to a sample from Rae Armatrout, a conversational poet who uses contrastive pitch, less regular rhythm, and a wider pitch range.  audio clip of Rae Armatrout</p>
<p>In using digital tools to analyze and visualize acoustic signals, we treat neither the tools nor the resulting data as supremely objective and corrective, but rather use the perspective they provide to complement and sometimes refine or check our own, inevitably idiosyncratic, aural perceptions and impressions. Beyond Poet Voice, we were, and are, interested in exploring trends and changes in performance styles over time, and changing tastes in performance styles, not only in poetry recordings but other genres of performative speech, such as political addresses, sermons, and radio broadcasts.</p>
<p>To visualize, interpret, describe and quantify patterns in pitch and timing for our research on poetry performance, we wanted one or more open-source, user-friendly tools that could easily and accurately visualize pitch contours, or intonation patterns, with the text aligned beneath the contours. We wanted our tools to be user-friendly for the humanist, not requiring much, if any, programming skills to use. Yet we also want to enable users to apply them with some basic knowledge about speech production and perception, and about signal processing. Additionally, we want these tools to provide numerical values measuring pitch (in Hertz) and timing (in seconds) for further analysis, and possibly other data about the voice, including intensity, breathiness, nasality, etc.</p>
<p>There is a long history to the hope that, by tracking pitch, we might measure and visualize vocal patterns of expression. In 1853, Edouard-Leon Scott de Martinville began creating what he called phonautograms,  “a visual record of the pitch of someone&rsquo;s voice, how loudly he spoke, and with what emphasis” . He felt that this represented  “our living speech” , our essential character even, and he  “regarded Edison&rsquo;s invention of the phonograph in 1877, as pointless, because it reproduced sound instead of writing it”   <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>.</p>
<p>As we have written elsewhere <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, pitch has long been neglected in the study of prosody in poetry, despite much interest in its role among prominent poetry scholars such as I.A. Richards, who wrote in 1926 that  “[a] more serious omission is the neglect by the majority of metrists of the pitch relations of syllables &hellip; that a rise and fall of pitch is involved in metre and is as much a part of the poet&rsquo;s technique as any other feature of verse, as much under his control also, is indisputable”   <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> .</p>
<p>This neglect in 1926 was understandable, due to the lack of tools for pitch analysis. Today, however, there are many commercial and open-source software packages for tracking pitch and performing other speech analysis. For qualitative and quantitative analysis in linguistics, available tools for analyzing pitch and timing variables are called  <em>pitch-trackers</em>  and  <em>forced aligners</em> . A pitch-tracker samples a speaker&rsquo;s pitch, called the fundamental frequency, or f0, at certain intervals, e.g. every 10 milliseconds. A forced aligner takes a transcript of a speech recording and aligns it with the recording, delivering timing information.</p>
<p>Figures 2 and 3 show the pitch contour for Louise Glück reading a few lines from  “The Wild Iris”   <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> in  <em>Drift</em> <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> , the open-source pitch-tracker whose development we have overseen, now hosted by SpokenWeb at Concordia University. Figures 4 and 5 show word and pause length data in CSVs for the same recording from Gentle, an open-source forced aligner that Drift works with, and the fundamental frequency for every ten milliseconds in Hertz for two words, It is, from  <em>Drift</em>  (Both tools are described in detail in section 4).<br>




























<figure ><img loading="lazy" alt="Pitch contour line chart of the spoken sentence “It is terrible to survive as consciousness.”" src="/dhqwords/vol/17/2/000688/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000688/resources/images/figure02_hu1c217210596d7842219b607548b926dd_72791_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000688/resources/images/figure02_hu1c217210596d7842219b607548b926dd_72791_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000688/resources/images/figure02_hu1c217210596d7842219b607548b926dd_72791_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000688/resources/images/figure02.png 1478w" 
     class="landscape"
     ><figcaption>
        <p>Pitch contour in Drift. Louise Glück reading “The Wild Iris” (1992)
        </p>
    </figcaption>
</figure></p>




























<figure ><img loading="lazy" alt="Pitch contour line chart of the spoken sentence “buried in the dark earth”" src="/dhqwords/vol/17/2/000688/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000688/resources/images/figure03_hu51c1cdb7878c9680d3410d74cf26d949_75513_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000688/resources/images/figure03_hu51c1cdb7878c9680d3410d74cf26d949_75513_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000688/resources/images/figure03_hu51c1cdb7878c9680d3410d74cf26d949_75513_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000688/resources/images/figure03.png 1478w" 
     class="landscape"
     ><figcaption>
        <p>Pitch contour in Drift. Louise Glück reading “The Wild Iris” (1992)
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Table of duration of words spoken in Figures 2 and 3" src="/dhqwords/vol/17/2/000688/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000688/resources/images/figure04_hu8a96d2c59b062108fec90f52b9b4cfb5_37832_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000688/resources/images/figure04_hu8a96d2c59b062108fec90f52b9b4cfb5_37832_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000688/resources/images/figure04.png 416w" 
     class="landscape"
     ><figcaption>
        <p>Gentle data: Pause start and end times and pause length. Louise Glück reading “The Wild Iris” (1992)
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Table of times, pitches, and phonemes for all instances of it and is" src="/dhqwords/vol/17/2/000688/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000688/resources/images/figure05_hu6014d46b83f24ad33558ce03af60b782_54674_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000688/resources/images/figure05_hu6014d46b83f24ad33558ce03af60b782_54674_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000688/resources/images/figure05.png 416w" 
     class="portrait"
     ><figcaption>
        <p>Drift data: Fundamental frequency every 10 ms in hertz. Louise Glück reading “The Wild Iris” (1992)
        </p>
    </figcaption>
</figure>
<p>The pitch contour of Glück&rsquo;s voice shows the fundamental frequency, the vibration rate of the vocal cords in speech, keeping to a narrow pitch range, starting off at 185 Hz, rising to 207 with terrible, and so on; the Gentle data also shows that Glück pauses for almost a third of a second after survive and buried, lingering to emphasize the suffering involved.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></p>
<p>The harmonic frequencies of the fundamental frequency, which follow the formula f1 = 2 x f0, f2 = 3 x f0, etc. as they resonate through the vocal tract, give a voice its unique timbre and distinguish different vowels regardless of the pitch.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>  The following spectrograph in Matlab illustrates the fundamental frequency of Glü;ck&rsquo;s voice saying It is terrible; again, the fundamental frequency is around 200 Hz; the second harmonic (f1) is at 400 Hz, the third (f2) at 600 Hz, and so on, all the way up the seventeenth harmonic at 3,600 Hz.<br>




























<figure ><img loading="lazy" alt="Spectrogram of the spoken sentence “It is terrible to survive”" src="/dhqwords/vol/17/2/000688/resources/images/figure06.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000688/resources/images/figure06_hu8ea1dccb4988cb31a5e6ea0884bc7928_128086_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000688/resources/images/figure06_hu8ea1dccb4988cb31a5e6ea0884bc7928_128086_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000688/resources/images/figure06.png 348w" 
     class="landscape"
     ><figcaption>
        <p>Spectrogram of the fundamental frequency (f0) and multiple harmonics of the fundamental in hertz (f1, f2, etc). Louise Glück reading “The Wild Iris” (1992)
        </p>
    </figcaption>
</figure></p>
<p>As a rule, more expressive speakers use a relatively wider range of pitch. However, it is also important to note that  “pitch perception is not linear” ; an octave is a logarithmic relation, twice or half a given frequency <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. For instance, an octave above 120 Hz is 240 Hz; an octave below is 60 Hz. This means we do not perceive women as having a wider vocal range than men, although they use a wider range of pitch as measured in Hertz. The same holds for notes on a piano: the octave between C3 and C4 uses a wider pitch range than between C2 and C3, but we hear it as the same interval. This makes interpreting linear graphs of pitch a challenge, and thus we display the more perceptually relevant logged pitch values, as with the pitch contour (in  <em>Drift</em> , above) of Glück&rsquo;s voice.</p>
<p>In analyzing the pitch of human speech, we could in theory base our approach on articulation, perception, or acoustics. Measuring articulation — especially, for pitch, the vibration of the vocal folds, but also the movements of the tongue, lips, jaw, etc. — is not usually possible. As humanists, we often work from recorded speech audio, and/or lack the requisite instrumentation to objectively measure vocal fold vibration. Measuring perception would be impractical, even though pitch is perceptual. As phonologist Carlos Gussenhoven explains in  <em>Phonology of Tone and Intonation</em> :  “Unfortunately, listeners lack the appropriate conceptualizations and vocabulary to report their sensations, and are typically incapable of saying even whether a given pitch change represents a fall or rise” <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. Since individual perception is largely a black box process, it may be impossible to say  <em>why</em>  different individuals report pitch differently, or why they make certain errors, e.g. whether pitch is rising or falling.</p>
<p>Moreover, the fuzziness and subjectivity of perceived pitch can be an impediment to research because of individual and cultural differences. Our descriptions of pitch, not to mention what pitch range we feel is appropriate for a given speaker in a given context, varies according to culture, among other variables — e.g., the same woman might speak at a higher average pitch and use a wider pitch range in her native Japanese than in American English. Dutch speakers describe pitch as high or low pitch, whereas the same vocal quality is characterized as thin or thick in Farsi <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>. And so on.</p>
<p>Consequently, the best and most established approach to pitch estimation relies on computational analysis of speech acoustics. A pitch tracker such as we use (Drift) samples the fundamental frequency of a recorded voice — Drift samples it every 10 milliseconds — and is designed to avoid errors as much as technically possible, even with noisy recordings. We strongly advocate this computational approach to speech acoustics because 1) the algorithms approximate perception, in that they rely on similar acoustical features as human listeners do when estimating pitch; 2) computational approaches developed, practiced and vetted by a large number of expert researchers in acoustic analysis are comparatively objective in the sense of being unaffected by a researcher&rsquo;s personal biases about pitch, or by codifying biases explicitly; 3) the techniques can be used on arbitrarily large datasets with minimal additional resources; 4) they are usually reproducible, so results can be replicated within or across research groups, a matter of increasing importance in any field aspiring to rigorous empirical scholarship; and 5) the algorithms themselves can be shared openly, compared, and queried when they yield errors or fail, which they inevitably do sometimes with real data.</p>
<p>Despite the sophistication of contemporary automatic pitch trackers, errors arise, partly from the limits of the algorithms but partly as a result of the inherent qualities of the human voice as a complex and dynamic time-frequency signal, as the figure showing the harmonics of Glü;ck’s voice suggests. To begin with,  “voiceless friction [can be mistaken] for voicing, and [so] irregular measurement points may show up during fricatives and releases of affricated plosives. Conversely, [a pitch tracking program] may interpret irregularly voiced signals as voiceless”   <sup id="fnref1:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. In non-technical terms, such errors are caused by some unvoiced consonants being incorrectly marked as voicing pitch, and in other cases the pitch value of vowels being missed. If an algorithm makes these errors, they have to be detected by looking at the data, or the visualization of that data, or filtering the data. Thus, robustness to additive noise is an important goal for research on the voice. Not only that, but a</p>
<blockquote>
<p>pitch tracker may fail to analyze the voiced signal correctly. When the voice becomes creaky, as it often does at lower pitches, the algorithm may become confused by peaks in the signal that do not correspond to the vibratory action of the vocal folds. If these appear halfway through the period &hellip; they may lead to &hellip; doubling errors… Similarly, the algorithm may miss every second periodicity peak, believing; these peaks determine the sound quality rather than the periodicity (halving errors). Such octave jumps are usually easy to detect: the pitch track shows a sudden change to a value half or double that of the immediately preceding value, while there is no auditory impression that corresponds to that jump.</p>
</blockquote>
<p>In the pitch contour above of Glü;ck reading  “consciousness” , for instance, there is an octave jump — a halving error — beneath the syllable ness. Octave jumps and noise errors occur more frequently in noisy recordings, of course, and with programs not optimized for noise. While common in pitch estimation, octave jumps can be addressed with heuristics that constrain the probable pitch range, for instance by gender, or attempt to repair errors posthoc without affecting the basic estimation algorithm, especially with recent advances in pitch-tracking.</p>
<p>Many different pitch algorithms have been applied to speech audio, all of which ultimately try to estimate the vocal fold rate. Some deal mainly with the speech as a signal in time, whereas others emphasize frequency representations or first filter speech into different frequency bands before working on it in time. Still others use so-called cepstral analysis, a hybrid time-frequency approach which leverages the fact that in speech production, whatever the vocal folds are doing (mainly creating pitch) is acoustically dissociable from what the rest of the vocal tract is doing (e.g. making vowels and syllables). Today&rsquo;s most frequently used pitch estimation methods, and their accuracy in estimating male and female pitch in clean speech, are discussed in Strömbergsson <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>, pitch-tracking performance on noisy speech is discussed in Jouvet and Laprie <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>.</p>
<p>In our view, the choice of pitch tracker is less a principled decision and more a pragmatic one, with an eye toward ease of use, having open-source (readable) code, noise-robustness, a low error rate with clean and noisy speech, and ease of integration within a larger workflow. Gussenhoven puts it more succinctly:  “In practice, the choice of pitch tracker is determined by circumstance and convenience: their evaluation is typically beyond the competence of a phonologist”   <sup id="fnref2:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. While we agree with the basic premise, we do insist that researchers using any pitch tracker should have a basic conceptual understanding of how it works under the hood, so they are cognizant of its strengths and limitations.</p>
<p>In addition to errors that follow from the natural variance and complexity of speech, a potentially greater challenge for pitch trackers is additive noise and, more generally, recording quality. In our work, it quickly became clear, in fact, that tools commonly used by linguists to analyze both pitch and timing patterns in so-called natural speech, recorded in the ideal acoustic conditions of a sound booth, would not work well for research on recordings of poetry readings, which can be noisy, either due to the recording equipment used, background noise at a venue of a poetry reading or, even in the case of highly produced studio recordings, due to age.</p>
<p>Praat is a tool both of us have used, to begin research visualizing intonation patterns (MacArthur in 2012 and 2013, prior to our collaboration) and to manipulate pitch for experiments addressing how the brain represents and attends to speech (Miller, since 2009). An open-source program for speech analysis developed in C and C++ at the University of Amsterdam by the phonetic scientists Paul Boersma and David Weenink, Praat was initially released in 2003 and is periodically updated. It uses a time-domain pitch-tracking technique developed by Boersma, which showed great improvement over earlier frequency-domain techniques. Praat identifies the best pitch candidate at any time frame (say, every 10 ms) by finding peaks in the autocorrelation function, which all periodic sounds (including voiced speech) will show.</p>
<p>Among its innovations were to deal gracefully with two side effects of typical signal processing that reduce the accuracy of the pitch estimates (specifically correcting for windowing into time frames and sampling). Praat then traces an estimated pitch path across time to determine the final pitch contour, incorporating a cost to minimize excessive voiced-unvoiced transitions and octave jumps. However, Praat is not very user-friendly and has very limited and unattractive data visualization options, and it is not easy to extract the data about pitch and timing from Praat. Linguists who use it write and share scripts to run particular tasks that cannot be performed using the basic Praat interface. For humanists who cannot write code, or simply do not want to spend their time this way, the limitations of Praat quickly become apparent. Praat also provides no simple way to align text beneath speech — that is, to line up the intonation pattern of a line of a poem with the text.</p>
<p>A forced aligner that can be used with Praat, called FAVE (Forced Alignment and Vowel Extraction), does not work well with incomplete or flawed transcripts — a problem for large-scale analysis of audio archives for which transcripts may not be readily available, like a poetry archive such as PennSound <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. Like other forced aligners, FAVE incorporates a “dictionary” of possible words and an acoustic model of speech, in this case of American English, trained on hours of labeled recordings. For the acoustics, it does not represent speech as a complex sound pressure waveform, but rather as much lower-dimensional Perceptual Linear Prediction coefficients, which use a perceptually-inspired front end and in many cases a cepstral analysis to extract speech-relevant (e.g. vowel formant) parameters. The acoustic model in FAVE was built with the HTK Speech Recognition Toolkit, which uses Hidden Markov Models to determine the probabilities of transitions from one state–in this case speech sound or phoneme–to the next. The aligner is therefore mapping a transcript onto best-guess acoustic sequences, giving the timing of all (identified) words and phones.</p>
<p>In the midst of frustrations with Praat in 2013, MacArthur joined as a user-tester the NEH Institute HiPSTAS (High-Performing Sound Technologies for Access and Scholarship), directed by Tanya Clement, and tried out the program ARLO (Adaptive Recognition with Layered Optimization) to study pitch patterns in poetry recordings.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>  A machine-learning speech analysis and visualization tool originally intended to analyze birdsong, ARLO has significant limitations for speech analysis: it displays non-standard spectrograms with unusual time compression, making it hard to perceive speech features, and it requires sizable supercomputing resources to run. As well, many parameters require considerable manipulation to produce accurate pitch values, and pitch data is difficult to extract. The goal of  “[d]eveloping ARLO as a web-based application that can be leveraged by a wide community of users”  was abandoned <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. However, HiPSTAS was invaluable in bringing together communities of scholars interested in studying voice recordings, such as poetry readings and oral histories, and it supported novel research.</p>
<h2 id="4">4.</h2>
<p>The potential for digital voice studies research advanced considerably in 2015, when we began collaborating and also met Robert Ochshorn, who at the time was a media-interface researcher in San Francisco at Communication Design Group Labs, conceived by Alan Kay.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>  If the choice of tools is indeed  “determined by circumstance and convenience” , it can help to connect with leading-edge researchers from Silicon Valley. Ochshorn and Max Hawkins had just designed and released Gentle in 2015.</p>
<p><em>Gentle</em> <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>  is built on top of an optimal open-source speech recognition toolkit, Kaldi, initially developed at Johns Hopkins University in 2009 <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. Gentle  “take[s] media files and their transcripts and return[s] extremely precise timing information for each word (and phoneme) in the media” . It was designed specifically to function with more flexibility than FAVE, to be  “easier to install and use … handle noisy and complicated audio … and … be unusually accommodating to long or incomplete transcripts”   <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> (It can also produce rough transcripts of the spoken text of a recording from scratch — the degree of accuracy varies according to recording quality, and the errors are entertaining — which can then be corrected and aligned with the recording.) CSVs with the start and end time of each word can be downloaded from Gentle as well; see above sample for the Glü;ck recording. From this data, it&rsquo;s a simple matter to calculate word and pause duration, as well as Words Per Minute, a standard linguistic measure of speaking rate.</p>
<p>Through Ochshorn, we also learned of a pitch-tracking algorithm developed in 2012, better suited to the audio archives humanists study:  <em>Noise Robust Pitch Tracking by Subband Autocorrelation Classification</em> , by computer scientist Byung Suk Lee and electrical engineer Daniel P. W. Ellis. The Lee-Ellis algorithm was  “[t]rain[ed] on bandlimited and noisy speech (processed to simulate a low-quality radio channel) [and] leads to a great increase in performance over state-of-the-art algorithms, according to both the traditional GPE measure, and a proposed novel Pitch Tracking Error which more fully reflects the accuracy of both pitch extraction and voicing detection in a single measure”   <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup></p>
<p>Ochshorn and Max Hawkins then developed a prototype user-interface for Drift, which combines the Lee-Ellis algorithm for pitch-tracking with Gentle&rsquo;s forced alignment features to visualize text beneath the pitch contour of a given speech recording, showing which words are spoken as the voice rises and falls, remains at the same pitch, etc. (See above pitch contours for Trethewey, Gluck, Llompart, Zapruder and Yeats.) A CSV with time in seconds, pitch in Hertz, words and phonemes can be downloaded from Drift (see figure above). Drift also has potential applications for the hearing impaired, providing a clear visualization of intonation patterns that might complement closed captioning. In addition to the online demos, both Gentle and Drift are available for free download and installation on Macs.</p>
<p>The development and dissemination of Gentle and Drift were supported in 2018 and 2019 by a NEH Digital Humanities Advancement grant project,  “Tools for Listening to Text-in-Performance” ,<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>  and continue to be supported by a 7-year Can$2.5 million SSHRC grant project,  <em>The Spoken Web: Conceiving and creating a nationally networked archive of literary recordings for research and teaching</em> . <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>  With considerable improvements to both the interface and functionality, thanks to our talented undergraduate research assistants at UC Davis, Richard Kim, Hannan Walliullah and especially Sarah Yuniar, Drift4<sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>  was released on November 14, 2022, and is hosted by the SSHRC-funded SpokenWeb project for the long term.</p>
<p>In parallel with Ochshorn&rsquo;s development of Gentle and Drift, and also with support from the NEH and SSHRC grants, we have also built a toolbox in Matlab called Voxit, to enable greater ease of data exploration and in-depth analysis (or manipulation) of vocal characteristics. Voxit is a sort of feature-rich, developmental sandbox for large-scale quantitative analysis to complement the simpler and user-friendly Drift and Gentle, which are best for qualitative, visual and small-scale quantitative analysis. The main engines for analyzing speech in Voxit are i) the same Lee-Ellis algorithm for pitch tracking that Drift uses (Subband Autocorrelation Classification), and ii) WORLD, a vocoder-based, high-quality speech analysis, manipulation, and synthesis program developed by Masanori Morise (who also worked with Hideki Kawahara on a predecessor to WORLD, called TANDEM-STRAIGHT). WORLD, which is available in C++, Python and Matlab, estimates speech parameters such as voiced-unvoiced distinctions and pitch, with the particular goal of producing high-quality resynthesized speech with low computational cost.</p>
<p>Voxit uses the Lee-Ellis pitch and other vocal/acoustic properties encoded by WORLD to provide vocal prosodic measures that have perceptual importance for speaking style, context, etc., such as pitch range (in octaves), pitch speed (in octaves per second), pitch acceleration (in octaves per second squared), and rhythmic complexity of pauses  <sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>  <sup id="fnref2:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, and more recently, intensity range and intensity speed (in decibels).<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>  (Drift4 incorporates all of the Voxit prosodic measures as well.) While Voxit does not feature forced alignment internally, it can import the word- and phoneme-level alignment produced by Gentle and derived measures based on the alignment alone, or on the alignment in relation to the other derived speech parameters. It thus offers a powerful and readily extensible toolkit for speech-acoustic-linguistic analysis for humanistic research, particularly for large datasets.</p>
<p>To better understand how the two approaches can work, and work together, we encourage users to explore a number of our publications, including  “Beyond Poet Voice: Sampling the (Non-)Performance Styles of 100 American Poets” <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>  which illustrates the applications of the Voxit toolbox with 100 sample recordings;  “After Scansion: Visualizing, Deforming and Listening to Poetic Prosody” <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup> , which walks users through applications of Drift and Gentle with 15 sample poetry recordings;  “John Ashbery’s Reading Voice” <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup> , which analyzes recordings from the 92nd Street Y over five decades; and  “101 Black Women Poets in Mainly White and Mainly Black Rooms” ,<sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>  which further analyzes 203 recordings.</p>
<p>To return to Poet Voice, when we analyzed sample recordings of 100 American poets, we found that other pitch and timing patterns — in addition to a slow pace and narrow pitch range — are also important in the perception of this style of reading poetry <sup id="fnref2:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>.</p>
<p>Voices that sound, at least to us, like they are using Poet Voice tend to read relatively slowly, with a predictable rhythm, in terms of tempo and pauses, compared to poets we might hear as more expressive or conversational, which tend to exhibit less predictable, and thus more complex, rhythmic patterns. They also tend to change pitch slowly, as well as using a relatively narrow range of pitch, again compared to more expressive or conversational speakers. The following figures show some of these variables for recordings of these poems in their entirety: Natasha Trethewey&rsquo;s  “Monument” , Louise Glück&rsquo;s  “The Wild Iris” , Cecilia Llompart&rsquo;s  “Omens” , Matthew Zapruder&rsquo;s  “When It&rsquo;s Sunny They Push the Button” , William Butler Yeats&rsquo;s  “The Lake Isle of Innisfree” , Rae Armantrout&rsquo;s  “Heart of It” , and the first 2:45 of poets who do not sound, to us, as if they are using Poet Voice.<br>




























<figure ><img loading="lazy" alt="Bar chart" src="/dhqwords/vol/17/2/000688/resources/images/figure07.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000688/resources/images/figure07_hu502af5e7481c2909a6f6ded2b0aef552_60220_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000688/resources/images/figure07_hu502af5e7481c2909a6f6ded2b0aef552_60220_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000688/resources/images/figure07.jpg 1024w" 
     class="landscape"
     ><figcaption>
        <p>Pitch Range, Speed and Acceleration in Sample Recordings by Seven Poets
        </p>
    </figcaption>
</figure></p>




























<figure ><img loading="lazy" alt="Bar chart" src="/dhqwords/vol/17/2/000688/resources/images/figure08.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000688/resources/images/figure08_hu1af203fd9bf88cca656c319a9e6dd864_52990_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000688/resources/images/figure08_hu1af203fd9bf88cca656c319a9e6dd864_52990_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000688/resources/images/figure08.jpg 1024w" 
     class="landscape"
     ><figcaption>
        <p>Rhythmic Complexity of Pauses in Sample Recordings by Seven Poets (a lower value means a more predictable rhythm)
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Bar chart" src="/dhqwords/vol/17/2/000688/resources/images/figure09.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000688/resources/images/figure09_hu454e758f48a53ed0767c52e8b709fcb2_47475_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000688/resources/images/figure09_hu454e758f48a53ed0767c52e8b709fcb2_47475_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000688/resources/images/figure09.jpg 1024w" 
     class="landscape"
     ><figcaption>
        <p>Words Per Minute in Sample Recordings by Seven Poets
        </p>
    </figcaption>
</figure>
<p>From these few samples, we conclude that, when some listeners hear poets read with even just one or two of these characteristics — slow pitch speed, slow pitch acceleration, narrow pitch range, low rhythmic complexity, and/or slow speaking rate — they hear Poet Voice. <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>  In other words, we listen selectively and use fuzzy inference, seeking at least one reason, or apparently objective vocal quality, to support or justify the way we respond to a reading style, whether we like it or not. But Poet Voice is not a monolithic manner of reading poetry, nor, to point out the obvious, is it innately irritating. Poet Voice is collectively constructed, at least in part, in the ears of listeners, as Eidsheim might say.</p>
<p>What is potentially transformative about slow listening research, as our work on Poet Voice suggests, is that the digital tools provide a nuanced empirical and quantitative perspective on the intuitions we have developed as, respectively, a poetry scholar, poet and amateur singer with years of experience attending poetry readings and listening to and teaching with poetry recordings (MacArthur), and as a neuroscientist of speech perception and amateur musician with more than a casual interest in vocal performance, in speech and song (Miller). This digital, empirical, quantitative perspective is not infallible nor objective, but it is a very useful complement to our very human perspectives. Both of us are fascinated by (and opinionated about) what makes for compelling performative speech, in teaching, in academic lectures and in U.S. culture at large. And yet we recognize — and these tools have helped us appreciate this point deeply further — that, as we test our own biases and refine our own intuitions in terms of speech perception, we need all the help we can get!</p>
<p>There is just no reason to rely any longer on older methods of impressionistic generalizing, without recourse to digital tools or computational analysis, about or from a small number of familiar recordings, which are not incorporated into the scholarship published about them, such that readers are not actually listening to the object of study. This has been the typical scholarly approach of close listening. We do not at all mean to disrespect the crucial work of close listening or of Bernstein, who has encouraged our research every step of the way. His former student Chris Mustazza, now co-director of PennSound, characterizes the new approaches we and others are using as  “machine-aided close listening”   <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>. The rich intuitions of scholars form an excellent starting point for research on poetry performance, which can benefit enormously from these digital methods. Indeed, it was heartening when Bernstein wrote about our work in 2017:  “You are certainly doing the work I had hoped might be done”  .</p>
<p>And we are not alone. In recent years, a small but growing number of literary and humanities scholars have begun to apply digital sound studies tools to the analysis of speech recordings. Some of this work is led by other fields with more training in the human voice, media history and/or digital tools. For instance,  <em>The Oxford Handbook of Voice Studies</em>  (2019) edited by Nina Eidsheim, which focuses mostly on voice in song, oral history and political speech, includes pieces by comparative literature scholar Tom McEnaney on the timbre of NPR voices, and film studies scholars Dan Wang on cinematic speech, and Jennifer Fleeger on robot speech in film.  <em>The Sound Studies Reader</em>  (2012) edited by Jonathan Sterne, also includes pieces on sound in film. The  <em>Journal of Cultural Analytics</em>  and  <em>Digital Humanities Quarterly</em>  welcome work on the study of sound in literary recordings, though both are understandably dominated by computational analysis of text and image.  <em>The Journal of Interdisciplinary Voice Studies</em> , founded in 2016, also has potential as a place to host scholarship on literary recordings.</p>
<p>Drift and Gentle have been applied to many genres of performative speech, including and beyond poetry recordings. Our NEH project Tools for Listening to Text-in-Performance, co-directed by MacArthur and Neil Verma, involved a team of 20 user-testers on Drift and Gentle from across the U.S., representing the disciplines of communications, literary studies, film studies, performance studies, media and radio history, comparative literature, science and technology studies, theatre, and media preservation. Initial results illustrate both the potential of this research for all sorts of performative speech, and the way that tools can be applied in unpredictable ways, depending on the object of study and the scholar&rsquo;s interests. For instance, the research group at the University of Wisconsin-Madison used Drift to consider  “different genres of podcasts and radio …. to analyze potential differences in tone and delivery” , and they used Gentle  “to see if different genres of podcasts have different conventions of duration and WPM [Words Per Minute, or speaking rate]”  (see <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>.</p>
<p>In an application we did not anticipate, the Podcastre group also found it useful to use Gentle&rsquo;s ability to create rough transcripts to search for particular vocabulary in podcasts, as a tool to explore which podcasts to study more closely. Gretchen Jude, a performance studies scholar, has used both tools to study the  “speed and flow of speech as well as hesitations on words, and placement and length of pauses”  in second-language speakers of English, and Adam Hammond and Jonathan Dick have used both tools to analyze different speakers&rsquo; performances of T.S. Eliot&rsquo;s  <em>The Waste Land</em> , focusing on the question of  “whether timing and pitch data from Gentle and Drift (and the outputs of the prosodic measures script) can reveal something to a human listener (very familiar with the recordings) that they didn&rsquo;t already know. Our suggestion was that they could, and our example was Eliot&rsquo;s reading of The Waste Land, which the prosodic measures position as one of the most internally varied of the readings we&rsquo;ve heard, despite most [human] listeners&rsquo; sense that he&rsquo;s among the most monotonous”   <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>.</p>
<p>Media historian Patrick Feaster (co-founder of  <em>FirstSounds.org</em> ) has used Gentle and Drift to analyze recordings of  “Cal Stewart … a well-known phonographic storyteller who recorded dozens of original comic spoken-word selections in the role of Uncle Josh Weathersby between 1897 and his death in 1919…. to compar[e] and contras[t] examples of his work in an effort to trace how his repertoire, style, and dynamic performance strategies evolved over time” . Jacob Smith, a media historian at Northwestern, has used Drift to analyze pitch variables in vaudeville ethnic stereotypes as performed on phonograph records from 1905 and 1911 by Ada Jones and Len Spencer, for an essay that appeared in  <em>The Oxford Handbook of Cinematic Listening</em> ,  “The Courtships of Ada and Len: Mediated Musicals and Vocal Caricature Before the Cinema” .</p>
<p>Another signal of serious academic interest in the intersection of sound studies and literature is a special section of PMLA in March 2020 devoted to Aurality and Literacy, curated by Matthew Rubery, author of  <em>The Untold Story of the Talking Book</em>  (2016), and Christopher Cannon. Though it did not much involve directly applying digital tools to literary recordings, one particular piece in that issue articulates both the need for and some of the obstacles to this sort of research on literary audio. As James English argues in  “Teaching the Novel in the Audio Age” , the success of the audiobook,  “the market for [which] is dominated by literary works, and specifically by novels, which comprise nearly three quarters of all sales” , necessitates new pedagogies that incorporate audio versions of literary texts into teaching, as much as the texts themselves. For English,  “[e]very vocal performance of a novel is an interpretation, a reading as well as a reading out loud”  and  “[n]one stands outside what [Matthew] Rubery calls the  politics of narration ” . Thus concerns arise, with the voices of different characters and narrators, about vocal stereotyping according to race, gender, sexuality, (dis)ability, etc. Yet he concludes that these concerns should not be a focus in teaching audio books:</p>
<blockquote>
<p>The novel is a dialogic form, and even those written in the first person (a distinct minority, by the reckoning of Ted Underwood and his collaborators) incorporate lots of reported speech. Except in the rare case of full-cast audio dramatizations, audiobooks require a vocal performer capable of rendering multiple voices. Conveying social distinctions between characters through faked accents and other tricks of the voice is a skill fundamental to performative work in the medium. Some degree of stereotyping is inescapable</p>
</blockquote>
<blockquote>
<p>The issues around vocal stereotyping can of course be embraced as teachable controversies. But that shifts time and attention away from other interpretative concerns, other teaching that we might have in mind for a class. It also requires of us some new proficiencies with classroom technology<br>
. <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup></p>
</blockquote>
<p>Those proficiencies, for English, mostly come down to preparing audio segments from audio books for listening and discussion, accepting the time commitment required, being prepared for the technical difficulties that may arise for both students and instructors — and then  “contend[ing] with our discipline&rsquo;s entrenched anti-audio prejudices” .</p>
<p>The methods of slow listening, as we have outlined them above, can be usefully applied to audio books — not to reduce the analysis to finger-pointing about vocal stereotypes, but to help students and instructors alike to think more deeply about the politics of performance and identity, so central to both the dramatization and interpretation. A former undergraduate student of English, Alexander Ullman, a Ph.D. candidate at the University of California, Berkeley, is doing promising such work on audio books and Black/Jewish identity, using Drift and Gentle. Acknowledging in our pedagogy and scholarship that the aural/oral dimensions of literature matter as much as the text, and indeed directly affect the reception and interpretation of the text, extends a long and necessary movement away from New Critical assumptions about the text&rsquo;s primacy. In teaching and studying audio books and other recorded performances of literature, we can learn to register and articulate our own implicit aural biases and preconceptions — and also, perhaps to discover a greater freedom in the choices we make as interpreters and (sometimes reluctant) performers of literature in the classroom.</p>
<h2 id="5">5.</h2>
<p>User-friendliness and open-source are two concepts that continue to guide the development of Gentle, Drift, and Voxit. The justifications for open-source software are well-known and persuasive. Familiar as the term user-friendly is, it requires some unpacking. Ochshorn, the interface designer and software developer with whom we have worked closely on Drift and Gentle, is fond of relating an anecdote to illustrate the tension between designing tools that are easy to use, and tools that transparently present the complexity behind their processes and allow the user to interact with the underlying data. The anecdote is from historian David F. Noble&rsquo;s  <em>Forces of Production: A Social History of Industrial Automation</em>   <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>. Noble writes:</p>
<blockquote>
<p>If the relationship between technical people and those who wield social power informs their designs and their estimates of what is possible, so too &hellip; does their relationship with [users] &hellip; Suppose … an engineer designed a machine for his best friend, for her birthday… saying, with true professional pride, Happy birthday. I have built for you my finest machine; it is so well-designed, it can be run by an idiot. No doubt his friend, who does not consider herself an idiot, would be taken aback…. and the engineer would be obliged to try to redesign the machine for someone who was not an idiot. This would be very difficult, given the orientation of his professional knowledge, and he might not even know where to begin. (Of course, he might start by pretending he was designing it for himself.)</p>
</blockquote>
<p>The gender of the characters in this anecdote is not accidental, of course. A DH tool like Voyant, some might say, is designed to be run by an idiot — while others would insist that it enables an accomplished historian, for instance, who has spent years mastering their field of the U.S. Civil War, and who is a parent of small children, to engage in DH research in text mining without being obliged to learn to code in their non-existent spare time or go back to school (perhaps on a one-year Mellon New Directions Fellowship) to study computer science. Gentle and Drift, in their ease of use, follow a similar approach as Voyant. Although they feature simple interfaces, however, the data and visualizations they provide require some knowledge of audio signal analysis and speech production and perception to interpret. Praat, in its user-unfriendliness, is obviously designed not for idiots but for patient linguists, for whom spending a time writing scripts to analyze recordings is a more legitimate use of their research time.</p>
<p>Noble continues the anecdote:</p>
<blockquote>
<p>However, had [the engineer] presented that same machine to a manufacturer, with the same claim — that it could be run by an idiot — he would probably have run into no such difficulty. Imbued with the philosophy of work simplification and deskilling, desirous of reducing his labor costs and minimizing his labor problems and, because of his rights as an employer, having the power to compel his workers to do idiot work, the manufacturer would probably have found his machine quite satisfactory. Indeed, it is his criteria, embedded in the engineer&rsquo;s art, that shaped his design in the first place</p>
</blockquote>
<p>We are not, in collaborating with Ochshorn on the development of Gentle and Drift, developing a product for sale, and the knowledge production that academics are engaged in is not, of course, idiot work. Rather than deskilling, we aim to draw on the different skills of researchers from different disciplines, as collaborative, cross-disciplinary work allows.</p>
<p>There is considerable value, as Ochshorn suggests in  “Intimacy and Interface”  (a survey of his work that also functions as a sort of manifesto about his approach to interface design), in interfaces that allow us to interact directly with the data that software allows us to analyze, and to understand something of the processes involved. Emphasizing the hermeneutic work of interface design and digital media analysis, he writes:</p>
<ul>
<li>Intimate interfaces cannot be wireframed or otherwise faked. They are a lens more than a frame.</li>
<li>Repetition can lead to new discoveries. Use is not “monotonous” and therefore automation is never the goal.</li>
<li>Meaning “passes through” the system. “The answer” is never directly modeled, but occurs in the heads of humans.</li>
<li>Programming intimate interfaces is more intimate than using them. And since this intimacy is fundamentally lingual, it is a non-intuitive process poorly served by “end user” tooling.</li>
<li>[&hellip;] Search, and re-search, must be processes of acquiring intimacy[,] not abstracting to an outline or de-skilling to a workflow. <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup></li>
</ul>
<p>While Drift and Gentle are not the most innovative examples of Ochshorn’s creations — some of those, developed for working artists, allow for novel interactive research with film and video, and can be sampled in a talk he gave at Google Brain in 2017<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>  — they provide both ease of interaction with the object of study (in our research recordings of performative speech) and direct access to the underlying data. They provide a lens; they are a means to an end that tries not to obscure the means; and they encourage small-scale, intimate, qualitative research as a necessary prelude to large-scale, quantitative research.</p>
<p>Our own collaboration honors the fact of disciplinary expertise — Ochshorn&rsquo;s skill in and knowledge about interface design, object-oriented programming, and audio signal processing are complemented by MacArthur&rsquo;s intimacy with poetry as an oral form and her capacity to pose rich questions about poetry performance and literary history, and by Miller&rsquo;s understanding of speech production and perception, audio signal processing and quantitative analysis. The years of training and experience that each of us brings to the collaboration cannot be underestimated. In DH, of course, it is not unusual that technical expertise is provided by men expertise is provided by men (Ochshorn and Miller), though they do not provide only that, nor that the woman participating in the collaboration (MacArthur) has acquired new technical knowledge in order to carry out the research.</p>
<p>In  “An Information Science Question in DH Feminism” , Tanya Clement writes:</p>
<blockquote>
<p>In digital humanities, the technology of mastering technology has been considered a productive means of combatting what is considered the general “degree of ignorance about information technology and its critical relevance to humanities education and scholarship” <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup> &hellip; [t]here has been much debate in DH about whether designing and building tools gives one an indispensable knowledge of its processes and whether or not women and people of color (and others) are precluded from these activities for a variety of very real and very situated reasons. In this sense, the rhetoric of mastery over technology can be intellectually prohibitive since it threatens an advancement of knowledge production from other perspectives<br>
<sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup></p>
</blockquote>
<p>While we agree that, on the one hand, requiring — much less fetishizing — technical mastery in DH research can lead to the exclusion of valuable and novel perspectives from DH research, we also have practical objections to the requirement of technical mastery. To be precise, we resist expectations that collaborative researchers can or should, on the fly or on the cheap, acquire real expertise in one another&rsquo;s disciplines. Beyond the political and economic problems with asking graduate students and scholars in the humanities to master digital technologies or acquire advanced coding skills — which must inevitably take time away from the primary study of, for instance, literary history — it is practically inefficient not to collaborate across disciplines on the development of tools such as Gentle and Drift and the Voxit toolbox, and in the research applying them to poetry recordings.</p>
<p>At the same time, it would be all too easy for a literary scholar with no background in linguistics, data visualization or quantitative analysis to misunderstand Gentle and Drift and the data they provide. Thus our approach in developing these tools, training users to apply them, and developing tutorials and documentation, has been to emphasize ease of use and access to data while also educating users on the basics of speech production and perception, audio signal processing and quantitative analysis. We are now at work on a Slow Listening book project, in collaboration with Neil Verma and Christopher Grobe, that will offer a history of machine-assisted voice analysis, a critical theoretical approach, a linguistically grounded method, and four case studies, providing models for future research, from literary performance and AI voices to radio drama and podcasts.</p>
<p>The image at the outset of this article, a pitch contour in Drift, visualizes the pitch of John Ashbery&rsquo;s voice, in a 1952 reading of his sestina  “The Painter” ,<sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>  at the 92nd Street Y in New York. The painter in the poem aspires to paint the sea. Eventually, he gives up, and leaves the canvas blank. The text shown in the pitch contour is line 9 of the poem, articulating advice given to the painter by the  “people who lived in the buildings” , who watch him work at his impossible task:  “Try using the brush / As a means to an end. Select, for a portrait, / Something less angry and large, and more subject / To a painter&rsquo;s moods”  (ll. 9-12).  “The Painter”  almost too neatly thematizes Ashbery&rsquo;s poetic ambitions — not only to represent, but to enact on the page the big impossible subject of consciousness unfolding in time, here symbolized by the changing face of the sea, as it constantly moves and shifts. This is an apt figure for the experience of listening in real time. Sound, and the human voice in particular, elude our perceptual grasp, much as the sea slips through our fingers, to mix metaphors. But these tools, we hope, extend the possibilities for listening more slowly and thoughtfully.</p>
<p>While it isn’t possible to embed audio files in this article, we do provide stable links at zenodo.org.</p>
<p>See, for instance, the Soundbox project, developed at Duke University: <a href="http://soundboxproject.com">http://soundboxproject.com</a>.</p>
<p>See our discussion of Raphael Allison’s  <em>Bodies on the Line: Performance and the Sixties Poetry Reading</em>  (2014) in <sup id="fnref3:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>. See also Leslie Wheeler, who asserts that contemporary American poets, as observed at the 2006 Associated Writers Conference, typically do not  “display emotions at their readings but instead tend . . . to manifest intellectual detachment, if not in the poem’s words then through carefully neutral delivery”   <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. This may sound intuitively accurate, but what does neutral delivery mean? Might the display of some emotions come across as vocal restraint? And so on.</p>
<p>See our discussion of Raphael Allison&rsquo;s  <em>Bodies on the Line: Performance and the Sixties Poetry Reading</em>  (2014) <sup id="fnref4:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>. See also Leslie Wheeler, who asserts that contemporary American poets, as observed at the 2006 Associated Writers Conference, typically do not  “display emotions at their readings but instead tend &hellip; to manifest intellectual detachment, if not in the poem’s words then through carefully neutral delivery”   <sup id="fnref1:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. This may sound intuitively accurate, but what does neutral delivery mean? Might the display of some emotions come across as vocal restraint? And so on.</p>
<p><a href="https://drift4.spokenweb.ca/">https://drift4.spokenweb.ca/</a></p>
<p>An average frequency for male voices is 125 Hz, and 225 Hz for female voices <sup id="fnref3:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>, though this can vary by language, region, and many other variables; by male and female in this context, we mean biological sex assigned at birth.</p>
<p>While linguists typically refer to the fundamental frequency as f0, there is some disagreement about whether to start counting at 0 or 1.</p>
<p>Please see <a href="http://dh2016.adho.org/abstracts/128">http://dh2016.adho.org/abstracts/128</a>.</p>
<p>In 2015-16, MacArthur had an ACLS Digital Innovations Fellowship at the University of California, Davis, with the initial plan of developing a pitch-tracking interface for humanities scholars using Praat and ARLO. CDG, initially funded by SAP, turned into HARC (Human Advancement Research Lab, part of Y Combinator Research). Ochshorn co-founded a start-up, Reduct.Video, in 2017.</p>
<p><a href="http://lowerquality.com/gentle/">http://lowerquality.com/gentle/</a></p>
<p><a href="https://textinperformance.soc.northwestern.edu/">https://textinperformance.soc.northwestern.edu/</a></p>
<p><a href="https://spokenweb.ca/">https://spokenweb.ca/</a></p>
<p><a href="https://drift4.spokenweb.ca/">https://drift4.spokenweb.ca/</a></p>
<p>Comparing data for intensity — volume or amplitude, in other words, measured in decibels — can be very challenging across recordings, as many variables influence intensity patterns, included the recording space, recording equipment, media format, distance of a speaker from a microphone, etc. However, patterns within recordings can be meaningful.</p>
<p><a href="https://doi.org/10.22148/16.022">https://doi.org/10.22148/16.022</a></p>
<p><a href="https://arcade.stanford.edu/content/after-scansion-visualizing-deforming-and-listening-poetic-prosody">https://arcade.stanford.edu/content/after-scansion-visualizing-deforming-and-listening-poetic-prosody</a></p>
<p><a href="https://www.theparisreview.org/blog/2019/10/29/john-ashberys-reading-voice/">https://www.theparisreview.org/blog/2019/10/29/john-ashberys-reading-voice/</a></p>
<p><a href="https://lareviewofbooks.org/article/101-black-women-poets-in-mainly-white-and-mainly-black-rooms/">https://lareviewofbooks.org/article/101-black-women-poets-in-mainly-white-and-mainly-black-rooms/</a></p>
<p><a href="http://rmozone.com/snapshots/2017/10/rmo-at-google/">http://rmozone.com/snapshots/2017/10/rmo-at-google/</a></p>
<p><a href="https://www.theparisreview.org/blog/2019/10/29/john-ashberys-reading-voice/">https://www.theparisreview.org/blog/2019/10/29/john-ashberys-reading-voice/</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Jody Kreiman and Diane Sidtis,  <em>Foundations of Voice Studies: An Interdisciplinary Approach to Voice Production and Perception</em> . New York: Wiley, 2011, 305-306.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Frost, Robert.  “Never Again Would Birdsong Be the Same” .  “Collected Poems, Prose and Plays” . New York: Library of America (1995): 308&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Goffman, Erving.  <em>Forms of Talk</em> . Philadelphia: University of Pennsylvania Press (1981).&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Bernstein, Charles (ed.)  <em>Close Listening: Poetry and the Performed Word</em> . Oxford University Press (1998).&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:6">
&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:7">
<p>Sterne, Jonathan.  <em>The Audible Past: Cultural Origins of Sound Reproduction</em> . Duke University Press Books, Durham, NC (2003): 15.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>MacArthur, Marit, and Miller, Lee M.  “After Scansion: Visualizing, Deforming and Listening to Poetic Prosody” .  <em>Stanford ARCADE Colloquy Series: Alternative Histories of Prosody</em> , Dec. 13, 2018.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Eidsheim, Nina Sun.  <em>The Race of Sound: Listening, Timbre and Vocality in African American Music</em> . Duke University Press Books (2019): 9. 26..&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:11">
&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:12">
<p>“Jacobellis v. Ohio” , 378 U.S. 184 (1964).&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>MacArthur 2016.  “Monotony, the Churches of Poetry Reading, and Sound Studies” ,  <em>PMLA</em>  131.1 (Jan. 2016): 38-63.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>MacArthur, Marit, Zellou, Georgia and Miller, Lee M.  “Beyond Poet Voice: Sampling the Performance Styles of 100 American Poets” .  <em>Journal of Cultural Analytics</em> , March 2018. <a href="http://culturalanalytics.org/2018/04/beyond-poet-voice-sampling-the-non-performance-styles-of-100-american-poets/">http://culturalanalytics.org/2018/04/beyond-poet-voice-sampling-the-non-performance-styles-of-100-american-poets/</a>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Petrusich, Amanda.  “ Domestic Arts.  Rev. of Bill Callahan’s Shepherd in a Sheepskin Vest” .  <em>The New Yorker</em>  (June 2019): 88-89.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Smith, Rich.  “Stop Using  Poet Voice .”  CityArts. Encore Media Group (July 2014).&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Wilkinson, Alec.  “A Voice from the Past” . The New Yorker (May 2014).&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Richards, I.A.  <em>Principles of Literary Criticism</em> . Psychology Press, Routledge Classics Series, New York, NY (1926, 2001).&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Glück, Louise.  “The Wild Iris” . Wild Iris. New York: Ecco (1992): 22–23.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:21">
&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:22">
&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:23">
<p>Lehiste, Ilse.  <em>Suprasegmentals</em> . Cambridge, MA, Massachusetts Institute of Technology Press (1970): 65.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Gussenhoven, Carlos.  <em>The Phonology of Tone and Intonation</em> . Cambridge University Press, New York, NY (2004): 3, 6, 5.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Dolscheid, S., Shayan, S., Majid, A., and Casasanto, D.  “The Thickness of Musical Pitch: Psychophysical Evidence for Linguistic Relativity” .  <em>Psychological Science</em> , 24(5), (2013) <a href="https://doi.org/10.1177/0956797612457374">https://doi.org/10.1177/0956797612457374</a>&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Strömbergsson, S.  <em>Proceedings of the Annual Conference of the International Speech Communication Association</em> , INTERSPEECH. <a href="https://doi.org/10.21437/Interspeech.2016-240">https://doi.org/10.21437/Interspeech.2016-240</a>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Jouvet, D., and Laprie, Y.  “Performance analysis of several pitch detection algorithms on simulated and real noisy speech data” .  <em>25th European Signal Processing Conference</em> , EUSIPCO 2017. <a href="https://doi.org/10.23919/EUSIPCO.2017.8081482">https://doi.org/10.23919/EUSIPCO.2017.8081482</a>&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Rosenfelder, Ingrid, Fruehwald, Josef, Yuan, Jiahong, et al.  “FAVE (Forced Alignment and Vowel Extraction)” . Suite Version 1.1.3 <a href="https://doi.org/10.5281/zenodo.9846">https://doi.org/10.5281/zenodo.9846</a>&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:30">
<p>Clement, T, Auvil, L., Tcheng, D.  “White Paper: High Performance Sound Technologies for Access and Scholarship” .  “White paper for the NEH Office of Digital Humanities”  (January 2016).&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:32">
&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:33">
<p>Povey, Daniel, Nagendra Goel, Lukás Burget, Mohit Agarwal, Pinar Akyazi, Feng Kai, Arnab Ghoshal, Ondrej Glembek, Martin Karafiát, Ariya Rastrow, Richard C. Rose, Petr Schwarz and Samuel Thomas.  “Low Development Cost, High Quality Speech Recognition for New Languages and Domains: Report from 2009 Johns Hopkins / CLSP Summer Workshop” . Allen Institute. Semantic Scholar (2009).&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>Ochshorn, Robert and Hawkins, Max.  <em>Gentle</em> . Computer software. GitHub. Vers. 2.0. LowerQuality, 2016.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Lee, B. and Ellis, D.  “Noise Robust Pitch Tracking by Subband Autocorrelation Classification” .  <em>Interspeech</em> . 2012.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:37">
&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:38">
&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:39">
&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:40">
&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:41">
&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:42">
&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:43">
&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:44">
<p>Oversimplifications about the voice are hard to escape, as exemplified in the game of telephone that occurred when our research briefly went viral, as in the aggregator Newser’s URL description,  “Science Proves Boring Poet Voice Exists” : <a href="https://www.newser.com/story/258972/science-proves-boring-poet-voice-exists.html">https://www.newser.com/story/258972/science-proves-boring-poet-voice-exists.html</a>. The headline was even worse:  “Poems May Be Great, but  Poet Voice  Is the Pits” . Newser misread an article that appeared in Atlas Obscura,  “An Algorithmic Investigation of the Highfalutin&rsquo;  Poet Voice ” , which in turn brought attention to but caricatured aspects of the longer article published in  <em>The Journal of Cultural Analytics</em> , and took its title not from anything we wrote about Poet Voice, but from a quotation from poet Rich Smith’s popular polemic about Poet Voice quoted above, which appeared in City Arts. <a href="https://www.cityartsmagazine.com/stop-using-poet-voice/">https://www.cityartsmagazine.com/stop-using-poet-voice/</a>&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Chris Mustazza, C.  “Machine-aided close listening: Prosthetic synaesthesia and the 3D phonotext” .  <em>Digital Humanities Quarterly</em>  12:3 (2018)&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>Mertens, Jacob et al.  “Drifting Voices: Studying Emotion and Pitch in Podcasting with Digital Tools” .  <em>Saving New Sounds: Podcast Preservation and Historiography</em> , edited by Jeremy Wade Morris and Eric Hoyt, University of Michigan Press, 2021, pp. 154–78.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Adam Hammond and Jonathan Dick  “They Do the Police in Different Voices: Computational Analysis of Digitized Performances of T. S. Eliot’s The Waste Land” .  <em>Association for Computation in the Humanities</em> , Pittsburgh, PA, June 2019.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>English, J.  “Teaching the Novel in the Audio Age”    <em>PMLA/Publications of the Modern Language Association of America</em> , 135:2, pp. 419-426. <a href="https://doi.org/10.1632/pmla.2020.135.2.419">https://doi.org/10.1632/pmla.2020.135.2.419</a>&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Noble, D.  <em>Forces of Production: A Social History of Industrial Automation</em>  Routledge: 2011.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Ochshorn, Robert.  “Intimacy and Interface” . Lecture. Davis, California. February 15, 2016.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:52">
<p>McGann, J.  “Culture and Technology: The Way We Live Now, What Is to Be Done?” .  <em>New Literary History</em> . 36:1. The Johns Hopkins University Press: 2005.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Clement, T.  “An Information Science Question in DH Feminism” .  <em>Digital Humanities Quarterly</em>  9.2 (2015).&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:55">
<p>Wheeler, Lesley.  <em>Voicing American Poetry: Sound and Performance from the 1920s to the Present</em> . Cornell University Press, Ithaca, NY, (2008).&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The Explainability Turn</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000685/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000691/?utm_source=atom_feed" rel="related" type="text/html" title="Sentiment Analysis in Literary Studies. A Critical Survey"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000692/?utm_source=atom_feed" rel="related" type="text/html" title="Unpacking tool criticism as practice, in practice"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000685/</id><author><name>David M. Berry</name></author><published>2023-07-07T00:00:00+00:00</published><updated>2023-07-07T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>How can we know what our computational infrastructures are doing to us? More to the point, how can we trust that algorithms and related technologies do not have a detrimental effect? As technologies make up more of our digital environment, they not only provide tools for thought, but they also shape and direct the very way we think. The move from relying on books to understand a topic to using the internet to research a topic is profoundly different, not only in terms of the acceleration in access to information, but also in the reliance on surfing and searching for information. These are different cognitive modes, or styles of thinking (see <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>  <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>). Digital infrastructures combined with spatial and temporal organisation create forms of digitally enabled structures that serve to change the cognitive capacity of humans (see for example <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>). In 1981, Steve Jobs, then CEO of Apple, famously called computers  “Bicycles for the Mind” , implying that they augmented the cognitive capacities of the user, making them faster and more capable <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. But others are not so positive, with writers such as Nicholas Carr worrying that they might also undermine and fragment the possibility for thought. As Carr wrote</p>
<blockquote>
<p>over the past few years I&rsquo;ve had an uncomfortable sense that someone, or something, has been tinkering with my brain, remapping the neural circuitry, reprogramming the memory. My mind isn&rsquo;t going — so far as I can tell — but it&rsquo;s changing. I&rsquo;m not thinking the way I used to think<br>
. <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
</blockquote>
<p>Similarly, Bernard Stiegler <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> has argued that the programming industries have a vested interest in changing the way individuals think to make possible a new digital consumption economy. In this paper, I examine this new situation and social responses to computational infrastructures that can now be seen to weaken historical practices of cognition. I use the term cognition to represent not just the cognitive processes of the human mind, but to include a more substantive notion which includes not only thinking, but also feeling and projecting. In particular, I understand cognition as a synthetic faculty in the application of reason which opens the possibility for a decision. The aim is to begin to account for the way in which this synthetic faculty is being automated by algorithmic processing such that the human cognitive ability to connect factors into an explanation becomes increasingly deficient. When connected into contemporary digital infrastructures, rather than acting as bicycles for the mind, these technologies replace certain cognitive functions of the mind. Being owned and controlled by corporate organisations they tend to weaken explanatory and critical thinking and instead nudge and influence human behaviour in directions that are profitable.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  When incorporated into digital platforms these technologies can be combined to create distraction spaces for what we might call frenetic passivity to repress critical cognitive activity or thought. Revelations from industry insiders and researchers of behavioural nudging and manipulation techniques have been widely documented and have served to prompt public calls for more regulation over these systems (see <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>  <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>). We have also seen changes to the regulatory environment as the public has become increasingly uneasy about these automated systems (for example, see <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>  <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>).</p>
<p>Digital technologies substitute artificial analytic capacities that bypass and replace the synthetic function of reason. Algorithms often overtake human cognitive faculties by shortcutting individual decisions by making a digital suggestion or intervention. The most obvious example of this is Google Autocomplete on the search bar which tries to predict what a user will type before they have completed a sentence – and make it easy for the user to just click that rather than thinking through what they are writing. This technology has also been rolled-out to Gmail, where Google will write a user&rsquo;s emails by predicting what it thinks the user might be planning to write. Similarly, recent breakthroughs in artificial intelligence, such as GPT-3 also create long-form, remarkably competent, written texts based on a similar automated capacity. These techniques are increasingly being incorporated into many aspects of computer interfaces through design practices that predict, persuade, or nudge particular behavioural outcomes. For example, Apple devices often know where you are due next by consulting your calendar and auto-calculating your route to the next event and warning the user of the minimum time for them to arrive – sometimes even cautioning the user to leave immediately. These technologies use the mobilisation of processes of selecting and directing activity through the automation of data from information collected from millions of users <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. As Noble has noted,</p>
<blockquote>
<p>What each of these searches represents are Google&rsquo;s algorithmic conceptualizations of a variety of people and ideas. …Google&rsquo;s dominant narratives reflect the kinds of hegemonic frameworks and notions that are often resisted by women and people of color. Interrogating what advertising companies serve up as credible information must happen, rather than have a public instantly gratified with stereotypes in three-hundredths of a second or less<br>
<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>.</p>
</blockquote>
<p>We are witnessing the social being transformed by digital technologies that transform individuals&rsquo; thinking towards operational or instrumental thought. But it is also important to remain alert to the social dimension beyond the level of the individual so that we are attentive to the relationship between social being and consciousness. This includes the reconfiguring of social life through the technical infrastructures of computational mediation which themselves privilege individualistic ways of framing and understanding the world. A consequence of which, as Geert Lovink has noted, is that  “there is no  social  anymore outside of social media.”  Merleau-Ponty earlier warned us,</p>
<blockquote>
<p>Thinking operationally becomes a sort of absolute artificialism, such as we see in the ideology of cybernetics, where human creations are derived from a natural information process, but which is itself conceived on the model of human machines. If this kind of thinking takes over humanity and history, and if, pretending to be ignorant of what we know about humanity and history through contact and through location… then we enter into a cultural regimen in which there is neither truth nor falsehood concerning humanity and history, then we enter into a sleep or nightmare from which nothing would be able to awaken us<br>
<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>.</p>
</blockquote>
<p>Whilst I do not have the space to rehearse all the arguments that inform this paper (but see <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>  <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>  <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>), it can be seen that resituating the cognitive processes of thought within the concrete reality of the increasingly smart infrastructures that surround us changes not only how we think but also our relationship to the decisions that are taken on our behalf. My aim is to use the way in which infrastructural logics of computation decentre and overtake modes of thought, for example by undermining concentration, focus and attention, to examine the way in which this leads to a situation that undermines trust in systems. This is to critically assess attempts to assuage worries over the opaque and threatening potential of computation through a new right to challenge algorithms and their decisions called explainability. I will later suggest new critical practices are possible within digital humanities for investigating and potentially contesting these technologies by taking on board and extending this notion. <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup></p>
<p>I believe that the  <em>General Data Protection Regulation 2016/679</em>  (GDPR) <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> can help us to understand this new problematic. When instantiated in national legislation it has created a new right in relation to automated algorithmic systems that requires the controller of an algorithm to supply an explanation of how a decision was made to the user (or data subject) – what we might call the  <em>social right to explanation</em> . The GDPR is a regulation in EU law on data protection and privacy for citizens within the European Union and the European Economic Area.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>  The GDPR creates a new kind of subject, the data subject to whom a right to explanation (amongst other data protection and privacy rights) is given. The notion of a data subject has a range of very specific and unique rights as a natural person, which distinguishes them from an artificial intelligence, machine-learning system, algorithm or indeed a corporation. This definition creates what we might call a post-posthuman subjectivity by creating and reinforcing a boundary between humans, corporations and machines.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>  Additionally, it has created a legal definition of processing through a computer algorithm <sup id="fnref1:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>. In consequence, this has given rise to a notion of explainability which creates the right  “to obtain an explanation of [a] decision reached after such assessment and to challenge the decision”   <sup id="fnref2:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>  It has been argued that this regulation mandates a requirement for a representation of the processes of computation used in an automated decision, the calculative model, for example, and for it to be presented to the data subject on request (<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>  <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> , cf. <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>).<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>  It is crucial however to understand that this is not just an issue of legal rights, this has also created a normative demand for a social right to explanation.</p>
<p>This debate has had implications for artificial intelligence systems with the assumption that they might have to have the capacity to provide a self-description. This has become known as the problem of explainability for artificial intelligence research, and has led to the emergence of the subfield of Explainable Artificial Intelligence (XAI). Although the GDPR is limited to the European Union, in actuality it is likely to have global effects as it becomes necessary for global companies to standardise their software products and services but also to respond to growing public disquiet over these systems (see also <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>  <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>  <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>).<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>  This has also become part of a wider public discourse. Explanation was one of the rights outlined in an  <em>algorithmic bill of rights</em>  published in 2019, for instance, which argued that</p>
<blockquote>
<p>we have the right to be given explanations about how algorithms affect us in a specific situation, and these explanations should be clear enough that the average person will be able to understand them&hellip; The terms of service for an AI application — or any service that uses algorithmic decision-making processes — should be written in language plain enough that a third grader can comprehend it&hellip; It should be available in every language as soon as the application goes live.  <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup><br>
.</p>
</blockquote>
<p>Consequently, Explainable AI has become known as transparent AI because it attempts to design AI systems whose actions can be easily understood by humans. These new AI systems are designed to produce more  “explainable models, while still maintaining a high level of learning performance”  and prediction accuracy thus helping humans to  “understand, appropriately trust, and effectively manage the emerging generation of artificially intelligent partners”   <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. This means that XAI systems should have to have the ability to explain their rationale, characterise their strengths and weaknesses, and convey an understanding of how they will behave in the future in order to strengthen their public accountability. These requirements pose a very difficult challenge to the developers of these systems and remain aspirational in AI system design.</p>
<p>One of the key drivers for the attention given to explainability has been a wider public unease with the perceived bias of algorithms in everyday life, especially in the rise in automated decision processes and the calls for accountability in these systems (see <sup id="fnref1:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>  <sup id="fnref1:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>). Many of these debates foreground the question of the future of humanity and the kinds of societies that these technologies create the conditions for. These implications are increasingly discussed in the media and in politics, particularly in relation to a future dominated by technologies which are thought to have huge social consequences. Computation combined with artificial intelligence and machine learning has raised challenging questions about creativity, post-work futures, mass unemployment, AI controlled drone systems, and surveillance capitalism amongst other impacts. These are important issues, but here I drill down to focus on the cognitive and explanatory issues.</p>
<p>The discussion I wish to present in this paper is largely speculative. My aim is to explore how the cognitive capacities of humans might be strengthened by developing that capacity for explanatory modes of thought through the use of explainability as a critical concept. It seems to me that we have two issues that are interesting to consider. Firstly, the GDPR requires digital technologies, such as automated decision systems (ADS), to be explainable in some sense and therefore pose a problem of representation.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>  Secondly, interpretation problems stem from a difficulty in translating a highly complex processual system that does not immediately lend itself to easy explanation for a number of difficult reasons. Explanation has nonetheless become expected as part of the political and legislative response to concerns over algorithmic inequality, bias and the opaqueness of computational systems.</p>
<p>In the first section of this paper, I seek to outline the contours under which this critique becomes urgent by an initial examination of cognitive infrastructures. In the second section, I turn to think about the concept of explainability and its potential for developing a possible tactic in response to the wider toxicity generated by algorithmic governance. The aim is to offer an immanent critique of the notion of explainability. By immanent critique, I refer to an approach drawn from the Frankfurt school, whereby the internal terms and concepts within a system are examined in relation to the reality of the claims they make about and the actuality of the world. Thus, computational systems are justified both discursively and in terms of their internal logics and yet there are contradictory tendencies in these supposedly univocal systems. Discourse and algorithms become a technique to exercise power, for example through nudging strategic behaviour for shaping the labour, both physical and mental, of users in specific digital environments, however these behavioural techniques do not always produce the desired effect. Although behavioural logics of control operate in our everyday lives which are subject to algorithmic management from increasingly prevalent hyper-individualised capillaries of power, there remain spaces of contestation. The justificatory move to explainability as a panacea for these systems is therefore an important diagnostic site for interrogating algorithms&rsquo; power and ubiquity. <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup></p>
<h2 id="1-thinking-infrastructures">1. Thinking Infrastructures</h2>
<p>One of the most difficult tasks facing the critical theorist today is understanding the delegation and prescription of agency in digital infrastructures. Due to their size and complexity these infrastructures are capital intensive systems and hence tend to be developed by corporations or governments in order to combine multiple systems into a single unity. In this form they point towards a unification of multiple grammars within a system of communication, such that they converge on a single ontology or technical stack. This tendency eventually allows for an underlying infrastructure to be commoditised as an external product in its own right, such as shown with the Amazon Web Services (AWS) system. AWS was originally created for Amazon&rsquo;s internal purposes as a corporate retentional system. Since 2006 it has become a key infrastructure with an annual income of its own of $17.1 billion (8% of Amazon’s annual revenues in 2017) and is used by customers and even competitors for various forms of so-called cloud computing. These infrastructures can be understood as systemic, themselves made up of a number of component layers, but nonetheless constituting a distinct digital totality and increasingly structured through the data architecture made possible through the implementation of edge, core and cloud compute. Edge devices, such as smartphones, feed data into core (on-premises large computing data centres) for algorithmic processing, or to cloud (off-premises shared data servers) to run AI models or complex operations. This network topology is often called the edge-to-core-to-cloud pipeline for efficiently processing data, moving data to algorithms located where the processing power is best located.</p>
<p>The patterning of these layers of computation into vast laminated systems creates what I call infrasomatization (see <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>). This notion draws on the work of Bernard Stiegler who has pointed to Alfred J. Lotka&rsquo;s and Nicholas Georgescu-Roegen&rsquo;s notion of exosomatization as a crucial means of understanding computational capitalism (see <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>  <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>).<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>  Exosomatization and endosomatization were developed by Lotka and Georgescu-Roegen in their work on ecological economics and by Karl Popper in relation to what he called objective knowledge (see <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>  <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>  <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>  <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>  <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>). Exosomatization can be understood as the use of tools (from Greek exō meaning outside), whereas endosomatization is the evolutionary adaptation of bodies into claws, nails, shells, etc. (from Greek endon meaning within), soma, of course is from the Greek sōma meaning body.</p>
<p>Whilst these have been important contributions, by introducing a third term, infrasomatic, I want to argue that we should move beyond a binary of either endosomatic or exosomatic. I think this notion captures the reticular nature of specific forms of digital technologies, which create new non-human agencies and, potentially, unpredictable entropic effects – so infrasomatization combines the notion of using software, information and automation to create infrastructures. To concentrate on the notion of infrasomatization, is to try to understand the particularity of how algorithms are deployed as a new form of cognitive infrastructure. That is, algorithms are not just exosomatizations, not just the production of tools or instruments. Infrasomatizations are created by the combination of other infrastructural systems. Indeed, infrasomatizations rely on a complex fusion of endosomatic capacities and exosomatic technics leading to what Berns and Rouvroy call algorithmic governance <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup> and Stiegler has called the automatic society <sup id="fnref1:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>. Infrasomatizations can be thought of as social-structuring technologies – inscribing new forms of the social (or, in a neoliberal register, sometimes the anti-social) onto the bodies and minds of humans and their institutions. They are made to be always already poised for use, to be configured and reconfigured, and built into particular constellations that form the underlying structures for the creation of social subjects. Infrasomatizations have an obduracy that can be mobilised to support specific instances of thought, rationality and action. So, for example, in the case of social media, the technical infrastructure introduces a new element overtaking and reconfiguring social relations through a new grammar of communication prescribed by these technologies. This results in changes in social relations and consequently social being. Infrasomatizations can be understood to operate in a similar manner to an infra-law, which Foucault described as,</p>
<blockquote>
<p>extend[ing] the general forms defined by law to the infinitesimal level of individual lives; or they appear as methods of training that enable individuals to become integrated into these general demands. They seem to constitute the same type of law on a different scale, thereby making it more meticulous and more indulgent<br>
<sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>.</p>
</blockquote>
<p>Infrasomatizations similarly have the capacity to operate across different scales with remarkable fidelity, from micro-targeting of nudges, to aggregated groups or universes of individuals which can be manipulated simultaneously. The term infrasomatization also gestures toward a kind of gigantism, the sheer massiveness and interconnectedness of fundamental computational technologies and resources. The infrastructural dimension of these infrasomatizations means that they can be scaled to the level of planetary technics, as their physical location, particularly when presented as computational abstractions such as notions of compute, can be strategically placed (and moved) dynamically and geographically. Compute, in this sense, is an abstract unit of computation which tends to be priced at a particular level by cloud server companies so one can purchase a certain capacity of computation. The cloud infrastructures&rsquo; size contrasts with the phenomenological experience of the minuteness or ephemerality of the kinds of personal devices that are increasingly merely interfaces or gateways to underlying smart infrasomatic systems. For example, we might consider how technologies of location are made possible by the geospheric locative satellites, in particular GPS, but also extrapolation from WiFi, camera and audio data. Location is as crucial to the development of infrasomatizations as is the machine-learning of abstract patterns in data. This is because location provides important context, and this context enables smarter abductions to be made with data, assuming as it does that a specific piece of information, practice or action makes more sense within a particular place.<sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>  This is manifested in a dual structure which has a physical and logical geography often encoded simultaneously into infrasomatizations. The first kind of location that are understood within the computational systems of infrasomatizations tend to be place-poor, lacking an understanding of the specificity of place and tend towards a calculative, instrumental Cartesian representation of space. This is in marked contrast to the phenomenological experience of place infused with mood, texture, relationships and materiality <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>.<sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>  The second is a technical geography overlaid onto this grid, as noted above, with the division into engineering data and processing distribution over a system division of edge, core and cloud. Although these are invisible to the user, this new secondary tripartite division of the computational is arguably more important and increasingly saturates everyday life, due to the infrasomatic distribution of processing and analysis that this structure requires and makes possible.<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup></p>
<p>A process of cybernetic feedback, where the system is able to self-monitor across this geography means that infrasomatic systems strengthen and grow. For example, the computational capacities of Amazon&rsquo;s infrastructural systems increase their reach and power from the use of its client&rsquo;s computational practices and metadata. An infrasomatization thereby learns from its usage, which creates an amplification loop which eventually cements its functionality as a computational necessity – it becomes smart. It knows when to move computational capacity from cloud to core, when to move compute resources into specific geographic locations and when to cache data requests across the system&rsquo;s geographic spread. Hence by extrapolating and scaling these learning systems, a private corporate retentional system becomes first a regional and then planetary one. This is commonly referred to as Infrastructure As A Service (IAAS). One of the key elements towards understanding these large-scale infrasomatizations is that they tend towards a logic of value extraction. That is, that their size and scale create a tendency that is manifest in the algorithms that make up these systems towards data capture and its intensification towards the maximisation of rent-seeking behaviour. This is largely a logic dictated precisely from the fact that many of these systems tend towards monopoly or oligopolistic behaviour – what Peter Thiel infamously referred to as a move from  “zero to one”   <sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>. This is because as a disparate collection of digital subsystems is subsumed within a larger totality, the utility of this system eventually becomes overwhelming and cost-effective such that moving or exiting an infrastructure is increasingly prohibitive. This creates the possibility for monopoly rent on the infrastructure and hence drives the tendency toward gigantic informational systems, and monopoly-oriented corporations. Thus, the principal means of value extraction enacted in these infrasomatizations tends to be through the control of multiple monopolies at different layers of the technical stack. It goes without saying that this is an extremely profitable means of extracting value creating new forms of powerful companies, such as the FAANG corporations (Facebook, Apple, Amazon, Netflix, Google).</p>
<p>Within popular culture, a wider social concern with algorithms can be seen in the social media which have been used to highlight the inexplicable ways in which people&rsquo;s lives have been affected by an algorithmic decision. Sometimes these discussions reflect a confusion by users over the distinction between noise, where the decision is affected by incomplete or inaccurate data causing inconsistency or no decision being made, and bias, where the accuracy of a decision has been swayed by a predetermined or computed result affected by human biases (see <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>). These have been used to justify a need for explanation to help the public understand algorithms. Bias in computer systems usually derive from either (1) data-driven bias, where the biases are embedded in the data itself, (2) bias through interaction with humans, for example Microsoft’s Tay chatbot which developed a fascist conversation style (3) emergent bias, for example through likes and shares, (4) similarity bias, where filter bubbles can emerge, and (5) conflicting goals bias, where stereotypes have been used in the development of the software in particular ways <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>. Indeed, there are now many documented cases where algorithmic decision processes have discriminated against people on the basis of their names, their home address, gender or skin colour <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>  <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>  <sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>.<sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>  This is reflected in an  “anxiety felt by those who fear the potential for bias to infiltrate machine decision-making systems once humans are removed from the equation”   <sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>. It is in this context that public disquiet has risen in relation the perceived unfairness of these, often unaccountable, automated algorithmic systems.</p>
<p>So Facebook, for example, has created an infrasomatization for capture and exploitation of the social graph, particularly digital identity, through its social network and the creation of facial recognition systems such as Detectron <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>. Google similarly has created infrasomatizations for the various functions of search, compute, storage and databases, networking, big data, and cloud AI, identity and security, Internet of Things (IoT), API platforms, and location services, such as Google Maps. These are often built extremely quickly and issues of bias are rarely considered as part of this engineering effort. This phase of digital transformation is easily missed as it takes place behind the interface in proprietary corporate environments, and as such is a non-visual dimension of a computational mode of development. Through these infrasomatic logics, cultural practices are captured and rearticulated through grammars of action which can be used to describe, and then build infrasomatizations that may become cultural monopolies in their own right. For example, the contemporary emergence of a vast social system structured around social media which inculcates a craving for likes, followers, subscribers and views directly connected to a political economy of advertising, marketing and consumption is only the most obvious contemporary manifestation of this process.</p>
<p>The implications of this new system of exploitation is the creation of constellations of infrasomatizations that can be mobilised into de facto monopolies in specific imbrications. This, I would argue is a better way to understand these computational structures rather than the notion of platforms that tends to use a self-description favoured by companies in Silicon Valley itself, and therefore hides more than it reveals. These infrasomatic systems are able to extract rent or tolls to pass data and calculations around a system – whether measured in terms of compute, data traffic or time. The forms of data they carry, even if only manifest as abstract metadata, are in themselves extremely valuable. Even if a particular customer of the infrasomatization may expressly prohibit the harvesting of their own data they cannot control secondary data produced as a result of their interaction on the system. This infrasomatic data offers another means of value extraction, both in terms of predicting the future growth of these infrastructures, but also the potentials for new circulations of data and logic for profit. By use of these multiple data exhausts, the owners of these infrasomatizations are able to capture trends, identify social tendencies and patterns, and to reincorporate this knowledge into their infrasomatic ecology, and depending on the corporation, feed this information back into circulation to amplify these tendencies in a profitable direction. Within Silicon Valley this is understood as the capacity of a digital company to create a moat which prevents competitors from disrupting their business model, rather like a castle with a moat surrounding it to prevent attack and capture. The creation of an infrasomatic layer is, therefore, not just a digital logic, it is also a business logic. These logics reinforce each other, creating a structure that, given enough physical computing infrastructure can scale at an exponential pace, and thereby capture value and create a kind of dependency in its customers and users very quickly.</p>
<p>The need to convert this raw data from its digital logic into a business logic has consequently resulted in major breakthroughs in artificial intelligence, particularly machine learning, through the creation of classification and filtering systems modelled on brain structures, and the underlying neurons. Consequently, we see a growing use of computational systems to abstract, simplify and visualize the amount of Big Data that is being collected. A side-effect of this has been to reinforce a tendency towards causal and statistical models to map, understand, and interpret complex social and cultural phenomena. For example, in 2008 Chris Anderson famously announced the End of Theory as he claimed the data deluge had made the scientific method obsolete. Indeed, he argued that  “we can stop looking for models, instead we can analyze data without hypotheses” . He further argued that we can  “throw the numbers into the biggest computing clusters the world has ever seen and let statistical algorithms find patterns where science cannot”  and that  “with enough data, the numbers speak for themselves”   <sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>. But of course, this shift to statistical explanation is not neutral, rather it is linked to the emergence of a political economy specific to the computational. In this data-based accumulation regime social life is transformed into calculable and predictable social trends which may be manipulated and channelled. The most striking example of this regime is the use of Facebook data by the company Cambridge Analytica which they argued could create psychographic models which could then be nudged to influence behaviour. The alleged result of these techniques includes the Brexit referendum result and the election of Donald Trump as president in 2016 <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>. Although their efficacy remains contested these nascent techniques are continually refined and improved and moved from a communicational terrain to a cognitive one.</p>
<p>Computation today means to be in the middle of things, it is no longer an end, but rather a means, a passage-way between two points: from dumb to smart. In becoming smart devices, computational systems transform everyday life into what can be thought of as a vast oil field of data, awaiting extraction by a new set of digital cultural industries. It is of no surprise that FAANG (Facebook, Apple, Amazon, Netflix and Google), the leaders of the technology industry, are racing to create the technologies for their vision of a digital life. Mathematician and architect of supermarket giant Tesco&rsquo;s Clubcard, Clive Humby, described data as the new oil in 2006 <sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>. It is increasingly clear that we are now in the middle of an oil rush at the centre of which lies our lives. As Wired explains,  “like oil, for those who see data&rsquo;s fundamental value and learn to extract and use it there will be huge rewards” <sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>. Humby further argues that  “data is just like crude. It&rsquo;s valuable, but if unrefined it cannot really be used. It has to be changed into gas, plastic, chemicals, etc to create a valuable entity that drives profitable activity; so must data be broken down, analyzed for it to have value” . But it is not just the one-off collection of data, it is the iterative gathering of data, repeated again and again that creates the conditions for these possible insights. The oil fields of life will not soon be spent, instead they will yield greater and greater quantities of data, from which more profit can be earned.<sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup></p>
<p>This extractive metaphor serves not only Silicon Valley but also inspires governmental policy. For example, Meglena Kuneva, European Consumer Commissioner, has without blinking, described personal data as  “the new oil of the internet and the new currency of the digital world”   <sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup>. The UK Office for National Statistics has argued that  “if data is the new oil, open data is the oil that fuels society and we need all hands at the pump”   <sup id="fnref:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup>. What makes data into open data, is that it is free of intellectual property restrictions that prevent it from being used by others by publishing constraints, such as copyright, or that it is owned exclusively by its creators. Open data, like open access publications and open source before them, grants a corporation the right to dice up and remix data. When you use your smartphone, or a smart object, the first thing that has to be clicked is the agreement to let companies extract and use this data. As the New York Times argues,</p>
<blockquote>
<p>Personal data is the oil that greases the Internet. Each one of us sits on our own vast reserves. The data that we share every day — names, addresses, pictures, even our precise locations as measured by the geo-location sensor embedded in Internet-enabled smartphones — helps companies target advertising based not only on demographics but also on the personal opinions and desires we post online<br>
<sup id="fnref:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup>. </p>
</blockquote>
<p>These claims reflect what we might call a cult of data-ism and a renunciation of the extended and important role of critical reason and theoretical thinking in modern society. But this data-ism extends beyond the mere collection of data and its analysis. Data that is collected in data lakes can be used to formulate behavioural and predictive logics which can provide useful interpretative and calculative advantages to corporations. They then provide the opportunity for algorithmic interventions – what I call algoventions – into patterns of behaviour or thought. These practices have been increasingly extended across society, but possibly the most intensive and ambitious use of these infrasomatic technologies takes place in so-called smart cities. Here the city is built from the ground up to facilitate the data capture and feedback loops to make possible a management and organisational control layer over the city giving top-view to city officials, but also selectively sharing data with corporations and individuals to use in their everyday activities. For example, public transport usage and problems can be collected, aggregated and circulated back to the users of the public transportation system to provide them with early-warnings of issues, propose alternate routes, or to alert them to major outages in a system. Smart cities, and their underlying infrasomatizations, are strongly coupled to geolocation data, indeed, the grid of the city is a key abstract principle upon which the data about a city is projected. By unifying multiple data streams derived from smart infrastructures, smart city computers can create realtime digital twins which attempt to create and thereby impose a data-centric spatial logic onto city life. These systems are tasked with classifying, understanding, and predicting future states of the digital twin of the city, that is the city as a gigantic finite-state machine built on the collection of massive amounts of civic, corporate and personal data.</p>
<p>Through a combination of these techniques, infrasomatizations are created which produce smart technologies that act as gateways that open out to spatial forms of organisation that delegate a locative-calculative model onto the user, structuring the world in terms of an index of spaces that are given relational properties within the row and column structure of the underlying tables and databases. We therefore need to contest this new social pattern and develop alternative visions – part of which can be through creating new tools and new modes of working with technology, but we also need tool criticism and a research programme dedicated to understanding the algorithmic condition.<sup id="fnref:67"><a href="#fn:67" class="footnote-ref" role="doc-noteref">67</a></sup></p>
<h2 id="2-the-explainability-turn">2. The Explainability Turn</h2>
<p>It is clear that in the context of infrasomatizations, the first important question we need to consider is what counts as an explanation. Indeed, explanations are generally considered to be able to tell us how things work and thereby giving us the power to change our environment in order to meet our own ends. In this sense of explanation then, science is often supposed to be the best means of generating explanations <sup id="fnref:68"><a href="#fn:68" class="footnote-ref" role="doc-noteref">68</a></sup>. So, with a stress on the importance of explanation, the GDPR makes it a criterion of adequacy for satisfactory use of algorithmic decision systems in the European Union, and thereby legitimating their use in a multitude of settings. Thus, explainability and the underlying explanation are linked to the question of justification. So, what then is an explanation?</p>
<p>Hempel and Oppenheim <sup id="fnref:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup> argue that an explanation seeks to  “exhibit and to clarify in a more rigorous manner” . Some of the examples they give include whole temperature reading from a mercury thermometer, which can be explained using physical properties of the glass and of mercury which has been rapidly immersed in hot water. Similarly, they present the example of an observer of a row boat where part of the oar is submerged under water and appears to be bent upwards <sup id="fnref1:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup>. An explanation therefore attempts to explain with reference to general laws. Mill argues that  “an individual fact is said to be explained by pointing out its cause, that is, by stating the law or laws of causation, of which its production is an instance”  and that  “a law or uniformity in nature is said to be explained, then another law or laws are pointed out, of which that law itself is, but a case, and from which it could be deduced”   <sup id="fnref:70"><a href="#fn:70" class="footnote-ref" role="doc-noteref">70</a></sup>. Similarly, Ducasse argued in 1925 that  “explanation essentially consists in the offering of a hypothesis of fact, standing to the fact to be explained as case of antecedent to case of consequent of some already known law of connection”   <sup id="fnref:71"><a href="#fn:71" class="footnote-ref" role="doc-noteref">71</a></sup>. Hempel and Oppenheim therefore argue that an explanation can be divided into its two constituent parts, the explanadum and the explanans,</p>
<blockquote>
<p>By the explanandum, we understand the sentence describing the phenomenon to be explained (not the phenomenon itself); by the explanans, the class of those sentences which are adduced to account for the phenomenon<br>
<sup id="fnref2:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup>.</p>
</blockquote>
<p>In this sense of an explanation, the explanandum is a logical consequence of the explanans. The explanans itself  “must have empirical context, that is, it must be capable, at least in principle, of test by experiment or observation,”  which creates conditions for testability. However, this causal mode of explanation can become inadequate in fields concerned with purposive behaviour, as with infrasomatic digital systems.</p>
<p>In this case it is common for reference to purposive behaviour, such as in so-called machine behaviour, to be given in relation to motivations and therefore for teleological rather than causal explanation. Thus, the goals sought by the system are required in order to provide an explanation. Teleological approaches to explanation may also make us feel that we really understand a phenomenon because it is accounted for in terms of purposes, with which we are familiar from our own experience of purposive behaviour. One can, therefore, see a great temptation to use teleological explanation in relation to AI systems, particularly by creating a sense of an empathetic understanding of the personalities of the agents. So, a proposed explanans might sound suggestively familiar, but  “upon closer inspection proves to be a mere metaphor, or to lack testability, or to include no general law, and therefore to lack explanatory power”   <sup id="fnref3:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup>. In relation to explanation, therefore, explainability needs to provide an answer to the question why? Scriven argues that  “the right description is the one which fills in a particular gap in the understanding of the person or people to whom the explanation is directed” . This can be seen as the value of explainability as  “closing the gap in understanding (or rectifying misunderstanding)”   <sup id="fnref:72"><a href="#fn:72" class="footnote-ref" role="doc-noteref">72</a></sup>.</p>
<p>It is clear that the concept of explainability, and the related practices of designing and building explainable systems, have an underlying theory of general explainability, but also a theory of the human mind. These two theories are rarely explicitly articulated in the literature, and I want to bring them together to interrogate how explainability cannot be a mere technical response to the contemporary problem of automated decision systems, but actually requires philosophical investigation to be properly placed within its historical and conceptual milieu.</p>
<p>The next important move is to connect the concept of explanation to automated decision systems and the explanations that they can provide. As shown above, writers such as Friedman have argued that explanation is almost always explanation of laws as a general regularity or pattern of behaviour more typical of the physical sciences <sup id="fnref:73"><a href="#fn:73" class="footnote-ref" role="doc-noteref">73</a></sup>. But far too many discussions of explanation assume that what can be said about scientific explanation exhausts what of interest there is that can be said about explanation. However, in relation to algorithmic systems what we tend to be talking about is what Ruben has called  “singular explanation”  Additionally, explanation is ambiguous as it may refer to the product or to a process, so as Bromberger points out, an  “explanation may be something about which it makes sense to ask: How long did it take? Was it interrupted at any point? Who gave it? When? Where? What were the exact words used? For whose benefit was it given?”  (Bromberger, quoted in <sup id="fnref1:73"><a href="#fn:73" class="footnote-ref" role="doc-noteref">73</a></sup>). The other form of explanation  “may be something about which none of the [previous] questions make sense, but about which it makes sense to ask: Does anyone know it? Who thought of it first? Is it very complicated?”   <sup id="fnref2:73"><a href="#fn:73" class="footnote-ref" role="doc-noteref">73</a></sup>.  So, in speaking of an explanation one might be referring to an act of explaining, or to the product of such an act.</p>
<p>It certainly seems to be the case that the right to explanation that is being developed in relation to the GDPR is chiefly interested in the idea of an explanatory product. Thus, an explanatory product can be characterised solely in terms of the kind of information it conveys, no reference to the act of explaining being required. The question therefore becomes, what information has to be conveyed in order to have explained something? So in terms of the requirements given, the function of explanation is that explanation should enable us to understand why something has happened within an automated decision system. Crucially, this connection between an explanatory product and the legal regime that enforces it has forced system designers and programmers to look for explanatory models that are sufficient to provide legal cover, but also at a level at which they are presentable to the user or data subject. It is also uncertain if the  “right is only to a general explanation of the model of the system as a whole (&lsquo;model-based&rsquo; explanation), or an explanation of how a decision was made based on that particular data subject&rsquo;s particular facts (&lsquo;subject-based&rsquo; explanation)”   <sup id="fnref:74"><a href="#fn:74" class="footnote-ref" role="doc-noteref">74</a></sup>. This is not an easy requirement for any technical system, particularly in light of the growth of complicated systems of systems, and the difficulty of translating technical concepts into everyday language. It might therefore be helpful to think in terms of full and partial explanation, whereby a partial explanation is a full explanation with some part left out. That is, that, while presenting a complicated system of automated decision systems, it is likely pragmatically that explanations will assume an explanatory gap, assuming that the data subject is in possession of facts that do not need to be repeated. It will be interesting to see if the implementation of these systems results in an explanatory pragmatism, and how the legal system responds. </p>
<p>This of course leads to the danger of creating persuasive explanations rather than transparent explanations or a pragmatic explanation drawing on the notion of a good enough explanation. It also raises questions related to the over-simplication of explanations or misleading explanations and how one might challenge them or even question their underlying explanatory model.<sup id="fnref:75"><a href="#fn:75" class="footnote-ref" role="doc-noteref">75</a></sup>  This difficulty might explain the recent turn towards explainability through the notion of machine behaviour, drawing on insights drawn from research on humans and animals applied to machines.<sup id="fnref:76"><a href="#fn:76" class="footnote-ref" role="doc-noteref">76</a></sup>   These researchers argue,</p>
<blockquote>
<p>in the context of machines, we can ask how machines acquire (develop) a specific individual or collective behaviour. Behavioural development could be directly attributable to human engineering or design choices…. [or] a machine may acquire behaviours through its own experience. For instance, a reinforcement learning agent trained to maximize long-term profit can learn peculiar short-term trading strategies based on its own past actions and concomitant feedback from the market… In the study of animal behaviour, adaptive value describes how a behaviour contributes to the lifetime reproductive fitness of an animal. In the case of machines, we may talk of how the behaviour fulfils a contemporaneous function for particular human stakeholders<br>
<sup id="fnref:77"><a href="#fn:77" class="footnote-ref" role="doc-noteref">77</a></sup>.</p>
</blockquote>
<p>So underlying the concept of explainability is the assumption that algorithms are themselves explainable and following from that, that algorithms are something that can be explained to a human. This further assumes that the interpretative activity that humans are capable of can be mobilised to understand algorithms, or at least their active computational dimension. But the concept also assumes that there exists what we might call a general algorithmic explainability, in other words that all computational processes can be rendered as an explanation, and therefore explained with recourse to a translation into the discursive or symbolic order in which humans can interpret what an algorithm is doing. This therefore gestures to a theory of the human mind whereby subjective experience is capable of undertaking interpretative work and thereby of creating meaning out of an explanation of a given algorithm. But in cases where the infrasomatic systems are progressively undermining this kind of cognitive skill, this reveals a contradiction in the notion of explainability – humans might struggle to understand explanations and might therefore require cognitive support from visualisation systems created to support that capacity.</p>
<p>There is an assumption that provided we know all the factors that influenced an automated decision, whether directly or indirectly, we must be able to comprehend the movement of states within which an automated system must move on the occasion of a certain event, set of data, or calculation. However, this assumption is rather ambitious in that it assumes a lot of background, contextual or tacit knowledge and a particular level of cognitive capacity. Renz <sup id="fnref:78"><a href="#fn:78" class="footnote-ref" role="doc-noteref">78</a></sup> describes this mode of apprehending and understanding realistic rationalism, arguing that  “a realistic rationalism must be able to make plausible that everything that is or that happens can in principle be grasped or comprehended — that every being is, to use a traditional term, intelligible” . This might imply that an algorithm is different from its explanation, and that the algorithm exists prior to its explanation. This also has methodological implications such that an explanation must be able to secure the intelligibility of the automated process within the concepts already understood by the human interpreter.</p>
<p>These requirements raise difficult issues for designers of algorithmic decision systems as they might be impossible to implement, even on systems that seem relatively simple on the surface. As discussed above, a major justification is the growing public concerns over biases, whether intentional or not, being built into an algorithmic or machine-learning system. So, the new right to explanation has been mobilised as an attempt to mitigate these worries but also put in place legislative means to seek redress for them through the GDPR. But this does not necessarily mean that the actual algorithm need be provided, nor details of the processing steps outlined. Thus, this is increasingly a representational challenge – how to represent an algorithmic decision to a data subject. In effect, the processing might be presented as a simplified model, or explanation, that shows the general contours of the algorithm used in a particular case to an assumed reader, an increasingly cognitively sophisticated user who can understand the explanation.<sup id="fnref:79"><a href="#fn:79" class="footnote-ref" role="doc-noteref">79</a></sup></p>
<p>I call this the Explainability Turn. It is a genuinely interesting question as to the extent to which explainability will be able to mitigate the public anxieties manifested when confronted with opaque automated decision systems. The scale of the challenge represented by the requirement to provide an explanation seems to me to be under-appreciated, and clearing the grounds for even thinking about this problem cannot be overstated. It nonetheless seems clear that the notion of explainability has been derived from an epistemological insight informed by debates over how scientific activity itself can be explained. However, computers and their algorithms are not so easily fitted into the derivations of general laws that explanation seems to require, and this assumption therefore remains an interesting aporia in the notion of explainability.</p>
<p>Hence, I argue that thinking about explanation in relation to algorithms needs to be informed by the humanities which can enrich these debates, for example by deepening the meaning of explainability with what I call understandability. That is, rather than providing descriptions purely from the domains of a formal, technical and causal model of  <em>explanation</em>  (dominant in the sciences), these technologies would benefit from critical approaches that take account of  <em>understanding</em> , more common in the humanities and social sciences (see <sup id="fnref1:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> for an earlier discussion of this, see also <sup id="fnref:80"><a href="#fn:80" class="footnote-ref" role="doc-noteref">80</a></sup>). The notion of explanation needs to be interrogated by the humanities, and particularly the concept of explainability it gives rise to. This is increasingly relevant to the growing public visibility of humanities and the potential for the use of machine learning in related fields, such as digital humanities. Therefore, this is an area that digital studies and digital humanities could make an important contribution both in thinking about their own work and the impact of algorithms, but also working in conjunction with other fields.</p>
<p>Unfortunately, due to limitations of time I do not have time to discuss further here. But if it is the case that infrasomatizations create cognitive infrastructures that proletarianise our cognitive faculties creating anti-thought, overtaken thought and non-thought, then explainability creates a potential way of bringing back into visibility these issues. For the user these infrasomatizations are experienced through smart-phones and tablets which close the loop from within the brain to the outside environment, such that the aperture of thought is mediated and compressed. Hence, the capacity for the human brain to perceive that algorithms are organizing their thoughts, or even to perceive that algorithms are at work, is impaired, if not destroyed – human reason is thereby diminished and made susceptible to persuasion and propaganda as demonstrated by the Cambridge Analytica scandal that continues to reverberate. These systems aim to directly influence the practice of cognition as it has been historically constituted. New retentional and protential systems are therefore directly implicated in a process of transforming the way in which we create the conditions for cognition , directly subverting, and in extreme cases replacing elements of cognitive processes in human thought and experience.</p>
<h2 id="3-conclusion">3. Conclusion</h2>
<p>Part of the responses we need to develop are through thinking about infrastructures differently. We might, for example, seek to develop new logics for what Bernard Stiegler has called a contributory economy as an alternative form of political economy for digital society <sup id="fnref1:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. I agree that strategies such as these are crucial to create a safe-harbour for critical reason and hence to enable the contestation or transformation of infrastructures into new possibilities and thereby create the conditions for a new epoch. In order to do this I have argued previously that we need to undertake a programme of criticism with respect to the computational and particularly its manifestation in digital capitalism <sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. But we need to go further and seek to understand and challenge the way in which smart infrastructures recast certain regulatory or legal limitations into ineffective measures from which they are able to extract excessive amounts of profit and exhaust the wider economy creating new forms of structural poverty and inequality. The combination of new smart technologies and the social right to explanation that explainability makes possible opens up a potential for a new critical space of what we might call tool criticism and the development of a wider literacy for a general public sharing increased anxiety about the effects of these automated systems. This seems to me exactly the kind of expertise that humanists and social scientists are highly skilled at and who could therefore help inform the debate over explainability.<sup id="fnref:81"><a href="#fn:81" class="footnote-ref" role="doc-noteref">81</a></sup></p>
<p>It is here, I argue, that theory and its development is crucial to understand the contemporary computational situation through the confrontation of the object with its own concept. We need to develop an approach that refuses to ignore and smooth over contradictions and contradictory claims. Computational societies continue to embody interaction based on deception and distortion (in other words, as ideology), and which can often be translated unreflexively into algorithmic forms. The cult of data-ism is a turn away from the project of seeking to understand society and culture through the application of critical reason in human affairs towards a data-deterministic world. It is problematic to erect an abstract and metaphysical standard by which human action and society can be judged – yet the cult of data-ism makes such a claim and works hard to produce and reproduce this new data-centric milieu. Algorithms and data must be subject to citizens&rsquo; power to contest and challenge this new form of authority and it is here that the concept of explainability offers a novel potential. Indeed, as a critical concept it might contribute to concrete examples of computationalism by drawing on critical theory and transforming explanation and explainability into critical practices. This further enables us to challenge the cult of data-ism and an administrative approach to thinking about algorithms and instead to suggest different ways of being in a digital age.</p>
<p>The digital world is not a static object; it is a highly dynamic and relational system which is in constant movement and undergoing continual change. For example, it is quite remarkable to note that the internet has never been taken off-line in order to be upgraded or changed, rather it is built through accretions and replacements that are slotted into or onto the existing system structure whilst it is still running. This is an important aspect to understanding the always-on nature of these new infrasomatic systems. It also makes understanding the material specificity of algorithmic systems extremely important, and helps to show why an analysis that focused only on the data or content of an infrasomatic or infrastructural system would be insufficient. We need to challenge the voracious appetite for data which extends to all aspects of life and is often accompanied by a cult of data-ism expressed through the cyber-libertarian notion that information wants to be free.<sup id="fnref:82"><a href="#fn:82" class="footnote-ref" role="doc-noteref">82</a></sup></p>
<p>We might note that in advanced capitalist societies, economic anarchy is interwoven with rationalization and technology to create fewer chances for mental and reflective labour. Under such conditions, the values of instrumental reason are accorded a privileged status since they are embodied in the concept of rationality itself. The confounding of calculation with rational thinking implies that whatever cannot be reduced to number is illusion or metaphysics. As a result, the conditions are created for a greater susceptibility of society to demagogic discourses and charismatic forms of power and a weakening of the potential for individuation. This forms part of the wider significance of infrasomatizations and how we need, more than ever, social critique and critical thinking under contemporary conditions. Indeed, behind the ideological claims of data science and related approaches, particularly in Silicon Valley, this fetishism of calculation and computation is dominant. In spite of its efforts to reflect the object of analysis in terms of the manifest forms of development, such as here with algorithms, critical theory depends in its analysis on particular historical conditions.</p>
<p>It is crucial to maintain a dynamic distinction between social processes and resultant social forms of commodity fetishism that make up the underlying political economy of the new digital milieu. Institutional and ideological formations are not simple reflections of an economic base; instead, work has to be done to understand both culture and economy in relation to the growing use of computation. In the context of computation it requires that we need to consider the specific historical ideas and practices within which we experience algorithms and in which they are made and remade. We must, therefore, examine the particular historical conditions that give the present its shape in relation to the specific material and ideological formations that algorithms introduce into the social and economic conditions of society. Explainability, and the explanations it might give rise to, seems to me to offer a particularly rich potential for contributing to this project. This means that we need to critique an ahistorical notion of the algorithm and critically interrogate metaphors and analogies used in explainability that are necessary to explain but are not sufficient for understanding the instantiation of algorithmic forms.</p>
<p>One potential response then, is that on the ruins of critical reason a new sense of the gradients of cognition must be understood – what exactly are the faculties of the mind that are directly undermined or replaced by infrasomatizations? The ruins must be uncovered to create new values, new standards, new defences, to create situated identities and critical spaces for defending against the onslaught of the algorithmic giants of the 21st century. Weapons for the weak will be needed to push back this colonisation of public and private reason. The only way for there to be critical reason in a digital age, will be if it is rebuilt on these ruins. The digital humanities can contribute a new research programme to interrogate the political and technical digital monopolies that invade our lives. I suggest that the first stages will be through the mobilization of a critical concept of explainability, the second through the creation of new tools, and lastly through the theorisation of a critique of computational reason.</p>
<p>Many technology companies rely on techniques developed in casinos to nudge behaviour to maximise profitability, such as creating addictive experiences and by disarming the will of the user. Using techniques such as  “Trigger, Action, Reward and Investment”  these systems help create addition to a particular product (see <sup id="fnref:84"><a href="#fn:84" class="footnote-ref" role="doc-noteref">84</a></sup>  <sup id="fnref:85"><a href="#fn:85" class="footnote-ref" role="doc-noteref">85</a></sup>).</p>
<p>We might contrast the idea of explainability, which is intended to create explanations, with the notion of observability developed by Rieder and Hoffman (2020) and what Lipton (2017) and others have called interpretability. Rieder and Hoffman argue that  “observability emphasises the conditions for the practice of observing in a given domain &hellip; We therefore position observability as an explicit means of, not an alternative to regulation”   <sup id="fnref:86"><a href="#fn:86" class="footnote-ref" role="doc-noteref">86</a></sup>. I seek to explicitly link explainability to critique, whereas observability is developed as an administrative concept to aid in regulatory and policy outcomes. Interpretability is closer to my idea of explainability as aiding human understanding of algorithmic models and software <sup id="fnref:87"><a href="#fn:87" class="footnote-ref" role="doc-noteref">87</a></sup>.</p>
<p>Following the GDPR, in the UK, the enabling legislation for the European GDPR is the  <em>Data Protection Act 2018</em> .</p>
<p>It appears that the idea is that only a natural person may ask for an explanation, preventing algorithms or corporations from requesting an explanation from other algorithms or corporations.</p>
<p>Whilst non-binding, the Recitals  “dissolve ambiguity in the operative text of a framework” , and they provide a critical reference for future interpretations <sup id="fnref1:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>.</p>
<p><sup id="fnref1:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> argue that the  “GDPR does not, in its current form, implement a right to explanation, but rather what we term a limited &lsquo;right to be informed&rsquo;”  although this has been contested in the literature as their argument rests on a rather narrow reading of the effects of Recital 71 (see <sup id="fnref1:74"><a href="#fn:74" class="footnote-ref" role="doc-noteref">74</a></sup>. But nonetheless  “the GDPR’s right of access only grants an explanation of automated decision-making addressing system functionality, not the rationale and circumstances of specific decisions”   <sup id="fnref2:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>).</p>
<p>It is important to note that although this paper has focussed on the GDPR, explainability was also part of a Darpa research programme in 2016 (DARPA-BAA-16-53). More information can be found here: <a href="https://www.darpa.mil/attachments/DARPA-BAA-16-53.pdf">https://www.darpa.mil/attachments/DARPA-BAA-16-53.pdf</a></p>
<p>This means that algorithmic systems are required to provide their processing descriptions under this right to explanation and potentially giving rise to a critical field such as Explainable Digital Studies – XDS.</p>
<p>These issues are explored in depth in the work of <sup id="fnref:88"><a href="#fn:88" class="footnote-ref" role="doc-noteref">88</a></sup> who focuses on how social conflict is mediated through particular assemblages of algorithmic systems.</p>
<p>Exosomatization and endosomatization have been deployed by Stiegler to think about human augmentation and digital technologies, particularly in relation to the anthropocene and the counter-entropic move towards a neganthropocene (see for example, <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  <sup id="fnref2:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>).</p>
<p>Equally important is the overlaying of computational and therefore calculable layers over the physical environment. These layers are crucial for next generation infrasomatizations, using maps and other locative technologies.</p>
<p>For example, in terms of the technical transformation of place we might consider the softwarization of the home – a site of so-called micro-location. Its conversion into an algorithmic space is a process which is now well under way and which involves transforming dumb things into smart objects through the use of artificial intelligence. But AI cannot function without data, large amounts of data, to help them understand the world. Smart devices need to watch and record us, harvesting vast quantities of data, so that our every activity can be captured by sensors and cameras embedded within them. One of the more contentious recent examples is the proposal by Amazon to build a surveillance-as-a-service system. In this patented system, the company aims to use its network of delivery drones to keep watch over customers&rsquo; houses using location data to form a flying Neighbourhood Watch drone system. It is suggested that customers could request that Amazon&rsquo;s drones visit their property hourly, daily, or weekly, and the drones would look for signs of break-ins, such as smashed windows, doors left open, and intruders lurking on people&rsquo;s property (<sup id="fnref:89"><a href="#fn:89" class="footnote-ref" role="doc-noteref">89</a></sup>). The patent further suggests that drones could be equipped with night vision cameras and microphones to expand their sensing capabilities <sup id="fnref:90"><a href="#fn:90" class="footnote-ref" role="doc-noteref">90</a></sup>. This is in addition to an earlier patent application envisions using a combination of Amazon Ring doorbell cameras and facial recognition technology to build a system that could be used to match images of people who show up at your door to a  “suspicious persons”  database (<sup id="fnref:91"><a href="#fn:91" class="footnote-ref" role="doc-noteref">91</a></sup>, <sup id="fnref:92"><a href="#fn:92" class="footnote-ref" role="doc-noteref">92</a></sup>). It goes without saying that these activities produce useful raw data in vast quantities and for which more intensive surveillance systems are being built.</p>
<p>This highlights the importance of the relationship between the instrumental imposition of location, understood technically as geo-fencing, against that of what Bernard Steigler is increasingly referring to as locality, a counter-computational politics of place (see <a href="http://internation.world">http://internation.world</a> ).</p>
<p>This has even resulted in families and groups being deliberately separated by algorithms for profit, or AI scans for a babysitter with  “respect and attitude”   <sup id="fnref:93"><a href="#fn:93" class="footnote-ref" role="doc-noteref">93</a></sup>.</p>
<blockquote>
<p>data is not the new oil – it’s the new plutonium and that data at the micro-personal level gives technology unprecedented power to influence &hellip; Amazingly powerful, dangerous when it spreads, difficult to clean up and with serious consequences when improperly used<br>
<sup id="fnref:94"><a href="#fn:94" class="footnote-ref" role="doc-noteref">94</a></sup>.</p>
</blockquote>
<p>Academia is itself in the middle of a digital revolution, the outlines of which are still only dimly perceived. For example, open access licenses create the data foundations for gigantic systems of surveillance to be built to monitor, manage and control academic labour. University management are enthusiastically building new collection systems using these open access licenses as their foundations (often with the tacit approval of academic faculty, librarians and researchers). This situation is happening right under the noses of academics who are swayed by moralistic arguments about participation and the sharing of knowledge, but which will actually result in the bypassing of historical and hard-won principles of academic freedom built on the notion that academic labour means that the copyrights belong in the first instance to the scholar, not to the university. This was originally developed as a practice to protect the rights of academics who could choose where to publish their work without limitation. These rights are now carelessly discarded with little critical thought as to the unintended consequences of a restriction of publication into open access venues. One of the most immediate effects is that for the first time in history, universities can, without restriction, build monitoring systems for publication at a very fine granularity because they do not have to worry about infringing academic rights of publication. These systems create accounting logics, themselves linked to performance monitoring, and eventually a policing function over academic labour. Open access has thereby become a political doxa and a technical system of organisation and management.</p>
<blockquote>
<p>counterfactuals bypass the substantial challenge of explaining the internal workings of complex machine learning systems. Even if technically feasible, such explanations may be of little practical value to data subjects. In contrast, counterfactuals provide information to the data subject that is both easily digestible and practically useful for understanding the reasons for a decision, challenging them, and altering future behaviour for a better result<br>
<sup id="fnref1:83"><a href="#fn:83" class="footnote-ref" role="doc-noteref">83</a></sup>Note how this conveniently avoids the problematic of explanation of the underlying algorithm and instead resituates the responsibility for changing behavioural outcomes onto the individual. This looks less like a right to explanation than a means to avoid the social responsibilities on data processors implicit in explainability by creating a minimal form of explanation. Which even they have to concede counterfactuals may be insufficient in themselves  <sup id="fnref2:83"><a href="#fn:83" class="footnote-ref" role="doc-noteref">83</a></sup>.</p>
</blockquote>
<p>This also raises questions about the potential for what we might call explainability regress, whereby explanations are sought for the explanation and so on ad infinitum. Until these cases are tested in practice, it is difficult to know what the limitations will be in relation to explanations provided by a system.</p>
<p>Additionally, digital humanists tend to be familiar with technical systems and the questions raised by understanding and interpretation more generally, for example in the discussions about hermeneutics, understanding and practices of close and distant reading.</p>
<p>It is worth reflecting on the naivety of some proponents of open access who extol the virtues of free information without connecting it to its genesis in cyberlibertarian modes of thought (see <sup id="fnref:95"><a href="#fn:95" class="footnote-ref" role="doc-noteref">95</a></sup>.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Hayles, N. K. (2007)  “Hyper and Deep Attention: The Generational Divide in Cognitive Modes” ,  <em>Profession</em> , 13, 187-199.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Hayles, N. K. (2010)  “How We Read: Close, Hyper, Machine” ,  <em>Ade Bulletin</em> , Number 150, 62-79.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Hutchins, E. (1995)  <em>Cognition in the wild</em> . MIT Press.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Jobs, S. (1981)  “When We Invented the Personal Computer…,”    <em>COMPUTERS and PEOPLE Magazine</em> , July-August 1981.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Carr, N. (2008)  “Is Google Making Us Stupid? What the Internet is doing to our brains” ,  <em>The Atlantic</em> , <a href="https://www.theatlantic.com/magazine/archive/2008/07/is-google-making-us-stupid/306868/">https://www.theatlantic.com/magazine/archive/2008/07/is-google-making-us-stupid/306868/</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Stiegler, B. (2015)  “Power, Powerlessness, Thinking, and Future” ,  <em>Los Angeles Review of Books</em> , <a href="https://lareviewofbooks.org/article/power-powerlessness-thinking-and-future/#!">https://lareviewofbooks.org/article/power-powerlessness-thinking-and-future/#!</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Stiegler, B. (2018),  <em>The Neganthropocene</em> , Open Humanities Press, <a href="http://openhumanitiespress.org/books/download/Stiegler_2018_The-Neganthropocene.pdf">http://openhumanitiespress.org/books/download/Stiegler_2018_The-Neganthropocene.pdf</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:9">
<p>Zuboff, S. (2019)  <em>The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power</em> , Profile Books.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>McNamee, R. (2019)  <em>Zucked!</em> , Penguin Press.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>EU (n.d.)  “Are there restrictions on the use of automated decision-making?” , <a href="https://ec.europa.eu/info/law/law-topic/data-protection/reform/rules-business-and-organisations/dealing-citizens/are-there-restrictions-use-automated-decision-making_en">https://ec.europa.eu/info/law/law-topic/data-protection/reform/rules-business-and-organisations/dealing-citizens/are-there-restrictions-use-automated-decision-making_en</a>&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p><em>European Parliament (2022) EU Digital Markets Act and Digital Services Act explained</em> , European Parliament, <a href="https://www.europarl.europa.eu/news/en/headlines/society/20211209STO19124/eu-digital-markets-act-and-digital-services-act-explained">https://www.europarl.europa.eu/news/en/headlines/society/20211209STO19124/eu-digital-markets-act-and-digital-services-act-explained</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Malabou, C. (2019)  <em>Morphing Intelligence: From IQ Measurement to Artificial Brains</em> , Columbia University Press.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Noble, S. U. (2018)  <em>Algorithms of Oppression</em> , New York University Press.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Merleau-Ponty, M. (2007)  “Eye and Mind” , in Toadvine, T. and Lawlor, L. (Eds.)  <em>The Merleau-Ponty Reader</em> , Northwestern University Press.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Berry, D. M. (2011)  <em>The Philosophy of Software</em> . London: Palgrave.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Berry, D. M. (2014)  <em>Critical Theory and the Digital</em> . New York: Bloomsbury.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Daston, L. (2022)  <em>Rules: A Short History of What We Live By</em> , Princeton University Press&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:20">
<p>GDPR (2016)  <em>General Data Protection Regulation, Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016</em> , <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1528874672298anduri=CELEX%3A32016R0679">https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1528874672298anduri=CELEX%3A32016R0679</a>&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:22">
&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:23">
&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:24">
<p>Goodman, B. and Flaxman, S. (2017)  “European Union Regulations on Algorithmic Decision- Making and a  Right to Explanation ” ,  <em>AI Magazine</em> , 38(3):50–57, 2017.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Selbst, A. D. and Powles, J. (2017)  “Meaningful Information and the Right to Explanation” .  <em>International Data Privacy Law</em> , 7(4):233–242.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Wachter, S., Mittelstadt, B., and Floridi L. (2017)  <em>Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation</em> .  <em>International Data Privacy Law</em> , 7(2):76–99, 2017.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:28">
<p>Darpa (n.d.)  <em>Explainable Artificial Intelligence (XAI)</em> , <a href="https://www.darpa.mil/program/explainable-artificial-intelligence">https://www.darpa.mil/program/explainable-artificial-intelligence</a>&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Sample, I. (2017)  “Computer says no: why making AIs fair, accountable and transparent is crucial” ,  <em>The Guardian</em> , <a href="https://www.theguardian.com/science/2017/nov/05/computer-says-no-why-making-ais-fair-accountable-and-transparent-is-crucial">https://www.theguardian.com/science/2017/nov/05/computer-says-no-why-making-ais-fair-accountable-and-transparent-is-crucial</a>&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Kuang, C. (2017)  “Can A.I. Be Taught to Explain Itself?” ,  <em>The New York Times</em> , <a href="https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html">https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html</a>&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:32">
<p>Samuel, S. (2019)  “10 things we should all demand from Big Tech right now” ,  <em>Vox</em> , <a href="https://www.vox.com/the-highlight/2019/5/22/18273284/ai-algorithmic-bill-of-rights-accountability-transparency-consent-bias">https://www.vox.com/the-highlight/2019/5/22/18273284/ai-algorithmic-bill-of-rights-accountability-transparency-consent-bias</a>&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Gunning, D. (2017)  <em>Explainable Artificial Intelligence (XAI): Programme Update</em> , <a href="https://www.darpa.mil/attachments/XAIProgramUpdate.pdf">https://www.darpa.mil/attachments/XAIProgramUpdate.pdf</a>&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:35">
&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:36">
<p>Berry, D. M. (2016)  “Infrasomatization.”    <em>Stunlaw</em>  at: <a href="http://stunlaw.blogspot.co.uk/2016/12/infrasomatization.html.">http://stunlaw.blogspot.co.uk/2016/12/infrasomatization.html.</a>&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Bobulescu, R. (2015)  “From Lotka&rsquo;s biophysics to Georgescu-Roegen&rsquo;s bioeconomics.”    <em>Ecological Economics</em>  120, 194–202.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Steigler, B. (2016)  “The New Conflict of the Faculties and Functions: Quasi-Causality and Serendipity in the Anthropocene.”    <em>Qui Parle: Critical Humanities and Social Sciences</em> , Volume 26, Number 1, June 2017, pp. 79-99&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:40">
<p>Lotka, A.J. (1925)  <em>Elements of Physical Biology</em> . William and Wilkins Company, Baltimore.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>Georgescu-Roegen, N. (1970/2011)  “The Entropy Law and the Economic Problem” , in Bonaiuti, M. (Ed.),  <em>From Bioeconomics to Degrowth: Georgescu-Roegen&rsquo;s &lsquo;New Economics&rsquo; in Eight Essays</em> , London: Routledge Studies in Ecological Economics, pp. 49–57.&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Georgescu-Roegen, N., (1972/2011).  “Energy and Economic Myths” , in Bonaiuti, M. (Ed.), From  <em>Bioeconomics to Degrowth: Georgescu-Roegen&rsquo;s &lsquo;New Economics&rsquo; in Eight Essays</em> , London: Routledge Studies in Ecological Economics, pp. 58–92.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Georgescu-Roegen, N., (1978/2011)  “Inequality, Limits and Growth From a Bioeconomic Viewpoint” , in Bonaiuti, M. (Ed.),  <em>From Bioeconomics to Degrowth: Georgescu-Roegen&rsquo;s &lsquo;New Economics&rsquo; in Eight Essays</em> , London: Routledge Studies in Ecological Economics, pp. 103–113 (2011).&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Popper, K. (1972)  <em>Objective Knowledge: An Evolutionary Approach</em> , Oxford: University of Oxford Press.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Berns, T. and Rouvroy, A. (2013)  “Gouvernementalité algorithmique et perspectives d&rsquo;émancipation : le disparate comme condition d&rsquo;individuation par la relation?” , accessed 14/12/2016, <a href="https://works.bepress.com/antoinette_rouvroy/47/download/">https://works.bepress.com/antoinette_rouvroy/47/download/</a>&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>Foucault, M. (1995)  <em>Discipline and Punish: The Birth of the Prison</em> , New YOrk: Vintage Books 1995.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:48">
<p>Evans, L. (2015)  <em>Locative Social Media Place in the Digital Age</em> , Palgrave Macmillan.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:50">
&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:51">
<p>Masters,B. and Thiel,P. (2015)  <em>Zero to One: Notes on Start Ups, or How to Build the Future</em> , Virgin Books.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Jaume-Palasi, L. (2018)  “Blessed by the algorithm: Computer says NO!” , <a href="https://media.ccc.de/v/froscon2018-2307-keynote">https://media.ccc.de/v/froscon2018-2307-keynote</a>&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Hammond, K. (2016)  “5 Unexpected Sources of Bias in Artificial Intelligence” ,  <em>Tech Crunch</em> , <a href="https://techcrunch.com/2016/12/10/5-unexpected-sources-of-bias-in-artificial-intelligence/">https://techcrunch.com/2016/12/10/5-unexpected-sources-of-bias-in-artificial-intelligence/</a>&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Buranyi, S. (2017)  “Rise of the racist robots – how AI is learning all our worst impulses” ,  <em>The Guardian</em> , <a href="https://www.theguardian.com/inequality/2017/aug/08/rise-of-the-racist-robots-how-ai-is-learning-all-our-worst-impulses">https://www.theguardian.com/inequality/2017/aug/08/rise-of-the-racist-robots-how-ai-is-learning-all-our-worst-impulses</a>&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Eubanks, V. (2017)  <em>Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor</em> , St Martin&rsquo;s Press.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:57">
<p>Casey, Bryan and Farhangi, Ashkon and Vogl, Roland, (2018)  “Rethinking Explainable Machines: The GDPR&rsquo;s &lsquo;Right to Explanation&rsquo; Debate and the Rise of Algorithmic Audits in Enterprise”  (February 19, 2018).  <em>Berkeley Technology Law Journal</em> , Available at SSRN: <a href="https://ssrn.com/abstract=3143325">https://ssrn.com/abstract=3143325</a>&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>Facebook (2019)  <em>Detectron</em> , <a href="https://research.fb.com/downloads/detectron/">https://research.fb.com/downloads/detectron/</a>&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Anderson, C. (2008)  “The End of Theory: The Data Deluge Makes the Scientific Method Obsolete.”    <em>Wired</em> . Accessed 18/12/2015 at: <a href="http://www.wired.com/science/discoveries/magazine/16-07/pb_theory">http://www.wired.com/science/discoveries/magazine/16-07/pb_theory</a>&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Guardian (2018)  “The Cambridge Analytica Files: A year-long investigation into Facebook, data, and influencing elections in the digital age” ,  <em>The Guardian</em> , <a href="https://www.theguardian.com/news/series/cambridge-analytica-files">https://www.theguardian.com/news/series/cambridge-analytica-files</a>&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Palmer, M. (2006)  “Data is the New Oil” , <a href="http://ana.blogs.com/maestros/2006/11/data_is_the_new.html">http://ana.blogs.com/maestros/2006/11/data_is_the_new.html</a>&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>Toonders, Y. (2014)  “Data is the New Oil of the Digital Economy” ,  <em>Wired</em> , <a href="https://www.wired.com/insights/2014/07/data-new-oil-digital-economy/">https://www.wired.com/insights/2014/07/data-new-oil-digital-economy/</a>&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p>See also Jim Balsillie who argued that&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p>Kuneva, M. (2009)  “Keynote Speech” ,  <em>Roundtable on Online Data Collection, Targeting and Profiling</em> , <a href="http://europa.eu/rapid/press-release_SPEECH-09-156_en.htm">http://europa.eu/rapid/press-release_SPEECH-09-156_en.htm</a>&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:65">
<p>Davidson, R. (2016)  “Open Data is the new oil that fuels society” , Office for National Statistics, <a href="https://blog.ons.digital/2016/01/25/open-data-new-oil-fuels-society/">https://blog.ons.digital/2016/01/25/open-data-new-oil-fuels-society/</a>&#160;<a href="#fnref:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:66">
<p>Sengupta, S. (2012)  “Should Personal Data Be Personal?” ,  <em>The New York Times</em> , <a href="https://www.nytimes.com/2012/02/05/sunday-review/europe-moves-to-protect-online-privacy.html">https://www.nytimes.com/2012/02/05/sunday-review/europe-moves-to-protect-online-privacy.html</a>&#160;<a href="#fnref:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:67">
&#160;<a href="#fnref:67" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:68">
<p>Pitt, J.C. (1988)  <em>Theories of Explanation</em> , Oxford University Press.&#160;<a href="#fnref:68" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:69">
<p>Hempel and Oppenheim (1988)  “Studies in the Logic of Explanation” , in Pitt, J.C. (ed.)  <em>Theories of Explanation</em> , Oxford University Press.&#160;<a href="#fnref:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:70">
<p>Mill, J. S. (1858)  “Of the Explanation of the Laws of Nature” , in  <em>A System of Logic</em> , New York, Book III, Chapter XII, Section 1.&#160;<a href="#fnref:70" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:71">
<p>Ducasse, C. J. (2015)  “Explanation, Mechanism and Teleology” , in  <em>Truth, Knowledge and Causation</em> , Routledge.&#160;<a href="#fnref:71" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:72">
<p>Scriven, M. (1988)  “Explanations, Predictions, and Laws” , in Pitt, J.C. (Ed.)  <em>Theories of Explanation</em> , Oxford University Press&#160;<a href="#fnref:72" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:73">
<p>Ruben, D. H. (2016)  <em>Explaining Explanation</em> , Routledge.&#160;<a href="#fnref:73" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:73" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:73" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:74">
<p>Edwards, L. and Veale, E. (2018)  “Enslaving the algorithm: from a &lsquo;right to an explanation&rsquo; to a &lsquo;right to better decisions&rsquo;?” , January 2018.  <em>Publication in IEEE Security and Privacy</em> , <a href="https://pureportal.strath.ac.uk/files-asset/72824599/Edwards_Veale_SPM_2018_Enslaving_the_algorithm_from_a_right_to_an_explanation_to_a_right_to_better_decisions.pdf">https://pureportal.strath.ac.uk/files-asset/72824599/Edwards_Veale_SPM_2018_Enslaving_the_algorithm_from_a_right_to_an_explanation_to_a_right_to_better_decisions.pdf</a>&#160;<a href="#fnref:74" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:74" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:75">
<p>For example, the user might be able to challenge an explanation or appeal to a higher authority if it were considered inadequate.&#160;<a href="#fnref:75" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:76">
<p>One is tempted to assume that some developers believe that behavioural models of automated systems will be easier to describe, perhaps as black-boxed input-output models, or that a user will naturally find these descriptions more comprehensible. There is some similarity between  “machine behaviour”  approaches and the thinking behind the idea of so-called  “counter-factual explanations”  proposed by <sup id="fnref:83"><a href="#fn:83" class="footnote-ref" role="doc-noteref">83</a></sup>, which assumes that by changing the input conditions a counter-factual output can be presented to the user. They argue that&#160;<a href="#fnref:76" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:77">
<p>Rahwan, I. and Cebrian, M. and Obradovich, N. and Bongard, J. and Bonnefon, JF. and Breazeal, C. and Crandall, J. and A. Christakis, N. and Couzin, I. and Jackson, M. and R. Jennings, N. and Kamar, E. and M. Kloumann, I. and Larochelle, H. and Lazer, D. and McElreath, R. and Mislove, A. and C. Parkes, D. and Pentland, A. and Wellman, M.. (2019).  “Machine Behaviour” .  <em>Nature</em> . 568. 477-486. 10.1038/s41586-019-1138-y.&#160;<a href="#fnref:77" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:78">
<p>Renz, U. (2018)  <em>The Explainability of Experience: Realism and Subjectivity in Spinoza&rsquo;s Theory of the Human Mind</em> , Oxford University Press.&#160;<a href="#fnref:78" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:79">
&#160;<a href="#fnref:79" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:80">
<p>Connolly, R. (2020)  “Why Computing Belongs Within the Social Sciences” ,  <em>Communications of the ACM</em> , August 2020, Vol. 63 No. 8, Pages 54-59&#160;<a href="#fnref:80" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:81">
&#160;<a href="#fnref:81" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:82">
&#160;<a href="#fnref:82" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:83">
<p>Wachter, S. and Mittelstadt, B. and Russell, C. (2018).  “Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR” .  <em>Harvard journal of law and technology</em> , 31. 841-887.&#160;<a href="#fnref:83" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:83" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:83" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:84">
<p>Schüll, N. D. (2014)  <em>Addiction by Design: Machine Gambling in Las Vegas</em> , Princeton University Press.&#160;<a href="#fnref:84" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:85">
<p>Eyal, N. (2014)  <em>Hooked: How to Build Habit-Forming Products</em> , Portfolio Penguin&#160;<a href="#fnref:85" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:86">
<p>Rieder, B. and Hofmann, J. (2020)  “Towards platform observability” ,  <em>Internet Policy Review</em> , 9(4). <a href="https://doi.org/10.14763/2020.4.1535">https://doi.org/10.14763/2020.4.1535</a>&#160;<a href="#fnref:86" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:87">
<p>Lipton, Z. I. (2017)  “The Mythos of Model Interpretability” , <a href="https://arxiv.org/pdf/1606.03490.pdf">https://arxiv.org/pdf/1606.03490.pdf</a>&#160;<a href="#fnref:87" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:88">
<p>Irani, L. (2015)  “The cultural work of microwork” ,  <em>New Media and Society</em>  17(5): 720-739.&#160;<a href="#fnref:88" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:89">
<p>Porter, J. (2019)  “Amazon patents &lsquo;surveillance as a service&rsquo; tech for its delivery drones” , <a href="https://www.theverge.com/2019/6/21/18700451/amason-delivery-drone-surveillance-home-security-system-patent-application">https://www.theverge.com/2019/6/21/18700451/amason-delivery-drone-surveillance-home-security-system-patent-application</a>&#160;<a href="#fnref:89" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:90">
<p>USPTO (2019a)  “Image creation using geo-fence data” , USPTO, <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2andSect2=HITOFFandp=1andu=%2Fnetahtml%2FPTO%2Fsearch-bool.htmlandr=1andf=Gandl=50andco1=ANDandd=PTXTands1=10313638.PN.andOS=PN/10313638andRS=PN/10313638">http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2andSect2=HITOFFandp=1andu=%2Fnetahtml%2FPTO%2Fsearch-bool.htmlandr=1andf=Gandl=50andco1=ANDandd=PTXTands1=10313638.PN.andOS=PN/10313638andRS=PN/10313638</a>&#160;<a href="#fnref:90" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:91">
<p>USPTO (2019b)  “Generating Composite Facial Images Using Audio/Visual Recording and Communication Devices” , USPTO, <a href="https://www.aclunc.org/docs/Amazon_Patent.pdf">https://www.aclunc.org/docs/Amazon_Patent.pdf</a>&#160;<a href="#fnref:91" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:92">
<p>Meek, A. (2019)  “Amazon-owned Ring has reportedly been spying on customer camera feeds” , <a href="https://bgr.com/2019/01/10/ring-camera-customer-feeds-accessed-creepy-privacy-violation/">https://bgr.com/2019/01/10/ring-camera-customer-feeds-accessed-creepy-privacy-violation/</a>&#160;<a href="#fnref:92" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:93">
<p>Harwell, D. (2018)  “Wanted: The &lsquo;perfect babysitter.&rsquo; Must pass AI scan for respect and attitude” ,  <em>The Washington Post</em> , <a href="https://nuzzel.com/sharedstory/11232018/washingtonpost/wanted_the_perfect_babysitter_must_pass_ai_scan_for_respect_and">https://nuzzel.com/sharedstory/11232018/washingtonpost/wanted_the_perfect_babysitter_must_pass_ai_scan_for_respect_and</a>&#160;<a href="#fnref:93" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:94">
<p>Balsillie, J. (2019)  “Jim Balsillie : &lsquo;Data is not the new oil – it&rsquo;s the new plutonium&rsquo;” ,  <em>Financial Post</em> , <a href="https://business.financialpost.com/technology/jim-balsillie-data-is-not-the-new-oil-its-the-new-plutonium">https://business.financialpost.com/technology/jim-balsillie-data-is-not-the-new-oil-its-the-new-plutonium</a>&#160;<a href="#fnref:94" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:95">
<p>Golumbia, D. (2016).  “Marxism and Open Access in the Humanities: Turning Academic Labor against Itself” ,  <em>Workplace</em> , 28, 74-114.&#160;<a href="#fnref:95" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The Politics of Tools</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000690/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000690/</id><author><name>Stephen Ramsay</name></author><published>2023-07-07T00:00:00+00:00</published><updated>2023-07-07T00:00:00+00:00</updated><content type="html"><![CDATA[<blockquote>
<p>Zilu said, If the ruler of Wei were to entrust you with governance of his state, what would be your first priority? The Master said, Most certainly, it would be to rectify names.<br>
Confucius,  <em>Analects</em>    <br>
To speak of the politics of tools is to take the political nature of technology for granted, and rightfully so. If the generation of historians, literary critics, sociolinguistis, and philosophers who came up in the academy after Foucault are united by anything, it is the idea that most things are wrapped up in issues of power, and therefore cannot be said to stand outside the realm of the political in any way. Such is the case, therefore, with any sort of technology at all — from pencils to weapons systems — and it is the business of humanistic inquiry to make plain the precise ways in which, as Foucault himself put it,  “power comes from everywhere”   <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>And yet digital humanities has often been accused of violating this central directive. Alan Liu offered this sobering assessment in 2012.</p>
<blockquote>
</blockquote>
<p>While digital humanists develop tools, data, and metadata critically [&hellip;] rarely do they extend their critique to the full register of society, economics, politics, or culture. How the digital humanities advances, channels, or resists today&rsquo;s great postindustrial, neoliberal, corporate, and global flows of information-cum-capital is thus a question rarely heard in the digital humanities associations, conferences, journals, and projects with which I am familiar. Not even the clichéd forms of such issues — for example, the digital divide,  surveillance,  privacy,  copyright, and so on — get much play.</p>
<p>It is as if, when the order comes down from the funding agencies, university administrations, and other bodies mediating today&rsquo;s dominant socioeconomic and political beliefs, digital humanists just concentrate on pushing the execute button on projects that amass the most data for the greatest number, process that data most efficiently and flexibly (flexible efficiency being the hallmark of postindustrialism), and manage the whole through ever smarter standards, protocols, schema, templates, and databases uplifting Frederick Winslow Taylor&rsquo;s original scientific industrialism into ultraflexible postindustrial content management systems camouflaged as digital editions, libraries, and archives — all without pausing to reflect on the relation of the whole digital juggernaut to the new world order.</p>
<p><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> <br>
Called now to be woke — in a metaphor that hearkens back to one of humanism’s more confident eras — digital humanities now struggles to articulate precisely how its work is properly political, and whether its commitment to tools is for good or ill.</p>
<p>Liu’s essay was hardly the only — or even, in the wider scheme, the most significant — catalyst for subsequent soul searching.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  And in some sense, Liu’s call for a closer critical alignment with cultural studies has been taken far more literally than he could have imagined. The cultural studies to which DH now finds itself in uneasy dialogue is not so much its later refraction in political readings of the artifacts of human history, but in the far more concretized politics of the 1968 academy — a world in which a seminar that could not place itself in clear relation to the workers’ councils was perhaps not worth holding at all (one is reminded of earlier scholar-activists like Korsch and Lukács). Stephen Greenblatt recalls a moment from the immediate aftermath of that period in which he was attempting to teach Marx with, one assumes, all the nuanced ambivalence one would expect from a competent scholar.  “I remember someone finally got up and screamed out in class  You’re either a Bolshevik or a Menshevik — make up your fucking mind ” <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
<p>Liu was not stating the problem so starkly, and yet great swaths of the digital humanities community now take the questions he posed with an urgency and immediacy that is entirely palpable. It is now routine to begin a digital humanities conference with a kind of litany in which the refugee and the immigrant are welcomed, heteronormativity is denounced, misogyny is rejected, assaults on human dignity (bullying, harassment) are banned, and (at least in Canada, Australia, and the U.S.) the stolen lands of the First Nations are acknowledged. Such desiderata are quite obviously commendable (if only in intention), but that such announcements might well precede a discussion of machine learning and metadata highlights the unease. We are haunted by the thought that a woke coder or a leftist web designer is simply someone who has not made up their mind whether to choose between Athens and Palo Alto. We wonder if the politics of tools is not an object of philosophical reflection on the less instrumental aspects of our endeavors, but, as in the double entendre of my title, an entirely pejorative description of our own political confusions.</p>
<p>Michael Oakeshott would seem a very unlikely figure in this discussion. The late work I consider most germane to these matters,  <em>The Politics of Faith and the Politics of Skepticism,</em>  is not obviously a book about politics and technology at all, but rather a treatise on what he takes to be the stylistic extremes of modernity as enunciated wherever (and whenever) we find ourselves engaged in political activity.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>  It is perhaps wise to let Oakeshott himself speak on the essential nature of these extremes:</p>
<blockquote>
<p>In the politics of faith, the activity of governing is understood to be in the service of the perfection of mankind. There is a doctrine of cosmic optimism which, not from observation but as an inference from the perfection of its creator, attributes an unavoidable perfection to the universe. And there is, further, a doctrine in which human perfection appears as a providential gift, assured but not deserved. But the idea of human perfectibility characteristic of the politics of faith, so far from being derived from either of these doctrines, is hostile to them both. In the politics of faith, human perfection is sought precisely because it is not present; and further, it is believed that we need not, and should not, depend upon the workings of divine providence for the salvation of mankind. Human perfection is to be achieved by human effort, and confidence in the evanescence of imperfection springs here from faith in human power and not from trust in divine providence. We may, perhaps, be permitted to encourage ourselves by believing that our efforts have the approval and even the support of providence, but we are to understand that the achievement of perfection depends upon our own unrelaxed efforts, and that if those efforts are unrelaxed, perfection will appear.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
</blockquote>
<p>The politics of skepticism, by contrast, is  “in every way the opposite:”</p>
<blockquote>
<p>[I]n the politics of skepticism governing is understood as a specific activity, and in particular it is understood to be detached from the pursuit of human perfection. [&hellip;] [I]n modern times, the politics of skepticism (regarded as an abstract style of politics) may be said to have its roots either in the radical belief that human perfection is an illusion, or in the less radical belief that we know too little about the conditions of human perfection for it to be wise to concentrate our energies in a single direction by associating its pursuit with the activity of governing. Human perfection (so the argument runs) may be evanescent, and, moreover, it may be a single and simple condition of human circumstances (though this may be doubted), but, even on those assumptions, to pursue perfection in one direction only (and particularly to pursue it as the crow flies, regardless of what there may be to do in the interval before we embrace it) is to invite disappointment and (what might be worse than the mortification of non-arrival) misery on the way. [&hellip;] The office of government here is not be the architect of a perfect manner of living, or (as faith understands it) of an improved manner of living, or even (as it turns out) of any manner of living at all. [&hellip;] The skeptic in politics observes that men live in proximity with one another and, pursuing various activities, are apt to come into conflict with each other. And this conflict, when it reaches certain dimensions, not only makes life barbaric and intolerable, but may even terminate it abruptly. In this understanding of politics, then, the activity of governing subsists not because it is good, but because it is necessary. Its chief office is to lessen the severity of human conduct by reducing the occasions of it.<br>
<sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Upon these two very brief extracts from a lengthy argument, several observations must be made.</p>
</blockquote>
<p>For Oakeshott, governance does not mean the particular establishment of constitutions, nation states, delineated systems of social order, the credos and platforms of political parties, or even philosophical meditations on governance as such. He has in mind not  “Who shall rule?”  (and by what warrant), but rather  “What shall government do?” <sup id="fnref2:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  Political activity is conceived as the  “understanding and care of public arrangements” <sup id="fnref3:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Thus Oakeshott puts forth these two forms (or better, styles) of political activity as unrealizable ideals (in the Platonic sense) and as extremes that are neither found in unattenuated form nor without some mixture of the two occurring either simultaneously or in tension with one another in actual political practice. That is to say, we cannot locate in history a moment in which either tendency has entirely prevailed — and indeed, were such extremes to somehow manifest themselves fully, they would immediately appear as self-contradictory and logically incoherent. Yet at the same time, Oakeshott detects these two tendencies playing out, as a kind of concordia discours of the two styles, in the actual practice of political life over the course of the last five hundred years, as well as in the politics of his own day. <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></p>
<p>Faith and skepticism have obvious religious overtones, and Oakeshott does not deny that religion has been an important factor in modern political thought and practice (he even, at several points, describes the politics of faith as  “essentially Pelagian”   <sup id="fnref4:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>). But close examination of these two passages will confirm that while a particular religious view might help to enable one or the other, it is just as important to notice that religious worldviews — even very insistent and socially totalizing ones — might inform precisely  <em>one or the other</em>  at any given moment. There are as many varieties of the politics of faith as there are interpretations of the word perfection,<sup id="fnref5:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> and there is nothing in either notion that requires an explicitly religious vision. When New York Mayor Michael Bloomberg, in 2012, sought to ban the sale of sweetened soft drinks that exceeded 16 oz in a serving (as a matter of public health), he might have been engaging in  <em>something like</em>  the politics of faith. But among the many who accused him of instituting a nanny state, no one suggested that he had spiritual salvation in mind. It is also not the case that either term falls neatly along the conventional axes of left and right. At the risk of summoning Godwin&rsquo;s Law, one might say that the Nazis horrifying vision of human perfectibility had much more to do with the politics of faith than its opposite (though, as Oakeshott would no doubt point out, the politics of skepticism is by no means absent from the on-the-ground politics of something like state fascism).</p>
<p>Again, a brief summary hardly does justice to a complex, book-length argument. But it is perhaps enough to orient us toward the truly provocative idea that Oakeshott introduces into his discussion of the two poles, which is that no serious form of the politics of faith can emerge without the enlistment of technology:</p>
<blockquote>
<p>[In the early modern period], the power of government was also being enlarged by the application of more efficient techniques, most of which had already seen an apprenticeship in some other field of activity, in commerce or in industry. Indeed, almost the whole apparatus by means of which governments in our own day are able to exercise a minute control over the activities of their subjects — the apparatus of banking and book-keeping, the records, registers, files, passports, dossiers and indexes — was already waiting to be exploited. Without ease of movement and communication, without a ready supply of paper and ink, without all those reports and records which spring up whenever paper, ink and human curiosity are joined, without a literate population, without ready means of identification, without settled frontiers, without (in short) a high degree of mastery over men and things, the prospects of the politics of faith are nugatory; with them, there is little to stand in their way.<br>
<sup id="fnref6:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> <br>
The analogy with our contemporary moment could not be more vivid. But Oakeshott&rsquo;s boldest thesis is that technology does not come to the aid of an emergent politics of faith, but rather creates the conception in the first place. Those who propose a new form of political activity do not realize its virtues  <em>and then</em>  seize on the technological power that could bring it about, but instead discover a politics of faith precisely when, as in the early modern period, there is  “a remarkable and intoxicating increase of human power”  borne of technological innovation and expansion <sup id="fnref7:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. States do not discover the virtues of total surveillance and then look around for the means by which surveillance might be undertaken, but instead discover the entire conception of governance as a quest for human perfectibility because the technology of surveillance has appeared as a new affordance.</p>
</blockquote>
<p>At least two objections immediately arise.</p>
<p>First: If it is true that technology is logically and temporally prior to the politics it enables, does it not therefore become neutral? And is this not like saying that guns are innocent of any ethical association with murder? There are arguments to this effect, of course, and they are often refuted simply by noting that while a pistol might well be used to drive a nail, its intended use suggests that ethical intentions are already inscribed in the object itself. Then again, the idea that technologies define the regime of political activity (as opposed to serving as the instrumental outcome of political goals) makes some sense of the numerous occasions in which individual technologists appear innocent of the horrors with which their inventions come to be implicated. Richard Jordan Gatling (1818–1903), among the more important figures in the development of the modern machine gun, offers a classic example. Having noticed that most soldiers in the American Civil War were dying of sickness and disease (as opposed to gunshots):</p>
<blockquote>
<p>It occurred to me that if I could invent a machine gun which could by its rapidity of fire, enable one man to do as much battle duty as a hundred, that it would, to a large extent supersede the necessity of large armies, and consequently, exposure to battle and disease would be greatly diminished.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup></p>
</blockquote>
<p>Even if one accuses Gatling of outright moral stupidity, we are still left with the task of providing an account of his role in the creation of the modern screw propeller. That, after all, is an essential element of every nuclear submarine — a weapon capable of creating levels of suffering and catastrophe of which Gatling could not possibly have conceived. One could, indeed, multiply such examples endlessly. A graduate student with no other purpose save better soybean production invents Agent Orange. A researcher interested in studying learning, creates a tool (the IQ test) beloved of crazed eugenicists to this day. The first thing ever played over a loudspeaker to a crowd were Christmas carols; it wasn&rsquo;t long before Joseph Goebbels was among the first to realize its far more insidious capabilities. So while we cannot declare technology neutral, we can — at least in many cases — proclaim individual technologists to be, at worst, unwitting instruments of forces of which they are mostly unaware. Technology is not politically neutral is, in all such cases, a statement not about some individual mechanism, but about a record of instrumental usage pondered with a good deal of hindsight.</p>
<p>Second: Do not such technologies serve the politics of skepticism equally? Yes, but here Oakeschott&rsquo;s identification of these two tendencies as distinctive of modernity becomes most legible. The ancient empires maintained their vast domains under arms and with what methods of surveillance they could muster. But in such technologically primitive circumstances, even the politics of skepticism cannot fully emerge. The Roman Empire (or the Persian, or the Han) could perhaps hope to avoid strife among a subjected people inconveniently occupying (and in many cases, constituting) the resources they hoped to exploit, but they could not — and over time, proved themselves largely unable to — develop a vision of, and a set of robust institutions for, the prevention of local conflict borne of nothing more than proximity (the imposition of peace for its own sake, or perhaps peace as ideology or as normative political calculus). As for the politics of faith: Even if the Roman imperial cult had had any aspirations toward human perfectibility (and it certainly did not), it is extremely difficult to imagine how that might have been efficiently maintained by Rome even in the less remote regions of the empire. Where no obvious means are available, no obvious ends can properly emerge. Yet late antiquity also sees the rise of Stoicism, Epicureanism, and eventually Christianity as popular forms of social and religious thought. And while none of these creeds (at least in their original, ideal forms) ever succeeds in formulating a concrete political vision, one could scarcely summon more incandescent instances in which the perfectibility of the human person is assumed.</p>
<p>Finally, it is important to note that the question to which Oakeshott&rsquo;s thesis is directed is not primarily that to which the two tendencies offer themselves as solutions (What shall government do?), but rather as a way of explaining the ambivalence and ambiguity of modern political discourse. That we do not possess a clear scientific vocabulary with such terms as right,  justice,  order,  freedom,  democracy,  socialism, or, for that matter, governance (one could extend this list infinitely) is a function of the fact that all such terms are ever destined to serve two masters. Each appears — with radically different meanings — in both the politics of faith and the politics of skepticism. Attempts to specify them further with supposedly more precise adjectives —  <em>natural</em>  rights,   <em>democratic</em>  socialism,   <em>individual</em>  freedom — only serve to deepen the rift. Nowhere is this more evident than in the term social justice as used in contemporary anglophone political discourse. Those more aligned with the politics of faith would very much like the adjective social to act as a useful clarification, and even perhaps to render the entire term slightly innocuous (who, after all, could object to a just society?). For those inspired by skepticism, though, the term is an obvious shibboleth suggestive of an entirely activist and progressive stance. For some, the term can only be employed with yet another qualification: the social justice  <em>warrior</em>  who takes up arms against all that is good and decent in a politics manifestly focused on what is traditional and sensible.</p>
<p>It should surprise us not at all, though, to discover that our own political aspirations as academics — our desire to be politically relevant and politically engaged — is a technologically-enabled manifestation of the politics of faith. The humanities, and in particular, the humanities as it is practiced and taught in higher education, has seldom had any other goal than the cultivation of human consciousness. And by consciousness, we of course mean, quite unapologetically, better and higher consciousness. Other reasons might be summoned. Good citizenship is still frequently mentioned, and preparation for more concrete endeavors (law, business, medicine, or ministry) remains a sturdy rationale in some quarters. But all such teleologies only reframe the centrality of consciousness or awareness as ends in themselves. Art for art&rsquo;s sake (we can substitute any humanistic discipline we like for art in this venerable formulation) is perhaps a part of the calculation for some, but even the most ardent admirers of Shakespeare will surely see the absurdity of spending enormous sums of money in order to provide their children with four years of aesthetic rapture. If politics is our goal, the elitism of this proverb becomes self-refuting. Yet the study of literature and art, culture and history, philosophy and politics — even in their most narrow and specialized forms — can all be enfolded into the capacious realm of consciousness. If the humanities has a politics, it is a politics that relies heavily on the idea of human perfectibility. Skeptics we may be, but we are not practitioners of the  <em>politics</em>  of skepticism. Perhaps in other times and places, it has been precisely the purpose of higher education to do nothing more than fecklessly maintain existing structures bent on no more noble purpose than maintaining order within an eternally defective human community. But the humanities in particular — understood in as broad a way as possible — has perhaps never known such an academy, or has known it only as its natural enemy.</p>
<p>But it is not our liberalism that makes this assignation relevant. The humanities has certainly also known, in prior ages, a politics of faith with entirely conservative ends in mind. Humanistic education has very often been conceived precisely as a way of policing racial, religious, gender, and class boundaries with the quite obvious goal of perfecting those who are conceived as worthy of perfection, and who will perforce rule those less enlightened. Even the apparent move to popularize humanistic knowledge that prevailed in the first half of the twentieth century in both the U.S. and the U.K. ( <em>Great Books of the Western World,</em>  the launch of Penguin Books,  <em>The Loeb Classical Library</em> ) left no doubt as to who was properly in charge of perfection.</p>
<p>The trouble, of course, is that the humanities are hardly the only manifestation of the politics of faith in modern society. For surely, one could not find a more luminous example of the politics of faith than Silicon Valley and all its works. We are subjected daily to its inexorable reframing of human desire and human potential — a torrent of apps and sites focused not merely on idle pleasures and diversions, but (more crucially) on wellness; on the virtues of being hyper-informed and aware of whatever occupies the instant; on the transhuman fantasy of the quantified self; on the essential excellence of various balances (work/life, self/other, body/spirit); on happiness in the fullest, and even the most ancient sense of the word; and, of course, productivity as a morally efficacious activity. Such bids for human perfectibility are irreducibly voluntarist in almost every sense of the term. In fact, they are so committed to the idea that our beliefs are entirely ours to choose without interference, that it is not even clear that those who are manifestly engaged in the manipulation of our desires and beliefs regard it as manipulation. Within the totalizing logic of the market, one experiences coercion as merely the marriage of two freedoms: the freedom to buy and the freedom to sell. That this will absolutely lead to the purchase of many more iPhones escapes no one at all; the only question is how to expand this logic further afield, so that more might come to know the salvation on offer. The anxious ethical dilemmas of former ages can be dispensed with in a phrase: Don&rsquo;t be evil.</p>
<p>Both visions are enabled by the same sources of power: the  “banking and book-keeping, the records, registers, files, passports, dossiers and indexes.”   <sup id="fnref8:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Or rather, by the  “intoxicating increase” <sup id="fnref9:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> of their digital successors: the user profiles, digital signatures, and network graphs; the mining and the analytics; the ability not only to account for the present, but perhaps even to predict the future (the heretofore unattainable dream of every king). The corporatization of the university is, in fact, precisely this: a conception of the way we undertake political arrangements within the university now made available by data, metrics, a concern with measurable outcomes, and the (invariably digital) tools that have brought these affordances into view.</p>
<p>Still, if the matter of how one uses the tools has any intelligibility at all (as a spectrum of ethical choices and options), that intelligibility lies mainly with the perfectibility one has in mind. And on this point, Silicon Valley and the humanistic academy are almost incommensurable paradigms. Where the one posits a genial and mostly circumscribed wellness, the other repeatedly and eternally offers the same as speculation and question. One has a short attention span; the other remains irrefragably committed to the longue durée. One quantifies the self; the other complicates it and rediscovers it. One loves binary terms; the other approaches them archly and with suspicion. Voluntaristic conceptions of belief (says Humanitas) are just so many shadows on the wall of the cave; one can scarcely imagine a class in the humanities that does not begin with the observation of its fatuousness and propose a journey (however tortuous an inconclusive) upward. That it is not possible to discover  “in the tools themselves”  some sort of political meaning that is ontologically prior to these commitments should perhaps not deter us from declaring them not politically neutral, but it should render a great number of common statements about the politics of tools at least banal if not tautological. It matters not at all that one might compose either  <em>Mein Kampf</em>    <em>or</em>  the Sermon on the Mount using a word processor. It might matter a great deal that neither one, as a matter of historical fact, was produced with this particular technology. To speak of such matters is not to locate one means with two entirely different ends, but rather two means fully and distinctly defined by ends that are not entirely void of metaphysical similarity.</p>
<p>None of this absolves digital humanities of anything. Even with radically different — and even opposed — teleologies in view, the fact that so many of our tools and techniques are handed to us by an industry with its own distinct politics of faith suggests, at least, a hardy vigilance. That we might merely advance and channel, and thus fail to resist,  “today&rsquo;s great postindustrial, neoliberal, corporate, and global flows of information-cum-capital” <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> remains a possibility. But the mere use of digital tools does not automatically forecast that failure, and the adumbration of a supposedly activist form of digital humanities work does not guarantee success. If that failure were to come, it could only come from a disavowal of the far grander aims of the humanities itself. Breaking faith with that vision, however ramified in its possibilities and articulations, would be devastating indeed. At the edge of that event horizon, digital humanities would not even succeed in being what its most bitter detractors imagine it to be. At that point, no one would be capable of asking the questions Liu asks, because digital humanities will have become something far worse than a paradox or an oxymoron. It will have become the quaint term of art once used by a benighted group who still believed that the humanities had purpose and meaning. On that day, the global flows of information-cum-capital — pursuing faith or skepticism as they please — will have presumably won.</p>
<p>Oakeshott&rsquo;s formulation is extreme, because it suggests that the  “intoxicating increase” <sup id="fnref10:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> of technological power is not some new affordance toward which the humanities may stand in some merely practical or instrumental way. On this account, one might say that the expansion of technological power created the digital humanities — making it not only possible, but conceivable. And following that thought to its conclusion, we find that the term tool is itself among the ambivalent and ambiguous terms of its political discourse, ever ready to be taken one way or another as one conceives or reconceives the nature of the humanities itself. Oakeshott, though, would claim a virtue in such ambiguity:</p>
<blockquote>
<p>Politics is a conversation between diverse interests, in which activities that circumstantially limit one another are saved from violent collision; and here, words (words, indeed, which have a continuous range of meaning in which the extreme meanings are mediated to one another) may sometimes serve our turn better than a scientific vocabulary designed to exclude all doubleness.<br>
<sup id="fnref11:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> <br>
To ask What is the politics of tools? is to ask a question as rife with possibility — and confusion — as What is justice? or What is democracy? We sense that there are such things as justice and democracy, and we likewise suspect that tools have a politics. But as with justice and democracy, one might more profitably ask what underlies our deployment of tools as political interventions.</p>
</blockquote>
<p>Perhaps this is only to restate Liu’s complaint in slightly different terms. Certainly, nothing in the preceding discussion lessens the urgency of our need to avoid just pressing the execute button on our projects. Still, one must acknowledge that accurate assessment of the political meaning of our tools is no easy matter, and certainly not a simple matter of, as Liu put it,  “scaling”  our thinking about metadata into  “thinking critically about the power, finance, and other governance protocols of the world.” <sup id="fnref2:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> If, in fact, it is true that our tool-building, while favoring a politics of faith, cannot define or predict the specific political arrangements that may later arise, we should perhaps be most circumspect not when we are tempted to imagine our efforts to be neutral, but rather when we imagine our tools to be acts of resistance or outright political activism. The former indicates a fallacy to which any humanist at all is hopefully alive; the latter, though, reflects a potentially more dangerous naiveté about the outworkings of power. Ethical thinking, political responsibility, and critique are undoubtedly obligations of the present. But thinking critically about the politics of our tools must surely also mean a certain skepticism toward the essential goodness of what we are doing. The future that awaits may well realize entire political formations on the basis of our endeavors; they may also, despite our best efforts and loudest protestations, turn our efforts to political ends entirely opposed to those for which we now long.</p>
<p>The manuscript for  <em>The Politics of Faith and the Politics of Skepticism</em>  was found among Oakeshott&rsquo;s papers after his death in 1990, and published posthumously in 1996. It is not entirely clear when it was written, and while a nascent form of its ideas may be detected in an essay from 1929 ( “Religion and the World” ), I feel justified in considering it a late work.</p>
<p>Oakeshott is quite insistent that these two tendencies characterize political modernity. He does not, for example, align Aristotle&rsquo;s notion of human flourishing (εὐδαιμονία) as a politics of faith alternative to the politics of skepticism that may well have predominated in the Greek city states (or at least, he does not mention what seems to me an obvious antecedent). He nonetheless admits to various manifestations of the politics of skepticism prior to the early modern period, and avers that such was perhaps the predominant political attitude of medieval Europe.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Foucault, Michel. (1990)  <em>The History of Sexuality: An Introduction.</em>  Vol. 1, New York: Vintage.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Liu, Alan. (2012)  “Where is Cultural Criticism in the Digital Humanities?”    <em>Debates in the Digital Humanities.</em>  Gold, Matthew K. (ed.). Minneapolis: University of Minnesota Press.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>See, for example, Matthew K. Kirschenbaum&rsquo;s trenchant precis of this and similar detractions in his 2014 essay,  “What is  Digital Humanities,  And Why Are They Saying Such Terrible Things About It?”   <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Greenblatt, Stephen. (2005)  <em>The Greenblatt Reader</em>  . New York: Lackwell.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:6">
<p>Oakeshott, Michael. (1996)  <em>The Politics of Faith and the Politics of Skepticism</em> . Edited by Timothy Fuller, New Haven: Yale UP.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref10:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref11:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:8">
<p>Wahl, Paul, and Donald R. Toppel. (1965)  <em>The Gatling Gun</em>  . New York: Arco.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Kirchenbaum, Matthew K. (2014)  “What is  “Digital Humanities”  and Why Are They Saying Such Terrible Things About It?”    <em>Differences</em> , 25.1.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Tool criticism in practice. On methods, tools and aims of computational literary studies</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000687/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000687/</id><author><name>J. Berenike Herrmann</name></author><author><name>Anne-Sophie Bories</name></author><author><name>Francesca Frontini</name></author><author><name>Clèmence Jacquot</name></author><author><name>Steffen Pielström</name></author><author><name>Simone Rebora</name></author><author><name>Geoffrey Rockwell</name></author><author><name>Stéfan Sinclair</name></author><published>2023-07-07T00:00:00+00:00</published><updated>2023-07-07T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="0-preliminaries">0. Preliminaries</h2>
<p>This paper is a case-driven contribution to the discussion on the method-theory relationship in practices within the field of Computational Literary Studies (CLS)<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>  Progress in this field dedicated to the computational analysis of literary texts has long revolved around the new, digital tools: tools, as computational devices for analysis, have had here a comparatively strong status as research entities of their own, while their ontological status has remained unclear to the day. As a rule, they have widely been imported from the fields of data science and NLP, while less often being hand-tailored to specific tasks within interdisciplinary settings. Although studies within CLS are evolving to both a higher degree of specialization in method (going beyond the limitations of out-of-the-box tools) and a stronger theoretical modeling (e.g., <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>), the technological dimension remains a defining factor. An unreflective adoption of technology in the shape of tools can compromise the plausibility and the reproducibility of the results produced using these tools.</p>
<p>Our paper presents a multi-faceted intervention to the discussion around tools, methods, and the research questions that are answered with them. It presents research perspectives first conceived at the ADHO SIG-DLS workshop  “Anatomy of tools: A closer look at textual DH methodologies”  that took place in Utrecht in July 2019. At that event, the authors discussed selected case studies to address tool criticism from several angles. Our goal was to leverage a tool-critical perspective, in order to  “take stock, reflect upon and critically comment upon our own practices”  within CLS.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
<p>We identified Textométrie, Stylometry, and Semantic Text Mining as three central types of hands-on CLS. For each of these sub-fields, we asked: What are our tools and methods-in-use? What are the implications of using a tool-oriented perspective as opposed to a methodology-oriented one? How do either relate to research questions and theory? These questions were explored by case-studies on an exemplary basis.</p>
<p>The unifying perspective of this paper is an applied tool criticism — a critical inquiry leveraged towards crucial dimensions of CLS practices. Here we re-compose the original oral papers and add entirely new sections, to create a useful overview of the issue through a combination of perspectives. While we elaborated the thematic connections between the individual case studies, we hope the interactive spirit of an exemplary exchange remains palpable: individual research perspectives shape the case studies reported for Textométrie, Stylometry, and Semantic Text Mining. They are complemented by further studies showcasing CLS-specific perspectives on replicability and domain-specific research, and a short section discussing a tool inventory as a practical, community-based incarnation of tool criticism.</p>
<p>The  <em>practice of tool criticism</em> , the evaluation of a tool&rsquo;s suitability to a specific task, is a  <em>sine qua non</em>  in the interdisciplinary setup of a Digital Humanities discipline like CLS, where actors have different degrees of types of technological expertise. Here is where tool criticism caters to  “the evaluation of the suitability of a given digital tool for a specific task”   <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. Importantly, the goal is to  “better understand the impact of any bias of the tool on the specific task, not to improve the tools performance”   <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</p>
<p>Here, tool criticism is mainly methodological and epistemological: it complements the narrower, domain-dependent practice of  <em>methodological evaluation</em> , where established ways of testing a method&rsquo;s reliability, objectivity and validity, or precision and recall, respectively, are widely standardized. Tool criticism thus operates in a field of practices where such standards are not conventional yet, but goes beyond them also, by combining a methodological with a  <em>critical</em>  enquiry that  <em>can</em>  be epistemological, but can also extend to financial, pedagogical, disciplinary and other implications. It aims to unearth presuppositions ingrained in the tools that often neither data scientists nor humanities scholars may be naturally aware of in interdisciplinary settings. Especially when a tool becomes successful and thus popular, the evaluation of its suitability to specific tasks is often backgrounded or even neglected.</p>
<p>With the 2019 workshop title  <em>Anatomy of Tools</em> , we chose an analogy from the field of biology to convey our joint aim of  <em>dissecting</em>  case studies with respect to the role of the tool respectively. In our work, we noticed that in CLS generally highly diverse incarnations of tool are subsumed under one general concept, each tool different in type, specificity, and goal. Therefore, we operationally define the term tool<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  as follows:</p>
<blockquote>
<p>At the most basic level, in the present paper, a tool is  _a computational device used for carrying out  analyses _ . This potentially includes aids for diverse sub- <em>processes</em>  such as data collection, data pre-processing, annotation and indexing, as well as analyses proper, which may or may not involve frequency counts, algorithmic and statistical modeling, or visualization. A tool is here thus understood as a type of methodological vehicle used for contributing to the pursuit of a particular research goal on some aspect of literary discourse treated as data. In the context of CLS, a tool digitally retrieves, and/or represents, and/or operates upon and/or manipulates literary data,<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>  which principally includes annotations and metadata.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  This includes for instance text analysis tools such as Voyant, program libraries for R or Python, as well as general-purpose tools such as Excel spreadsheets or visualization tools.</p>
</blockquote>
<blockquote>
<p>By contrast to a  <em>method</em> , a tool is further defined by its typically reified and closed character. As a computational implementation of a method, it exists as a distinctive  <em>entity</em>  with a limited set of functions. A tool often includes a graphical user interface (GUI), which makes it also phenomenologically perceived as a particular device rather than a potentially adaptable set of conditions. Another relevant dimension of tools is its transformative power, as emphasized by Weizenbaum and others:  “[T]he tool is much more than a mere device: It is an agent for change”   <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. If a tool is successful, which means widely and conventionally used in order to carry out a task, this  <em>change</em>  does not only happen at the level of the  <em>method</em>  of doing something, but potentially also extends to the  <em>object</em>  to which method is applied. The object is then co-constructed by the method – which in turn has effects on the scholarly  <em>subject</em>  using the tool, for example, on their epistemological framework.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>
</blockquote>
<p>How can actors know enough about the  “bias of the tool on the specific task,”   <sup id="fnref2:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> how can they gauge its validity, or its capacity for producing plausibility? Or its potential of inducing change in the world? In the present paper, we will not offer many decisive answers to the important questions raised by the use of tools in CLS, and neither can we dive deep into systematic epistemological, media-theoretical, or sociological discussions. However, we do describe critically how a few exemplary tools are applied to several typical research questions within representative sub-fields of CLS. Our aim is to give a practical foothold for a principled  <em>tool-critical awareness</em> .</p>
<p>The paper is structured in the following way: In the introduction (Section 1), we raise issues of tool criticism of current CLS at the interface between methodology and theory. Here, we discuss the advantages and disadvantages of the discourse on tools vs. methods, as well as the dimensions of different types of user groups, and a shift from tools towards a more integrated perspective on modeling. We also make a case for tool defense. In the main part, we first present three tool-critical case studies of what we have called method-driven schools: Textométrie, Stylometry, and Semantic Text Mining (Section 2). Each of its sub sections (Sections 2.1 - 2.3) addresses a pertinent approach, giving an overview of its usability and strengths in the actual research, as well as pointing out problems and formulating specific avenues for further development. Taking a slightly different angle, Section 3 will then discuss the important issue of replicability and the range of its potential incarnations in CLS – in between its humanities and science poles. In the fourth section, we single out an example for one  <em>specific research domain</em>  (poetry), addressing the need for domain-specific tool adaptation in a particular case. The fifth section will present one attempt at a practical solution for handling and gauging methods in Computational Literary Studies, the  <em>SIG-DLS Tool Inventory</em> , which was designed to provide both a perspective of orientation and criticism. Finally, we draw a summary and conclusion.</p>
<h2 id="introduction">Introduction</h2>
<p>Tool criticism <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>  <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> has made us aware that the digital tools widely distributed in DH have the power to reify theoretical  <em>a prioris</em>   <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>  <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>. Therefore, the community needs a handle for gauging their validity, or capacity for producing plausibility <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>, possibly applying a sense of craft <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. But tools are not just tools – the current panorama in CLS presents a plethora of computational devices used for carrying out  “literary analyses: instruments, protocols and practices for processing, analyzing and visualizing data”  (see our operational definition of tool above). On a general level, all of these are used to examine aspects of literature, but a closer look reveals that the methodological heirdom of CLS is a precarious patchwork. Just loose connections link tools from stylometry to those from NLP and computational linguistics, to those from corpus linguistics, and to ones more genuinely developed within literary studies. At the moment we are dealing with a rich, but also atomized situation. Some tools, but by far not all, involve aggregation and statistical models, while others center on visualization, while yet others have a different epistemic approach, centering on implementing a hermeneutic or deconstructivist mode of enquiry. Some tools combine multiple methods.</p>
<p>What is more, CLS practices are diverse also in the degree of reduction and generalization. They vary in the way they explicitly address the fit of (digital) data and method to literary modeling <sup id="fnref1:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>  <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>  <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. The practices run the gamut extending from a computational, or quantitative, paradigm <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> with computational linguistics, text mining, quantitative linguistics, and corpus linguistics and an analog, qualitative paradigm with structuralist, hermeneutic, or deconstructivist approaches. It is evident how these have substantially distinct requirements, intentions and ways of defining the limitations imposed by the digital.</p>
<blockquote>
<p>As the role of digital tools in these [sic!] type of studies grows, it is important that scholars are aware of the limitations of these tools, especially when these limitations might bias the outcome of the answers to their specific research questions. While this potential bias is sometimes acknowledged as an issue, it is rarely discussed in detail, quantified or otherwise made explicit. On the other hand, computer scientists (CS) and most tool developers tend to aim for generic methods that are highly generalisable, with a preference for tools that are applicable to a wide range of research questions. As such, they are typically not able to predict the performance of their tools and methods in a very specific context. This is often the point where the discussion stops. <sup id="fnref3:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
</blockquote>
<p>In the current paper, we address selected tools in concrete scenarios of application within CLS, as well as the preconditions of  <em>replicability/recapitulation</em>  and  <em>domain specificity</em>  as well as practical questions of how to conduct tool criticism more systematically and openly.</p>
<p>There is a fertile ground for this in CLS, which have clearly developed a  “sense of tool criticism”  that includes an awareness of built-in bias in generic tools  “inherited”  from Computer Science and NLP <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>  <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>, and appears to evolve to an explicit sense of digital methodology <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. Tool criticism, posited by Karin van Es and colleagues as  “a rigorous inquiry into the tools used for research”   <sup id="fnref1:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> is indeed already becoming an  “essential element of the overall research process”   <sup id="fnref2:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. Accordingly, more emphasis has been put on the adaptation and scaling of methods to specific research questions, combining reflected and critical approaches with the affordances of digitization, constructively managing constraints. Most recently, the replication-debate that originated from psychology has demonstrated that common and explicit criteria, or at least a differentiated conversation about underlying axioms, are desirable (see replies to  “the Da-paper”   <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup><sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> ).</p>
<p>Interpreted as a contribution to serious scholarship, the – also clearly polemic – paper by Nan Z. Da<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>  highlights that constructive criticism is needed for methodological and theoretical progress, which examines whether a certain method is actually applied well to some type of research question. We believe that the time is ripe for a constructive literary method criticism, which can foster a uniquely humanities perspective of digital enquiry. One of the most interesting positions emerging from our workshop is that of tools as – ideally – well-calibrated instruments for getting things done in CLS. From here, we have started thinking along the lines of a  <em>tool defense,</em>  which concerns the balance between methodological and content-related research. Driven by the affordances of the digital transformation, CLS has so far understandably put an emphasis on the how – the development of methodology, as well as digital resources and standards. Meanwhile, the what, that is, historically contextualized and systematic enquiries about literary texts, structures, and discourse have not received equal attention. Looking out at the future of CLS, we realize that the discussion about tools directly relates to the definition of digital literary studies as a discipline: is it predominantly a methodological experiment, or is it a serious data-driven, digitally enhanced, enquiry into things literary? Starting to answer these questions means to address strategies of tool evaluation, but also standards of methodological training.</p>
<p>In light of these issues, when juxtaposing our section 2 on Textométrie, Stylometry, and Semantic Text Mining we also asked  <em>How do practices relate to different types of actors in the field?</em>  In CLS, scholars originally trained in literary studies typically approach methodology differently from scholars originally trained in data science. For example, our discussion of textométrie (2.1) raises very different questions from that of semantic text mining (2.3). At the same time, there are clear differences between the statistical models applied in the different computational fields – NLP, corpus linguistics, and computational linguistics, which only in part coincide with the division between explanatory / exploratory / predictive perspectives.</p>
<p>Scholars, by discipline and training, may vary in their research focus, some preferring to solve methodological questions, while others concentrate on questions about periods, stylistic features, or the history of ideas, to name a few. While it is indispensable to understand the way a tool works at a fundamental level, not every scholar is interested in the development of methodology for its own sake. Along these lines, an important point made in the discussion was  <em>that we need a well-calibrated arsenal of instruments</em>  in the hands of a  <em>scholarly majority</em> : transparent tools/methods as a reliable basis for the emerging mainstream, who rather than advance a method, wishes to pursue literary research questions. Such methods fulfill multiple functions, one of which is providing a basic common ground on how to carry out fundamental operations of analysis and interpretation.<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>  This is precisely where we have identified the perspective of tool defense. Section 2 aims at striking a balance in between criticism and defense.</p>
<p>At the moment, one of the most pertinent questions in the broader field of science is that of  <em>replication</em> , addressed by section 3, which emphasizes that digital humanistic enquiry may, however, entail a qualitative, sometimes even emphatic, understanding of cultural phenomena embedded in rich historical contexts. Not only where interpretation involves the appreciation of texts or parts of texts through aesthetic and otherwise hermeneutic processes, we have to deal with an irreducible subjectivity. But there is a clash with replicability approached as one of the criteria of the scientific method.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>  In CLS, we thus need to discuss whether, when and where we want to strive for replicability based on accounts of objectivity – and whether, when and where the softer criterion of intersubjectivity may be more adequate. Section 3 prompts questions such as:  <em>What is the status of replicability in CLS, and are there possibly specific  literary  types of replicability? What culture of replication do we want to develop in the humanities? What traditions can we draw on?</em></p>
<p>Closely related to the need for standards and ready-made tools in CLS is that of  <em>domain specificity</em>  addressed by section 4: While CLS should at one level advance towards a standard inventory of methods and tools, in ultimate instance valid and meaningful results can be achieved only if sources and methodologies are tailored to the specific research questions, which in turn are nested within domains of expert knowledge. Thus, a practical CLS tool criticism can hardly avoid factoring in the affordances of target domains such as prose, drama, and poetry:  _How can the gap between domain generality and specificity be bridged in practice? _ Section 4 singles out one specific domain, poetry, as an exemplary use case. _  _ Section 5 on the  <em>DLS-Tool Inventory</em>  follows by illustrating an ongoing initiative to address documentation, comparability and community-driven evaluation:  _How can we systematically record and compare methods and tools, gauge their usability and the fundamental assumptions incarnated? _ It showcases one attempt at making available tools as embedded in concrete case studies, offering a foothold for judging their applicability, as well as practical replication and/or recapitulation of particular studies.</p>
<h2 id="2-three-methodological-schools-within-cls">2. Three Methodological Schools within CLS</h2>
<p>Based on what has emerged so far from the  <em>DLS-Tool Inventory</em>  and our observations of research practices, we have identified three schools that coincide with different types of (handling) digital tools – or indeed methods: Textométrie, Stylometry, and Semantic Text Mining. In the following sub-sections, three short tool-critical case studies will address each of these by practical example, addressing its advantages and limitations.</p>
<h2 id="21-textométrie-applying-a-general-tool-to-a-specific-research-question">2.1 Textométrie: Applying a general tool to a specific research question</h2>
<p>Textometric tools are widely used to explore literary corpora by a mix of quantitative and qualitative methods. Textométrie is an approach to statistical text analysis, developed in France during the 1970s, following lexicometry, a traditional statistical approach to study lexical particularities of literary texts, such as common words, hapax legomena, and specific keywords <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>  <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. In addition, textometry applies methods of data analysis, for instance factor analysis or clustering, that enable mapping of words and texts as they are similar or opposed to each other within a corpus.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>  Its objective is to produce interpretable statistics of textual data, in a contrasting perspective. Bolstered by the development of accessible software platforms incorporating textual statistics, textometry has produced a number of relatively generic tools, alongside a productive body of research in the domain of stylistics and corpus linguistics <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. As textometry involves the principled interaction between quantitative (reductive) and qualitative (contextualizing) enquiry <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>, it is an attractive approach for scholars from the field of stylistics, which is traditionally qualitative and interpretative. In mixed methods, they are able to capitalize on pattern detection of quantitative operations for larger-scaled studies and re-contextualization that often leads to original observations.</p>
<p>Currently, the most pertinent textometric tools are probably  <em>Hyperbase</em> <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>  (Etienne Brunet, University of Nice) and  <em>TXM</em>  (Serge Heiden, Ecole Normale Supérieure of Lyon). In the following, we will report on a study carried out with TXM (version 0.5). We chose TXM as it may be referred to as a canonical tool. It is a text analysis environment which is well documented, available in open-source, and compatible with texts encoded in XML. It also comprises a graphical client based on CQP and R and is available for Microsoft Windows, Linux, Mac OS X and as a J2EE web portal.<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup></p>
<p>In the following, we will reflect on using TXM as a comprehensive, out-of-the-box tool for a diachronic stylistic analysis by applying it to one exemplary study of French poetry.  <em>How can the gap between domain generality of the tool and the specificity of the research question be bridged in practice? What advantages and disadvantages need to be faced?</em></p>
<p>In our TXM case study, we explore the poetic style of the poems written by the French poet Guillaume Apollinaire (1880-1918) from a diachronic perspective. The literary analysis of the poetry of Apollinaire is meant as an illustration only: this subsection primarily aims to highlight and to scrutinize the strengths and the limitations of the TXM tool. Apollinaire is one of the most eminent French poets of the early twentieth century. He is particularly known as an important figure in the renewal of poetic forms alongside contemporary avant-garde movements in art (cubism, dadaism). His poetry is marked by  <em>discontinuity</em> ,  <em>heterogeneity</em>  and  <em>fragmentation</em> , similar to other authors of this period (e.g. Romains, Salmon, Jacob). One important dimension for interpretation and analysis of his poetic writing is perpetual reorganization: texts being rewritten, reused in other contexts, transformed from prose into poetry, see <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>  <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>  <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>  <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>  <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>. These sign-marks of Apollinaire&rsquo;s writing appear at several levels, including the composition of the collections, different types of tone, lexical resources, influences, and thematic issues.</p>
<p>Usually, analyses are based on thematic differences within Apollinaire&rsquo;s work, especially between his two main collections:  <em>Alcools</em>  (1913) and  <em>Calligrammes</em>  (1918). Approaching style as a dynamic factor <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>  <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>, our case study deliberately adopts a fresh look, with the intention to be unbiased with regard to a thematic approach, centering in on the diachronic evolution of writing.<br>
_If style is conceived of as a dynamic factor, how may Apollinaire&rsquo;s heterogeneous poetry be analyzed textometrically as a homogeneous unit? _        _How may the evolution of Apollinaire&rsquo;s style be textometrically traced over the years? _        <em>Can we textometrically re-assess value judgments predominantly based on thematic aspects?</em></p>
<p>We depart from the hypothesis of a temporal evolution of stylistic, specifically, syntactic, structures in Apollinaire&rsquo;s poetic oeuvre. As there are issues with the clear temporal reference of Apollinaire&rsquo;s texts, we resort to the criterion of relative dating, enriching the corpus by temporal metadata. Going by publication dates, Apollinaire&rsquo;s anthumous poetic oeuvre appears in several collections of varying scope over a period of about eight years:  <em>Le Bestiaire ou Cortège d’Orphée</em>  (1911),  <em>Alcools</em>  (1913),  <em>Vitam impendere amori</em>  (1917) and  <em>Calligrammes</em>  (1918).</p>
<p>Metadata covering just these dates would present a distortion of the genealogy of writing, however.  <em>Alcools</em> , for instance, a striking example of the phenomenon of perpetual rewriting, was published in 1913, but actually collects poems originally composed over more than a decade (1898 — 1913).<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>  This temporal heterogeneity poses a substantial problem for designing a metadata schema: dates need to be provided for each text in order to facilitate a diachronic contrastive analysis of the corpus.</p>
<p>In order to get a handle on a potential evolution of Apollinaire&rsquo;s style, it appears fruitful to consider syntactic configurations. Striking a balance between descriptive accounts of style, for instance,  <em>discontinuity</em>  and  <em>fragmentation</em> , and the affordances of a formal tool such as TXM, we focused on the distribution and the use of grammatical words and especially what we will call here the syntactic link markers, i.e. the lexical links between sentences, for example conjunctions and relative pronouns. Interestingly, the use of these grammatical words is explicitly mentioned in Apollinaire&rsquo;s poetics, for example, in 1915, where he posits a  “simplification of the syntax of poetry”   <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>. Our method is thus to compare several sub-divisions of Apollinaire&rsquo;s poetic corpus for the distribution of grammatical words, but paying special attention to the date of writing, which needs to be manually re-attributed to each poem. In TXM, we thus use basic database functions to shape the representation of the data to our needs.</p>
<p>The first step in using TXM is corpus construction and pre-processing. This includes tokenization, lemmatization, and automatic annotation of textual features, such as part of speech, as well as the enrichment by metadata such as authorship, data of publication, genre, text collection. It is thus pivotal that TXM takes care of important analytical steps, the researcher relying on the sub-modules and parameter settings of the general tool provided for the community. In our annotation of the Apollinaire corpus, we aim to represent its original structural organization from the largest unit, the subset constituted by Apollinaire&rsquo;s poetic collections ( <em>Alcools</em> ,  <em>Bestiaire</em> ,  <em>Calligrammes</em>  &hellip;) down to that of the verse: title of the poetry collection &gt; section &gt; subdivision (if needed) &gt; title of the poem &gt; stanza &gt; verse. These structural metadata are completed by information about textual particularities, especially at the poem-unit level. We use six units (optional marked with <em>): title, subtitle</em>, epigraph*, date of writing*, date of edition, and date of publication (see <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>).</p>
<p>The research logic of TXM requires systematic temporal data. Our relative dating – defined as the marking up of each text according to its writing date, either supposed or authorized <sup id="fnref1:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup> – has the advantage of transcending the potentially problematic unity of texts created by the poetry collections. <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>  The collection  <em>Alcools</em> , for example, is based on a set of themes and alternates cycles and inspirations. Using the TXM database detaches the poems from their previously perceived unit (the collection) and thus liberates them from efficacious prior ascription, facilitating new perspectives. The textometric analysis works on sub-sets indexed by the newly added temporal attributes, potentially identifying, in the various collections, new organizations of Apollinaire&rsquo;s poems.</p>
<p>For the diachronic analysis, we apply TXM&rsquo;s  “specificity calculation” <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>, which highlights the positive as well as negative specificities in terms of a defined set of linguistic markers, comparing all temporal subsets with each other.</p>
<p>Building upon the part-of-speech-tagging in TXM (launched at ingesting a corpus), and our division of temporal sub-sets (by year), we examine the diachronic distribution of syntactic link markers (for example: lorsque, quand, qui, que, parce que). Figure 1 shows positive and negative specificities in the distribution of syntactic link markers (significant over- vs. underuse in comparison with the other temporal subsets). It highlights clear trends in the way Apollinaire uses the syntactic link markers.<br>




























<figure ><img loading="lazy" alt="Line chart with one red line and one blue line" src="/dhqwords/vol/17/2/000687/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000687/resources/images/figure01_hu0a37498edbbc124d3c8f1782f1bbec6d_76008_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000687/resources/images/figure01_hu0a37498edbbc124d3c8f1782f1bbec6d_76008_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000687/resources/images/figure01.png 632w" 
     class="landscape"
     ><figcaption>
        <p>Diachronic distribution of subordinating conjunctions in Apollinaire’s poetic corpus specificity calculation. Comparison between Supposed Writing Years (in red) and Authorized Writing Years (in blue)
        </p>
    </figcaption>
</figure></p>
<p>The figure also depicts a comparison between the distribution specificities for the metadata Authorized Writing Years (in blue), and Supposed Writing Years (in red).</p>
<p>For the assumed writing years, the graph reveals a striking over-representation of the style markers in 1915, 1916, and 1917, and even the Authorized Writing Years (in blue) depict a significant overuse in 1915 and 1916. The year 1917 shows a difference between the assumed and the authorized writing date — the latter does not deviate much from a statistical chance result, falling into the banality zone (in textometry, the significant specificity scores are usually below -2 and above +2). It is on the basis of this corpus&rsquo;s analyses that we choose, through several pilot studies, to favor the assumed writing years for our stylistic studies. Adding relative temporal data indeed seems to provide us with genealogical-philologically more appropriate and often more meaningful results than the authorized year of writing (which is after all, most often more artificial).</p>
<p>The data (including further features, see <sup id="fnref2:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>) show a trend that is in line with the author&rsquo;s poetics: Over time, stylistic links become more common in Apollinaire&rsquo;s poems. This finding actually defies the idea of a deep heterogeneity, as it points to the increase of devices used for creating cohesion and coherence, at least at the stylistic level. The data also show that the attributed dates render more pronounced amplitudes than the authorized dates.</p>
<p>Our example of textometric study shows that a generic tool can be put to specific use when this use is based on intricate expert knowledge (here about how to handle the metadata). Using a tool like TXM allows respecting the complexity of the literary subject, even if it — as in our case, the dating of Apollinarian texts — is fragile. The scholar is not relieved of their critical responsibility. As a tool capable of processing structured data, TXM allows for the modeling of data based on criteria that are not always explicit. Entering the estimated dates into the database has the potential (and risk) of their reification, enhanced through visualization and ensuing analysis, especially where no automatic reflection is built into the analytical process regarding the basis for temporal attribution. At the same time, the textometric analysis offers several opportunities for a heuristic change of perspectives, specifically through simultaneous representation of estimated and authorized dates, which allows for systematic comparison of different types of ascription. For users from stylistics, TXM has the advantage of flexibly partitioning the corpus into several different sub-corpora, comparable to each other. It should be mentioned that the whole analysis hinges on pivotal pre-processing steps, such as tokenization, lemmatization, and part-of-speech tagging. The accuracy of these automatic steps needs to be rigorously gauged (are the words correctly separated, including compositional lexical units that cross white space boundaries? Are parts of speech correctly identified?) The same holds at a different level for the research logic tacitly presented (e.g., analytic relevance of basic unit word, of part of speech). These present possible blind spots that users need to be aware of and are required to thoroughly check in each analysis.</p>
<h2 id="22-word-frequencies-in-stylometry">2.2 Word Frequencies in Stylometry</h2>
<p>Stylometry uses a series of tools and methods for the statistical analysis of style, based on advanced calculations on stylistic properties of texts, whereby mostly focusing on word frequencies. Its main applications have been both authorship attribution and distant reading. Initially developed through the use of spreadsheets, stylometric methods have been fully implemented into programming languages such as R and Python <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>  <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>, and enhanced by a wide variety of visualizations, derived from research fields such as philogenetics and network theory <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. However, from a very pragmatic point of view, it can be stated that the most widely and frequently used tool in stylometry are simple algorithms that count words, on which methods like  “Delta distance”   <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup> are applied.</p>
<p>In the abovementioned, fairly dramatic, critique of computational literary studies, <sup id="fnref1:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> made a controversial case against the application of quantitative methods to literary texts.<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>  She argues that much work in this field essentially boils down to counting words. We agree that this view is somewhat reductive, but also find it not without merit: it certainly applies to much of the present-day approaches that are dominant in stylometry and, consequently, to many of the tools that are available. While this methodological focus is to some extent justified by empirical work, the under-explored options for stylometry to move beyond naive word counting need specific attention. Stylometrists, for instance, often take pride in the fact that their tools typically work on raw texts that require little preprocessing. In this, stylometry ignores much of the achievements of literary theory in the twentieth century, such as the importance of focalization or the (actual or implied) reader <sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>  <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>  <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>.<sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>  Richer (pre)processing pipelines, that also tap into syntax and discourse, might allow stylometry to revitalize its connection with literary theory, but come with significant barriers for non-Anglo-Saxon literatures.</p>
<p>In their thought-provoking article, <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup> already proposed a method that took into consideration not only word count, but also syntactic tags as features for stylometric analysis. By working on the results of a partial parser, which performs  “a structural analysis that is more than mere chunking but less than the parse tree of a fully recursive grammar”   <sup id="fnref1:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>, it became possible to measure the syntactic structure of sentences. Hirst and Feiguina tested this method on the attribution of the works of the Brontë sisters, reaching some very promising accuracy scores. Curiously enough, however, the method did not find extensive application in the following years. While <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup> cited it as one of the most promising methods, approaches like  <em>Delta</em>  (a similarity measure based just on the most frequent words) have dominated the field of stylometry, with just a few attempts <sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>  <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup> to include part-of-speech tags and phrase-structures as well.</p>
<p>The main reason for such a forgetfulness is the fact that similar approaches have proved quite inefficient when compared to others in competition-like setups. In the computational linguistics community, the most relevant of these setups is PAN ( <em>Plagiarism Analysis, Authorship Identification, and Near-Duplicate Detection</em> ), <sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>  a competition held each year in the context of the Conference and Labs of the Evaluation Forum (CLEF) conference, where teams of programmers are invited to write scripts to solve a series of shared tasks, generally focused on authorship attribution. This shared task can be considered in general as a good research practice, as it implies a criticism of tools that are constantly rethought and improved through competition <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>.</p>
<p>Even if the final goals of stylometry clearly move away from simple authorship attribution, aiming at a quantitative characterization of authorial style, it should be noted how attribution is still the most frequently adopted task when verifying the efficiency of stylometric methods (cf. <sup id="fnref1:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>  <sup id="fnref1:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>  <sup id="fnref1:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>). In fact, if it cannot be proven that a computer is actually able to tell apart the style of two authors, any approach that adopts it to study authorial style can be easily dismissed as frail or inconsistent.</p>
<p>An overview of the methods presented for the authorship identification task at PAN 2014 notes how the features preferred by participants are  “low-level measures” , such as  “character measures (i.e., punctuation mark counts, prefix/suffix counts, character n-grams, etc.) or lexical measures (i.e., vocabulary richness measures, sentence/word length counts, stopword frequency, n-grams of words/stopwords, word skip-grams, etc.)”   <sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>. Only one approach was based on high-level features, obtaining some of the lowest scores. Hirst himself participated in the 2012 PAN competition, getting the worst result in the authorship attribution task.<sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>  Finally, in one of the most recent PAN competitions, focused on multi-authored fanfiction texts, just a few teams used POS tags and they were clearly outperformed by those who chose the simplest methods, based on character and word n-grams <sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup>. In conclusion, notwithstanding the originality and the theoretical consistency of the idea, the approach seems to prove inefficient when applied to an effective measuring of style. Reasons may be many, starting from the necessary automated (pre-)processing of texts, which might generate errors in itself. In addition, overfitting may be a source of error in machine learning approaches (that are more and more frequently used in stylometry): a combination of too many high-level features can make a model strong for a specific case study (see the Brontë sisters in <sup id="fnref2:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>), but can also hinder its generalizability. From this point of view, simple wordcount might prove less insightful, but much more stable. Finally, it is undeniable that, while NLP tools have been developed extensively for English, efficient applications to other languages are still missing, where research is a few – if not many – steps behind. Therefore, while wordcount proves reliable whatever the language of application <sup id="fnref2:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>, the same cannot be said with approaches that rely on high-level features.</p>
<p>However, during the past few years, the interest towards more linguistically informed approaches has never fully extinguished. In fact, there is the impression that state-of-the-art stylometric methods work efficiently not because they are able to catch the very nature of style, but just because they scrape the surface of a phenomenon that has much more profound implications. In fact, by modeling stylistic distance as a statistical difference in the frequency of use of some words (or characters), stylistic choices such as syntactic construction and discourse structuring might be implicitly modeled (as they determine these very frequencies). However, such implicit modeling catches them only indirectly, and thus incompletely (see also <sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup>).</p>
<p>In recent years, positive experimental results have finally started to support this theoretical need. In the PAN 2019 Cross-Domain Authorship Attribution Task (once again, focused on fanfiction texts in four different languages), one team proposed a fruitful integration between word- (and punctuation-) count, stemming, text distortion, and POS-tagging. The tagging was performed using Spacy,<sup id="fnref:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup>  which reaches  “an accuracy that varies from 95.29% to 97.23%”   <sup id="fnref:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup>. Notwithstanding the errors generated by the tagger, the approach ranked second (and even first for Spanish texts, cf. <sup id="fnref:67"><a href="#fn:67" class="footnote-ref" role="doc-noteref">67</a></sup>), confirming how, with an improvement of NLP tools, the dream of a stylometry finally able to move beyond wordcount and reach some more theoretically-pregnant dimensions might not be a dream anymore.</p>
<h2 id="23-semantic-text-mining">2.3 Semantic Text Mining</h2>
<p>Semantic Text Mining methods, such as sentiment analysis, topic modelling, and word embeddings, apply tools for text analysis and visualization based on external semantic information and co-occurrence methodologies. They offer the potential of addressing key questions in literary theory and narratology, from the identification of genre to the visualization of plot. These emerging approaches are now beginning to broaden the scope of computational literary studies and to open up new, still unexplored, potentialities. But it is not only these potentialities that still await exploration, but also the limitations and caveats of the methods&rsquo; application in humanities research that in many cases require more systematic investigations.</p>
<p>Among these methods, topic models based on Latent Dirichlet Allocation (LDA) and Gibbs Sampling <sup id="fnref:68"><a href="#fn:68" class="footnote-ref" role="doc-noteref">68</a></sup>  <sup id="fnref:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup> have become particularly popular in digital humanities research in recent years (see e.g. <sup id="fnref:70"><a href="#fn:70" class="footnote-ref" role="doc-noteref">70</a></sup>  <sup id="fnref:71"><a href="#fn:71" class="footnote-ref" role="doc-noteref">71</a></sup>  <sup id="fnref:72"><a href="#fn:72" class="footnote-ref" role="doc-noteref">72</a></sup>). They allow for explorations and analyses of the content and the semantic structure of digital text corpora. They permit researchers to model a corpus&rsquo; content in terms of so-called topics, groups of words which are apparently semantically related, and show the distribution of these topics within the corpus. By observing single, meaningful topics, scholars can scan large text collections for documents relevant to a specific discourse, or estimate how the prominence of such a discourse developed along the time axis (e.g. <sup id="fnref:73"><a href="#fn:73" class="footnote-ref" role="doc-noteref">73</a></sup>). Texts can be sorted according to their content, and it is also possible to derive content-related features for text classification from topic models (e.g. <sup id="fnref:74"><a href="#fn:74" class="footnote-ref" role="doc-noteref">74</a></sup>). Thanks to an increasing number of available tools and libraries, the method is, by this day, accessible to a wide range of users<sup id="fnref:75"><a href="#fn:75" class="footnote-ref" role="doc-noteref">75</a></sup>  (Figure 2).<br>




























<figure ><img loading="lazy" alt="Screencapture featuring heatmap" src="/dhqwords/vol/17/2/000687/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000687/resources/images/figure02_huec3406601c1c0e6adc139965d3b74aa5_279349_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000687/resources/images/figure02_huec3406601c1c0e6adc139965d3b74aa5_279349_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000687/resources/images/figure02.png 936w" 
     class="landscape"
     ><figcaption>
        <p>Interface of the DARIAHTopicsExplorer as an example for how accessible topic modeling nowadays is to users. Among other results, the interface produces a heat map overview of the distribution of topics in the corpus (here, a small collection of English short stories). This heat map shows us, among other things, that a topic in which the words mowgli and jungle weigh most heavily is very present in Kipling&rsquo;s <em>The Jungle Book</em> .
        </p>
    </figcaption>
</figure></p>
<p>The popularity of topic modeling in digital humanities combined with its technical accessibility may suggest that it is a well understood method – safe to use without a second thought – but this impression is misleading. Basically, there are three issues to consider when using topic modeling: (1) in order to use it, one has to make decisions that require a basic understanding of the algorithm, (2) for many of these decisions there are still no best practices and recommendations rooted in systematic, empirical, methodological research, and (3) attempts to validate a computational method for semantic analysis is generally not unproblematic.</p>
<p>(1) The methodology of topic modeling is rather intricate: LDA topic models are based on relatively advanced probabilistic procedures, which are probably understood only vaguely by many users. The method requires a number of informed decisions that have to be taken by these users – about the number of topics, iterations, chunk sizes, even hyperparameter settings and the innumerable possible ways to preprocess the texts.</p>
<p>(2) Moreover, even after years of application in the field, it is still hard to find clear recommendations and best practices concerning the choice of model parameters or preprocessing steps in topic modeling. As <sup id="fnref:76"><a href="#fn:76" class="footnote-ref" role="doc-noteref">76</a></sup> points out in a survey on how topic modeling has been used in digital humanities in the past, many studies do not even bother to report the parameter settings of their experiments. If experiments are reported in more detail, studies often copy the decisions that seemingly worked well in other studies. The field would certainly benefit from more thorough methodological research providing empirical grounds for clear and systematic recommendations and best practices tailored towards the specific demands of the field.</p>
<p>(3) But there is a more fundamental problem that affects the search for parameters that produce good topic models: the impossibility to clearly define a good topic model. In semantic text mining we attempt to map a mathematical concept onto the much more elusive phenomenon of semantic meaning.<sup id="fnref:77"><a href="#fn:77" class="footnote-ref" role="doc-noteref">77</a></sup>  Human readers are often stunned by the combinations of words found in topic models. One of the most popular German tutorials on topic modeling introduces the concept with an example topic composed of the keywords “theater, actor, play, role, applause&hellip;”.<sup id="fnref:78"><a href="#fn:78" class="footnote-ref" role="doc-noteref">78</a></sup>  It is obvious to the reader that grouping these words together seems to be meaningful, and that is why scholars are attracted to topic modeling. But to evaluate the method, it is necessary to quantify how meaningful this combination is compared to others.</p>
<p>Other areas of text mining can deal with that kind of problem much more straightforwardly. To evaluate a method for authorship attribution or POS-tagging, we can create test sets containing instances the classes of which we already know and observe how many texts are attributed correctly to their authors, or how many words are tagged correctly with their respective POS tags. But what is the correct semantic description of a fictional text? Some approximations have been tried. Probably the closest to the intuition of meaningfulness of a topic is the word intrusion method <sup id="fnref:79"><a href="#fn:79" class="footnote-ref" role="doc-noteref">79</a></sup>  <sup id="fnref:80"><a href="#fn:80" class="footnote-ref" role="doc-noteref">80</a></sup>, where a random word is added to a topic and human annotators are tasked to identify it. If a random intruder is easy to spot, the original words of the topic are considered semantically close. Another popular idea is that a meaningful interpretable topic can be identified by measuring the semantic coherence of its keywords-based co-occurrence in an external source (usually wikipedia), e.g. in terms of Pointwise Mutual Information (PMI). A third approach is based on previous knowledge about the internal structure of an evaluation corpus: if the content topics of the texts in a collection are known in advance, thanks for example to key words provided by the authors, a good topic model could be defined as one that allows a classifier to attribute texts to keywords using the topic distributions as features <sup id="fnref1:72"><a href="#fn:72" class="footnote-ref" role="doc-noteref">72</a></sup>. These are all but approximations to our intuition of meaningfulness, and future research may even show that they can produce contradicting recommendations in some cases. <sup id="fnref:81"><a href="#fn:81" class="footnote-ref" role="doc-noteref">81</a></sup></p>
<p>Despite the current challenges, topic modeling is a useful tool for exploring the content – literally speaking, the topoi – of a corpus. It thereby can, without a doubt, considerably assist us in hypothesis generation. However, the fact that this method has both been factually established in the digital humanities community for some years and is relatively accessible should not lead us to believe that our understanding of how to apply it in our field is exhaustive and complete, and that we can reliably base matter-of-fact statements with ease on the results of topic modeling. To get to this point, further research dedicated specifically to the methodology of topic modeling and its application on research questions in digital humanities will be required.</p>
<h2 id="3-recapitulation-replication-reanalysis-repetition-or-revivication">3. Recapitulation, Replication, Reanalysis, Repetition, or Revivication</h2>
<p>In Section 2, we examined textometry, stylometry, and semantic text mining as three subfields of CLS that are driven by methodology. The different sub sections each showed how very different tools can indeed be well-suited to the intended tasks, requiring, however, both methodical skill and expert knowledge of the content under scrutiny. The required knowledge of the inner workings of the tool at hand was increasingly complex from textometry over stylometry to topic modeling, while the required domain knowledge was almost inversely graded from Apollinaire over general style markers to recurrent topics in a small collection of English short stories. A main difference was that the Apollinaire study is a fully fledged case study, while stylometry and semantic text mining each discuss more generically the implications and limitations of their tools.</p>
<p>For all types of studies, however, pre-processing steps, such as tokenization, lemmatization, and part-of-speech tagging emerged as being of high importance. They need to be rigorously gauged and even epistemologically reflected, as for example the analytic relevance of basic unit word and part of speech. It was demonstrated that methodological and analytical experimentation is fruitful beyond the single word level across approaches. However, this is where we enter into the realm of methodological evaluation, testing whether method is tailored to its task. In many fields, this includes the fundamental question whether replication of a study&rsquo;s results is possible. In the present section on  <em>Recapitulation, Replication, Reanalysis, Repetition, or Revivication,</em>  we will discuss an example of how replication can in fact be addressed in a digital humanities setting such as CLS.</p>
<p>In 1973 John B. Smith <sup id="fnref:82"><a href="#fn:82" class="footnote-ref" role="doc-noteref">82</a></sup> published an article on  “Image and Imagery in Joyce&rsquo;s Portrait: A Computer-Assisted Analysis”  with at its heart a visualization of the intensity of verbal images in the text. As Smith points out, commenting on the visualization, the richness of the imagery peaks at the end of Chapter 1, as he expected, at the pandybat episode. <sup id="fnref:83"><a href="#fn:83" class="footnote-ref" role="doc-noteref">83</a></sup><br>




























<figure ><img loading="lazy" alt="Photocopied line chart where the y-axis is “Volume per Unit” and the x-axis is “Word Units”" src="/dhqwords/vol/17/2/000687/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000687/resources/images/figure03_hu487f55f96c9d52afee8700a21031095f_276963_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000687/resources/images/figure03_hu487f55f96c9d52afee8700a21031095f_276963_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000687/resources/images/figure03.png 852w" 
     class="landscape"
     ><figcaption>
        <p>Smith&rsquo;s Visualization
        </p>
    </figcaption>
</figure></p>
<p><em>How did Smith get his visualization (Figure 3) and does it do what he says it does?</em>  We set out to try to replicate this visualization as a way of understanding Smith and early experiments in textual visualization. This is part of a larger project which, like  <em>Hermeneutica</em> , is a hybrid combination of book <sup id="fnref:84"><a href="#fn:84" class="footnote-ref" role="doc-noteref">84</a></sup> and tool (<a href="https://voyant-tools.org">https://voyant-tools.org</a>). Drawing on this research the following section will:</p>
<ul>
<li>Talk about Smith&rsquo;s visualization and how it was brought back to life,</li>
<li>Show some examples of experiments in revivification of techniques, and</li>
<li>Reflect on what the practice might be doing and what we might call it.</li>
</ul>
<p>How did Smith generate the visualization of Joycean imagery? What Smith did, according to the article, was to develop a custom dictionary of some 1,300 terms with emotional valence to track and visualize image intensity or volume through the novel. He divided the text into 500-word chunks, approximately the number of words on a page, as he puts it, and he then counted the number of imagery words from his dictionary in each chunk, weighting some, and graphed the results.<br>




























<figure ><img loading="lazy" alt="Digitally generated line chart" src="/dhqwords/vol/17/2/000687/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000687/resources/images/figure04_hu446e37eda45a63839e32e61db785a43e_93282_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000687/resources/images/figure04_hu446e37eda45a63839e32e61db785a43e_93282_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000687/resources/images/figure04.png 586w" 
     class="landscape"
     ><figcaption>
        <p>Replication of Smith&rsquo;s Visualization
        </p>
    </figcaption>
</figure></p>
<p>When we tried to reproduce his results, Figure 4 is what we got. Not quite the graph that Smith got, but similar. We developed our revivified interpretation of Smith&rsquo;s technique, or Zombie tool, in a Jupyter Python notebook using a version of the text from Gutenberg. The first difficulty we ran into recapitulating Smith was reconstituting his dictionary of words with emotional valence. Fortunately, Smith is still alive and he pointed us to an appendix to his book on Joyce titled  <em>Imagery and the Mind of Stephen Dedalus</em>   <sup id="fnref:85"><a href="#fn:85" class="footnote-ref" role="doc-noteref">85</a></sup> which we OCRed and corrected in order to recreate his method.<br>




























<figure ><img loading="lazy" alt="Alphabetized table lsiting words along with their frequency per chapter" src="/dhqwords/vol/17/2/000687/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000687/resources/images/figure05_hu4ed85a06125a913d1c73397de47495e5_117792_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000687/resources/images/figure05_hu4ed85a06125a913d1c73397de47495e5_117792_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000687/resources/images/figure05.png 798w" 
     class="landscape"
     ><figcaption>
        <p>Part of Table of Imagery Words from [^smith1980]
        </p>
    </figcaption>
</figure></p>
<p>Smith also explained in email correspondence that for his graph he didn&rsquo;t use raw counts per segment but instead weighted each count by the logarithm of the frequency of the word in the entire text – this serves to add more importance to higher frequency terms.</p>
<p>Alas, our updated graph,<sup id="fnref:86"><a href="#fn:86" class="footnote-ref" role="doc-noteref">86</a></sup>  despite having access to the original data beyond the published paper, still doesn&rsquo;t really match the original results, which raises questions about the significance and purpose of such replications. Does it call into question Smith&rsquo;s interpretation of Joyce, or his model, or his method of implementing the model, or is our replication at fault? Did  <em>we</em>  miss something?<br>




























<figure ><img loading="lazy" alt="Screencapture of code notebook with description and code snippet" src="/dhqwords/vol/17/2/000687/resources/images/figure06.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000687/resources/images/figure06_huf2152aaa7e142aaaccd02cabff159757_127687_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000687/resources/images/figure06_huf2152aaa7e142aaaccd02cabff159757_127687_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000687/resources/images/figure06.png 936w" 
     class="landscape"
     ><figcaption>
        <p>The Jupyter Notebook
        </p>
    </figcaption>
</figure></p>
<p>One of the issues that arises when you try bring historical research and associated tools back to life is the question of how accurately to redevelop the tools used in the replication. Does one need to use exactly the same tools as in the original? In this case, should we be working on a mainframe using something close to the analytical environment used by Smith? In Figure 6 you can see a screenshot of the Jupyter Python notebook, which is the environment we decided to use for this revivification. We chose the notebook model as it encourages a programming style where you explain what you are doing in the spirit of replication rather than emulating the original environment. Ironically, that means our code is by definition different from Smith&rsquo;s original because it is implemented in a deliberately reflective literary programming environment.<sup id="fnref:87"><a href="#fn:87" class="footnote-ref" role="doc-noteref">87</a></sup></p>
<p>One might wonder why we wanted to revivify Smith&rsquo;s work? Why bring back work that is largely forgotten in the digital humanities community?</p>
<p>One reason to recover Smith was that he was one of the first to reflect on visualization and computer criticism. Despite being forgotten, his visualization is interesting because it is one of the first text visualizations published not as part of a technical document, but in a paper addressed to literary critics. Smith was a pioneer in visualization and criticism, as a later 1978 paper in the journal  <em>Style</em>  titled  “Computer Criticism”   <sup id="fnref:88"><a href="#fn:88" class="footnote-ref" role="doc-noteref">88</a></sup> showed. As such you could say that our project was one of media archaeology – recovering a mediating technology (visualization of emotional imagery) that has recently seen a revival in various forms, including sentiment analysis.</p>
<p>A second reason was to revisit some of the methods that Smith pioneered and the ideas they bore. The problem with tools is that like all Zombies they don&rsquo;t last that long without human reuse and no one pays them much attention when they are working. Who remembers ARRAS <sup id="fnref:89"><a href="#fn:89" class="footnote-ref" role="doc-noteref">89</a></sup>, arguably one of the most influential early tools in the history of humanities computing?<sup id="fnref:90"><a href="#fn:90" class="footnote-ref" role="doc-noteref">90</a></sup></p>
<blockquote>
<p>Part of the reason instruments have largely escaped the notice of scholars and others interested in our modern techno-scientific culture is language, or rather its lack. Instruments are developed and used in a context where mathematical, scientific, and ordinary language is neither the exclusive vehicle of communication nor, in many cases, the primary vehicle of communication. Instruments are crafted artifacts, and visual and tactile thinking and communication are central to their development and use.<br>
<sup id="fnref:91"><a href="#fn:91" class="footnote-ref" role="doc-noteref">91</a></sup></p>
</blockquote>
<p>Following <sup id="fnref1:91"><a href="#fn:91" class="footnote-ref" role="doc-noteref">91</a></sup> we believe that tools can and do bear knowledge, including theories of interpretation, just as discourses do, but they bear them differently. This raises the question of how one interprets tools if they can bear knowledge. Obviously one approach is to try to use them as they were used at the time, but how does one use a dated tool when you don&rsquo;t have the code or the platform to run it on? In other words,  <em>how does one bring something back to life so one can see how it worked in bearing knowledge?</em></p>
<p>Our answer is: interpretative replications, or what we playfully call zombie tools. The idea is to replicate the interpretative ideas and methods rather than the particular materiality of the tool. The advantage of the notebook style of programming for replications is that they bring the interpretation of the replication to the fore, allowing one to create a type of Frankenstein&rsquo;s monster, a hybrid of explanation and code that mutually preserve knowledge. In other words, a zombie or revenant created through reanimation of the ideas.</p>
<p>What was interesting to us about Smith&rsquo;s work was how he uses text analysis and visualization to model a theory of interpretation drawn from the novel he is interpreting. This allowed him to show how he believes Joyce applied to his own writing the aesthetic theory of artistic imagery presented explicitly by Daedalus, the lead character in Chapter V of the  <em>Portrait</em>   <sup id="fnref:92"><a href="#fn:92" class="footnote-ref" role="doc-noteref">92</a></sup>. In other words, Smith translated his interpretative thesis into a software tool or model that could then be evaluated by a computer. His thesis was an interpretation of a widely discussed aesthetic theory drawn from the novel itself. He applied the tool back onto the novel as a way of evaluating his model and ultimately testing whether Joyce actually followed his own aesthetic theory.</p>
<p>For our purposes, the computational model of Joyce&rsquo;s imagery and whether it translates the hermeneutical thesis is not that important. What we propose is interpretative replication as a way of bringing ideas and techniques back to life and that this could be important to computer criticism and stylistics. To that end we want to make a number of points about all the re-words that we can use: Revivification, Recapitulation, Recapture, Recovery, Replication, Reflection, Reproduction, Relive, Respond, Reinterpretation, Revenant &hellip;</p>
<p>First of all, what this project is not trying to do is scientific replication. As <sup id="fnref:93"><a href="#fn:93" class="footnote-ref" role="doc-noteref">93</a></sup> notes in  <em>The Seven Sexes: A Study in the Sociology of a Phenomenon, or the Replication of Experiments in Physics</em> , there is a lot of enculturation going on in what gets called scientific reproduction. Replication, in Collins&rsquo; account, is not straightforward, as almost no complex experiment can be described in sufficient detail to be replicated precisely without having to make assumptions, as we did in the Smith case. Collins goes further to suggest that what is often needed is the  <em>tacit knowledge</em>  that only shared training, close communication or shared researchers moving between labs can provide. Thus, enculturation is the combination of training and negotiation that leads to experiments being considered for replication in the first place and then ensures that the experiments are replicated in a fashion that extends the field. In short, sociologists of science point out how replication is a practice that in each field is constructed by the field. The question for us in the digital humanities then is how do we want to construct replication?  <em>What culture of replication do we want to develop in the humanities? What traditions can we draw on?</em></p>
<p>One possible tradition is what gets called  “experimental archaeology”   <sup id="fnref:94"><a href="#fn:94" class="footnote-ref" role="doc-noteref">94</a></sup>  <sup id="fnref:95"><a href="#fn:95" class="footnote-ref" role="doc-noteref">95</a></sup>. While this set of practices has its problems, we can learn from the way they are defining the replication in their field. For example, in <sup id="fnref:96"><a href="#fn:96" class="footnote-ref" role="doc-noteref">96</a></sup>&rsquo;s  “Introduction to experimental archaeology”  he talks about some of the types of problems with reproductions that are not sufficiently scientific for what they want to define as truly experimental, in the sense of replicable experiments:<br>
Lack of clear aims  Insufficient detail on materials and methods  Compromises over authentic materials  Inappropriate parameters  Lack of academic context</p>
<p>We assume that generally for (digital) humanities scholars, the ultimate goal of research is not proof, or prediction, but understanding.<sup id="fnref:97"><a href="#fn:97" class="footnote-ref" role="doc-noteref">97</a></sup>  When applied to interpretative replication, our aim is therefore not, for example, to use only authentic materials, but to learn about the potential today of past methods. We agree that aims should be clear, but they do not have to be to prove that Smith was right or wrong, especially given that we do not have all the materials and the exact weights for words. Instead, in interpretative replication and its failures, we learn about ourselves: what we know and do not know. We unpack our assumptions and imagine what we could do rather than learn only about Smith.</p>
<p>An alternative practice that does not aim for scientific credibility is what the artist Judith Buchanan <sup id="fnref:98"><a href="#fn:98" class="footnote-ref" role="doc-noteref">98</a></sup> calls  “revivification” . What she and her performers do is to bring to present life and understanding silent films of Shakespeare plays. She does this through a combination of lecture, commentary and live performance while the film plays. She calls it revivification because what they do is collaborate with the dead performers (of the silent films) to create renewed knowledge. When you attend a performance you find that she lectures, live actors perform certain lines, and the original silent films play out on the screen. This is replication enriched by her interpretation and that of the actors with the goal of understanding the phenomena.</p>
<p>Her theorization is appealing as it acknowledges that any replication is an interpretation of the replicated. We in the humanities are in a collaboration with the dead. We engage with them rather than just stand on their shoulders. The humanities have a different relationship with our histories than the sciences. The hermeneutic circularity of Smith, who draws theory from a novel in order to interpret the novel, is appropriate to the humanities in a way it would not be to most sciences. There is a similar hermeneutic circularity to interpretative replication. It is both about understanding ourselves and the past. It is a thinking-through of the past.</p>
<p>For all these reasons we see replication in the digital humanities as a practice of replying, and re-doing in a larger dialogue, but also re-plying in the sense of folding back onto our past. This is appropriate in the humanities where we eat our past to stay current.</p>
<h2 id="4-domain-specificity-the-example-of-plotting-poetry">4. Domain Specificity. The Example of Plotting Poetry</h2>
<p>In this section, we shift our focus from the perspective of tools, methods and replication towards a systematic area of application, poetry. The choice of that area is arbitrary. However, the situation of poetry is somewhat specific. Versification is intrinsically related to various formal measures, and was a subject of quantitative analyses long before any computational methods were available for counting meters, feet, syllables, rhymes and such. However, readily available tools developed for the computational study of literary texts – though they can sometimes be applied to poetry – are often not a perfect fit for versified texts, due to the intrinsic specificities of the highly regulated material that is verse. As for the poetry-specific devices being produced, their transfer from one text to another is made more difficult by language and time-period differences as well as by individual variations in the use of rules between poets. Furthermore, the general challenge – not restricted to poetry – posed by the utter diversity of hermeneutic goals, is made somewhat more acute by the relatively smaller number of scholars working on poetry.</p>
<p>Because poetry is so fundamentally linked to a number of forms, and because the variation and creativity in the form are so essential to the production of meaning in poems, the use of quantitative methods for the study of poetry is first geared towards versification. Meters, rhymes, caesuras, stresses can all be very aptly studied with the use of computational methods. Progressively, the fastidious manual collection of data is being replaced as much as possible with automatic data collections. Computational tools are being produced to detect or predict metric syllables, rhyming phonemes, etc., but this effort is somewhat disseminated and has yet to produce universally performant and flexibly adaptable tools. Indeed, the rules of versification form a vast and variable series of systems.</p>
<p>The very principles of meter vary from one language to the other, with tonic, syllabic, syllabo-tonic and other systems requiring very different rules to be detected. Furthermore, even within one language area, different eras – and different poets – have produced a range of practices within versification systems. Such systems are often quite strict, and have a high interpretative value, yet remain singular to a language, time period, sub-genre, or to a specific form (the sonnet, for instance, has its own set – or sets – of strict rules). These telling systems being so worthy of a close inspection, and of a systematic one, researchers are actively producing their own tools to automatically collect precise data to quantify verse features. There is, obviously, no obligation to focus solely on genre-specific features of poetic texts, and tools that are useful in analyzing prose texts may be simply transposed to the study of poetry. Yet in doing so, one has two obstacles to overcome: the resistance of the material itself, and the hermeneutic relevance of the endeavor.</p>
<p>There is, obviously, no obligation to focus solely on genre-specific features of poetic texts, and tools that are useful in analyzing prose texts may be simply transposed to the study of poetry. Yet in doing so, one has two obstacles to overcome: the resistance of the material itself, and the hermeneutic relevance of the endeavor.</p>
<p>First, the use of language in poetic texts is particularly prone to anomalies, constrained as it is by both the corset of verse and the effort towards an economy of words and depth of meaning. Poetry often relies on the ambiguity, the polysemy, the shortcomings of language, to produce a richer layering of less obvious meanings. Automatic taggers of any kind struggle with this linguistic prolificity, such as the lack of a clear and linear syntax, higher degree of polysemy, redundancy, or words being used with unexpected or isolated meanings. POS-taggers, for instance, wrestle with the relatively frequent misuse or category change of words in poetry, as well as with the unusual word order, which is unfortunate as POS-categories are very useful to the study of poetry and to the understanding of versification. Similarly, topic modeling and other clustering methods suffer from the lack of linearity of a versified text, where the verse unit as a structural element plays an important role in the construction of meaning, alongside the syntactic units and the physical proximity, with which it may agree or disagree.</p>
<p>Second, stylistic analyses designed for prose might not be as relevant, on their own, once applied to poetry. In focusing on relatively less foregrounded structures, they risk missing the point of a text by failing to address its genre-specific and language-specific form: its versification, its controlled polysemy, the significations of its rhymes, enjambments, choice of meter, degree of obedience to the rule. The latter issue, although not specific to digital humanities, is at the core of how digital humanities and the study of poetry interact, for a focus on versification is bound to produce large amounts of data. Versification descriptions typically include fine information not just about each poem, stanza, rhyme, line, hemistich and syllable group, but also numerous information about each syllable and about its parts. This need for a high granularity has long prompted versification scholars to try and mechanize the handling, if not the collection of such data.</p>
<p>There are, thus, two broad ways to explore poetic corpora with the help of computational methods. One is to focus on features shared with prose, and for this, one can borrow any of the more generic tools of digital literary studies, such as TXM in France (see above), or CATMA (<a href="https://catma.de">https://catma.de</a>). Researchers may use parts of speech distribution, word frequencies, topic modeling, word vectors, even sentiment analysis, to gather data of ever-improving quality, although not necessarily as precise, and thus as meaningful and interpretable as data collected by learned humans. Machine Learning, deep learning, neural networks are also used, producing convincing results in authorship or genre attribution for instance, whilst so far, the black box effect of such endeavors bars the traditional untangling of how poetic devices function. In using these tools, not designed with poetry in mind, one important challenge for the researcher is to make good use of them, to gather enough hermeneutical benefit, to get insight into new or crucial issues, and to avoid banalities.</p>
<p>The other approach, focusing on poetry-specific features, is seldom addressed by readily available tools. The rules of versification are so language-specific that a tool developed for one language might need considerable adaptations to be reused in another. As in other literary genres, it is difficult to predict the many features that poetry scholars might want to model, and stylistic questions geared towards interpretation tend to focus on features so exclusively characteristic that a tool developed by one team to describe one phenomenon, although it may form part of a further exploration taking said phenomenon into account, might not fit the precise needs of another team.</p>
<p>Although the very object&rsquo;s lack of universality is an obstacle to the interoperability of devices, there is a genuine need for tools tailored for poetry and usable for a range of research questions. Such tools are progressively being developed, mostly by researchers trying to address their own needs, in particular for the exploration of versification features <sup id="fnref:99"><a href="#fn:99" class="footnote-ref" role="doc-noteref">99</a></sup>  <sup id="fnref:100"><a href="#fn:100" class="footnote-ref" role="doc-noteref">100</a></sup>  <sup id="fnref:101"><a href="#fn:101" class="footnote-ref" role="doc-noteref">101</a></sup>. Some teams procure fully integrated applications, many share Python packages for all to use, and many more researchers – the group  <em>Plotting Poetry</em>  now has 65 members<sup id="fnref:102"><a href="#fn:102" class="footnote-ref" role="doc-noteref">102</a></sup>  – develop precise methods to fit their own research goals, without having a neat tool to share with the wider community. To mention but a few, Valérie Beaudouin&rsquo;s  <em>Métromètre</em>   <sup id="fnref:103"><a href="#fn:103" class="footnote-ref" role="doc-noteref">103</a></sup>, Eliane Delente and Richard Renault&rsquo;s  <em>Malherbe</em>   <sup id="fnref:104"><a href="#fn:104" class="footnote-ref" role="doc-noteref">104</a></sup> or Benoît Brard and Stéphane Ferrari&rsquo;s work for French <sup id="fnref:105"><a href="#fn:105" class="footnote-ref" role="doc-noteref">105</a></sup>, Klemens Bobenhausen&rsquo;s  <em>Metricalizer</em>  for German <sup id="fnref:106"><a href="#fn:106" class="footnote-ref" role="doc-noteref">106</a></sup>, Daniele Fusi&rsquo;s  <em>Chiron</em>  for Latin and Ancient Greek <sup id="fnref:107"><a href="#fn:107" class="footnote-ref" role="doc-noteref">107</a></sup>, more recently the Postdata project&rsquo;s  <em>Anja</em> ,  <em>Skas</em>  and  <em>Disco</em>  for Spanish <sup id="fnref:108"><a href="#fn:108" class="footnote-ref" role="doc-noteref">108</a></sup>, Arto Anttila and Ryan Heuser <sup id="fnref:109"><a href="#fn:109" class="footnote-ref" role="doc-noteref">109</a></sup> for English and Finnish, Petr Plecháč and Robert Kolár&rsquo;s  <em>versologie</em>  tools <sup id="fnref:110"><a href="#fn:110" class="footnote-ref" role="doc-noteref">110</a></sup>, Igor Pilshchikov and Anatoli Starostinor&rsquo;s <sup id="fnref:111"><a href="#fn:111" class="footnote-ref" role="doc-noteref">111</a></sup> or David Birnbaum and Elise Thorsen&rsquo;s works <sup id="fnref:112"><a href="#fn:112" class="footnote-ref" role="doc-noteref">112</a></sup> for Russian, all automatically analyze various components of verse. Further efforts towards interoperability are made, and one must salute the teams who provide well-thought web ontologies focused on versification phenomena, such as the Postdata project.<sup id="fnref:113"><a href="#fn:113" class="footnote-ref" role="doc-noteref">113</a></sup></p>
<p>Besides the purer automatic detection efforts, where the quest for data is so time and energy consuming that it risks delaying the hermeneutical goals, many computer-aided poetry researchers mix manually collected and automatically collected data, to achieve a compromise, get smaller, high quality datasets, and allow text interpretation based on a mix of distant and close reading, one informing, testing and guiding the other <sup id="fnref:114"><a href="#fn:114" class="footnote-ref" role="doc-noteref">114</a></sup>. And some scholars simply use data management tools, such as Excel or Matlab, to handle data collected manually, typically versification data to explore the stylistic relevance, the poetics of versification routines, or the evolution of practices, sometimes other types of data, for instance to reflect on the diachronic reception of a sub-genre, or on more contingent reader response.</p>
<p>Another aspect of digital poetry studies to be mentioned is the production of various poetry generators, which evolved from relatively simple literary devices such as Raymond Queneau&rsquo;s  <em>Cent mille milliards de poèmes</em>   <sup id="fnref:115"><a href="#fn:115" class="footnote-ref" role="doc-noteref">115</a></sup> to elaborate computer programs such as Pablo Gervas&rsquo; WASP.<sup id="fnref:116"><a href="#fn:116" class="footnote-ref" role="doc-noteref">116</a></sup>  Their development and examination through initiatives such as Thierry Poibeau and Valérie Beaudouin&rsquo;s OUPOCO project <sup id="fnref:117"><a href="#fn:117" class="footnote-ref" role="doc-noteref">117</a></sup>  provides remarkable insights into what constitutes the uniqueness of a poet&rsquo;s voice.</p>
<p>Poetry studies, thus, are still in the process of developing both interoperable tools, and more uniquely tailored methodologies, with a majority of researchers so far piecing together their own methods, mixing a variety of programming, data analysis and visualization techniques with manual data collections, with or without a view to interpretation. In this observation, we wish to stress that the journey towards relevant quantitative stylistics research is not always linear, nor should it be; the devices developed should continually feed a methodological reflection and reuse, and their applications should be tested and renewed, so as to improve hermeneutical benefit. The group Plotting Poetry, founded by Anne-Sophie Bories and now part of the SIG-DLS, gathers scholars of very diverse geographical, linguistic and indeed methodological realms around a yearly conference.<sup id="fnref:118"><a href="#fn:118" class="footnote-ref" role="doc-noteref">118</a></sup>  This platform for the sharing of practices, challenges, and results, is fostering collaborations, and through those, the emergence of well-needed interoperable tools.</p>
<h2 id="5-the-digital-literary-stylistics-tool-inventory-dls-ti">5. The Digital Literary Stylistics-Tool Inventory (DLS-TI)</h2>
<p>The above has shown that CLS is defining itself in many facets, including chief methodological areas such as textometry, stylometry, and semantic text mining, but also in very specific applications, for example to the genre of poetry, and with regard to its own range of types of replication. We have shown that this definition draws to a large extent from the tools and methods applied in concrete research. Systematically assessing the usage of tools is not only a way of taking stock and boosting information, but also to foster replication/re-analysis and comparability. Moreover, and crucially for our analysis, it provides a way to analyze how different tools embody different hermeneutical approaches and address different methodological needs, how one and the same tool can be used by different communities with different goals, how one community may resort to various tools to target different stylistic phenomena.</p>
<p>The idea of gathering information on tool usage from the community is not new, and has been inspired by pre-existing initiatives. An example that seems particularly interesting is the LRE-map.<sup id="fnref:119"><a href="#fn:119" class="footnote-ref" role="doc-noteref">119</a></sup>  Launched at LREC 2010 and soon extended to other conferences, it has been collecting data on the use of Language Resources in submitted papers <sup id="fnref:120"><a href="#fn:120" class="footnote-ref" role="doc-noteref">120</a></sup>. Opposite to traditional catalogues, the LRE-map typically has several entries for the same resource, corresponding to the different papers in which their use is described. Opposite to other catalogues of language resources, where entries are compiled by creators and thus mostly represent their point of view on resource and its intended uses, the LRE map has developed over time to represent rather the user&rsquo;s point of view i.e. the way in which it was applied in actual research. A lexical resource such as WordNet, for instance, is often cited as an ontology in the LRE map, for this is the way it is often applied in NLP today. Also, the diachronic span of the LRE map allows for the detection of trends in the use of resources over time. In part, the success of the LRE-map is due to the decision to work with a very limited set of metadata, and to the bottom-up collection of data in conjunction with large events.</p>
<p>Within the field of DH various notable comparable initiatives can be named. We cite among others the DIRT directory,<sup id="fnref:121"><a href="#fn:121" class="footnote-ref" role="doc-noteref">121</a></sup>  a comprehensive catalogue of digital tools, albeit without links to use cases; the Catalogue of Digital Editions,<sup id="fnref:122"><a href="#fn:122" class="footnote-ref" role="doc-noteref">122</a></sup>  an interesting example of community driven collection of metadata for a particular type of resource; the review of Tools and Environments for Digital Scholarly Editing<sup id="fnref:123"><a href="#fn:123" class="footnote-ref" role="doc-noteref">123</a></sup>  is currently ongoing by the German Institute for Documentology and Scholarly Editing (IDE); the ACDH Tool Gallery, linked to a series of training workshops, as well as the recently launched TAPoR database of tools,<sup id="fnref:124"><a href="#fn:124" class="footnote-ref" role="doc-noteref">124</a></sup>  drawn from the ADHO-proceedings <sup id="fnref:125"><a href="#fn:125" class="footnote-ref" role="doc-noteref">125</a></sup>. <sup id="fnref:126"><a href="#fn:126" class="footnote-ref" role="doc-noteref">126</a></sup></p>
<p>The idea of a Tool Inventory curated by the SIG-DLS (DLS-TI)<sup id="fnref:127"><a href="#fn:127" class="footnote-ref" role="doc-noteref">127</a></sup>  has developed out of such initiatives, as well as from the epistemological reflections outlined in the introduction to this paper, as a first attempt to gather information on tool usage in CLS, in a way that would do justice to all different approaches and perspectives currently existing in the field, and the following paragraphs offer an overview of this. Accordingly, the definition of tool adopted sees them as incarnations of methods. Tools, just like other types of resources such as corpora, lexicons, grammars, etc. are not neutral, but often the reification of theoretical a priori.</p>
<p>From the practical point of view our initiative draws from the aforementioned previous initiatives in that:</p>
<ul>
<li>it is based on bottom up contributions of descriptions by researchers;</li>
<li>it is intended to be use-case-oriented; the idea is not just to collect lists of tools but concrete real-world usage; crucially we aim to collect contributions which do not come from the developers of the tool;</li>
<li>it relies on a simple method of collection and a limited set of descriptors, aimed at identifying the name and type of tool, including with reference to the TaDiRAH ontology, and the type of use in real DH scenarios such as published research, such as papers, books, blog posts, but also projects, or academic courses.</li>
</ul>
<p>One line in the inventory represents a use case contribution. The same tool may thus be entered several times, by different contributors or even by one and the same contributor providing different use cases. As the aim is to review existing practices in the community, the focus is on off the shelf tools which are applied to diverse aims.</p>
<p>We decided to accept a broad but text-analysis oriented definition of tool, defined as any method or technique that provides ways of data manipulation and interpretation, including desktop GUIs, online Virtual Research environment and libraries for R or Python (see above). In the inventory, we also include general-purpose tools such as Excel spreadsheets when they are used for central CLS tasks such as data manipulation, but exclude, for instance, data acquisition libraries such as lxml for Python used to scrape xml. Visualization tools are also taken into account, as this task is a central one for the interpretation of data.</p>
<p>In 2018 the first call was launched to populate the inventory. To date, 35 use cases have been collected. The results are still limited, but some first interesting trends can be already identified, such as the importance of R packages and Python libraries for the community. In turn, this is linked to the fact that many of the tools that have been entered are not specifically designed for literary or stylistic analysis, but are implementations of Natural Language Processing algorithms or statistics measures. On the other hand of the spectrum, a number of entries refer to desktop applications (TXM, WCopyFind, Docuscope, …) which are used for very specific purposes and seem to be more specifically geared towards CLS.</p>
<p>Such preliminary results mirror our intuition about the current practices in the community. On the one hand, there is a tendency towards the development of highly specialized methods based on generic building blocks. On the other hand, there is simultaneously the need for dedicated tools, with a well-identified and -tested set of functions, which address both usability and repeatability needs.</p>
<p>As we hope to gather an increasing number of entries from future campaigns, we believe that the DLS-TI may become an important instrument to monitor the needs of the community, which in turn may benefit those institutions and infrastructures – such as CLARIN<sup id="fnref:128"><a href="#fn:128" class="footnote-ref" role="doc-noteref">128</a></sup>  and DARIAH ERIC and their national consortia - that are currently devoted to creating resources for the DH community. Through its perspective on use cases, it also allows scrutinizing methods epistemologically, in relation to research questions and theoretical frameworks. Relatedly, as a systematic inventory not only of tools, but also of case studies, the DLS-TI can function as a basis for replication and reanalysis - and thus help progress in the field. Finally, initiatives such as the DLS-TI could be beneficial in identifying the needs of the community, and in deciding where best to invest time and money be it in terms of development of user-friendly interfaces, or in the organization of training and events that promote the exchange of best practices.</p>
<h2 id="6-conclusions-the-many-facets-of-tool-criticism">6. Conclusions. The many facets of tool criticism</h2>
<p>This intervention began as a series of anatomies of tools – a playful concept applied to different approaches, which, we hope, documents relevant vantage points within CLS. In addition to the predictable quantitative ones, validity and replicability, we have offered hermeneutic plausibility  <sup id="fnref1:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> and open-ended tinkering as among the ultimate causes or mindsets of computational literary studies. Having said this, validity, reliability, and objectivity of explanatory hypothesis testing do resonate with much of what we believe computational literary studies are and should be about. This apparent conflict in fact appears indicative of not only the diversity of approaches within the emerging field, but also of that of research stages. What seems crucial though, is to maintain an awareness of one&rsquo;s aims and axioms within this rich conversation – which necessarily involves a sense of (computational) method.</p>
<p>Rather than just applying tools prepared by some pioneering expert, CLS scholars have become more interested and knowledgeable about methods and their fit to research questions and data. Future cohorts of scholars may take tested and tried methods for granted, and most of them may concentrate on testing and exploring research questions, rather than on method development (as today is still so much needed in the case of Topic Modeling, for instance). When computational methods have become reliable and transparent vehicles for most, this means that fewer scholars need to concentrate on honing them. A matter of division of tasks is only functional, however, where a critical level of validation and practical experience has been reached and is embedded as continuous practice. As we have shown, humanistic interactions, not only with artefacts and phenomena of the past, but also with historical tools and methods, form an important source of insight.</p>
<p>We may or may not have already entered a phase of the digital transformation of literary studies in which digital methodology may be reintegrated with the field and its various sub-fields. In any case, further maturation is likely to produce a new type of division of labor, where continuous development, calibration and reflection of tools is but one, albeit focal, activity.</p>
<p>Taking the argument of tool defense voiced in the introduction one step further, the instrumentalist dimension of algorithmic data science <sup id="fnref:129"><a href="#fn:129" class="footnote-ref" role="doc-noteref">129</a></sup> is worthy of some positive attention: using an instrument to further sophisticated literary modeling, for example machine learning for predictive modeling, is as warranted as a truth-oriented, or explanatory, type of modeling, whose goal is to develop a mechanistic model of the process that originally produced the observed data and which strives to estimate the parameters of this process. Here, of course, critical enquiry into algorithmic logic is a precondition, possibly at a larger scale than just CLS.</p>
<p>A few other topics: Annotation is a scholarly universal <sup id="fnref:130"><a href="#fn:130" class="footnote-ref" role="doc-noteref">130</a></sup>, and one of the externalizations of modeling in DH practices <sup id="fnref:131"><a href="#fn:131" class="footnote-ref" role="doc-noteref">131</a></sup>. Enrichment of raw texts by annotation <sup id="fnref:132"><a href="#fn:132" class="footnote-ref" role="doc-noteref">132</a></sup> is one of the key practices where scholarly knowledge and theory are made explicit. This includes hermeneutic, progressively altered annotations that depict a rather inductive approach <sup id="fnref:133"><a href="#fn:133" class="footnote-ref" role="doc-noteref">133</a></sup>  <sup id="fnref:134"><a href="#fn:134" class="footnote-ref" role="doc-noteref">134</a></sup> and rule-based annotation systems such as MIPVU <sup id="fnref:135"><a href="#fn:135" class="footnote-ref" role="doc-noteref">135</a></sup>  <sup id="fnref:136"><a href="#fn:136" class="footnote-ref" role="doc-noteref">136</a></sup>, as well as the pertinent issue of inter-coder reliability <sup id="fnref:137"><a href="#fn:137" class="footnote-ref" role="doc-noteref">137</a></sup>.</p>
<p>Another important aspect is modeling through metadata, as highlighted for example in the TXM study. Metadata reside at the interface of data-scientific and philological dimensions of literature studies, as they allow adding multiple variables to the data model. Together with text sampling and markup, metadata constitute the philological object, ideally in an explicitly theory-driven way. In research practice, this also involves important decisions about schemata, but also about missing or incorrect entries.</p>
<p>A crucial dimension of CLS that was addressed in our discussion is source criticism. Building corpora is no trivial task, as they are where the research question, but also general and specific assumptions about literary discourse are modeled both conceptually and as data <sup id="fnref:138"><a href="#fn:138" class="footnote-ref" role="doc-noteref">138</a></sup>  <sup id="fnref:139"><a href="#fn:139" class="footnote-ref" role="doc-noteref">139</a></sup>  <sup id="fnref1:131"><a href="#fn:131" class="footnote-ref" role="doc-noteref">131</a></sup>. We need source criticism and reflection about what it means that literature is represented either digitally or in an analog medium, we need to understand what we sample, and how we sample. We need to be aware of bias, but also know that doing CLS, defining research questions and operationalizations, necessarily involves highlighting some aspects and therefore hiding others, in an interpretation of Popper. On that note, the discussion about hermeneutic vs. algorithmic criticism has become less irreconcilable since attention has shifted to the role of modeling, which has highlighted the logical relation between theory, data, and method <sup id="fnref2:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. The attention to modeling emphasizes the need for scholarly control and critique of all pertinent levels. With <sup id="fnref:140"><a href="#fn:140" class="footnote-ref" role="doc-noteref">140</a></sup>, we think it is a constructive vision of computational literary studies to say that it  “passes on its theories; but it also passes on a critical attitude towards them. The theories are passed on, not as dogmas, but rather with the challenge to discuss them and improve upon them” . This approach at the level of modeling, we think, does not preclude an emphatic way of approaching our objects at certain stages of research.</p>
<p>We have shown how the question of digital methodologies, epistemic practices, and research motives cuts directly to the identity of computational (or digital) literary studies: In fact, CLS&rsquo;s putative emphasis on tools / methodology may actually indicate that digital literary enquiry has not been as fundamentally detached from traditional studies – literary studies, stylistics, cultural studies etc. – as the administrative and institutional perspective may suggest. For ontological and other definitions of digital humanities, see for example <sup id="fnref:141"><a href="#fn:141" class="footnote-ref" role="doc-noteref">141</a></sup> and contributions in <sup id="fnref:142"><a href="#fn:142" class="footnote-ref" role="doc-noteref">142</a></sup>.<sup id="fnref:143"><a href="#fn:143" class="footnote-ref" role="doc-noteref">143</a></sup>  Rather, CLS emerges as one of the incarnations of literary studies, capitalizing on the affordances of the digital – and simultaneously being shaped by them. Admittedly, whether this may allow for eventually more freedom, on a grander scale, depends on the willingness of established Humanities disciplines and gatekeepers to venture for an update. Provided some more time, a fundamental change may just be at our doorstep, with literary data-driven modeling pursued not at the sidelines of the field, but complementing the practices at its center.</p>
<p>In the past few years, the term Computational Literary Studies (CLS) has become more prominent than its alternatives, including Digital Literary Stylistics (DLS). While DLS focuses more on aspects of style (stylometry, corpus stylistics), we decided to use the term CLS in the current paper, except when referring to resources that are explicitly named  “DLS,”  such as the ADHO-Special Interest Group  “Digital Literary Stylistics”  (SIG-DLS), and the DLS tool inventory.</p>
<p>SIG DLS organized a pre-conference workshop at DH2019 in Utrecht on 9 July 2019, see <a href="https://dls.hypotheses.org/activities/anatomy">https://dls.hypotheses.org/activities/anatomy</a></p>
<p>The term tool is heavily underspecified in digital humanities. For example, the glossary of ForText, a popular DH-training resource in the German-speaking context, does not incorporate a lemma for tool  <a href="https://fortext.net/ressourcen/glossar">https://fortext.net/ressourcen/glossar</a> (retrieved 13 October 2022). In the following, in absence of a comprehensive definition to draw from, we provide a largely operational one.</p>
<p>We use the term literary data to include a wide array of data. CLS presently centers mostly on textual data, and our case studies do the same. However, a growing body of CLS research is dedicated to studying multi-modal, especially audio and visual data. For a recent overview see <sup id="fnref:144"><a href="#fn:144" class="footnote-ref" role="doc-noteref">144</a></sup>.</p>
<p>Our predicate operates upon includes for example visualization, analysis, annotation, curation, comparison cf. <sup id="fnref1:130"><a href="#fn:130" class="footnote-ref" role="doc-noteref">130</a></sup>. In his  “Scholarly Primitives”  paper, John Unsworth gives an indirect definition in the table at the bottom of the document in which he transfers the human genome project into a  “human genre project:”    “2.Tools: What protocols and tools for data submission, viewing, analysis, annotation, curation, comparison, and manipulation will you need to make maximal use of the data? What sorts of links among datasets will be useful?” .</p>
<p>Computational methods and resources are change agents in Weizenbaum’s sense: they alter literary scholars’ practices and the modeling of objects and theories. For example, Herrmann (forthcoming) shows how corpora are externalizations of the philological object in practical and theoretical senses, and thus are key arenas of this change. A digital literary corpus is different both from a collection of books and a ‘mere digital database’, because it has a more deliberate modeling function: It is built to construct narratives  <sup id="fnref1:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>.</p>
<p><a href="https://culturalanalytics.org/2019/09/special-forum-on-responses-to-nan-z-da/">https://culturalanalytics.org/2019/09/special-forum-on-responses-to-nan-z-da/</a></p>
<p>Post-hoc analyses of Nan Z. Da’s polemic paper and the ensuing debate have revealed that instead of a methodological paper that it appeared to be at the surface, it rather worked as an disciplinary in- and outgroup profiling.</p>
<p>A good candidate for the most fundamental academic practice is comparison <sup id="fnref:145"><a href="#fn:145" class="footnote-ref" role="doc-noteref">145</a></sup>, which, externalized by computational methods, presently is evolving in new ways (see also the CRC1288  “Practices of Comparing. Ordering and Changing the World”   <a href="https://www.uni-bielefeld.de/sfb/sfb1288/">https://www.uni-bielefeld.de/sfb/sfb1288/</a>).</p>
<p>Reproducibility / replicability is one of the core principles of scientific progress. Direct replication is the  “attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data”   <sup id="fnref:146"><a href="#fn:146" class="footnote-ref" role="doc-noteref">146</a></sup>. The so-called replication crisis has affected many empirical fields such as medicine and psychology. While one way of addressing it has focused on scientific malpractice, for social constructivists in the sense of <sup id="fnref:147"><a href="#fn:147" class="footnote-ref" role="doc-noteref">147</a></sup> the crisis highlights precisely the scholarly practices that are constructed by dynamics of the field.</p>
<p><a href="http://textometrie.ens-lyon.fr/spip.php?rubrique80">http://textometrie.ens-lyon.fr/spip.php?rubrique80</a></p>
<p><a href="http://ancilla.unice.fr/">http://ancilla.unice.fr/ </a></p>
<p>TXM is in constant development and its team is taking constructive feedback to implement and complete its statistical studies.</p>
<p>It is therefore a composition of aborted or simply abandoned former projects that literary specialists often name cycles (the  “Stavelot cycle” , the  “Annie cycle” , see <sup id="fnref1:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>  <sup id="fnref1:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>).</p>
<p>The supposed dates of writing are based on analyses of the manuscripts and the first states of publication of the poems of Apollinaire initiated with great rigor and much erudition by M. Décaudin in 1969 <sup id="fnref2:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>, as well as in his edition of the text for the Bibliothèque de la Pléiade <sup id="fnref:148"><a href="#fn:148" class="footnote-ref" role="doc-noteref">148</a></sup>. It is completed by the analysis of his notebooks and his correspondence kept at the Fonds Jacques Doucet (<a href="http://www.bljd.sorbonne.fr/index.php">http://www.bljd.sorbonne.fr/index.php</a>), which make it possible to give certain texts a quite precise drafting interval.</p>
<p>This section took its start as a short abstract titled  <em>Less than countless. Options to move beyond word counting in stylometry</em>  originally provided by Mike Kestemont for the workshop. The original abstract was substantially extended and revised by Simone Rebora and the co-authors.</p>
<p>One exception, though, might be that of  “mixed methods”   <sup id="fnref1:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>, which combine wordcount with approaches such as keyness analysis to identify the linguistic phenomena that should be investigated more closely. Such methods have also been employed successfully in authorship attribution studies (cf. <sup id="fnref:149"><a href="#fn:149" class="footnote-ref" role="doc-noteref">149</a></sup>) and can be considered as an effort to build a bridge between raw statistics and the hermeneutic and aesthetic dimensions of literary studies. However, it should be noted that they as a rule build upon simple wordcounts (e.g., keyness analysis is generally based on raw word frequencies).</p>
<p><a href="https://pan.webis.de/">https://pan.webis.de/</a></p>
<p><a href="https://pan.webis.de/clef12/pan12-web/author-identification.html">https://pan.webis.de/clef12/pan12-web/author-identification.html</a></p>
<p><a href="https://spacy.io/">https://spacy.io/</a></p>
<p>e.g. <a href="http://mallet.cs.umass.edu/">http://mallet.cs.umass.edu/</a> by <sup id="fnref:150"><a href="#fn:150" class="footnote-ref" role="doc-noteref">150</a></sup>; or <a href="https://dariah-de.github.io/TopicsExplorer/">https://dariah-de.github.io/TopicsExplorer/</a> by <sup id="fnref:151"><a href="#fn:151" class="footnote-ref" role="doc-noteref">151</a></sup>.</p>
<p>This problem extends to other forms of semantic text mining. For sentiment analysis, see <sup id="fnref:152"><a href="#fn:152" class="footnote-ref" role="doc-noteref">152</a></sup>.</p>
<p><sup id="fnref:153"><a href="#fn:153" class="footnote-ref" role="doc-noteref">153</a></sup>  <a href="https://fortext.net/routinen/methoden/topic-modeling">https://fortext.net/routinen/methoden/topic-modeling</a></p>
<p>For example, choosing a higher number of topics can improve classification scores while producing less coherent topics in terms of PMI at the same time (Keli Du, personal communication).</p>
<p>A pandybat is a stiff leather strap with a handle that was used for punishing students in Ireland.</p>
<p>See <a href="https://github.com/sgsinclair/epistemologica/blob/master/Smith-Imagery.ipynb">https://github.com/sgsinclair/epistemologica/blob/master/Smith-Imagery.ipynb</a></p>
<p>As part of the larger project we are developing an alternative to Jupyter called Spyral as in spiral notebook. It is notebook environment that is also an extension of Voyant (<a href="https://voyant-tools.org">https://voyant-tools.org</a>) so you can call Voyant tools within notebooks. It is based on JavaScript rather than Python because that is what a lot of the Voyant interface is developed in. We hope it will give users of Voyant a way to extend their explorations. Spyral is available at <a href="https://voyant-tools.org/spyral/">https://voyant-tools.org/spyral/</a>.</p>
<p>ARRAS was one of the first tools to be designed to be used for interactive exploration of a text rather than in a batch mode. It influenced subsequent tools like TACT and eventually Voyant.</p>
<p>Humanistic understanding may very well encompass phases of hypothesis testing and predictive methods (machine learning algorithms). Eventually, however, these steps serve to enlighten us about the conditions and effects of people’s interaction with culture, meaning, and, generally, life.</p>
<p><a href="https://www.plottingpoetry.org">https://www.plottingpoetry.org</a></p>
<p><a href="https://github.com/linhd-postdata/Network-of-ontologies">https://github.com/linhd-postdata/Network-of-ontologies</a></p>
<p><a href="http://nil.fdi.ucm.es/index.php?q=node/206">http://nil.fdi.ucm.es/index.php?q=node/206</a></p>
<p><a href="http://www.transfers.ens.fr/l-oupoco-l-ouvroir-de-poesie-combinatoire">http://www.transfers.ens.fr/l-oupoco-l-ouvroir-de-poesie-combinatoire</a></p>
<p><a href="https://www.plottingpoetry.org">https://www.plottingpoetry.org</a></p>
<p><a href="http://lremap.elra.info/">http://lremap.elra.info/</a></p>
<p><a href="http://dirtdirectory.org/">http://dirtdirectory.org/</a> (offline at the time of writing, last accessed 2 July 2023)</p>
<p><a href="https://dig-ed-cat.acdh.oeaw.ac.at/">https://dig-ed-cat.acdh.oeaw.ac.at/</a></p>
<p><a href="https://www.i-d-e.de/cfr-tools/">https://www.i-d-e.de/cfr-tools/</a></p>
<p><a href="http://tapor.ca/home">http://tapor.ca/home</a></p>
<p><a href="https://www.oeaw.ac.at/acdh/events/event-series/acdh-tool-gallery-52/">https://www.oeaw.ac.at/acdh/events/event-series/acdh-tool-gallery-52/</a></p>
<p><a href="https://dls.hypotheses.org/774">https://dls.hypotheses.org/774</a></p>
<p>The DLS-TI could also be a useful addition to the CLARIN Resource Families initiative, see <a href="https://www.clarin.eu/resource-families">https://www.clarin.eu/resource-families</a></p>
<p>See also initiatives such as OpenMethods, which curate  “descriptions of methods and tools, tool and methods critique, as well as practical and theoretical reflections about how and why humanities research is conducted digital and how the increasing influence of digital methods and tools changes scholarly attitudes and scientific practices of humanities research”   <a href="https://openmethods.dariah.eu/">https://openmethods.dariah.eu/</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:2">
<p>Erlin, M., Piper, A. Knox, D., Pentecost, S., Drouillard, M., Powell, B. and Townson, C.  “Cultural Capitals: Modeling Minor European Literature” .  <em>Journal of Cultural Analytics</em>  6 (1). <a href="https://doi.org/10.22148/001c.21182">https://doi.org/10.22148/001c.21182</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Underwood, T.  <em>Distant Horizons: Digital Evidence and Literary Change</em> , First edition., University of Chicago Press, Chicago (2019).&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:5">
<p>Traub, M.C. and van Ossenbruggen, J.  <em>Workshop on Tool Criticism in the Digital Humanities - Report</em> , CWI Techreport, Amsterdam (2015).&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:7">
&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:8">
&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:9">
<p>Weizenbaum, J.  <em>Computer Power and Human Reason: From Judgment to Calculation</em> . Penguin, Harmondsworth. (1984).&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:11">
<p>van Es, K., Wieringa, M. and Schäfer, M.T.  “Tool Criticism: From Digital Methods to Digital Methodology” .  <em>Proceedings of the 2nd International Conference on Web Studies</em> . ACM, New York, NY, USA (2018), pp. 24–27. doi: <a href="http://doi.acm.org/10.1145/3240431.3240436">http://doi.acm.org/10.1145/3240431.3240436</a>&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Koolen, J., van Gorp, M. and van Ossenbruggen, J.  “Lessons Learned from a Digital Tool Criticism Workshop” .  <em>Proceedings from DH Benelux 2018</em> . Amsterdam, The Netherlands (2018).&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Flanders, J. and Jannidis, F.  <em>The Shape of Data in Digital Humanities: Modeling Texts and Text-Based Resources</em> , Routledge, Taylor and Francis Group, London; New York (2019).&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>McCarthy, W.  <em>Humanities Computing</em> , Palgrave Macmillan UK (2005).&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Winko, S.  “Zur Plausibilität als Beurteilungskriterium literaturwissenschaftlicher Interpretationen” .  <em>Theorien, Methoden und Praktiken des Interpretierens</em> . De Gruyter, Berlin, Boston (2015), pp. 483–511. doi: <a href="https://doi.org/10.1515/9783110353983.483">https://doi.org/10.1515/9783110353983.483</a>&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Piper, A.  “Think Small: On Literary Modeling” .  <em>PMLA</em>  132(3):651–658. doi: <a href="https://doi.org/10.1632/pmla.2017.132.3.651">https://doi.org/10.1632/pmla.2017.132.3.651</a>&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Piper, A.  <em>Enumerations</em> , The University of Chicago Press, Chicago (2018).&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Herrmann, J.B.  “In a Test Bed with Kafka. Introducing a Mixed-Method Approach to Digital Stylistics” .  <em>Digital Humanities Quarterly</em>  011(4).&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Noble, S.U.  <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em> , New York University Press, New York University.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>O’Neil, C.  <em>Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</em> , 1 edition., Crown, New York (2016).&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Hayles, N. K.  <em>How We Think: Digital Media and Contemporary Technogenesis</em> . University of Chicago Press, Chicago (2012).&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Da, N.Z.  “The Computational Case against Computational Literary Studies” .  <em>Critical Inquiry</em>  45(3):601–639. doi: <a href="https://doi.org/10.1086/702594">https://doi.org/10.1086/702594</a>&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:24">
&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:25">
&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:26">
&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:27">
<p>Guiraud, P.  <em>Index Des Mots d’Alcools de G. Apollinaire (Index Du Vocabulaire Du Symbolisme. 1)</em> , Klincksieck, Paris (1953).&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Lafon, P. and Muller, C.  <em>Dépouillements et Statistiques En Lexicométrie, Travaux de linguistique quantitative</em> , Slatkine/Champion, Genève/Paris (1984).&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:30">
<p>Heiden, S., Magué, J.-P. and Pincemin, B.  “TXM : Une plateforme logicielle open-source pour la textométrie - conception et développement” .  <em>JADT</em>  2010. (2010), pp. 1021–1032.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Pincemin, B.  “Analyse Stylistique Différentielle à Base de Marqueurs et Textométrie” . In: Garric, N. and Maurel-Indart, H. (eds.).  <em>Vers Une Automatisation de l’analyse Textuelle. texto ! Textes and Cultures</em> , Volume XV - n°4 et XVI - n°1 (2011), pp. 54–61.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:33">
&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:34">
<p>Debon, C.  <em>‘Calligrammes’  Dans Tous Ses États - Édition Critique Du Recueil de Guillaume APOLLINAIRE</em> , éditions Calliopées, Paris (2008).&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Décaudin, M.  <em>Le Dossier d’alcools</em> , Droz, Paris (1969).&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Follet, L.  “Apollinaire Entre Vers et Prose, de  “L’Obituaire”  à la  “Maison des Morts” ” ,  <em>Semen</em>  3, février 1987. doi: <a href="http://semen.revues.org/5523">http://semen.revues.org/5523</a>&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Jacquot, C.  “Le Poulpe, une Figure de la  Plasticité  d’Apollinaire?” ,  <em>Apollinaire</em>  11 (2012), pp. 35–43.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Moore, C.  <em>Apollinaire en 1908, la Poétique de l&rsquo;Enchantement: Une Lecture d&rsquo;Onirocritique</em> , Paris, Minard (1995).&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Herschberg-Pierrot, A.  “Style, Corpus et Genèse” .  <em>Corpus</em>  5.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Jenny, L.  <em>Le Style En Acte. Vers Une Pragmatique Du Style</em> , MētisPresses, Genève (2011).&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:42">
<p>Apollinaire, G.  <em>Lettres à Madeleine. Tendre Comme Le Souvenir</em> , Gallimard, Paris, France (2005).&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Jacquot, C.  “Corpus Poétique et Métadonnées: la Problématique de la Datation dans les Poèmes de Guillaume Apollinaire” .  <em>Modèles et Nombres En Poésie</em> . Champion, Paris (2017), pp. 81–103.&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:45">
<p>Lafon, P.  “Sur la Variabilité de la Fréquence des Formes dans un Corpus” .  <em>Mots. Les Langages du Politique</em>  1(1): 127–165. doi: <a href="https://doi.org/10.3406/mots.1980.1008">https://doi.org/10.3406/mots.1980.1008</a>&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>Eder, M., Rybicki, J. and Kestemont, M.  “Stylometry with R: A Package for Computational Text Analysis” .  <em>The R Journal</em>  8(1):107–121.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Evert, S., Proisl, T., Jannidis, F., Reger, I., Pielström, S., Schöch, C. and Vitt, T.  “Understanding and Explaining Delta Measures for Authorship Attribution” .  <em>Digital Scholarship in the Humanities</em>  32(suppl_2):ii4–ii16. doi: <a href="https://doi.org/10.1093/llc/fqx023">https://doi.org/10.1093/llc/fqx023</a>&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Eder, M.  “Visualization in Stylometry: Cluster Analysis Using Networks” .  <em>Digital Scholarship in the Humanities</em>  32(1):50–64. doi: <a href="https://doi.org/10.1093/llc/fqv061">https://doi.org/10.1093/llc/fqv061</a>&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Burrows, J.  “ Delta:  a Measure of Stylistic Difference and a Guide to Likely Authorship” .  <em>Literary and Linguistic Computing</em>  17(3):267–287. doi: <a href="https://doi.org/10.1093/llc/17.3.267">https://doi.org/10.1093/llc/17.3.267</a>&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:51">
<p>Bal, M.  <em>Narratology: Introduction to the Theory of Narrative</em> , Fourth Edition., University of Toronto Press, Toronto Buffalo London (2017).&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Genette, G.  <em>Figures III</em> , Éditions du Seuil, Paris (1972).&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Miall, D.S.  “Reader-Response Theory” .  <em>A Companion to Literary Theory</em> . John Wiley and Sons, Ltd (2018), pp. 114–125. doi: <a href="https://doi.org/10.1002/9781118958933.ch9">https://doi.org/10.1002/9781118958933.ch9</a>&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:55">
<p>Hirst, G. and Feiguina, O.  “Bigrams of Syntactic Labels for Authorship Discrimination of Short Texts” .  <em>Literary and Linguistic Computing</em>  22(4):405–417. doi: <a href="https://doi.org/10.1093/llc/fqm023">https://doi.org/10.1093/llc/fqm023</a>&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Eder, M.  “Does Size Matter? Authorship Attribution, Small Samples, Big Problem” .  <em>Literary and Linguistic Computing</em>  30(2):167–182. doi: <a href="https://doi.org/10.1093/llc/fqt066">https://doi.org/10.1093/llc/fqt066</a>&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>van Cranenburgh, A.  “Literary Authorship Attribution With Phrase-Structure Fragments” .  <em>Proceedings of the NAACL-HLT 2012 Workshop on Computational Linguistics for Literature</em> . Association for Computational Linguistics, Montréal, Canada (2012), pp. 59–63.&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>Frontini, F., Boukhaled, M.-A. and Ganascia, J.-G.  “Mining for Characterising Patterns in Literature Using Correspondence Analysis: an Experiment on French Novels” .  <em>Digital Humanities Quarterly</em>  11(2).&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:60">
<p>Gius, E., Reiter, N. and Willand, M.  “Foreword to the Special Issue  “A Shared Task for the Digital Humanities: Annotating Narrative Levels” ” .  <em>Journal of Cultural Analytics</em> . doi: <a href="https://doi.org/10.22148/16.047">https://doi.org/10.22148/16.047</a>&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Stamatatos, E., Daelemans, W., Verhoeven, B., Potthast, M., Stein, B., Juola, P., Sanchez-Perez, M.A. and Barrón-Cedeño, A.  “Overview of the Author Identification Task at PAN 2014” .  <em>Working Notes Papers of the CLEF 2014 Evaluation Labs. CEUR Workshop Proceedings</em> , 877-897 (2014).&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:63">
<p>Kestemont, M., Tschuggnall, M., Stamatatos, E., Daelemans, W., Specht, G., Stein, B. and Potthast, M.  “Overview of the Author Identification Task at PAN-2018: Cross-Domain Authorship Attribution and Style Change Detection” .  <em>Working Notes Papers of the CLEF 2018 Evaluation Labs. CEUR Workshop Proceedings</em>  (2018), pp. 1–25.&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p>Bubenhofer, N. and Dreesen, P.  “Linguistik als antifragile Disziplin? Optionen in der digitalen Transformation” .  <em>Digital Classics Online</em> , pp. 63–75. doi: <a href="https://doi.org/10.11588/dco.2017.0.48493">https://doi.org/10.11588/dco.2017.0.48493</a>&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:65">
&#160;<a href="#fnref:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:66">
<p>Bacciu, A., La Morgia, M., Mei, A., Nerio Nemmi, E., Neri, V. and Stefa, J.  “Cross-domain Authorship Attribution Combining Instance Based and Profile Based Features” . In: Cappellato, L., Ferro, N., Losada, D. E. and Müller, H. (eds.).  <em>CLEF 2019 Labs and Workshops, Notebook Paper</em> . (2019).&#160;<a href="#fnref:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:67">
<p>Daelemans, W., Kestemont, M., Manjavacas, E., Potthast, M., Rangel, F., Rosso, P., Specht, G., Stamatatos, E., Stein, B., Tschuggnall, M., Wiegmann, M. and Zangerle, E.  “Overview of PAN 2019: Bots and Gender Profiling, Celebrity Profiling, Cross-Domain Authorship Attribution and Style Change Detection” . In: Crestani, F., Braschler, M., Savoy, J., Rauber, A., Müller, H., Losada, D. E., Heinatz Bürki, G., Cappellato, L. and Ferro, N. (eds.).  <em>Experimental IR Meets Multilinguality, Multimodality, and Interaction</em> . Springer International Publishing, Cham (2019), pp. 402–416.&#160;<a href="#fnref:67" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:68">
<p>Blei, D.M.  “Probabilistic Topic Models” .  <em>Communication of the ACM</em>  55(4):77–84. doi: <a href="https://doi.org/10.1145/2133806.2133826">https://doi.org/10.1145/2133806.2133826</a>&#160;<a href="#fnref:68" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:69">
<p>Steyvers, M. and Griffiths, T.  “Probabilistic Topic Models” .  <em>Latent Semantic Analysis: A Road to Meaning</em> . Laurence Erlbaum (2007), pp. 424–440.&#160;<a href="#fnref:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:70">
<p>Binder, J.M. and Jennings, C.  “Visibility and meaning in topic models and 18th-century subject indexes” .  <em>Literary and Linguistic Computing</em>  29(3):405–411. doi: <a href="https://doi.org/10.1093/llc/fqu017">https://doi.org/10.1093/llc/fqu017</a>&#160;<a href="#fnref:70" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:71">
<p>Mitrofanova, O.  “Probabilistic Topic Modeling of the Russian Text Corpus on Musicology” . In: Eismont, P. and Konstantinova, N. (eds.).  <em>Language, Music, and Computing</em> . Springer International Publishing, Cham (2015), pp. 69–76.&#160;<a href="#fnref:71" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:72">
<p>Schöch, C.  “Topic Modeling Genre: An Exploration of French Classical and Enlightenment Drama” .  <em>Digital Humanities Quarterly</em>  11(2).&#160;<a href="#fnref:72" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:72" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:73">
<p>Pavlova, I. and Fischer, F.  “Topic Modeling 200 Years of Russian Drama” .  <em>Proceedings of the EADH Conference</em>  (2018).&#160;<a href="#fnref:73" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:74">
<p>Henny, U., Betz, K., Schlör, D. and Hotho, A.  “Alternative Gattungstheorien. Das Prototypenmodell am Beispiel hispanoamerikanischer Romane” .  <em>Proceedings of the DHd 2018 Conference</em> . Cologne (2018).&#160;<a href="#fnref:74" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:75">
&#160;<a href="#fnref:75" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:76">
<p>Du, K.  “A Survey On LDA Topic Modeling In Digital Humanities” .  <em>Proceedings of the 2019 Digital Humanities Conference</em> . Utrecht (2019).&#160;<a href="#fnref:76" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:77">
&#160;<a href="#fnref:77" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:78">
&#160;<a href="#fnref:78" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:79">
<p>Bhatia, S., Lau, J.H. and Baldwin, T.  “Topic Intrusion for Automatic Topic Model Evaluation” .  <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em> . Association for Computational Linguistics, Brussels, Belgium (2018), pp. 844–849.&#160;<a href="#fnref:79" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:80">
<p>Lau, J.H. and Baldwin, T.  “The Sensitivity of Topic Coherence Evaluation to Topic Cardinality” .  <em>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em> . Association for Computational Linguistics, San Diego, California (2016), pp. 483–487.&#160;<a href="#fnref:80" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:81">
&#160;<a href="#fnref:81" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:82">
<p>Smith, J.B.  “Image and Imagery in Joyce’s Portrait: A Computer-Assisted Analysis” .  <em>Directions in Literary Criticism: Contemporary Approaches to Literature</em> . The Pennsylvania State University Press, University Park, PA (1973), pp. 220–227.&#160;<a href="#fnref:82" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:83">
&#160;<a href="#fnref:83" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:84">
<p>Rockwell, G. and Sinclair, S.  <em>Hermeneutica: Computer-Assisted Interpretation in the Humanities</em> , MIT Press (2016).&#160;<a href="#fnref:84" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:85">
<p>Smith, J.B.  _Imagery and the Mind of Stephen Dedalus: A Computer-Assisted Study of Joyce’s  <em>A Portrait of the Artist as a Young Man</em> _ , Bucknell University Press, Lewisburg, PA (1980).&#160;<a href="#fnref:85" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:86">
&#160;<a href="#fnref:86" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:87">
&#160;<a href="#fnref:87" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:88">
<p>Smith, J.B.  “Computer Criticism” .  <em>Style</em>  XII(4):326–356.&#160;<a href="#fnref:88" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:89">
<p>Smith, J.B.  “A New Environment For Literary Analysis” .  <em>Perspectives in Computing</em>  4(2/3):20–31.&#160;<a href="#fnref:89" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:90">
&#160;<a href="#fnref:90" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:91">
<p>Baird, D.  <em>Thing Knowledge: A Philosophy of Scientific Instruments</em> , University of California Press, Berkeley (2004).&#160;<a href="#fnref:91" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:91" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:92">
<p>Joyce, J. <em>A Portrait of the Artist as a Young Man, Text, Criticism, and Notes</em> . Edited by Chester G. Anderson. The Viking Press, New York (1968).&#160;<a href="#fnref:92" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:93">
<p>Collins, H.M.  “The Seven Sexes: A Study in the Sociology of a Phenomenon, or the Replication of Experiments in Physics” .  <em>Sociology</em>  9(2):205–224. <a href="https://doi.org/10.1177/003803857500900202">https://doi.org/10.1177/003803857500900202</a>&#160;<a href="#fnref:93" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:94">
<p>Ascher, R.  “Experimental Archeology” .  <em>American Anthropologist</em>  63(4):793–816. doi: <a href="https://doi.org/10.1525/aa.1961.63.4.02a00070">https://doi.org/10.1525/aa.1961.63.4.02a00070</a>&#160;<a href="#fnref:94" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:95">
<p>Millson, D. (ed)  <em>Experimentation and Interpretation: The Use of Experimental Archaeology in the Study of the Past</em> . Oxbow Books (2010).&#160;<a href="#fnref:95" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:96">
<p>Outram, A.K.  “Introduction to Experimental Archaeology” .  <em>World Archaeology</em>  40(1):1–6. doi: <a href="https://doi.org/10.1080/00438240801889456">https://doi.org/10.1080/00438240801889456</a>&#160;<a href="#fnref:96" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:97">
&#160;<a href="#fnref:97" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:98">
<p>Buchanan, J.  “Collaborating With the Dead: Revivifying Frank Benson’s Richard III” . Booklet published by Silents Now.&#160;<a href="#fnref:98" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:99">
<p>Bories, A.-S., Purnelle, G. and Marchal, H.  <em>Plotting Poetry: On Mechanically-Enhanced Reading</em> , Presses Universitaires de Liège, Liège (2021).&#160;<a href="#fnref:99" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:100">
<p>Plecháč, P., Kolár, R., Bories, A.-S. and Říha, J.  “Tackling the Toolkit. Plotting Poetry through Computational Literary Studies” , Prague: ICL CAS. <a href="https://doi.org/10.51305/ICL.CZ.9788076580336">https://doi.org/10.51305/ICL.CZ.9788076580336</a>&#160;<a href="#fnref:100" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:101">
<p>Bories, A.-S., Plecháč, P. and Ruiz Fabo, P.  <em>Computational Stylistics in Poetry, Prose, and Drama</em> , De Gruyter (2023).&#160;<a href="#fnref:101" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:102">
&#160;<a href="#fnref:102" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:103">
<p>Beaudouin, V.  <em>Mètre et Rythme Du Vers Classique</em> . Corneille et Racine, Honoré Champion, Paris (2002).&#160;<a href="#fnref:103" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:104">
<p>Delente, É. and Renault, R.  “Projet Anamètre : Le Calcul du Mètre des Vers Complexes” .  <em>Langages</em>  199(3):125–148. <a href="https://doi.org/doi:10.3917/lang.199.0125">https://doi.org/doi:10.3917/lang.199.0125</a>&#160;<a href="#fnref:104" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:105">
<p>Brard, B. and Ferrari, S.  “Des Vers et des Mesures : Détection des Noyaux Vocaliques” .  <em>Langages</em>  199(3):107–124. doi: <a href="https://doi.org/doi:10.3917/lang.199.0107">https://doi.org/doi:10.3917/lang.199.0107</a>&#160;<a href="#fnref:105" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:106">
<p>Bobenhausen, K. and Hammerich, B.  “Métrique littéraire, métrique linguistique et métrique algorithmique de l’allemand mises en jeu dans le programme Metricalizer” .  <em>Langages</em>  199(3):67–88. doi: <a href="https://doi.org/doi:10.3917/lang.199.0067">https://doi.org/doi:10.3917/lang.199.0067</a>&#160;<a href="#fnref:106" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:107">
<p>Fusi, D.  “A Multilanguage, Modular Framework for Metrical Analysis: It Patterns and Theorical Issues” .  <em>Langages</em>  199(3):41–66. doi: <a href="https://doi.org/doi:10.3917/lang.199.0041">https://doi.org/doi:10.3917/lang.199.0041</a>&#160;<a href="#fnref:107" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:108">
<p>Martínez Cantón, C.I., Ruiz Fabo, P., González-Blanco García, E. and Poibeau, T.  “Automatic enjambment detection as a new source of evidence in Spanish versification” .  <em>Plotting Poetry : On Mechanically-Enhanced Reading / Machiner La Poésie: Sur Les Lectures Appareillées</em> . Basel (2017).&#160;<a href="#fnref:108" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:109">
<p>Anttila, A. and Heuser, R.  “Phonological and Metrical Variation across Genres” .  <em>Proceedings of the Annual Meetings on Phonology. Linguistic Society of America</em> , Washington, DC (2016).&#160;<a href="#fnref:109" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:110">
<p>Plecháč, P. and Kolár, R. K <em>apitoly z Korpusové Versologie</em> , Akropolis, Prague (2017).&#160;<a href="#fnref:110" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:111">
<p>Pilshchikov, I. and Starostin, A.  “Reconnaissance Automatique des Mètres des Vers Russes : Une Approche Statistique sur Corpus” .  <em>Langages</em>  199(3):89–106. doi: <a href="https://doi.org/10.3917/lang.199.0089">https://doi.org/10.3917/lang.199.0089</a>&#160;<a href="#fnref:111" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:112">
<p>Birnbaum, D.J. and Thorsen, E.  “Markup and meter: Using XML tools to teach a computer to think about versification” .  <em>Proceedings of Balisage: The Markup Conference</em> . (2015). <a href="doi:10.4242/BalisageVol15.Birnbaum01">doi:10.4242/BalisageVol15.Birnbaum01</a>&#160;<a href="#fnref:112" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:113">
&#160;<a href="#fnref:113" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:114">
<p>Bories, A.-S. Des Chiffres et Des Mètres.  <em>La Versification de Raymond Queneau</em> . Honoré Champion, Paris, France (2020).&#160;<a href="#fnref:114" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:115">
<p>Queneau, R.  <em>Petite Cosmogonie Portative</em> , Gallimard, Paris (1961).&#160;<a href="#fnref:115" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:116">
&#160;<a href="#fnref:116" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:117">
&#160;<a href="#fnref:117" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:118">
&#160;<a href="#fnref:118" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:119">
&#160;<a href="#fnref:119" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:120">
<p>Calzolari, N., Del Gratta, R., Francopoulo, G., Mariani, J., Rubino, F., Russo, I. and Soria, C.  “The LRE Map. Harmonising Community Descriptions of Resources” .  <em>Proceedings of LREC 2012, Eighth International Conference on Language Resources and Evaluation</em> . Istanbul, Turkey (2012), pp. 1084–1089.&#160;<a href="#fnref:120" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:121">
&#160;<a href="#fnref:121" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:122">
&#160;<a href="#fnref:122" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:123">
&#160;<a href="#fnref:123" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:124">
&#160;<a href="#fnref:124" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:125">
<p>Barbot, L., Fischer, F., Moranville Y. and Pozdniakov, I.:  “Which DH Tools Are Actually Used in Research?”  In:  <em>weltliteratur.net</em> , 6 Dec 2019. URL: <a href="https://weltliteratur.net/dh-tools-used-in-research/">https://weltliteratur.net/dh-tools-used-in-research/</a>&#160;<a href="#fnref:125" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:126">
&#160;<a href="#fnref:126" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:127">
&#160;<a href="#fnref:127" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:128">
&#160;<a href="#fnref:128" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:129">
<p>Jones, M. L.,  “How We Became Instrumentalists (Again)” .  <em>Historical Studies in the Natural Sciences</em> , 48(5): 673-684. doi: <a href="https://doi.org/10.1525/hsns.2018.48.5.673">https://doi.org/10.1525/hsns.2018.48.5.673</a>&#160;<a href="#fnref:129" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:130">
<p>Unsworth, J.  “Scholarly Primitives: What Methods do Humanities Researchers Have in Common, and How Might our Tools Reflect This” .  <em>Symposium on Humanities Computing: Formal Methods, Experimental Practice</em> . King’s College, London. (2000).&#160;<a href="#fnref:130" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:130" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:131">
<p>Herrmann, J.B.  <em>Externalizations. Data-Driven Literary Studies</em> .&#160;<a href="#fnref:131" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:131" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:132">
<p>Rapp, A.  “Manuelle und automatische Annotation” . In: Jannidis, F., Kohle, H., Rehbein, M. (eds.)  <em>Digital Humanities</em> . J.B. Metzler (2017) <a href="https://doi.org/10.1007/978-3-476-05446-3_18">https://doi.org/10.1007/978-3-476-05446-3_18</a>&#160;<a href="#fnref:132" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:133">
<p>Gius, E. and Jacke, J.  “The Hermeneutic Profit of Annotation: On Preventing and Fostering Disagreement in Literary Analysis” .  <em>International Journal of Humanities and Arts Computing</em>  11(2):233–254. doi: <a href="https://doi.org/10.3366/ijhac.2017.0194">https://doi.org/10.3366/ijhac.2017.0194</a>&#160;<a href="#fnref:133" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:134">
<p>Percillier, M.  “Creating and Analyzing Literary Corpora” .  <em>Data Analytics in Digital Humanities</em> . Springer, Cham (2017), pp. 91–118.&#160;<a href="#fnref:134" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:135">
<p>Herrmann, J.B., Woll, K. and Dorst, A.G.  “Linguistic Metaphor Identification in German” .  <em>MIPVU in Multiple Languages</em> . John Benjamins, Amsterdam / Philadelphia (2019).&#160;<a href="#fnref:135" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:136">
<p>Steen, G.J., Dorst, A.G., Herrmann, J.B., Kaal, A.A., Tina, Krennmayr. and Pasma, T.  <em>A Method for Linguistic Metaphor Identification: From MIP to MIPVU</em> , John Benjamins, Amsterdam and Philadelphia (2010).&#160;<a href="#fnref:136" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:137">
<p>Kuhn, J.  “Computational Text Analysis Within the Humanities: How to Combine Working Practices from the Contributing Fields?” .  <em>Language Resources and Evaluation</em>  53(4): 565–602. doi: <a href="https://doi.org/10.1007/s10579-019-09459-3">https://doi.org/10.1007/s10579-019-09459-3</a>&#160;<a href="#fnref:137" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:138">
<p>Bode, K.  <em>A World of Fiction: Digital Collections and the Future of Literary History</em> , University of Michigan Press., (2018).&#160;<a href="#fnref:138" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:139">
<p>Herrmann, J.B. and Lauer, G.  “Korpusliteraturwissenschaft. Zur Konzeption und Praxis am Beispiel eines Korpus zur literarischen Moderne” .  <em>Osnabrücker Beiträge zur Sprachtheorie (OBST)</em>  92:127–156.&#160;<a href="#fnref:139" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:140">
<p>Popper, K.R.  <em>Conjectures and Refutations: The Growth of Scientific Knowledge</em> , 3rd ed. revised., Routledge and Kegan Paul, London (2002).&#160;<a href="#fnref:140" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:141">
<p>Svensson, P.  “Sorting Out the Digital Humanities” .  <em>A New Companion to Digital Humanities</em> . John Wiley and Sons, Ltd (2015), pp. 476–492. doi: <a href="https://doi.org/10.1002/9781118680605.ch33">https://doi.org/10.1002/9781118680605.ch33</a>&#160;<a href="#fnref:141" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:142">
<p>Terras, M., Vanhoutte, E. and Nyhan, J.  <em>Defining Digital Humanities: A Reader</em> , Routledge, London/New York (2013).&#160;<a href="#fnref:142" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:143">
&#160;<a href="#fnref:143" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:144">
<p>Herrmann, J.B., Jacobs, A. and Piper, A.  “Computational Stylistics” . In D. Kuiken and A. Jacobs (Eds.),  <em>Handbook of Empirical Literary Studies</em> , pp. 451-486. Berlin: De Gruyter.&#160;<a href="#fnref:144" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:145">
<p>Descartes, R.  <em>Règles pour la Direction de l’Esprit</em>  (3rd Ed.; J. Sirven, Ed.). Brin, Paris (1959).&#160;<a href="#fnref:145" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:146">
<p>Open Science Collaboration. (2015).  “Estimating the reproducibility of psychological science” .  <em>Science</em> , 349(6251), aac4716–aac4716. doi: <a href="https://doi.org/10.1126/science.aac4716">https://doi.org/10.1126/science.aac4716</a>&#160;<a href="#fnref:146" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:147">
<p>Berger, P. and Luckmann, T.  <em>The Social Construction of Reality: A Treatise in the Sociology of Knowledge</em> , Doubleday, Garden City, NY (1967).&#160;<a href="#fnref:147" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:148">
<p>Apollinaire, G.  <em>Œuvres Poétiques</em> , M. Adéma et M. Décaudin eds., Bibliothèque de la Pléiade, Gallimard, Paris, France (1994).&#160;<a href="#fnref:148" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:149">
<p>Rebora, S., Herrmann, J.B., Lauer, G. and Salgaro, M.  “Robert Musil, a war journal, and stylometry: Tackling the issue of short texts in authorship attribution” .  <em>Digital Scholarship in the Humanities</em>  34(3):582–605. doi: <a href="https://doi.org/10.1093/llc/fqy055">https://doi.org/10.1093/llc/fqy055</a>&#160;<a href="#fnref:149" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:150">
<p>McCallum, A.K.  <em>MALLET : A Machine Learning for Language Toolkit</em> , (2002). <a href="http://mallet.cs.umass.edu">http://mallet.cs.umass.edu</a>&#160;<a href="#fnref:150" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:151">
<p>Simmler, S., Vitt, T. and Pielström, S.  “Topic Modeling with Interactive Visualizations in a GUI Tool” .  <em>Proceedings of the 2019 Digital Humanities Conference</em> . Utrecht (2019).&#160;<a href="#fnref:151" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:152">
<p>Kiefer, K.  “Tool Criticism on emotional text analysis” .  <em>Proceedings of the EADH Conference</em> . (2018).&#160;<a href="#fnref:152" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:153">
<p>Horstmann, J.  “Topic Modeling”  In:  <em>forTEXT. Literatur digital erforschen</em> . Available at: <a href="https://fortext.net/routinen/methoden/topic-modeling">https://fortext.net/routinen/methoden/topic-modeling</a>[Accessed: 3 December 2019].&#160;<a href="#fnref:153" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Unpacking tool criticism as practice, in practice</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000692/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000685/?utm_source=atom_feed" rel="related" type="text/html" title="The Explainability Turn"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000692/</id><author><name>Karin van Es</name></author><published>2023-07-07T00:00:00+00:00</published><updated>2023-07-07T00:00:00+00:00</updated><content type="html"><![CDATA[<h1 id="unpacking-tool-criticism-as-practice-in-practice">Unpacking tool criticism as practice, in practice</h1>
<h2 id="introduction">Introduction</h2>
<p>The digitalization and datafication of all aspects of our cultural practices and social interactions have created new opportunities for research. Thanks to easy-to-use data analysis tools and digital infrastructures, even those humanities scholars who lack programming skills can work with large-scale empirical datasets in order to disclose patterns and correlations within them. Although empirical research trends have existed throughout the history of the humanities <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, these recently emergent possibilities have revived an empiricist attitude among some humanities scholars schooled in more critical and interpretive traditions. This development has strengthened the position of those who have long thought that the humanities needed more objective means of inquiry to better substantiate their interpretive claims. It has been argued, however, that some of the interpretive humanistic tradition&rsquo;s strengths have been relinquished as a result. As Drucker and Svensson note, scholars engaged in digital projects sometimes leave their critical sensibilities behind:  “such projects can demonstrate more positivism than the positivism we often (and sometimes erroneously) associate with science and technology”   <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. The problem, in part, stems from the fact that the assumptions and concepts of the computational methods embedded in tools, often derived from the empirical sciences, are generally left unscrutinized <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. These tools become the stage of  “an encounter between two sets of epistemic traditions – hermeneutic and empirical”   <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> and raise questions about methodology.</p>
<p>Prompted by this  “methodological moment”  (Scheinfeldt in <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>) within the humanities, there has been a call for tool criticism, as it has been termed (<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> and <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>). These authors have drawn attention to the need for digital humanists to critically reflect on the impact of their research tools, which have computational methods embedded within them, on knowledge production. Rather than as mere instruments, these tools are envisioned as a set of conditions; their affordances are at once enabling and constraining practices. The proposal that our research tools are caught up in the epistemic process is not new <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>  <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. However, as a result of the computational turn and the proliferation of easy-to-use tools for data analysis and visualisation, there is a need to put the matter back on the agenda of the humanities and encourage further discussion on digital methodologies. Tool criticism takes part in a response to the call for a third-wave digital humanities that develops a programme of criticism with regard to the computational <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>, and it moves the discussion forward.</p>
<p>In this paper I seek to make tool criticism a bit more concrete. To do so I explore tool criticism as a response to instrumentalism in the digital humanities and proposes it to be part of what a critical digital humanities does. Subsequently, I explore it as a practice, and in practice. More specifically, I discuss two critical making–inspired workshops in which participants analysed the affordances of digital tools and infrastructures and engaged with their underlying assumptions and values. The first workshop approached  “games-as-tools”   <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. Participants modified a card game, playing with its material and mechanical constraints in order to argue with its claims and assumptions. The second workshop, drawing on the concept of  “digital infrapuncture”   <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, asked participants to examine digital infrastructure in terms of capacity and care. They first identified pain and stress in a chat environment, caused by the norms and values embedded in the design of the infrastructure (e.g. the platform discriminates against or even excludes certain users and practices). The participants then designed bots that intervened and offered relief in the system. Finally, reflection on the sort of tool criticism performed in the workshops enables an exploration of the critical and reflective attitude required of digital humanities scholars when conducting research with computational tools and digital infrastructures.</p>
<h2 id="against-instrumentalism">Against Instrumentalism</h2>
<p>Research in the digital humanities is supported by many different computational tools and digital infrastructures. Examples of such tools include Excel, Tableau, Python, Google NGram Viewer, ImagePlot and the Digital Methods Initiative Issue Crawler. Whereas tools are often used individually or by small teams and are oriented towards solving particular tasks, infrastructures work on a larger scale and combine multiple functions and applications. Infrastructures can be defined as  “the relationships, interactions and connections between people, technologies, and institutions (that help data flow and be useful”   <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. Examples of digital infrastructures relevant to digital humanities research include Getty, DBpedia, Europeana, DARIAH, and HuNi. A challenge in working with tools and infrastructures is that they have heterogenous development, funding and use contexts. These are all factors that impact their stability and appropriateness for research aims (see <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> ).</p>
<p>The computational turn has created a flood of empirical data, which can now be wrangled with in many easy-to-use tools. In the humanities we currently encounter a  “renewed positivist dream”  in which computational tools are applied uncritically <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. In an earlier contribution to this journal, Drucker and Svensson find that  “[h]umanists continue to be seduced by tools to whose workings they give limited attention, so they execute their projects (e.g. in network analysis software) without knowing how the results were generated”   <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> . This phenomenon has also been labelled  “blunt instrumentalism”   <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. Here computational tools, are treated as transparent and neutral. Their affordances and embedded methods, though exercising an impact on the epistemological process, are not critically analysed.</p>
<p>Patrik Svensson underscores the instrumental tendencies in the humanities, pointing to the propensity of  “think[ing] about infrastructure as placeless, immaterial, and neutral”   <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. He puts forth the view that our tools and infrastructures in fact embody  “ways of perceiving, interrogating, and enacting the world”   <sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. To avoid being governed by a scientific and engineering paradigm that now dominates the design of digital infrastructures, Svensson suggests that humanities scholars ought to become more involved in building. This way, models of infrastructure can be developed that are based on the humanities&rsquo; own needs and desires (see also <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>).</p>
<p>Inspired by Lev Manovich&rsquo;s assertion that a prototype  <em>is</em>  a theory, Alan Galey and Stan Ruecker <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> propose that experimental digital prototypes can contain arguments. They state that  “digital artifacts have meaning, not just utility” , and argue that these efforts should be considered peer-reviewable forms of research. Allington et al. <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>, however, have been critical of the idea that the building of computational tools can be a substitute for scholarly writing. They point out how Computer Science departments have never awarded PhD degrees on the basis of programming competence alone. Relevant to our discussion here is the idea that tools can embody the perspectives of their makers. However, it is important to point out that the assumptions and values in tools are not necessarily always the product of intent.</p>
<p>Responding to the concerns about instrumentalism, Mathieu Jacomy, one of the developers of Gephi, lashes out at academics. In a blog post he makes the following plea:</p>
<blockquote>
<p>Please stop summarizing your detailed argumentation down to tools influence us because of presuppositions built into them. Nobody stuffed your tool. That is not how it works. Most tool makers do not really know what they are doing – they just experiment. They do not try to influence you – they probably do not care about you.<br>
<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></p>
</blockquote>
<p>Jacomy goes on to argue that tools arrive as accidents and not as  “the Trojan horses of methodological imperialists”   <sup id="fnref1:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. While not every affordance of a tool is intentional or connected to the implementation of methods (some can, for instance, concern functionality), he overlooks how all choices reflect a particular perspective, contain certain assumptions and have implications for how knowledge is ultimately produced.</p>
<p>Against the background of instrumentalism, Drucker and Svensson find there is insufficient attention to the material support of knowledge production and that this should be addressed by the critical sensibilities of humanities scholars <sup id="fnref2:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. They examine  “middleware”  as a concept enabling attention to be paid to  “the ways tools  <em>structure our arguments</em>  or  <em>express thinking</em>  in protocols programmed into these platforms”  (<sup id="fnref3:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, my emphasis). Looking at what I have emphasized here in italics, an important differentiation is made between the basic affordances of tools and the affordances  <em>implemented</em>  in software by design <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>. Not only then do tools embed methods, Drucker and Svensson here point to the importance of analysing the material properties that enable and constrain use and influence the biases and assumptions behind them. The popular network visualisation and analysis software package Gephi, for instance, lacks the ability to trace the history of modifications made to network visualisations (see <sup id="fnref1:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>).</p>
<h2 id="tool-criticism-as-critical-digital-humanities">Tool Criticism as Critical Digital Humanities</h2>
<p>In light of a more general criticism charging that the digital humanities tend to be anti-interpretive (Allington et al., 2016), there have been calls for a  “ <em>critical</em> ”  digital humanities (<sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>  <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>  <sup id="fnref2:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>) which incorporates critical and interpretive traditions into the digital humanities. Conducting tool criticism, raising questions about how our computational tools are caught up in the epistemic process, needs to be part of what a critical digital humanities (CDH) does. Tool criticism is necessary particularly because these tools often bear assumptions and concepts derived from the empirical sciences (<sup id="fnref1:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>  <sup id="fnref3:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>).</p>
<p>David M. Berry has argued for the strengthening of a programme of criticism around the computational <sup id="fnref2:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. However, in the view of Rieder and Röhle, a concentration on the digital and the understanding of code with regard to the scrutiny of computational tools would be short-sighted <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. Such a focus emphasizes programming as a required skillset but overlooks the concepts and knowledges that are mobilized in the use of these tools (cf. <sup id="fnref4:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Likewise, Dennis Tenen explains that  “[j]ust applying the tool or even  learning to code  alone was therefore insufficient for making sense of the results. What could help me, then, and what is only now beginning to surface in DH literature is a critical conversation about methodology”   <sup id="fnref1:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. In raising questions about computational tools and their embedded computational methods, these scholars share an interest in tool criticism discussions about digital methodologies in the humanities.</p>
<p>The use of tools and infrastructure in humanities research requires that these tools, and the researcher&rsquo;s relation to them, be made a site of critical analysis – which is to say, that they demand tool criticism. As we have defined it elsewhere, tool criticism concerns</p>
<blockquote>
<p>the critical inquiry into digital tools and how they are used for various purposes within the research process. It reviews the qualities of the tool in light of, for instance, research activities, and it reflects on how the tool (e.g., its data source, working mechanisms, anticipated use, interface, and embedded assumptions) affects the user, the research process and output, and its reliance on the user&rsquo;s training. <sup id="fnref2:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.</p>
</blockquote>
<p>Central to this notion is a critical and reflexive attitude towards the tools used to create knowledge. Inspired by reflection-in-action <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>, tool criticism involves continuous  <em>interaction</em>  rather than the exercise of detached judgement from a distance. It is important, then, to reflect on the choices made in  <em>using</em>  the tools. This also explains why critical making–inspired workshops are used in this paper to explore tool criticism as practice, in practice. Tool criticism helps bring the traditional critical and interpretive strengths of humanities scholarship back into focus within digital humanities scholarship (cf. <sup id="fnref5:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>). It recognizes that tools are socio-technical constructions and are never simply a means of facilitating certain outcomes. They possess certain affordances and also reflect the worldviews of their makers.</p>
<p>As mentioned earlier, Drucker and Svensson have argued the importance of paying attention to how the material features of tools support knowledge production <sup id="fnref4:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. This is equally relevant in relation to our  <em>digital</em>  or computational tools. In the 1980s and &rsquo;90s the digital was seen as virtual and as existing outside material constraints. This popular discourse was misleading. Paul Dourish, in examining the material dimension of software and digital information, exhibits an interest in the materialities of information –  “those properties of representations and formats that constrain, enable, limit, and shape the ways in which those representations can be created, transmitted, stored, manipulated, and put to use – properties like their heft, size, fragility, and transparency”   <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>. In addition, software is always in-material due to its being embedded in physical data carriers <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>. Importantly, the material properties of tools and infrastructures exert influence on what, and how, they enable us to know.</p>
<p>One term used to capture the complexity of tools and their function with respect to a more encompassing methodology is the stack. It is defined as  “the interlinked and dependent layers of tools and abstractions that make up any contemporary computational application or procedure”   <sup id="fnref6:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> . Reflecting on the Natural Language Toolkit, Tenen explains,  “Each level of abstraction in the movement from statistical methods, to Python code, to graphical user interface introduces its own set of assumptions, compromises, and complications”   <sup id="fnref2:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. In addition to computational tools, digital infrastructures are used in research. These are intricate networks of relations that come into being as a system. Linking these issues back to the problem of instrumentalism, the conception of these tools as transparent is misguided because tools reflect methodological issues and because they have material properties with epistemological implications.</p>
<h2 id="critical-makinginspired-workshops">Critical making–inspired workshops</h2>
<p>The two workshops discussed in this paper seek to promote  <em>tool criticism thinking</em>  as a means of demonstrating the importance of  “methodological awareness and self-critique”   <sup id="fnref7:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> when humanities students and scholars engage in computational research. These workshops can be understood as experiments in what Matt Ratto has popularized as critical making and oscillates between building and reflection. In critical making workshops, participants build prototypes as a way of conceptual exploration. These prototypes  “achieve value through the act of shared construction, joint conversation, and reflection”   <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. This emphasis on the workshop process and the exchange that emerges rather than on a final product differentiates this sort of activity from  “critical technical practice”   <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> and  “critical design”   <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>.</p>
<p>Most of the external funding for DH projects has been directed toward tool-building rather than interpretive work <sup id="fnref8:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. This crux of tension in the digital humanities between intellectual labour on the one hand and making and practice on the other has often been captured in the catchphrase more hack, less yack. The split was epitomized when Stephen Ramsay, in  “Who&rsquo;s In and Who&rsquo;s Out” , provocatively stated that digital humanities scholars need to learn how to code and build things <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. The present paper&rsquo;s premise is that this opposition is misinformed and unproductive, as  “the humanities is both/and”   <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>. The critical making–informed workshops discussed here, in combining building and theorizing, equally reject such a binary. They underscore that the building of tools is/should be linked to theorisation. However, to explore these workshops here, is not to make an argument for the need to learn how to build things, but acknowledges that engaging in tool criticism requires a basic understanding of the biases and assumptions of the tools/infrastructure being used.</p>
<p>Concerns over instrumentalism noted have also sparked debates as to the particular skills and literacies needed in the digital humanities. Some thinkers have argued that digital humanities scholars need to learn how to code (<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>  <sup id="fnref1:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>  <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>), whereas others have warned that teaching students to program is time-consuming, detracts from the development of critical thinking <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>, and may foster a  “false sense of mastery”  over the technology <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>. Importantly, Rieder and Röhle <sup id="fnref2:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> find that the teaching of programming proficiency does not mean that the concepts and techniques employed in digital tools are clarified. The use of Gephi, for instance, would require an understanding of graph theory or sociometry. As Rieder explains in his recent book,</p>
<blockquote>
<p>But beyond attributions of sometimes very broad properties to the digital or, more recently, to algorithms, scholars in the humanities and social sciences still rarely venture more deeply into the intellectual and material domains of technicality that hardware and software developers invent and draw on to design the forms, functions and behaviors that constitute technical objects and infrastructures.<br>
<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>. Commenting on the idea of a critical code studies, Rieder questions whether this type of  “meaningful and context-aware reading”  of code would even be possible for humanities scholars <sup id="fnref1:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>.</p>
</blockquote>
<p>How, then, can humanities scholars who use computational tools and infrastructures critically engage with them? To answer this question the work of Ben Schmidt proves useful. He suggests that, in order to understand algorithms, it is important to grasp the transformations they bring about <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>. To demonstrate the usefulness of his proposal, Schmidt discusses the debate between Annie Swafford and Matt Jockers over Jockers&rsquo;  <em>Syuzhet</em>  package that explores plots through sentiment analysis. Schmidt explains,  “[t]he default smoothing in the  <em>Syuzhet</em>  package assumes [&hellip;] the start of every book has an emotional valence that continues the trajectory of its final sentence” . This function might be useful for the study of sitcom episodes, which tend to be cyclical in nature, but he finds it is less suitable for novels. Essentially, Schmidt proposes an engagement with the basic logics and principles of algorithms and an assessment of their suitability for the research at hand.</p>
<p>Schmidt&rsquo;s suggestion is certainly more attainable for digital humanities scholars than the deep engagement with the intellectual and material domains of technicality proposed by Rieder. His approach facilitates critical evaluation of tools and infrastructures, yet it should not be interpreted as an excuse to remain entirely uneducated about the concepts and methods at stake (for a basic understanding is certainly needed!). Schmidt&rsquo;s argument, however, needs to be extended as a tool is more than an algorithm. In other words, digital humanists should reflect on how a computational tool, the entirety of its stack, performs transformations and impacts knowledge production which includes inquiry into the methods <sup id="fnref9:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. It requires the posing of questions related to all the levels of abstraction. In terms of critical reflectivity, this is also what I had hoped to explore with the participants of the workshops. Prior to the workshops we introduced them to the notion of tool criticism, discussing its definition and purpose. During the workshops, when the participants tried to put it in practice, it became apparent what it entailed and demands of users and where its challenges lie.</p>
<h2 id="playable-datasets">Playable datasets</h2>
<p>Stefan Werning, a colleague at Utrecht University, has been organizing playable data workshops for several years now (see <sup id="fnref1:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>). These sessions have focused on exploring small/mid-sized datasets through card games. Participants play with the mechanisms and parameters of a card game as a means to facilitate new ways of calculating, sorting and ranking the underlying data sets (i.e. expressed in numbers, colours, identities etc.). These mechanics operate similarly to a layout algorithm like ForceAtlas2 in Gephi in that they need to fit the structure of the data at hand, but also distinctly (re)frame the types of insights that may be derived from the dataset <sup id="fnref2:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>.</p>
<p>The playable data workshops centred on game co-creation, which can be understood as a type of critical making. As Odendaal and Zavala (2018) explain,  “a physical game can help players make sense of something abstract and hidden and that is consequently excluded from public discussion”   <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>. Although existing perspectives on critical (board/card) game-making are focused on games regarded as products, Glas et al. developed a technique called  “discursive game design”   <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>. Here game co-creation becomes an ongoing critical conversation. Specifically, following Galey and Ruecker, the approach proposes a trajectory of iterations involving a prototype. Each iteration then developed represents a statement about the argument and a consideration of alternative paths.</p>
<p>The workshops drew on Nathan Altice&rsquo;s view of the playing card as a platform According to Altice,  “cards are platforms too. Their  hardware  supports particular styles, systems, and subjects of play while stymying others”   <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>. Altice goes on to explain how a game&rsquo;s design is influenced by the cards&rsquo; five main characteristics or affordances: planar, uniform, ordinal, spatial and textural. Having two opposing sides allows for concealment and the uneven distribution of information among players; the game operates as a surface for images, text and art. The uniformity of the cards allows them to be stacked and reordered as a deck. This affordance introduces elements of chance and assures fairness. Moreover, cards are ordinal, allowing them to be counted, ranked, and sorted. They also occupy space, meaning that the cards&rsquo; arrangement in a particular order can have significance. Also, cards are textural, designed to be handled (e.g., shuffling, dealing, cutting, etc.) and require proximity to one another. In short, Altice clarifies the ways that cards impose material and mechanical restraints. As Werning puts it, the playful datasets workshops treated games-as-tools. As such, observations about games can be extended to thinking about how computational tools are impacted by design choices.</p>
<p>In December 2019, within the context of our teaching the research master course  “Data-driven tools and methods”  for 15 students within Media and Culture Studies at the Faculty of Humanities, I collaborated with Werning on a Playable Datasets workshop. In the workshop we incorporated tool criticism, as a reflective perspective taken up by the participants. Specifically, students were instructed to explore the  <em>mechanical</em>  and  <em>material</em>  constraints of a game we provided them and to make a series of modifications to it. For the workshop Werning had developed the  “App Publisher”  game using a dataset containing metadata from almost 10,000 apps from the Google Play Store.<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>  Using nanDECK, he had converted a sample dataset from the Google Play Store into customizable playing cards.<sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>  The game was about the political economy of app publishing. Following the discursive game design approach, the game served as a starting point for subsequent modifications initiated by the students. In other words, they were asked to  <em>argue</em>  with the values and assumptions of the prototype in front of them.</p>
<h2 id="reflections">Reflections</h2>
<p>Three main observations can be made about the workshop that are relevant to the aims of this paper. First, participants realized that making a game prototype entails  <em>a whole chain of tools</em>  including Excel, nanDeck and Google Play API. They realized how each step in the process of making a prototype had involved the making of choices and the following of certain procedures. They had worked with Excel to clean the dataset<sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>  and with nanDECK to design the cards. They struggled with the limitations imposed by only having access to the data made available through the Google Play Store API service, which restricted the scope of potential games they could make. Students raised questions about the meaning of the data, which they determined was multivalent (e.g., they mean something different to Google than to the maker or players of the original prototype) and thus dependent on the position from which one asked such questions. The workshop also made explicit how data and tools were intertwined. The tools they worked with determined the data that was available to scrape (Google Play Store API) and how it could be manipulated (Excel and nanDECK). The game mechanisms, in turn, provided ways of exploring the dataset and influenced how the data were understood. In arguing with the game prototype the students experienced first-hand how  “Specific data sets and algorithms, designed to work together, cannot be easily separated and appropriated for other ends”   <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>.</p>
<p>Second, the workshop participants struggled in having to make and to critically reflect as part of a single process. They started out rather upbeat, pinpointing which assumptions about the app marketplace were embedded in the original game prototype. Tasked with making their own prototype based on the existing dataset, however, they struggled. They needed to learn how to work with various tools, but this effort took too much time and hindered their ability to  <em>think</em>  about their process. Only afterwards, when preparing their presentation, did they start to grasp the implications of their decisions and how their options had been framed by their tools. The session&rsquo;s time constraints minimized critical work in favour of results. Asking and attending to questions about approach, methods, and goals would certainly have slowed the process down – but, we should stress, moving slowly doesn&rsquo;t have to be experienced as something negative. Berry and Fagerjord have suggested that critical work in digital humanities projects can function as a  “ <em>productive</em>  slowdown”   <sup id="fnref1:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. The experienced challenge of combining critical reflection and building was, in the end, primarily a limitation of how the workshop had been designed. New iterations could consider more time and space for engagement.</p>
<p>One team presented a short meme-based video made by student Daniël Everts on trying to engage with and reflect on nanDECK with the help of the software&rsquo;s 169-page manual.<sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>  The video&rsquo;s humor centres on the protagonist scrolling endlessly through the manual (two days later, three weeks later) on their computer. Finally, they push a large Spok (sic!) button, whereupon the fictional _ Star Trek_  Vulcan enters the room and, contrary to his famous hyperrationalism, repeatedly smashes the computer with his fist. Frustrations over the steep learning curves of computational tools are ever more frequently encountered when we are teaching practical data skills in our programme. The limitations experienced here were more about the remediation of analogue cards. Students implicitly reflected on the affordances of cards, earlier discussed in relation to Altice, in giving form to the games they developed. Werning and I also discussed whether we should have given them paper, scissors, and pens to design their game. Now they worked within the parameters of what was possible in code, which the students needed to learn on the fly.</p>
<p>The frustration with the nanDECK manual points to the gap between  <em>transparency and explainability</em> . In other words, making the workings of a tool transparent does not mean that the user  <em>understands</em>  how and why it works the way it does. Transparency is, for instance, often pursued by sharing the code of software. Again, many people may lack the knowledge to comprehend and interpret it. Explainability would entail that how the software tool works is made interpretable to the user, explained in such a manner that they grasp its underlying concepts and models. The workshop furthermore raised the question as to  <em>how much</em>  the students needed to understand of the tool and what needed to be addressed in their discussion of the prototype they had made. Rather organically, they let go of the idea that they had to understand all the minute details of the tools and began focusing more on transformations to address the values and assumptions of the game prototypes.</p>
<p>Lastly, the workshop&rsquo;s participants spent a lot of time fine-tuning their prototype with an eye to its usability, concerning themselves with matters such as the legibility of fonts and images on the cards. Here, they aligned with the approaches of the HCI community, which stress  “ efficient completion of tasks”  and are oriented towards transparency and clarity <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>. This orientation produced the impression that the game provides a window onto the underlying data and presents certainty about the apps and their relations. Interestingly, the participants could have used ambiguity to reflect the complexity of the app marketplace. Their choices, by contrast, demonstrated the appeal and persuasiveness of using simple categories, measures, and representational forms. In short then, the students seemingly favoured clean and unambiguous data and interfaces. This observation points to the importance of consideration for one&rsquo;s own ontological and epistemological assumptions.</p>
<h2 id="bots-and-digital-infrapuncture">Bots and digital infrapuncture</h2>
<p>To further explore tool criticism thinking, I also discuss insights prompted by another workshop. Cristina Cochior and Manetta Berends, both researchers/designers active in the Netherlands, designed and led the  “bots and digital infrapuncture”  online workshop hosted in June 2020 by  <em>Data School</em>  at Utrecht University.<sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>  It was attended by eight participants, primarily PhD candidates, most of which had some basic programming skills. The workshop was preceded by a lecture in which Deb Verhoeven discussed digital infrapuncture, a concept she initially introduced in an opening keynote for the 2016 Digital Humanities at Oxford Summer School (see <sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>). Like Svensson, Verhoeven is also concerned with the fact that most research infrastructures in DH do not reflect humanistic goals. She proposed digital infrapuncture as a new model for digital humanities infrastructure. The concept draws from the work of Manuel de Sola-Morales on urban acupuncture and Steven Jackson&rsquo;s (2014) essay  “Rethinking Repair” . As Verhoeven explained, it combines the word infrastructure and acupuncture and is a way of exploring how small-scall infrastructure interventions can transform larger contexts. Rather than building new infrastructures, digital infrapuncture looks to relieve systemic pressure, which she termed hurt, through these interventions. Verhoeven&rsquo;s work responds to scholarly conversations on the need to reconsider big data humanities infrastructure in terms of capacity and care cf. <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. In the workshop presentation she proposed  <em>agency</em> ,  <em>impact</em> , and  <em>power</em>  as key conceptual axes on which current research infrastructures can be rethought and rebuilt. These conceptual axes were considered and discussed during the group discussion when identifying and tackling identified hurt.</p>
<p>Verhoeven&rsquo;s introduction to digital infrapuncture was followed by a short lecture by Cochior, in which she explored Bot Logic as a framework through which to understand bots&rsquo; impact (their affective and effective forces alike). The workshop&rsquo;s aim was to devise bots in chat protocols that would intervene in the logics of the platform, creating small interventions that overhaul the notion of structure itself and offer relief. The workshop consisted of five parts: (a) brainstorming chat protocols, (b) identifying where it hurts, (c) designing a bot to puncture and deflate stress, (d) scripting how the bot acts upon the infrastructure, and finally (e) group discussion. I briefly reflect on the process and on outcomes involving two teams as a means to fleshing out what tool criticism actually entails in practice.</p>
<p>The first team, a duo of which I was part, focused on critique of the neoliberal university on Twitter in the Netherlands. We considered the Matthew effect of accumulated advantage as well as related questions of visibility and voice in academia. We thought about ways that bots could be used to amplify academics with few Twitter followers, but settled on another hurt, namely that caused by the hierarchies of visibility for political inaction in the Netherlands on issues pertaining to the neoliberalization of universities. To amend this hurt, we proposed a bot that would tweet posts with hashtags such as #WOinActie (a community of employees and students in the Netherlands protesting the neoliberalization of the university) directed to the Minister of Education, Culture and Science. Another team picked the open-source decentralized social network Mastodon and contemplated ways of countering radical voices on the Mastodon timelines. They came up with a bot that supported the coverage of a range of perspectives on a topic. It would identify a post&rsquo;s topic and compare it to the entries in a categorized database, in order to then counter it with an article offering a different perspective on that topic.</p>
<h2 id="reflections-1">Reflections</h2>
<p>The workshop prompted a series of questions relevant to tool criticism. These queries centred on issues concerning the distribution of  <em>agency</em>  among users, bots, and platforms/infrastructures, as well as with  <em>scale</em>  and  <em>interconnections</em>  relating to questions of impact. In terms of agency, we knew that a bot tweeting at the Minister of Education, Culture and Science would immediately be muted or blocked, which got us thinking about whether we could actually  <em>intervene</em>  on the platform. Was this possible, or are bots merely a means to  <em>augment</em> ? And if so, should augmentation be seen as a form of intervention? It seemed that what the bot would be doing was more akin to what Michel de Certeau calls tactics. As he explains,  “[t]he space of a tactic is the space of the other. Thus it must play on and with a terrain imposed on it and organized by the law of a foreign power”   <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>. In other words, the bot would simply be acting within the environment as defined by the platform&rsquo;s own given strategies. In fact, Andreas Hepp proposes that bots are often  “media in media”   <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>. Based on platforms such as Facebook and Twitter, they simply act upon these platforms. In other words, they intervene  <em>on</em>  rather than  <em>in</em>  the infrastructure. The latter possibility would require access – signalling uneven power relations - which we would never have. Questions were thus raised about the platform&rsquo;s ownership and how certain affordances reflected its purpose and the level of involvement of the audience.</p>
<p>The Mastodon team, with their bot, wanted to stimulate impartial coverage of news topics. They were critical of their own proposal to do so but formulated valuable reflections on  <em>scale</em>  and  <em>interventions</em> . Plantin et al. argue that digital technologies have contributed to a platformization of infrastructures and an infrastructuralization of platforms. As they explain, platforms and infrastructures are both structures that underlie and support a system or organization,  “but they differ in scale and scope”   <sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup> They characterize the former with terms such as  “centrally designed and controlled” ,  “modular frameworks” , and  “small scales and scopes” ; the latter are described by terms and phrases like  “widely accessible” ,  “heterogeneous systems and networks” , and  “essential services”   <sup id="fnref1:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>. Van Dijck et al. explain that in North America and Europe, Alphabet-Google, Facebook, Microsoft, Amazon, and Apple provide infrastructural services on which many other apps and platforms are built. The services of these tech companies are integrated into many websites, enabling the collection of user data across the Web and various apps <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>. Such complex interdependencies are also present in the digital infrastructures used for research. These relations, and the implications of their dependencies, need to be considered in the analysis of how research infrastructure shapes the research process. They prompt important questions about agency, impact and power.</p>
<p>In addition to scale, the Mastodon team reflected with the workshop participants on the impact of the bot&rsquo;s interventions. We realized that the proposed bot might actually thwart the ideals of impartial coverage by giving attention to positions not supported by credible evidence. Regardless of whether or not the bot could work, it was interesting to think through the larger impact it might exert. Specifically, we discussed what had happened when representatives of social media platforms fact-checked against Wikipedia. In these cases, the hurt (i.e., the dissemination of fake news) had simply been displaced and travelled elsewhere: users started falsifying Wikipedia entries to prevent posts from being classified as fake. This phenomenon reminded us that systems are often interrelated and that interventions in one place might extend further than anticipated. Similar to our thinking about a Twitter neoliberal academia bot, the question arose as to where the critical location of intervention is situated and whether we had the requisite access to intervene in such a space.</p>
<h2 id="conclusions">Conclusions</h2>
<p>In this paper, two critical making–inspired workshops were used as a springboard to unpack tool criticism and explore the types of reflections it brings to the fore. Our tools and infrastructures, it was underscored, require critical attention as they are not neutral actants in knowledge production. The workshops helped make explicit the thinking that tool criticism entails and the challenges that digital humanities scholars should confront when using tools and infrastructures. The critical modality in which such scholars have traditionally been trained should be directed towards their computational tools and infrastructures in the digital humanities.</p>
<p>The workshops underscored the complex network of  <em>relations</em>  between human and non-human actors that come into being and enact agency. Understanding tools is also a question of grasping their relation to users, and it requires the ability to treat them not as objects but as  “a set of conditions, structured relations, that allow certain behaviours, actions, readings, events to occur”   <sup id="fnref1:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>. This idea was the conception at the centre of the workshops. Tool criticism is a continuous process of thinking and acting  <em>with</em>  tools. From earlier workshops we had learned that teaching participants the basics of programming would require a lot more time. In the bots and infrapuncture this enactment had therefore been substituted with a scripting exercise. While this was obviously not the same activity, participants were nonetheless asked to run their code and consider how the bot would work in practice. During the playable datasets workshop in particular we noticed that participants struggled to move between making the game prototype and engaging in critical reflection on their process. Although critical work takes time, there should nonetheless be reflection on one&rsquo;s approach, methods, and the goals of the tools being used. This insight supports Berry and Fagerford&rsquo;s call for a productive slowdown in research projects.</p>
<p>Moreover, the workshops brought to light that we often use not only  <em>a</em>  tool but rather a  <em>chain</em>  of tools. This observation underscores Dobson&rsquo;s argument that criticism needs to be implemented throughout the entirety of the research process (not just in relation to its results). Alternatively, researchers may use digital infrastructure that relies on or is interwoven with other tools or infrastructures. These interact with and co-define the inputs and outputs. It also became apparent that a focus on the transformations brought about by tools – rather than getting lost in the details about how they function – was sufficient for conversations to ensue about their assumptions and values. However, here the participants of both workshops were somewhat at an advantage in their already having affinity with the Humanities.</p>
<p>As seen in the workshops, tool criticism thinking raises questions about impact, access and establishes relations of power and links to ownership. The tools we use are often appropriated from other disciplines or taken from other institutional and commercial contexts. More specifically, tool criticism prompts a series of questions. Who made it? For who (not)? With what purpose? Such questions are not unfamiliar as they are, for instance, grounded in traditional source criticism <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. However, enthusiasm for big data research in the humanities, necessitates these are revisited and updated. The workshops surfaced questions that engage explicitly with the materiality of the tools that play a role in transforming the data we work with. These include: What assumptions and values are established through its affordances and implemented in the design? Can we examine and adapt the underlying code? What is the impact of different settings and parameters (materials and mechanics). What happens when we use this set of rules instead of some other? How would certain decisions change how we interpret the underlying data? Here the relation between tool and research also proved of importance: What are my own assumptions and values?</p>
<p>What complicates the aim of tool criticism in answering these questions is that these computational tools are often easy-to-use and thus  <em>seem</em>  transparent and neutral. Furthermore, tools are complex and dynamic in that they not only consist of interlinked and dependent layers but are also networked with other human and non-human actors (including underlying data sets). Criticism is contingent not only on questions of  <em>access</em>  to the black boxes (e.g., code and algorithms, models and strategies) but also on the subsequent ability to make sense of it. The nanDECK tutorial was a powerful reminder that transparency is not enough for users to understand the stakes - its biases and assumptions - of using the tool. It demands that users of tools become more informed and literate about the building blocks of these technologies.</p>
<p>While our initial definition of tool criticism (<sup id="fnref1:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>  <sup id="fnref3:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>) addressed the fact that our computational tools contain values and assumptions pertaining embedded concepts and methods that should be subject to scrutiny, we failed to extend our inquiry to include concerns related to capacity and care. Here, books such as Data Feminism (2020) by Catherine D&rsquo;Ignazio and Lauren F. Klein, with its seven principles of data feminism <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>, and All Data Are Local by Yanni Alexander Loukissas <sup id="fnref1:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup> might prove useful. Concerns for data justice as well have been expressed in relation to automated tools by Virginia Eubanks in  <em>Automating Inequality</em>  (2019) <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup> and Safiya Noble in  <em>Algorithms of Oppression</em>  (2018) <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. By incorporating such concerns into the questions we raise about our research and the tools and infrastructures we employ, tool criticism becomes an important component of digital  <em>humanities</em>  scholarship.</p>
<p>Engaging in tool criticism is, as the participants of these critical making-inspired workshops experienced, no simple task. It needs to be part and parcel of the research process, necessitates a slowing down and an eagerness to learn about the basic principles of the tool. For humanities scholars in particular, this sort of criticism requires discussions not just about methodology but also about ethics and care. New research tools and infrastructures for the humanities should consider questions of access and agency in local contexts. Workshops of the sort discussed here are a modest step to help raise awareness of the fact that computational tools are not neutral and that a lot of interpretive acts are involved in working with them. Moreover, the insights and reflections generated in these workshops can help formulate the type of questions that we need to be asking about computational tools in digital humanities research and beyond and surface issues that we need to collectively address.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>The author would like to thank Stefan Werning, Cristina Cochior, Manetta Berends and Deb Verhoeven for their co-orgnanization/participation in the workshops and the fruitful exchange this allowed for on tool criticism.</p>
<p>It was based on a dataset scraped and shared via Kaggle by Lavanya Gupta.</p>
<p>Cf. <a href="http://www.nand.it/nandeck/">http://www.nand.it/nandeck/</a></p>
<p>In the course they had read the article by <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup> about how the notion of ‘cleaning’ proposes an underlying correct order of data. As such, they were primed to think also about the impact of this on knowledge production.</p>
<p>The video was later posted to YouTube on January 7, 2020: <a href="https://www.youtube.com/watch?v=dGKdNYSjTHk">https://www.youtube.com/watch?v=dGKdNYSjTHk</a></p>
<p>This workshop has since been developed as an online module to stimulate tool criticism thinking with short video contributions from Deb Verhoeven, Seda Gürses and Andreas Hepp: <a href="https://bots-as-digital-infrapunctures.dataschool.nl/">https://bots-as-digital-infrapunctures.dataschool.nl/</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Bod, Rens. (2013)  <em>A New History of the Humanities: The Search for Principles and Patters from Antiquity to the Present</em> . Oxford University Press, Oxford.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Drucker J. and P. Svensson. (2016)  “The Why and How of Middleware” ,  <em>Digital Humanities Quarterly</em>  10.2. Available at: <a href="http://www.digitalhumanities.org/dhq/vol/10/2/000248/000248.html">http://www.digitalhumanities.org/dhq/vol/10/2/000248/000248.html</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Dobson, J. E. (2019)  <em>Critical Digital Humanities: The Search for a Methodology</em> . Champaign: University of Illinois.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Masson, E. (2017)  “Humanistic Data Research. An Encounter Between Epistemic Traditions.”  In MT. Schäfer and K. van Es (eds),  <em>The Datafied Society. Studying Culture through Data</em> , Amsterdam University Press, Amsterdam, pp. 25-38.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Rieder, B and T. Röhle. (2017)  “Digital Methods: From Challenges to Bildung.”  In M.T. Schäfer and K. van Es (eds.),  <em>The Datafied Society: Studying Culture through Data</em> , Amsterdam University Press, Amsterdam , pp.109–24.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Koolen, M., Van Gorp, J., and van Ossenbruggen, J. (2019)  “Toward a Model for Digital Tool Criticism: Reflection as Integrative Practice” , Digital Scholarship in the Humanities, 34.2: 368–85.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Van Es, K., Wieringa, M. and Schäfer, M. T. (2018)  “Tool Criticism: From Digital Methods to Digital Methodology”    <em>ACM WS.2 2018: Proceedings of the 2nd International Conference on Web Studies</em> , Paris, France, October 2018.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Van Es, K., Schäfer, M. T., and Wieringa, M. (2021)  “Tool Criticism and the Computational Turn: A  Methodological Moment  in Media and Communication Studies”    <em>MandK Medien and Kommunikationswissenschaft</em>  69 (1): 46-64.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Van Geenen, D. (2020)  “Critical Affordance Analysis for Digital Methods: The Case of Gephi.”  In M. Burkhardt, M. Shnayien and K. Grashöfer (eds.),  <em>Explorations in Digital Cultures</em> , Meson press, Lüneburg, pp. 1–21.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Baird, D. (2004)  <em>Thing Knowledge: A Philosophy of Scientific Instruments</em> . University of California Press, Berkeley.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Latour, B. and S Woolgar. (1986)  <em>Laboratory Life: The Construction of Scientific Facts</em>  (2nd edition). Princenton University Press, Princeton.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Berry, D. (2011)  “The Computational Turn: Thinking About the Digital Humanities” ,  <em>Culture Machine</em> , 12: 1-22.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Werning, S. (2020)  “Making Data Playable: A Game Co-creation Method to Promote Creative Data Literacy” ,  <em>Journal of Media Literacy Education</em> , 12.3: 88-101.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Verhoeven, D. (2016)  “Opening Keynote: Identifying the Point of It All: Towards a Model of  Digital Infrapuncture , Digital Humanities at Oxford Summer School” . Available at: <a href="http://podcasts.ox.ac.uk/opening-keynote-identifying-point-it-all-towards-model-digital-infrapuncture">http://podcasts.ox.ac.uk/opening-keynote-identifying-point-it-all-towards-model-digital-infrapuncture</a>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Parsons, M.A. (2015)  “e-Infrastructures and RDA for data intensive science” ,  <em>Research Data Alliance</em> . Available at: <a href="https://rd-alliance.org/sites/default/files/attachment/Infrastructures,%20relationship,%20trust%20and%20RDA_MarkParsons.pdf">https://rd-alliance.org/sites/default/files/attachment/Infrastructures,%20relationship,%20trust%20and%20RDA_MarkParsons.pdf</a>&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Tenen, D. (2016)  “Blunt Instrumentalism”  In M. K. Gold and L. F. Klein (eds),  <em>Debates in the Digital Humanities</em> , University of Minnesota Press, Minneapolis, pp. 83-91.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Svensson, P. (2015)  “The Humanistiscope – Exploring the Situatedness of Humanities Infrastructure.”  In P. Svensson and D.T. Goldberg (eds),  <em>Between Humanities and the Digital</em> , The MIT Press, Cambridge, MA, pp. 337-54.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Drucker, J. (2012)  “Humanistic Theory and Digital Scholarship.”  In M. K. Gold (ed.),  <em>Debates in the Digital Humanities</em> , University of Minnesota Press, Minneapolis, pp. 85–95.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Galey, A. and S. Ruecker. (2010)  “How a Prototype Argues” ,  <em>Literary and Linguistic Computing</em> , 25.4: 405–24.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Allington, D. S. Brouillette, S., and Golumbia, D. (2016)  “Neoliberal Tools (and Archives): A Political History of Digital Humanities.”    <em>Los Angeles Review of Books</em> . Available at: <a href="https://lareviewofbooks.org/article/neoliberal-tools-archives-political-history-digital-humanities/">https://lareviewofbooks.org/article/neoliberal-tools-archives-political-history-digital-humanities/</a>&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Jacomy, M. (2020)  “Digital Criticism: In Favor of the Scientific Instrument” ,  <em>Reticular Hypotheses</em> . Available at: <a href="https://reticular.hypotheses.org/1692">https://reticular.hypotheses.org/1692</a>&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Schäfer, M. T. (2011)  <em>Bastard Culture!: How User Participation Transforms Cultural Production.</em>  Amsterdam University Press, Amsterdam.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Berry, D. and Fagerjord, A. (2017)  <em>Digital Humanities</em> . Polity Press, Cambridge.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Schön, D. (1983)  <em>The Reflective Practitioner: How Professionals Think in Action</em> . Basic Books, New York.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Dourish, P. (2017)  <em>The Stuff of Bits: An Essay on the Materialities of Information</em> . The MIT Press, Cambridge, MA.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Van den Boomen, M., Lammes, S., Lehmann, A., Schäfer, M. T., and Raessens, J. (2009)  “Introduction: From the Virtual to Matters of Fact and Concern.”  In M. van den Boomen, S. Lammes, A. Lehmann, M. T. Schäfer and J. Raessens (eds.),  <em>Digital Material: Tracing New Media in Everyday Life and Technology</em> , Amsterdam University Press, Amsterdam, pp. 7-17.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Ratto, M. (2011)  “Critical Making: Conceptual and Material Studies in Technology and Social Life” ,  <em>The Information Society</em> , 27.4: 252-60.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Agre, P. E. (1997)  “Toward a Critical Technical Practice.”  In G. Bowker, L. Gasser, L. Star, and B. Turner (eds),  <em>Bridging the Great Divide: Social Science, Technical Systems, and Cooperative Work</em> , Erlbaum, Mahwah, pp. 131-58.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Dunne, A. (2005)  <em>Hertzian Tales: Electronic Products, Aesthetic Experience, and Critical Design</em> . The MIT Press, Cambridge, MA.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Ramsay, S. (2011)  “Who’s In and Who’s Out” , Author’s blog. Available at: <a href="http://stephenramsay.us/text/2011/01/08/whos-in-and-whos-out">http://stephenramsay.us/text/2011/01/08/whos-in-and-whos-out</a>&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Nowvisikie, B. (2016)  “On the Origin of ‘Hack’ and ‘Yack.’”  In M. K. Gold and L. F. Klein (eds),  <em>Debates in the Digital Humanities</em> , University of Minnesota Press, Minneapolis, pp. 66-70.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Rushkoff, D. (2010)  <em>Program or Be Programmed: Ten Commands for a Digital Age.</em>  OR Books, New York.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Galloway, A. (2016)  “The Digital in the Humanities: An Interview with Alexander Galloway. (Alissa Dinsman)” ,  <em>Los Angeles Review of Books</em> . Available at. <a href="https://lareviewofbooks.org/article/the-digital-in-the-humanities-an-interview-with-alexander-galloway/">https://lareviewofbooks.org/article/the-digital-in-the-humanities-an-interview-with-alexander-galloway/</a>&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>Fuchs, C. (2017)  “From Digital Positivism and Administrative Big Data Analytics Towards Critical Digital and Social Media Research” ,  <em>European Journal of Communication</em> , 32.1: 37–49.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Chun, W. (2013)  “Wendy Hui Kyong Chun in Conversation with Adeline Koh” ,  <em>E-Media Studies</em> , 3.1. Available at: <a href="https://journals.dartmouth.edu/cgibin/WebObjects/Journals.woa/xmlpage/4/article/428">https://journals.dartmouth.edu/cgibin/WebObjects/Journals.woa/xmlpage/4/article/428</a>&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Rieder, B. (2020)  <em>Engines of Order: A Mechanology of Algorithmic Techniques</em> . Amsterdam University Press, Amsterdam.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Schmidt, B. (2016)  “Do Digital Humanists Need to Understand Algorithms?”  In M.K. Gold and L.F. Klein (eds),  <em>Debates in the Digital Humanities</em> , University of Minnesota Press, Minneapolis, pp. 546-555.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Odendaal, A., and Zavala, K. (2018)  “Black Boxes out of Cardboard: Algorithmic Literacy through Critical Board Game Design” ,  <em>Analog Game Studies</em> . Available at: <a href="http://analoggamestudies.org/2018/12/black-boxes-out-of-cardboard-algorithmic-literacy-through-critical-board-game-design/">http://analoggamestudies.org/2018/12/black-boxes-out-of-cardboard-algorithmic-literacy-through-critical-board-game-design/</a>&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Glas, R., van Vught, J.F., and Werning, S. (2020)  “ Thinking Through  Games in the Classroom: Using Discursive Game Design to Play and Engage with Historical Datasets” ,  <em>Transactions of the Digital Games Research Association</em> , 5.1.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Altice, N. (2014)  “The Playing Card Platform” ,  <em>Analog Game Studies</em> . Available at: <a href="http://analoggamestudies.org/2014/11/the-playing-card-platform/">http://analoggamestudies.org/2014/11/the-playing-card-platform/</a>&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:42">
&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:43">
&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:44">
<p>Loukissas, Y.A. (2019)  <em>All Data Are Local: Thinking Critically in a Data-Driven Society</em> . The MIT Press, Cambridge.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:46">
<p>Drucker, J. (2013)  “Performative Materiality and Theoretical Approaches to Interface” ,  <em>Digital Humanities Quarterly</em> , 7.1. Available at: <a href="http://www.digitalhumanities.org/dhq/vol/7/1/000143/000143.html">http://www.digitalhumanities.org/dhq/vol/7/1/000143/000143.html</a>&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:48">
<p>Nowvisikie, B. (2015)  “On Capacity and Care” , Author’s blog. Available at: <a href="http://nowviskie.org/2015/on-capacity-and-care/">http://nowviskie.org/2015/on-capacity-and-care/</a>&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>De Certeau, M. (1984)  <em>The Practice of Everyday Life</em> . Translated by Steven Rendall. University of California Press, Berkeley and Los Angeles.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Hepp, A. (2020)  “Artificial Companions, Social Bots and Work Bots: Communicative Robots as Research Objects of Media and Communication Studies” ,  <em>Media, Culture and Society</em> : 1-17.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Plantin, J. C., Lagoze, C. Edwards, P. N., and Sandvig, C. (2018)  “Infrastructure Studies Meet Platform Studies in the Age of Google and Facebook” ,  <em>New Media and Society</em> , 20.1: 293-310.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Van Dijck, J., Poell, T., and de Waal, M. (2018)  <em>The Platform Society: Public Values in a Connective World.</em>  Oxford University Press, Oxford.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>D’Ignazio, C. and L. F. Klein. (2020)  <em>Data Feminism</em> . The MIT Press, Cambridge, MA.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Eubanks, V. (2019)  <em>Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor</em> . St. Martin&rsquo;s Press, New York.&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Noble, S. (2018)  <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em> . NYU Press, New York.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Rawson, K. and Muñoz, T. (2019)  “Against Cleaning.”  In M. K. Gold and L. F. Klein (eds),  <em>Debates in the Digital Humanities</em> , University of Minnesota Press, Minneapolis, pp. 279–92.&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">How to Do Things with Deep Learning Code</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000684/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000684/</id><author><name>Minh Hua</name></author><author><name>Rita Raley</name></author><published>2023-06-22T00:00:00+00:00</published><updated>2023-06-22T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>




























<figure ><img loading="lazy" alt="Dictionary definition of the phrase deep learning code which reads “1. a set of instructions that are learned using a high level of detail, such as to interpret information and modify systems. 2. a word that probably exists; with an alternative definition made by a machine learning algorithm.”" src="/dhqwords/vol/17/2/000684/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure01_hu6517ecf19048dded959b739be1f6b885_41265_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure01_hu6517ecf19048dded959b739be1f6b885_41265_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure01.png 740w" 
     class="landscape"
     ><figcaption>
        <p>Screen capture from <em>This Word Does Not Exist</em>
        </p>
    </figcaption>
</figure>
<h2 id="1-overview">1. Overview</h2>
<p>The public conversation about large language models is nothing if not riddled with sensation. Even apart from OpenAI’s already-notorious ChatGPT, or a Google engineer’s claim of sentience for its conversational model, the reporting on research advances in Natural Language Processing (NLP) almost inevitably cultivates some degree of alarm and auratic mystery. Some of this affect is generalizable to the field of artificial intelligence, which continues to be overcoded as a dangerous and impenetrable black box. But the enclosure of the NLP research environment behind Application Programming Interfaces (APIs), and the concomitant development of language models requiring compute resources beyond the means of ordinary users, has also contributed to the mystification.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>  Paradigmatic headlines such as <a href="https://www.nytimes.com/2022/04/15/magazine/ai-language.html"> “A.I. Is Mastering Language. Should We Trust What It Says?” </a>  <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> communicate the threat of a singular, mystified, and unstoppable thing called AI, with humans relegated to the role of end users. One salient question for researchers, then, is how best to demystify large language models and explain their functioning, not only to help shape a sociotechnical consensus about their responsible application but also to help expand the horizon of possibility for human engagement, beyond instrumental use and risk assessment alike.</p>
<p>While there are technical methods to explain and understand language models — so-termed BERTology is one example<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  — the occasion of a scholarly conversation about Critical Code Studies (CCS) suggests a particular research question: What can be learned about machine learning systems when the techniques and lessons of CCS are applied at the level of code rather than theory? As the full range of contributions to this special issue attests, CCS applies critical hermeneutics to software code, documentation, structure, and frameworks. Among the more prominent case studies in the aforementioned are readings of BASIC, Perl, JavaScript, and C++ programs, all exercises in excavating the meanings or structures of signification that are both latent in and produced by code (e.g. <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>). This method has been developed for and honed on  <em>programmed</em>  code: words, characters, and symbols arranged according to rules and in a form that might be understood as textual. CCS in other words has traditionally grappled with artifacts that, while certainly mobile and changeable, have enough of a static quality to allow both for individual study and shared understanding. What though can this method do with machine learning systems that include code in this ordinary sense as well as statistical parameters and operations, that are in other words less lexical than they are mathematical? While we had previously expressed skepticism about the efficacy and utility of taking a CCS approach to a language model such as GPT-2 <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, we were challenged for this special issue to do precisely that: to consider the extent to which CCS might illuminate a system, either in terms of intent or functioning, that is comprised not just of code but also training data, model architecture, and mathematical transformations — to consider then if its methodology might be adapted for the study of an interactive system that is not strictly algorithmic.</p>
<p>In the wake of CCS, as well as Software Studies and Platform Studies, the subfield of Critical Artificial Intelligence Studies (CAIS) has emerged explicitly to take account of machine learning. CAIS calls for an end-to-end engagement and insists on the  <em>model</em>  as the unit of analysis. Even if not self-consciously presented as a field articulation, academic studies of machine learning have collectively shifted the emphasis away from code and toward the model, with a particular emphasis on vectorization, probabilitization, and generalization. Adrian Mackenzie, for example, asserts that  “code alone cannot fully diagram how machine learners make programs or how they combine knowledge with data”   <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. And in what may well become a foundational document for CAIS as such, in a so-termed  “incursion”  into the field, researcher attention is redirected from  “an analytical world of the  <em>algorithm</em>  to the world of the  <em>model</em> , a relatively inert, sequential, and/or recurrent structure of matrices and vectors”   <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. What this means more plainly is that CAIS concerns itself not with the code that implements a particular machine learning model, but rather its mathematical definition, not with  “symbolic logical diagrams”  but rather  “statistical algorithmic diagrams”   <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Deep learning code is thus positioned as merely one component of machine learning systems and not by itself granted priority. In contrast, we proceed from the observation that deep learning code in fact represents the myriad possible  <em>implementations</em>  of a machine learning model and its auxiliary programs. On this basis, we contend that the design choice and biases inherent in each implementation extend their significance beyond mathematical formulae and warrant a closer look.</p>
<p>While the  <em>model</em>  has tended to serve as the unit of analysis, the broader concern of CAIS has been to situate these models in their social, historical, and cultural contexts <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>  <sup id="fnref2:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>  <sup id="fnref1:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>  <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. Linking model architecture to context — whether that be use case, domain of implementation, or institutional setting — has thus allowed CAIS to pose crucial questions about the ethics and politics of machine learning systems. So too CCS has endeavored to engage both the socio-historical dimensions and effects of programming code, also with structural transformation as a hoped-for endgame <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. What remains to be done, and what is in part the purpose of our essay, is to test both the feasibility as well as the critical potential of CCS as a method when the object of study is deep learning code.</p>
<p>This then is our cue to take a closer look at one of the central terms for this analysis: code. While the discipline of Computer Science classifies different algorithms according to their composition and behavior (e.g. binary search, breadth-first search, insertion sort), there is no master deep learning algorithm, apart from frequently-used algorithms like backpropagation and domain-specific optimization procedures like gradient descent <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>  <sup id="fnref2:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. Deep learning code, then, is not homogenous or singular, a point underscored by the many iterations of single models, e.g. the GPT and DALL-E series. In the popular imaginary, deep learning, or AI as a cultural technique, might seem to adhere to the  “myth of unitary simplicity and computational purity”   <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, but in actual practice it is a collection of disparate processes that work toward the  “production of prediction”   <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.</p>
<p>Along these lines, Mackenzie has written of the difficulty of locating the difference between a game console and something like Google’s AlphaGo in program code, suggesting that researchers must look elsewhere to understand the particularities of a machine learning system <sup id="fnref3:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. He then goes further to articulate a limit for CCS that we accept as a challenge:  “the writing performed by machine learners,”  he contests,  “cannot be read textually or procedurally as programs might be read.”  This is the case, he notes, because  “the learning or making by learning is far from homogenous, stable, or automatic in practice”   <sup id="fnref4:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. That CCS as a method is somewhat mismatched or misaligned with technical objects whose behavior is defined by numerical parameters and vectors rather than logical symbols is further evinced by Jenna Burrell’s audit of the code of a spam filtering model: as that audit exercise illustrates, seeking to understand the rationale for classification decisions inevitably imposes  “a process of human interpretive reasoning on a mathematical process of statistical optimization”   <sup id="fnref1:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>  Deep learning objects that entail parallel processes and training schemes may indeed be challenging to read procedurally as CCS might read JavaScript; however, as we will endeavor to demonstrate, they can nonetheless be read textually and separately from their operations and mathematical foundations.</p>
<p>The common understanding of deep learning code is that it is an implementation of a deep learning model and ancillary functions that support the model, written in a specific programming language. Within the scope of our paper, these models are taken to be deep neural networks, specifically the Transformer architecture <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. In what follows, we will extract a representational map of a particular deep learning model with an open GitHub repository — GPT-2 — based on a close reading of two classes of code, that which pertains to the model and that which underwrites applications, thus countering the notion that deep learning code is uniform and homogenous. This representational map will in turn draw attention to the means by which we might oversee, interact with, and even direct the behavior of deep learning systems, and by extension both empirically rebut the fantasy of model sentience and demystify some of the auratic mystery of AI. To test our theory, we present case studies of two popular GPT-2 applications — the text adventure game,  <em>AI Dungeon</em> , and the conceptual artwork,  <em>This Word Does Not Exist</em>  — both of which demonstrate the interplay between what we will articulate as two classes of deep learning code.</p>
<h2 id="2-mapping-deep-learning-code">2. Mapping Deep Learning Code</h2>




























<figure ><img loading="lazy" alt="A GitHub commit with five Python files" src="/dhqwords/vol/17/2/000684/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure02_hu6862971868b8db225a460f0749e2941f_18480_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure02_hu6862971868b8db225a460f0749e2941f_18480_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure02.png 912w" 
     class="landscape"
     ><figcaption>
        <p>GPT-2’s source files in alphabetical order within its GitHub repository
        </p>
    </figcaption>
</figure>
<p>Our critical study of GPT-2’s source code begins with its GitHub repository and a classification of its code (Figure 2). Contained in the repository is a README summary, as well as a creative license, requirements file, and a source code folder containing five separate Python files: (1) model.py, as its name suggests, is the kernel of language models such as the GPT series, and it contains functions that define hyperparameters, softmax transformations, attention heads, and a number of familiar deep learning operations; (2) sample.py, also as its name suggests, samples a sequence of text from the model; (3) encoder.py both tokenizes text for model input and decodes text from model output; (4) interactive_conditional_samples.py generates samples with an initial prompt; and (5) generate_unconditional_samples.py generates samples without an initial prompt.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>  Deep learning code, like other software systems, can be metaphorically conceived in terms of layers: the model layer that defines the deep learning model and the application layer that primarily interacts with users or external software. Conceptually straddling the model and application layers are sample.py and encoder.py, which perform mediating functions that will become more evident in our subsequent discussion of GPT-2. (These latter functions are harder to classify because it remains an open question whether code that samples text from the model or encodes user input and decodes model output is considered part of the model or ancillary functions that support it.) What is somewhat surprising — and what in hindsight might have tempered the feverish reaction to ChatGPT in late 2022, had the chatbot been primarily understood as an application or interface — is that there is as yet no common taxonomy or representational map that differentiates the functions and structures representative of deep learning from the functions and structures that are integral, but not particular, to the implementation of deep learning models.</p>
<p>To that end, we will articulate as a heuristic a practical and conceptual distinction between two classes of code: core deep learning code (CDLC), kernel code that defines the deep learning model, and ancillary deep learning code (ADLC), ancillary or application code that ordinary developers can replace.  <em>Core</em>  deep learning code, of which model.py is the obvious primary instance, has an ordinary and domain-specific meaning: it produces machine learning predictions by implementing deep learning operations.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>  Hence, core encompasses core data structures and functions that directly execute core deep learning tasks such as classification or regression. In contrast, the remaining files in the source code folder operationalize the model’s outputs rather than directly contribute to its predictive functioning. They are in this respect ancillary, querying or indirectly supporting the model from an external location and, in the case of GPT-2, acting as interfaces that mediate between user requests and deep learning predictions (e.g. specifying and wrangling behaviors, or filtering outputs, as with the aggregating of individual predictions into the composite form of a news article, poem, recipe, or adventure game).</p>
<p>In this paper, we primarily consider the significance of ancillary code as a post-prediction apparatus, that is, code that is run after a prediction has been made. However, it is important to emphasize that ancillary code surrounds the model, and can thus also interact with the model at the start of the production of prediction. As we will explain, code such as the web scraper that was used to generate GPT-2’s training data might also be considered as pre-prediction ancillary code with its own politics and significance. Although web scrapers can be used for tasks other than compiling training data, those that are used for this purpose are situated within the context of deep learning, and hence can also be considered deep learning code.</p>
<p>Our delineation of the two classes of code is motivated by their distinct empirical and theoretical properties. Thus, while deep learning code is often regarded as uniform, even basic — Mackenzie, for example, defines standard machine learning code as  “familiar, generic programming”  that is  “hardly ever hermetically opaque”  — our analysis complicates this characterization <sup id="fnref5:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. To start, we note that CDLC and ADLC emerge from, and to some degree reflect, different computing practices: artificial intelligence (AI) on the one hand and software development on the other. While CDLC is informed by the development of rules for  “modifying the connection strengths in simulated networks of artificial neurons”   <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>, as well as specialized hardware and software libraries capable of efficiently performing repetitive matrix operations (most notably, AI-accelerated hardware from NVIDIA and Google and software libraries such as Tensorflow and Keras), ADLC in contrast draws from a rich history of web development, APIs, and user interface design, depending on the form that it takes (e.g. a web application that allows users to chat with GPT-2, or an API that allows programmers to send requests to GPT-3 for prediction). Given these different historical trajectories, there is enough of a practical difference to explain why CDLC and ADLC seem in their programming conventions, vocabularies, and syntax almost to be different languages, both in their look and how they are read. In a nutshell: whereas the complexity of CDLC stems from the complexity of machine learning structures such as neural networks and procedures such as backpropagation, the complexity of ADLC arises from what it does with the machine learning output, such as integrating the outputs into other complex systems — for our purposes, a GPT-2-powered web app that needs to be accessed concurrently by thousands of users. A textual comparison of model.py (CDLC) and interactive_conditional_samples.py (ADLC) in GPT-2 will help reinforce the distinction.</p>
<p>Whereas interactive_conditional_samples.py defines a single function with a specific purpose, model.py in contrast is filled with functions that contain numerous technical and mathematical operations whose meanings may not be initially obvious to non-programmers. Although interactive_conditional_samples.py starts out with a fair bit of technical setup code, its main loop (lines 72 - 88) clearly communicates the module’s purpose. The module prompts for and saves user input into a variable named raw_text (line 73), encodes (line 77) and feeds it to the model (lines 80 - 82), and decodes (line 85) and prints the output iteratively (lines 86 - 87) (Figure 3). The translational work ADLC does here is facilitated by the presence of built-in Python functions (input, print) and intuitively-named functions (encode, decode). In fact, this syntactic composition is what marks ADLC as such. This generic program is easy to understand in GPT-2’s case because it executes basic operations while outsourcing the predictive work to model.py, which handles the complex deep learning work.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>  We can then, to a certain extent, imagine the execution of interactive_conditional_samples.py as we read the code.</p>




























<figure ><img loading="lazy" alt="Several lines of code in an editor" src="/dhqwords/vol/17/2/000684/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure03_hu503058b2c1939f48ba8da773a65f5bcd_33210_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure03_hu503058b2c1939f48ba8da773a65f5bcd_33210_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure03.png 614w" 
     class="portrait"
     ><figcaption>
        <p>Snippet of interactive_conditional_samples.py
        </p>
    </figcaption>
</figure>
<p>In contrast, model.py itself has a complex structure and vocabulary that makes comprehension, and interpretation, especially demanding. The imaginative exercise for the execution of model.py’s predictive process is more challenging due to its dependence on vast arrays of numbers and their complex interactions. In addition, at any one time the model could conceivably be in several different possible states as determined by its weights, leading to different outputs given a particular input.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>  The code looks significantly different from interactive_conditional_samples.py because of its almost exclusive dependence on Tensorflow, Google Brain’s machine learning library, which features a host of abstruse-sounding functions, the relative obscurity of which is a necessary product of their specialized and optimized functioning. The relative illegibility of GPT-2’s CDLC can partly be attributed to the developers’ programming style and the demanding requirements of production code. GPT-2 was written not as a hobbyist project but as a service provider for numerous applications, so while it could have been written using many more loops and basic data structures, it would then have taken much longer to train and run. Nevertheless, we can see that the file is arranged into a series of Python functions (softmax, norm, attention_mask, etc.) and smaller data structures that together form the network representation of GPT-2. We can also review the code and derive a sense of the operations being performed (e.g. matrix multiplication, reshapes), but the calculations being performed would be too massive for any one person to parse. Even if a reader were familiar with the functions, in other words, GPT-2 is better studied through its mathematical formulation than through its implementation. Consider, for example, the line of code  “0.5<em>x</em>(1+tf.tanh(np.sqrt(2/np.pi)<em>(x+0.044715</em>tf.pow(x, 3))))”  to describe GELU (an activating function frequently used in neural networks), which is much easier to parse if read as a math formula.</p>
<p>The complexity of model.py, and more broadly the inability to fully examine its execution, does not however mean that one cannot study the intricacies of deep learning systems, either technically or critically. For this purpose, we can take a cue from computer science and apply the concept of abstraction to our analysis. Because fundamental deep learning operations such as vectorization, learning, and gradient descent exist in the mathematical abstract without programming implementation, it is possible to talk about them without citing the underlying code.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>  One could make the argument that all computer code subtends abstract math, but the challenge of understanding CDLC has meant that abstraction has almost necessarily been at the core of the study of deep learning operations. For example, research on machine learning models has thus far focused on the diagram <sup id="fnref6:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>, vectorization <sup id="fnref2:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>, learning <sup id="fnref3:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>, and pattern recognition <sup id="fnref3:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  <sup id="fnref4:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. In contrast, the abstract counterpart of ADLC is not prominently featured in analyses of deep learning. Put another way, the possibility of analyzing model.py and its operations analogically and metaphorically has already been proven by extensive qualitative engagement with deep learning. While we by no means wish to dismiss or even contest the project of CAIS — abstracting deep learning operations is after all foundational to the work of interpretation — we can nonetheless ask what is missed if researchers only focus on training data, model architecture, and the abstraction of deep learning code.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup></p>
<p>Although we have suggested that ADLC looks like generic programming, it is important to note that its substance and significance differs by operational context. As a thought experiment, consider the loop, the signature feature of which, as Wilfried Hou Je Bek explains,  “is the minimal means that result in automated infinite production”   <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>. This infinite production is trivial in the context of a small computer program that prints out numbers from one to ten, and has historical precedents in automation and mechanical reproduction, but takes on a more sinister value in the contexts of disinformation, hate speech, or even autonomous weaponry. These then are the stakes for a CCS analysis of ancillary deep learning code, which operates outside the periphery of a deep learning model but is fundamental to its operation.</p>
<p>Our premise, then, is that analysis grounded in code citation has perhaps too quickly been deemed inessential to the work of understanding and engaging artificial intelligence. More specifically, our suggestion is that ADLC is productive terrain for critical and creative engagement, not least because its structure, logic, and syntactic form is closer to human language than CDLC.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>  While the predictive outputs of CDLC, particularly model.py, are in the form of unprocessed numerical data, ADLC does the heavy lifting of translating and assigning meaning to that numerical data.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>  Because CDLC replicates or maps mathematical formulas and deep learning concepts (e.g. code that implements a layer of a neural network), the interpretive work is seemingly limited to the implementation details, as in the choice of framework or programming language. ADLC, on the other hand, can be used to interpret and manipulate the raw output in seemingly unlimited ways, and it is this creative and ethicopolitical potential that makes it a particularly fertile area for CCS analysis. In the following sections, we trace examples of ADLC doing this transformative work with increasing levels of complexity and identify two of its major functions in the context of a text adventure game and a fictional dictionary: structuring the output from GPT-2 and constructing interfaces that mediate between the user and the language model.</p>
<p>Our analysis starts with a closer look at GPT-2’s ADLC to help illustrate the argument and suggest possibilities of thinking both logically and intuitively about it. ADLC is an accessible, and replaceable, component of GPT-2’s source. Removing the two files, generate_unconditional_samples.py and interactive_conditional_samples.py, would thus not affect GPT-2’s production of prediction, and in fact most forks of GPT-2’s source code replace the files with the programmer’s own interface. If considered in relation to word vectors and the attention mechanism, generate_unconditional_samples.py’s printing of GPT-2’s outputs might be regarded as a somewhat fundamental and trivial operation. But printing GPT-2’s output is only one implementation of ADLC’s mediation between user prompts and parameters (length of sample, number of samples, randomness) and model parameters (length, nsamples, temperature) — and other implementations, other forms of interaction, as we will outline, are both more interesting and more generative. Regarding GPT-2 as an interactive system rather than an algorithm, with ADLC as the front-facing interface for an underlying language model, allows us to explore the possibilities as well as limits of ADLC with respect to controlling GPT-2’s behaviors. That is, the behavior of GPT-2, as the user experiences it, can be understood to be configured by its myriad interfaces rather than its internal predictive logic engine, which is itself only limited to one behavior: text generation. These interfaces extend GPT-2’s behavioral capacity and transform text generation into media generation, interactive entertainment, and collaborative writing. Put another way, although GPT-2 is a language model that generates text sequences, it takes specific examples of ADLC in order for GPT-2 to function as a news writer, dungeon master, chat bot, or language artist, as it is imagined to do for  <em>AI Dungeon</em> ,  <em>This Word Does Not Exist</em> , and many other applications besides.</p>
<p>It is perhaps an understatement to note that the playful quality of these two applications is somewhat at odds with the instrumentalist quality of GPT-2’s ADLC. For a field such as CCS, which has historically been attuned to the rhetorical properties of code and to what makes it interesting as a cultural artifact — not only its literariness and humor but also its political potential, one excellent example of which is the CCS working group’s discussion of gender and <a href="http://wg20.criticalcodestudies.com/index.php?p=/discussion/18/week-1-colossus-and-luminary-the-apollo-11-guidance-computer-agc-code">The Apollo 11 Guidance Computer (AGC) Code</a> — the relative dryness of GPT-2’s source might initially cause some perplexity. There are no unreadable texts, to be sure, but there might seem to be limits to what can be said about numerical data and code that bears no traces of programmer whimsy and is absent not only of cultural references, in-jokes, and easter eggs, but also of manifest traces of authorship and subjectivity, apart from the occasional typographical error. Counter-intuitive as it may seem, however, even a snippet of ADLC can be remarkably generative. If, for example, the code for a mobile phone application can be read as an instantiation of an argument about immigration and border politics <sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>, we might by extension consider how a line such as  “if 0, continues to generate samples [indefinitely]”  opens up philosophical and political questions of control.</p>




























<figure ><img loading="lazy" alt="a code snippet reading “:nsamples=0 : Number of samples to return, if 0, continues to generate samples indefinitely.&#34;”" src="/dhqwords/vol/17/2/000684/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure04_hu77ffdc1d67d28e1d37513c839889bc30_2296_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure04_hu77ffdc1d67d28e1d37513c839889bc30_2296_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure04.png 427w" 
     class="landscape"
     ><figcaption>
        <p>Snippet in the sample_model function within generate_unconditional_samples.py
        </p>
    </figcaption>
</figure>
<p>This snippet of generate_unconditional_samples.py comes from the function sample_model’s docstring and explains how the nsamples parameter is used to specify the number of samples that GPT-2 generates (Figure 4).<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>  Dictated by Python conventions, a docstring is a block of text nested within a function that acts as an explanatory summary, and thus can be studied under the same critical apparatus as software paratexts and code comments <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>  <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. The snippet is taken from the file, generate_unconditional_samples.py, which allows for the most rudimentary form of interaction between a user and GPT-2. After configuring a few parameters such as random seed, model size, and length and number of samples to generate, and then executing the program, generate_unconditional_samples.py will continue to print samples to the console in the format below until the maximum number of samples specified is reached (Figure 5).</p>




























<figure ><img loading="lazy" alt="Two samples of outputs" src="/dhqwords/vol/17/2/000684/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure05_hucfc5c65fae06b4892027db6a5e9ddf83_67406_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure05_hucfc5c65fae06b4892027db6a5e9ddf83_67406_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure05_hucfc5c65fae06b4892027db6a5e9ddf83_67406_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000684/resources/images/figure05.png 1343w" 
     class="landscape"
     ><figcaption>
        <p>Reconstruction of GPT-2’s outputs printed to the console
        </p>
    </figcaption>
</figure>
<p>This prescribed limit is particularly suggestive because the original developers effectively designed a way for it to be circumvented. As line 70 of the code indicates, GPT-2 will continue to predict and print samples unless one of two conditions is true: (1) the number of samples generated exceeds the nsamples limit or (2) the nsamples limit supplied is zero (Figure 6). Thus, if nsamples were zero, GPT-2 would print samples indefinitely until interrupted by the user’s keyboard, memory depletion, or power loss.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>  (The parallels with Stanislaw Lem and Trurl’s machines write themselves.)</p>




























<figure ><img loading="lazy" alt="A lengthy snippet of code" src="/dhqwords/vol/17/2/000684/resources/images/figure06.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure06_hu3cc2991d837887737974edfb0bd6023a_74010_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure06_hu3cc2991d837887737974edfb0bd6023a_74010_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure06.png 426w" 
     class="portrait"
     ><figcaption>
        <p>Snippet of generate_unconditional_samples.py
        </p>
    </figcaption>
</figure>
<p>Nevertheless, the irony of zero as a limit for infinite generation has the effect of drawing our attention to the crux of the matter: the point at which human action affects — or fails to affect — machine behavior. In this particular instance, the interaction with GPT-2 is not only limited but essentially one sided; in technically imprecise terms, it amounts to start the machine and let it run. It might even be conceived as a contemporary iteration of the  “Hello, World!”  program, with the text passed onto the print function generated by another function (GPT-2) rather than a human. It is perhaps an obvious point but one that bears repeating: interactions between humans and machine learning systems cannot and should not take this form.</p>
<p>If restricted human action is suggested by the syntax of the file name, generate unconditional, then interactive unconditional might seem in turn to promise a more substantive mode of engagement than mere behavior initiation. Indeed, interactive_unconditional_samples.py does make it possible for users to interact and have a degree of influence over GPT-2’s predictions, in that several lines of this code allow users to input a phrase or sentence of their choosing for the model to complete. But here too action is limited, in this instance to the production of single-use seed text: thus, type the quick brown fox and then wait for the output. GPT-2 will attempt to follow from the prompt and complete the sentence as many times as specified, but each iteration is distinct in that the user needs to prompt the model with more seed text and the model will not take prior input into account when generating further text. While the call-and-response structure of an interaction, for example, might seem to suggest a balance of forces, and even a kind of mutuality between human and machine, the process is better thought of in terms of input-output, with all its connotations of routinized, mechanized, even roboticized action.<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>  It is in other words cooperative writing only in the rudimentary sense that there are at least two actants generating words in sequence.</p>
<p>We can now shift our attention to the degree with which generate_unconditional_samples.py and interactive_conditional_samples.py transform the language model’s numerical output and remark on their equally basic operation. (For economy, we restrict our attention to generate_unconditional_samples.py, as the analysis applies to both.) After querying the model and receiving the results, generate_unconditional_samples saves the output to a variable succinctly named out on line 71. At this point, the data contained in out would be meaningless to readers because it is still numerical; that is, each individual token in the output string is still encoded as numbers. In order to transform the data to readable text, it must then be passed to a decoder on line 74, at which point the decoding mechanism housed within encoder.py looks up a dictionary entry to map the numerical tokens back to their textual counterparts (Figure 7). Although the translational work here is non-trivial — readers cannot otherwise parse GPT-2’s output — the operation itself is basic and limited to dictionary queries. It is though of course possible to use ADLC to perform more complex transformations after the decoding stage to more dramatically alter GPT-2’s output, as we shall outline.</p>




























<figure ><img loading="lazy" alt="several lines of code" src="/dhqwords/vol/17/2/000684/resources/images/figure07.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure07_hud6f10a7b9ce4867e31391ba2fe539d5d_5780_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure07_hud6f10a7b9ce4867e31391ba2fe539d5d_5780_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure07.png 209w" 
     class="landscape"
     ><figcaption>
        <p>Representative entries in the dictionary used for encoding and decoding. After the special unicode token, \u0120, the words are followed by their numerical ID.
        </p>
    </figcaption>
</figure>
<p>This deep dive into GPT-2’s GitHub repository and analysis of its ADLC has thus far not specified the  <em>which</em>  and the  <em>when</em>  — all-important delimiters for a language model that came to fame in part because of its staged release <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. We have hinted at the reconstruction required to look back and analyze the experience of what it was like to interact with GPT-2 in 2019 and can now be more explicit about the archaeological work one has to do in order to analyze the model in the present. What we have studied thus far is an almost-exact snapshot of the ADLC as it appeared in the first release in 2019, a picture that represents OpenAI’s initial vision and its open invitation to developers to explore the limits of GPT-2’s behavior. The intervening years have seen a number of changes, not only to GPT-2 but also to its dependencies. Tensorflow, for example, has evolved to such an extent that much of the code of GPT-2 will not work unless updated to align with Tensorflow’s new protocols. Even more important to the running of the original GPT-2 model are the weights, which must be downloaded via download_model.py in order for the model to execute. Thus, one could envision a future CCS scholar, or even ordinary user, attempting to read GPT-2 without the weights and finding the analytical exercise to be radically limited, akin to excavating a machine without an energy source from the graveyard of <a href="http://www.alamut.com/subj/artiface/deadMedia/dM_Manifesto.html">dead media</a>.</p>
<p>With an analysis of interactive_conditional_samples.py, we seem to have come to a fork in the road of developer engagements with GPT-2’s source code. We have mapped its structure and identified the prescribed interfaces through which the model interacts with the world, observing the relatively basic means by which GPT-2’s ADLC transforms the raw output and constructs the interaction medium. The next step takes us outside the repository so we may consider how the circulation of GPT-2’s source code generated new instances of ADLC that in turn morphed into new interfaces for interaction and new forms of management, regulation, and control.</p>
<h2 id="3-applications-of-gpt-2">3. Applications of GPT-2</h2>
<p>GPT-2 can be described in basic terms as a computational procedure that takes a vectorized token (a textual unit) as input and outputs a corresponding vector of token probabilities. Extensive user engagement, however, has transformed the language model into an interactive object whose function extends well beyond the production of deep learning prediction.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>  The story of the staged release of GPT-2 is at this point perhaps well known: it proceeds from the debut of the partial model (117m parameters) in February 2019, its fanfare fueled both by the fantastic tale of Ovid’s unicorn as well as the suggestion that it performed too well and thus needed to be guarded against malicious use through the withholding of the full 1.5b parameter model <sup id="fnref1:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. Because the release was open source and the technological barrier for interaction relatively low, the announcement of GPT-2 as a better model was a siren song that lured users of all capacities into a range of experiments to test its capacities and the code went into widespread circulation. The release then was a textbook instance of a computational object moving from the  “clean room of the algorithm”  to the  “wild, tainted and unpredictable space of dynamic and shared environment”   <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>. Marino narrates such a trajectory in related terms, writing of his realization that he needed to  “take code out of the black box and explore the way its complex and unique sign systems make meaning as it circulates through varied contexts”   <sup id="fnref2:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. In the case of GPT-2, much of the enthusiasm driving circulation derived from experiments with fine-tuning, the process of editing GPT-2’s internal weights by training it on specific texts so that it can better emulate them. Fine-tuning alters the CDLC and might be thought as a form of technical speculation (e.g. altering the parameters and the training data). Although we will not elaborate on how fine-tuning affects the model, as we shall see shortly, the process plays an important role in enabling  <em>This Word Does Not Exist</em>  to generate fictitious dictionary entries. Our concern will be a more expressive and conceptual form of speculation, in the guise of transforming ADLC and developing different interfaces that allow for a modicum of control over GPT-2.</p>
<p>Perhaps the most organic extensions of the form of interaction made possible by interactive_conditional_samples.py are projects that configure GPT-2 as a writing assistant. Interactive writing platforms such as  “<a href="https://transformer.huggingface.co">Write With Transformer</a>”  situate GPT-2 in an auxiliary role as a kind of editor, queueing up the model to autocomplete the user’s input text, and thus reaffirm a hierarchy of labor (it is after all the user who writes with GPT-2). TabNine, which hooks into conventional code editors like Visual Studios Code, is particularly notable in this regard in that GPT-2 is pulled into an authoring environment in which the user can direct its operations, as opposed to writing with GPT-2 within its source code. While certainly functional, these examples are precisely and even only that: although there is a certain degree of fine-tuning that takes place to shape GPT-2’s output, the language model’s output is precisely replicated for the user without any addition modifications that might otherwise improve its quality (which we have already seen with generate_unconditional_samples.py and interactive_conditional_samples.py). For more imaginative work with ADLC that treats GPT-2’s output not as plain text but as poetic material, and interaction not as a basic chatbot session but as something more like an expansive  <em>Dungeons &amp; Dragons</em>  session, we turn to  <em>AI Dungeon</em>  and  <em>This Word Does Not Exist</em> , two of many implementations that demonstrate the transformative work of developers outside of OpenAI and attest to the vibrancy and collaborative spirit of the NLP community writ large.</p>
<p>Originating in a college hackathon project,  <em>AI Dungeon</em>  is built on a version of the GPT-2 model fine-tuned on a corpus of choose-your-own-adventure stories. While we have elsewhere elaborated on the game’s provision of a framework for evaluating language models and its status as a paradigmatic instance of citizen NLP, for this analysis we wish to highlight the political and aesthetic potential of the commands available on the game’s interface as they are articulated by ADLC <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. Particularly when viewed in relation to the modes of interaction we have here been charting, game commands like remember,  revert, and alter serve as potent examples of true collaboration between human users and deep learning models. To start, we return to the GitHub repository for an earlier version of  <em>AI Dungeon</em> , in order to highlight the ADLC responsible for the game interface <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>. Within the repository, there is a copy of the GPT-2 model in the generator folder, which also contains CTRL, another language model with which the game was experimenting. The GPT-2 in this generator folder is almost a mirror copy of the one in the original GPT-2 repository, apart for the notable absence of the aforementioned ADLC modules — generate_unconditional and interactive_conditional — which have here been replaced by play.py, a more expressive form of ADLC structured as a text adventure game that feeds user inputs to a language model for the response.</p>
<p>play.py contains code that prints out a splash image of the game’s title and sets up the archetypical &gt; delimiter awaiting user input. The module initiates an iterative gameplay loop whereby the underlying language model narrates a story, awaits for user input in the linguistic form of actions or game commands, processes the input, and then returns the next portion of the story. The call-and-response loop with GPT-2 is familiar, but with subtle differences: play.py calls GPT-2 via two wrappers that extend the language model’s functionality on lines 175 and 176. Called on line 175, GPT2Generator essentially mimics generate_unconditional_samples.py or interactive_conditional_samples.py by processing the user input and querying the underlying language model. However, GPT2Generator extends the language model’s functionality by doing some post-processing work such as removing trailing sentences, converting the output into the second person, correcting punctuation (at line 85 in gpt2_generator.py, it moves periods outside quotation marks), and filtering so-termed bad words. What GPT2Generator does then is somewhat inexactly shape the model’s output to bring it more in line with contemporary linguistic protocols and the generic conventions of a text adventure game. The second wrapper, StoryManager, is built on top of GPT2Generator and does the work that its name suggests: past events generated by GPT-2 and the player’s actions are strung together and maintained in memory, constituting a story.</p>
<p>While work that play.py does to transform or translate the raw output from GPT-2 into the form of a text adventure game is fundamental, we find even more compelling the use of ADLC to extend the underlying language model’s functionality and radically reimagine our interaction with it. Of particular note are those mechanics that, true to the form of a game, prompt incremental action and in so doing emphasize collaboration and revision. Remember, for example, is an experimental command allowing players to embed pieces of information that are constantly fed into GPT-2 at each step of the prediction and thus emulate a loose memory for the AI narrator. Revert functions as a kind of rewind and allows players to return to any step in the preceding narrative. Alter, perhaps the most dramatic of the three, allows for a complete edit of the AI’s predictions at each step, offering players the remarkable ability to address and fix predictions, as opposed to prompting the model to produce a new prediction from scratch, as if no lessons had been learned. While these commands all give some indication of the expressive capacity of next-gen text generators and advance the development of different modes of human-AI interaction, what is especially germane to our discussion are the processes and conditions that made them possible in the first place.</p>
<p>Notably, such creative work is enabled by very basic programming constructs. Conditional statements on lines 233 to line 320 in play.py determine what command the user wants to take (e.g. elif command == revert). Within these conditional statements, rudimentary operations are creatively exploited to mimic advanced behaviors; for example, reverting a game step is as simple as decrementing an index within the story manager’s memory. Other complex mechanics like alter might be enabled by more complex functions, but what we highlight here is the relatively low bar for engagement with language models and deep learning application development. In the case of  <em>AI Dungeon</em> , almost all of the extra behaviors for the game stem from commands coded in play.py, an instance of ADLC in the  “wild”   <sup id="fnref1:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> and the means by which developers of all abilities, including those who are not specialists in machine learning, can tinker with GPT-2, manipulate its outputs, and more broadly operationalize the model so that it serves as a medium for creative production.<sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>  Improving GPT-2, or any deep learning model, certainly depends on the modification of model architecture and the development of further training data, but the work done with play.py suggests that ADLC is a no less meaningful means by which to direct the model’s functioning — all the more so because it is a technique and tool available to ordinary users.</p>
<p>Borrowing its title from the notorious deep fake application,  <em>This Person Does Not Exist</em> ,  <em>This Word Does Not Exist</em>  (TWDNE) serves as a further example of the creative capacities of ADLC, as well as, not coincidentally, the discursive framing of GPT-2 as  “dangerous”   <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>. Generating a faux lexicography requires two steps: conditioning (fine-tuning) the model and post-processing the output. Conditioning starts with urban_dictionary_scraper.py, which, as its name suggests, scrapes Urban Dictionary and formats the information into a data structure that corresponds to a dictionary entry <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>. The function _parse_definition_div then scrapes the site using the common method of searching for HTML elements corresponding to the specified information — in this instance, finding the location of the word’s definition and then looking for HTML elements with an attribute appropriately named meaning. Once all the relevant information is extracted, it is inserted into a data structure that organizes the information for final compilation into a fine-tuning dataset (Figure 8).</p>




























<figure ><img loading="lazy" alt="A code snippet" src="/dhqwords/vol/17/2/000684/resources/images/figure08.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure08_hu8a0910c0fdccca299a3c0bb92ed4e870_7649_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure08_hu8a0910c0fdccca299a3c0bb92ed4e870_7649_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure08.png 284w" 
     class="landscape"
     ><figcaption>
        <p>The data structure that constitutes a dictionary entry
        </p>
    </figcaption>
</figure>
<p>After the relevant dictionary entries are scraped, they are collated and formatted in train.py into a training dataset used to fine-tune GPT-2. Of note in this process is the clever communication protocol that facilitates information extraction down the line. On line 903 in train.py, special tokens (&lt;|bod|&gt;, &lt;|pos|&gt;, &lt;|bd|&gt;, &lt;|be|&gt;, &lt;|pad|&gt;) are inserted and divide the training instances (i.e. a word and relevant information like its definition) into informational chunks. In this way, GPT-2 is conditioned to generate strings of text that have the embedded structure of a dictionary entry, with a word, part of speech, definition, and exemplary usage.</p>
<p>The embedded structure is evident in the example of the custom generation of the fictitious word, cochiadiography, which begins with word_generator.py to gather user input and initialize parameters, and then datasets.py to call on GPT-2 for text generation on line 567 (GPT-2 is here also enclosed in a wrapper class that extends its functionality):</p>
<p>&lt;|bod|&gt;cochiadiography&lt;|pos|&gt;noun&lt;|bd|&gt;art and literature relating to these matters.&lt;|be|&gt;students found their fair share of mistakes in the present work, with students undertaking someCochiadiography&lt;|eod|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;&lt;|pad|&gt;</p>
<p>In this sample, we see that the relevant information is cleverly separated by artificial delimiters designed by the programmer. After the raw output is generated, a pattern matching process starting on line 586 of datasets.py further decodes the output. (Note that this human-readable string implies that a decoding step that was highlighted in generate_unconditional_samples.py has already taken place.) On this line, the output is matched against a predefined pattern to identify the aforementioned special tokens that articulate the information in a dictionary entry, as well as information nestled between the tokens (with this specification, the &lt;|pad|&gt; token will be regarded as meaningless and discarded). Next, another pattern matching function (group) parses the successful string to extract the different pieces of information and save them to separate variables. At this point, other post-processing measures akin to those used by  _AI Dungeon _ are in play, notably among them the filters that catch and remove objectionable content.</p>
<p>Removing profanity from  <em>AI Dungeon</em>  is a basic operation by no means particular to deep learning: unless censorship is toggled off, output from GPT-2 is passed to the aptly named remove_profanity function, which relies on an external module, also aptly named <a href="https://github.com/areebbeigh/profanityfilter/blob/master/profanityfilter/profanityfilter.py">ProfanityFilter</a>, to replace words appearing on a custom censor list with strings of the * character. That there is something inherently subjective and even arbitrary about a list of 114 profane words should be evident from the start but further evinced by the presence of goddamned; that there is something blunt about the operation is evinced by the use of the Python re (regular expression) for basic find-and-replace. More suggestive because more intricate is TWDNE’s screening for hate speech with a custom blacklist of some 5,763,399 words and phrases that begins as follows when a set of blacklisted words is loaded (Figure 9):</p>




























<figure ><img loading="lazy" alt="A long list of words and symbols with some spacing errors between words" src="/dhqwords/vol/17/2/000684/resources/images/figure09.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure09_hu13ea26ceba131c439bb26e461c6f242e_80733_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure09_hu13ea26ceba131c439bb26e461c6f242e_80733_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure09.png 867w" 
     class="landscape"
     ><figcaption>
        <p>TWDNE’s blacklist
        </p>
    </figcaption>
</figure>
<p>What garbage conceptual poetry is this, a reader might ask, and they would not be wrong to wonder at the sourcing and means by which such a text file would be generated. The atrocities grossly alluded to at the outset ( “killing and scalping” ) are clear enough, and reference to Levin Tilmon writing to Abraham Lincoln in 1861 about the composition of the Union forces might lead one to surmise that the filter flags all content related to the U.S. Civil War, but what exactly happened in Malta in February 1960, and would this determination necessitate a deep dive into the fevered swamps of 4chan’s /pol/ board, or at least a passing familiarity with contemporary conspiracy theory?<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>  And what to do with  “more complex,”  also a delimited token, much less  “and guards” ? What taboo subjects or language do these expressions index and why should they be subject to content moderation? Both the content and the form of the .txt file, with all of the liberties taken therein with punctuation and spelling, suggest that the list results from either model training or finetuning, with  “and guards”  perhaps appearing, who knows, in an Urban Dictionary entry that also mentions the Holocaust (and indeed the paradigmatic logic of machine learning — correlationism — is here very much on display). To use the Saussurean framework, we might note then that ADLC not only resituates numerical data within the realm of langue (a syntactical, rules-based conception of language), as we have seen with the decoding mechanism in generate_unconditional_samples.py, but in the case of bad word filters, it also manifestly pulls that output into the realm of parole (gesturing toward, if not always adhering to, social conventions in its treating of certain words and concepts as taboo).</p>
<p>Regardless of the precise mode of composition of the blacklist used by the faux lexicographic application, its arbitrariness is evinced by our discovery of the word, bastardistic (Figure 10). Like cochiadiography,  bastardistic began as a string generated by the language model. To borrow terms from TWDNE’s template, that string was then  “invented, defined and used”  as a word — more properly, translated into a word — by datasets.py and not filtered by the blacklist, a process that opens up another meaning of the project’s title. It is not simply that bastardistic is a representative word that does not exist, but that the application is not actually outputting words; what is at work, in other words, is not language generation, but rather function returns. Good output, by whatever metric, might summon the fantasy of model sentience, but this is easily countered by an interface such as TWDNE, which engineers the output in a manner that exposes GPT-2 as a mere function returning four pieces of structured lexicographic data.</p>




























<figure ><img loading="lazy" alt="Definition of the fake word bastardistic" src="/dhqwords/vol/17/2/000684/resources/images/figure10.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000684/resources/images/figure10_hu7b037cbb05257ed034ef10087332c5ad_62995_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000684/resources/images/figure10_hu7b037cbb05257ed034ef10087332c5ad_62995_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000684/resources/images/figure10_hu7b037cbb05257ed034ef10087332c5ad_62995_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000684/resources/images/figure10.png 1204w" 
     class="landscape"
     ><figcaption>
        <p>Screen capture from <em>TWDNE</em>
        </p>
    </figcaption>
</figure>
<p>Part of OpenAI’s stated rationale for the withholding of the full model of GPT-2 in February 2019, we recall, was concern about prospective misuse, which would include not only disinformation but also hate speech <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>. There was then and is now work being done at the level of training data and the model (CLDC) to guard against the emergence of another Microsoft Tay, but it is nonetheless left to developers to determine the acceptable parameters of their applications and implementations of GPT-2. Pattern matching, regular expressions, and filtering — all examples of ADLC performing ordinary functions in relation to deep learning objects — are some of the means toward this end. The need for such ad hoc techniques at all stages of the communication pipeline, however, serves as a reminder that the wild expressivity of NLG can take both negative and affirmative form — hence the discourse on risk and responsibility. Whereas generate_unconditional_samples.py in the GPT-2 source code functions with something like complete openness, then, it falls to the ADLC in  <em>AI Dungeon</em>  and  <em>This Word Does Not Exist</em>  to manage and regulate the model’s output.</p>
<h2 id="4-conclusion">4. Conclusion</h2>
<p>Through the developmental arc extending from generate_unconditional_samples.py to  _AI Dungeon _ and  <em>This Word Does Not Exist</em> , we have traced a process of continual modification and refinement of GPT-2’s behavior through distributed engagement, the effect of which has been to bring the model into true cooperative relation. Our analysis of GPT-2’s code has shown that deep learning’s potential for interactivity is embedded within the open-source Python kernel that made widely available the tools for building interfaces that structure user engagement. The open source code also made it possible for developers to identify and then address unacceptable or otherwise faulty behavior — exercises that arguably contribute to a sense of community and collective responsibility. While the source code defining the limits of interaction was written by OpenAI, then, the whole of the code apparatus that we now refer to as  “GPT-2”  was authored by a wide range of developers, from amateurs to academics and professional programmers.<sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>  At some level, the centralization of AI research cannot be contested, not least because of the massive quantities of data available to, because extracted by, companies such as Google, Facebook, Amazon, and OpenAI. But from a different angle the research environment seems far more distributed, with (often) self-trained individuals and institutional actors alike working to refine the behavior of deep learning models.</p>
<p>Future CCS work with language models can continue work with GPT-2 as well as other open-source models such as the permutations of GPT and BERT, BLOOM, CLIP, and DALL-E.<sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>  It can also lend its voice to the conversation about what can and cannot be done with GPT-3’s API and to the request to make the model more easily callable by either external software or non-software products. If the statistical and mathematical foundations of deep learning have meant that qualitative research has almost necessarily had recourse to abstraction, an insistence on code as the object of analysis may advance and sustain humanistic engagement in that textual scholars can meaningfully contribute to the development of analytical frameworks that in turn inform actual research practices. Doing things with deep learning code, then, may very well mean helping to produce another possible future for language models, one that is more open and more available to both creative engagement and critical scrutiny.</p>
<blockquote>
<p>it is difficult to characterize precisely the inductive bias of BACKPROPAGATION learning, because it depends on the interplay between the gradient descent search and the way in which the weight space spans the space of representable functions. However, one can roughly characterize it as  <em>smooth interpolation between data points</em><br>
<sup id="fnref2:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup> Inductive bias, then, is not the answer to the methodological challenge to which we are responding. The problems of interpretability and explainability are also crucial for deep learning, but not within the immediate purview of this paper. For an overview see <sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>  <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>.</p>
</blockquote>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>For example, even though OpenAI’s GPT-3 is now integrated within applications spanning disparate domains and industries, as of this writing it remains accessible to the general public only through an Application Programming Interface (API) <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>, and operationally legible only through experiments done by researchers <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>  <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup> or attempts at replicating its source code <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Johnson, S. (2022)  “A.I. Is Mastering Language. Should We Trust What It Says?” ,  <em>New York Times</em> , 15 April. Available at: <a href="https://www.nytimes.com/2022/04/15/magazine/ai-language.html">https://www.nytimes.com/2022/04/15/magazine/ai-language.html</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://huggingface.co/transformers/bertology.html">BERTology</a> is a field that studies the specific components of language models such as hidden states and weights. Another example of a project endeavoring to explain language models is Ecco, an open-source library for the creation of interfaces that help to explain language models like GPT-2 by illuminating input saliency and neuron activation <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>; a third is <a href="https://ml4a.github.io/ml4a/looking_inside_neural_nets/">Looking inside neural nets</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Montfort, N., et al. (2012)  <em>10 PRINT CHR$(205.5+RND(1));:GOTO 10</em> . MIT Press, Cambridge.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Hua, M. and R. Raley. (2020)  “Playing with Unicorns:  <em>AI Dungeon</em>  and Citizen NLP.”    <em>Digital Humanities Quarterly</em> , 14.4. <a href="/dhqwords/vol/14/4/000533/">http://digitalhumanities.org/dhq/vol/14/4/000533/000533.html</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Mackenzie, A. (2017)  <em>Machine Learners: Archaeology of a Data Practice</em> . MIT Press, Cambridge.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Roberge, J. and Castelle, M. (2021)  <em>The Cultural Life of Machine Learning: An Incursion into Critical AI Studies</em> . Palgrave Macmillan.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Mackenzie, A. (2015)  “The Production of Prediction: What Does Machine Learning Want?”    <em>European Journal of Cultural Studies</em>  18.4-5, 429–445.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Burrell, J. (2016)  “How the Machine  Thinks : Understanding Opacity in Machine Learning Algorithms.”    <em>Big Data &amp; Society</em> , pp. 1–12.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Underwood, T. (2020)  “Machine Learning and Human Perspective.”    <em>PMLA</em>  135.1, pp. 92–109.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Offert, F. (2021)  “Latent Deep Space: GANs in the Sciences.”    <em>Media + Environment</em> .&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Marino, M. (2020)  <em>Critical Code Studies</em> . MIT Press, Cambridge.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Rumelhart, D. et al. (1986)  “Learning Representations by Back-Propagating Errors.”    <em>Nature</em>  323 (October 1986), pp. 533–536.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Bogost, I. (2015)  “The Cathedral of Computation.”    <em>The Atlantic</em> , 15 January. <a href="https://www.theatlantic.com/technology/archive/2015/01/the-cathedral-of-computation/384300/">https://www.theatlantic.com/technology/archive/2015/01/the-cathedral-of-computation/384300/</a>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>For completeness, we remark that machine learning research has traditionally used the concept of inductive bias to describe the set of assumptions that a learning algorithm makes to predict outputs for inputs that it has not previously encountered <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>. For example, the inductive bias of a nearest neighbor algorithm corresponds to the assumption that the class of an instance x will be most similar to the class of other instances that are nearby in Euclidean distance <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>. Thus, the inductive bias of a learning algorithm loosely corresponds to its interpretation of the training data to make decisions about new data. Using this formulation, one might begin to see how an interpretation of deep learning decision-making might be possible. In contrast, Tom Mitchell observes that&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Vaswani, A. et al. (2017)  “Attention Is All You Need.”    <em>arXiv</em>  preprint (June 2017). <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>To be technically precise, an &lt;|endoftext|&gt; token is used as a way to partition training data and separate different texts. Thus, generate_unconditional_samples.py generates samples from an initial &lt;|endoftext|&gt; token, which is essentially nothing.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>For example, matrices feature prominently in core deep learning code because they are used to implement the layers of a neural network. Arithmetic operations are also a frequent occurrence, but are often performed with matrices rather than single numbers. In fact, matrix multiplication is an operation so integral to a neural network’s predictive capabilities that there exists specialized hardware to optimize it.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Bengio, Y. et al. (2021)  “Deep Learning for AI.”    _Communications of the ACM _ 64.7 (July 2021), pp. 68–75. <a href="https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltext">https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltext</a>.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Our claims about the legibility of source code written in Python rely on a distinction between a novice programmer who understands basic principles such as conditional statements and loops and a data scientist who works with neural networks, especially one with a deep understanding ofTransformers and GPT-2.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Making a related point, Burrell suggests that it is not productive ultimately to apply interpretation to mathematical optimization, or to attempt to parse the decision-making logic of a neural network — in our terms, CDLC — because of its escalating complexity:  “reasoning about, debugging, or improving the algorithm becomes more difficult with more qualities or characteristics provided as inputs, each subtly and imperceptibly shifting the resulting classification”   <sup id="fnref2:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>See <sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup> and <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup> for an emerging mathematical theory and theoretical treatment (respectively) of deep learning. See <sup id="fnref1:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup> and <sup id="fnref1:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup> for core texts on machine learning and deep learning.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Parrish, A. (2018)  “Understanding Word Vectors.”  GitHub repository. <a href="https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469">https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469</a>.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Training data is one of the more urgent, as well as more visible, problems necessitating critical intervention, of which Joy Buolamwini and Timnit Gebru’s work is particularly of note <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Hou Je Bek, W. (2008)  “Loop.”  In M. Fuller (ed),  <em>Software Studies: A Lexicon</em> , MIT Press, Cambridge: 179–183.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>There may well be examples of creative developers who have tried to bend the rules at the level of the model in the creation of innovative deep learning structures and operations, e.g. the attention mechanism in the Transformer network. It is also perfectly reasonable to expect to see interesting code comments in both CDLC and ADLC (although in our experience it is not common for the former). We stand by our initial observation that it would be much more difficult and time-intensive to apply the CCS framework to study CDLC, but we also think it would be a generative exercise for future research. For this paper, however, we choose to focus on what is in our view the more manifestly creative area of deep learning code: ADLC.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Consider the example of a classifier like Logistic Regression trained to classify tumors: depending on the data, the two outputs might be 0 or 1, which would not be meaningful without assigning them respective values of benign and malignant. Such a classification would be necessarily arbitrary and this serves as a reminder of the real interpretive work that happens in the use of ADLC to transform numerical output into linguistic form. This notion of transformation is especially compelling in the context of deep learning because so many transformations have to take place in order for a prediction to be made. Data extracted from an external source must be cleaned and formatted before it can be used to train a model, and an input requiring a predicted output must also be cleaned and would be transformed into numerous vector spaces as it is fed through the model.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>GPT-2’s internal model of the English language relies on the assumption that the current words in a sentence determine the occurrence of subsequent words <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>. At each prediction time step, GPT-2 outputs the probability of every textual unit in its vocabulary (50,257 for the smallest model) given the previous words in a sequence. While a common observation of GPT-2 in action might be that it is writing, then, what it is actually doing is sampling, by which we mean the drawing of a random observation from a probability distribution.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Goodger, D. and G. van Rossum. (2001)  “PEP 257 — Docstring Conventions.”    <em>Python.org</em> , 29 May. <a href="https://www.python.org/dev/peps/pep-0257/#what-is-a-docstring">https://www.python.org/dev/peps/pep-0257</a>.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Douglass, J. (2010)  “Comments on Comments in Code.”  Critical Code Studies Conference Proceedings. <a href="http://thoughtmesh.net/publish/369.php">http://thoughtmesh.net/publish/369.php</a>&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p><a href="https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-long-complex">Python</a> can handle integers with effectively  “unlimited precision,”  which means that there is not a limit on how big the value for generated can be, unlike languages such as Java and C <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. What this means is that generated can exceed the conventional limits on integers, so that the main loop in sample_model can indeed run indefinitely.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>The high quality of ChatGPT’s output, and particularly its ability to remember prior exchanges, seems once again to have invoked the specter of machinic liveness, but the structure of the input-output process with GPT-3.5 is of course no different from GPT-2.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Solaiman I. et al. (2019)  “Release Strategies and the Social Impacts of Language Models.”    <em>arXiv</em>  preprint (November 2019). <a href="https://arxiv.org/pdf/1908.09203.pdf">https://arxiv.org/pdf/1908.09203.pdf</a>&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>For this issue of interaction, we find helpful Florian Cramer’s articulation of software as  “a cultural practice made up of (a) algorithms, (b) possibly, but not necessarily in conjunction with imaginary or actual machines, (c) human interaction in a broad sense of any cultural appropriation and use, and (d) speculative imagination”   <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>. We also find helpful the genealogical account of computer interaction in <sup id="fnref2:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> as well as the account of a paradigm shift from algorithms to interactive systems in <sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Murtaugh, M. (2008)  “Interaction.”  In M. Fuller (ed),  <em>Software Studies: A Lexicon</em> , MIT Press, Cambridge: 143–148.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Walton, N. (2019)  “AI-Dungeon.”  GitHub repository. <a href="https://github.com/AIDungeon/AIDungeon">https://github.com/AIDungeon/AIDungeon</a>.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Python creator Guido van Rossum states in an interview that the programming language was implemented in a way that emphasizes interactivity and that it was based on ABC, which was  “intended to be a programming language that could be taught to intelligent computer users who were not computer programmers or software developers in any sense”   <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>. Deep learning’s commitment to Python thus had the effect of expanding access to a wide population of programmers. Coding in such an easily-accessible and common language (overshadowed only by JavaScript and HTML/CCS) and opening the source code (model.py) to be callable implicitly invites other Python users to interact and experiment with your model.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Smith, A. (2020)  “ Dangerous  AI generates words that don’t exist.”    <em>The Independent</em> , 14 May. <a href="https://www.independent.co.uk/tech/ai-new-word-does-not-exist-gpt-2-a9514936.html">https://www.independent.co.uk/tech/ai-new-word-does-not-exist-gpt-2-a9514936.html</a>.&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Dimson, T. (2020)  “This Word Does Not Exist.”  GitHub repository. <a href="https://github.com/turtlesoupy/this-word-does-not-exist">https://github.com/turtlesoupy/this-word-does-not-exist</a>.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>TWDNE’s blacklist is used not only to filter output but also to evaluate the creativity of the same:  creative words: 1 – (num_blacklisted / max(num_succeeded_match, 1))   nonconforming: num_failed_match / num_generated&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>OpenAI. (2019)  “Better Language Models and Their Implications.”    <em>OpenAI Blog</em> , 14 February. <a href="https://openai.com/blog/better-language-models/">https://openai.com/blog/better-language-models/</a>.&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>EuletherAI’s open-source <a href="https://6b.eleuther.ai">GPT-J</a> is particularly noteworthy here, not only as a model for responsible AI research but also as an impressive outsider appropriation of the model.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>While our analysis holds for GPT-2’s ADLC, further research is required in order to determine whether it applies to other domains such as computer vision and generative adversarial networks (GANs).&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>OpenAI. (2021)  “GPT-3 Powers the Next Generation of Apps,”  25 March. <a href="https://openai.com/blog/gpt-3-apps/">https://openai.com/blog/gpt-3-apps/</a>.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Branwen, G. (2020)  “GPT-3 Creative Fiction.”    <em>Gwern.net</em> , June 2020. <a href="https://www.gwern.net/GPT-3">https://www.gwern.net/GPT-3</a>.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>Rong, F. (2021)  “Extrapolating to Unnatural Language Processing with GPT-3&rsquo;s In-context Learning: The Good, the Bad, and the Mysterious.”    <em>The Stanford AI Lab Blog</em> , 28 May. <a href="https://ai.stanford.edu/blog/in-context-learning/">https://ai.stanford.edu/blog/in-context-learning/</a>.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Wiggers, K. (2021)  “AI Weekly: Meet the people trying to replicate and open-source OpenAI’s GPT-3.”    <em>VentureBeat</em> , 15 January. <a href="https://venturebeat.com/2021/01/15/ai-weekly-meet-the-people-trying-to-replicate-and-open-source-openais-gpt-3/">https://venturebeat.com/2021/01/15/ai-weekly-meet-the-people-trying-to-replicate-and-open-source-openais-gpt-3/</a>.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Alammar, J. (2020)  “Interfaces for Explaining Transformer Language Models.”    <em>Jay Alammar</em> . <a href="https://jalammar.github.io/explaining-transformers/">https://jalammar.github.io/explaining-transformers/</a>.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Alpaydin, E. (2020)  <em>Introduction to Machine Learning, 4th edition</em> . MIT Press, Cambridge.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Mitchell, T. (1997)  <em>Machine Learning</em> . McGraw Hill.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Berner, J. et al. (2021)  “The Modern Mathematics of Deep Learning.”    <em>arXiv</em>  Preprint (May 2021). <a href="https://arxiv.org/abs/2105.04026">https://arxiv.org/abs/2105.04026</a>.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Roberts, D. et al. (2021)  “The Principles of Deep Learning Theory.”    <em>arXiv</em>  Preprint (June 2021). <a href="https://arxiv.org/abs/2106.10165">https://arxiv.org/abs/2106.10165</a>.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Buolamwini, J. and T. Gebru. (2018)  “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.”    <em>Proceedings of Machine Learning Research</em>  81 (2018), pp. 1–15.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Bengio, Y. (2008)  “Neural Net Language Models.”    <em>Scholarpedia</em>  3.1. <a href="http://www.scholarpedia.org/article/Neural_net_language_models">http://www.scholarpedia.org/article/Neural_net_language_models</a>.&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Golubin, A. (2017)  “Python internals: Arbitrary-precision integer implementation.”    <em>Artem Golubin</em>  (September 2017). <a href="https://rushter.com/blog/python-integer-implementation/">https://rushter.com/blog/python-integer-implementation/</a>.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Cramer, F. (2005)  <em>Words Made Flesh: Code, Culture Imagination</em> . Piet Zwart Institute, Rotterdam. <a href="https://www.netzliteratur.net/cramer/wordsmadefleshpdf.pdf">https://www.netzliteratur.net/cramer/wordsmadefleshpdf.pdf</a>.&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>Wegner, P. (1996)  “The Paradigm Shift from Algorithms to Interaction.”  Communications of the ACM (October 1996), <a href="https://www.semanticscholar.org/paper/The-Paradigm-Shift-from-Algorithms-to-Interaction-Wegner/ed4e399e9b39ce45918e3fa7077a613b4556b6ce">https://www.semanticscholar.org/paper/The-Paradigm-Shift-from-Algorithms-to-Interaction-Wegner/ed4e399e9b39ce45918e3fa7077a613b4556b6ce</a>.&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>Venners, B. (2003)  “The Making of Python: A Conversation with Guido van Rossum.”    <em>Artima</em>  (January 2003). <a href="https://www.artima.com/articles/the-making-of-python">https://www.artima.com/articles/the-making-of-python</a>.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Gilpin, L. et al. (2018)  “Explaining Explanations: An Overview of Interpretability of Machine Learning.”  2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA). <a href="https://ieeexplore.ieee.org/abstract/document/8631448">https://ieeexplore.ieee.org/abstract/document/8631448</a>.&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Lipton, Z. (2018)  “The Mythos of Model Interpretability.”    <em>ACM Queue</em>  (May-June 2018). <a href="https://dl.acm.org/doi/pdf/10.1145/3236386.3241340">https://dl.acm.org/doi/pdf/10.1145/3236386.3241340</a>.&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">SEDES: Metrical Position in Greek Hexameter</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000675/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://rlskoeser.github.io/dhqwords/vol/17/1/000665/?utm_source=atom_feed" rel="related" type="text/html" title="The Stories We Tell: Project Narratives, Project Endings, and the Affective Value of Collaboration"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000675/</id><author><name>Stephen A. Sansom</name></author><author><name>David Fifield</name></author><published>2023-05-31T00:00:00+00:00</published><updated>2023-05-31T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Metrical position has long interested scholars of Greek hexameter poetry. In his  <em>Encheiridion dia Metrôn</em>  ( “Handbook on Meter” ), Hephaestion of Alexandria (2nd c. CE) referred to positions within meter as χώραι ( “places; positions,”  cf.  <em>LSJ</em>  s.v. χώρα  3) and used the term to describe places in the line that contain various types of metrical  “feet”  (πόδες, cf. <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> s.v. πούς  4), such as the dactyl (‒ ⏑ ⏑) and spondee (‒ ‒), as well as the  “final”  (τῆς τελευταίας, 7.1) position that may contain syllabic diversity, such as catalexis.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  Aristides Quintilianus (circa 4th c. CE) likewise used χώρα to describe metrical position in his  <em>Peri Musikês</em>  ( “On Music” ), including the  “first places”  (ταῖς πρώταις χώραις, 1.24.27) of feet in the line (cf. <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>). But it was not until the early 20th century that scholars interested in the statistical analysis of meter systematized notation for all possible positions of linguistic phenomena in the hexameter line; of these efforts, <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> has gained the most currency.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  Later, <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> and others Latinized the terminus technicus from χώρα to  _ sedes _  ( “seat; place” ), and now the term is ubiquitous in philological studies of metrical position.</p>
<p>With this greater precision, scholars have examined various forms of repetition in hexameter according to their metrical position. These studies largely focus on articulating metrical tendencies, such as colometric patterns <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> and the primacy of  _ caesurae _  (τομαί) at certain  _ sedes _   <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>, <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>  In particular, <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> discovered what he called the  “localization”  of  “word-types,”  that is, the  “concentration of occurrences (of specific metrical shapes) in but a few of the possible positions”  (114). Following O’Neill, <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> argued that such tendencies established  “patterns of expectancy”  or norms in the mind of poet and audience, and philologists have begun to explore the potential intertextual, stylistic, cognitive, and literary effects of these patterns, for example, in <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>, <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>, <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>, <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>, <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>, <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>, and <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>. <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></p>
<p>These studies have provided useful data and promising applications, but their potential has been somewhat constrained by limitations in scope, objects of analysis, and at times computational media. O’Neill treated only a relatively small number of lines, though his survey has been expanded and the data verified by <sup id="fnref2:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>, <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>, and <sup id="fnref1:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. A lack of aggregate statistics on repeated words by sedes has restricted intertextual readings to the examination of infrequent words, hapax, or dis legomena, for example in <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>  Even inquiries into anomalous behavior such as breaks in Hermann’s Bridge (that is, avoidance of word end between the biceps [two short elements] of the fourth foot <sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>, <sup id="fnref1:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>) have been confined to a few authors or passages, due to a lack of available data. Existing digital tools for identifying repetitions in hexameter poetry — for example, the Thesaurus Linguae Graecae <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> or Perseus Project under PhiloLogic <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>, for searching corpora by word list, lemma, or text string; the <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>, for repeated phrases; and <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>, for intertexts by n‑gram matching <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> — do not take into account metrical position. Future work on metrical position in Greek hexameter needs new methods and access to data in order to identify repetitive phenomena in meter more accurately and completely. <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>  With such information, scholars can then better discern their linguistic causes and potential poetic effects.</p>
<p>In this article, we introduce SEDES, a software system for identifying, quantifying, and visualizing metrical position in ancient Greek hexameter poetry. Like intertextualist studies of metrical position, SEDES at present focuses on the repetition of words — more specifically, of lemmata. Our present purpose is to describe the design of the SEDES system and demonstrate a sample of its utility. <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>  Engineering the system required bringing together existing resources in the processing of Greek poetry, as well as the creation of new processes, measurements, tests, and visualizations, all of which aid researchers of Greek literature and otherwise in the processing of poetic texts for computer and literary analysis and, more generally, provide a method that benefits the quantitative analysis of repetitive language in meter. In what follows, we show how SEDES generates these data, before giving examples of its application to Greek hexameter poetics, in particular the fields of oral formularity and intertextuality.</p>
<h2 id="processing-pipeline">Processing Pipeline</h2>
<p>The core function of SEDES is to assign a numeric value — an expectancy score — to every word in a work of verse. The expectancy of a word is a quantification, in a sense we will define later, of how frequently that word’s lemma appears at a given sedes in a corpus of works. After computing expectancy scores, SEDES provides ways of visualizing and interacting with them. The SEDES system is composed of a pipeline of programs, each of which performs a portion of the processing task. See Figure 1.</p>




























<figure ><img loading="lazy" alt="Schematic diagram of information flow through the programs of SEDES" src="/dhqwords/vol/17/2/000675/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure01_huaa5f6baf31024648063fd4eed24eb598_182250_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure01_huaa5f6baf31024648063fd4eed24eb598_182250_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure01_huaa5f6baf31024648063fd4eed24eb598_182250_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000675/resources/images/figure01_huaa5f6baf31024648063fd4eed24eb598_182250_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000675/resources/images/figure01_huaa5f6baf31024648063fd4eed24eb598_182250_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000675/resources/images/figure01.png 2640w" 
     class="landscape"
     ><figcaption>
        <p>The SEDES processing pipeline comprises three programs: tei2csv, expectancy, and tei2html. Visualizing a text requires analyzing not only it, but all other texts of the corpus.
        </p>
    </figcaption>
</figure>
<p>The input to the pipeline is a set of XML documents marked up according to the TEI Guidelines <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. The selection of documents defines the corpus relative to which expectancy scores are computed. In developing SEDES, we have used 12 TEI texts from the Perseus Project <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>, totaling about 73,000 lines, with a minimum length of 479 lines and a maximum of 21,356. See Table 1 for a listing of texts, which span more than a millennium and comprise a variety of styles. We often define the corpus as all 12 works, but the system makes it possible to work with only a subset, in order to include or exclude certain authors or eras, for example.<br>
Works in the full SEDES corpus.    Work  Date (circa c.)  Lines  Words        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0133">Iliad</a>, <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0133">Homer</a>    8th BCE  15,683  111,865        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0135">Odyssey</a>, <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0135">Homer</a>    8th BCE  12,107  87,185        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0137">Homeric Hymns</a>    7th–6th BCE  2,342  16,022        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0129">Theogony</a>, <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0129">Hesiod</a>    8th BCE  1,042  7,040        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0131">Works and Days</a>, <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0131">Hesiod</a>    8th BCE  831  5,856        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0127">Shield of Heracles</a>, <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0127">Hesiod</a>    6th BCE  479  3,298        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0227">Argonautica</a>, <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0227">Apollonius Rhodius</a>    4th BCE  5,834  38,841        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:2008.01.0481">Hymns</a>  <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:2008.01.0481">, Callimachus</a>    3rd BCE  941  6,480        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:2008.01.0483">Phaenomena</a>, <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:2008.01.0483">Aratus Solensis</a>    3rd BCE  1,155  7,752        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0228">Idylls</a>, <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0228">Theocritus</a>    3rd BCE  2,527  18,071        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:2008.01.0490">Fall of Troy</a>  <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:2008.01.0490">, Quintus Smyrnaeus</a>    4th CE  8,801  60,098        <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:2008.01.0485">Dionysiaca</a>, <a href="https://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:2008.01.0485">Nonnus of Panopolis</a>    5th CE  21,356  126,870      Total    73,098  489,378   <br>
Though similar techniques could be applied to other forms of verse, SEDES is specially adapted to hexameter. In hexameter, vowels are distinguished by length. A line consists of six feet, which each may be either a long syllable followed by another long syllable (a spondee, denoted – –), or a long syllable followed by two short syllables (a dactyl, – ⏑ ⏑). The metrical shape of a word — its pattern of long and short syllables — limits the places (sedes) in a line it may appear. (Though there is some flexibility: a word may, subject to certain rules, sometimes be reinterpreted to have a different metrical shape than it would otherwise have, in order to fit the meter.) Even given the range of permissible slots for each word, most words tend to appear at some sedes more often than others. It is this non-uniform distribution of word placements that SEDES is designed to analyze.</p>
<p>The first program in the SEDES pipeline, tei2csv, assigns a lemma and a sedes to every word in the corpus. (We consider multiple instances of the same word separately — the same word in different lines may appear at different sedes, for example.) Later parts of the pipeline will operate, not on the original words of the text directly, but on the  “lemma– sedes  pairs”  to which they are mapped by tei2csv. Concretely, tei2csv does the following three steps of segmentation, lemmatization, and scansion for every document in the corpus:</p>
<ol>
<li>Break the document into lines and words.  2. Look up a lemma for each word.  3. Scan every line metrically, thereby finding a sedes for each word.</li>
</ol>
<p>The output of tei2csv is a collection of CSV files, one for each TEI file in the corpus. The CSV files map every instance of every word in the corpus to the lemma and sedes of that instance, what we call a lemma–sedes pair. The next program in the pipeline, called expectancy, takes these CSV files as input and does the statistics necessary to compute expectancy scores:</p>
<ol start="4">
<li>Compute an expectancy score for every unique lemma–sedes pair.</li>
</ol>
<p>The output of the expectancy program is another CSV file that maps every observed combination of lemma and sedes to a numeric expectancy score. The final program in the pipeline, tei2html, takes as input the expectancy CSV file and the TEI of any single work — which may or may not be part of the corpus that was used to define expectancy — and produces an output visualization of the work:</p>
<ol start="5">
<li>Produce an HTML file that depicts differences in expectancy across words.</li>
</ol>
<p>We will describe the above steps in detail in the subsections that follow. But first, we will walk through an example of applying the SEDES processing pipeline to book 1, line 1 of the  <em>Odyssey</em>   <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> from start to finish.</p>
<p>In the source TEI file, the line looks like this: <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span> <span style="color:#f92672">&lt;l&gt;</span>a)/ndra moi e)/nnepe, mou=sa, polu/tropon, o(\s ma/la polla\<span style="color:#f92672">&lt;/l&gt;</span> 
</span></span></code></pre></div><p>The <l> and </l> XML tags delimit a line. The text between the tags is Beta Code <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>, a method of representing written ancient Greek using ASCII characters: a  represents the letter alpha; ), /, , and  = are various diacritics; and so on. The tei2csv program isolates the line from the XML markup and decodes the Beta Code to yield a line of verse represented in Unicode:</p>
<pre tabindex="0"><code> ἄνδρα μοι ἔννεπε, μοῦσα, πολύτροπον, ὃς μάλα πολλὰ 
</code></pre><p>( “Tell me, Muse, about the versatile man, who very many…” ) The program then scans the line metrically, marking each syllable as long (notated –) or short (notated ⏑). A long syllable counts for 1 position and a short syllable counts for 0.5. The scansion of the example line is:</p>
<pre tabindex="0"><code> ἄν δρα μοι ἔν νε πε, μοῦ σα, πο λύ τρο πον, ὃς μά λα πο λλὰ – ⏑ ⏑ – ⏑ ⏑ – ⏑ ⏑ – ⏑ ⏑ – ⏑ ⏑ – – 1 2 2.5 3 4 4.5 5 6 6.5 7 8 8.5 9 10 10.5 11 12 
</code></pre><p>The sedes of a word is the sedes of its first syllable. In this example, ἄνδρα is at sedes  1, μοι is at sedes  2.5, and so on. Separately from scansion, every word in the line is mapped to its lemma. Here, the word ἄνδρα maps to the lemma ἀνήρ, μοι maps to ἐγώ, and so on for the rest of the words. The output of this process is a lemma and a sedes for each word: a lemma–sedes pair. The calculation of sedes and the finding of a lemma are independent operations: it is the syllables of the original words of the line, not their derived lemmata, that determine sedes.</p>
<p>The tei2csv program emits a CSV file with one row per input word, representing the word’s lemma, sedes, and other metadata.<br>
work  book_n  line_n  word_n  word  lemma  sedes  metrical_shape  scanned  num_scansions  line_text      Od.,  1,  1,  1,  ἄνδρα,  ἀνήρ,  1,  –⏑,  auto,  1  &ldquo;ἄνδρα μοι&hellip;&rdquo;      Od.,  1,  1,  2,  μοι,  ἐγώ,  2.5,  ⏑,  auto,  1  &ldquo;ἄνδρα μοι&hellip;&rdquo;      Od.,  1,  1,  3,  ἔννεπε,  ἐνέπω,  3,  –⏑⏑,  auto,  1  &ldquo;ἄνδρα μοι&hellip;&rdquo;      Od.,  1,  1,  4,  μοῦσα,  μοῦσα,  5,  –⏑,  auto,  1  &ldquo;ἄνδρα μοι&hellip;&rdquo;      Od.,  1,  1,  5,  πολύτροπον,  πολύτροπος,  6.5,  ⏑–⏑⏑,  auto,  1  &ldquo;ἄνδρα μοι&hellip;&rdquo;      Od.,  1,  1,  6,  ὃς,  ὅς,  9,  –,  auto,  1  &ldquo;ἄνδρα μοι&hellip;&rdquo;      Od.,  1,  1,  7,  μάλα,  μάλα,  10,  ⏑⏑,  auto,  1  &ldquo;ἄνδρα μοι&hellip;&rdquo;      Od.,  1,  1,  8,  πολλὰ,  πολύς,  11,  ––,  auto,  1  &ldquo;ἄνδρα μοι&hellip;&rdquo;   <br>
Expectancy is a function of lemma and sedes jointly: it measures, for each lemma, how that lemma is distributed over the possible sedes, in the context of the overall corpus. Having run tei2csv on the  <em>Odyssey</em> , we run it again on the other works of the corpus to obtain the necessary context, in the form of a collection of CSV files that give a lemma and a sedes for every word. The expectancy program takes all these files as input, analyzes the statistical distribution of sedes for each lemma, and outputs another CSV file that maps lemma–sedes pairs to their expectancy scores, using mathematical formulas we will define below. An excerpt of the output of the expectancy program is shown below. The x column counts the number of occurrences of a lemma–sedes pair throughout the corpus, and z shows the expectancy of that pair. From this sample output, we see that the expectancy of the lemma ἀνήρ (man) at sedes  1 is +1.11, that of ἐγώ (I) at sedes  2 is −0.13, and so on.<br>
lemma  sedes  x  z      [&hellip;]      ἀνήρ  1  452  +1.1089031679816      ἀνήρ  2  35  −1.60788923391802      ἀνήρ  2.5  100  −1.18440840388571      [&hellip;]      ἐγώ  2  430  −0.132108322471802      ἐγώ, , ,   2.5  1027  +1.79559085302027      ἐγώ  3  457  −0.0449259477008033      [&hellip;]      ἐνέπω  3  8  −1.32295427519852      [&hellip;]   <br>
Finally, the tei2html program takes as input the TEI file of the  <em>Odyssey</em>  along with the expectancy CSV file. tei2html renders a human-readable HTML representation of the text, optionally highlighting each word according to its expectancy. One visualization style is shown below, with words shaded according to their expectancy: low expectancy is dark and high expectancy is light. Other styles will be explored in the section on visualization.</p>
<p>ἄνδρα  μοι  ἔννεπε, μοῦσα, πολύτροπον, ὃς  μάλα  πολλὰ</p>
<p>The programs that constitute SEDES are written in Python 3. Running SEDES from start to finish on every work in our corpus (12 TEI files, 73,000 lines, and 490,000 words) on a 2019 MacBook Pro takes about one minute. About 45% of the time is spent on segmentation, lemmatization, and scansion; 9% on expectancy computation; and 46% on generating visualization output.</p>
<h2 id="segmentation-into-lines-and-words">Segmentation into Lines and Words</h2>
<p>Scansion is an operation on individual lines, and lemmatization is an operation on individual words. SEDES begins by breaking a TEI document into lines, and its lines into words.</p>
<p>Segmentation into lines is fairly straightforward. Lines are delimited by either the l element, which encloses lines; or the lb element, which separates them: <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup></p>
<h1 id="_iliad_--135156-tlgbetacodeperseusiliad"><em>Iliad</em>  1.351–56 <sup id="fnref1:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup><sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup></h1>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;l&gt;</span>mh=ter e)pei/ m&#39; e)/teke/s ge minunqa/dio/n per e)o/nta,<span style="color:#f92672">&lt;/l&gt;</span> <span style="color:#f92672">&lt;l&gt;</span>timh/n pe/r moi o)/fellen *)olu/mpios e)gguali/cai<span style="color:#f92672">&lt;/l&gt;</span> <span style="color:#f92672">&lt;l&gt;</span>*zeu\s u(yibreme/ths: nu=n d&#39; ou)de/ me tutqo\n e)/tisen:<span style="color:#f92672">&lt;/l&gt;</span> <span style="color:#f92672">&lt;l</span> <span style="color:#a6e22e">n=</span><span style="color:#e6db74">&#34;355&#34;</span><span style="color:#f92672">&gt;</span>h)= ga/r m&#39; *)atrei/+dhs eu)ru\ krei/wn *)agame/mnwn<span style="color:#f92672">&lt;/l&gt;</span> <span style="color:#f92672">&lt;l&gt;</span>h)ti/mhsen: e(lw\n ga\r e)/xei ge/ras au)to\s a)pou/ras.<span style="color:#f92672">&lt;/l&gt;</span> 
</span></span></code></pre></div><h1 id="_theogony_--97983-perseustheogony"><em>Theogony</em>  979–83 <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup></h1>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;lb/&gt;&lt;milestone</span> <span style="color:#a6e22e">ed=</span><span style="color:#e6db74">&#34;P&#34;</span> <span style="color:#a6e22e">unit=</span><span style="color:#e6db74">&#34;para&#34;</span> <span style="color:#f92672">/&gt;</span>kou/rh d&#39; *)wkeanou=, *xrusa/ori karteroqu/mw| <span style="color:#f92672">&lt;lb</span> <span style="color:#a6e22e">rend=</span><span style="color:#e6db74">&#34;displayNum&#34;</span> <span style="color:#a6e22e">n=</span><span style="color:#e6db74">&#34;980&#34;</span> <span style="color:#f92672">/&gt;</span>mixqei=s&#39; e)n filo/thti poluxru/sou *)afrodi/ths, <span style="color:#f92672">&lt;lb</span> <span style="color:#f92672">/&gt;</span>*kalliro/h te/ke pai=da brotw=n ka/rtiston a(pa/ntwn, <span style="color:#f92672">&lt;lb</span> <span style="color:#f92672">/&gt;</span>*ghruone/a, to\n ktei=ne bi/h *(hraklhei/h <span style="color:#f92672">&lt;lb</span> <span style="color:#f92672">/&gt;</span>bow=n e(/nek&#39; ei)lipo/dwn a)mfirru/tw| ei)n *)eruqei/h|. 
</span></span></code></pre></div><p>Having isolated a line, we decode its text contents from Beta Code to Unicode. We extract words from the line by splitting on sequences of non-letter, non-diacritic characters. For this purpose, the apostrophe character (’), used to mark elision in words like ἀλλ’, is considered to be a letter character. Some TEI documents use apostrophes to mark quotations, which complicates word extraction by giving the character a second meaning as punctuation. When we discovered uses like this, we amended it in the source document using quotation markup.</p>
<h2 id="lemmatization">Lemmatization</h2>
<p>SEDES needs a way of defining which words count as the same for the purpose of computing distributions over sedes. Our instrument for deciding which words are considered equivalent is the lemma. <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>  In lexicography, a lemma is the dictionary headword with which all its morphological variants are associated. Ancient Greek is a highly inflected language, one in which words take on many forms according to their grammatical function. The lemma unifies the many related forms of a word and bundles them under one label. For example, the genitive singular word ἀοιδῆς and the dative plural ἀοιδαῖς both have the same lemma, ἀοιδή (song); the two words therefore fall into the same bucket for the purpose of computing statistics. (Note, however, that lemma assignment does not affect the scansion procedure that will be described in the next section; scansion uses the words of the original text, pre-lemmatization.) As a semantic matter, lemma corresponds to lexeme, an item of meaning removed from a language’s inflectional rules; we may think of a lemma as a representative of a lexeme, standing for a group of related words. <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup></p>
<p>Mapping a word to its lemma is not trivial <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>. But strictly speaking, we do not care about a word’s lemma per se. All we care about is when two words have the same lemma. In mathematical terms, equality of lemmata is an equivalence relation that partitions the universe of words into equivalence classes: all words that have the same lemma are in the same class, and no two words in the same class have different lemmata. <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>  As long as a lemmatization algorithm is consistent, it may as well output abstract tokens like x1234 as literal Greek words. <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>  This is to say that the consequence of a word being lemmatized incorrectly is that the word ends up in a different class than it should: it is missing from its true class and is instead grouped with some other class of words (or a class by itself). Whether such an error makes a meaningful difference in the statistics depends on how many times the word occurs, and the sizes of the other lemma classes. In SEDES, we use the backoff Greek lemmatizer <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>  of the Classical Language Toolkit <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>. The backoff lemmatizer employs a chain of sub-lemmatizers (which are various forms of dictionary lookup and regular expression transformations <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>, <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>), trying each in turn until one returns a result. If no lemma is found by any of these techniques, the last-resort fallback is to use the word itself as the lemma. The fallback occurs for about 2% of words in the corpus (7% of unique words). A random sample of 100 lines suggests a 98.6% accuracy rate: we identified 10 misattributed lemmata among the 721 words in  <em>Iliad</em>   13.563–662.</p>
<p>We augment the CLTK lemmatizer with a preprocessing step that attempts variations on accent marks: if the initial lemmatization fails, the lemmatizer applies one of a small set of accent transformations, namely, changing a grave accent to an acute accent, or removing an acute accent.<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>  The pre-transformation step makes a few thousand words lemmatizable that would not be otherwise. We further have the lemmatizer first consult a hardcoded list of our own, manually determined lemmata, which we use this list for words that are common in our corpus but for which automatic lemmatization fails.</p>
<h2 id="scansion">Scansion</h2>
<p>The computation of expectancy requires a word’s lemma and sedes. In the previous step we found the lemma; now we tackle the sedes. Sedes is a byproduct of scansion, which, in the context of Greek hexameter, means determining the metrical value (long or short) of every syllable in a line.<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>  Once a scansion is settled, the sedes of a word is determined by the metrical values of the words preceding it in the line. For automatic scansion, we use the Python hexameter module <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>. Here we will briefly describe how the algorithm works.</p>
<p>The first step is to isolate syllables by looking for vowels and diphthongs. Each lexical syllable is assigned a preliminary metrical value according to language rules that are specific to Greek. An example of these rules is that, unless modified by other rules, the vowels ε and ο are short, η and ω are long, and other vowels are (for now) undetermined. At this point in the analysis, a syllable may be classified as definitely long, definitely short, or one of a few other values that govern how the syllable may be resolved into long or short in the next step.</p>
<p>Resolution of preliminary metrical values into final metrical values is accomplished using a finite automaton. A finite automaton is a computational state machine that represents (or recognizes) a restricted set of inputs — in our case, the set of properly formed lines of Greek hexameter. The automaton matches lines of hexameter the same way that a regular expression matches a subset of strings. The automaton encodes various rules of the poetic form: for example, that a line contains six feet total; that the first half of a foot must be a long syllable; and that the second half of every foot but the last may be either one long syllable or two short syllables. Each transition in the automaton is marked with both the preliminary metrical values that permit the transition to be taken, and the final metrical value the syllable is to be assigned, when that transition is taken. In general, there is more than one way of fitting a line into the schema of hexameter. For example, one might change a short syllable to a long early in the line, making compensating adjustments to following syllables in order to maintain the same total length. This fact is reflected in the automaton by there being multiple paths from start to finish when there are multiple feasible scansions. Not all scansions are equally good, however. The automaton’s output is biased towards parsimony by weights attached to state transitions, which penalize metrical value assignments that require uncommon metrical rules. The associated final metrical values of the path with lowest weight becomes the scansion of the line.</p>
<p>Occasionally, the automatic scansion algorithm yields either no paths through the automaton, or two or more paths of equal weight. We scanned these problematic lines by hand and added them to a list of scansion overrides, which take precedence over automatic scansions. There are 1,526 entries in the list of overrides, about 2.1% of the lines in the corpus. Manually scanning lines whose automatic scansion is undefined or ambiguous requires human expertise in the form of meter being analyzed. The CSV output of tei2csv records the source of the scansion in the scanned column — either manual or auto. The num_scansions column counts the number of equally weighted automatic scansions found, usually 1.</p>
<p>Once every syllable in a line has been assigned its metrical value, it is straightforward to determine the sedes of each word. Start at the beginning of the line and sedes  1. Advance the sedes by 1 for a long syllable, and by 0.5 for a short syllable. The sedes of a word is the sedes of its first syllable. The sedes of words in a line are not all necessarily distinct. For example, in  <em>Iliad</em>  1.241 <sup id="fnref1:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>, σύμπαντας· τότε δ’ οὔ τι δυνήσεαι ἀχνύμενός περ, the two adjacent words δ’ and οὔ share sedes  5, because they are pronounced as one word.</p>
<p>To evaluate the accuracy of the automatic scansion algorithm, we randomly sampled 1,200 lines from the entire corpus and manually checked their automatic scansion. 1,195 lines (99.6%) were scanned correctly.</p>
<h2 id="expectancy-computation">Expectancy Computation</h2>
<p>We now come to the central question: how expected is each word, given its lemma and the sedes at which it appears? Following <sup id="fnref3:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, we call the measure of expectedness expectancy. Expectancy is not a property of lemma only or of sedes only, but of both considered jointly. For each lemma–sedes pair, we ask: given the distribution of this lemma in the corpus, is this sedes usual or unusual?</p>
<p>Our metric of expectancy is the z‑score, which measures distance from the mean of a distribution in units of the standard deviation <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>, <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>. The formula for the z‑score of an observed value x is z = (x - μ)/σ where μ is the mean of a population and σ is its standard deviation. A  z‑score of +1.5, for example, describes a value that is 1.5 standard deviations greater than the mean. Values greater than the mean have positive scores, and values less than the mean have negative scores. We count how many times a certain lemma appears at a certain sedes, and the z‑score expresses whether that count is greater or less than would be expected, given the counts at that and other sedes.</p>
<p>In our definition of expectancy, different lemmata do not interact. <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>  The expectancy of a lemma at a particular sedes depends only on the distribution of that lemma. For example, in our corpus, the lemma βοῦς (cow) appears 448 times, while χέλυς (tortoise) appears only 8 times. It is more expected, then, in some sense, for any given word to be βοῦς than to be χέλυς. But we are not interested in comparing βοῦς versus χέλυς; rather we weigh βοῦς against other instances of βοῦς, and χέλυς against other instances of χέλυς.</p>
<p>To establish corpus-wide distributions of lemmata and sedes, we repeat the three previous steps — segmentation, lemmatization, and scansion — for every work in the corpus, using the tei2csv program to create a collection of work-specific CSV files with a lemma and sedes for every word. Then a separate program, called expectancy, takes as input the whole collection, computes the expectancy of every unique lemma–sedes pair across the entire corpus, and writes a table of computed expectancy values to another CSV file. This table will be used in the next step to produce a visualization for a single work.</p>
<p>The expectancy program begins by counting the number of occurrences of each unique lemma–sedes pair. Then, for each lemma, it examines the lemma’s distribution over the possible sedes. Before applying the z‑score formula to the table of sedes counts, we weight each count by itself. For instance, the weighted mean of the distribution of counts [1, 2, 2, 15] is not (1 + 2 + 2 + 15) / 4 = 5, but rather (1×1 + 2×2 + 2×2 + 15×15) / (1 + 2 + 2 + 15) = 11.7. This is because the counts represent 20 total words, not 4; since the majority of words appear at a sedes having a count of 15, a representative count should be closer to 15 than it is to 1 or 2. We similarly weight the standard deviation calculation. To be precise, we use the following formulas for the weighted mean and standard deviation of a vector of sedes frequency counts [c <em>1</em> , …, c <em>n</em> ]:</p>
<p>$$\begin{align*} \mu &amp;= \frac{\sum_{i=1}^n c_i \times c_i}{\sum_{i=1}^n c_i} \ \sigma &amp;= \sqrt{\frac{\sum_{i=1}^n c_i \times (c_i - \mu)^2}{\sum_{i=1}^n c_i}}. \end{align*}$$</p>
<p>The output of the expectancy program is a CSV file that maps lemma–sedes pairs to their respective z‑scores.</p>
<p>The z‑score formula is not defined for distributions whose standard deviation is zero. Such a situation arises when the frequency counts for a lemma are exactly equal in every sedes where it appears. Examples are ἑκηβόλος (far-shooter), which occurs 42 times but always in sedes  6.5, and Κίλλα (the astyonym Killa), which occurs 4 times total, twice each in sedes  1 and 11). Important special cases of this general phenomenon are words that appear only once or twice in the corpus, such as the  <em>hapax legomenon</em>   ἑλώρια ( <em>Iliad</em>   1.4, lemma ἑλώριον). Expectancy is also undefined for lemmata that never appear in the corpus — those whose table of frequency counts is everywhere zero. This last situation may occur only when when the work under consideration is not part of the corpus that defines expectancy: if it had been, all its lemmata would necessarily have a nonzero count in at least one sedes. For the purposes of visualization, we treat undefined z‑scores as if they were zero; i.e., neither more nor less frequent than expected. Figure 2 shows the distribution of z‑scores for every word in the entirety of our corpus.</p>




























<figure ><img loading="lazy" alt="Histogram of z-scores." src="/dhqwords/vol/17/2/000675/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure02_huc2dd91e4db8fb76c27066c7016852a0a_18272_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure02_huc2dd91e4db8fb76c27066c7016852a0a_18272_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure02_huc2dd91e4db8fb76c27066c7016852a0a_18272_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000675/resources/images/figure02_huc2dd91e4db8fb76c27066c7016852a0a_18272_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000675/resources/images/figure02_huc2dd91e4db8fb76c27066c7016852a0a_18272_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000675/resources/images/figure02.png 1800w" 
     class="landscape"
     ><figcaption>
        <p>Histogram of z‑scores for all words across our entire corpus. This chart excludes about 33,000 words with undefined z‑scores. Over 95% of z‑scores lie in the interval [−1.75, +1.75], though the tail of negative values extends as far as −11.5.
        </p>
    </figcaption>
</figure>
<p>Even disregarding lemmata, it is not the case that all sedes are equally likely to be the site of the start of a word. A simple demonstration of this fact is that every line of hexameter contains a word at sedes  1 (the first word), but whether there is a word at sedes  2 depends on the how long the first word is. Figure 3 shows the distribution over sedes for the works in our corpus. One might reasonably suggest applying a correction to the expectancy formulas to adjust for an assumed a priori distribution over sedes. We have chosen not to do so, reasoning that a word’s appearing at an uncommon sedes is itself a sign of unexpectedness.</p>




























<figure ><img loading="lazy" alt="Bar chart of sedes frequencies." src="/dhqwords/vol/17/2/000675/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure03_hu20dc1561163936b8aa1967cce52890cd_20414_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure03_hu20dc1561163936b8aa1967cce52890cd_20414_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure03_hu20dc1561163936b8aa1967cce52890cd_20414_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000675/resources/images/figure03_hu20dc1561163936b8aa1967cce52890cd_20414_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000675/resources/images/figure03_hu20dc1561163936b8aa1967cce52890cd_20414_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000675/resources/images/figure03.png 1800w" 
     class="landscape"
     ><figcaption>
        <p>Distribution of sedes cross the full corpus. Not all sedes are equally likely.
        </p>
    </figcaption>
</figure>
<p>Further exploration and justification of the utility of z‑scores as a measure of expectancy appears below in the section  “Interpretation of  z ‑scores.”  We now show how expectancy scores feed into the final step of the pipeline, namely visualizing numeric expectancy data.</p>
<h2 id="visualization">Visualization</h2>
<p>The data files emitted by the previous steps lend themselves to various forms of analysis. Our specific goal is to produce a readable visualization of the source text, with every word highlighted according to its expectancy.<sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>  Such a visualization enables a human reader to quickly visually peruse and identify words whose expectancy is much different than expected, aided by the context of the surrounding text. Words thus identified may be worthy of further investigation.</p>
<p>The processing pipeline terminates in the tei2html program, which takes as input a TEI text and the table of lemma–sedes expectancy scores output by the expectancy program, and produces a visualization that uses HTML, CSS, and JavaScript. Like tei2csv, tei2html isolates words from its TEI input and assigns each one a lemma and sedes. It looks up the expectancy scores of the lemma–sedes pairs, and emits an HTML document where every word is annotated with its expectancy and other metadata.</p>
<p>The HTML document provides an interactive selection of visualization styles. A simple and effective way to depict expectancy is to shade the color of words on a scale from dark to light.<sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>  In this style, words with higher expectancy fade into the background, and those with lower expectancy are visually emphasized (Figure 4).</p>




























<figure ><img loading="lazy" alt="&#34;Shade text&#34; visualization." src="/dhqwords/vol/17/2/000675/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure04_hu5f61bf1872dda4e48c679afc78947af8_129430_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure04_hu5f61bf1872dda4e48c679afc78947af8_129430_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure04.png 1177w" 
     class="landscape"
     ><figcaption>
        <p>Words shaded according to z‑score, dark to light.
        </p>
    </figcaption>
</figure>
<p>A variation of this style is a diverging color gradient, which, rather than emphasizing the difference between negative and positive, emphasizes distance from the mean. In this style, z‑scores close to zero are visually diminished, while those that are large positive or large negative are highlighted in saturated and contrasting colors. Here, negative z‑scores are red and positive z‑scores are blue (Figure 5).</p>




























<figure ><img loading="lazy" alt="&#34;Shade text, diverging&#34; visualization." src="/dhqwords/vol/17/2/000675/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure05_hufed3286455c4e758ebd78101b5e7bec8_134447_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure05_hufed3286455c4e758ebd78101b5e7bec8_134447_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure05.png 1177w" 
     class="landscape"
     ><figcaption>
        <p>Words shaded on a diverging scale, red to gray to blue.
        </p>
    </figcaption>
</figure>
<p>Words vary in their length and visual density; of two words shaded identically, the longer word may be visually more prominent, simply because up more space. In an attempt to mitigate this potential bias, we have provided alternative styles that attach filled circles of uniform size to words, where the circles are shaded rather than the text (Figure 6). Here, as well, the gradient may be sequential or diverging.</p>




























<figure ><img loading="lazy" alt="&#34;Shade bubbles, diverging&#34; visualization." src="/dhqwords/vol/17/2/000675/resources/images/figure06.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure06_hu39efa4422ed8e342c4ba8724f516285d_374331_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure06_hu39efa4422ed8e342c4ba8724f516285d_374331_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure06.png 1177w" 
     class="landscape"
     ><figcaption>
        <p>Shaded circles of uniform size are an alternative to text shading.
        </p>
    </figcaption>
</figure>
<p>The visualization has an align to sedes grid option that vertically aligns words according to their sedes (Figure 7).<sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>  This option may be combined with any visualization style.</p>




























<figure ><img loading="lazy" alt="Text aligned to sedes grid." src="/dhqwords/vol/17/2/000675/resources/images/figure07.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure07_hu775c7926d6e4f969660898e7e32806c6_157100_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure07_hu775c7926d6e4f969660898e7e32806c6_157100_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure07_hu775c7926d6e4f969660898e7e32806c6_157100_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000675/resources/images/figure07_hu775c7926d6e4f969660898e7e32806c6_157100_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000675/resources/images/figure07_hu775c7926d6e4f969660898e7e32806c6_157100_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000675/resources/images/figure07.png 2189w" 
     class="landscape"
     ><figcaption>
        <p>Align to sedes grid forces words in the same sedes into vertical alignment.
        </p>
    </figcaption>
</figure>
<p>The HTML output provides a panel for selecting visualization options and displaying additional information (Figure 8). Clicking on a word shows its metrical shape, lemma, sedes, and expectancy, as well as the distribution of the lemma over sedes and the resulting z‑scores.</p>




























<figure ><img loading="lazy" alt="Interface showing data provided for a single word" src="/dhqwords/vol/17/2/000675/resources/images/figure08.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure08_hubb05a77537d012d5e6aa9dab778249dd_176247_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure08_hubb05a77537d012d5e6aa9dab778249dd_176247_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure08_hubb05a77537d012d5e6aa9dab778249dd_176247_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000675/resources/images/figure08_hubb05a77537d012d5e6aa9dab778249dd_176247_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000675/resources/images/figure08_hubb05a77537d012d5e6aa9dab778249dd_176247_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000675/resources/images/figure08.png 1903w" 
     class="landscape"
     ><figcaption>
        <p>The interactive panel that controls visualization and shows information about selected words, here showing the sedes and z‑score distribution of the lemma ζεύς, found in <em>Iliad</em>  1.5.
        </p>
    </figcaption>
</figure>
<h2 id="interpretation-of-zscores">Interpretation of z‑scores</h2>
<p>The essential aspect we hope to capture with SEDES is how expected, in some human sense, a lemma is at a particular metrical position. There are many possible ways to quantify expectancy (e.g., frequency charts à la <sup id="fnref2:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>); the one we have chosen is the z‑score. The z‑score is an adaptive measure that does not assume a specific prior distribution of counts over sedes. Because the z‑score is normalized to the standard deviation of a distribution, it provides a common basis of comparison for all lemmata, whether frequent or rare. Let us take two examples to explore the meaning of the z‑score and how it is affected by the underlying sedes distribution. The two lemmata we will look at both occur over 50 times, but with markedly different distributions.</p>
<p>First, consider the lemma μορφή (shape; beauty). It overwhelmingly appears at sedes  11, and only rarely occurs at four other sedes. Sedes  11 is assigned a z‑score of +0.33, whose nearness to zero indicates that it is expected, or unmarked, at this sedes.<sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>  In contrast, the rarely occurring sedes are assigned large negative z‑scores, less than −3.00, which indicate a low degree of expectancy.<br>
Sedes distribution and expectancy of μορφή.    Sedes  x    z‑score      1  8  −3.01      2  2  −3.15      4  5  −3.08      6  1  −3.18      11  150  +0.33   <br>
Next, consider the lemma δένδρεον (tree). Its distribution is less skewed. It occurs with roughly equal frequency at sedes  3, 7, and 9; still more often at sedes  1, but not overwhelmingly so. This lemma is more likely to appear at sedes  1 than at any other single sedes — but sedes  1 accounts for fewer than half of total instances. In this distribution, a count of 11 is closer to typical than a count of 19. The evenly distributed sedes accordingly get negative z‑scores that are relatively close to zero. The sedes with a larger count gets a positive z‑score, farther from zero.<br>
Sedes distribution and expectancy of δένδρεον.    Sedes  x    z‑score      1  19  +1.30      3  10  −1.02      7  12  −0.51      9  11  −0.76   <br>
The extreme z‑scores — those that are most negative and most positive — naturally stand out as being worthy of attention. The most negative scores are the rare outliers, the sedes at which a lemma appears much less frequently than usual. The first example above illustrates such a situation. A large negative score is a hint (though not a guarantee) that something unexpected is happening compositionally: perhaps a common word is used in an uncommon way, or as part of an uncommon poetic structure. In the other direction, the most positive z‑scores show where a lemma appears  <em>more</em>  frequently than usual. Note an apparent contradiction: in order for a lemma to be more than expected at a certain sedes, it must appear there a large number of times — does that not make the lemma actually expected at that sedes? But there is no contradiction, really: large positive z‑scores arise only with counts that are larger than the mean, but which are outweighed by the sum of smaller counts at other sedes. The second example above is such a case. In contrast to the rare outliers signified by large negative z‑scores, large positive z‑scores represent occurrences that occur frequently yet are still unusual in the larger context of the lemma. The diverging color scale visualization options bring out both phenomena.</p>
<p>It is important not to confuse z‑scores with pure frequency counts. A low z‑score does not mean that a lemma itself is uncommon. Just the opposite: it means that  <em>a particular sedes</em>  is an uncommon one for the given lemma. Intuitively, a lemma’s appearance at one sedes can only count as unusual if there are sufficiently many instances of the lemma at other sedes to establish what usual is. Large negative z‑scores are only possible with frequently occurring lemmata. To reach a z‑score as low as −2, there must be at least 5 total instances of a lemma; for −5 there must be at least 26; and for −10 there must be at least 101. (Compare to the empirical distribution of z‑scores in Figure 2.)</p>
<p>It may happen that the demands of poetic form affect word placement and therefore the distribution of sedes. For instance, some lines in a poem may be more or less formulaic than others, and therefore be more or less constrained in their composition. Suppose that in a special subset of lines (invocations, say), a certain lemma falls at a sedes at which it does not commonly appear in other, non-invocation lines. The relatively low frequency of the lemma at its place in an invocation is, then, partially a reflection of the relative rarity of invocation lines. In the subset of lines that are invocations, the lemma may in fact be perfectly expected at a sedes that is unusual in the wider context of the poem. It is possible to imagine specializations of sedes expectancy that take into account additional factors, such as the functional or literary purpose of the lines in which words appear. Doing so, however, requires presupposing criteria by which a work is to be subdivided. Our present purpose is different: to use sedes as a tool to  <em>discover</em>  where the placement of words has been affected, whether by formula or by any other cause.</p>
<h2 id="sedes-in-action-formula-and-intertext">SEDES in Action: Formula and Intertext</h2>
<p>We have engineered SEDES to be useful for diverse types of analysis and, by making the code available as free software, to be adaptable to the interests of future researchers of metrical position in Greek hexameter, by itself or in tandem with other digital humanities tools. Most readily, it is designed to compute and visualize the frequency of lemmata. Users can explore the corpus with the visualization (either online or by downloading the program), look for dark shading among the sea of gray, and click for statistics on the lemma. Or, after downloading the program, they can create the CSV file of underlying data and organize it in a spreadsheet according to their own interests, for example by ordering rows by lemma and z‑scores. Once the user finds a word in an unexpected position, they then can interpret its literary significance (see, e.g., <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>). As a sample of its functionality in relation to established ways of interpreting Greek hexameter, in what follows we briefly gesture towards the integration of sedes analysis with two prominent interpretative modes: formularity and intertextuality.</p>
<p>SEDES adds granular, novel information to our understanding of formulaic regularity. In oral-poetic theory and Homeric philology, the formula serves as one of the most basic and useful units of composition, though the quality and nature of the formula in epic diction is highly contested.<sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>  As defined by <sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>, a formula is  “a group of words which is regularly employed under the same metrical conditions to express a given essential idea”  (<sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup>; cf. <sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup>   “une expression qui est régulièrement employée, dans les mêmes conditions métriques, pour exprimer une certaine idée essentielle” ). Despite its focus on single and not groups of words, SEDES helps to identify unexpected behavior in constituent words of the group, behavior that should inform our conception of formulaic regularity. Take the phrase πατρίδα γαῖαν, (to one’s) fatherland. Using a collated lemma search in the <sup id="fnref1:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> or a phrase search in the <sup id="fnref1:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>, we find that the phrase πατρίδα γαῖαν occurs 21 times in the  <em>Iliad</em> , with 19 instances positioned at line end (after the bucolic diaeresis at sedes  9–12).<sup id="fnref:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup>  Iliad 15.499 is typical:</p>
<blockquote>
<p>οἴχωνται  σὺν  νηυσὶ  φίλην  ἐς  πατρίδα  γαῖαν<br>
( <em>Iliad</em>  15.499, πατρίς  z = +0.51 at sedes  9, 19 instances at line end)</p>
</blockquote>
<p>There is variance in the preceding elements: most often the phrase is introduced with the preposition φίλην ἐς (to the beloved (fatherland)), though three instances at line end lack preceding φίλην ἐς ( <em>Iliad</em>   7.335, 13.645, and 15.706). Although the phrase πατρίδα γαῖαν is highly regular and predictable in other respects, two exceptional instances in the  <em>Iliad</em>  shift its metrical position away from line end:</p>
<blockquote>
<p>ἐμβαδὸν  ἵξεσθαι  ἣν  πατρίδα  γαῖαν  ἕκαστος<br>
( <em>Iliad</em>  15.505, πατρίς  z = −1.81 at sedes  7, Ajax to Achaians)</p>
</blockquote>
<blockquote>
<p>σὴν  ἐς  πατρίδα  γαῖαν, ἐπεί  με  πρῶτον  ἔασας<br>
( <em>Iliad</em>  24.557, πατρίς  z = −2.37 at sedes  3, Priam to Achilles)</p>
</blockquote>
<p>In the two exceptions, by collating the paired lemmata search or phrase search with the SEDES visualization, we see that there is also a change in the expectancy of the phrase’s constituent parts, πατρίς and γαῖα. Sedes  9 is a natural place for the lemma πατρίς, whether or not part of a formula. While γαῖα remains relatively expected in each position, in sedes  3 and 7 πατρίς is placed unexpectedly (Figure 9).</p>




























<figure ><img loading="lazy" alt="Table showing x, x/Σx, and z values" src="/dhqwords/vol/17/2/000675/resources/images/figure09.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure09_hucb6be1d89402cc7b17cf300f00e5cc29_41297_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure09_hucb6be1d89402cc7b17cf300f00e5cc29_41297_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure09_hucb6be1d89402cc7b17cf300f00e5cc29_41297_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000675/resources/images/figure09_hucb6be1d89402cc7b17cf300f00e5cc29_41297_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000675/resources/images/figure09_hucb6be1d89402cc7b17cf300f00e5cc29_41297_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000675/resources/images/figure09.png 1844w" 
     class="landscape"
     ><figcaption>
        <p>Table of lemma πατρίς (οf one’s fathers) by sedes in the Archaic subset of the corpus, with expectancy. The total number of instances of the lemma is Σx = 133.
        </p>
    </figcaption>
</figure>
<p>When comparing the instances of the phrase at  <em>Iliad</em>  15.505 and 24.557 with the 19 others at line end, there is a difference in formularity. If you were to ask which instances of the formula πατρίδα γαῖαν are most formulaic, it seems reasonable to claim that the 19 instances of the phrase at line end are more formulaic than the two that occur elsewhere, due to their regularity in that position of the line. This in itself suggests that not all instances of even a single formula are equally expected in a given metrical position. But we could have seen this shift of phrase even without SEDES, using, for example, the repeated phrase tool of the Chicago Homer or a proximity search for the two lemmata in the  <em>Thesaurus Linguae Graecae</em> . What SEDES allows us to see for the first time is that the placement of the phrase at sedes  3 and 7 not only deviates from normal metrical placement for the  <em>phrase</em> , it places the  <em>word</em>   πατρίς, in particular, in a less expected place. In other words, while the phrase is formulaic in all instances, it is less so in  <em>Iliad</em>   15.505 and 24.557, where it is out of place and where its constituent words, especially πατρίς, stray from their typical positions.</p>
<p>This new information about the differing metrical behavior of constituents of formulae has at least three effects. First, it nuances the notion of the flexibility of formulaic language <sup id="fnref:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup>. SEDES shows that words within a phrase may behave in different ways  <em>qua</em>  words, even if they remain contiguous within the phrase and the phrase is not otherwise expanded or contracted. Future work on epic formularity can adapt and incorporate SEDES to fit different models of concepts central to the idea of the formula. If scholars of epic language who are committed to the empirical investigation of formularity are to define the quality and nature of this fundamental component of epic composition, the sedes expectancy of constituent elements of formulae — individual words — should factor into notions associated with formularity, such as typicality, regularity, expectation, economy, and flexibility.</p>
<p>Second, unexpected constituents of a formula may interact with other literary features of a text. Scholars have shown how the meaning of individual elements of formulae, such as an epithet, can become more or less salient at different moments in the text <sup id="fnref:67"><a href="#fn:67" class="footnote-ref" role="doc-noteref">67</a></sup>, <sup id="fnref:68"><a href="#fn:68" class="footnote-ref" role="doc-noteref">68</a></sup>, <sup id="fnref:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup>.  <em>Sedes</em>  expectancy may also do something similar when one or more elements of a formula occurs in an unexpected position. Of the two instances above, the more statistically marked instance of πατρίδα is at  <em>Iliad</em>   24.557, in which it occurs at a sedes (3) that is more than two standard deviations away from the mean (z = −2.37). In the context of book 24, the unexpected placement of πατρίς (of one’s father[land]) concords with the book’s emphatically paternal semantics, several of which align with the sedes of πατρίδα. The final book of the  <em>Iliad</em>  features a clandestine visit by Priam, the king of Troy, to Achilles’ tent through divine aid. Priam appears suddenly at Achilles’ camp and kisses Achilles’ hands (24.477–9), astounding Achilles and his companions (θάμβος…θάμβησεν…θάμβησαν Iliad 24.482–4), and utters his first words of petition: remember your father (μνῆσαι πατρὸς σοῖο   <em>Iliad</em>  24.486). As <sup id="fnref:70"><a href="#fn:70" class="footnote-ref" role="doc-noteref">70</a></sup> states,  “Priam’s first words are a culmination of (the  <em>Iliad</em> ’s) theme (of father–son relationships).”  In this sudden, incipient statement, πατρός occupies sedes  3, a less expected position for the lemma πατήρ (z = −1.24) and the same unexpected sedes as πατρίδα (γαῖα) later. It is notable that of the twenty instances of words with the root πατρ- in  <em>Iliad</em>   24, only this πατρὸς, the errant πατρίδα (γαῖαν) of 24.557, and one final instance (24.592) occur in sedes  3. The last time that Achilles addresses Patroklos, whose name etymologizes as glory ( <em>kleos</em> ) of the father ( <em>patr-</em> ), the name of his dead companion occurs in sedes  3 (μή μοι Πάτροκλε σκυδμαινέμεν, Iliad 24.592) for the only time in the vocative case — a case particularly marked for Patroklos, as the narrator famously speaks it in apostrophe eight times <sup id="fnref:71"><a href="#fn:71" class="footnote-ref" role="doc-noteref">71</a></sup>. Moreover, as a phrasal search in <sup id="fnref2:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> shows, the lines immediately surrounding the shifted πατρίδα γαῖα are suffused with paternal referentiality, including an interformulaic reference to the fatherly petitions of Chrysês in book 1 (δέξαι ἄποινα   <em>Iliad</em>   24.555 ≈ δέχθαι ἄποινα 1.23) and the often parental formula, ζώειν καὶ ὁρᾶν φάος ἠελίοιο, spoken by Thetis about Achilles twice (18.61, 442; cf. 24.562) and by the Trojan leader Anchises after pleading for his flourishing progeny (θαλερὸν γόνον) in the  <em>Homeric Hymn to Aphrodite</em>  (104–5).<sup id="fnref:72"><a href="#fn:72" class="footnote-ref" role="doc-noteref">72</a></sup>   Sedes expectancy draws our attention to potential cross-effects of the unexpectedly placed πατρίς, related words in the same sedes, and paternal thematics in the passage.</p>
<p>Third, the fact that otherwise formulaic phrases, lines, or passages may contain words that are unexpectedly placed can reveal craft where before the reader may have assumed strict regularity. We see this especially at work in passages that are repeated verbatim in two or more places. Take, for example, Ajax’s speech to the Achaians in  <em>Iliad</em>   15.560–64, three lines of which are repeated from book 5 (15.562–64 = 5.530–32). We may visualize sedes expectancy and repeated phrases together using SEDES and notation from the <sup id="fnref3:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> ( <em>Iliad</em>   15.560–64):</p>
<blockquote>
<p>Ἀργείους  δ’  ὄτρυνε  [1[2[3μέγας  [4Τελαμώνιος3]  Αἴας·2]4]<br>
[5[6[7ὦ1]  [8[9φίλοι7]  ἀνέρες9]  ἔστε,8]  καὶ6]  αἰδῶ  θέσθ’  ἐνὶ  θυμῷ,5]  [10ἀλλήλους  τ’  αἰδεῖσθε  [11κατὰ  [12κρατερὰς  ὑσμίνας.11]12]  αἰδομένων  δ’  ἀνδρῶν  πλέονες  σόοι  ἠὲ  πέφανται· φευγόντων  δ’  οὔτ’  ἂρ  κλέος  ὄρνυται  οὔτέ  τις  ἀλκή10].</p>
</blockquote>
<blockquote>
<p>Great Telamonian Ajax roused the Argives: Oh friends, be men, and put shame in your heart, and consider one another throughout the fierce struggles. When men are considerate more of them end up safe but when they flee there is neither glory nor any warcraft.</p>
</blockquote>
<p>It is immediately apparent that within the passage’s formulae there is variation in the expectancy of individual words. Some phrases contain words that are especially expected in their given sedes, such as the pronoun and epithets (phrases 1–4) on line 560. We see greater disparity beginning on line 561, where, although they occur elsewhere in repeated phrases, words such as ἀνέρες (men) and αἰδῶ (shame) are less expected. Perhaps what is most interesting is that the lines (passage 10) repeated verbatim from book 5 contain several unexpected placements of words at sedes  4 (αἰδεῖσθε, ἀνδρῶν, and οὔτ᾽). Here, sedes expectancy joins other remarkable stylistic features, such as the pragmatic focus on the participles αἰδομένων and φευγόντων which begin both their lines and sentences opposed rhetorically in antithesis (fighting vs. fleeing). Rhetoric affects word order which, with SEDES, we can now see shifts words from their more typical positions and can result in stacking of unexpectedly placed words along particular sedes. SEDES also reveals that formulaic analysis with frequency data is insufficient in articulating the regular or erratic composition of constituent features of this otherwise repetitious material of epic diction, as is especially apparent in longer passages repeated verbatim.</p>
<p>There are likely more ways that sedes expectancy can alter our understanding of epic formularity, the identification and study of which will occupy future research with SEDES. For example, it is clear from the brief look at sedes expectancy and formulae above, in particular the regularity of πατρίδα γαῖα at line end, that formulae too have sedes expectations of their own. Adaptation of SEDES code and methodology could assist in articulating these expectations quantitatively, a function that could then better identify moments when even formulae subvert expectation.</p>
<p>SEDES allows scholars to better locate and qualify intertextual relationships between different passages based on the sedes expectation of lemmata. While the utility of sedes expectancy to intertextuality is argued more extensively in <sup id="fnref1:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>, below is a synopsis of the significance of sedes expectancy to words that appear in the same or different sedes in two texts (Figure 10).</p>




























<figure ><img loading="lazy" alt="Matrix with expectancy of sedes of one word between the same or different texts." src="/dhqwords/vol/17/2/000675/resources/images/figure10.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000675/resources/images/figure10_hu7f389ba58335378bd710234a18db4a10_113155_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000675/resources/images/figure10_hu7f389ba58335378bd710234a18db4a10_113155_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000675/resources/images/figure10_hu7f389ba58335378bd710234a18db4a10_113155_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000675/resources/images/figure10.png 1421w" 
     class="landscape"
     ><figcaption>
        <p>Matrix of sedes intertextuality by expectancy.
        </p>
    </figcaption>
</figure>
<p>Passages that feature the same lemma in the same sedes have different interpretations given the expectancy of the lemma. If a word is expected in a particular position, such as πατρίδα in sedes  9 (z  = +0.51 in the Archaic corpus, cf. above), its appearance there in two or more passages should not in and of itself suggest intentional reference or allusion. Rather, it is likely to be the result of typical compositional practice for hexameter poetry, what <sup id="fnref:73"><a href="#fn:73" class="footnote-ref" role="doc-noteref">73</a></sup> calls modello-codice (generic model). But if a word occurs in the same unexpected sedes in both passages, it is more likely to be a direct reference, what <sup id="fnref1:73"><a href="#fn:73" class="footnote-ref" role="doc-noteref">73</a></sup> calls modello-esemplare (individual model). An example of this can be found in the highly unexpected placement of the lemma σελήνη (moon), which occurs only twice at sedes  6.5 (x  = 2, Σx  = 157, z  = −8.80 in the whole corpus): in the Shield of Achilles passage in both  <em>Iliad</em>   18.484 and Quintus of Smyrna’s  <em>Fall of Troy</em>   5.8. SEDES provides readers of Greek hexameter the quantitative information necessary for better distinguishing between generic and individual types of intertextuality when regarding the shared metrical position of words.</p>
<p>In the past, scholars would often disregard the possibility of an intertextual relationship if a word occured in different sedes. Sedes expectancy, however, provides a way to identify new intertexts even in cases when there is a difference in sedes. When a word occurs in different sedes that are both relatively unexpected, in both instances the unexpected sedes reflects a break in the pattern of expectancy and thus merits further attention. For example, the name of the goddess Ἀφροδίτη occurs at sedes  6 in  <em>Iliad</em>   9.389 (οὐδ’ εἰ χρυσείῃ Ἀφροδίτῃ κάλλος ἐρίζοι) and at sedes  2 in  <em>Od</em> . 20.73 (εὖτ’ Ἀφροδίτη δῖα προσέστιχε μακρὸν Ὄλυμπον), both of which have z‑scores of −10.0 in the whole corpus, which are among the lowest of any lemma–sedes pair; the other 99% of the time Ἀφροδίτη occurs exclusively at sedes  10 (x  = 200, Σx  = 202, z  = +0.10).<sup id="fnref:74"><a href="#fn:74" class="footnote-ref" role="doc-noteref">74</a></sup>  Despite their different sedes, both instances thwart expectations. This fact should cause the researcher to investigate the two further, at which point other collective features emerge: shared language such as the works of Athena (ἔργα δ᾽ Ἀθηναίη) in adjacent lines ( <em>Iliad</em>   9.390,  <em>Od</em> . 20.72) or their presence in character speech by notoriously versatile speakers, Achilles and Penelope; cf.  <sup id="fnref:75"><a href="#fn:75" class="footnote-ref" role="doc-noteref">75</a></sup>. Conversely, in cases in which the expectancy of the word is high in both sedes, or mixed high and low, there is perhaps less reason to suppose intertextuality by sedes is a helpful mode of interpretation. Such statistical data combining word and meter could inform future quantitative intertextuality such as that of <sup id="fnref1:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> and as described in <sup id="fnref1:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>. By focusing interpretive efforts on statistically marked instances of words, SEDES gives readers of hexameter an additional tool with which to investigate repetitive phenomena in Greek epic such as formulae and intertexts.</p>
<h2 id="conclusion">Conclusion</h2>
<p>SEDES reached its current state through a long process of evolution and iterative development. It originated as a tool to investigate sonic patterns in poetry, by identifying lines with similar tonal patterns, counting letter n-grams, and quantifying alliteration. It later became specialized for the purpose of finding the metrical positions of all occurrences of forms of a lemma, which enabled analysis of the kind we have described in this article, albeit of only one lemma at a time. At that point, we were using texts sourced from the Thesaurus Linguae Graecae <sup id="fnref2:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> and Diogenes <sup id="fnref:76"><a href="#fn:76" class="footnote-ref" role="doc-noteref">76</a></sup> as a tool for lemma lookup. A concrete vision began to take shape of what we wanted to accomplish with SEDES: to compute metrical positions and other statistical information about every word in a large corpus, in an automated fashion. The difficulty of automating Diogenes lookups, and a general preference for freely available data sources, caused us to switch our source of texts from the Thesaurus Linguae Graecae to Perseus, and to begin developing programs around the direct processing of source TEI files. Automating all the steps of the processing pipeline made it feasible to start producing visualizations of an entire work at a time.</p>
<p>The decision to switch to Perseus texts was an important one, enabling us to take control over the entire processing pipeline. Moreover, open-access texts facilitate reproducibility of statistical results, and lower the barriers to participation by people who are not specialists in classical studies. Regardless of the source of texts, a project of this nature requires paying substantial attention to textual and data-format issues.</p>
<p>SEDES was developed in the context of a set of texts we wished to analyze and does not automatically generalize to other Greek hexameter texts. Analyzing texts outside the set we have considered will likely require manual tweaking of the processing programs, as well as adding to the tables of manual lemmatizations and scansions for words and lines that resist automatic processing. When we expanded the corpus from six to twelve texts, to incorporate Hellenistic and Imperial Greek works, we had to make adjustments to the TEI parser to account for previously unseen markup variations. <sup id="fnref:77"><a href="#fn:77" class="footnote-ref" role="doc-noteref">77</a></sup>  A beneficial side effect of this work has been the discovery and correction of various errors in the source texts.</p>
<p>SEDES provides groundwork for future corpus-level analysis of Greek hexametrical poetry, including by combining textual features (lemma, sedes, and metrical shape) in different ways and by expanding to additional features. More generally, it provides a framework for the analysis of metrical position in metrical language, by which the researcher assembles a corpus, analytical pipeline, and visualization of basic statistics for further development of the program, model, concept, and interpretation and appreciation of the text. Due to the limited size of the Greek hexameter corpus, the method results more from the slow work of philology using basic statistics than from the capacious abilities of machine learning. In some respects, this methodology reflects the disciplinary background of the authors. Yet the benefits of such an interest in poetic language within a limited corpus have focused our attention on a particular approach to lemmatized word frequencies correlated with metrical position. This attention to metrical position, a long-standing interest in classical philology, demonstrates a new route for future studies that seek strong correlations between linguistic phenomena and other formal features of Greek poetry.</p>
<h2 id="availability">Availability</h2>
<p>SEDES source code and documentation are available at <a href="https://github.com/sasansom/sedes">https://github.com/sasansom/sedes</a>. The project home page, with sample visualization outputs, is <a href="https://sasansom.github.io/sedes/">https://sasansom.github.io/sedes/</a>.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>We express gratitude to Patrick Burns, author of CLTK’s Greek lemmatization; Kyle P. Johnson of CLTK; Hope Ranker, author of the hexameter scansion module; Lisa Cerrato of the Perseus project; David Mimno; Rachel Greenstadt; Annie Lamar; Simeon Ehrlich; Stanford’s Center for Spatial and Textual Analysis (CESTA); and the  <em>Digital Humanities Quarterly</em>  reviewers.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:3">
<p>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<pre><code>_ Caesura _  ( “cutting” ), as in a pause or word break in a verse, with τομή as the Greek equivalent (cf.  _LSJ_  s.v. τομή IV.2). 
</code></pre>
&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:13">
<p>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p>&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p>&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:65">
<pre><code>_Iliad_  2.140, 158, 174, 454, 4.180, 5.687, 7.335, 460, 9.27, 47, 414, 11.14, 13.645, 15.499, 505 (sedes  7–10), 706, 16.832, 18.101, 23.145, 23.150, 24.557 (sedes  3–6); note also the variants, in the fatherland (ἐν πατρίδι γαίῃ) at  _Iliad_  3.244, 8.359, and 22.404, and from one’s fatherland (γαίης ἄπο πατρίδος) at  _Iliad_  13.696 and 15.335.
</code></pre>
&#160;<a href="#fnref:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:66">
<p>&#160;<a href="#fnref:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:67">
<p>&#160;<a href="#fnref:67" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:68">
<p>&#160;<a href="#fnref:68" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:69">
<p>&#160;<a href="#fnref:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:70">
<p>&#160;<a href="#fnref:70" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:71">
<p>&#160;<a href="#fnref:71" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:72">
<p>&#160;<a href="#fnref:72" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:73">
<p>&#160;<a href="#fnref:73" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:73" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:74">
<p>&#160;<a href="#fnref:74" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:75">
<p>&#160;<a href="#fnref:75" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:76">
<p>&#160;<a href="#fnref:76" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:77">
<p>&#160;<a href="#fnref:77" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">An Integral Web-map for the Analysis of Spatial Change over Time in a Complex Built Environment: Digital Samos</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000652/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000652/</id><author><name>Estefanía López Salas</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-05-26T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>The project Digital Samos is devoted to study the monastic site of San Julián de Samos, which is one of the most ancient and largest monasteries in Spain. We examine the evolving nature of the monastic architecture along with its surrounding environment, the sacred precinct, and the nearby village. This monastic compound has been written and re-written through continuous spatial changes over the course of centuries. As a consequence, Samos is currently a palimpsest, that is, a complex built environment defined by multiple historical layers.</p>
<p>Despite the monastery as a single entity has been largely examined by scholars since the late 19th century onwards,<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>  the monastic site as a totality of the religious buildings and their agricultural plots, the nearby urban tissue, the geographical setting, and the surrounding landscape, was not previously addressed when the present project began. This is probably due to the difficulties that spatiotemporal analysis involves in the case of built environments defined by layers that cross millennia.</p>
<p>To uncover and reconstruct those historical layers in spatial and temporal terms, we utilize a multidisciplinary approach that combines historical sources, evidence-based investigation, and digital technologies. Historical sources related to monastic architecture and landscape at Samos are diverse and, sometimes, scarce, incomplete, or uncertain. The extant fragments of past monastic compounds may appear currently decontextualized, dispersed, hidden, or even lost. As a consequence, to investigate and reconstruct those multiple layers poses a set of challenges that concerns both urban history and architectural history. Digital tools can help us to overcome those challenges.</p>
<p>Through computer-aided design (CAD) tools we created a series of phased 2D maps and 3D models that visualize the main stages of the monastic site evolution from the High Middle Ages to the early 21st century. These digital visualizations help us, as scholars, to gain a better understanding of the processes by which the monastic site of San Julián de Samos was designed, understood, changed, and experienced over time as a totality of topography, architecture, and human history.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  A number of initiatives has also demonstrated in recent decades that the communication of knowledge with digital methods in academia can promote the understanding of cultural heritage and spread awareness of the importance of preserving and protecting historical architecture along with its context outside academia.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
<p>In June 2018, we began a new in-process work for the project with the creation of an interactive web-map, hosted by Universidade da Coruña at <a href="https://digitalsamos.udc.es/interactive_map.html">https://digitalsamos.udc.es/interactive_map.html</a>.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>  This new stage emerged from our participation in the Getty Summer Institute  “Advanced Topics in Digital Art History: 3D (Geo)Spatial Networks”   <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, where instructors and participants illustrated how web-based platforms have become essential vehicles for presentation and dissemination of research about architectural heritage. They can be also thought and designed as tools to ensure the intellectual integrity of computer-based visualization outcomes in research and communication of urban and architectural history <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>In addition, an issue of major concern in the architectural community and virtual heritage domain at large is how we can publish graphic materials such as vector plans, 3D models, or geospatial historical maps in such a way that their rigor is clear to their full consideration as research arguments. Print and online publications not only put a limit on the number of figures or illustrations to be published per article, but they also establish specific types of image file formats, which are generally raster graphics. The first issue — number — gives priority to prose in scientific publications. This fact usually leads to the consideration of graphic materials or multimedia outputs as an accompaniment to the text, but not the research arguments themselves <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>  <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.</p>
<p>As Freddolini recently pointed out,  “… the activity of writing involves diverse aspects that include the possible ways to visualize and disseminate my research… Tools for data visualization, to cite only one example, are not only a corollary –or a demonstration– of what I  write , but essential components of the arguments I aim to create…”   <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. However, the use of common image file formats force researchers in those fields to convert their original vector CAD architectural plans, graphic 3D models reconstructions, or geospatial GIS historical maps into fixed images when they aim to publish their work. As a consequence, historical data and the different types of thinking and interpretation that were made and integrated in the computer-aided design visual materials, through layers, categories, or attributes, are generally lost.</p>
<p>This is a common challenge we faced when we tried to communicate the results of our research about the monastic site of San Julián de Samos. The interactive web-map of Digital Samos is created to overcome that challenge through the use of web-mapping tools, while it also promotes the understanding of the historical site among scholars and public. It displays the extensive knowledge we acquired about this complex built environment through on-site and archival research into a digital publication, in which the reader is granted access to the evolution of the historical site. In addition to cartographic display showing detailed information about the setting topography and the compound of the monastic site (buildings, precinct, and village), the web-map aims to become a more scientific successor to the phased CAD maps we previously created. By taking advantage of the potentials of the digital domain, we try to overcome the limitations of the traditional series of fixed images in which we converted the CAD maps for prior dissemination of our research. Instead of static phased maps that revealed the complexity of spatiotemporal changes by means of time fragmentation or color coding design, the prototype web-map we present in this paper walks toward a more integral and effective online interface, where the final user is able to interact with space, time, scale, layers, and sources. All spatial entities are displayed in the form of web graphic features with attributes with historical data and interpretation within one single digital output.</p>
<p>The paper is organized into three main parts. First, we present the project focus on the spatiotemporal analysis of a centuries-old Spanish monastic site and its main outcomes so far. Second part is devoted to the specific domain of web-mapping tools. Based on related works and projects in the field, we show how web-mapping can help us to better make sense of complex built environments that humans have formed and re-formed over time. As this point we also connect our project to existing literature in Spatial Humanities on deep mapping, thereby contextualizing the present case study. Then, we explain how we faced the process of creating an integral scientific web-map for Digital Samos that goes beyond static 2D representations of a multi-layered past physical realm in a definitive publication. We present the workflow, its potential, and pitfalls. Finally, we discussed the challenges, the present limitations, and the future developments of what we consider a functional prototype web-map for spatiotemporal analysis, presentation, and dissemination in the field of digital art and architectural history, while we also summarize why this project is valuable as a case study. The web-map is here conceived as a means for public outreach, a self-explanatory visual product, in which accessibility, transparency, legibility, and integrity of visual and textual spatial data in a digital environment aims to promote a fuller understanding of the process that defined the past monastic site(s).<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></p>
<h2 id="san-julián-de-samos-beyond-historical-practice">San Julián de Samos beyond historical practice</h2>
<p>The main art historical question in the project San Julián de Samos is spatial change over time of a historical monastic site that includes the monastic buildings, the sacred precinct, the nearby village, and the surrounding rural area (Figure 1). The monastery was founded before the 7th century and, like most religious houses, it changed across its long life through constant constructions and re-constructions. Studying the question of spatial change over time is crucial to analyze how the site was conceived, understood and experienced, as a sum of different pieces (monastic buildings, topography, urban tissue, geographical features) instead of as a single artifact (Figure 2).</p>




























<figure ><img loading="lazy" alt="A set of three Google map screencaps showing the location of the monastery of San Julián de Samos, increasingly zoomed in from left to right." src="/dhqwords/vol/17/2/000652/resources/images/figure01.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure01_hub9c144cb69b0a2447520c9ca4312086f_1063423_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure01_hub9c144cb69b0a2447520c9ca4312086f_1063423_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure01_hub9c144cb69b0a2447520c9ca4312086f_1063423_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure01_hub9c144cb69b0a2447520c9ca4312086f_1063423_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure01_hub9c144cb69b0a2447520c9ca4312086f_1063423_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure01.jpg 4606w" 
     class="landscape"
     ><figcaption>
        <p>Google Satellite maps showing the location of the monastery of San Julián de Samos in progressive closeness to the country (Spain), the province (Galicia) and the place (Samos).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="A color photograph of the monastery of San Julián de Samos. The site is seen at a distance and form slightly above, as though the photographer is on a hill above the site. A group of buildings of various layout and construction are seen in a small valley between green forested hills." src="/dhqwords/vol/17/2/000652/resources/images/figure02.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure02_hu4675d334d7e155fea2ceec59f4f94412_3488572_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure02_hu4675d334d7e155fea2ceec59f4f94412_3488572_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure02_hu4675d334d7e155fea2ceec59f4f94412_3488572_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure02_hu4675d334d7e155fea2ceec59f4f94412_3488572_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure02_hu4675d334d7e155fea2ceec59f4f94412_3488572_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure02.jpg 4000w" 
     class="landscape"
     ><figcaption>
        <p>The monastery of San Julián de Samos and its present context. Photograph: June 2011, the author.
        </p>
    </figcaption>
</figure>
<p>The first part of our research process comprised the collection of historical and contemporary sources. Historical ones are very disparate from each other, such as building contracts, rental agreements, books of demarcations, cadasters, historical photographs, old maps, expropriation records, and civil engineering projects. Contemporary sources collected are images, plans, on-site investigation, measure surveys, remains, testimonies, scientific papers, book chapters, etc.</p>
<p>The second part of the research process was focused on generating 2D maps and 3D models with Computer-Aided Design programs, that is digital tools, to recreate the multiples phases of spatial change of this monastic site over time. The monastic site was re-created and then visualized through static images of plans/maps and renderings, one per each main phase of transformation (Figures 3 and 4). We used a code for 2D map drawing that is comprised of different colored lines. Each colored line has a different meaning about the knowledge it represents. For example, dark and grey lines visualize buildings that are extant nowadays, that is evidence. On the contrary, brown and orange lines are used to draw hypothetical parts of the monastic site. We also used a different color to represent those monastic proposals that were planned but not built (Figure 5).</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure03.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure03_hu9ba5392b0f7236ea70f6ae8a883ecf7c_37486152_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure03_hu9ba5392b0f7236ea70f6ae8a883ecf7c_37486152_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure03_hu9ba5392b0f7236ea70f6ae8a883ecf7c_37486152_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure03_hu9ba5392b0f7236ea70f6ae8a883ecf7c_37486152_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure03_hu9ba5392b0f7236ea70f6ae8a883ecf7c_37486152_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure03.jpg 10194w" 
     class="landscape"
     ><figcaption>
        <p>A selection of phased computer-aided design 2D maps of the monastic site of San Julián de Samos from Middles Ages to early 18th century. Images: the author.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure04.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure04_hu12f269eaccecae66322171f2f20ab793_7871620_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure04_hu12f269eaccecae66322171f2f20ab793_7871620_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure04_hu12f269eaccecae66322171f2f20ab793_7871620_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure04_hu12f269eaccecae66322171f2f20ab793_7871620_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure04_hu12f269eaccecae66322171f2f20ab793_7871620_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure04.jpg 6635w" 
     class="landscape"
     ><figcaption>
        <p>A selection of phased 3D reconstructions of the monastic site of San Julián de Samos from Middles Ages to early 18th century. Images: the author.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure05.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure05_hub3f8eab0da3086d59f0dc8fe510c89d7_1833125_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure05_hub3f8eab0da3086d59f0dc8fe510c89d7_1833125_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure05_hub3f8eab0da3086d59f0dc8fe510c89d7_1833125_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure05_hub3f8eab0da3086d59f0dc8fe510c89d7_1833125_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure05_hub3f8eab0da3086d59f0dc8fe510c89d7_1833125_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure05.jpg 2943w" 
     class="landscape"
     ><figcaption>
        <p>Vector map/plan generated with AutoCAD of the monastic site at Samos in the second half of the 16th century along with the associated layers of entities and colors classified in accordance with the status of the knowledge that they represent (evidence vs hypothesis). Images: the author.
        </p>
    </figcaption>
</figure>
<p>Through this methodology we were able to recover the lost monastic compound of the Late Middle Ages from which only some remains are extant currently <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. We could analyze the reasons behind the architectural reform that took place in the late 15th century and its consequences on the definition of a new monastic site <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. We discovered the role of monks in the creation and evolution of the sacred precinct and the immediate village of Samos, as urban planners <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>  <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. We came to understand the multiple processes that surrounded the replacement of the Romanesque church and cloister by bigger buildings, and the role that context, topography, and geographical features played in the monastic design of the 18th century. We also analyzed through digital representation how a proposed but unbuilt fourth cloister would have changed completely the historical monastic realm, as well as the losses that secularization brought to architecture and monastic landscape in the 19th century <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>  <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>  <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>.</p>
<p>The new knowledge was acquired in the process of making the maps and models due to the reasoning that was applied to create them from sources and interpretations while also filling the gaps caused by ambiguity, uncertainty, or absence of data. This is what Elena Svalduz called  “a new form of intellectual reasoning through modeling”  or representation of past spaces by means of digital visualization tools <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>. We also consider that most of this new knowledge in the form of visual products must be communicated from scholars to the scientific community and general public without losing the potential of the visual sense. However, scientific publications prioritize textual analysis as it also happens in the evaluation of knowledge production within academia, where images, videos, maps, or models that results from serious research are rarely considered as rigorous as texts. The inclusion of visual data in publications is usually restricted to a specific number of figures and its presentation is also limited by widely used raster image formats instead of vector graphics.</p>
<p>In our case, the project outcomes reveal the potential of digital visualization for art-historical academic research as we have largely published in paper conferences, journal articles, and book chapters.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>  However, the lack of funds and the high cost of print publication prevented us from presenting the project along with its sources and results in any complete fashion so far. The creation of a web presence could provide, we think, an ideal solution to not only make the research outcomes about Samos accessible and better known in and outside academia, but also to test a new form of publication beyond the limits of scientific journals in what refers to the dissemination of visual-centered projects, where drawings, maps, images, and digital graphic outputs are not a complement of the text, but a new form of scholarly production to be recognized as rigorous as textual research <sup id="fnref1:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>  <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  <sup id="fnref1:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. In addition, we should not forget that each form of communication can do something that the other cannot and, for that reason, both should be considered complementary, and neither superior, as Ethington and Toyosawa point out in their comparison of cartography, which operates by simultaneity and juxtaposition, and semantic text, which is syntactically linear and narratological <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. In this way the idea of creating an interactive web-map of the spatiotemporal changes at the monastery of San Julián de Samos was born.</p>
<h2 id="references-and-goals-for-digital-samos-web-map">References and goals for Digital Samos web-map</h2>
<p>Working with 2D maps and 3D models poses a set of challenges in publication. The main one is the file format. While maps and models that reconstruct past spaces are usually created with computer-aided design or 3D computer graphics software toolsets, print and online scientific journals mainly display these types of digital products in the form of images, that is, fixed visual representations of real or imagined past spaces. None of the data on which the generation of the digital product was based on, or the interpretations the scholars made through various types of thinking, are usually published along with the images. They may be explained in the prose narrative that the images accompany, but as two entities separately <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>.</p>
<p>This fact leads to a main difference between the map or model made by the scholar with the final map or model to be published in what refers to information and interpretation. It also shows another difference, which is not always visible, between the way we display and read text and images in scientific publications. While we are able to quote any excerpt of the text to cite the source or sources in which our argument is based, such quotation is not possible in the case of spatial features that define the image of a 2D map or a 3D model. As a consequence, the connection between our visual arguments and their evidence is lost <sup id="fnref1:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>, although it is fundamental to guarantee the rigor and transparency of scholarly publication.</p>
<p>This is an issue of major concern in the computer-based visualization of cultural heritage research community that both the London Chapter (2009) and the Principles of Seville (2011) highlight <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>  <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>  <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>. Sufficient information to document and disseminate computer-aided visualization outcomes is needed to enable the understanding of the relationship between research sources, implicit knowledge, explicit reasoning, and visualization-based outcomes, but also to facilitate the recognition of accuracy in the field.</p>
<p>The London Chapter (2009) points out that a first way to accomplish this challenge is through the publication of a two-dimensional record of the computer-based visualization outputs along with the methods used, and the interpretations made <sup id="fnref1:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. However, in this paper we propose to create a web-map were data and interpretations embedded during the generation of phased CAD maps for spatiotemporal analysis at Samos are also displayed when the online publication is faced.</p>
<p>This challenge has already been accomplished by a number of research teams in historical studies about complex built environments with different purposes and results. Such is the case of the  “Digitally Encoded Census Information and Mapping Archive”  (DECIMA), which was designed as a research tool for historians interested in early modern Florence.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>  DECIMA website is an open-access platform. In the so-called mapping tool, users can interact with mapped data from three censuses of 1551, 1561, and 1563. These are displayed on a historical map of the city from 1584 georeferenced onto a contemporary one <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. The design of DECIMA database and web platform enables users to display one census data layer or a group of them. As we zoom in the map, it is also possible to click on projected points with a cursor and a data table with associated census information about residents and properties will be displayed. In addition to that, DECIMA offers a data query tool for interactive analysis about ownership, shops, occupation, property values, or gender. It has already proved to be a powerful analytical tool that, even from simple questions, leads to new interpretations and knowledge about the modern Florence, its social conditions and relations <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. However, spatial features are simplified in the form of dots which is enough for the analysis of human movement or economic activity in the past city, but not for the study of the built environment in spatial terms.</p>
<p>In this sense, another relevant example is the project  “Visualizing the Mountain Estate: Landscape, Architecture and Experience in Chengde.”  Their authors are developing an interactive web platform thought and designed as a tool for evolving research and discovery in a historical environment.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>  The project is devoted to study an important Qing Dynasty Imperial Park in Chengde (China) that was built in multiple phases over the most part the eighteenth century and then deconstructed and reconstructed in the following two centuries. To approach how this imperial park was conceived, understood and experienced, the web-map of this project visualizes the whole built park environment along with its topography and hydrology over a current orthophotograph. The platform provides users with a layer control to select the type of landscape feature to visualize (buildings, walls, rivers, islands, lakes&hellip;). Moreover, data can be filtered by structure type, construction data and reign for selected display. As we interact with the map, it is also possible to click on each building and a pop-up with associated data is opened. Each pop-up shows organized relevant information as well as a link to extended textual data and non-textual outputs about the selected building to explore the spatial environment at will. This is a work in progress and its results are still to come, but the main aim is to enable researchers and users to query the database in the future and, by doing so, to address new questions of the historical environment through computational analysis and interactive presentation <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>.</p>
<p>In the particular field of monastic architecture, Wulfman, Mylonas, Loyer, Bonde, and Maines developed the MonArch Project website to explore the ways in which complex relationships among textual, architectural, and archaeological evidence can be represented in non-traditional formats to create a new form of scholarly expression for their work about the Abbey of Saint-Jean-des-Vignes in Soissons (France) <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>. They realized that archaeological evidence supports and illustrates the textual narrative at the same time that the latter contextualizes the archaeology and monastic architecture, so they proposed a web infrastructure that allows authors to present their arguments and also users of the website to develop their own interpretations around monasticism, the abbey’s structures, place, community, and economy based on an interactive interface.<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup></p>
<p>This project demonstrates the potential of digital representation in a web-context to publish detailed corpora of material findings, to present the spatial dimensions of social relationships, and to recover the human actions performed in the past <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. However, in what refers to the presentation and dissemination of the past architectural spaces the results are limited. They created an interactive site plan of the Romanesque abbey with a time slider and clickable phases showing some evidence options for that period, but the user is not able to directly interact with each spatial element or to have access to historical or excavated data from the visual argument, so the exploratory possibilities are somehow restricted as well as the provision of information to understand the nature of evidence and hypothesis.</p>
<p>Another promising project is an in-process collaborative platform, called SIG 4D, presented by Rollier-Hanselmann, Petty, Mazuir, Faucher, and Coulais for the case study of Cluny Abbey (France), considered the greatest building of European Christendom in the 12th century <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>. By using the TerraExplorer Pro software, they try to integrate 2D maps and 3D models created from historical data and archaeological excavations into one single GIS database and research system. Their aim is to offer scholars a digital tool for research analysis, where the access to disparate data is possible as well as its comparison to better understand the Cluniac site. The project is focused on studying the relationship between the abbey and the surrounding landscape through the hybrid nature of the archaeological artefacts. For this purpose, they argue that it is essential the collaboration and the combination of data coming from different disciplines. In the digital realm, the authors also recognize that the diversity of data and its integration in a single geographic system bring technical difficulties they still have to solve. Web-mapping and online dissemination of the SIG 4D seem to be additional aims as they presented in the project workflow <sup id="fnref1:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>, but no access to the system is accessible yet.</p>
<p>The third and last case study that this state of the art comprises is the Sera project, led by José Ignacio Cabezón <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>.<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>  It is focused on Sera, one of the largest and most important monasteries in the Tibetan world. Cabezón created a multimedia, interactive database that allows users to explore different aspects of Sera: its physical layout, history, material culture, educational system, and ritual life that, on the whole, defined what he called the richness and complexity of Tibetan monastic life.<sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>  The project includes a section devoted to the physical space of the monastery. Sera buildings are classified according to their form into: compounds, complexes, or freestanding structures.<sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>  A compound is said to be an enclosure, that is, a single building or a group of adjoining buildings with an interior courtyard, such as the main regional houses, apartments, or lama residences. A complex is a group of buildings that share some kind of association, but no necessarily adjoining and enclosed. Freestanding buildings are single structures with no association to nearby ones and with no perimeter wall.</p>
<p>The architecture of Sera is represented in an interactive web-map.<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>  They gathered data of mayor structures within the monastery, images, GPS readings, and field notes during a field trip that, later on, were the foundation to develop an image catalogue and the narrative descriptions of each building, compound, and complex of the monastery. Then, they created a digital map of the monastic site using a GIS software that was finally converted into a web-deliverable, flash map of the monastic architecture. The map is said to integrated the narrative descriptions and the image database, however it is no longer working after Adobe Flash Player was retired in 2020. This is also what happened with the MonArch Project website.<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup></p>
<p>The previous examples demonstrate the potentials of a web-map, not only as a means to access and showcase a project, but also as a research tool that allows public to explore, interpret, and analyze data in the wholeness of each case study, to pose novel questions, and to create new ways to engage with and gain knowledge about historical built environments. They also illustrate different ways to address the representation of architectural space and spatiotemporal analysis in a web context mainly from archaeological excavations and historical data. Different software tools were used in each case study in accordance with data and purposes of analysis, but also depending on funding. Moreover, while web-maps of DECIMA and Mountain Estate are fully functional, the MonArch and Sera Projects are deprecated and the SIG 4D for Cluny Abbey seems to be a desktop system on the way to being transformed into a web-map. A common concern in these projects is looking for new forms of publication in what refers to 2D maps that, first, enables interaction with different source of data, and secondly, aims to open new paths for query and exploration (Figure 6).</p>
<p>The four examples are efforts to build increasingly more complex maps of visible and invisible aspects of a place. They aspire to be more-than-representational and they put emphasis on one particular user interaction: exploration. Anyone who approaches these maps is given various possible paths to dive within them and explore different questions. We argue that they are attempts to move towards more integrated spatial frameworks for research while they also illustrate some challenges and potentials of what has recently emerged as deep mapping practices in the field of Spatial Humanities <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>  <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>  <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>  <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>  <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>.<sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup></p>
<p>Although there is no scholarly consensus on what deep mapping entails as a practice or what a deep map is as a product <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>  <sup id="fnref1:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>, the four previous examples do aim to  “record and represent the grain and patina of place through juxtapositions and interpretations of the historical and the contemporary… the conflation of oral testimony, anthology, memoir, biography, natural history and everything (their authors) might ever want to say about a place”   <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. They are not simply digital maps, but  “subtle and multilayered views of small area(s) of the earth”   <sup id="fnref1:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>  <sup id="fnref1:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup> that take advantage of the digital tools to comprise layers of meaning and process and to develop routes for new forms of spatial narratives. They are also  “shaped by a particular scholarly vision but offering an open-ended, exploratory environment”  that is only limited by available data, framework design, query tools, and the end user’s critical eye, knowledge, and imagination <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure06.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure06_hu3ce5b4ba5b1be8ebeefb095c6b63b335_2240070_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure06_hu3ce5b4ba5b1be8ebeefb095c6b63b335_2240070_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure06_hu3ce5b4ba5b1be8ebeefb095c6b63b335_2240070_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure06_hu3ce5b4ba5b1be8ebeefb095c6b63b335_2240070_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure06_hu3ce5b4ba5b1be8ebeefb095c6b63b335_2240070_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure06.jpg 4198w" 
     class="landscape"
     ><figcaption>
        <p>Four examples of scientific web-maps for research and dissemination in Art and Architectural History: 1. DECIMA WebGIS (<a href="https://utoronto.maps.arcgis.com/apps/webappviewer/index.html?id=d9692905ff41436d99cf7c398552ca39">https://utoronto.maps.arcgis.com/apps/webappviewer/index.html?id=d9692905ff41436d99cf7c398552ca39</a>); 2. Visualizing the Mountain Estate. Landscape, Architecture, and Experience in Chengde (<a href="https://blogs.ntu.edu.sg/bssz/">https://blogs.ntu.edu.sg/bssz/</a>); 3. The MonArch Project – The site of Saint-Jean-des-Vignes (Figures 3 and 7 published by [^bondeetal2009], <a href="http://monarch.brown.edu/">http://monarch.brown.edu/</a>); 4. Sera Interactive Map – Sera Project (Figure 2 published by [^budapesti2019]).
        </p>
    </figcaption>
</figure>
<p>They allow us to set the goals of the interactive web-map for our Digital Samos project in accordance with our research questions. First, through the web-map we aimed to make the spatiotemporal analysis of the monastic site at Samos accessible to a broader audience. Besides, we considered important to allow interaction between the user and the platform, not only as a way to engage new audiences, but also to enable them to learn about this historical site at its own pace. Another goal was to make readable the relations between sources upon which the research was built and any project output in order to create a reliable web environment, where intellectual integrity is guaranteed. In addition, we prioritized a fully functional result in what refers to the final representation of change over time in the web context. To achieve a detailed web-display of spatial features was considered a high issue along with their embedded data and topographical context, instead of a simplification of the original geometries into points, or ideal shapes. This implies a series of difficulties from a technical perspective, as we will explain in the following section.</p>
<p>Digital Samos is in conversation with many concerns in literature about deep mapping, as not only aspires to delineate and give shape to the locational properties of a particular monastic place. It also tries to go deep in the horizontal surface and to embrace the verticality of spatiotemporal analysis along with multimedial navigability for critical reflection and open-ended exploration <sup id="fnref2:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup> ] <sup id="fnref1:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>  <sup id="fnref2:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>. By going deeper there are more layers we discover and Digital Samos aims to give an answer to how we can hold them all together, that is, how we can frame them as a map, as deep mappers seek [Roberts 2016, 3]. All in all, the web-map of Digital Samos aims to renew the interest in the monastic past realm through accessibility and dissemination, interaction and public engagement, transparency and rigorousness, all of which is inside an integral platform, a new research tool to further our knowledge about this site in its intactness by means of interactive visual presentation and interpretation.</p>
<h2 id="from-fixed-cad-to-an-integral-web-map">From fixed CAD to an integral web-map</h2>
<p>The next step of the process was to deal with how to make all these goals possible. This was not only a technical challenge and an experiment in a new way of communicating this project about monastic architecture, urban history and landscape, but it was also an iterative process of thinking and learning through web development in an intellectual way. This is what we aim to explain next.</p>
<p>To understand the process of making the integral web-map demands, first, to remind that the project has a conceptual focus on space and on its dynamic transformation over time. Therefore, space and time are two key factors to be represented in our web-based environment. All maps and models previously generated in the project visualize spatiotemporal changes by using computer-aided design (CAD) technologies. Therefore, the first step was to explore how it might be possible to turn the existing visualizations of past spaces into a web-map that meets all the goals set before.</p>
<p>A first way to approach this challenge could be to generate one image per each phase of the evolving monastic complex and to display all of them in a website created with a content management system (CMS), even in relation with a timeline. When a map or plan is displayed in a website as a fixed image or as a series of images showed in chronological order, they do not usually have associated data to each feature represented, beyond the one we may add manually through embedded external hyperlinks, for instance. In addition to that, if we showed maps or architectural plans in this way, they would not be georeferenced either. As a result, the historical site would not dialogue with current physical realm. We would not enable audience to interpret and understand the relations between present and past monastic compounds by looking at both at the same time. These were some of the limits that early attempts in the sphere of website representation of urban history projects dealt with, lack of geo-referencing and accuracy of dependency relationships between documentation and visualizations, weak user interaction options, and short-term sustainability <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>.</p>
<p>Our aim is to push the concept of CAD maps that revealed the complexity of spatial changes over time by means of phased representations much further, toward a more integral and effective interface (Figure 7). We considered creating a digital and interactive two-dimensional map to portray spatial changes over time in permanent relationship with: previous and following realms, the present monastic complex, research sources, and extant physical remains. For the first attempt, we left the incorporation of the existing three-dimensional models pending for a future scale-up of the project. Although the sense of space provided by a two-dimensional map is limited, it is generally best to start simple and expand the project in following developments. As for time, the aforementioned two-dimensional web-map in the singular was conceived, actually, as many maps overlapped. Each one will represent a main phase of the process of changes at San Julián de Samos over time. We aimed that the multiple maps might be displayed or hidden by the user at will as a way to explore and discover spatial changes and relations between them in the interaction. In order to simplify the process of making, we also selected the most relevant stages to be represented. For that reason, each stage would be an abstraction that does not visualized changes on a short-term time basis. Although we are aware that the analytical nature of the project showed is reduced with this decision, to increase the number of stages will be possible and easier in future developments of the web-map, after learning how to face the whole process for a lower number of them.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure07.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure07_hu9690fed82455d8f627f21b02f3f936f1_17297962_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure07_hu9690fed82455d8f627f21b02f3f936f1_17297962_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure07_hu9690fed82455d8f627f21b02f3f936f1_17297962_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure07_hu9690fed82455d8f627f21b02f3f936f1_17297962_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure07_hu9690fed82455d8f627f21b02f3f936f1_17297962_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure07.jpg 9325w" 
     class="portrait"
     ><figcaption>
        <p>First conceptual model for an integral web-map showing spatiotemporal changes in the historical site of San Julián de Samos. Image: the author.
        </p>
    </figcaption>
</figure>
<p>Each single spatial feature in our existing phased maps and models shapes a building, a property, a road, or any other part of the monastic built environment in the past according to historical sources and current physical remains. We always try to show how it actually was. When sources or remains are scarce, ambiguous or even non-extant, hypotheses had to be developed by forcing a dialogue between available evidence. The hypothetical parts of our maps were made visible by means of color-coded lines. However, connections between spatial features and historical documentation or physical remains that supported the reconstruction were missing in the definite maps and models. The reason was that the software application used to generate them, AutoCAD. When this project started, this CAD program did not offer the possibility to associate non-spatial information to each spatial feature. In other words, there were no attributes appended to features displayed in our maps and models, although all of them were classified in layers according to their type, the level of knowledge and the source. However, historical data that supported the reconstructions was not readable within the 2D or 3D graphic outputs, unlike text-based research findings where we can quote any reference to a book or an archival document, for instance, by embedding its text directly in our written argument <sup id="fnref2:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>. This sort of quotation would be fundamental to create a transparent and rigorous visual output, where integrity is ensured, as we previously pointed <sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>. It would also end up in the creation of self-explanatory digital maps and models about historical sites opened to scientific evaluation, again like research scholarship in the form of text <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>.</p>
<p>With all this in mind, the next step towards the web-map was to resort to a geographic information system (GIS). They are designed to store, manage, analyze, and display spatial data, either past or present. In research about historical built environments and urban history, GIS has already been proved as a powerful tool to track and analyze changes in time. Historical maps created with GIS have many potentials: to define shapes, to create layers, to assign attributes to those shapes and layers, to represent the passage of time to some extent, and to use visualization as a means of inquiry, both in desktop and online applications <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>. In particular, we decided to use QGIS, a free and open source geographic information system.</p>
<p>At this point, the following question could arise: why not simply use a GIS system since the very beginning? This is a question that often appears in the discussions about the best approach to historical 2D/3D drawing, mapping and modelling of past architectural spaces. The short answer is that computer-aided design (CAD) and drafting applications (e.g. AutoCAD) and 3D computer graphics software (e.g. Blender, 3D max) offers much more degree of freedom with regards to freehand design and 3D modelling that is not possible in GIS or in HBIM <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>  <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. CAD tools and 3D graphics software better allow the process of reasoning or intellectual representation that is needed for the understanding and rigor reconstruction of complex past architectures. For instance, they enable the scholar to properly describe the actual irregularities of historical complex built environments, which are much more difficult to be represented with GIS or HBIM applications <sup id="fnref1:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>  <sup id="fnref1:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. On the contrary, GIS, as well as HBIM software, do integrate various types of data, so vector features may have associated datasheets with historical information that can be finally turned into web-maps.</p>
<p>To move the project from AutoCAD to QGIS was not an immediate process. We had to adapt the existing CAD files to a new program and way of working within it, along with continuous thoughts regarding how to improve the representation of spatiotemporal changes in a new web-based context as well as how to manage and structure textual data and spatial features in accordance with the proposed aims (Figure 8).</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure08.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure08_huf1e42358698321ba5b193d72e110cf12_3071963_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure08_huf1e42358698321ba5b193d72e110cf12_3071963_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure08_huf1e42358698321ba5b193d72e110cf12_3071963_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure08_huf1e42358698321ba5b193d72e110cf12_3071963_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure08_huf1e42358698321ba5b193d72e110cf12_3071963_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure08.jpg 7327w" 
     class="landscape"
     ><figcaption>
        <p>Project workflow from 2D CAD maps of the monastic site to the web-map of Digital Samos. Image: the author.
        </p>
    </figcaption>
</figure>
<p>The first step was to geo-reference the CAD files so in the web output they will be displayed in relation with present cartography. The following step was to turn CAD files into shapefiles (SHP) to be readable by QGIS.<sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>  This was not a direct step. Each map generated with CAD represents one phase of the monastic site’s biography through multiple overlapped layers. Each layer comprises diverse types of geometries: lines, circles, polylines, points&hellip; and each geometry might represent a single spatial feature or just one part of it. This is an important issue to clearly distinguished, for instance, between remains and hypothesis by using CAD tools. In QGIS each SHP file or layer of the project is only able to comprised one type of geometry: points, lines, or polygons. This difference between both programs forced the creation of a series of individual CAD files to later represent each stage of the monastic site at a distinct moment in time within QGIS. Each of them only comprises one type of geometry readable in QGIS. For instance, in the case of the CAD map that represented the monastic site from the twelfth century to the fifteenth century, we generated nine CAD files that were converted into SHP files in a following step: contour_lines (lines), guest_house (polygons), Romanesque_church (polygons), Romanesque_cloister (polygons), Chapel_of_the_Cypress (polygons), hospital (polygons), roads (polygons), rivers_1 (polygons), rivers_2 (lines).</p>
<p>However, this initial division of each phased CAD map into multiple layers prior to their conversion into SHP files was not only due to one technical reason. It also resulted from thinking about: what type of historical information supported each graphic reconstruction; how we aimed to structure it; and in which way spatial features should be visualized to ensure a clear and friendly understanding, interpretation, and evaluation of the final interface by users. To find a proper answer to all these questions was the result of an iterative process of thinking, making, checking the results and moving the process forwards or backwards to test other ways of making through all of which we learnt and advanced the project.</p>
<p>For instance, the files called contour_lines and rivers_2 in the group of SHP files of the monastic site from the twelve to the fifteenth centuries only comprise one type of geometry: lines. Therefore, the initial thought could be to merge them in a single file if we only consider it as a technical issue. However, if we also reflect about how they should be displayed for an easy visual understanding by means of color-coded lines and fills, the separation between the two files is needed.</p>
<p>The layers called Romanesque_church and Romanesque_cloister could also perfectly be within a single SHP file called monastic_buildings along with the QGIS layers of guest_house, Chapel_of_the_Cypress and hospital. All of them just comprise one type of geometry (polygons). Besides, the attribute table with information on spatial features of the layer can be organized with the same structure, as they are all under the consideration of monastic buildings. However, if we think about how to display the question of change over time in the web-based map without forgetting the diverse evolving nature of each monastic building, we come to the conclusion that their separation is also needed for an integral and legible visual reading and understanding of the resulting interface. Although it is possible to assign diverse attributes to each spatial feature within the same layer, we cannot follow the same path in what refers to their visualization yet, as the styling options (color, fill, type of line&hellip;) of a vector layer will be applied to all its spatial features.</p>
<p>To go in depth in this issue, the next example is a reflection about how to best represent a historical fact with spatial consequences, which is the fire of 1534 in the Romanesque cloister, in the web-map. It affected one part of the monastic complex and monks decided to rebuild it immediately. Based on sources, the shape of the spatial feature was not altered. So to visualize it by means of changes of shape in a two-dimensional representation is not possible. To make easier the legibility of this change in the period corresponding to the monastic site in the first half of the sixteenth century beyond the addition of a textual annotation, the cloister is represented by a different line-coded polygon. As a result, one historical fact with architectural consequences is somehow made visible to the observer (Figure 9).</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure09.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure09_hu997283db3f72a5a16882e6b05357c924_412959_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure09_hu997283db3f72a5a16882e6b05357c924_412959_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure09_hu997283db3f72a5a16882e6b05357c924_412959_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure09_hu997283db3f72a5a16882e6b05357c924_412959_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure09_hu997283db3f72a5a16882e6b05357c924_412959_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure09.jpg 3111w" 
     class="landscape"
     ><figcaption>
        <p>From left to right: 1. the monastery in the Late Middle Ages with the cloister represented with a contour line and a fill color; 2. the monastery in the first half of the 16th century after the fire of 1534, with the cloister represented with a contour line but without a fill color to graphically display the historical fact; 3. the monastery in the first half of the 16th century after the fire of 1534 with displayed historical data in a pop-up. Image: the author.
        </p>
    </figcaption>
</figure>
<p>After the first four groups of layers called The Place,  Pre-twelve century,  From twelve to fifteenth centuries, and First half of the sixteenth century were created and georeferenced onto a contemporary cartography in QGIS,<sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>  the following step was to learn how this simple GIS map could be turned into a web-map. For this purpose, we made some trials with two QGIS plug-ins: QGIS Cloud Free and QGIS2WEB. The first plug-in was tested in QGIS 3.4. The free application is presented as a web-GIS platform for publishing unlimited public maps and data on the internet for non-commercial and non-government uses, but with storage for their databases limited up to 50Mb.<sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>  The process to create and publish a QGIS project is quite easy by taking just a few steps.<sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>  However, the trials made with our databases were not fulfilling as the plug-in worked unstable in the latest release of QGIS, as the QGIS Cloud Support Team confirmed. Besides, we soon realized that the storage limit of 50Mb to upload the local database of our maps in QGIS Cloud Free would not be enough once we have created the missing groups of layers.</p>
<p>In regards to QGIS2WEB, it also enables users to create an OpenLayers/Leaflet web-map from a QGIS project, but this is not automatically published in an online platform, as it happens with QGIS Cloud. In other words, we can generate the HTML, CSS and JavaScript files that defined the web-map with QGIS2WEB, but then we need a web hosting to release it. Trials carried out with this plug-in allowed us to create a simple interactive map in a quick way. It is possible to set what layers or group of layers will be visible or hidden in the web-map as well as to select the base-map onto which they will be georeferenced. We can also add a series of tools for user’s interactivity, such a scale and zoom, an address search for locations, a layers list, a measure tool, the option to highlight features, and to show pop-ups when mouse hovers over features.<sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>  However, we also checked that QGIS2WEB did not represent all the spatial features defined in our QGIS project and, above all, it has many limitations to control and customize the resulting web-map according to the project requirements, unless we manually enhance the basic template generated by the plug-in (Figure 10).<br>
<a href="http://digitalhumanities.org/dhq-annex/000652/figure10/#15/42.7327/-7.3294">http://digitalhumanities.org/dhq-annex/000652/figure10/#15/42.7327/-7.3294</a>  Result of the second trial to create a web-map with the QGIS2WEB plug-in. Webmap: the author. Interface controls may be hidden depending on the size of your browser window. Navigate using map scroll bars or open the map in a new window to access interface controls.   <br>
In any case, the exploration of these two ways to create a web-map from a QGIS project led us to learn about Leaflet. Leaflet is one of the two powerful web-mapping libraries used by QGIS2WEB developers. It is an open-source JavaScript library designed to create friendly interactive maps that work efficiently in all major desktop and mobile platforms.<sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>  Leaflet API is said to be simple to read and easy to use even for beginner JavaScript developers. It is well-documented in its website, where we also found tutorials to get started with Leaflet basics as well as lots of plug-ins to extend its functionalities.</p>
<p>Another relevant feature of Leaflet is that we can create a web-map from map vectors defined by GeoJSON objects.<sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>  GeoJSON is a JSON format that encodes a geometry (one geographical feature) or a collection of geometries by defining their coordinates along with their non-spatial attributes <sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup>. The features include points, line strings, polygons, and multipart collections of these types (multi-points, multi-line strings, and multi-polygons). The non-spatial attributes are similar to the attribute table with textual information associated to a layer in QGIS.</p>
<p>For several months, the in-process work of Digital Samos was focused on learning how to use Leaflet and what potentials it offers for the interactive map of the monastic site at Samos. In addition to that, the in-process work revealed that if we aimed to meet all the aforementioned goals for free, we would need to design a custom-built platform; that is, a manually coded web-map (Figure 11). Otherwise, its future capabilities would be limited. However, making the decision of custom-designing the website to display our research involves dealing with a series of challenges that we also discovered in the in-process work.<br>
<a href="http://digitalhumanities.org/dhq-annex/000652/figure11/">http://digitalhumanities.org/dhq-annex/000652/figure11/</a>  Manually coded interactive web-map showing the basics of Digital Samos spatial framework: visual, multilayered, multi-scalar, time-based and structurally open-ended. Webmap: the author. Interface controls may be hidden depending on the size of your browser window. Navigate using map scroll bars or open the map in a new window to access interface controls.</p>
<h2 id="struggling-with-integrity-of-visual-and-textual-data-in-web-mapping-challenges-and-opportunities">Struggling with integrity of visual and textual data in web-mapping: challenges and opportunities</h2>
<p>The web-map of Digital Samos is hosted by the Universidade da Coruña, as a way to guarantee its future sustainability in addition to a custom-design solution (Figure 12). Its code is written with three programming languages: HTML, CSS and JavaScript. HTML provides a means to create the structure of the website: the main sections and their content. The interactive web-map was created with Leaflet, which is a JavaScript mapping library, as we previously said. CSS was used for describing the presentation of the HTML structure and the interactive map; that is, its layout or graphic design (format, fonts, style, colors&hellip;).</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure12.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure12_hu6226c325439becae80fb6d59c89c86e0_518964_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure12_hu6226c325439becae80fb6d59c89c86e0_518964_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure12_hu6226c325439becae80fb6d59c89c86e0_518964_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure12_hu6226c325439becae80fb6d59c89c86e0_518964_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure12_hu6226c325439becae80fb6d59c89c86e0_518964_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure12.jpg 1919w" 
     class="landscape"
     ><figcaption>
        <p>Image of the interactive web-map of the Digital Samos project, <a href="https://digitalsamos.udc.es/interactive_map.html">https://digitalsamos.udc.es/interactive_map.html</a>. Image: the author.
        </p>
    </figcaption>
</figure>
<p>In the present article, we are not going to explain how we developed the code for the interactive web-map, but we will reflect about the functionalities implemented in the web-based map to meet our goals, some of the problems we faced in the process, a critical evaluation of the current solutions and some thoughts about what things we had left out in this first cut of the web presence and how we aim to move it forward in the future.</p>
<p>The interactive web-map layout is divided into two main parts. The left one is devoted to long-form textual narrative. The spatial data is showcased in the right container. The latter is much wider as a way to visually highlight the focus of the project on spatiotemporal changes by using digital representation. When we open the interactive map we find a short, but needed explanation about how to use it in the left side, and the empty topography and hydrology of the place we study is shown on the right part.</p>
<p>The very first functionality of the map is the layers control in its upper right side (Figure 13). It is opened or closed if we move the mouse over it. It comprises two groups of layers. The first one displays the sub-web-maps that visualize each stage of the monastic site evolution in chronological order. The second group, separated by a grey line, is composed of the base-maps used to geo-reference the previous layers. None of the layers are displayed by default, so if we want to start our exploration of the map, we have to click the radio button corresponding to one of them. In brief, this is explained in the non-textual left container of the map, where we recommend beginning the exploration by clicking on the first layer called The Place. If we do so, the area where the monastery was built is visualized in a two-dimensional representation in the website. We can learn about it if we scroll the textual narrative to the section with the same title. The platform always tries to make it easy, but subtle, to follow the recommended exploration by representing the same structure in the layers control and in the sections of the narrative left trail. These first features give user freedom to explore the web-based spatial environment at will, but it also provides a clear and simple path through the spatial and data content by the addition of an accompanying textual narrative. In a future development, we aim to create one-to-one connections between the name of each layer within the layers control and the narrative section by the same name, so whether you click on one or the other, both textual and non-textual parts of the web-map will be displayed at the same time. This way integrity and legibility will be enhanced.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure13.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure13_hu7f48c4963f2d1aa194922e7a7b26c1de_4686609_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure13_hu7f48c4963f2d1aa194922e7a7b26c1de_4686609_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure13_hu7f48c4963f2d1aa194922e7a7b26c1de_4686609_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure13_hu7f48c4963f2d1aa194922e7a7b26c1de_4686609_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure13_hu7f48c4963f2d1aa194922e7a7b26c1de_4686609_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure13.jpg 3925w" 
     class="portrait"
     ><figcaption>
        <p>Sequence of eight screenshots of the interactive web-map of Digital Samos Project, <a href="https://digitalsamos.udc.es/interactive_map.html">https://digitalsamos.udc.es/interactive_map.html</a>, showing: the sub-web-map by default, the first layer The Place, the second layer Pre-twelfth century, the third layer From twelfth to fifteenth century, the fourth layer First half of the sixteenth century, the fifth layer Second half of the sixteenth century, the sixth layer First half of the seventeenth century, and the seventh layer Second half of the seventeenth century in the present version, November 2021. Image: the author.
        </p>
    </figcaption>
</figure>
<p>Another functionality of the present platform is that we can always display a phased map of the monastic site onto the current cartography due to the addition of two base-maps: Google Satellite and Google Street View. This way, the website enables users to visualize any re-created past realm of the monastery, the village and their context in relation with the present built environment (Figure 14). We can discover what artefacts are preserved, altered or lost, for instance, by means of visual comparison. We think it would be also an effective tool to better understand the spatial changes between consecutive time periods if we could visualize two or more phased web-maps at the same time. However, the basic layers control of Leaflet just comprises two groups of layers: layers within the first group are displayed one by one, but layers of the second group can be showed all together or even along with one layer of the first group.<sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup>  However, the ability to display a number of phased web-maps would of course be essential to make clearer the spatial change over time to human eye. This could be done by means of a multi-mode viewer that allows user to study overlapped transparent layers or synchronized multiple side-by-side maps <sup id="fnref:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup>.<sup id="fnref:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup></p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure14.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure14_hu2b1515b1c9f016bf9e700c92c8063ca4_1486611_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure14_hu2b1515b1c9f016bf9e700c92c8063ca4_1486611_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure14_hu2b1515b1c9f016bf9e700c92c8063ca4_1486611_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure14_hu2b1515b1c9f016bf9e700c92c8063ca4_1486611_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure14_hu2b1515b1c9f016bf9e700c92c8063ca4_1486611_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure14.jpg 1919w" 
     class="landscape"
     ><figcaption>
        <p>Screenshots of the interactive web-map of Digital Samos Project, <a href="https://digitalsamos.udc.es/interactive_map.html">https://digitalsamos.udc.es/interactive_map.html</a>, showing the phase called From twelfth to fifteenth century onto two current base-maps: Google Satellite and Google Streets. Image: the author.
        </p>
    </figcaption>
</figure>
<p>All previous features give an answer to how to represent space and time in a web-based environment, by starting simple with a two-dimensional map that we aim to expand to a three-dimensional model integrated in the platform somehow in the future. For now, we show what was where and when. This is the basic spatiotemporal knowledge for any historical exploration of the past monastic site. Each layer of the web-map is defined by discrete, measurable elements that represent the space, the answer to what was where and how the different elements were related to each other. However, we also pointed out previously that we aimed to create a self-explanatory web-map through the integration of historical non-textual data within the two-dimensional context in order to ensure transparency, legibility and evaluation.</p>
<p>For this purpose, we implemented functionalities of highlighting features and pop-up windows. When the user hovers the cursor on the map, most of its spatial features change their color. It means that they have assigned attributes with embedded historical data to display and explore by clicking on a particular highlighted object. These one-to-one connections aim to extend the interaction between user and the map as well as to create an integrated platform. Pop-up windows were designed to not obscure the visibility of the underlying map by means of transparent backgrounds when they are opened. This way, not only do they favor the integration of textual data within the map with immediacy, but they also ensure a permanent vision of the spatial feature within its context.</p>
<p>In this part of the in-process work, we ruminated on what textual information should be showed and how to structure it at length. So far we have created three main different types of pop-ups. The first type is used in the case of spatial features such as roads, rivers, bridges, dams and the hypothetical area of the first monastic settlement (Figure 15). Historical data about them is scarce, so the pop-up window is designed to only display the name of the feature.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure15.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure15_hu9a75fef3e71ee603a140afb781bde9cc_562637_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure15_hu9a75fef3e71ee603a140afb781bde9cc_562637_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure15_hu9a75fef3e71ee603a140afb781bde9cc_562637_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure15_hu9a75fef3e71ee603a140afb781bde9cc_562637_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure15_hu9a75fef3e71ee603a140afb781bde9cc_562637_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure15.jpg 1916w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot displaying the first type of pop-up windows created for spatial features with scarce historical data. Interactive web-map of Digital Samos Project, <a href="https://digitalsamos.udc.es/interactive_map.html">https://digitalsamos.udc.es/interactive_map.html</a>. Image: the author.
        </p>
    </figcaption>
</figure>
<p>The second type of pop-up window was defined for monastic buildings (Figure 16). In their current layout, data is displayed starting with the name of the building. Next we show the main art history style period and the construction date, if known. We also indicate whether the selected entity is extant or not currently. We gathered references to events that caused spatial changes in the period visualized, such as a fire, an ongoing reconstruction&hellip; As the present layers embrace long-term time periods, we considered it relevant to highlight what spatial changes were taking place at the moment and why, beyond the knowledge we gain through the spatial feature that recreates them. Finally, there is a hyperlink called View more. The creation of this linked information is still a work in progress, but the idea is, when clicked, user could extend their knowledge through: detailed maps of the selected building, three-dimensional models to be able to experience the space, access to historical and contemporary photographs, brief historical descriptions&hellip; all of which expand the understanding and analysis of the question of change over time.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure16.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure16_hu186178b0c1a4a836e735cfa863fb515a_522315_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure16_hu186178b0c1a4a836e735cfa863fb515a_522315_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure16_hu186178b0c1a4a836e735cfa863fb515a_522315_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure16_hu186178b0c1a4a836e735cfa863fb515a_522315_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure16_hu186178b0c1a4a836e735cfa863fb515a_522315_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure16.jpg 1916w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot displaying the second type of pop-up windows created for the monastic buildings. Interactive web-map of Digital Samos Project, <a href="https://digitalsamos.udc.es/interactive_map.html">https://digitalsamos.udc.es/interactive_map.html</a>. Image: the author.
        </p>
    </figcaption>
</figure>
<p>The third main type of pop-up window was created for the spatial features that represent farming properties and residential plots located in the surroundings of the monastery and in the village (Figure 17). It is the most complex pop-up as data come from very disparate sources in each time period, among which we find or not the name of the property, the name of the owner, the name of the tenant or subtenant, their jobs, the location, the tenancy year, the holding type, etc. As for now, the third type of pop-up is actually designed with four possible displays that better structure and show data related to farming and residential plots in accordance with the most relevant historical documents in four of the seven phases already represented in the platform. Each pop-up is a rich subset of data that comes mainly from two types of archival documentation: rental agreements and books of demarcations from the sixteenth and seventeenth centuries. We can find up to twenty different variables displayed in the third type of pop-ups. We tried to structure historical information in a similar order to enable the integration of web tools for spatial data query and analysis within the platform in the future. For instance, simple questions regarding the names of tenants or the rents of their properties face with tools that read multiple data sets at a time might reveal new insights into the evolving nature of the monastic site and its human and socioeconomic history.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000652/resources/images/figure17.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000652/resources/images/figure17_hu00ab8b59a7e74337bb88027f3021e179_542022_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000652/resources/images/figure17_hu00ab8b59a7e74337bb88027f3021e179_542022_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000652/resources/images/figure17_hu00ab8b59a7e74337bb88027f3021e179_542022_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000652/resources/images/figure17_hu00ab8b59a7e74337bb88027f3021e179_542022_1500x0_resize_q75_box.jpg 1500w,/dhqwords/vol/17/2/000652/resources/images/figure17_hu00ab8b59a7e74337bb88027f3021e179_542022_1800x0_resize_q75_box.jpg 1800w,/dhqwords/vol/17/2/000652/resources/images/figure17.jpg 1916w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot displaying one sub-type of pop-up windows created for residential and farming plots in the second half of the sixteenth century. Interactive web-map of Digital Samos Project, <a href="https://digitalsamos.udc.es/interactive_map.html">https://digitalsamos.udc.es/interactive_map.html</a>. Image: the author.
        </p>
    </figcaption>
</figure>
<p>Last but not least, although we can learn about what artefacts in the historical site/s are extant today through the information gathered in the pop-ups, the web-map in its current form does not provide, we admit, a clear but needed graphic distinction between evidence and hypothesis, or even between different levels of probability regarding the recreation of lost built entities or plot tissues. To overcome this weak point in terms of an accurate communication of the visual outcome, one solution would be to use color-coded lines as we previously created for the CAD maps. In the present form of our web-based environment, graphic design already contributes to convey conceptual issues regarding spatial changes, for instance, through different types of lines to distinguish between ended monastic buildings (solid lines) and works in progress (dash lines) within each phase. In future developments, we will go on working in the map layer styling as it impacts visual analysis and, therefore, it is an essential and constant consideration for producing web-maps both for individual and public viewing.</p>
<h2 id="conclusions">Conclusions</h2>
<p>This article introduced the Digital Samos interactive web-map, an online 2D representation of spatiotemporal changes implemented for one of the largest and most ancient monastic sites in Spain, San Julián de Samos. Digital Samos web-map was first released in late April 2019 and it offers fully functional access to six main stages of the site’s biography: the empty place prior to the foundation of the monastery; the monastic settlement before the 12th century; the monastery of the Late Middle Age; the transformations of the monastic site in the first half of the 16th century along with the formation of the nearby Samos village; the spatial changes that took place in the second half of the same century; and its ending in the early 17th century. In November 2019 we added a new spatiotemporal layer, the one corresponding to the first steps towards the mayor transformation of the monastic site from the late 17th century that were not completed until the 18th century. The latter is still pending to be added to the interactive map, as well as the complex monastic compound of the early 19th century prior to secularization.</p>
<p>Unlike existing web-map displays for monastic architecture, the Digital Samos prototype addresses an open representation of past compounds without compromising interaction with each feature, the accuracy of geometries and the integration of historical data in the web output. We offer a practical solution to create a self-explanatory or self-speaking virtual product due to the integration of both visual (graphic) and textual (written) data that complement each other in a novel and friendly digital environment. We show a way to overcome some limitations of fixed images for the interpretation and presentation of research outcomes in urban and architectural historical studies in and outside academia. We make use of the potentials of digital vectorised maps that may inspire others to dream big by working gradually with spatial and temporal data in the study of built environments that, like this web-map, were not built in a day.</p>
<p>The present article documents the project workflow, pitfalls and challenges to convert two separate initial research outputs (vector maps/plans) and historical data into one integral virtual product for presentation and dissemination of our spatiotemporal analysis in the field of architectural history where not only buildings, but also topography, geographical features and monasticism history play a role that is visualized in the web context.</p>
<p>The process reveals some technical challenges for non-technical backgrounds as well as some needed improvements to be implemented in future development. We tried to communicate both effectively from the particular subdomain of architectural history research in and through web technology. We situated our argument within a broader context of research and we included explanations of the significance of our web-map in a way that could be easily applied in other case studies. We also offer a cost-effective and sustainable solution to overcome limitations caused by the lack of funding or the use of specific commercial software that may affect the continuation of digital projects over time, its evolution towards new stages, or the possibility to involve specialists with technical backgrounds.</p>
<p>Digital Samos is woven with some common threads and complex requirements that are under consideration in the wider discussions and debates around deep maps. It develops a multilayer and multi-scalar spatial structure for a view of a particular monastic area that is meant to be  “visual, time-based and open-ended”   <sup id="fnref2:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>. It is designed as an exploratory environment where scholars and public alike might gain knowledge through the exploration of a particular place or pursue their own questions <sup id="fnref2:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>. It has a capacity for thick expert description that might be unstable and changing in response to new data or insights <sup id="fnref3:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>  <sup id="fnref3:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>. It also embraces the spatiotemporal contingent to incorporate time into analyses that are spatially contextualized <sup id="fnref3:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>  <sup id="fnref4:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>. It calls into the question the primacy of texts as the foundation of knowledge by taking advantage of the potential of technology and it walks towards an alternative construction of spatial narratives that embraces complexity, multiplicity, and simultaneity <sup id="fnref4:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>. During the process of constructing this prototype, we can learn and understand what works best in this new arena and make the most of thinking through making. The case study offered identifies a gap in the way spatial change over time in complex built environments is approached and disseminated in academia, and it proposes a solution that might help unravelling or getting at least a better understanding of a complex monastic site. With this approach we are able to integrate the complexity of the spatial transformations over time at San Julián de Samos, allowing us to present and make readable the large variety of information and interpretation the research contained, through explorable layers of meaning and process that lead to new forms of spatial narratives in a web context. In sum, it is another effort to move forward a more integrated spatial framework for humanities research as literature about deep mapping demands <sup id="fnref4:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>.</p>
<p>Through the work we present in this article, its open-ended results, the challenges we posed and the opportunities we approach, we hope to contribute, both conceptually and technically, to move forward the application of web-mapping tools in urban history and architectural history for a better understanding, presentation and dissemination of complex built environments. We expect this web-map to favor the engagement of a broader audience in and out academia through its attractive, clear and integrated appearance that, undoubtedly, makes visible to the observer eyes the complexity of one monastic built environment while it changed over time. We think it opens new possibilities for publication of visual research beyond traditional raster graphics that, on the whole, aims to no longer be considered just a visual demonstration or end visual product, but essential pieces of the research arguments themselves.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>The author would like to thank the instructors and participants in the Visualizing Venice Summer Institute  “Advanced Topics in Digital Art History: 3D (Geo)Spatial Networks”  2018-2019 for their theoretical and technical visions and feedback upon which this new adventure was born and owes a lot.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>For the history of the monastery of San Julián de Samos see: <sup id="fnref:67"><a href="#fn:67" class="footnote-ref" role="doc-noteref">67</a></sup>, <sup id="fnref:68"><a href="#fn:68" class="footnote-ref" role="doc-noteref">68</a></sup>, <sup id="fnref:69"><a href="#fn:69" class="footnote-ref" role="doc-noteref">69</a></sup>, <sup id="fnref:70"><a href="#fn:70" class="footnote-ref" role="doc-noteref">70</a></sup>, <sup id="fnref:71"><a href="#fn:71" class="footnote-ref" role="doc-noteref">71</a></sup>, <sup id="fnref:72"><a href="#fn:72" class="footnote-ref" role="doc-noteref">72</a></sup>, <sup id="fnref:73"><a href="#fn:73" class="footnote-ref" role="doc-noteref">73</a></sup>, <sup id="fnref:74"><a href="#fn:74" class="footnote-ref" role="doc-noteref">74</a></sup>, <sup id="fnref:75"><a href="#fn:75" class="footnote-ref" role="doc-noteref">75</a></sup>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>The research project was started in: <sup id="fnref:76"><a href="#fn:76" class="footnote-ref" role="doc-noteref">76</a></sup>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>See, for example: <sup id="fnref:77"><a href="#fn:77" class="footnote-ref" role="doc-noteref">77</a></sup>  <sup id="fnref:78"><a href="#fn:78" class="footnote-ref" role="doc-noteref">78</a></sup>  <sup id="fnref:79"><a href="#fn:79" class="footnote-ref" role="doc-noteref">79</a></sup>  <sup id="fnref:80"><a href="#fn:80" class="footnote-ref" role="doc-noteref">80</a></sup>  <sup id="fnref:81"><a href="#fn:81" class="footnote-ref" role="doc-noteref">81</a></sup>  <sup id="fnref:82"><a href="#fn:82" class="footnote-ref" role="doc-noteref">82</a></sup>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>The Digital Samos project is accessible at: <a href="https://digitalsamos.udc.es/index.html">https://digitalsamos.udc.es/index.html</a>. In August 2018, it was selected by the Getty Foundation to feature its Digital Art History Initiative page, <a href="https://www.getty.edu/foundation/initiatives/current/dah/index.html">https://www.getty.edu/foundation/initiatives/current/dah/index.html</a>. In February 2020, it was awarded with a special mention in the second edition of the Hispanic Digital Humanities Prizes, HDH 2020.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Duke University.  “Advanced Topics in Digital Art History: 3D (Geo)Spatial Networks. A Getty Foundation-Sponsored Summer Institute sponsored by the Visualizing Venice Team.”  Available at: <a href="https://sites.duke.edu/duke_arthist_3dgeo/">https://sites.duke.edu/duke_arthist_3dgeo/</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Jaskot, P. B., H. Jacobs, V. Szabo, M. Olson, and E. Triplett.  “Shaping the Discipline of Digital Art History. A recap of an advanced summer institute on 3-D and (geo)spatial networks.”    <em>The Iris. Behind the Scenes at the Getty</em> , Dec. (2018).&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Chattopadhyay, S.  “Architectural representations, changing technologies, and conceptual extensions.”    <em>Journal of the Society of Architectural Historians</em> , 71-3 (2012): 270–272.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Staley, D. J.  <em>Computers, visualization, and history: how new technology will transform our understanding of the past</em> . Hoboken: Taylor and Francis (2015).&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Sullivan, E., A. D. Nieves, and L. M. Snyder.  “Making the model: scholarship and rhetoric in 3-D historical reconstructions.”  In J. Sayers (ed.),  <em>Making things and drawing boundaries: experiments in the Digital Humanities</em> , Minneapolis, University of Minnesota Press (2017), pp. 301–316.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Helmreich, A.  “Introducción a la Historia del Arte Digital: un conversación colaborativa.”    <em>H-ART. Revista de historia, teoría y crítica de arte</em> , 9 (2021): 161-182.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>By following the principles of the: <sup id="fnref2:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> and <sup id="fnref1:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>López Salas, E.  “Methodological proposal in order to reconstruct the plans of a disappeared medieval architecture: the Romanesque church of St. Julian’s Monastery at Samos (Lugo).”    <em>Arqueología de la Arquitectura</em> , 10 (2013), e002.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>López Salas, E.  “The reform of Samos Abbey between 1491 and 1637: uncovering the logic of the architectural changes.”    <em>Imago Temporis. Medium Aevum</em> , 11 (2017): 345-383; 519-543.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>López Salas, E.  “Decoding the planning rules of the monastic urban and rural forms around Samos Abbey.”  In M. Abel, Mickey (ed.),  <em>Medieval Urban Planning: The Monastery and Beyond</em> . Newcastle upon Tyne: Cambridge Scholars Publishing (2017), pp. 46-74.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>López Salas, E.  “The role of the regular clergy in the planning of the landscape. The case of San Julián de Samos.”    <em>Hispania Sacra</em> , 69-139 (2017): 19-29.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>López Salas, E.  “Descubriendo un paisaje histórico. El espacio cercado del monasterio de San Julián de Samos en el siglo XIX.”    <em>RHA. Revista da História da Arte. Série W</em> , 5 (2017): 168-182.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>López Salas, E.  “Seeking the traces of a former monastic landscape in the vicinity of Samos Abbey (Galicia, Spain).”  In W. Kobylińska-Bunsch, Z. Kobyliński and L. D. Nebelsick (eds.),  <em>Archaeologica Hereditas, 10</em> , Warsaw, Institute of Archaeology of the Cardinal Stefan Wyszyński in Warsaw/Art History of the University of Warsaw (2017), pp. 195-211.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>López Salas, E.  “Organización, elementos y estado del espacio cercado de San Julián de Samos a través de una escritura de toma de razón de 1836.”    <em>Studia Monastica</em> , 59-1 (2017): 163-187.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Svalduz, E.  “Architectural and urban change over time. The school, church and monastery of Santa Maria della Carità.”  In K. L. Huffman, A. Giordano and C. Bruzelius (eds.),  <em>Visualizing Venice. Mapping and modeling time and change in a city</em> , New York: Routledge (2018), pp. 36–42.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>A comprehensive list of publications and communications related to the research carried out in Digital Samos is available at the project website:  “Articles and Book Chapters,”   <a href="https://digitalsamos.udc.es/research_publications.html">https://digitalsamos.udc.es/research_publications.html</a>,  “Congresses, Workshops, Seminars and Conferences,”   <a href="https://digitalsamos.udc.es/research_congresses.html">https://digitalsamos.udc.es/research_congresses.html</a>.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Ethington, P. J. and N. Toyosawa.  “Inscribing the Past: Depth as Narrative in Historical Spacetime.”  In D. J. Bodenhamer, J. Corrigan, and T. M. Harris (eds.),  <em>Deep maps and Spatial Narratives</em> , Bloomington, Indiana University Press (2015), pp. 72-101.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>McClure, D. and G. Worthey.  “Colophon. Grapl, the Graves Platform.”  In T. S. Mullaney (ed.),  <em>The Chinese Deathscape. Grave Reform in Modern China</em> , Stanford, Stanford University Press (2019).&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p><em>London chapter for the computer-based visualization of cultural heritage</em> , version 2.1, Feb. 2009. Available at: <a href="http://www.londoncharter.org/index.html/">http://www.londoncharter.org/index.html/</a>.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p><em>The Seville principles. International principles of virtual archaeology</em> , 2011. Available at: <a href="https://icomos.es/wp-content/uploads/2020/06/Seville-Principles-IN-ES-FR.pdf">https://icomos.es/wp-content/uploads/2020/06/Seville-Principles-IN-ES-FR.pdf</a>.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Lanjouw, T. and J. Waagen.  “Making 4D: principles and standards for virtual reconstruction in the humanities by the 4D Research Lab”    <em>4D Research Lab Report Series</em> , 1 (2021): 3-31.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>University of Toronto, DECIMA, <a href="https://decima-map.net/">https://decima-map.net/</a>.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Pecile, E.  “Respecting Historical Spatial Integrity: Building a Historical 3D Florence and Avoiding the Video Game.”    <em>Disegnarecon</em> , 11-21 (2018): 10.0-10.8.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Terpstra, N. and C. Rose.  <em>Mapping Space, Sense, and Movement in Florence. Historical GIS and the early modern city</em> . New York, Routledge (2018).&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Office of Information, Knowledge and Library Services (OIKLS), NTU Singapore. Visualizing the Mountain Estate. Landscape, Architecture, and Experience in Chengde, <a href="https://blogs.ntu.edu.sg/bssz/">https://blogs.ntu.edu.sg/bssz/</a>.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Whiteman, S., B. Dhanapalan, and H. Sum.  <em>Visualizing the Mountain Estate. Landscape, Architecture, and Experience in Chengde</em> , 2018. Available at: <a href="https://sites.duke.edu/duke_arthist_3dgeo/projects/visualizing-the-mountain-estate/">https://sites.duke.edu/duke_arthist_3dgeo/projects/visualizing-the-mountain-estate/</a>.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Wulfman C.E., E. Mylonas, A. Loyer, S. Bonde and C. Maines.  “The Abbey Inside the Machine: The MonArch Project.”  Digital Humanities 2007, University of Illinois, Urbana-Champaign, June 2007.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Brown University, The MonArch Project, <a href="http://monarch.brown.edu/">http://monarch.brown.edu/</a>.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Bonde, S., C. Maines, E. Mylonas, and J. Flanders.  “The Virtual Monastery: Re‐Presenting Time, Human Movement, and Uncertainty at Saint‐Jean‐des‐Vignes, Soissons.”    <em>Visual Resources: an international journal on images and their uses</em> , 25-4 (2009): 363-377.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>Rollier-Hanselmann, J., Z. Petty, A. Mazuir, S. Faucher, and J. F. Coulais.  “Développement d’un SIG pour la ville médiévale de Cluny.”    <em>Archeologia e Calcolatori</em> , 5 (2014): 164-179.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Budapesti, I.  “Past, Present, and Future of Digital Buddhology.”  In D. Veidlinger (ed.),  <em>Digital Humanities and Buddhism</em> , Berlín/Boston, De Gruyter, pp. 25-40.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>The Tibetan &amp; Himalayan Library, Sera Monastery, <a href="https://www.thlib.org/places/monasteries/sera/">https://www.thlib.org/places/monasteries/sera/</a>&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Cabezón, J. I.,  “Sera Monastery Project Overview,”   <a href="https://www.thlib.org/places/monasteries/sera/about/wiki/sera%20monastery%20project%20overview.html">https://www.thlib.org/places/monasteries/sera/about/wiki/sera%20monastery%20project%20overview.html</a>&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Cabezón, J. I.,  “The Space of Sera (Se ra’i khor yug),”   <a href="https://www.thlib.org/places/monasteries/sera/spaces/%23!essay=/cabezon/sera/spaces/s/b4">https://www.thlib.org/places/monasteries/sera/spaces/#!essay=/cabezon/sera/spaces/s/b4</a>&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>The Tibetan &amp; Himalayan Library, Sera Interactive Map, <a href="https://www.thlib.org/places/monasteries/sera/spaces/map/">https://www.thlib.org/places/monasteries/sera/spaces/map/</a>&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Brown University, The MonArch Project, <a href="http://monarch.brown.edu/site">http://monarch.brown.edu/site</a>.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>Bodenhamer, D. J.  “The Potential of Spatial Humanities.”  In D. J. Bodenhamer, T.M. Harris, and J. Corrigan (eds.),  <em>The Spatial Humanities. GIS and the future of Humanities Scholarship</em> , Bloomington, Indiana University Press (2010), pp. 14-30.&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Bodenhamer, D. J., T.M. Harris, and J. Corrigan.  “Spatial Narratives and Deep Maps: a special report.”    <em>International Journal of Humanities and Arts Computing</em> , 7 1-2 (2013): 170-175.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Bodenhamer, D. J., T.M. Harris, and J. Corrigan.  <em>Deep maps and Spatial Narratives</em> . Bloomington, Indiana University Press (2015).&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Murrieta-Flores, P. and B. Martins.  “The geospatial humanities: past, present and future.”    <em>International Journal of Geographic Information Science</em> , 33-12 (2019): 2424-2429.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Roberts, L.  “Deep Mapping and Spatial Anthropology.”    <em>Humanities</em> , 5-5 (2016): 1-7.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>This brief historiographic context related to deep mapping was added to the paper based on the suggestions provided by reviewers to which we want to express our gratitude for their constructive thoughts. Deep maps or deep mapping are not terms we have found ourselves using to any great extent in Digital Samos work to date, but we have certainly identified some common threads in recommended literature to which our web-map is in conversation with.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Earley-Spadoni, E.  “Spatial History, deep mapping and digital storytelling: archaeology’s future imagined through an engagement with the Digital Humanities.”    <em>Journal of Archaeological Science</em> , 84 (2017): 95-102.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Pearson, M. and M. Shanks.  <em>Theatre/Archaeology</em> . London, Routledge (2001).&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Ridge, M., D. Lafreniere, and S. Nesbit.  “Creating Deep Maps and Spatial Narratives through Design.”    <em>International Journal of Humanities and Arts Computing</em> , 7 1-2 (2013): 176-189.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Cardesín Díaz, J. M.  “Historia urbana multimedia: entre los Sistemas de Información Históricos (HIS) y la realidad virtual.”    <em>Ayer. Revista de Historia Contemporánea</em> , 110-2 (2018): 141-175.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Hatchwell, S., Insh, F. and Leaper, H.  “Born Digital: Early Career Researchers Shaping Digital Art History.”    <em>Visual Resources: an international journal on images and their uses</em> , 35 1-2 (2019): 171-179.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Münster, S., K. Friedrichs, and W. Hegel.  “3D Reconstruction Techniques as a Cultural Shift in Art History?”    <em>International Journal for Digital Art History. Digital Space and Architecture</em> , 3 (2018): 39-60.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Camerlenghi, N. and Schelbert, G.  “Learning from Rome: Making Sense of Complex Built Environments in the Digital Age.”    <em>Journal of the Society of Architectural Historians</em> , 77-3 (2018): 256-266.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Lanjouw, T.  “Some thoughts about integrating documentation, modelling and publication for historical 3D models.”  Available at: <a href="https://pure3d.eu/index.php/2021/10/26/4d-research-lab-blog-post/">https://pure3d.eu/index.php/2021/10/26/4d-research-lab-blog-post/</a>.&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Boeykens, S., S. Maekelberg and K. De Jonge.  “(Re-)creating the past: 10 years of digital historical reconstructions using BIM.”    <em>International Journal for Digital Art History, Digital Space and Architecture</em> , 3 (2018): 62–85.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>GISConvert, <a href="https://www.gisconvert.com/">https://www.gisconvert.com/</a>. There are also QGIS plug-ins to insert topographic lines from CAD to QGIS, as well as information related to natural resources as rivers. Both topography and natural resources at each stage of the monastic site evolution represent the historical compound that is not exactly the same as the present one.&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>National Air Orthophotography Programme (PNOA). Spanish National Geographic Institute (IGN), <a href="https://www.ign.es/iberpix2/visor/">https://www.ign.es/iberpix2/visor/</a>.&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>QGIS Cloud Plans, <a href="https://qgiscloud.com/en/pages/plans">https://qgiscloud.com/en/pages/plans</a>.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Sourcepole AG, QGIS Cloud, <a href="https://qgiscloud.com/en/pages/quickstart">https://qgiscloud.com/en/pages/quickstart</a>.&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Morales A.  “Publica tus mapas en la web con qgis2web,”   <a href="https://mappinggis.com/2016/03/crea-aplicaciones-webmapping-con-qgis/">https://mappinggis.com/2016/03/crea-aplicaciones-webmapping-con-qgis/</a>.&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Agafonkin V.  “Leaflet: an open-source JavaScript library for mobile-friendly interactive maps,”   <a href="https://leafletjs.com/">https://leafletjs.com/</a>.&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>Leaflet.  “Using GeoJSON with Leaflet,”   <a href="https://leafletjs.com/examples/geojson/">https://leafletjs.com/examples/geojson/</a>.&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p>Crickard III, P.  <em>Leaflet.js Essentials</em> . Birmingham, Packt Publishing (2014).&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p>Leaflet,  “Leaflet Plugins,”   <a href="https://leafletjs.com/plugins.html">https://leafletjs.com/plugins.html</a>.&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:65">
<p>Henel, J.  “JHNA’s Enhancements (or  JHNA 2.0 ).”    <em>Journal of Historians of Netherlandish Art</em> , 11-2 (2019).&#160;<a href="#fnref:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:66">
<p>See, for example: Institut Cartogràfic i Geològic de Catalunya.  “Changes in the territory,”   <a href="https://www.icgc.cat/es/Aplicaciones/Visores/Cambios-en-el-territorio">https://www.icgc.cat/es/Aplicaciones/Visores/Cambios-en-el-territorio</a>.&#160;<a href="#fnref:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:67">
<p>Arias Arias, P.  <em>Historia del Real Monasterio de Samos</em> . Santiago de Compostela, Imprenta, Lib. y Enc. Seminario Conciliar (1950).&#160;<a href="#fnref:67" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:68">
<p>Arias Cuenllas, A.  <em>Historia del monasterio de San Julián de Samos</em> . Samos, Monasterio de Samos (1992).&#160;<a href="#fnref:68" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:69">
<p>Castro, M.  “Un monasterio gallego,”  in  <em>Boletín de la Comisión Provincial de Monumentos Históricos y Artísticos de Orense</em> , IV (1912): 82-83-84-85-86, 113-120, 136-143, 163-171, 189-195, 201-208.&#160;<a href="#fnref:69" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:70">
<p>Durán, M.  <em>La Real Abadía de San Julián de Samos: estudio histórico-arqueológico</em> . Madrid (1947).&#160;<a href="#fnref:70" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:71">
<p>Folgar de la Calle, M. C.  “A construcción do gran mosteiro de San Xulián de Samos. Cen anos de transformacións arquitectónicas.”  In E. Fernández Castiñeiras, and J. M. Monterroso Montero (eds.),  <em>Arte benedictina nos camiños de Santiago. Opus Monasticorum II,</em>  Santiago de Compostela, Xunta de Galicia (2006), pp. 149-178.&#160;<a href="#fnref:71" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:72">
<p>Folgar de la Calle, M. C. and A. E. Goy Diz.  <em>San Xulián de Samos: Historia e arte nun mosteiro. Opus Monasticorum III</em> . Santiago de Compostela, Xunta de Galicia (2008).&#160;<a href="#fnref:72" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:73">
<p>López Peláez, A.  <em>El monasterio de Samos: estudio histórico</em> . Lugo, Imprenta a cargo de Juan M. Bravos (1894).&#160;<a href="#fnref:73" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:74">
<p>Portilla Costa, P. de la.  <em>Monasterio de Samos Guía histórico-artística</em> . Lugo, Monasterio de Samos (1978).&#160;<a href="#fnref:74" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:75">
<p>Portilla Costa, P. de la.  <em>Monasterio de San Julián de Samos. Historia de dos restauraciones (1880 y 1951)</em> . A Coruña, Fundación Caixa Galicia (2003).&#160;<a href="#fnref:75" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:76">
<p>López Salas, E.  <em>The monastery of San Julián de Samos (Lugo-Spain), a study and interpretation of the monastic space and its evolution</em> . Ph.D. thesis, Universidade da Coruña (2015).&#160;<a href="#fnref:76" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:77">
<p>Borin, P.  “An integrated information management system for consistent historic narratives and visualizations. Ghett/App for the Venetian ghetto.”    <em>Disegnarecon</em> , 9-17 (2016): 4.1–4.9.&#160;<a href="#fnref:77" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:78">
<p>Calabi, D.  “Memory, narrative and display – city museums in recent initiatives and debates.”    <em>Planning Perspectives</em> , 24-3 (2009): 385–390.&#160;<a href="#fnref:78" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:79">
<p>Harris, D.  “Architectural history’s futures.”    <em>Journal of the Society of Architectural Historians</em> , 74-2 (2015): 147–151.&#160;<a href="#fnref:79" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:80">
<p>King, L., J. F. Stark, and P. Cooke.  “Experiencing the digital world: the cultural value of digital engagement with heritage.”    <em>Heritage &amp; Society</em> , 9-1 (2016): 76–101.&#160;<a href="#fnref:80" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:81">
<p>Monteleone, C., I. Friso, and F. Panarotto.  “For the fifth centenary of the ghetto in Venice: virtual transformations of architecture and city at the Doge’s Palace.”    <em>Disegnarecon</em> , 9-17 (2016): 3.1–3.12.&#160;<a href="#fnref:81" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:82">
<p>Svalduz, E.  “Researching, interpreting and representing: reflections on a few experiences (M9, Carpi, VV and the Accademia).”  In D. Calabi (ed.),  <em>Built city, designed city, virtual city. The museum of the city,</em>  Rome: Croma - Università degli studi Roma Tre (2013), pp. 121–135.&#160;<a href="#fnref:82" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Computational Paremiology: Charting the temporal, ecological dynamics of proverb use in books, news articles, and tweets</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000676/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000676/</id><author><name>Ethan Davis</name></author><author><name>Christopher Danforth</name></author><author><name>Wolfgang Mieder</name></author><author><name>Peter Sheridan Dodds</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-05-26T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Our goal here is to advance computational paremiology: The data-driven study of proverbs, and in general to examine the utility of frequency-based studies of common phrases in large corpora. In particular, we hope to answer the following: Can a computational study of proverbs in large corpora offer unique insight in the study of those proverbs? And is this novel kind of approach appropriate to corpus linguistics and studies using corpora broadly? We first build a quantitative foundation by searching for and counting instances of an ecology of proverbs, and estimating their frequency of use over time in several large corpora from different domains. We then characterize basic temporal dynamics allowing us to address fundamental questions such as whether or not proverbs appear in texts according to a similar probability distribution to words <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>  <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<p>In studies of phraseology, data on frequency of use is often conspicuously absent <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. The recent proliferation of large machine-readable corpora has enabled new frequency-informed studies of words and  <em>n</em> -grams (phrases of length  <em>n</em> ) that have expanded our knowledge of language use in a variety of settings, from the Google Books  <em>n</em> -gram Corpus and the introduction of culturomics  <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>  <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>, to availability and analysis of Twitter data <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. Routine formulae, or multi-word expressions that cannot be reduced to a literal reading of their semantic components, remain notoriously averse to reliable identification despite carrying high degrees of symbolic and indexical meaning <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. It is, for instance, much easier to chart a probability distribution of single words or  <em>n</em> -grams than phrases like proverbs, conventional metaphors, or idioms, which must be associated with a lexicon – a set of meaningful linguistic units.</p>
<p>Studies of words alone can generally assume that each word is lexically represented as such, but the study of phrases with a particular cultural use may require a lexicon in addition to the text being studied. Here, we use Mieder’s  <em>Dictionary of American Proverbs</em>  as such a resource. Assuming words or grams as fundamental components of texts risks flattening the complex interrelations between common phrases that might place a text in a historical or literary context, by de-emphasizing or omitting altogether culturally significant phrases. We show a case (proverbs) in which established computational methods may be applied to a class of culturally meaningful phrases, with results that paint a valid and substantially unique picture of language use in the corpora studied.</p>
<p>Perhaps the most recognizable routine formulae are proverbs and their close cousin, idioms. Centuries of the study of proverbs – paremiology – have shown their importance in language and culture, and that they are immensely popular among the folk (the people for whom these phrases are culturally relevant) <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. Proverbs are generally metaphorical in their use, and map a generic situation described by the proverb to an immediate context. In light of challenges in developing reliable instruments for measurement and quantification of figurative language, research would greatly benefit, as it has with words, from a better understanding of the frequency and dynamics of proverb use in texts. By applying new methodologies in measuring frequency and probability distributions, this study seeks to contribute to this endeavor.</p>
<p>Before going any further, we must detail a more precise definition of the proverb. Though there is still some debate, it is widely agreed that proverbs are popular sayings that offer general advice or wisdom. Naturally, not all such sayings are proverbs. Mieder’s definition is perhaps the most useful for our present purposes:  “Proverbs [are] concise traditional statements of apparent truths with currency among the folk. More elaborately stated, proverbs are short, generally known sentences of the folk that contain wisdom, truths, morals, and traditional views in a metaphorical, fixed, and memorizable form and that are handed down from generation to generation”   <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>.</p>
<p>Proverbs maintain a particular relationship with their context of use that provides a fruitful domain for frequency and probability analysis. An important part of the proverb is the context in which it is used. The metaphorical property of a proverb need not only have to do with the proverb itself (as in the proverb/metaphor war is hell, in which war is compared to hell within the proverb). In general, the use of a proverb is metaphorical in context, meaning that the proverb offers wisdom about a current situation via a metaphoric comparison to a proverbial one <sup id="fnref1:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. For instance, while the proverb  “still waters run deep”  might be used to caution someone against taking a seeming calm for granted, as it may belie unseen dangers. As with many other proverbs, it is hard to imagine anyone using the proverb  “you can’t put lipstick on a pig”  in any literal or pragmatic context. Rather, these phrases offer wisdom embodied in the culture as opposed to that of the speaker. In this way proverbs may be used generically without proffering personal expertise.</p>
<p>Proverbs are necessarily ambiguous enough to offer wisdom in any number of situations. Michael Lieber argued that this ambiguity paradoxically gives proverbs the function of disambiguating situations in which they are used. In part due to their role as cultural rather than individual wisdom, they can be invoked impersonally as a way of clarifying a complex reality <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. As such, part of Winick’s definition of the proverb is that they  “address recurrent social situations in a strategic way”   <sup id="fnref2:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>.</p>
<p>It is important to note the distinction between proverbs and idioms. An example of an idiom would be the phrase red herring denoting a mislead. The meanings of idioms, like proverbs, often cannot be ascertained from the meanings of their component words. But unlike proverbs, idioms are often not complete sentences, require context, and need not reference a paradigmatic situation. Proverbs on the other hand represent a complete situation and offer some sort of general wisdom. The boundary between the two is rather fuzzy and contains many idioms and proverbial expressions. For instance, the proverb  “every cloud has its silver lining”  is perhaps more well known by its idiomatic reduction silver lining. In fact, people may use an idiom without any knowledge of its proverbial context. Our intent here is to focus on expressions of full proverbs, and not their idiomatic uses. As previous work has shown, it is possible to investigate the manipulations and idiomizations of individual proverbs <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>  <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. Our approach has limitations, and further research into flexible searches or other identification methods will be essential in future work.</p>
<p>Metaphor and idiom identification and comprehension are an open area of research in machine learning and NLP (Natural Language Processing) <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>  <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. In general, metaphors and metaphorical speech are difficult to identify, and do not occur in consistent, repeated phrasings. Whereas in the study of individual words, one is allowed the tacit assumption that most of these words are represented in the lexicon of the language, in the search for routine formulae, one must access the lexicon as an essential step in verifying a phrase’s meaningfulness. Furthermore, the source and target domains of their metaphoric mapping are seldom explicit, as laid out by Lakoff and Johnson in their  <em>Conceptual Metaphor Theory</em>   <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>  <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. Proverbs generally appear in the same recognizable format, and in the form of a full, self-contained sentence. Prospectively, understanding of the conceptual mapping involved in proverb use may provide a useful step towards general understanding of metaphors in the above fields <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>  <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>.</p>
<p>Arguably, the proverb’s flexibility of use has helped make them an essential part of language and communication, literature, discourse, and media <sup id="fnref1:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. Interest in the collection and study of proverbs dates back to at least the ancient Greeks and Sumerians. Erasmus famously collected proverbs. In English literature, the proverb has been an important device for many famous authors, among them Geoffrey Chaucer, William Shakespeare, Oscar Wilde, and Agatha Christie <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>  <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>.</p>
<h2 id="quantitative-approaches">Quantitative Approaches</h2>
<p>This is by no means the first quantitative study of proverb use. Permiakov called for demographic studies of proverb knowledge to gather an impression of which proverbs were being used by the folk, in the interest of establishing a paremiological minimum: A minimum lexicon of proverbs for understanding a language <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>. Subsequent interest in proverb knowledge in psychology and folklore resulted in several studies conducted in the United States. Early studies by Albig and Bain in the 1930s found that American college students could recall on average between 25 and 27 distinct proverbs, many of which were common among participants <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>  <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. A more recent study by Haas observed proverb familiarity among college students in several regions of the US. They performed experiments in both proverb generation and proverb recognition. Notably, students could recognize more proverbs than they could recall on their own <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>.</p>
<p>Apart from the lexicographic collection of proverbs from texts, several attempts have been made to quantify and characterize their use. Whiting, in his assiduous collection of proverbs from texts in  “Modern Proverbs and Proverbial Sayings”   <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>, kept track of the frequency with which they were encountered. Norrick attempted a manual search for proverb frequency, though he was constrained to only using proverbs starting with the letter  <em>f</em> , and used a relatively small text sample <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. In the first serious computational analysis of proverb frequency, Lau searched for and counted instances of proverbs in newspapers in the Lexis/Nexis ALLNWS database <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>.</p>
<p>David Cram theorized that proverbs, acting as self-contained lexical units, were employed much in the same way that words are, and that their use involved a lexical loop where the speaker accesses the lexicon in addition to the syntax when forming a text. As such, in the case of proverbs (and phrasal idioms), one ought to  “analyze a syntactic string as a single lexical item”   <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>.</p>
<p>Moon’s exhaustive early study of fixed expressions and idioms (denoted FEIs) in the Oxford Hector Pilot Corpus (OHPC) did just that <sup id="fnref1:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. His study represents the first serious attempt to apply the new tools of computational linguistics to routine formulae. He searched the OHPC (a precursor to the British National Corpus or BNC) for instances of 6776 FEIs from the  <em>Collins Cobuild English Language Dictionary</em> . It is worth noting that at the time, there were few machine-readable English phraseological lexica. Though proverbs consisted of only 3.5% of the searched phrases (240), 19% of the expressions found in the corpus were proverbial expressions, the second most common subtype behind simple expressions (70%). Of the proverbs found, 59% were deemed metaphorical. Moon notes that exploitation of FEIs are easy to miss, and uses the proverb  “a bird in the hand is worth two in the bush”  as an example.</p>
<p>Significantly, Moon noted that journalism was over-represented in the corpus, and that the results did not represent the distributions of these FEIs in English as a whole. This and other similar caveats inspired the present study to observe genre-specific corpora separately, and compare after analysis.</p>
<p>Čermák’s essay collection  <em>Proverbs: Their Lexical and Semantic Features</em>  contains several essays that deal with the distribution of proverbs in the British National Corpus <sup id="fnref2:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. In Čermák’s pioneering essays, he searches for occurrences of English proverbs in the BNC corpus (100 million words) <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. In his study, even the most common proverbs seem to occur relatively infrequently. For example,  “easier said than done”  is the most common, appearing 62 times in the entire corpus. His study discusses the relevance of corpus occurrence to a paremiological minimum (he uses a limited proverb list from Wiktionary). Another study focuses on text introducers to various proverbs using collocation analysis. (Čermák notably created/spearheaded one of the first machine-readable phrasaeological lexica in the  “Czech Idiom Dictionary”  (1994).)</p>
<p>Čermák relates frequency dictionaries to discussions of a paremeological minimum. Should proverb frequency in large corpora be considered when judging that minimum? Of course, there are problems with this approach as well: proverbs rely heavily on oral tradition, and are prone to frequent corruptions and purposeful exploitations. As such there is no guarantee that a search of a given phrasing of a proverb will capture all, if any, of its occurrences in a text. There are ways around this on an individual basis, but it depends on the proverb: some employ parallel structures (like good X make good Y), or have popular idiomizations (like silver lining). Longer proverbs are more likely to appear in more than one form, as words and clauses can be swapped rearranged, or omitted without changing their overall meaning, which makes computational identification more difficult. Shorter proverbs will more reliably appear in a consistent form because there are fewer words to manipulate, and any manipulation is likely to change their meaning.</p>
<p>In a recent introductory paremiology textbook, Steyer (2015) outlined a process general corpus linguistic method for studying proverbs, similar to Moon and Čermák. Most recently, Haas (2022) used Google Trends to analyze the frequency of Google searches of proverbs included in discourse around the COVID-19 pandemic. Here, we expand on the above literature, including much larger corpora and proverb data sets.</p>
<p>Should the ambition be to find these distributions in English as a whole? We contend that there is no such universal corpus for any language. Clearly use of these phrases is context-dependent, it seems unlikely inter-contextual searches will yield greater insight than single-genre searches. Instead, frequency dynamics and distributions in separate corpora from differing contexts may be more informative.</p>
<h2 id="from-data-on-language-to-culture">From Data on Language to Culture</h2>
<p>Our present study of proverbs from a corpus linguistic point of view examines proverb frequency using several methods that are well established in the study of words, though rarely used in conjunction: namely the dynamics of frequency over time, and the relationship between frequency and relative popularity (rank). We illustrate that moving beyond words to the study of significant phrases provides worthwhile insight that cannot be captured by word-based methods, and yet reproduces some of the expected behavior of words.</p>
<p>One of the foundational achievements in the study of complex systems was Zipf’s identification of scaling laws in language and other social phenomena <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Studies of scaling can help us understand the relationship between common and uncommon observations, and are particularly suited to studies of language, which relies both on the utility of some elements, and the specificity of others. A rank distribution describes the relationship between the frequency of a word’s appearance, and its resulting rank among all words in the text. Zipf’s law shows that there is an inverse relationship between the frequency and rank of words in a text, and that the most common 20% of the unique words in a text account for 80% of overall word frequency. It was first observed by Zipf that the rank distribution of words in a text follows a  <em>power law</em>     F      r      =  c      r      -  α      ,   where   r   is a word’s rank,   F      r       is its frequency, with   α  ≃  1  . As early as 1996, natural language (in the context of computational linguistics) was cited explicitly as an example of the recently coined  “complex adaptive systems”   <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>While primary interest here is paid to its appearance and seeming ubiquity in language, the same class of distributions have been observed in phenomena across a wide range of fields including physics, biology, psychology, sociology, urban studies, and engineering <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>  <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>.</p>
<p>One shortcoming noted in many evaluations of Zipf&rsquo;s law in text is that power law scaling breaks down toward the tails of these empirical distributions, meaning that the lowest ranked words do not seem to follow Zipf’s law. Recent work by Williams et al. <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> showed that power law scaling holds over more orders of magnitude when randomly partitioned phrases are used rather than individual words. That study also suggested a refocusing of corpus linguistic attention from words to phrases as essential elements of language. Further work by Williams et al. (<a href="#williams2015a">2015a</a>) suggested that changes in scaling in Zipf distributions of large corpora can be attributed to text mining. Few, if any, attempts have been made to apply Zipf&rsquo;s law to phraseological lexica.</p>
<p>With large amounts of newly digitized text, corpus linguistics and lexicology/lexicography have seen renewed wider interest, and new results. Can these methods be used to tell new stories that are of interest to those working in the humanities? And in particular, how can that work embed itself into the existing wealth of knowledge accrued by those disciplines. In this case, how can computational work on proverbs situate itself in the existing knowledge-base of paremiology?</p>
<p>In their seminal 2011 paper, Michel et al. discussed the newly created Google Books corpus, and coined the term culturomics to describe the nascent discipline concerned with observable trends in the use of  <em>n</em> -grams over time <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. They present several case studies, among them trends in the use of “influenza” with historical outbreaks, and the use of geographical and antagonistic terms alongside the history of the American Civil War. These case studies make use of time series data and relative frequency to tell complex stories of interest from simple queries.</p>
<p>Pechenick et al. note that there are serious issues with assertions that Google Books offers a reliable representation of culture. For one, books are not indexed by popularity, and each book appears only once. As a result, the linguistic contributions of the most popular books are weighted equally with the least popular <sup id="fnref1:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. Secondly, the increase in volume of scientific publications in the last century causes the last century of English as a whole to be relatively skewed towards that genre. For instance, enormously influential books like  <em>To Kill a Mockingbird</em> ,  <em>I Know Why the Caged Bird Sings</em> ,  <em>Mockingjay</em> , or  <em>Harry Potter and the Order of the Phoenix</em>  are only represented once, and share the same weight as even the most obscure books. In the last century, the rise in volume of scientific and academic publication drastically increased the relative influence of this type of writing. Here, we examine only the English Fiction subset of the corpus, which is a less problematic subset <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>.</p>
<p>Other work by Reagan et al. utilized the timelines  <em>within</em>  texts to evaluate the emotional arc of a text, given word valence (sentiment) data. Emotional arcs were created by plotting the changing sentiment of words in a text as it progresses: from beginning to end, how positive or negative is the overall languge in a given section? Inspired by Kurt Vonnegut&rsquo;s rejected Master&rsquo;s thesis (in anthropology) on the shapes of stories, they found that the emotional arcs of most stories in the Gutenberg corpus could be reduced to a handful of paradigmatic shapes <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>.</p>
<p>Work by Underwood et al. used historical use of gendered names and words to reveal trends in gender representation in literature using data from the HathiTrust digital library <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>.</p>
<p>StoryWrangler, a tool recently developed by Alshaabi et al. allows users to explore the temporal dynamics of  <em>n</em> -grams found on Twitter <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. Using a data set reflecting a random 10% of Twitter since 2008 (presently over 150 billion tweets), Storywrangler tracks the prevalence of  <em>n</em> -grams on a daily scale.  <em>n</em> -grams are portrayed via rank by popularity, and convey the rise/dynamics of President Trump (further depicted in the PoTUSometer) <sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>, or the meteoric rise, and continued influence of Justin Bieber (of surprising relevance to this work). Unlike the Google Books  <em>n</em> -gram Corpus, StoryWrangler is notable in its ability to track phrases in both original tweets and retweets, conveying aspects of popularity through amplification.</p>
<p>Beyond simple words and phrases, data have been used to track the progression of ideas. For instance, Leskovec et al.&rsquo;s paper on meme-tracking tracked the progression and mutation of popular sayings as they proliferated through news reporting and blogging <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>.</p>
<p>Recently, Computational Folkloristics has gained recognition as an area of study, with a 2016 issue of the  <em>Journal of American Folklore</em>  being devoted to the subject <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>. Using classification, networks, geographical data, temporal data, and digitized text, folklorists and other interested academics have explored new possibilities in understanding texts and cultural history. The  <em>Danish Folklore Nexus</em>  developed by Abello et al. provides tools for large-scale analysis of Danish folk tales and stories, aiding in classification of stories, or mapping their similarity to others through networks. Tools like this can augment traditional methods of studying folklore, using data-driven methodology to guide future avenues of folklore research <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>. This represents a paradigmatic example of a computational tool participating in the continued discourse around folklore, without being an end in and of itself.</p>
<h2 id="data-and-methods">Data and Methods</h2>
<p>In an effort to quantify the ecology of proverbial language, a list of over 14,000 proverbs was obtained from Mieder&rsquo;s  <em>Dictionary of American Proverbs</em>   <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>. Proverbs were stored in an SQL database for ease of access, and matched for frequency with four distinct corpora:</p>
<p>The Gutenberg Corpus (English)   The  <em>New York Times</em>  (1988-2007)  The Google Books  <em>n</em> -gram Corpus (1800-2000)  Twitter (2008-2020)</p>
<p>For Google Books, the proverb shit happens was added to the set of proverbs to illustrate the emergence of a modern proverb.</p>
<p>Individual corpora were collected as follows.</p>
<h2 id="a-gutenberg">A. Gutenberg</h2>
<p>The Gutenberg corpus comprises over 60,000 collected published documents spanning several centuries. The present study restricts its use to the subset of documents in English. As the metadata for the Gutenberg corpus does not consistently encode the date of original publication, temporal data was collected using author birth dates (gathered from the gutenbergr library for R) <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>. These were used in place of publication dates, as the publication dates in the corpus seldom represent the original publication, instead they represent the digitized edition. For temporal analysis, documents without authors and their birth dates were omitted.</p>
<p>The Gutenberg corpus comes with several caveats. Firstly, works were curated by perceived importance. Works also disproportionately represent the 18th and 19th centuries, and for this reason much of our work with Gutenberg focuses on this period. Several authors have much of their extensive oeuvre represented in the corpus (e.g., Anthony Trollope, Mark Twain), which could compromise a more objective view of English writing tendencies of the period.</p>
<h2 id="b-the--_new-york-times_">B. The  <em>New York Times</em></h2>
<p>Data from the  <em>New York Times</em>  were gathered from the  <em>New York Times</em>  Annotated Corpus of 1.8 million articles from 1987-2007 [Sandhaus 2008]. The data are organized in NTIF (News Industry Text Format) formatted XML-readable documents. The corpus includes obituaries and other short pieces in addition to more traditional news articles.</p>
<h2 id="c-google-books">C. Google Books</h2>
<p>The 2020 English Fiction Google  <em>n</em> -grams corpus consists of every  <em>n</em> -gram that appears at least 40 times in its set of millions of digitized books. For each  <em>n</em> -gram the corpus provides on each year it appears in the data set, the frequency with which it appeared that year, and the number of documents it appeared in that year <sup id="fnref2:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Unlike Gutenberg and the  <em>New York Times</em> , Google Books does not contain the raw text of the concerned documents, rather it displays the counts for popular  <em>n</em> -grams in the corpus, organized by  <em>n-</em> gram length. This creates an obvious limitation, where only phrases of the same length can be studied together.</p>
<h2 id="twitter">Twitter</h2>
<p>Data from Twitter was accessed through the Vermont Complex Systems Center&rsquo;s StoryWrangler API <sup id="fnref2:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. StoryWrangler receives a randomly selected 1/10th of each day&rsquo;s tweets from Twitter&rsquo;s Decahose API (including retweets), and organizes  <em>n</em> -grams by rank and frequency. Data for 2-gram and 3-gram proverbs were obtained though the tool, and were aggregated so the collection was case insensitive. Similar to Google Books, this corpus is organized by  <em>n-</em> gram counts rather than full texts.</p>
<h2 id="d-data-processing-and-visualization">D. Data Processing and Visualization</h2>
<p>The data from all four corpora were processed using Python, and the libraries pandas and matplotlib were used for organization and visualization respectively <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>  <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>.</p>
<p>In our processing of Gutenberg and the  <em>New York Times</em> , punctuation in both proverbs and texts was removed. Twitter data were punctuation insensitive. Regular expressions were used to capture variations in punctuation when processing the Google Books  <em>n</em> -gram Corpus.</p>
<p>Estimating the frequency of a proverb’s use is essential to this work. Simple counts don’t lend themselves to comparing results between corpora of different sizes, and do not capture the frequency of the proverb in relation to the size of a single corpus. Relative frequency can be calculated simply by dividing the raw frequency by a quantity describing the size of a corpus (number of articles, number of  <em>n</em> -grams, number of books, etc.) Expressed mathematically, it is calculated as:       f      r  e  l      =      f      t        /        n      t       which is the frequency   f   for time period   t   divided by the number of documents   n   found during time period   t  .</p>
<p>Zipf distributions were plotted using ranks of proverbs in a corpus, with rank 1 being the most frequent against their frequency. Zipf distribution plots are shown on a log-log scale as is standard, which displays less intuitive power law functions as more intuitive linear functions. For results and analysis, see Appendix A.</p>
<p>A network approach will be useful in exploring how different books are connected by the proverbs they share. In this case, a connection is drawn between two books if they share at least one proverb. The resulting network emerges after this step is performed for each possible pair of books. In network analysis, an important metric is  <em>centrality</em> , which in this case describes how well-connected a book is in the larger network. Specifically, we calculate  <em>betweenness centrality</em> , which assesses how often a given book appears in the shortest path between any other two books in the network. A book with high betweenness centrality in this network appears in the path between many pairs of books in the network. For results and analysis, see Appendix B.</p>
<p>Betweenness centrality in these networks is calculated as   b      v      =    ∑    s  ≠  v  ≠  t                σ      s  t          v              σ      s  t            ,where       σ      s  t          denotes the number of shortest paths between books  <em>s</em>  and  <em>t</em> , and       σ      s  t          v          denotes the number of those paths that also pass through book  <em>v</em> .</p>
<p>Most processing was performed using the Vermont Advanced Computing Core (VACC) located at the University of Vermont.</p>
<h2 id="results">Results</h2>
<h2 id="gutenberg">Gutenberg</h2>
<p>While the most popular entry in the Gutenberg corpus and the Google Books  <em>n</em> -gram corpus was the phrase  “hold your tongue,”  this phrase is classified as a proverbial expression rather than a proverb (its use requires outside context). For clarity of focus the phrase has been excluded from figures in this section. Sink or swim, another proverbial expression, has been left in. In light of the limitations of the Gutenberg corpus detailed in Methods, it is difficult to make claims about the trends of proverb use over time (Figure 1). It is clear from the data shown in Figure 1 that proverbs appear in a remarkable portion of the documents in the corpus.  “The sooner the better”  for example, appears in nearly one in every ten documents in the early 1800s.</p>




























<figure ><img loading="lazy" alt="sixteen frequency charts showing frequencies on the y axes and years on the x axes. The years go from 1800-1950" src="/dhqwords/vol/17/2/000676/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000676/resources/images/figure01_hu8d5325ec5aa9bdbbcb6dc2144c9c30cb_1187144_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000676/resources/images/figure01_hu8d5325ec5aa9bdbbcb6dc2144c9c30cb_1187144_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000676/resources/images/figure01_hu8d5325ec5aa9bdbbcb6dc2144c9c30cb_1187144_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000676/resources/images/figure01_hu8d5325ec5aa9bdbbcb6dc2144c9c30cb_1187144_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000676/resources/images/figure01_hu8d5325ec5aa9bdbbcb6dc2144c9c30cb_1187144_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000676/resources/images/figure01.png 4800w" 
     class="landscape"
     ><figcaption>
        <p>Time series for the 16 most popular proverbs in the Gutenberg corpus, ranked by overall count. These most common proverbs occur in a large portion of documents in the corpus for most of the period studied. For instance, the sooner the better regularly appeared in at least 5% of documents from the 19th century. Plots are ordered in the grid by rank first left to right, then top to bottom. Note that the vertical axis ranges vary across plots to highlight individual variation in time.
        </p>
    </figcaption>
</figure>
<h2 id="the--_new-york-times_">The  <em>New York Times</em></h2>
<p>Figure 2 shows time series plots for the 16 most common proverbs in The  <em>New York Times</em>  Annotated Corpus. Shown are frequency binned by month and year, and normalized by article count. All articles are included in the count including smaller articles like obituaries (the average article count is 248 per issue). It is by no means a surprise that proverbs appear frequently in journalism; in fact Lau&rsquo;s study found as much <sup id="fnref1:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. Not present in that work, is a temporal dimension (not to mention a different time period). It is clear in Figure 2 that the proverbs represented are used on a monthly or semi-monthly basis, and are rarely if ever absent in a year&rsquo;s publications. In these representations of proverb use, it is easier to identify use patterns and perhaps to extract narratives from their dynamics. The easiest, if somewhat trivial case is  “to delay may mean to forget”  owes its yearly rhythm to its role as the NYT&rsquo;s charity tagline. Its frequency of use increased markedly over the period studied, though stayed confined to the winter holiday months.</p>




























<figure ><img loading="lazy" alt="sixteen frequency charts showing frequency counts for key phrases over time. the y-axes show frequencies and the x-axes show years from 1988-2008" src="/dhqwords/vol/17/2/000676/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000676/resources/images/figure02_hu47507a081635d052a838e338e93cd8b5_1696601_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000676/resources/images/figure02_hu47507a081635d052a838e338e93cd8b5_1696601_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000676/resources/images/figure02_hu47507a081635d052a838e338e93cd8b5_1696601_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000676/resources/images/figure02_hu47507a081635d052a838e338e93cd8b5_1696601_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000676/resources/images/figure02_hu47507a081635d052a838e338e93cd8b5_1696601_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000676/resources/images/figure02.png 4800w" 
     class="landscape"
     ><figcaption>
        <p>Time series plots for the 16 most popular proverbs in the <em>New York Times</em> from 1997-2007 (ranked by overall count). The gray represent the data binned by month, and the orange represent the data binned by year. The proverb to delay may mean to forget owes its yearly rhythm to its role as the NYT&rsquo;s charity tagline. The frequencies are normalized by article count (obits, and non-body included). Plots are ordered in the grid by rank first left to right, then top to bottom.
        </p>
    </figcaption>
</figure>
<p>With the exception of  “to delay may mean to forget,”  and consistent with accepted definitions of the proverb, the consistency with which proverbs are used in the  <em>New York Times</em>  suggests they are employed widely for their utility in mapping general wisdom to a specific context.</p>
<p>Nonetheless, prominent spikes in frequency can be associated with historical events. For instance, the brief several-fold increase in the use of boys will be boys around November of 1992 is likely attributed to a contentious and widely publicized sexual assault case at the time, which prompted additional discussion of rape culture. Before the trial, the president of the New Jersey chapter of the National Organization for Women was reported as saying,  “We&rsquo;re going to stop this &lsquo;boys will be boys&rsquo; attitude from continuing in this country.”  Meanwhile in the trial, the lawyer for the defense excused the rapists’ actions, telling the jury,  “boys will be boys”   <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>  <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>.</p>
<p>The maximum in use of  “pay as you go”  in 2004 seems to correspond with discussion around President Bush and the Republican party’s budget plans, referencing the  “pay as you go”  budget policy from the 1990&rsquo;s by which tax cuts and spending increases must not increase the defecit. Its increase in use in 1996 seems to owe to discussion of the Environmental Bond Act being proposed in New York at the time, which proponents argued would cause fewer delays than  “pay as you go”  funding for environmental clean-up <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>  <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>.</p>
<h2 id="google-books">Google Books</h2>
<p>In Figure 3 are time series plots for the 12 most common 2-gram proverbs in the Google  <em>n</em> -grams corpus. Here the gray represents yearly frequency (counted once per volume), and the orange represents the five-year rolling average, normalized by the number of volumes in a given year. One can see clearly from the figure the emergence of several more recent proverbs: safety first,  money talks, and shit happens.</p>




























<figure ><img loading="lazy" alt="nine frequency charts showing the frequencies of key phrases over time. The y axes all show frequencies and the x axes show years from 1800-2000" src="/dhqwords/vol/17/2/000676/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000676/resources/images/figure03_hu5e92faf8c4ab5829a910554299f81dce_1265390_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000676/resources/images/figure03_hu5e92faf8c4ab5829a910554299f81dce_1265390_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000676/resources/images/figure03_hu5e92faf8c4ab5829a910554299f81dce_1265390_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000676/resources/images/figure03_hu5e92faf8c4ab5829a910554299f81dce_1265390_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000676/resources/images/figure03_hu5e92faf8c4ab5829a910554299f81dce_1265390_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000676/resources/images/figure03.png 4800w" 
     class="landscape"
     ><figcaption>
        <p>Time series plots for the 12 most popular 2-gram proverbs in the Google Books n-gram Corpus (ranked by overall count). The gray represent the yearly frequency, while the orange represent the five-year rolling average. The dramatic increase in use of the proverbs shit happens and safety first correspond with previous scholarship on their emergence. Plots are ordered in the grid by rank first left to right, then top to bottom.
        </p>
    </figcaption>
</figure>
<p>Safety first exhibits a precipitous rise in usage in the early 20th century. Specifically, in 1912, the National Safety Council (NSC) in the US adopted the phrase as its slogan to promote standards of worker safety, though the Safety First Movement was initiated by US Steel in 1906. Its origin has been traced back to at least 1818 <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. The data shown in Figure 3 support the history of its popularization <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>  <sup id="fnref1:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>.</p>
<p>Previous scholarship on the proverb shit happens (which does not appear in  <em>The Dictionary of American Proverbs</em> ) traced its origin to the year 1944, and its rise in popularity corresponds to its humorous use as a bumper sticker, and cultural controversy (and legal battles) associated with it <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>  <sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>. It’s increasing currency is illustrated in its appearance in Tom Clancy’s popular novel,  <em>Clear and Present Danger</em> :  “Look, in field operations anything can go wrong … We are not immune. Shit happens, as they say”   <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>. It also famously appeared in the movie  <em>Forrest Gump</em>   <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>.</p>
<p>Figure 4 shows time series plots for the 16 most popular 3-gram proverbs in the Google Books  <em>n</em> -gram corpus. Though the proverb never say never originated in 1887 <sup id="fnref2:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>, it is evident that it gained far wider popularity in the late 1900s. Though the proverb enough is enough dates at least to 1546 <sup id="fnref3:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>, its popularity seems to vastly increase throughout the 20th century. The proverb divide and conquer seems to have briefly gained popularity around the World War II era.</p>




























<figure ><img loading="lazy" alt="sixteen frequency charts showing the frequencies of key phrases over time. The y-axes show frequency counts and the x-axes show years from 1800 to 2000" src="/dhqwords/vol/17/2/000676/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000676/resources/images/figure04_hub43956624b5071be6f57820c83474a5c_1554481_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000676/resources/images/figure04_hub43956624b5071be6f57820c83474a5c_1554481_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000676/resources/images/figure04_hub43956624b5071be6f57820c83474a5c_1554481_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000676/resources/images/figure04_hub43956624b5071be6f57820c83474a5c_1554481_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000676/resources/images/figure04_hub43956624b5071be6f57820c83474a5c_1554481_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000676/resources/images/figure04.png 4800w" 
     class="landscape"
     ><figcaption>
        <p>Time series plots for the 16 most popular 3-gram proverbs in the Google Books Ngram Corpus (ranked by overall count). The gray represents the yearly frequency, while the orange represents the 5 year rolling average. The rise in popularity of the proverb never say never is shown. A period of increased usage of the proverb divide and conquer corresponds with the World War II era. Plots are ordered in the grid by rank first left to right, then top to bottom.
        </p>
    </figcaption>
</figure>
<h2 id="twitter-1">Twitter</h2>
<p>On Twitter, the four most common 2-gram proverbs, on average, don&rsquo;t seem to exhibit much variability in their usage (Figure 5). The proverbs be yourself and time flies seem to remain above       10      -  6      , or 1 in every million 2-grams on Twitter during the period studied. An increase in usage of “safety first” in early 2020 may be related to the onset of the coronavirus pandemic during the same period.</p>




























<figure ><img loading="lazy" alt="screenshot of nine frequency charts showing 2-grams of key phrases over time on Twitter. Charts are arranged by rank with be yourself ranking first. The graphs are colored with orange and gray to display frequiencies" src="/dhqwords/vol/17/2/000676/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000676/resources/images/figure05_hu144c8144435a13fb1083fd38c913b487_84904_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000676/resources/images/figure05_hu144c8144435a13fb1083fd38c913b487_84904_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000676/resources/images/figure05.png 864w" 
     class="landscape"
     ><figcaption>
        <p>Time series plots for the nine most popular 2-gram proverbs on Twitter (ranked by overall count). The gray represents the daily frequency, while the orange represents the 30 day rolling average. The proverbs be yourself and time flies maintain popularity over the period studied. Notably, the safety first shows an increase in popularity in early 2020, possibly relating to the coronavirus pandemic. Plots are ordered in the grid by rank first left to right, then top to bottom.
        </p>
    </figcaption>
</figure>
<p>Exhibited on Twitter (Figure 6), the convenience of proverbs as succinct narratives has made them useful in several titular media events in the past decade. Of note, Figure 6 shows marked shifts in frequency of never say never, and love is blind.  Never say never owes its initial attention in 2010 to Justin Bieber&rsquo;s single of the same title ( <em>Justin Bieber: Never Say Never</em> ), repeated as his slogan and title of a biographical documentary. This was not the first film to utilize the proverb in its title; Sean Connery&rsquo;s final performance as James Bond was titled  <em>Never Say Never Again</em>  (1983).</p>




























<figure ><img loading="lazy" alt="screenshot of sixteen frequency charts showing 3-grams of key phrases over time on Twitter. Charts are arranged by rank with never say never ranking first. The graphs are colored with orange and gray to display frequiencies" src="/dhqwords/vol/17/2/000676/resources/images/figure06.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000676/resources/images/figure06_hu43425e1e3bcb26ebd9b564303c19d847_113454_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000676/resources/images/figure06_hu43425e1e3bcb26ebd9b564303c19d847_113454_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000676/resources/images/figure06.png 864w" 
     class="landscape"
     ><figcaption>
        <p>Time series plots for 3-gram proverbs on Twitter (ranked by overall count). The gray represents the daily frequency, while the orange represents the 30 day rolling average. The proverb never say never owes its meteoric rise in popularity in 2010 to popular musician Justin Bieber&rsquo;s single and biographical documentary of the same name. never say never remains the most popular proverb on Twitter until 2016, when it is supplanted by enough is enough which has steadily gained popularity in the last decade, owed in part to its constant use by Senator Bernie Sanders, and punctuated by reactions to tragedies related to gun and police violence. Plots are ordered in the grid by rank first left to right, then top to bottom.
        </p>
    </figcaption>
</figure>
<p>Figure 7 shows the dynamics of never say never on Twitter in more detail. We observe first its meteoric rise in popularity at the time of  <em>Never Say Never</em> &rsquo;s (song) release as the lead single off the soundtrack for a modern remake of the  <em>Karate Kid</em>  movie (roughly two magnitudes in a single day). At the time of the single&rsquo;s official release on June 8th, 2010, never say never was the 63rd most used 3-gram on Twitter. When  <em>Justin Bieber: Never Say Never</em>  was released on January 31, 2011, never say never was the 34th most common 3-gram on Twitter; for comparison, I love you was 22nd at the time.</p>




























<figure ><img loading="lazy" alt="screenshot of one frequency chart showing 3-grams of key phrases over time on Twitter. The chart shows the frequency of the phrase never say never with the highest peak in 2010. The graphs are colored with orange and gray to display frequiencies" src="/dhqwords/vol/17/2/000676/resources/images/figure07.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000676/resources/images/figure07_hu4b0ecd8548397f564e7bfd206dfc94f3_111928_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000676/resources/images/figure07_hu4b0ecd8548397f564e7bfd206dfc94f3_111928_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000676/resources/images/figure07.png 840w" 
     class="landscape"
     ><figcaption>
        <p>Daily relative frequency of the 3-gram never say never on Twitter. While never say never was already popular on Twitter as of 2008, its popularity was amplified in 2010 by the release of Justin Bieber&rsquo;s single entitled “Never say never,” and his subsequent biographical documentary of the same name. Remarkably, it remained the most popular proverb on Twitter for almost six years, punctuated by anniversaries and reruns of the movie, until it was surpassed by enough is enough in 2016.
        </p>
    </figcaption>
</figure>
<p>Remarkably, the popularity of never say never on Twitter decayed so slowly that it did not reach its pre-Bieber frequency until 2016. The continued presence of the proverb in Twitter discourse suggests that in the wake of its initial rise, it was more frequently adopted to general non-Bieber usage. (A similarly popular 3-gram, non-proverbial song of that year,  “Rock That Body”  appeared and disappeared from the Twitter discourse in the span of a few months). While the enormity and fervor of Bieber&rsquo;s fanbase at the time (a period called Bieber fever  <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>) certainly contributed to its popularity, its continued use over a five-year period is compelling evidence that the proverb became a more integral part of the Twitter lexicon for a time.</p>
<p>In 2020,  “Love is Blind”  became the title of a literally minded reality dating show in which participants were quarantined in private rooms, only communicating via audio interfaces. In this instance, the proverb was not only an apt description of the show&rsquo;s narrative, but a template for its formation. Additionally, it came to represent a narrative solution to the isolation imposed by the concurrent pandemic. The increase in the phrase&rsquo;s popularity seems only to have lasted for the month of the show&rsquo;s release, after which it seems to settle at its former rate of use. The proverb itself is ancient, and translations exist nearly every European language.</p>
<p>While with never say never (the most popular proverb on Twitter), we see a sudden rise and slow decay, we see a different pattern in the second most popular proverb, enough is enough.</p>
<p>From 2016 to the present, we see a steady increase in the frequency of enough is enough on Twitter (Figure 8). Recent work by Mieder attributes its renewed popularity in part to its constant use by Bernie Sanders <sup id="fnref1:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. Unlike never say never there does not seem to be a single event that precipitates this trend. An investigation into the several local maxima (brief spikes in occurrence) suggests a possible narrative correspondence. Many of these local maxima correspond to events related to either police violence or mass shootings.</p>




























<figure ><img loading="lazy" alt="screenshot of one frequency chart showing 3-grams of key phrases over time on Twitter. The chart shows the frequency of the phrase enough is enough steady useage from 2010-2020 and peaks around major international events such as the Pulse nightclub shooting and the Parkland school shooting. The graph is colored with orange and gray to display frequiencies" src="/dhqwords/vol/17/2/000676/resources/images/figure08.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000676/resources/images/figure08_hu4a279b670a34711a1813b336ab60e7d1_316402_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000676/resources/images/figure08_hu4a279b670a34711a1813b336ab60e7d1_316402_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000676/resources/images/figure08_hu4a279b670a34711a1813b336ab60e7d1_316402_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000676/resources/images/figure08.png 1326w" 
     class="landscape"
     ><figcaption>
        <p>Daily relative frequency of the 3-gram enough is enough on Twitter. The popularity of enough is enough on Twitter grew steadily over the last decade, and it has been the most popular proverb on Twitter since 2016, perhaps originating from its consistent use by Senator Bernie Sanders [^mieder2019]. It has since become associated with growing protests against police brutality and gun violence. Annotations reflect widely reported violent events and protests (with the exception of the 2018 US midterm elections). The stark simplicity of this sixteenth century proverb evokes a narrative of repetition past the point of tolerance [^mieder1992]. In this instance, beginning as a condemnation of the continued reaffirmation of the status quo in US politics by Senator Sanders, it is now popular as collective outcry against political inaction in the wake of regular mass shootings in the US, and a lack of accountability in the killing of black Americans by police. The changing significance and popularity of the proverb in the past decade displays the aptitude of proverbial speech to be successfully employed in varying contexts, and its potential to illustrate narrative commonalities between phenomena.
        </p>
    </figcaption>
</figure>
<p>Famously, survivors of the Parkland shooting in 2018 appeared on the cover of  <em>Time</em>  magazine with a simple title:  “Enough.”   <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>. Coverage of the March for Our Lives against gun violence in the  <em>New York Times</em>  included the title:  <em>March for Our Lives Highlights: Students Protesting Guns Say  Enough Is Enough _   <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>. When protesters marched in DC in the wake of the murder of George Floyd, Politico&rsquo;s coverage was titled:  _ Enough is enough : Thousands descend on D.C. for largest George Floyd protest yet</em>   <sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>. Inasmuch as proverbs can create metaphorical mappings from a paradigmatic situation (or narrative) onto a present one, enough is enough represents a compelling narrative of continued injustice, and a critical point of retaliation. The data from Twitter display a narrative of repeated tragedy in spite of public outcry. The proverb was most popular during the 2018 US midterm elections, during which gun control was a major issue.</p>
<h2 id="concluding-remarks">Concluding remarks</h2>
<p>In this study, four corpora reveal four markedly different patterns of proverb use, which taken each within the limits of their methods of collection, can offer piecemeal insight into the relationship between phrases and the written record. Observing all four side by side, it should become clear that generalizing linguistic tendencies from individual corpora may not be a good idea. Even among corpora with significant temporal overlap the results differ due to both the scope of each corpus, and the way in which data are collected from texts. The present approach of studying data from distinct domains allows for both a more limited and more useful interpretation of the results: We can only claim that results are representative of proverb use on Twitter for instance, rather than proverb use in English as a whole — an impossible achievement.</p>
<p>So, rather than using the results to speak about  <em>all proverbs</em>  or all of language, we may use it as lens by which to identify areas (within a corpus) that warrant a closer look. In studies of common words, the concept the word represents is often dependent on its context, and evaluating context for each instance in a large corpus is generally not feasible. Proverbs carry with them a paradigmatic context</p>
<p>Unlike studies of common words, whose interpretation is often dependent on their context, we show that proverbs allow us to perform a different kind of analysis that focuses on the historical use of a stable paradigmatic narrative.</p>
<p>While much work up to this point uses computational methods to take a broader view of text than traditional methods of humanities scholarship, that broader view often necessarily obscures the context in which linguistic elements are used. A single word or short sequence of words may carry any number of meanings dependent on the words or concepts around it. Proverbs carry their own paradigmatic context which makes their meaning and use fairly consistent. While proverbs may be employed in many different practical situations, the paradigmatic situation they represent remains the same. In searching for proverbs, we are able to see how a paradigmatic context is applied to different practical contexts. The results of this search show not only the frequency of some sequence of words, but also the frequency with which a particular cultural concept is employed.</p>
<p><em>N</em> -gram based methods of analyzing common phrases in texts suffer from the inclusion of many sequences of words which do not have any self-contained meaning. Our work, in which phrases must be represented in the lexicon, ensures that each phrase studied is meaningful. In an analysis of all 3-grams in a text, a very common phrase without a fixed meaning, like and this is could obscure a far less common meaningful phrase like love is blind, even though it is common among phrases with fixed meanings. Our study of a specific cultural-linguistic phenomenon highlights the utility of using an extensive lexicon to isolate the phenomenon being studied.</p>
<p>We demonstrate that lexically significant phrases (here proverbs), which are relatively stable and self-contained, can discern trends that words or  <em>n</em> -grams would likely miss. In each corpus studied, evidence of proverbs’ changing use over time is shown to validate previous scholarship, reflect cultural events, and offer a quantitative, longitudinal perspective unable to be achieved by traditional methods in the study of proverbs.</p>
<p>The study of common and flexible phrases seems to lend itself to this mode of inquiry. Through novel or context-specific words and phrases, we are able to observe discourse around specific phenomena (pizzagate,  pandemic, or Make America Great Again). In contrast, through more generic culturally significant phrases, we may be able to observe how we organize specific phenomena into the paradigmatic narratives they represent.</p>
<p>Much attention has been paid to the use of words and  <em>n</em> -grams in general in large corpora, but it is difficult to extract from them instances of individual narrative or metaphorical language use. Proverbs, in their tendency to act as both narrative and metaphor, and in their often relatively fixed structure, are an ideal test case for our ability to observe broader cultural narratives through the piecemeal, routine stories employed by the folk. Studies of n-grams tend to organize their interpretation around n-grams which attain a specific historical use-case. In our study of proverbs, we are able to trace the progression of a paradigm and its varying application to historical changes and events.</p>
<p>A natural limitation of this study, and any study that uses extant data to study language, is the issue of representativeness. In this study that limitation is twofold: Both the lexicon for directing the search, and the data being searched are inherently limited. While  <em>The Dictionary of American Proverbs</em>  is extensive, and represents much that is known of proverbs in America, it naturally excludes new proverbs and does not account for many ways in which the structure of the proverbs it contains may be manipulated in their practical use. There are lexical resources that address recent proverbs, for example  <em>The Dictionary of Modern Proverbs</em> , and the methodology of this study may be readily applied to such lexica <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>. Previous studies on proverb frequency have relied on composite corpora, namely variations of the BNC (British National Corpus), which contains manually curated selections from several domains of text. As shown in this study, composite corpora may miss important differences in proverb usage between domains.</p>
<p>Fieldwork (digital and otherwise) continues to be important in identifying new proverbs and changing structures of existing proverbs. This task may be aided in the future by tools like StoryWrangler, that track  <em>n</em> -gram rank, likely capturing new proverbs in the process. The task then would be extracting likely proverbs from these data, which would require linguistic, cultural, and computational expertise.</p>
<p>Much of proverb scholarship has been concerned with the idea of a paremiological minimum: A minimum proverbial lexicon for a language and culture. As shown by Lau (1996), and again in the present study, computational studies of the frequency of proverb use can contribute to the understanding of these minima, as those proverbs which seem ubiquitous in large corpora ought to be understood by speakers of a language. Temporal analysis of their frequency may further validate that their frequency is related to enduring currency among the folk, rather than correspondence with a specific occurrence. Another concern in paremiology and phraeseology is the origins of sayings. Work like the present study can serve to both validate and expand on previous scholarship on the history of phrases.</p>
<p>In the study of the statistical distribution of natural language, there exists the idea of a kernel lexicon, a subset of words that are essential to communication using a given language. Much literature on the study of culture and education has focused on what one might consider a minimum of cultural literacy. Special attention has been paid to which proverbs constitute part of that minimum. It is clear from this study that the most common proverbs vary considerably between corpora. Given the prevalence of these popular proverbs in their respective contexts, we can posit that English learners would benefit in their comprehension of the language if they were familiar with these proverbs.</p>
<p>Analyses of the frequency and rank of proverbs in this study (shown in Appendix A) verify that with ever increasing amounts of machine-readable textual data, we may produce longitudinal phraseological studies.</p>
<p>Traditionally, the study of metaphor in language has relied on theoretical interpretations <sup id="fnref1:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. This study opens up the possibility for new avenues in the study of metaphor that incorporate the currency of specific metaphors among the folk. A natural extension of this study would be employing a similar method to study idioms and conventional metaphors.</p>
<p>As machine comprehension of natural language becomes increasingly important, this area too, would benefit from an expanded lexicon that includes proverbs and routine formulae, and understanding of metaphor may be assisted by a more basic understanding of the mapping from general to specific situations that exists in the use of proverbs.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Thank you to David Dewhurst, Josh Minot, Michael Arnold, Nicholas Allgaier, Thayer Alshaabi for providing invaluable guidance in the writing of this paper. The authors are grateful for the computing resources provided by the Vermont Advanced Computing Core which was supported in part by NSF award No. OAC-1827314, and financial support from the Massachusetts Mutual Life Insurance Company to CMD and PSD.</p>
<h2 id="appendix-a">Appendix A</h2>
<p>Figure 9 shows Zipf distributions for entries from Mieder&rsquo;s  <em>Dictionary of American Proverbs</em>  (1992) for each of the four corpora studied, using 3-gram proverbs for Google Books and Twitter. While the distributions exhibit some Zipf’s Law-like behavior (heavy tails), we do not observe robust power-law scaling for all proverbs. We find the largest number of distinct proverbs appearing in Gutenberg and the  <em>New York Times</em> , on the order of thousands, with the Google Books and Twitter examples showing many fewer. We note that Zipf&rsquo;s law for words does not itself extend over many orders of magnitude <sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>, typically only 2 or 3, and that it is meaningful, mixed length phrases that present many orders of magnitude of scaling <sup id="fnref2:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. The Zipf distributions for proverbs are thus comparable to what we see for single words.</p>
<p>With a more sophisticated method of proverb detection, one that captures minor variations in phrase structure, we would expect to see some adjustments to the Zipf distributions we have observed, though a priori it is not clear how. Short, robust proverbs (time flies) will be well counted, while longer ones for which, say, constituent function words might be changed based on context or era (he/she/they who hesitates…) would only see their apparent observed frequency of usage grow.</p>




























<figure ><img loading="lazy" alt="frequency charts for for the phrases hold your tongue, to delay may mean to forget, time will tell, and never say never in the Project Gutenberg, NYT, Google Books, and Twitter" src="/dhqwords/vol/17/2/000676/resources/images/figure09.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000676/resources/images/figure09_hu28b55ebb4c426d3418de23d93cbf7380_319861_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000676/resources/images/figure09_hu28b55ebb4c426d3418de23d93cbf7380_319861_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000676/resources/images/figure09_hu28b55ebb4c426d3418de23d93cbf7380_319861_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000676/resources/images/figure09_hu28b55ebb4c426d3418de23d93cbf7380_319861_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000676/resources/images/figure09_hu28b55ebb4c426d3418de23d93cbf7380_319861_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000676/resources/images/figure09.png 1972w" 
     class="landscape"
     ><figcaption>
        <p>Zipf distributions for entries from Mieder&rsquo;s <em>Dictionary of American Proverbs</em> [^mieder1992]. For each corpus, proverbs are enumerated and shown on logarithmic axes as a function of rank, with hold your tongue, to delay may mean to forget, time will tell, and never say never topping the charts in Gutenberg, NYT, Google, and Twitter respectively. Each distribution exhibits heavy-tailed behavior, more prominently for Gutenberg and NYT.
        </p>
    </figcaption>
</figure>
<h2 id="appendix-b">Appendix B</h2>
<p>The data for proverbs in the Gutenberg corpus were used to construct a network with documents as nodes, connected if a given proverb appears in both documents. When betweenness centrality was calculated for nodes in the network, surprisingly James Joyce&rsquo;s  <em>Ulysses</em>  had the 14th highest centrality, close to several dictionaries of proverbs and quotations, and the collected works of Mark Twain (Table B-1). Creasy (2008) documented Joyce&rsquo;s use of proverbs in  <em>Ulysses</em>  from a critical perspective, noting that they are often altered, and blend high and low culture in the work. As Joyce uses many fewer proverbs than a comprehensive proverbial dictionary, the book&rsquo;s centrality in this network implies that Joyce&rsquo;s use of proverbs is far from arbitrary, and that his choice of proverbs is purposefully situated in the broader context of English proverbial knowledge.<br>
The 20 most central books by betweenness centrality, from a network of books connected by shared proverbs in Gutenberg. Notably, James Joyce&rsquo;s  <em>Ulysses</em>  appears alongside several proverb and quotations collections, and the collected works of Mark Twain.      Book  btwn centrality      1  Dictionary of Quotations  0.043048      2  Familiar Quotations  0.022821      3  Dictionary of English Proverbs and Proverbial Phrases  0.014274      4  A Polyglot of Foreign Proverbs  0.013061      5  The Entire Project Gutenberg Works of Mark Twain  0.013041      6  French Idioms and Proverbs  0.010083      7  Roget&rsquo;s Thesaurus  0.009785      8  Webster&rsquo;s Unabridged Dictionary  0.007978      9  U.S. Copyright Renewals 1950 – 1977  0.006709      10  The Project Gutenberg Complete Works of Gilbert Parker  0.006278      11  Proverb Lore  0.006028      12  Complete Project Gutenberg John Galsworthy Works  0.003897      13  Complete Project Gutenberg Works of George Meredith  0.003660      14  Ulysses  0.003184      15  The Historical Romances of Georg Ebers  0.003168      16  Familiar Quotations  0.003007      17  The Circle of Knowledge  0.002886      18  The Complete Poetic and Dramatic Works of Robert Browning  0.002749      19  Complete Project Gutenberg Oliver Wendell Holmes, Sr. Works  0.002657      20  Motion Pictures, 1960-1969: Catalog of Copyright Entries  0.002578</p>
<h2 id="appendix-c">Appendix C</h2>
<p>Tables 2-4 show the total count of the 50 most popular proverbs in</p>
<p>their respective corpora.<br>
The top 50 proverbs and proverbial expressions (from the  <em>Dictionary of American Proverbs</em> ) in the entire Gutenberg Corpus.      Proverb  Count      1  hold your tongue  2,284      2  the sooner the better  1,536      3  be yourself  739      4  let bygones be bygones  685      5  time flies  603      6  alls well that ends well  588      7  one thing at a time  580      8  business is business  534      9  sink or swim  531      10  forgive and forget  477      11  take it or leave it  436      12  nothing is impossible  421      13  better late than never  419      14  every man for himself  414      15  know thyself  394      16  share and share alike  372      17  slow but sure  363      18  live and let live  356      19  the more the merrier  352      20  the die is cast  348      21  honesty is the best policy  339      22  to be or not to be  335      23  do or die  322      24  never say die  319      25  extremes meet  289      26  art for arts sake  286      27  all men are created equal  265      28  let well enough alone  260      29  time is money  250      30  no accounting for taste  249      31  peace at any price  244      32  tastes differ  241      33  history repeats itself  235      34  boys will be boys  235      35  charity begins at home  231      36  love is blind  228      37  the end justifies the means  227      38  one good turn deserves another  224      39  blood is thicker than water  221      40  not wisely but too well  219      41  all things work together for good  213      42  first come first served  201      43  keep the wolf from the door  196      44  dead men tell no tales  195      45  the wages of sin is death  191      46  seeing is believing  187      47  keep a stiff upper lip  186      48  ignorance is bliss  185      49  where theres a will theres a way  183      50  murder will out  179        The top 50 proverbs and proverbial expressions (from the  <em>Dictionary of American Proverbs</em> ) in the  <em>New York Times</em>  from 1987-2007.      Proverb  Count      1  to delay may mean to forget  1,075      2  enough is enough  891      3  time will tell  864      4  pay as you go  597      5  take it or leave it  565      6  do or die  528      7  first come first served  463      8  be yourself  348      9  father knows best  307      10  never say never  276      11  live and let live  272      12  money talks  244      13  the sooner the better  240      14  better late than never  224      15  sink or swim  218      16  boys will be boys  213      17  time flies  205      18  time is of the essence  204      19  divide and conquer  198      20  gentlemen prefer blondes  192      21  to be or not to be  187      22  the show must go on  185      23  time is money  174      24  talk is cheap  167      25  every man for himself  166      26  leave well enough alone  163      27  put up or shut up  161      28  business is business  159      29  accentuate the positive  157      30  forgive and forget  151      31  you get what you pay for  142      32  safety first  142      33  too little and too late  140      34  there is no easy way  132      35  let the chips fall where they may  131      36  all men are created equal  129      37  the more the merrier  128      38  history repeats itself  122      39  let bygones be bygones  117      40  one thing at a time  113      41  let nature take its course  106      42  never say die  106      43  seeing is believing  102      44  nothing is impossible  100      45  war is hell  95      46  the worst is yet to come  85      47  actions speak louder than words  82      48  gone but not forgotten  82      49  to each his own  80      50  let the buyer beware  80        The top 50 3-gram proverbs and proverbial expressions (from the  <em>Dictionary of American Proverbs</em> ) in the Google Books Ngram Corpus.      Proverb  Count      1  hold your tongue  131,426      2  time will tell  65,640      3  forgive and forget  45,189      4  enough is enough  43,149      5  business is business  30,101      6  sink or swim  26,315      7  nothing is impossible  25,695      8  easy does it  23,655      9  do or die  21,672      10  time is money  18,856      11  practice makes perfect  17,469      12  never say never  16,649      13  divide and conquer  15,673      14  love is blind  14,439      15  seeing is believing  12,951      16  never say die  12,329      17  ignorance is bliss  11,838      18  history repeats itself  11,529      19  fair is fair  10,456      20  slow but sure  9,898      21  forewarned is forearmed  9,860      22  love conquers all  9,839      23  misery loves company  9,654      24  facts are facts  8,944      25  time will pass  8,389      26  orders are orders  7,620      27  the truth hurts  7,292      28  blood will tell  6,840      29  father knows best  6,783      30  try anything once  6,388      31  murder will out  6,349      32  silence is golden  6,278      33  war is hell  6,136      34  business before pleasure  5,811      35  talk is cheap  5,723      36  revenge is sweet  5,400      37  familiarity breeds contempt  5,095      38  might makes right  4,768      39  consider the source  4,677      40  toe the mark  4,549      41  every little helps  4,139      42  time marches on  4,019      43  nothing is perfect  4,007      44  money is power  3,757      45  circumstances alter cases  3,668      46  respect your elders  3,644      47  gentlemen prefer blondes  2,922      48  mother knows best  2,908      49  love never fails  2,848      50  nobody is perfect  2,801        The top 50 proverbs and proverbial expressions (from the  <em>Dictionary of American Proverbs</em> ) on Twitter from 2008-2021.      Proverb  Count      1  never say never  2,549,095      2  enough is enough  2,182,460      3  nothing is impossible  978,533      4  time will tell  869,662      5  the truth hurts  748,285      6  forgive and forget  557,294      7  talk is cheap  465,608      8  love is blind  426,010      9  practice makes perfect  405,635      10  nobody is perfect  399,324      11  time is money  383,632      12  ignorance is bliss  377,037      13  do or die  316,328      14  history repeats itself  307,467      15  love never fails  255,795      16  misery loves company  226,217      17  divide and conquer  94,085      18  facts are facts  90,513      19  respect your elders  89,372      20  seeing is believing  86,169      21  time will pass  84,432      22  silence is golden  82,346      23  love conquers all  80,964      24  revenge is sweet  69,820      25  health is wealth  66,274      26  never say die  65,115      27  prayer changes things  63,757      28  iron sharpens iron  57,065      29  sink or swim  50,361      30  tomorrow never comes  50,297      31  business is business  39,525      32  hold your tongue  34,344      33  nothing is perfect  34,050      34  try anything once  33,370      35  mother knows best  26,848      36  every little helps  23,672      37  never waste time  22,244      38  fair is fair  18,125      39  slow but sure  14,404      40  consider the source  14,201      41  justice is blind  11,604      42  money is power  10,186      43  time works wonders  10,079      44  time changes everything  9,512      45  like attracts like  8,320      46  familiarity breeds contempt  8,166      47  war is hell  7,439      48  easy does it  6,071      49  gentlemen prefer blondes  5,273      50  courtesy costs nothing  3,890</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Zipf, G. K. (2012)  <em>Human behavior and the principle of least effort: An introduction to human ecology.</em>  Mansfield Centre, Conn: Martino Publishing [u.a.].&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Balasubrahmanyan, V. K. and Naranan, S. (1996)  “Quantitative linguistics and complex system studies,”    <em>Journal of Quantitative Linguistics</em> , 3(3), pp. 177–228. doi: <a href="https://doi.org/10.1080/09296179608599629">10.1080/09296179608599629</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Williams, J. R. et al. (2015b)  “Zipf’s law holds for phrases, not words,”    <em>Scientific Reports</em> , 5(1), p. 12209. doi: <a href="https://doi.org/10.1038/srep12209">10.1038/srep12209</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Cancho, R. F. i. and Solé, R. V. (2001)  “Two regimes in the frequency of words and the origins of complex lexicons: Zipf’s law revisited,”    <em>Journal of Quantitative Linguistics</em> , 8(3), pp. 165–173.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Čermák, F. (2014)  <em>Proverbs: their lexical and semantic features</em> . Burlington, Vermont: The University of Vermont (Supplement series of Proverbium Yearbook of International Proverb Scholarship, volume 36).&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Michel, J.-B.  <em>et al.</em>  (2011)  “Quantitative analysis of culture using millions of digitized books,”    <em>Science</em> , 331(6014), pp. 176–182. doi: <a href="https://doi.org/10.1126/science.1199644">10.1126/science.1199644</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Pechenick, Eitan Adam, Danforth, C. M. and Dodds, P. S. (2015)  “Characterizing the Google Books corpus: Strong limits to inferences of socio-cultural and linguistic evolution,”    <em>PLOS ONE</em> . Edited by A. Barrat, 10(10), p. e0137041. doi: <a href="https://doi.org/10.1371/journal.pone.0137041">10.1371/journal.pone.0137041</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Alshaabi, T.  <em>et al.</em>  (2020)  “Storywrangler: A massive exploratorium for sociolinguistic, cultural, socioeconomic, and political timelines using Twitter,”    <em>arXiv:2007.12988 [physics]</em> . Available at: <a href="http://arxiv.org/abs/2007.12988">http://arxiv.org/abs/2007.12988</a> (Accessed: 7 December 2020).&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Sag, I. A.  <em>et al.</em>  (2002)  “Multiword expressions: A pain in the neck for NLP,”  in Goos, G. et al. (eds)  <em>Computational Linguistics and Intelligent Text Processing</em> . Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 1–15. doi: <a href="https://doi.org/10.1007/3-540-45715-1_1">10.1007/3-540-45715-1_1</a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Mieder, W. (2012)  <em>Proverbs are never out of season: Popular wisdom in the modern age</em> . New York: Peter Lang (International folkloristics, v. 7).&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Mieder, W. (2008)  <em>&lsquo;Proverbs speak louder than words&rsquo;: Folk wisdom in art, culture, folklore, history, literature and mass media</em> . New York: P. Lang.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Lieber, M. D. (1994)  “Analogic ambiguity: A paradox of proverb usage,”  in Mieder, W. (ed.)  <em>Wise Words: Essays on the Proverb</em> . New York: Garland (Garland reference library of the humanities, vol. 1638), pp. 99–126.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Moon, R. (1998)  <em>Fixed expressions and idioms in English: A corpus-based approach</em> . Oxford : New York: Clarendon Press ; Oxford University Press (Oxford studies in lexicography and lexicology).&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Fazly, A., Cook, P. and Stevenson, S. (2009)  “Unsupervised Type and Token Identification of Idiomatic Expressions,”    <em>Computational Linguistics</em> , 35(1), pp. 61–103. doi: <a href="https://doi.org/10.1162/coli.08-010-R1-07-048">10.1162/coli.08-010-R1-07-048</a>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Shutova, E. (2010)  “Models of metaphor in NLP,”  in  <em>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</em> . Uppsala, Sweden: Association for Computational Linguistics, pp. 688–697. Available at: <a href="https://www.aclweb.org/anthology/P10-1071">https://www.aclweb.org/anthology/P10-1071</a>.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Lakoff, G. and Johnson, M. (1985)  <em>Metaphors We Live By</em> . Chicago, Ill.: Univ. of Chicago Press.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Andersson, D. (2013)  “Understanding figurative proverbs: A model based on conceptual blending,”    <em>Folklore</em> , 124(1), pp. 28–44. doi: <a href="https://doi.org/10.1080/0015587X.2012.734442">10.1080/0015587X.2012.734442</a>.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Özbal, G.  <em>et al.</em>  (2016)  “Learning to identify metaphors from a corpus of proverbs,”  in  <em>Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</em> . Austin, Texas: Association for Computational Linguistics, pp. 2060–2065. doi: <a href="https://doi.org/10.18653/v1/D16-1220">10.18653/v1/D16-1220</a>.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Özbal, G., Strapparava, C. and Sinem Tekiroglu, S. (2016)  “PROMETHEUS: A corpus of proverbs annotated with metaphors,”    <em>LREC, Proceedings of the Tenth International Conference on Language Resources and Evaluation</em>  (LREC’16), pp. 3787–3793.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Abrahams, R. D. and Babcock, B. A. (1994)  “The literary use of proverbs,”  in Mieder, W. (ed.)  <em>Wise words: Essays on the Proverb</em> . New York: Garland (Garland reference library of the humanities, vol. 1638), pp. 415–437.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Obelkevich, J. (1994)  “Proverbs and social history,”  in Mieder, W. (ed.)  <em>Wise Words: Essays on the Proverb</em> . New York: Garland (Garland reference library of the humanities, vol. 1638), pp. 211–252.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Permiakov, G. L. (1989)  “On the question of a Russian paremiological minimum.,”    <em>Proverbium</em> , 6, pp. 91–102.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Albig, W. (1931)  “Proverbs and social control,”    <em>Sociology and Social Research</em> , (15), pp. 527–535.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Bain, R. (1939)  “Verbal stereotypes and social control,”    <em>Sociology and Social Research</em> , (23), pp. 431–446.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Haas, H. A. (2008)  “Proverb familiarity in the United States: Cross-regional comparisons of the paremiological minimum,”    <em>Journal of American Folklore</em> , 121(481), pp. 319–347. doi: <a href="https://doi.org/10.2307/20487611">10.2307/20487611</a>.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Whiting, B. J. (2014)  <em>Modern Proverbs and Proverbial Sayings</em> . Available at: <a href="https://0-doi-org.pugwash.lib.warwick.ac.uk/10.4159/harvard.9780674864153">https://0-doi-org.pugwash.lib.warwick.ac.uk/10.4159/harvard.9780674864153</a>.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Norrick, N. R. (1985)  <em>How Proverbs Mean: Semantic Studies in English Proverbs</em> . Berlin, New York: DE GRUYTER MOUTON. doi: <a href="https://doi.org/10.1515/9783110881974">10.1515/9783110881974</a>.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Lau, K. J. (1996)  “&lsquo;It’s About Time&rsquo;: The ten proverbs most frequently used newspapers and their relation to American values,”    <em>Proverbium</em> , 13, pp. 135–59.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Cram, D. (1994)  “The linguistic status of the Proverb,”  in Mieder, W. (ed.)  <em>Wise Words: Essays on the Proverb</em> . New York: Garland (Garland reference library of the humanities), pp. 73–97.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<pre><code>“British National Corpus,”  (2001). Available at: [http://www.natcorp.ox.ac.uk](http://www.natcorp.ox.ac.uk).  
</code></pre>
&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:31">
<p>Clauset, A., Shalizi, C. R. and Newman, M. E. J. (2009)  “Power-law distributions in empirical data,”    <em>SIAM Review</em> , 51(4), pp. 661–703. doi: <a href="https://doi.org/10.1137/070710111">10.1137/070710111</a>.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Martínez-Mekler, G.  <em>et al.</em>  (2009)  “Universality of rank-ordering distributions in the arts and sciences,”    <em>PLoS ONE</em> . Edited by M. Costa, 4(3), p. e4791. doi: <a href="https://doi.org/10.1371/journal.pone.0004791">10.1371/journal.pone.0004791</a>.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Pechenick, Eitan A., Danforth, C. M. and Dodds, P. S. (2015)  “Is language evolution grinding to a halt? The scaling of lexical turbulence in English fiction suggests it is not.”&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>Reagan, A. J.  <em>et al.</em>  (2016)  “The emotional arcs of stories are dominated by six basic shapes,”    <em>EPJ Data Science</em> , 5(1), p. 31. doi: <a href="https://doi.org/10.1140/epjds/s13688-016-0093-1">10.1140/epjds/s13688-016-0093-1</a>.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Underwood, T., Bamman, D. and Lee, S. (2018)  “The transformation of gender in English-language fiction,”  p. 25.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Dodds PS, Minot JR, Arnold MV, Alshaabi T, Adams JL, Reagan AJ, et al. (2021)  “Computational timeline reconstruction of the stories surrounding Trump: Story turbulence, narrative control, and collective chronopathy,”  PLoS ONE 16(12): e0260592. <a href="https://doi.org/10.1371/journal.pone.0260592">https://doi.org/10.1371/journal.pone.0260592</a>&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Leskovec, J., Backstrom, L. and Kleinberg, J. (2009)  “Meme-tracking and the dynamics of the news cycle,”  in  <em>Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD ’09</em> . Paris, France: ACM Press, p. 497. doi: <a href="https://doi.org/10.1145/1557019.1557077">10.1145/1557019.1557077</a>.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Tangherlini, T. R. (2016)  “Big folklore: A special issue on computational folkloristics,”    <em>The Journal of American Folklore</em> , 129(511), p. 5. doi: <a href="https://doi.org/10.5406/jamerfolk.129.511.0005">10.5406/jamerfolk.129.511.0005</a>.&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Abello, J., Broadwell, P. and Tangherlini, T. R. (2012a)  “Computational folkloristics,”    <em>Communications of the ACM</em> , 55(7), pp. 60–70. doi: <a href="https://doi.org/10.1145/2209249.2209267">10.1145/2209249.2209267</a>.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Mieder, W., Kingsbury, S. A. and Harder, K. B. (eds) (1992)  <em>A Dictionary of American Proverbs</em> . New York: Oxford University Press.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>Robinson, D. (2020)  <em>Gutenbergr</em> . Available at: <a href="https://cran.r-project.org/web/packages/gutenbergr/index.html">https://cran.r-project.org/web/packages/gutenbergr/index.html</a>.&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>The pandas development team (2020)  <em>pandas-dev/pandas: Pandas</em> . Zenodo. doi: <a href="https://doi.org/10.5281/zenodo.3509134">10.5281/zenodo.3509134</a>.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Hunter, J. D. (2007)  “Matplotlib: A 2D graphics environment,”    <em>Computing in Science &amp; Engineering</em> , 9(3), pp. 90–95. doi: <a href="https://doi.org/10.1109/MCSE.2007.55">10.1109/MCSE.2007.55</a>.&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Glaberson, W. (1992)  “Assault case renews debate on rape shield law,”    <em>The New York Times</em> .&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>[Hanley, R. (1992)  “Jury chosen in Glen Ridge assault trial,”    <em>The New York Times</em> .&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<pre><code>“Vote Yes on the Bond Act,”  (1996)  _The New York Times_ .  
</code></pre>
&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:47">
<p>Henry, J. (1996)  “How the money was spent in previous environmental Bond Acts,”    <em>The New York Times</em> .&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Mieder, W. (2019)  <em>“Right makes Might”: Proverbs and the American worldview</em> . Bloomington, Indiana: Indiana University Press.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Swuste, P., Gulijk, C. van and Zwaard, W. (2010)  “Safety metaphors and theories, a review of the occupational safety literature of the US, UK and The Netherlands, till the first part of the 20th century,”    <em>Safety Science</em> , 48(8), pp. 1000–1018. doi: <a href="https://doi.org/10.1016/j.ssci.2010.01.020">10.1016/j.ssci.2010.01.020</a>.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Mieder, W. (2004)  <em>Proverbs: a handbook</em> . Westport, Conn: Greenwood Press (Greenwood folklore handbooks).&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Georgia, S. C. of (1991)  “Cunningham v. State 1991.”&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Clancy, T. (1990).  <em>Clear and present danger</em> . Berkley mass-market edition. ed. Berkley Books, New York.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Zemeckis, R. (1994)  <em>Forrest Gump</em> . Paramount Pictures.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Tweedle, V. and Smith, R. J. (2012)  “A mathematical model of Bieber Fever: The most infectious disease of our time?,”  in.&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Alter, C. (2018)  “The Young and the Relentless,”    <em>TIME</em> . Available at: <a href="https://time.com/magazine/us/5210502/april-2nd-2018-vol-191-no-12-u-s/">https://time.com/magazine/us/5210502/april-2nd-2018-vol-191-no-12-u-s/</a>.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<pre><code>“March for Our Lives Highlights: Students Protesting Guns Say 'Enough Is Enough'”  (2018)  _The New York Times_ .  
</code></pre>
&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:57">
<p>Semones, E. (2020)  “&lsquo;Enough is enough&rsquo;: Thousands descend on D.C. for largest George Floyd protest yet,”    <em>POLITICO</em> .&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>Doyle, C. C., Mieder, W. and Shapiro, F. R. (2012)  <em>The Dictionary of Modern Proverbs</em> . New Haven: Yale University Press.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Williams, J. R.  <em>et al.</em>  (2015a)  “Text mixing shapes the anatomy of rank-frequency distributions,”    <em>Physical Review E</em> , 91(5), p. 052811. doi: <a href="https://doi.org/10.1103/PhysRevE.91.052811">10.1103/PhysRevE.91.052811</a>.&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Historical GIS and Guidebooks: A Scalable Reading of Czechoslovak Tourist Attractions</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000679/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000679/</id><author><name>Sune Bechmann Pedersen</name></author><author><name>Mathias Johansson</name></author><published>2023-05-26T00:00:00+00:00</published><updated>2023-05-26T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Scholars interested in the history of travel and tourism have long relied on historical guidebooks as a primary source to past patterns of mobility and cultural ideals. The guidebook’s descriptive and prescriptive nature — describing places, peoples, and cultures, and ordering them in a normative hierarchy of attractiveness — is a treasure trove of information about the practices and ideas constituting past travel cultures <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Historians have been keen to query guidebooks for insights about aesthetic sensibilities, communications and infrastructures, and representations of the other. The preferred method for studying such themes has been qualitative, close readings of travel guides (classical examples of this include <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>; <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>). Only recently have tourism historians begun to employ digitally enabled methods, for instance Historical Geographic Information Systems (HGIS) exploring the origins of nineteenth-century Baltic spa guests <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> and the family networks of Grand Tour travellers to Italy <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, or semantic modelling of Baedeker travel guides <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Scholars of the ancient world have also demonstrated the value of HGIS for studying travel times in the Roman Mediterranean <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> and for understanding Pausanias’s  <em>Periegesis Hellados</em>  — a complex cultural geography of Greece often referred to as the first guidebook <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. What we propose in this article, though, is for historians of modern tourism to take advantage of the comparatively homogenous nature of modern guidebooks and harness HGIS for new, computer-assisted tourism histories.</p>
<p>The primary aim of this article is to scrutinize the persistence of older tourist attractions under communism in Czechoslovakia. In doing so, we also demonstrate the promising methodological avenues for scalable reading of the tourist guidebook as a historical source, combining traditional close reading with computer-assisted distant reading <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. More specifically, the article illustrates the potential of systematically mapping the spatial information contained in guidebooks diachronically and in combination with qualitative, contextualizing sources. Approaching modern guidebooks to the same destination as time series enables the researcher to chart the rise and fall of touristic sites. The possibility to pinpoint the omission and disappearance of tourist attractions over time and across large geographical areas is particularly promising as such absences easily pass unnoticed during traditional close readings. The method also allows for visualizing attraction hierarchies by comparing the touristic sites contained in comprehensive guidebooks with those in compact guidebooks from the same period. Such observations can then inspire further research into changes and continuities in touristic infrastructure and forms of attraction. In these efforts, the current work thus seeks to bridge the gap between quantitative and qualitative uses of GIS (<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>; <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>; <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>).</p>
<p>This article illustrates some of the methodological opportunities outlined above through a scalable reading of the first guidebook to communist Czechoslovakia for western travellers after the Second World War. The guidebook  _Czechoslovakia _   <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> was published eleven years after the communist coup in 1948, and produced by Čedok, the Czechoslovak National Tourist Organization. To provide diachronic contextualization we compare this guidebook with two predecessors similar in terms of audience and scope, but markedly different in terms of production context. Closest in time is the  <em>Guide to the Czechoslovak Republic</em>   <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, Čedok’s first travel guide for foreign readers published under the democratic interwar government a decade after the republic’s foundation in 1918. Čedok published no similar volumes between 1928 and 1959, which makes the two publications ideal for a study of how the communist tourist authorities sought to present the country. The continuity in intended audience (foreign, primarily western tourists) combined with the radically differing political circumstances allows for novel insights into the persistence of old travel ideals under communism. The two volumes are further contextualized by comparison with the reputable German guidebook publisher Baedeker’s comprehensive  <em>Austria–Hungary including Dalmatia and Bosnia</em>  from 1905, which covered the geographical area that became Czechoslovakia after 1918. Taken together, the travel guides allow us to trace the (dis)continuities of tourist attraction distribution in communist Czechoslovakia.</p>
<h2 id="opening-communist-czechoslovakia-to-western-tourists">Opening communist Czechoslovakia to western tourists</h2>
<p>In 1957, more than one hundred diplomats and travel industry representatives from twenty-nine countries converged on Prague in Czechoslovakia for a five-day conference on international tourism. The event took place four years after the death of Stalin in 1953 at a time when the Communist government, in power since the coup in February 1948, was gradually improving its diplomatic relations with the West. Organised by Čedok, the primary aim of the conference was to promote Czechoslovakia as an international tourist destination and ease the mobility of Western tourists across the Cold War divide. The organizers hoped that the global meeting would facilitate contacts and sow the seeds of future collaboration between airlines, railways, and tourist associations of all continents. Shortly before the Prague conference, the travel bureaus of the socialist states had held a separate meeting in Carlsbad where they concluded that  “the most effective path to mutual understanding and comprehension is for nations to speak to nations in the most direct manner, by tourism.” <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>  The declaration echoed a stance taken by the Czechoslovak Politburo two years earlier as it revised its policy towards Western tourism in the autumn of 1955 <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. Back then, the leading political organ recognized that  “at present, the development of tourism is of particular political importance. Foreign trade is becoming one of the instruments of mitigating international tensions.” <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></p>
<p>In terms of formal tourism policy, the years 1955–56 marked the country’s turning point away from Stalinist isolation and towards the search for a  “common ground between East and West in the postwar world order”  later epitomised by the award-winning Czechoslovak pavilion at the 1958 Brussels World’s Fair <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. In 1955, Čedok made its first arrangements with western travel companies and the following year it invited forty western travel industry representatives to the country. Starting in March 1956, Czechoslovakia also began to issue regular tourist visas and Čedok prepared thirteen hotels of higher standard specifically for western guests <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>. Instead of seeing Western tourists solely as a threat to national security, the Communist regime prepared to capitalise on international tourism as a tool for cultural diplomacy and an invisible export.</p>
<p>To some extent the efforts of the Communist regime to attract foreign visitors and win international recognition through tourism mirrored initiatives of the newly founded Czechoslovak state in the interwar period. After the breakaway from the Austro-Hungarian empire at the end the First World War, the new state utilised international tourism to gain recognition abroad as an independent nation worthy of its sovereignty <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>. Čedok was quickly established as the country’s national travel agency and a semi-official tool of nation branding with several foreign offices (<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>; <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>). The country also participated in transnational collaboration on tourism, hosting the second international congress of national tourist organizations in 1926 <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. These congresses were continued immediately after the Second World War when the International Union of Official Tourist Organizations (IUOTO) was established with Czechoslovakia as a member. Following the February coup in 1948, though, the Stalinist regime in Prague left the organization at the onset of the Cold War.</p>
<p>Nine years later, in 1957, the country returned to the international tourist organization it had once helped found. The same year the international tourist conference in Prague crowned the reorientation of Czechoslovakia’s international tourism policy. Čedok representatives were sent on at least 14 different trips to Western Europe, North America, and Africa where they attended travel fairs and surveyed the local travel industry for potential partners.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>  These efforts to attract foreign tourists raised fundamental questions with significant ideological ramifications. What, in fact, were communist Czechoslovakia’s tourist attractions, and how could they be ordered in a hierarchy of attractiveness? Where should Western visitors be invited to travel and why? Security interests would have to be balanced against economic interests as the spatial distribution of tourist sites for foreigners risked interfering with military zones and state security efforts to thwart western cultural influences and spying. One aspect of the political dilemmas of international tourism to Cold War Czechoslovakia is captured in a US embassy cable sent from Prague to Washington DC in 1957.</p>
<blockquote>
<p>Visitors and permanent foreign residents in Prague often bemoan the fact that there is no up-to-date guidebook to the Czechoslovak capital city. Recently an embassy officer asked an employee of ARTIA, the responsible state publishing house, why this was so.  “Oh,”  the Czech replied,  “you have no idea what a difficult task it is, how great is the responsibility involved in determining which buildings and other landmarks should be included in such a guidebook and what reasons should be given for visiting them. So many offices and ministries would have to be consulted by an author, so many decisions would have to be made…” <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup><br>
Disregarding its somewhat satirical tone, the dialogue recounted in the cable illustrates Mary Heiman’s point how, in Czechoslovakia’s  “political system that routinely disgraced and punished anyone who stepped out of line with the current policy directives, there was not a lot of scope for independent initiative.”   <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> Four years earlier, however, amidst Stalinist show trials and campaigns to root out  “bourgeois elements,”  Čedok had in fact compiled an 80-page guide in Czech to Prague and its environs <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. Yet its lengthy sections on  “The recreation of Prague workers,”    “Prague on the road to socialism,”  and  “In the footsteps of the workers’ movement and the history of the Communist Party in Prague”  did not provide an ideal template for a guidebook geared to a western audience. Complicating matters further and exemplifying the dynamic and sometimes contradictory process of de-Stalinisation in Czechoslovakia, the editor of the 1953 guidebook was the prominent geographer Jiří Král — author of Čedok’s 1928  <em>Guide to the Czechoslovak Republic</em>  — who had been forced into retirement after the Communists came to power and now worked as a tourist guide in Prague to make ends meet. The estranged and somewhat eccentric Král was only rehabilitated in 1966, so he and his manuscript would have been unlikely candidates for the symbolically important job of introducing the country to western readers <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup></p>
</blockquote>
<p>The task of producing the first postwar guidebook for western tourists to Czechoslovakia instead fell on Jiří Chyský. The son of Čeněk Chyský, an important figure in the Czech tourist movement and author of guidebooks to Prague (<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>; <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>), Chyský junior had himself edited a Czech tourist guide to Prague in 1955 and written a booklet on the organization of domestic tourism the same year. Jiří Chyský was also an ardent communist and an employee of the Ministry of Justice who had helped the Party seize control of the scout movement in 1948, so he was undoubtedly attuned to the politics of tourism. Among his collaborators on the international guidebook project were Milan Skalník, an accomplice in the purge of the scout movement, and Vladimír Adamec, author of several guidebooks for domestic readers in the 1950s <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>. Unfortunately the Čedok archive has been lost, which makes further investigations into the production of the two guidebooks difficult <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. From other government sources we nevertheless know that in 1958, the Czechoslovak authorities reached an agreement with the Geneva-based guidebook publisher Louis Nagel, who was seeking to establish his publishing house as the leading provider of guides to Eastern Europe. Nagel’s had already published guides to Moscow and Leningrad <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> and Hungary <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>, and according to Čedok’s investigations, Nagel’s guides enjoyed a fine reputation in Switzerland and France as reliable and objective. The manuscript was eventually provided by Čedok in collaboration with Chyský, and seven other authors. Nagel’s published the result in 1959 simultaneously in English, French, and German editions. The print-run amounted to 3,000 copies to be sold through Western channels aiming to earn hard currency profits.<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup></p>
<p>Nagel’s 1959 guidebook to Czechoslovakia is a typical artefact of the cultural Cold War in which the superpowers vied for popular support at home and abroad. It lends itself well to the kind of close readings of descriptions and prescriptions that historians have honed since the cultural turn of the 1980s. However, with its 290 pages and an index of more than 600 entries, this list of toponyms meets the big data criteria set forth by Graham et al. to be  “big enough”  for  “computational intervention to make new sense of them”   <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>. HGIS provides another way of exploring the guidebook’s officially approved image of Czechoslovakia as a destination of Western tourism. It also allows for comparisons with the attractions represented by guidebooks from other periods or produced by other publishers. In this way, historical comparisons of guidebooks allow for diachronic studies of a destination’s tourist attractions across political caesuras, thereby querying the relation between politics and tourism from a new perspective.</p>
<h2 id="hgis-and-travel-guides">HGIS and travel guides</h2>
<p>Building a suitable corpus of guidebooks for exploration with HGIS involves several methodological challenges. First, attempts to build long time series face the problem of genre fluidity as the modern tourist guidebook is barely 200 years old. Before the publication of the first travel guides by Baedeker and Murray in the 1830s, travel writers liberally mixed advice with art history, geology, folklore, and political commentary. It was only with the introduction of authoritative, standardized, and regularly updated texts for travellers in the middle of the nineteenth century that travel writing and travel guide parted ways <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>. To ensure relative conformity of the compared texts, we recommend limiting a travel guide corpus to modern, post-1830s guidebooks.</p>
<p>The second challenge concerns the creation of a meaningful sample from the heaps of modern guidebooks churned out by a vast number of publishing houses around the world as leisure travel developed from an elite privilege to a mass phenomenon. In this study, the focus is on the officially approved image of Czechoslovakia as represented by travel guides produced by the state tourist agency targeted at foreigners. We therefore chose to focus on two travel guides produced by the same organization (Čedok), geared towards the same audience of relatively affluent foreigners with time to spare for a longer journey abroad;  <em>Guide to the Czechoslovak Republic</em>   <sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, and  <em>Czechoslovakia</em>   <sup id="fnref1:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. Čedok did not publish any similar travel guides for foreign tourists between 1928 and 1959, only some small brochures. To provide further historical contextualization we also compare with the 1905 Baedeker guide to Austria–Hungary. While the German version of this Baedeker guidebook was regularly updated until the outbreak of the First World War, the edition from 1905 was the final one published in English before the eventual dissolution of the Habsburg Empire. Čedok’s 1928 guidebook was published simultaneously in German and English, while the Čedok/Nagel guidebook from 1959 was published simultaneously in German, English, and French. We chose to compare the English editions of the three guidebooks since minimizing the number of German toponyms in the corpus reduced the need for disambiguating place names.</p>
<p>Working with twentieth century guidebooks entails a third methodological challenge. As the personal idiosyncrasies of travel writing gave way to the formulaic descriptions of frequently updated guidebooks the literary status of the genre diminished. Twentieth century guidebooks attained an ephemeral quality similar to grey literature with lasting consequences for preservation and access. Given the short half-life and low literary standing of these books, library and archive collections are often patchy. And even if one successfully locates a complete series of a guidebook title, a fourth challenge emerges: twentieth century guidebooks rank just about rock bottom of current digitization priorities. This is unsurprising, as the preserved books are often in good conditions, oftentimes under copyright, and perceived to be of marginal relevance to the national community’s cultural heritage. Since we did not possess the means required for producing digitized editions with high quality machine-readable text we opted for a simpler and more efficient method to prepare the data for computer-assisted analysis. Instead of working with complete guidebook texts we digitized, cleaned, and mapped only the toponyms included in the guidebook indexes. This cost-saving method builds on the reasonable assumption that the guidebook editors included all the places they deemed most relevant to foreign tourists in the three indexes. Our assumption is supported by the fact that the guidebooks contained comprehensive indexes (see Table 1) referring to an average of 2–3 unique toponym per content page. However, some of the toponyms are duplicates as the English-language indexes also included alternate names in Czech, Slovak, German, and Hungarian. The precise number of toponyms and unique positions for each guidebook is listed in table 1. Note that these numbers do not include indexed toponyms outside the 1959 borders of Czechoslovakia, nor do they include geographic entities that are not meaningfully represented by a single coordinate (e.g. rivers, mountain ranges, large forests). Such toponyms are also excluded from the maps.<br>
Table 1: Indexed toponyms and unique positions in the three guidebooks    Guidebook   Indexed toponyms  Unique positions      Baedeker (1905)  1007  754      Čedok (1928)  1523  1281      Čedok/Nagel (1959)  617  586   <br>
The method excludes all toponyms considered too marginal by the editors to feature in the index. However, this apparent weakness works to our advantage, as the point of the analysis is to identify continuity and change in tourist attractions — not to map every town or village mentioned in the travel guide merely to help readers navigate from one attraction to another. In the process we excluded toponyms listed as subentries under the bigger cities in the 1905 and 1959 guidebooks (such as palaces, churches, and museums) since our focus is on the countrywide range of attractions. Mapping the changing tourist geography of a city like Prague would undoubtedly yield interesting results. However, precise geocoding at street level during a period of rapid urban development would require manual labour beyond the scope of this project. For the heatmap visualizations (Figure 2) we still assigned approximate weight to the cities based on the subentries (or the page span in the case of the 1928 guidebook, which did not have subentries).<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup></p>
<h2 id="disambiguation-and-geolocation-of-historical-toponyms">Disambiguation and geolocation of historical toponyms</h2>
<p>To geolocate the lists of toponyms included in each index we matched them against a gazetteer with toponyms and coordinates compiled from the open-source geographical database GeoNames, supplemented with toponyms from WikiData. GeoNames boasts of having  “27 million geographical names”  compiled from 402 different sources, including official sources such as the Czech Office for Surveying, Mapping and Cadastre, and the Geodetic and Cartographic Institute Bratislava.<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>  A persistent challenge for HGIS is disambiguation (<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>; <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>). To capture all the possible places and toponyms inside the borders of communist Czechoslovakia we combined the gazetteers for Czechia, Slovakia, and Hungary and linked them with GeoNames’ own list of alternate names. To ease the disambiguation of historical toponyms featured in the travel guide indexes we supplemented the gazetteer with English and German spelling variations from WikiData, bringing the total number of languages to five. From the onset, our gazetteer thus contained 156,932 toponyms across 68,947 coordinates stored in a relational database.</p>
<p>The automated toponym disambiguation is a particular variant of Approximate String Matching (ASM): the problem of declaring whether two non-identical strings of characters match. It is a classical computer science problem that has inspired numerous solutions in the form of metrics declaring a pair a match or not based on a predetermined threshold (<sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>; <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>; <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>; <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>). Machine Learning models offer another solution, but while they tend to perform better, they also require training on large amounts of annotated data and typically lead to static models, needing retrained whenever new pairings are discovered (<sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>; <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>). In many toponym disambiguation cases, a simple metric approach thus suffices to yield reliable results efficiently (<sup id="fnref1:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>; <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>; <sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>). With more than 3,000 toponyms to geolocate and a need to minimize false positives, we opted for a very restrictive threshold to ensure that only highly similar toponyms were auto-matched (Jaro-similarity of 0.9).</p>
<p>For easy data entry, we constructed a place name disambiguation and geocoding application (CITADEL) composed of two parts: a web application with a graphical user interface (built with Anvil), linked with a server-side application (written in Python) to run the automated disambiguation and matching against the toponym database.<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>  When users enter index toponyms in the GUI they are matched against the gazetteer in a series of successively looser matching conditions, from requiring a perfect match to Jaro 0.9, to generate a list of probable positions. CITADEL geolocated the majority of the index toponyms and provided a short list of suggestions for most of the remaining toponyms to aid in their manual disambiguation. To assign a coordinate to the remaining toponyms we cross-referenced the indexes, the guidebook descriptions, modern and historical maps to approximate the coordinates. The toponyms we geolocated manually were added to the gazetteer to improve disambiguation and geolocation of other historical sources in the future. Finally, we mapped the toponyms<sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>  using the open-source GIS tool QGIS and importing historical borders from the CShapes 2.0 Dataset <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>.<sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup></p>
<h2 id="analysis">Analysis</h2>
<p>To provide a baseline for our interpretation of the 1959 travel guide we began by mapping its indexed toponyms along with the indexes of the 1905 and 1928 guidebooks. Figure 1 shows the results, with each dot representing the coordinate of a toponym within the borders of Cold War Czechoslovakia. Given our analytical focus on the tourist attractions in 1959 we chose to map all guidebooks on the same projection of communist Czechoslovakia’s political borders. Our emphasis on the country’s cold war borders admittedly yields a somewhat misleading impression of the earlier guidebooks since the area’s political geography appeared entirely different during the Austro-Hungarian Empire and the interwar period. Most importantly, in the Dual Monarchy before the Great War the Czech lands belonged to Austria whereas Slovakia constituted a part of Upper Hungary. Moreover, interwar Czechoslovakia also included the area east of Slovakia known as Carpathian Ruthenia (part of present-day Ukraine). We nevertheless decided to exclude Ruthenian toponyms from our analysis since this poor and remote region cursorily mentioned in the 1928 guidebook was transferred to the Soviet Union after the Second World War and thus did not feature in the 1959 guidebook.</p>




























<figure ><img loading="lazy" alt="A set of three maps of Czechoslovakia labeled 1905, 1928, and 1959 where toponyms are shown as dots" src="/dhqwords/vol/17/2/000679/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000679/resources/images/figure01_hu1121780f2b85227bf82fc6ddd2535841_4666346_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000679/resources/images/figure01_hu1121780f2b85227bf82fc6ddd2535841_4666346_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000679/resources/images/figure01_hu1121780f2b85227bf82fc6ddd2535841_4666346_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000679/resources/images/figure01_hu1121780f2b85227bf82fc6ddd2535841_4666346_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000679/resources/images/figure01_hu1121780f2b85227bf82fc6ddd2535841_4666346_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000679/resources/images/figure01.png 3103w" 
     class="portrait"
     ><figcaption>
        <p>Geolocated toponyms by travel guide
        </p>
    </figcaption>
</figure>
<p>At first sight, the three maps in Figure 1 show a similar, fairly even distribution of attractions throughout the elongated country. Upon closer inspection, however, the 1905 and 1928 maps include more toponyms in the western part of the country compared to the 1959 map. To make the differences clearer, we generated heatmaps based on the same toponym data and standardized across the three datasets to allow for comparison (Figure 2).<sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup></p>




























<figure ><img loading="lazy" alt="A set of three maps of Czechoslovakia labeled 1905, 1928, and 1959 where toponym density is indicated by color" src="/dhqwords/vol/17/2/000679/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000679/resources/images/figure02_hu9dbe516da33036c1efcfe7a954b962a6_2845380_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000679/resources/images/figure02_hu9dbe516da33036c1efcfe7a954b962a6_2845380_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000679/resources/images/figure02_hu9dbe516da33036c1efcfe7a954b962a6_2845380_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000679/resources/images/figure02_hu9dbe516da33036c1efcfe7a954b962a6_2845380_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000679/resources/images/figure02_hu9dbe516da33036c1efcfe7a954b962a6_2845380_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000679/resources/images/figure02.png 3253w" 
     class="landscape"
     ><figcaption>
        <p>Heatmaps of weighted geolocated toponyms by travel guide
        </p>
    </figcaption>
</figure>
<p>The heatmaps show a continuity of toponym density in four areas: The cities of Prague and Brno, which had long been the urban centres of Bohemia and Moravia; the Bohemian Paradise (Český ráj) northeast of Prague, famous for its medieval castles and distinctive sandstone rock formations; and the High Tatra Mountains on Slovakia’s northern periphery, a popular area for hiking, hunting, mountaineering, and medical retreats since the late nineteenth century. The heatmaps also show a clear shift in emphasis from the older guidebooks’ denser distribution of toponyms in Bohemia (the western half of present-day Czechia) and thinner distribution in the mountainous Slovakia compared to the 1959 guidebook’s more balanced representation of Czech and Slovak attractions. (Note here that the overall lower temperature of the 1959 map owes to its relatively smaller number of indexed toponyms compared to the older guidebooks.)</p>
<p>The high density of attractions in Bohemia on the 1905 and 1928 maps is an expected finding. Bohemia had traditionally been the richest and most populous part of the country and the West Bohemian spa triangle outlined by Carlsbad (Karlovy Vary), Marienbad (Mariánské Lázně), and Franzensbad (Františkovy Lázně) had a long history of attracting visitors from far-away lands <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>. The borderland’s spa towns continued to cater to an international clientele after the First World War while numerous historical castles perched on hilltops and charming chateaux surrounded by romantic gardens provided spectacular tourist sights. The pre-WWII density of attractions along the borders with present-day Austria, Germany, and Poland illustrates the transformation of areas characterized by high hills and deep forests into recreational sites for hiking, camping, and skiing in the early twentieth century. These parts of the country, Bohemian Switzerland, the Bohemian Forest (Šumava), and the Giant Mountains, were deemed such important tourist attractions that they merited special fold-out maps in the 1928 guidebook, underlining their touristic value and accessibility. Both the 1905 Baedeker and the 1928 Čedok guide also included detailed maps of the High Tatra Mountains, and the area’s many summits, saddles, valleys, lakes, hiking routes, and huts were meticulously described and indexed in all three guidebooks, which explains the high temperature there.</p>
<p>More surprising, though, is the relatively thin representation of western Bohemia in the 1959 guidebook and the more balanced representation of Czech and Slovak attractions. The first difference is a likely effect of the cold war militarization of this region where the Warsaw Pact bordered directly with NATO. For security reasons, the Czechoslovak authorities did not want western tourists roaming too close to the state border, which at this point was not yet fully demarcated and fortified <sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>. The second difference indicates an attempt to present the two parts of the country, the Czech lands and Slovakia, as equally attractive, despite the latter’s more remote location from the western tourist’s point of the view (which the guidebooks all adopted). Writing on behalf of the new state’s official tourist organisation, Král seems to have recognized the political obligation to give Slovakia a more detailed treatment already in 1928; a concern that did not burden a commercial guidebook publisher like Baedeker at the turn of the century. In his introduction, Král explained that</p>
<blockquote>
<p>The greatest attention is of course devoted to the world famous Spas. But also those regions, which nature has endowed with such uncommon attractions — notably in Slovakia and Subcarpathian Russia — and where so far, the foreigner has only rarely found his way, are dealt with here, allowing at least a rough idea to be formed by him, who would penetrate into districts where both people and nature have a character of their own, even if conditions are sometimes below the standard of comfortable tourism.<br>
<sup id="fnref2:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> Král’s guidebook devoted just 48 of its 272 pages (18%) to Slovakia but it was nevertheless considered exemplary compared to contemporary handbooks on Czechoslovakia. Writing a few years later, a reviewer of two English-language travel guides to Czechoslovakia (published outside the country) held up the reviewed books against Kral’s and found Slovakia treated  “in a very perfunctory way”  and  “rushed through in a very cursory manner”   <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>. Three decades later, the authors of the 1959 guidebook were careful to steer clear of the exoticizing language enveloping Slovakia and the historical bias towards attractions in Bohemia and Moravia. Numerically, 85 of its 290 pages (29%) covered Slovakia.</p>
</blockquote>
<p>To further probe the (dis)continuities between the three guidebooks we analysed the indexed toponyms with the help of a clustering algorithm. This method allowed us to merge coordinates referring to the same tourist site. For instance, the 1959 index contained an entry for  “Bouzov, castle”  while the 1928 index had an entry for  “Bouzov” , the Moravian village next to the castle. The geocoding process assigned different coordinates for the two entries, but since the attraction is the same, the clustering algorithm is useful to group such entries under a single coordinate. The clustering process also eliminates the problem that our multilingual gazetteer would sometimes contain near-identical coordinates for identical toponyms. The clustering algorithm merged any points within a radius of roughly 4 km calculated as the great-circle distance of the coordinates into the same cluster. The low radius was chosen to avoid an avalanche of clustering creating meaningless superclusters. When all positions within the radius had been placed in the same cluster, the cluster’s coordinates were calculated as the arithmetic mean of the member coordinates. The method allows for the subtraction of clusters between maps, which renders the (dis)continuities more visible.</p>




























<figure ><img loading="lazy" alt="Map of Czechoslovakia with black dots" src="/dhqwords/vol/17/2/000679/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000679/resources/images/figure03_hu858abf3db99bbb183e88afbc52b96db4_1235555_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000679/resources/images/figure03_hu858abf3db99bbb183e88afbc52b96db4_1235555_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000679/resources/images/figure03_hu858abf3db99bbb183e88afbc52b96db4_1235555_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000679/resources/images/figure03_hu858abf3db99bbb183e88afbc52b96db4_1235555_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000679/resources/images/figure03_hu858abf3db99bbb183e88afbc52b96db4_1235555_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000679/resources/images/figure03.png 3098w" 
     class="landscape"
     ><figcaption>
        <p>Geolocated toponym clusters (4 km) included in the Baedeker 1905, Čedok 1928 and Nagel 1959 guidebook indexes
        </p>
    </figcaption>
</figure>
<p>Figure 3 shows the 174 clusters comprised of 573 unique, close-neighbouring positions included in all three guidebooks. A quick glance at the map suffices to note that the country’s main border posts and all the bigger cities are represented. A closer reading of the clusters’ locations shows that the shared content includes a number of spas, many of which had been popular with foreign guests since the nineteenth century, e.g. Carlsbad, Marienbad, Franzensbad, Bad Königswart (Lázně Kynžvart), Bad Gräfenberg (Lázně Jeseník), Pistyan (Kúpele Piešťany), and Kúpele Korytnica. The clusters also contain some of the country’s picturesque old towns and famous castles including Český Krumlov, Karlštejn, Kroměříž, Křivoklát, and Loket. Natural landmarks such as peculiar rock formations, scenic cliffs, caves, forests, valleys, hills, and mountains also feature in all three guidebooks. Among the historical landmarks with an established pedigree as tourist attractions included in the books is the Austerlitz battlefield near Brno where Napoleon defeated the Austrian and Russian armies in 1806.</p>




























<figure ><img loading="lazy" alt="Map of Czechoslovakia with gray dots" src="/dhqwords/vol/17/2/000679/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000679/resources/images/figure04_hu858abf3db99bbb183e88afbc52b96db4_1308104_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000679/resources/images/figure04_hu858abf3db99bbb183e88afbc52b96db4_1308104_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000679/resources/images/figure04_hu858abf3db99bbb183e88afbc52b96db4_1308104_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000679/resources/images/figure04_hu858abf3db99bbb183e88afbc52b96db4_1308104_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000679/resources/images/figure04_hu858abf3db99bbb183e88afbc52b96db4_1308104_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000679/resources/images/figure04.png 3098w" 
     class="landscape"
     ><figcaption>
        <p>Geolocated toponyms clusters (4 km) with toponyms from both Čedok 1928 and Nagel 1959 guidebook indexes
        </p>
    </figcaption>
</figure>
<p>To check for the continuities between the Czechoslovak guidebooks produced by the country’s national tourist organisation, we also mapped the toponyms clusters shared by these two guidebooks (Figure 4) using the same clustering method and radius as outline above. The map includes 290 clusters comprised of 680 unique, close-neighbouring positions. The map is largely identical to Figure 3, though it includes even more famous castles and chateux (e.g. Pernštejn, Kost, and Zvíkov), some of which had possibly been closed to the public or in poor condition around 1905. The shared clusters between 1928 and 1959 also contain some remotely located dwellings such as the small Moravian town of Kralice where the humanistic scholar Comenius worked on a famous bible translation in the seventeenth century. By 1959 a Kralice Bible Museum had opened, which the communist-era guidebook hastened to stress  “is also of great interest to laymen because many very beautiful impressions have been produced by the Kralice press”   <sup id="fnref2:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>.</p>




























<figure ><img loading="lazy" alt="Map of Czechoslovakia with blue dots" src="/dhqwords/vol/17/2/000679/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000679/resources/images/figure05_hu858abf3db99bbb183e88afbc52b96db4_1413442_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000679/resources/images/figure05_hu858abf3db99bbb183e88afbc52b96db4_1413442_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000679/resources/images/figure05_hu858abf3db99bbb183e88afbc52b96db4_1413442_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000679/resources/images/figure05_hu858abf3db99bbb183e88afbc52b96db4_1413442_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000679/resources/images/figure05_hu858abf3db99bbb183e88afbc52b96db4_1413442_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000679/resources/images/figure05.png 3098w" 
     class="landscape"
     ><figcaption>
        <p>Geolocated toponyms clusters (4 km) unique to the 1928 guidebook index
        </p>
    </figcaption>
</figure>
<p>We then mapped the clusters unique to 1928 and 1959 individually, thus identifying the attractions unique to each guidebook (Figures 5 and 6). Using the same clustering algorithm we eliminated clusters containing toponyms from both indexes so that the remaining points were attractions at least 4 km away from any attraction listed in the other guide. Figure 5 thus shows the 480 toponym clusters (636 positions) included in the 1928 guidebook but not present in the 1959 guidebooks. The figure confirms the observation that the 1928 guidebook contained many more references to attractions along the western borders and a heavier emphasis on Bohemia. In comparison, the attractions unique to the 1959 guidebook (Figure 6) are overwhelmingly located in Slovakia, especially around Komárno on the border to Hungary and in the mountains of Central Slovakia. The Moravian Karst north of Brno and the Haná region around Olomouc where the Javoříčské caves were discovered in 1938 also contains toponym clusters unique to the 1959 guidebook. Other unique toponyms represent recently constructed dams and the new recreational areas that had sprung up in their vicinity (e.g. Brno and Slapy).</p>




























<figure ><img loading="lazy" alt="Map of Czechoslovakia with red dots" src="/dhqwords/vol/17/2/000679/resources/images/figure06.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000679/resources/images/figure06_hu4533c2636be143abc739be1662bbbd6e_1259382_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000679/resources/images/figure06_hu4533c2636be143abc739be1662bbbd6e_1259382_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000679/resources/images/figure06_hu4533c2636be143abc739be1662bbbd6e_1259382_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000679/resources/images/figure06_hu4533c2636be143abc739be1662bbbd6e_1259382_1500x0_resize_box_3.png 1500w,/dhqwords/vol/17/2/000679/resources/images/figure06_hu4533c2636be143abc739be1662bbbd6e_1259382_1800x0_resize_box_3.png 1800w,/dhqwords/vol/17/2/000679/resources/images/figure06.png 3098w" 
     class="landscape"
     ><figcaption>
        <p>Geolocated toponyms clusters (4 km) unique to the 1959 guidebook index
        </p>
    </figcaption>
</figure>
<p>Returning to the question of the relation between politics and tourism, we can thus conclude based on the toponym distribution maps that the 1959 Čedok editors departed from their predecessors’ emphasis on Bohemia to present a more balanced picture of Czechoslovakia. Otherwise, the result of this distant reading of guidebooks points to the continuity. With a 4 km clustering radius, the communist-era guidebook contains 290 clusters shared with the interwar guidebook and 173 unique clusters (193 positions). A closer look at the unique clusters show that many of them contain attractions unconnected with the Czechoslovak railroad network. The editor of the 1928 guidebook had deliberately organized the text in accordance with the railways, which explains why these harder-to-reach attractions feature exclusively in the 1959 guidebook. As Felix Jeschke writes about editor Jiří Král’s selection criteria,  “the railways were the network that made the country accessible, offering a pre-ordered system of routes. Places not served by the railway were not presented as destinations and had to be sought out by intrepid travellers themselves.”   <sup id="fnref1:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> Examples of such attractions added to the 1959 edition include the medieval castle of Smolenice, the baroque castle at Milotice, the excavation of fossilised trilobites at Skryje, the remote Slovak hunting grounds at Remetské Hámre, and the small wooden churches built in Byzantine style near Svidník. The addition of sights like these support our argument that the 1959 guidebook presented a country rich in romantic attractions dating back centuries.</p>
<p>Further scrutiny of the guidebook text substantiates our claim that the 1959 guidebook emphasized the country’s inherent appeal to tourists attracted by nature and historical architecture:  “The very many natural beauties of Czechoslovakia make the country a tourist’s paradise”   <sup id="fnref3:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. The Czechoslovak landscape has a  “fresh and green appearance”   <sup id="fnref4:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>,  “Slovakia is a paradise for all mountain lovers”   <sup id="fnref5:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>, and the numerous mineral springs are  “of world-wide reputation”   <sup id="fnref6:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. As we have already shown, the country’s numerous castles and chateaux featured prominently. Pernštejn is  “one of the most valuable architectural monuments”   <sup id="fnref7:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. Karlštejn is  “out of a fairy story”   <sup id="fnref8:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> and Konopiště was  “sumptuously rebuilt”   <sup id="fnref9:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. Readers had to look carefully to find tourist sites more explicitly related to contemporary politics or the history of communism. For instance, the Slovak National Uprising against the German occupants and their fascist collaborationists in August 1944 is relegated to a historical sidenote in small print in the section on Banská Bystrica, the city where the uprising took place. The museum dedicated to this event of considerable importance to the party’s self-understanding <sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup> is only mentioned after two sizeable paragraphs about renaissance  “burgher houses”  and  “the old castle buildings”   <sup id="fnref10:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. The scalable reading of the 1959 guidebook produced by communist Czechoslovakia’s National Tourist Organization thus demonstrates the continuity with the interwar branding of the country’s many tourist sights.</p>
<h2 id="conclusions">Conclusions</h2>
<p>In her work on heritage management in communist Czechoslovakia, Cathleen Giustino <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup> has shown how an ideological ambiguity was at play in the country’s castles and chateaux. After the Second World War, dozens of former aristocratic residences were confiscated and turned into state-owned museums, which became popular sites of domestic tourism. And as party loyalists often noted, the sites lacked clearly encoded ideological messages. The translation of communist cultural policy into heritage management and tourist site administration did not result in a simple eradication of the aristocratic material culture. Communist leaders had more pressing concerns than exhibition design at backwater tourist sites, leaving art historians and tour guides some discretion to promote their site’s high-cultural attractions. Our scalable reading of the 1959 guidebook suggests that its editors also had the liberty to steer clear of awkward ideological messages that could rub western readers the wrong way. Instead, the book appears tailored to the educated and historically interested international audience. Returning to the guidebook author’s dilemma recounted in the US embassy cable, our analysis shows that the editors eventually opted for continuity, including many of the attractions already mentioned in the 1905 and 1928 guidebooks. This tendency can be traced back to stylish photo books published by Artia, the state publishing house, since 1953, showcasing the beauties of Prague, as well as castles and chateaux, interspersed with images of socialist society <sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>. Books like these were sold at the Brussels Expo in 1958 where the Czechoslovak pavilion also introduced visitors to historic monuments with photos of castles and chateaux, hoping that it would attract foreign tourists to Czechoslovakia <sup id="fnref1:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>.<sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>  This hope, however, remained frustrated for a few more years. It was only by the mid-1960s that Western tourists started to arrive in Czechoslovakia in significant numbers and not until 1978 did the total number of visitors from non-socialist countries exceed one million <sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup>. Still, the attempts to normalize the image of communist Czechoslovakia in the West and reassert its status as a worthy destination of international tourism began already in the 1950s. By building on the legacy of romantic attractions established in the nineteenth century, Čedok tailored the guidebook to western audiences and showcased the entire country as ready for consumption by foreign visitors.</p>
<p>There is an important distinction to be made between cold war tourism and tourism in the Cold War as Christian Noack and Sune Bechmann Pedersen have argued. While the Cold War was at the centre of the first form of tourism, it was a contextual chronological marker in the second <sup id="fnref1:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>. The visualization of toponyms presented in this article allows for a distant reading of tourist attractions in Czechoslovakia and illustrates the symbolic continuity with the pre-war era, undisturbed by the Cold War, which our close reading also supported. Naturally, this was only symbolic. It goes without mentioning that the experiences of western tourists on the ground differed greatly from those of the interwar period, and that other sources than guidebooks are needed for research into this matter. Still, our scalable reading reveals the symbolic attempt by Czechoslovak authorities to normalize tourist relations across the Iron Curtain and re-integrate communist Czechoslovakia in the international tourist industry by perpetuating a pre-socialist tourist legacy. Our study has thus shown the efficacy of analysing travel guides with HGIS and pointed out a promising new methodological avenue for the field of tourism history. To enable similar research for other areas or travel guides, we have made CITADEL publicly available and prepared to be set-up for any combination of countries and languages.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>This work was supported by Erik Philip Sörensens stiftelse (grant no. H2019-039) and conducted at the DigitalHistory@Lund research platform, Media History, Department of Communication and Media, Lund University</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Parsons, Nicholas. (2007).  <em>Worth the detour: A history of the guidebook</em> , Stroud: Sutton.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Buzard, James. (1993)  <em>The Beaten track: European tourism, literature, and the ways to culture, 1800–1918</em> , Oxford: OUP.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Koshar, Rudy. (2000).  <em>German travel cultures</em> , Oxford: Berg.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Antons, Jan-Hinnerk. (2021)  “Historisch-Geografische Informationssysteme (HGIS) in der Tourismusgeschichte: Transnationale Besucherströme des Ostseetourismus im 19. Jahrhundert,”    <em>Zeitschrift für Ostmitteleuropa-Forschung,</em>  70(3), pp. 357–388. Available at: <a href="https://doi.org/10.25627/202170311016">https://doi.org/10.25627/202170311016</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Anderson, Carrie et al. (2017)  “Digital humanities and tourism history” ,  <em>Journal of Tourism History,</em>  9(2-3), pp. 246–269. Available at: <a href="https://doi.org/10.1080/1755182X.2017.1419455">https://doi.org/10.1080/1755182X.2017.1419455</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Czeitschner, Ulrike and Krautgartner, Barbara. (2017)  “Discursive constructions of culture: Semantic modelling for historical travel guides,”    <em>Sociology and Anthropology</em> , 5(4), pp. 323–331. Available at: <a href="https://doi.org/10.13189/sa.2017.050406">https://doi.org/10.13189/sa.2017.050406</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Meeks, Elijah and Grossner, Karl. (2012)  “ORBIS: An interactive scholarly work on the Roman world,”    <em>Journal of Digital Humanities</em> , 1(3), pp. 1–3. Available at: <a href="http://journalofdigitalhumanities.org/1%E2%80%903/orbis%E2%80%90an%E2%80%90interactive%E2%80%90scholarly%E2%80%90work%E2%80%90on%E2%80%90the%E2%80%90roman%E2%80%90world%E2%80%90by%E2%80%90elijah%E2%80%90meeks%E2%80%90and%E2%80%90karl%E2%80%90grossner">http://journalofdigitalhumanities.org/1‐3/orbis‐an‐interactive‐scholarly‐work‐on‐the‐roman‐world‐by‐elijah‐meeks‐and‐karl‐grossner</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Foka, Anna et al. (2021)  “Mapping ancient heritage narratives with digital tools”  in: Champion, Erik Malcolm (ed.)  <em>Virtual Heritage: A Guide.</em>  London: Ubiquity Press, pp. 55–66. Available at: <a href="https://doi.org/10.5334/bck">https://doi.org/10.5334/bck</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Fickers, Andreas and Clavert, Frédéric. (2021)  “On pyramids, prisms, and scalable reading,”    <em>Journal of Digital History,</em>  1(1), pp. 1–13. Available at: <a href="https://doi.org/10.1515/jdh-2021-1008">https://doi.org/10.1515/jdh-2021-1008</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Knowles, Anne. (2014)  “The contested nature of historical GIS,”    <em>International Journal of Geographical Information Science,</em>  28(1), pp. 206–211. Available at: <a href="https://doi.org/10.1080/13658816.2013.850696">https://doi.org/10.1080/13658816.2013.850696</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Martí-Henneberg, Jordi. (2011)  “Geographical Information Systems and the Study of History,”    <em>Journal of Interdisciplinary History</em> , 42(1), pp. 1–13. Available at: <a href="https://doi.org/10.1162/JINH_a_00202">https://doi.org/10.1162/JINH_a_00202</a> (Accessed: 14 December 2022).&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Blevins, Cameron. (2021)  <em>Paper trails: The US Post and the making of the American West</em> , New York: Oxford University Press.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Chyský, Jiří. (1959)  <em>Czechoslovakia</em> , Geneva: Nagel.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref10:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Král, Jiří. (1928).  <em>Guide to the Czechoslovak Republic</em> , Prague: Čedok.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Czech National Archives, Prague, Státní úřad plánovací II, f. 1177, vol. 471. Bulletin no. 2 (23 October 1957).&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Bechmann Pedersen, Sune. (2018)  “Eastbound tourism in the Cold War: The History of the Swedish Communist travel agency Folkturist,”    <em>Journal of Tourism History,</em>  10(2), pp. 130–145. Available at: <a href="https://doi.org/10.1080/1755182X.2018.1469679">https://doi.org/10.1080/1755182X.2018.1469679</a> (Accessed: 14 December 2022).&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Czech National Archives, Prague, Státní úřad plánovací II, f. 1177, vol. 468.  “Zpráva o rozvoji cestovního ruchu,”  appendix III (no date [1955]), p. 1.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Giustino, Cathleen M. (2012)  “Industrial design and the Czechoslovak pavilion at EXPO’58: Artistic autonomy, Party control and Cold War common ground,”    <em>Journal of Contemporary History,</em>  47(1), pp. 185–212. Available at: <a href="https://doi.org/10.1177/0022009411422371">https://doi.org/10.1177/0022009411422371</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Bechmann Pedersen, Sune. (2019)  “A Paradise behind the Curtain: Selling eastern escapes to Scandinavians”  in: Hoenig, Bianca and Wadle, Hannah (eds.)  <em>Eden für jeden? Touristische Sehnsuchtsorte in Mittel- und Osteuropa von 1945 bis zur Gegenwart.</em>  Göttingen: V&amp;R Unipress, pp. 227–249.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Jeschke, Felix. (2021)  <em>Iron landscapes: National space and the railways in interwar Czechoslovakia</em> , New York: Berghahn Books.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Štemberk, Jan. (2009).  <em>Fenomén cestovního ruchu: Možnosti a limity cestovního ruchu v meziválečném Československu</em> , Pelhřimov: Nová tiskárna Pelhřimov.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Mücke, Pavel. (2021)  “Hidden, yet visible workers of Czechoslovak international tourism: Macro and micro-historical views of ČEDOK’s branches abroad and tour guides during the period of late socialism (1968–1989),”    <em>Journal of Tourism History</em> , 13(1), pp. 75–94. Available at: <a href="https://doi.org/10.1080/1755182X.2020.1854353">https://doi.org/10.1080/1755182X.2020.1854353</a> (Accessed: 13 December 2022).&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Le Secrétariat-Général. (1926).  <em>Congrès International des Organisations Officielles de Propagande Touristique: Tenu à Prague du 27 juin au 5 juillet 1926</em> , The Hague.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>UNWTO archive, Madrid, International Union of Official Tourist Organizations, UIOOT 645. Letter by CEDOK president Grégr to IUOTO Secretary Morin (27 December 1956); Czech National Archives, Prague, Státní úřad plánovací II, f. 1177, vol. 472, CEDOK travel reports (1957–59).&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Archives Unbound,  “Czechoslovakia from Liberation to Communist State,”  1945–63: Records of the U.S. State Department Classified Files. 749.00. Embassy cable, American Embassy, Prague, to Department of State (27 August 1957).&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Heimann, Mary. (2009)  <em>Czechoslovakia: The State that failed</em> , New Haven: Yale University Press.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Král, Jiří. (1953).  <em>Kam na rekreaci v Praze a okolí</em> , Prague: Čedok.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Martínek, Jiří. (2008).  <em>Geografové v českých zemích, 1800–1945: biografický slovník</em> , Prague: Historický ústav.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>We are grateful to René Matlovič and Jiří Martínek for bringing the details about Král’s life to our attention.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Chyský, Čeněk. (1934)  <em>Průvodce Prahou</em> , Prague: Svaz československých dělnických turistů.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Chyský, Čeněk. (1948)  <em>Průvodce Prahou</em> , Prague: Knihkupectví Klubu českých turistů.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Lešanovský, Karel. (2009).  <em>Komunismus a skauti-komunisté</em> . Available at: <a href="https://s3.eu-central-1.amazonaws.com/uploads.mangoweb.org/shared-prod/skautskyinstitut.cz/uploads/2013/12/Komunismus_a_skauti-komuniste.pdf">https://s3.eu-central-1.amazonaws.com/uploads.mangoweb.org/shared-prod/skautskyinstitut.cz/uploads/2013/12/Komunismus_a_skauti-komuniste.pdf</a> (Accessed: 8 December 2022).&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Hais, Josef. (2008)  <em>Vývoj firmy ČEDOK v meziválečném období</em> . Diplomavá práce, Univerzita Karlova v Praze. Available at: <a href="https://dspace.cuni.cz/bitstream/handle/20.500.11956/19712/DPTX_2011_2_11210_0_165296_0_124671.pdf?sequence=1">https://dspace.cuni.cz/bitstream/handle/20.500.11956/19712/DPTX_2011_2_11210_0_165296_0_124671.pdf?sequence=1</a> (Accessed: 16 December 2022).&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<pre><code>_Moscou et Léningrad_ . (1956) Geneva: Nagel.   
</code></pre>
&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></li>
<li id="fn:35">
<p>Schreiber, Thomas. (1957).  <em>Hongrie</em> , Geneva: Nagel.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Czech National Archives, Prague, Státní úřad plánovací II, f. 1177, vol. 472. Travel report, Switzerland (25 September–2 October 1958).&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Graham, Shawn et al. (2022)  <em>Exploring big historical data: The Historian’s macroscope</em> , New Jersey: World Scientific.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Schaff, Barbara. (2022)  “Travel guides”  in: Zuelow, Eric and James, Kevin J. (eds.)  <em>The Oxford handbook of the history of tourism and travel</em> . Online ed. Oxford: Oxford University Press. Available at: <a href="https://doi.org/10.1093/oxfordhb/9780190889555.013.15">https://doi.org/10.1093/oxfordhb/9780190889555.013.15</a> (Accessed: 16 December 2022).&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>More precisely, we multiplied the page count by 4 of Prague, Brno, Olomouc, Ostrava, Bratislava, and Trnava (the cities with subentries in the 1959 guidebook). This produced approximate weights ranging from 2 (Trnava) to 100 (Prague), which is in line with the number of toponym subentries of the 1905 and 1959 guidebooks.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p><a href="https://www.geonames.org/">https://www.geonames.org/</a>. Last accessed 24 January 2022.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>Salvoldi, Daniele. (2017)  “A Historical Geographic Information System (HGIS) of Nubia based on the William J. Bankes archive (1815–1822),”    <em>Digital Humanities Quarterly</em> , 11(2). Available at: <a href="/dhqwords/vol/11/2/000294/">http://www.digitalhumanities.org/dhq/vol/11/2/000294/000294.html</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Horne, Ryan. (2020)  “Beyond lists: Digital gazetteers and digital history,”    <em>The Historian,</em>  82(1), pp. 37–50. Available at: <a href="https://doi.org/10.1080/00182370.2020.1725992">https://doi.org/10.1080/00182370.2020.1725992</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Levenshtein, Vladimir I. (1966)  “Binary codes capable of correcting deletions, insertions, and reversals,”    <em>Soviet Physics - Doklady,</em>  10(8), pp. 707–710. Available at: <a href="https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf">https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Navarro, Gonzalo. (2001)  “A guided tour to approximate string matching,”    <em>ACM computing surveys</em> , 33(1), pp. 31–88. Available at: <a href="https://dl.acm.org/doi/pdf/10.1145/375360.375365">https://dl.acm.org/doi/pdf/10.1145/375360.375365</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Cohen, William W., Ravikumar, Pradeep and Fienberg, Stephen E. (2003)  “A Comparison of string distance metrics for name-matching tasks”  in: Kambhampati, Subbarao and Knoblock, Craig A. (eds.)  <em>Proceedings of the 2003 International Conference on Information Integration on the Web.</em>  Acapulco: AAAI Press, pp. 73–78. Available at: <a href="https://dl.acm.org/doi/10.5555/3104278.3104293">https://dl.acm.org/doi/10.5555/3104278.3104293</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>Davis Jr., Clodoveu A. and De Salles, Emerson. (2007)  “Approximate string matching for geographic names and personal names”    <em>Proceedings of the Brazilian Symposium on GeoInformatics.</em>  São Paulo: INPE, pp. 49–60. Available at: <a href="http://mtc-m16c.sid.inpe.br/col/sid.inpe.br/mtc-m18/2014/12.09.17.09/doc/Approximate%20String%20Matching%20for%20Geographic%20Names%20and.pdf">http://mtc-m16c.sid.inpe.br/col/sid.inpe.br/mtc-m18/2014/12.09.17.09/doc/Approximate%20String%20Matching%20for%20Geographic%20Names%20and.pdf</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Recchia, Gabriel and Louwerse, Max. (2013)  “A Comparison of string similarity measures for toponym matching,”  in  <em>Proceedings of The First ACM SIGSPATIAL International Workshop on Computational Models of Place.</em>  New York: Association for Computing Machinery, pp. 54–61. Available at: <a href="https://doi.org/10.1145/2534848.2534850">https://doi.org/10.1145/2534848.2534850</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Hosseini, Kasra, Nanni, Federico and Ardanuy, Mariona Coll. (2020)  “DeezyMatch: A flexible deep learning approach to fuzzy string matching”    <em>Proceedings of the 2020 conference on empirical methods in natural language processing: System demonstrations</em> . Association for Computational Linguistics, pp. 62–69. Available at: <a href="https://doi.org/10.18653/v1/2020.emnlp-demos.9">https://doi.org/10.18653/v1/2020.emnlp-demos.9</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Kılınç, Deniz. (2016)  “An accurate toponym-matching measure based on approximate string matching,”    <em>Journal of Information Science,</em>  42(2), pp. 138–149. Available at: <a href="https://doi.org/10.1177/0165551515590097">https://doi.org/10.1177/0165551515590097</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Santos, Rui, Murrieta-Flores, Patricia and Martins, Bruno. (2018)  “Learning to combine multiple string similarity metrics for effective toponym matching,”    <em>International Journal of Digital Earth</em> , 11(9), pp. 913–938. Available at: <a href="https://doi.org/10.1080/17538947.2017.1371253">https://doi.org/10.1080/17538947.2017.1371253</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>For more details on CITADEL and its source code: <a href="https://github.com/MatJohaDH/citadel">https://github.com/MatJohaDH/citadel</a>&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>The dataset is published on Zenodo: <a href="https://doi.org/10.5281/zenodo.7418864">https://doi.org/10.5281/zenodo.7418864</a>&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Schvitz, Guy et al. (2022)  “Mapping the international system, 1886–2019: The CShapes 2.0 Dataset,”    <em>Journal of Conflict Resolution,</em>  66(1), pp. 144–161. Available at: <a href="https://doi.org/10.1177/00220027211013563">https://doi.org/10.1177/00220027211013563</a> (Accessed: 16 December 2022).&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Background layers were imported from <a href="https://www.eea.europa.eu/data-and-maps/data/digital-elevation-model-of-europe">https://www.eea.europa.eu/data-and-maps/data/digital-elevation-model-of-europe</a> and <a href="https://gisco-services.ec.europa.eu/distribution/v2/lau/download/">https://gisco-services.ec.europa.eu/distribution/v2/lau/download/#lau19</a> (accessed 12 September 2022).&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>The three maps have 20 as their shared maximum kernel density estimation and a radius of 20km. The colour scale has five gradients, each representing one fifth of the range, while the extremes are transparent (0) and black (&gt;20).&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Large, David Clay. (2015).  <em>The Grand spas of Central Europe: A History of intrigue, politics, art, and healing</em> , Lanham: Rowman &amp; Littlefield.&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>Bechmann Pedersen, Sune and Noack, Christian. (2019)  “Crossing the Iron Curtain: An Introduction”  in: Bechmann Pedersen, Sune and Noack, Christian (eds.)  <em>Tourism and travel during the Cold War: Negotiating tourist experiences across the Iron Curtain.</em>  Abingdon: Routledge, pp. 1–20. Available at: <a href="https://doi.org/10.4324/9780429201127">https://doi.org/10.4324/9780429201127</a>&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>J. H. R. (1931)  “Review of Wanderings in Czechoslovakia; Czechoslovakia: The Land and its people, by G. Druce &amp; C. Holland,”    <em>The Geographical Journal</em> , 77(4), pp. 371–372. Available at: <a href="https://doi.org/10.2307/1784295">https://doi.org/10.2307/1784295</a> (Accessed: 12 December 2022).&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Radonic, Ljiljana. (2014)  “Slovak and Croatian invocation of Europe: The Museum of the Slovak National Uprising and the Jasenovac Memorial Museum,”    <em>Nationalities Papers</em> , 42(3), pp. 489–507. Available at: <a href="https://doi.org/10.1080/00905992.2013.867935">https://doi.org/10.1080/00905992.2013.867935</a> (Accessed: 13 December 2022).&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Giustino, Cathleen M. (2013)  “Open gates and wandering minds: Codes, castles, and chateaux in socialist Czechoslovakia before 1960”  in: Giustino, Cathleen M., Plum, Catherine J. and Vari, Alexander (eds.)  <em>Socialist Escapes: Breaking Away from Ideology and Everyday Routine in Eastern Europe, 1945–1989.</em>  New York: Berghahn, pp. 48–72.&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Paulouš, J. A. (1953).  <em>Die schöne Tschechoslowakei</em> , Prague: Artia.&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>For additional details on the ambition to attract foreign tourists through the Brussels pavillion, see NA, SUP II, f. 1177, vol. 472,  “1958” . Zpráva o činnosti informačního střediska Čedoku v Bruselu v době Světové výstavy 1958.&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p>Franke, Antonín. (1984)  <em>Rukověť cestovního ruchu</em> , Prague: Merkur.&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Automatic Identification of Rhetorical Elements in classical Arabic Poetry</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000673/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000673/</id><author><name>Heyam Abd Alhadi</name></author><author><name>Ali Ahmad Hussein</name></author><author><name>Tsvi Kuflik</name></author><published>0001-01-01T00:00:00+00:00</published><updated>0001-01-01T00:00:00+00:00</updated><content type="html"><![CDATA[<h1 id="heading"></h1>
<h2 id="1-introduction">1. Introduction</h2>
<p>Rhetoric, balāgha in Arabic, is the art of persuasion as well as affectation through language. It is the means of conveying an idea in the most effective and convincing way, and with the most emotional impact <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In Arabic criticism, the term balāgha refers both to figures of speech (such as simile) and stylistic — including embellishing — elements (such as paronomasia) that are used by critics to analyse the aesthetic value of an artistic expression; mainly in classical Arabic poetry and the Qurʾān <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Since the ninth century CE, study of rhetoric has been stimulated by an increased interest in understanding the structure and development of poetry as well as by the need to rationalise the aesthetic implications of the theological postulate of the uniqueness (iʿjāz) of the Qurʾān <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Despite the great potential for study of rhetoric for so wide a range of research priorities both in and beyond itself, it remains lamentably neglected in modern research. Whereas there has been extensive research into Greek and mediaeval European rhetoric, there is nothing comparable for that of Arabic-Islamic texts, despite their high level of sophistication and their derivation from a major world civilisation. Among many factors which may explain this is the very large number of the rhetorical elements. In late rhetorical anthologies from the seventeenth-eighteenth century CE, their number is about one hundred and eighty. Identifying these elements in the thousands of classical Arabic poems that have been preserved from the pre-Islamic to the later Islamic periods, is a hard, if not impossible, mission. Tracing the development of rhetoric in this poetry is one way of understanding its development through ages. This is done by analysing their use in different poems during different periods, which is a lengthy and demanding undertaking far beyond a scope of a single study or researcher.</p>
<p>In order to make this feasible, our Arabic Rhetoric Identifier (known as the REI) had to be developed.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  The REI was created by a team led by A. Hussein and T. Kuflik. Its purpose is to enable researchers to annotate manually the rhetorical elements in Arabic poetry, and compile them into a database of rhetorical elements in classical Arabic poetry between the 5th and 16th centuries CE. The canon comprises 26,925 classical Arabic poems, only 75 of which have, to date, been manually analysed. The main challenges to researchers are the time-consuming nature of manual annotation and the high level of expertise required to identify and comprehend the properties of each element [see, for example, the elements in 7, 19, 20]. While automating this process is thus very necessary, it is also extremely challenging.</p>
<p>While there are many modern studies of rhetorical usage in non-Arabic literatures, there is a lacuna in the modern era in Arabic literature (see, for example, Western literature’s rich bibliography in comparison with its scarce listing for metaphor and metonymy in the  <em>Bibliography of Metaphor and Metonymy</em>   <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> ). Scholars of classical Arabic poetry agree that the differing use of rhetoric is the main reason for the development of Arabic poetry in its different periods [16; cf. chapters 1, 2]. Badīʿ — literally the new style (or the novel, original, extraordinary style) — was the term used by Arabic rhetoricians to describe the sophisticated use of some rhetorical elements in this poetry, a use which renders the literary text differently sophisticated and differently aesthetic. In short, scholars agree that rhetoric was used in pre- and early Islamic poetry (5th-8th centuries CE), although it was considered more important in the ʿAbbāsid era (750–1517 CE). The badīʿ is the major element which distinguishes ʿAbbāsid from pre-ʿAbbāsid poetry — although which figurative speeches in badīʿ style and how they were used to make this difference remains unresolved.</p>
<p>Despite the importance of badīʿ, studies which discuss it are few and incomplete (<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, cf. pp. 28-41):<br>
Most discuss badīʿ in separate and randomly chosen verses rather than in complete poems. Considering this style in complete poems gives a far more accurate picture of the nature of badīʿ in classical Arabic poetry.  Since the main hypothesis of modern research (and of classical scholars) is that badīʿ is more important in  <em>ʿAbbāsid</em>  than in the pre-Islamic era, modern studies focus on the badīʿ of this poetry in the later period.</p>
<p>As far as we know, there are no comparative studies that analyze the development of badīʿ from one period to another, other than those recently conducted by one author of this article <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>, and by Wolfhart Heinrichs in 1994 <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. Our approach is that the essence of badīʿ in classical Arabic periods, especially in ʿAbbāsid and pre-ʿAbbāsid times, cannot be described without identifying and analysing the rhetorical elements in complete poems. There are some 180 rhetorical elements described in classical books on rhetoric <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. The number of classical Arabic poems, from the pre-Islamic era until the most recent pre-modern period, is enormous, making manual rhetorical analysis for the entire corpus a mission impossible. For this reason, Hussein and Kuflik began developing a system that will automatically analyse several rhetorical elements in an existing corpus of some 26,000 poems<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>  (in development so access is currently restricted). This corpus includes poetry from pre-Islamic times to the Mamluk era, which ended early 16th century. All the poems were entered manually into the system by students of Arabic language and literature, according to printed versions of the poems. This article reports on the automatic analysis of 20 rhetorical elements. A manual analysis by A. Hussein of several poems in the present corpus showed these to be the main, recurrent rhetorical elements in the pre- and early Islamic period, including the ʿAbbāsid poetry in its first four centuries (that is, until the twelfth century CE). In addition, most of these elements (nos. 1, 2.3, 3.3, 10, 12, 14, 16, 17, 18, 19-20) are discussed in the first and oldest books on Arabic rhetoric, while the others (the rest of the 180 elements) appear only as later developments and feature in later rhetoric books. These were the two reasons for focusing on these elements in the present study.</p>
<p>The classical automation approach uses text-mining and machine-learning techniques to identify rhetorical elements in the text. This approach requires collecting a large set of examples for each rhetorical element, and training a machine-learning-based classifier to recognize them. As we did not have an annotated set of examples, our first task was finding a way for assembling a sufficient number of analyzed poems to train a classifier. Our proposal aims at automating this step by proposing a framework to identify individual rhetorical elements in classical Arabic poetry by combining natural language processing (NLP) techniques with a rule-based approach. This framework has been evaluated on a small set of Arabic poems, and results have been extremely encouraging.</p>
<p>The development of this automatic framework will make a vital contribution to the study of rhetoric in classical Arabic poetry. It will enable automatic recognition of the 20 selected rhetorical elements in a vastly larger corpus (26,925 poems) that cannot be handled manually. Analyzing the rhetoric in a corpus of this size will yield better understanding of the development of rhetoric in Arabic poetry from the pre-Islamic period to the 16th century CE.</p>
<p>It is nonetheless important to note that rule-based systems have their own limitations <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>, including the need for continuous maintenance and updating by experts – as demonstrated by this research. This is why we see it as an interim approach until sufficient sets of examples are available for training state-of-the-art machine learning algorithms for the task.</p>
<p>Another challenge is the imprecise nature of such systems. Not only do they tend to misclassify examples, they also miss relevant elements (false negatives) and suggest wrong elements (false positives). Even the current framework, which achieved, overall, extremely encouraging results, had widely differing success rates for different elements. There is more work to do to ensure a success rate closer to 100%.</p>
<p>This paper is structured as follows. Section 2, which follows this introductory section, gives background and reviews related work. Section 3 describes the features of classical Arabic poems. Our framework is delineated in Section 4, together with the NLP tools and resources used in its implementation. The dataset, experiments and results are described in Section 5, and Section 6 discusses the study’s implications and limitations. Conclusions and future work are considered in Section 7.</p>
<h2 id="2-background-and-related-work">2. Background and Related Work</h2>
<p>Over the years, considerable research efforts have been invested in developing methods and tools for NLP of Arabic. NLP of Arabic poetry, and, especially, identifying characteristics in this poetry, remain challenging.</p>
<p>Previous studies have focused on a range of aspects — morphology, morphological decomposition, morpho-syntactic analysis, sentiment analysis, semantic analysis and many others. One main research avenue is morphological analysis of Arabic texts, for which several tools exist. Among them are AlKhalil Morpho Sys 2 <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>, MADA <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>, MADA+TOKAN <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, MADAMIRA <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>, ASMA <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, MAGEAD <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>, BAMA <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>, SAMA <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>, SALMA <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>, Arabic Sentence-level <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> and ArSenL <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>.</p>
<p>Of these, AlKhalil2 <sup id="fnref1:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> is the most recent and seems to be the best. It is an Arabic morpho-syntactic analyzer with a large database, which it uses to segment and then analyze partially or totally vocalized Arabic words. For each, the resulting analysis is derived as a set of features — prefix, stem, type, pattern of word, root, part of speech (POS), lemma, pattern of lemma and suffix. It outperforms BAMA and SAMA, achieving coverage of over 99%, as well as performing better in identifying various features, including those determined in the word context: the lemma, the stem and the diacritized form. This, therefore, was the tool used in our study.</p>
<p>ArSenL <sup id="fnref1:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> is a large sentiment lexicon for Arabic, which uses different approaches linked to the English SentiWordnet (ESWN). It has 154,396 entries, each referring to a single Arabic word, and each consisting of eight fields — Arabic morphologic lemma (1), POS (2), positive sentiment score (3), negative sentiment score (4), confidence (5), Arabic WordNet (AWN) offset (6), sentiment WordNet offset (7), and AWN lemma (8). An example is:</p>
<h1 id="two-entries-in-arsenl-nil--not-in-language">Two entries in ArSenL. NIL = not in language</h1>
<pre tabindex="0"><code>&lt;imobiyriyAliy~_1; a;0;0.125;50; NIL;02746897; NIL zrAEap_1; n;0;0;100;100861982;00916464; ziraAoEap_n1AR
</code></pre><pre><code>Given its large lexicon, it was selected for our study.
</code></pre>
<p>Another tool that we used was the Arabic WordNet (AWN) (<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>, <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>, <sup id="fnref2:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>) based on WordNet <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>, which are, respectively, lexical resources in standard Arabic and English. The Arabic WordNet is a large lexical database, comprising nouns, verbs, adjectives and adverbs, grouped in sets of cognitive synonyms, each expressing a distinct concept <sup id="fnref1:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>.</p>
<p>Hussein conducted pioneering manual studies to learn the use of rhetorical elements in classical Arabic poetry. These studies are few in number and deal with a very small corpus. In <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>, he focuses on the use of a single rhetorical figure, the intellectual trope or majāz ῾aqlī (an important rhetorical element neglected in modern research) in one pre-Islamic wine poem. He explains in detail the idea of the majāz ῾aqlī, and discusses its semantic aspects in classical Arabic poetry, as shown in an incident concerning wine in a poem composed by Abū Dhu᾿ayb al-Hudhalī (d. ca. 648 CE). In another study <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>, he examines other rhetorical techniques and their use by Hudhalī poets in describing the element of wine. He suggests that rhetorical elements should be studied in as many classical Arabic poetry themes as possible. He also investigated <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> rhetorical texture in two traditional tripartite poems — one dating from the pre-Islamic period, composed by ʿAlqama l-Faḥl (d. ca. 603 CE), the other from the early ʿAbbāsid era, composed by Bashshār b. Burd (d. 784 CE). The two have the same structure, address the same themes and comprise virtually the same number of verses. A key question concerns the rhetorical figures each poet uses, which leads to a broader question: How different was the badīʿ (rhetorical) style in the poetry of the two eras, assuming that each poem is representative of its time?</p>
<p>Abuata and Al-Omari <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> adopt the same rule-based approach as us for computerized analysis of Arabic prosody. They introduce an algorithm to determine the correct metre for a given Arabic poem and to convert the poem into metric writing.</p>
<p>A new way of recognizing the characteristics of classical Arabic poetry is presented by <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. The authors focus on rhythm, which is considered the crown of this type of poetry. A stylistic study of Arab-American poetry <sup id="fnref1:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> attempts to analyze and describe the major features of this poetry, written by prominent Arab poets who immigrated to America during the 19th century. It examines their poetry according to linguistics, grammar, lexicon and rhetoric <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>.</p>
<p>A study of NLP for Arabic metaphors in <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> presents the challenges central to developing a computational NLP-based system for classical Arabic, Modern Standard Arabic and Dialect Arabic. It also highlights the main problems of translating Arabic metaphors into other languages.</p>
<p>This article proposes a method for supporting the study of rhetoric in Arabic literature. It demonstrates and evaluates an automatic rule-based framework for recognizing its 20 most important rhetorical elements, previously identified by experts in a time-consuming process. As we have seen, a wide variety of tools enables analysis of Arabic texts, and has paved the way for the present study — the first to examine automatic identification of rhetorical elements in classical Arabic poetry.</p>
<h2 id="3-features-of-classical-arabic-poems">3. Features of classical Arabic Poems</h2>
<p>Style is very much more salient than content in the historical development of the Arabic literary register, especially in classical Arabic poetry, where rhetoric is a primary feature. The development of rhetoric in literary texts, however, is significantly under-researched. Study of rhetoric and its development in practice are important not only for literary and critical studies, but also have considerable implications for our understanding of other fields of knowledge. The dense use of periphrasis in poems in one period, for example, followed by its relative displacement by simile in the next and by metaphor in the one after that may indicate and/or reflect cognitive-linguistic changes in Arab communities over time <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>.</p>
<p>Classical Arabic poetry is built of consecutive verses (lines in a poem), with each verse divided into two parts (hemistiches), the so-called ṣadr -صدر and ʿajuz-عجز, respectively. This is an example of a  <strong>verse</strong> :</p>
<h1 id="a-classical-arabic-verse">A classical Arabic verse</h1>
<blockquote>
</blockquote>
<p>ولا عيب فيهم غير أن سيوفهم - بهن فلول من قراع الكتائب</p>
<p>There is no fault in them, excepting that their swords have suffered dents in clashes with battalions</p>
<p>Of the 180 rhetorical elements in Arabic poetry <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, we focus on the 20 most frequently used. In the following, we bring brief definitions, sometimes with simple examples. Detailed definitions, including detailed examples, are found in the Appendix (9.1):</p>
<ol>
<li>Simile (تشبيه): comparing directly two objects; indicating that A is similar to B.  We have divided the following eight elements (nos. 2.1, 2.2, 2.3, 3.1, 3.2, 3.3, 4, 5) into four main groups(nos. 2–5), according to the identification method:  2. Repetition1 (تكرار1), comprising three minor elements:<br>
2.1. Repetition (تكرار): repeating the same word/s at least twice in the same verse while preserving the same meaning and the same grammatical structure and context (such as we are here; we are here).  2.2 Ploce (ترديد): repeating the same word at least twice in the same verse; having the same meaning, but with a different grammatical structure/context (such as we  <em>are here</em> ; they  <em>are here</em>   ).  2.3. Perfect Paronomasia/Perfect Pun; also Complete Paronomasia (جناس تامّ): Two words that are repeated in the same verse, each having a different meaning. The different meaning is a main difference between repetition and paronomasia.</li>
</ol>
<pre><code>3. Repetition2 (تكرار 2), comprising three minor elements: 
</code></pre>
<p>3.1. Extraction/Etymology (اشتقاق): Mentioning a personal name and another verb derived from this name — such as Ṣāliḥ (personal name) and ṣaluḥa (becoming good).  3.2. Semblance (مشاكلة): A word is used in a certain, actual (often non-metaphoric) sense; it is then repeated in another, non-actual (often metaphoric) sense within the same verse (such as we  ** <em>breathe</em> **  the fresh air outside; while you remain in your room  ** <em>breathing</em> **  the data from your books).  3.3. Free paronomasia (جناس مطلق): two words mentioned in the same verse, derived from the same root, or they look as if they have derived from the same root, and they have different meanings (such as fiḍḍa (silver) and faḍāʾ (space).</p>
<pre><code>4. Repetition3 (3تكرار), echoing the rhyme at the beginning of the line (رد الاعجاز على الصدور): the final word in a verse is repeated (with the same meaning or with different meanings; with the same form or in a derivative form) anywhere in the first hemistich of the same verse or as the first word in the second hemistich such as (A....//....A; or ..../A....A).  5. Repetition4, key words (كلمات مفتاح): a root that is repeated in more than one verse in the same poem.  6. Flowing (اطّراد): praising a person by noting the names of his father and grandfather/s. The word ibn (the son of) separates the names (A is  _the son of_  B  _the son of_  C....).  7. Afterthought/Retraction (رجوع): mentioning one thought, then negating it in the same verse (the abodes have not been changed through ages. Nay, I see that they have been totally demolished).  8. Catchword Verbal (تشابه الأطراف اللفظي): A verse opens with the same rhyming word which closed the previous verse ((1) A…. B; (2)B….C; (3)C….D).  9. Distribution Characters/Alliteration (توزيع) 
</code></pre>
<p>9.1. Distribution Characters/Alliteration 1 (توزيع 1): a single vowel or consonant is included in each word of a given verse.  9.2. Distribution Characters/Alliteration 2 (توزيع 2): a certain vowel or consonant is repeated in all or most words of an entire poem.</p>
<pre><code>10. Hemming (تصريع): the two hemistiches of a given verse end with the same rhyming letters.  11. Unraveling (توشيع): the verse ends with a general word in the dual form, followed by two single words that specify the two objects constituting this duality (I am suffering from  _two different situations: fear and hope_ ).  12. Counterchange (عكس, تبديل): two or more words appear in a certain order and are repeated in the same verse in reverse order (AB...BA).  13. Repartee (مراجعة): a conversation between different persons/objects in the same verse or in several verses in the same poem (He said.... I replied....).  14. Rhyming – in general – homoeoteleuton (سجع), dividing discourse into periods with similar-sounding last syllables. It is said to be: 
</code></pre>
<p>14.1. Congruent (مُوازَن): the verse includes several phrases; their final words agree in measure and rhyme.  14.2. Terminal (مُطَرَّف): as in 14.1, but with the final words agreeing in measure only.  14.3. Tucking (تشطير): each of the two hemistiches in a verse is divided into two phrases that share the same rhyming letters. The rhyming letters in the phrases of the second hemistich differ from those in the first (A..A // B..B).   14.4. Embroidery (ترصيع): each word in the first hemistich shares the same rhyming letter (and sometimes the same measure) with its equivalent word in the second hemistich (ABCD//ABCD).</p>
<pre><code>15. Verbal Congruence (مناسبة لفظيّة): the second hemistich includes a phrase that rhymes with an equivalent phrase in the first hemistich. The two phrases often open the two hemistiches.  16. Paronomasia/Pun (جناس), using or suggesting in a single verse words that differ in meaning but are phonetically and/or graphically alike or almost alike. 
</code></pre>
<p>16.1. Conjunct Paronomasia (جناس مركب - مَرْفُوّ): the paronomasia consists of two parts: a single word (the first part) and two words (the second part) which, when combined, are similar phonetically and graphically to the first part of the paronomasia (amradā (beardless) and am radā (or a death?).  16.2. Tipped Paronomasia (جناس ناقص - مُطَرَّف): one of the matching words of the paronomasia is longer than the other with at least one initial consonant (badā  appear and abadā  ever).  16.3. Tailed Paronomasia (جناس ناقص - مُذيَّل): one of the matching words of the paronomasia is longer than the other with at least one ending consonant (qanā  lances and qabābil  squadrons of horses).  16.4. Consonantal/Distorted Paronomasia (جناس محرف): the two matching words differ only in their vocalisation (and of course their meaning) (ʿabra  a tear and ʿibra  a lesson).  16.5. Substitutive or Variant Paronomasia (جناس التصريف): the two matching words have a single differing consonant (ilḥāḥ  insistence and ilḥāf  importuning).  16.6. Metathetic/Reverse Paronomasia (جناس مقلوب): all or some of the letters of one of the two matching words is in reverse order (sāqin  cup-bearer and qāsin  cruel).   16.7. Graphic Paronomasia (جناس تصحيف): The two matching words, when written, are shaped alike, differing only in their dots which, in the Arabic script, differentiates some letters from others (ḥabs حَبس  to restrain and jins جِنس  type).</p>
<pre><code>17. Negative Antithesis (طباق سلب): a word is introduced and then negated with a negation particle (A and not A (I know and I do not know)).  18. Positive Antithesis (طباق إيجاب): two different words that have contrary meanings (new and old).  19. The Satirist’s Feint (تأكيد الذّم بما يشبه المدح): Criticising an attribute in an individual, then exempting this by alluding that a positive attribute will be noted. The poet, however, disappoints expectations by referring to another negative feature rather than a positive (he has no good attribute,  _except of_  being the worst person in universe).  20. The Encomiast’s Feint (تأكيد المدح بما يشبه الذّم): praising an attribute in an individual, then exempting this, alluding that a negative attribute will follow. Here too, expectation is disappointed with another positive feature, instead of the expected negative (they have no fault, except their swords which they broke on the heads of their enemies).  
</code></pre>
<h2 id="4-tools-and-methods">4. Tools and Methods</h2>
<p>For the purpose of the study, a dataset of annotated poems was built. A set of 20 rhetorical elements was selected and the poems were annotated accordingly. The individual properties of each rhetorical element must be understood to create an automatic process that will recognize them. This identification requires different kinds of resources and techniques. Some features can be detected by applying one-to-one string-matching procedures, others by using Arabic morpho-syntactic analysis to tease out the ingredients of each word (e.g., root, stem), others still with sentimental analysis, which requires resources such as sentiment lexicons.</p>
<p>Working with only a small number of annotated poems, we were unable to use any classical machine-learning technique to identify these elements automatically, so our approach was rule-based.</p>
<p>A prototype of a rule-based system was built for automatic identification of these elements. The dataset, tools and methods are now described.</p>
<h2 id="i-poems-dataset">i. Poems Dataset</h2>
<p>Over the years, we collected a repository of classical Arabic poetry<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>  comprising 26,925 poems by 675 different poets. It includes pre-Islamic poetry, written before 622 CE; work by poets who lived in the pre-Islamic and early Islamic periods, known as mukhaḍrams; that of poets who lived in the Umayyad era (661-750 CE); and of Abbasid poets who lived after 750 CE. For the purpose of this study, 75 poems, composed according to the classical Arabic meters called the Khalīlian meters, and comprising an average 27 verses each, were collected and manually analyzed to identify their rhetorical elements. The poems were chosen to cover two main periods: the Abbasid (between the 8th and 10th centuries CE) and pre-Abbasid eras (poets who lived between the 6th and 8th centuries CE). The poems of the first period are often shorter than those of the second, and therefore their number is greater: 48 poems in comparison with 29 from the first era (five pre-Islamic poems, seven poems which were composed by poets who lived in pre-Islamic times, but whose lifetimes extended into the early Islamic [mukhaḍrams poets], and 17 poems from the Umayyad era). The number of verses in the poems in the two main eras is, however, to some degree balanced. It comprises 887 verses from the Abbasid period and 752 from the pre-Abbassid (140 pre-Islamic verses, 232 mukhaḍrams, and 380 Umayyad).</p>
<p>From these poems, 20 different rhetorical elements were selected and manually annotated. (See Appendix 9.3 for the exact number of examples in each dataset.)</p>
<h2 id="ii-nlp-tools-and-data-sources">ii. NLP Tools and Data Sources</h2>
<p>This subsection describes the NLP tools and data sources, and the techniques applied in the framework.</p>
<pre><code> _AlKhalil2_ , The AlKhalil2 [^boudchicheetal2017] was chosen because of its large database and because it is a morpho-syntactic analyzer of standard Arabic words out of context. The system analyses either partially or totally vowelized words. We used their morphological features, including prefix, stem and type of word, all of which are very useful in identifying most of the rhetorical elements. It is important to note, however, that AlKhalil2 was designed for modern Arabic whereas the classical Arabic poetry with which we worked differs from modern Arabic. As a first step, we report on evaluating it on our corpus and then discuss its implications.     _ArSenL Sentiment Lexicon_ , The ArSenL [^badaroetal2014] was selected for its large sentiment lexicon (154,396 entries). They comprise the eight fields shown in our background section — positive sentiment score (3), negative sentiment score (4) and AWN lemma (8). When the AWN lemma includes NIL (i.e., not in language), we interpreted the morphological word in the first field according to the Buckwalter Arabic Morphological Analyzer [^buckwalter2002b] to retrieve the Arabic word-form. Where the field AWN lemma included a valid offset (i.e., not NIL), we retrieved the Arabic word from AWN [^alkhatib2003]. The final step was calculating the objective score of each word, which is the sum of the fields of positive and negative sentiment scores. It should be noted that most words scored neutral.     _Arabic WordNet_ . We used the AWN source code to retrieve Arabic words from sentiment lexicons (described below).     _Buckwalter Arabic Morphological Analyzer_   [^buckwalter2002b] helped build a sentiment lexicon (tool 2), because entries in ArSenL [^badaroetal2014] contain fields that include NIL. This tool was used to convert Morphologic Arabic words to Arabic words (e.g., &lt;imobiyriyAliy~ to إمبيريالي).     _Arabic Sentiment Lexicon_ . We developed an Arabic sentiment lexicon, comprising 8,765 positive words and 9,813 negative words, in three phases. The first phase involved automatically retrieving Arabic words and their sentimental polarities from ArSenL [^badaroetal2014], using the Buckwalter Arabic Morphological Analyzer [^buckwalter2002b] and AWN [^elkatebetal2006]. The second phase manually retrieved Arabic words and their polarities from another lexicon [^elsahar_elbeltagy2015], and the final phase was manually enriching the lexicon with Arabic words and their polarities from the internet.[^5]        _Arabic Sentiment Analyser_ . We developed a word polarity-based Arabic Sentiment Analyzer using the lexicon described above (see Figure 7). 
</code></pre>
<ul>
<li>
<p>Step 1 was building a lexicon of sentiment words. It comprised two text files — the first file consisting of positive words, the second of negative. In addition, we manually created a text file of negative words.</p>
</li>
<li>
<p>Step 2 was building an Arabic Sentiment Analyzer based on polarity. Text verses were inputted, each verse devoted to one word in all its possible forms. (All words in each verse appear without diacritics because the lexicon includes words without diacritics.) The analyzer checks each word in the verses. Should it appear in one of the lexicons, its polarity value is set according to that lexicon. If, however, there is a negation particle before the word (in Arabic, they are mainly بلى, ليس, لكن,لم، لا، لن), its polarity is assigned the opposite value of the lexicon. The analyzer then calculates the final sentiment of the input: if the number of positive words is greater than that of negative words, the analyzer returns a value of 1; if negative words comprise the greater number, it returns -1; where they are equal, it returns 0 (i.e., neutral). This serves to identify the Satirist’s and Encomiast’s Feints (see Figure 6).</p>
<pre><code>_Arabic Lexicon for Antithesis_ . We developed an Arabic lexicon for words with contradictory meanings. It comprises 453 pairs of opposites, compiled in two stages. First was retrieving English words and their opposites from the internet ([^englischhilfen]  [^perfectyourenglish2019]), and using the AWN Browser 2.0.1 to get their Arabic opposites and synonyms. Second was manually enriching these opposites with Arabic words and their synonyms [^aljahiz2019].     _Graphical User Interface (GUI)_  (see Figures [2](#figure02) and [4](#figure04)).  
</code></pre>
</li>
</ul>
<h2 id="iii-rhetoric-elements-identification-framework-and-prototype">iii. Rhetoric Elements Identification Framework and Prototype</h2>
<p>We created a user-friendly system that integrates the NLP tools described above with a rule-based elements identification mechanism for automatic identification of rhetorical elements. The GUI and the algorithms are from NetBeans IDE 8.0.1 using Java platform JDK 1.8. The source codes of the first six tools were also implemented in Java. Figure 1 presents the abstract process of rhetorical element identification on a complete poem, line by line, while Figures 1 &amp; 5 show the process of identifying a rhetorical element. Figure 1 shows the overall abstract process of line by line analysis while Figure 5 shows an example of identifying one specific rhetorical element – Simile (as there are different implementations for different rules).</p>




























<figure ><img loading="lazy" alt="Flowchart of steps in poem breakdown" src="/dhqwords/vol/17/2/000673/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000673/resources/images/figure01_hubbf8eb9965abf1bf187bc2d4f7e097f3_37866_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000673/resources/images/figure01_hubbf8eb9965abf1bf187bc2d4f7e097f3_37866_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000673/resources/images/figure01.png 564w" 
     class="portrait"
     ><figcaption>
        <p>Abstract framework for rhetorical element identification. The process starts with selecting a poem and a rhetorical element. The system analyses the poem line by line to identify the rhetorical element.
        </p>
    </figcaption>
</figure>
<p>The  <em>Graphic User Interface</em>  (GUI) for identifying rhetorical elements is shown in <a href="#figure02">Figure 2</a>. The process is as follows (see <a href="#figure03">Figure 3</a>):<br>
Activate the system (1), and select a poem (2).  Select a rhetorical element from the 20 in the GUI.  Run the tools to identify the selected element for each verse. If more than one element is chosen, repeat the process for each  The color-coded results are visualized (3).</p>




























<figure ><img loading="lazy" alt="Dashboard of the Graphic User Interface, showing menu options." src="/dhqwords/vol/17/2/000673/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000673/resources/images/figure02_hu36aea101c36d7acb1a5cfed2fe93f2ff_90165_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000673/resources/images/figure02_hu36aea101c36d7acb1a5cfed2fe93f2ff_90165_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000673/resources/images/figure02_hu36aea101c36d7acb1a5cfed2fe93f2ff_90165_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000673/resources/images/figure02.png 1366w" 
     class="landscape"
     ><figcaption>
        <p>The main Graphic User Interface (GUI). The selected poem is on the left. Each button on the right is responsible for identifying a rhetorical element, color-matched to the poem’s text.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Flowchart showing annotation workflow" src="/dhqwords/vol/17/2/000673/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000673/resources/images/figure03_hu9ac2464004cacaa9a8d52ff725e5e54a_77880_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000673/resources/images/figure03_hu9ac2464004cacaa9a8d52ff725e5e54a_77880_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000673/resources/images/figure03.png 513w" 
     class="landscape"
     ><figcaption>
        <p>Illustration of the automatic annotation framework — from when the user initiates the process (1) to the desired result (3).
        </p>
    </figcaption>
</figure>
<p>We also created a GUI for the Arabic Sentiment Lexicon Tool, enabling building of the lexicon and interpreting the morphology of words (<a href="#figure04">Figure 4</a>).<br>




























<figure ><img loading="lazy" alt="Pop-up window labeled “Arabic Sentiment Lexicon is Based On: ArSenL_v1.0A.txt”" src="/dhqwords/vol/17/2/000673/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000673/resources/images/figure04_hu667329eca926f3b554ba168f0b367a95_4772_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000673/resources/images/figure04_hu667329eca926f3b554ba168f0b367a95_4772_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000673/resources/images/figure04.png 480w" 
     class="landscape"
     ><figcaption>
        <p>GUI for building the lexicon user file and interpreting the morphology of words.
        </p>
    </figcaption>
</figure></p>




























<figure ><img loading="lazy" alt="Flowchart of decision tree" src="/dhqwords/vol/17/2/000673/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000673/resources/images/figure05_hu4e9da0a5b582d3f0e2195c7719dc99b5_97520_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000673/resources/images/figure05_hu4e9da0a5b582d3f0e2195c7719dc99b5_97520_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000673/resources/images/figure05.png 943w" 
     class="portrait"
     ><figcaption>
        <p>Rhetorical element identification process example: Simile. The process is repeated for each word in a line, following a set of conditions that refer to the start of the word or whether it is one of a set of predefined words. If needed AlKhalil is consulted for morphological analysis and the results are further checked.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Flowchart" src="/dhqwords/vol/17/2/000673/resources/images/figure06.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000673/resources/images/figure06_hue860506cb1c1a8ced4983eb02da0f130_85177_500x0_resize_q75_box.jpg 500w,
    /dhqwords/vol/17/2/000673/resources/images/figure06_hue860506cb1c1a8ced4983eb02da0f130_85177_800x0_resize_q75_box.jpg 800w,/dhqwords/vol/17/2/000673/resources/images/figure06_hue860506cb1c1a8ced4983eb02da0f130_85177_1200x0_resize_q75_box.jpg 1200w,/dhqwords/vol/17/2/000673/resources/images/figure06.jpg 1224w" 
     class="portrait"
     ><figcaption>
        <p>Rhetorical element identifying process example, Satirist’s Feint and Encomiast’s Feint: The process starts with checking the sentiments of the ṣadr and ʿajuz, word by word, and then combining the results.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Flowchart" src="/dhqwords/vol/17/2/000673/resources/images/figure07.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000673/resources/images/figure07_hud36459917e0d08f81964114459f2f651_51297_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000673/resources/images/figure07_hud36459917e0d08f81964114459f2f651_51297_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000673/resources/images/figure07.png 674w" 
     class="portrait"
     ><figcaption>
        <p>Identifying a words’ sentiment.
        </p>
    </figcaption>
</figure>
<p>Another essential component enabled us to identify the emotions expressed by words (<a href="#figure07">Figure 7</a>), and, when needed, to calculate the overall emotion expressed by a complete line (<a href="#figure06">Figure 6</a>).</p>
<h2 id="iv-identifying-rhetorical-elements-rules">iv. Identifying Rhetorical Elements (Rules)</h2>
<p>The individual properties of each rhetorical element must be understood to create an automatic process capable of recognizing them. This identification requires different kinds of resources and techniques. Some features can be detected by applying one-to-one string-matching procedures, others by using Arabic morpho-syntactic analysis to tease out the ingredients of each word (e.g., root, stem), others still with sentimental analysis, which requires resources such as sentiment lexicons. Next, we describe the rules we applied to identifying each rhetorical element, how we applied them, and the tools we used.</p>
<ol>
<li><em>Simile</em>  (تشبيه). This can appear with and without word tokens. The latter is not included in our system. This rhetorical element is identified in two steps. The first identifies it by full word tokens in one of four groups (see also <a href="#figure05">Figure 5</a>):<br>
1.1. Words starting with the tokens مثل, فمثل, ومثل ,كالـ for which the system searches.  1.2. Words starting with the simile tokens كأن, فكأن ,وكأن. Each word is analyzed using the AlKhalil2 <sup id="fnref2:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> tool. If the type of the word is a حرف مشبّه بالفعل (particle that resembles the verb; a group of particles including إن – أن / كأن – لكن / ليت – لعل) and the word is one of the three tokens mentioned above, it is considered a simile.  1.3. All word tokens كما, كأنما, وكما, فكما, وكأنما فكأنما. The system searches for whole tokens. For each, vocalization (تشكيل) is removed, and it is then checked as to whether it is equal to one of the tokens. Where a match is found, it is a simile.  1.4. Verb tokens ظن, خال, حسب, شبه are analyzed using the AlKhalil2 <sup id="fnref3:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> tool to retrieve type and root. If its type is a verb and its root is equal to one of the tokens, it is a simile.</li>
</ol>
<p>The second step is identifying similes by the letter k- كـ. Each word is analyzed using AlKhalil2 <sup id="fnref4:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> to check whether it is a prefix. If the prefix is equal to كَ: حرف التشبيه, it is a Simile.   2.  <em>Repetition 1-4</em>  (تكرار). These rhetorical elements are identified by two tests. The first is when two identical words appear in the same verse. This is Repetition. The second is finding the same stem in more than one word, with different predefined prefixes. We exclude words of the following types: { حرف جر- preposition, حرف نداء – interjections, حرف عطف – copulative particle, and particles that indicate حرف نصب – accusative, حرف نفي – negation, حرف جزاء – compensation, حرف عطف – disjunctive, and حرف جزم – apocopative, أداة شرط - conditional particle}. Such particles are frequently repeated in poetry and are not, therefore, considered part of the text’s rhetorical texture. To exclude these words, we analyze every word in the verse using AlKhalil2 <sup id="fnref5:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> to determine its type. Where the type matches one of those mentioned above, the word is excluded. These tests also eliminate words used in the flowing  rhetorical element no. 6 identifications. To identify Repetition1-4-type (see Appendix 1) rhetorical elements, contextual association is also needed — for example, Semblance (مشاكله). At this point, however, it is sufficient to recognise repetition of the same word without reference to context.  3. The  <em>Flowing</em>  (اطراد) is when the word بن appears at least twice in the same verse.  4.  <em>Afterthought/Retraction</em>  (رجوع) is when the first word in the second part of the verse matches one of the predefined negation words — وما - and it is not, بلى - yes, it is!, وغير – but it is.  5.  <em>Catchword Verbal</em>  (تشابه الاطراف اللفظي) is when the last word in a verse reappears as the first word of the following verse.  6.  <em>Distribution Characters/Alliteration</em>  (توزيع). Type 1 is when the same consonant appears in all or almost of all words of a given verse. Type 2 is when the same consonant appears in all or most of the verses in the poem. The vowels ا, و, ي are ignored.  7.  <em>Hemming</em>  (تصريع) compares two-word suffixes — the last word in the first and second parts of the verse.  8.  <em>Unraveling</em>  (توشيع) is when the verse ends with a phrase containing a noun in dual form (مثنى), followed by two singular nouns connected with the particles wa or fa (and). Each word in the second part of the verse is analyzed with AlKhalil2 <sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> to check whether it is dual form.  9.  <em>Counterchange</em>  (عكس وتبديل) is when two sentences are composed of the same words, but in reverse order.  10.  <em>Repartee</em>  (مراجعة) is when two consecutive verses contain a reported conversation. The system finds this by searching for the word said and its derivatives.  11.  <em>Rhyming – in general – homoeoteleuton</em>  (سجع) is when the concluding syllables (the end of two parts) in two sentences within the same verse end with the same consonants. Where they sound similar, it is a sajʿ.   12.  <em>Verbal Congruence</em>  (مناسبة لفظيّة) is when the first and second parts of the poem contain individual words in the same locations that resemble one another, either in terms of their suffix (their final letter) or in their metrical pattern, or in both.  13.  <em>Paronomasia</em>  (جناس) comprises seven types that are identified in two phases. First, the prefixes and suffixes of each word are removed, and then the letter, vocalization and type of word-pair are examined.  14.  <em>Negative Antithesis</em>  (طباق سلب) is when two words (the same words or words that are derived from the same root) are repeated, and a negation particle precedes one of them.  15.  <em>Positive Antithesis</em>  (طباق إيجاب) is identified using our  <em>Arabic Lexicon of Opposites</em> , which lists words and their opposites. It searches for words and their opposites within the same verse.  The following two rhetorical elements are based on sentiment analysis. To identify them, we used an  <em>Arabic Sentiment Analyser</em> .  16.  <em>The Satirist’s Feint</em>  (تأكيد المدح بما يشبه الذّم) searches each verse for predefined terms — , ان ريغ , أن ريغ ان ىوس , أن ىوس , أن لاإ ,. Where found, the sentiment values of the words that precede and follow the term are calculated separately. When both values are positive, it is a Satirist’s Feint.  17.  <em>The Encomiast’s Feint</em>  (تأكيد الذّم بما يشبه المدح) is calculated as above. When both sentiment values are negative, it is an Encomiast’s Feint.</p>
<h2 id="5-experiments-and-results">5. Experiments and Results</h2>
<p>This section first describes the study that evaluated the suitability of AlKhalil2 for our task, and then the datasets, the process of defining the rules and testing the framework. <a href="#figure08">Figure 8</a> illustrates the evaluation process.</p>
<h2 id="i-dataset">i. Dataset</h2>
<p>As noted, we used a dataset comprising 75 classical era Arabic poems, composed by 35 poets (see Appendix 2 for the names and numbers of poems).</p>
<p>We divided these poems into two datasets: a training set (77%) and a test set (23%) (Appendix 2 shows details of poems and rhetorical elements in each). All were then manually annotated by an Arabic literature researcher. Each poem consists of several verses that include different rhetorical elements (see Appendix 4). It is important to note that we used only the training set for developing the rules for identifying the different rhetorical elements, while the test set was used to test the system. The experimental results described later refer to the automatic analysis of examples that were set aside and not used for training (development of rules).</p>
<p>The datasets are small because of the intensive manual effort required in annotation. There is, thus, only a modest number of manually tagged poems, each containing a modest number of rhetorical elements. Rules for identifying elements, which were not found in any of the poems (see Appendix 9.4), were defined by creating a second dataset of verses from poems in which they are featured (<sup id="fnref1:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>, <sup id="fnref1:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>, <sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>).<br>




























<figure ><img loading="lazy" alt="Flowchart" src="/dhqwords/vol/17/2/000673/resources/images/figure08.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000673/resources/images/figure08_hu5305eb54f212551483b73cf8566da257_21345_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000673/resources/images/figure08_hu5305eb54f212551483b73cf8566da257_21345_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000673/resources/images/figure08.png 501w" 
     class="landscape"
     ><figcaption>
        <p>The evaluation procedure: defining and testing rules to build algorithms with maximum success.
        </p>
    </figcaption>
</figure></p>
<h2 id="ii-procedure">ii. Procedure</h2>
<p>The procedure (Figure 8) was: (1) defining identification rules by studying the training set; (2) testing the system on the training set to debug, correct, improve and refine the rules, repeating the process until results could not be improved further; (3) finally, we applied the resulting rule-based system to the test set, that had been set aside and not used for training, and measured the results with precision, recall and F1 measures <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>.</p>
<h2 id="iii-evaluating-alkhalil2">iii. Evaluating AlKhalil2</h2>
<p>Given the potential language differences, we first evaluated the suitability of AlKhalil2 as an NLP tool.</p>
<p>We thus selected eight poems from our 75 poems by different poets, regions and times, used AlKhalil2 to analyze them, and checked the results manually. Overall, the results were good, but far from perfect (Table 1 presents the results).</p>
<p>Overall, AlKhalil2 correctly analyzed 74.2% of the words. It did not analyze 25.8% or analyzed them wrongly. The majority of the unanalyzed/wrongly analyzed words are either proper names (places, plants, tribes or given names) unknown to the system, or words which are incompletely or improperly vocalized. By improperly we mean one of four possibilities: (1) a consonant of the given word has no diacritics (i.e,, is not vocalized); (2) the Sun letters (t, th, d, dh, r, z, s, sh, ṣ, ḍ, ṭ, ẓ, n), that follow the definite article al-, are not vocalised with the shedda mark (indicating that a consonant is duplicated); (3) the tanwīn al-fatḥ is typed over the vowel ā instead of over the preceding consonant (such as  كتاباً  instead of كتابًا meaning a book in the accusative form); both ways of putting the tanwīn are possible in Arabic, however, in AlKhalil2 the second way is preferred); (4) the rhyming letter, in the accusative form, is often suffixed to the ā vowel, which is a prolongation of the fatḥa (such as akala is written a akalā; the verb means to eat).<br>
AlKhalil2 performance on classical Arabic poetry    Poem Details  Number of Words  Correct  Incorrect      Imruʾ al-Qays poem no. 8  194  131 (67.5%)  63 (32.4%)      Al-Aʿshā Maymūn 78  224  153 (68.3%)  71 (31.7%)      Abū Dulāma (1)  116  84 (72.4%)  32 (27.6%)      Al-Najāshī l-Ḥārithī 41  116  85 (73.2%)  31 (26.7%)      Jarīr 11  195  173 (88.7%)  22 (11.3%)      Ibn Qays al-Ruqayyāt 50  207  135 (65.3%)  72 (34.7%)      Dīk al-Jinn al-Ḥimṣī 38  86  72 (83.7%)  14 (16.3%)      Al-Namir b. Tawlab 34  195  156 (79.9%)  39 (20%)       <strong>Total</strong>    <strong>1,333</strong>    <strong>989 (74.2%)</strong>    <strong>344 (25.8%)</strong>    <br>
AlKhalil2 wrongly identifies this ā as the dual pronoun ā. In addition, in poetry, because of metric considerations, sometimes the masculine y and feminine t prefixes, from the imperfect verb in the two forms tafaʿʿala and tafāʿala (known as forms 5 and 6), are omitted (i.e., yatafaʿʿal and tatafaʿʿal can become tafaʿʿal; while yatafāʿl and tatafāʿal becomes tafāʿal). In these cases, AlKhalil fails to analyse the verb. Most can be addressed by a manual revocalisation or retyping. In any case, while the percentages 25.8 and 8.4 make AlKhalil2 less than perfect, its results were currently good enough for us (especially since it was the best tool we had).</p>
<h2 id="iv-framework-evaluation-results">iv. Framework Evaluation Results</h2>
<p>The overall results were quite good: overall precision of 0.918, recall of 0. 902 and F measure of 0.906. They are presented in <a href="#table02">Table 2</a>. The results differ greatly, with extremely successful identification of most of the elements, but relatively lower success levels in identifying Negative Antithesis, Positive Antithesis and the Satirist’s and Encomiast’s Feints. These differences are further discussed later.</p>
<p>We measured the success rate in identifying each rhetorical element separately, other than for Repetition1, Repetition2, the Satirist’s Feint and the Encomiast’s Feint (the results are presented in <a href="#table02">Table 2</a>). Elements 2.1, 2.2, and 2.3 (Repetition1) were treated as a single element since their classification is based on the same general rule with only minor differences — in 2.1, the word is repeated in the same context; in 2.2, two words with the same meaning are repeated in two different contexts; 2.3 resembles 2.2 but the meaning of the repeated words differs.<br>
Results of the rhetorical element identification system. T= true; F= false; P = positive; N = negative.      Precision  Recall  F1        Simile (التشبيه)  0.916  0.891  0.904        Repetition1 (التكرار)  0.962  0.838  0.896        Repetition2 (الاشتقاق)  0.902  0.925  0.913        Repetition3 (رد الاعجاز على الصدور)  0.941  0.941  0.941        Repetition4 – Key Words    1  1  1        Flowing (الاطراد)  1  1  1        Afterthought/ Retraction (الرجوع)  1  1  1        Catchword Verbal (تشابه الاطراف لفظي)  1  1  1        Distribution Characters/Alliteration 1 (التوزيع)  1  1  1        Distribution Characters/Alliteration 2 (توزيع 2)  1  1  1        Hemming (تصريع)  1  1  1        Unraveling (توشيع)  1  1  1        Counterchange (عكس وتبديل)  1  0.8  0.889        Repartee (مراجعة)  1  1  1        Rhyming – in general – homoeoteleuton (سجع)  1  0.875  0.933        Verbal Congruence (مناسبة لفظيّة)  0.778  0.875  0.824        Paronomasia (جناس)  0.857  0.75  0.8        Negative Antithesis (طباق سلب)  0.636  1  0.777        Positive Antithesis (طباق إيجاب)  0.551  0.457  0.5        Satirist’s, Encomiast’s Feint  تأكيد الذّم بما يشبه المدح  تأكيد المدح بما يشبه الذّم    0.818  0.692  0.75      Average  0.918  0.9o2  0.906   <br>
Rhetorical elements 3.1, 3.2 and 3.3 (Repetition2) are also based on the same main rule with minor differences. Rhetorical elements 19 and 20 (Satirist’s Feint and the Encomiast’s Feint ) are treated as one, since they follow the same rules other than their difference in polarity. Table 3 shows the true positives, false positives and false negatives derived. There were relatively high numbers of false positives and false negatives for only two of the rhetorical elements — Positive Antithesis (طباق إيجاب) and Paronomasia (جناس).<br>
Success rate. T= true; F= false; P = positive; N = negative      T-P  F-P  F-N        Simile (التشبيه)  33  3  4        Repetition1 (التكرار)  26  1  5        Repetition2 (الاشتقاق)  37  4  3        Repetition3 (رد الاعجاز على الصدور)  16  1  1        Repetition4 – Key Words    45  0  0        Flowing (الاطراد)  3  0  0        Afterthought/ Retraction (الرجوع)  5  0  0        Catchword Verbal (تشابه الاطراف لفظي)  8  0  0        Distribution Characters/Alliteration 1 (التوزيع)  5  0  0        Distribution Characters/Alliteration 2 (توزيع 2)  56  0  0        Hemming (تصريع)  5  0  0        Unraveling (توشيع)  14  0  0        Counterchange (عكس وتبديل)  4  0  1        Repartee (مراجعة)  7  0  0        Rhyming – in general – homoeoteleuton (سجع)  21  0  3        Verbal Congruence (مناسبة لفظيّة)  7  2  1        Paronomasia (جناس)  18  3  6        Negative Antithesis (طباق سلب)  7  4  0        Positive Antithesis (طباق إيجاب)  13  16  19        Satirist’s, Encomiast’s Feint  تأكيد الذّم بما يشبه المدح  تأكيد المدح بما يشبه الذّم    9  4  2</p>
<h2 id="6-discussion">6. Discussion</h2>
<p>Our results demonstrate that the system performs extremely well for most rhetorical elements — Repetition4, Flowing, Afterthought/Retraction, Catchword Verbal, Distribution Characters/Alliteration, Hemming, Unraveling and Repartee (<a href="#table02">Table 2</a>). This can be explained by the fact that identifying these elements requires checking the words and their occurrences without analysis or consideration of context. This means that identification of these rhetorical element is not conditioned by recognition of the context in which they appear, so the system does not need to understand the meaning of the verse to decide whether these elements are present. For example, opening a verse with the same word in which the previous one ended (the rhetorical element known as the Catchword Verbal) can be noted without understanding the content of the verses in which they appear.</p>
<p>Other rhetorical elements proved more challenging with errors in their identification. We conducted error analysis for each, and suggest possible solutions to improve results. This remains for future study.</p>
<p>While the framework’s identification of Simile and Repetition2 is high (precision = 0.916; recall = 0.925; F1= 0.913), we assume that the second test in Simile identification (that is, by the prefix ka- which is the particle of simile meaning like. The word after it is in the genitive) can be upgraded by considering context. Using the AlKhalil2, we encountered situations where a word could be segmented into multiple forms — one of the forms with the simile particle ka-, and the other with the ka- as part of the word. The word كواعب, for example, can be analysed in multiple forms, one of them with the simile ka-: ka-wāʿib; i.e., similar to a person who takes everything), but considering the context of the verse (which describes women), the word should not be understood as a simile; the k is part of the word kawāʾib (pl. of kāʿib) which means girls with swelling breasts. Moreover, identification of Counterchange, Rhyming and Paronomasia can be improved when we have sufficient poems containing them, allowing definition of appropriate rules. The current set is drawn from the scarce appearances of these rhetorical elements in the training set.</p>
<p>Identification of Repetition1 and Repetition3 is very good but can be further improved by considering context. Because the false negative rate for Repetition1 is high, we must add an option for removing them. Negative Antithesis identification, too, can be bettered by adding negation words, with further study needed to resolve situations where a word appears between the negation word and that which is repeated — for example, in poem  <em>Al-Najāshī</em>  62:</p>
<h1 id="a-passage-from--_al-najāshī_--62">A passage from  <em>Al-Najāshī</em>  62</h1>
<blockquote>
</blockquote>
<p>وَمَا زَالَ مِنْ هَمْدَانَ خَيْلٌ تَدُوسُهُمْ *** سِمَانٌ وَأُخْرَى غَيْرُ جِدّ سِمَانِ</p>
<p>The horses of the Hamdān tribe continued to trample upon them. These include both  <strong>fat</strong>  and  <strong>not-fatted</strong>  horses.</p>
<p>Identifying the Satirist’s and Encomiast’s Feints was less successful for several reasons: (1) a word may have positive and negative polarity, which requires contextual analysis (that is, guessing the verse’s meaning according to its other content). (2) The lexicons include words retrieved from non-formal sources, such as Twitter, requiring creation of a richer lexicon based on formal language. (3) The poet sometimes boasts of negative qualities or facts, as if they are positive (e.g., His sword is dripping blood in war means he is a warrior), which requires consideration of context. And (4) ambiguous words can be misclassified, again requiring attention to context. Lowest of all in performance is identification of Positive Antithesis, largely because the  <em>Arabic Lexicon for Antithesis</em>  which we built is insufficient. Since false negatives rate high in this poetry, a new, richer  <em>Arabic Lexicon for Antithesis</em> , based on formal language, must be created.</p>
<p>The diacritical text in which classical poems are usually written increases the accuracy of text analysis, reducing, as it does, the number of possible segmentations for each analyzed word. When this same text is inputted into the framework without diacritics, results are poorer. The AlKhalil2 tool returns all possible diacritical options for the word.</p>
<p>As in any study, ours has limitations, some of them indicated above. The first is its relatively small number of poems — 75 of the total 26,925 classical Arabic poems in the canon. The second is that some of these 75 are written without diacritics. And third is that the AlKhalil2 misses small parts — for example, the word كَتَيْسِ in the verse:</p>
<h1 id="a-classical-arabic-verse-read-by-alkhalil2">A classical Arabic verse, read by AlKhalil2</h1>
<blockquote>
</blockquote>
<p>مِكَرٍّ مِفَرٍّ مُقْبِلٍ مُدْبِرٍ مَعًا *** كتيس ظِبَاءِ الْحُلَّبِ الْغَذَوَانِ</p>
<p>Ready to charge, ready to fell, advancing, retreating equally well; [its speed] like [that of] a lively buck-gazelle that feeds upon the ḥullab trees, rock brought down from on high by [a raging] torrent.</p>
<p>This leads to a fourth limitation and is directly related to AlKhalil2 performance on classical Arabic poetry that is far from its performance on modern Arabic. Adapting it to classical Arabic poetry is an idea for future research.</p>
<p>Finally, the lack of a large annotated corpus forced us to apply a rule-based approach that is limited by the examples annotated to date, and considered by the developers. The rule-based approach is a well-known method that was used in early days of expert systems. It has numerous limitations, as it depends heavily on manual encoding of reasoning rules. It also applies only to instances for which rules were explicitly written, and thus needs ongoing maintenance <sup id="fnref1:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. This is a major limitation, especially given the small dataset we used. The process we followed exemplifies both the benefits of the approach as well as its limitations (also shown in the analysis above). Still, as noted, we see this as an interim solution, despite our very encouraging results. There remains great diversity between different rhetorical elements. We continue to strive for better results that ensure high quality results, even even sacrificing precision (accepting false positives) in order to increase recall (reducing, even eliminating false negatives). We thus suggest its use only until a sufficiently large dataset of annotated poems is available for training machine-learning classifiers for the task.</p>
<h2 id="7-conclusion-and-future-work">7. Conclusion and Future Work</h2>
<p>Identification of rhetorical elements in classical Arabic poetry is a time-consuming process. It requires many resources, and high-level Arabic literature experts. A new, automatic, rule-based mechanism for their identification is proposed in this article, and its use with 20 elements is demonstrated as a case study. For most, the framework&rsquo;s performance is very high.</p>
<p>Further work is needed in several areas. One is addressing the study’s limitations, presented in the Discussion, and exploring the suggested solutions, such as including a significantly larger number of manually analyzed poems in the system. Another is improving the performance of the current framework by adding rules to identify missed elements, ignore misidentification and generally upgrade results. A third direction is building Arabic Sentiment Lexicons based on formal words, which will manually enrich the Negation Word Lexicon and include context-based analysis.</p>
<p>This study selected 20 rhetorical elements for identification. The automatic identification of some of them (such as the Positive Antithesis, the Satirist’s Faint and the Encomiast’s Feint) can be improved by developing the existing program. There are others still to add — among them, Metaphor (the most challenging rhetorical figure), Periphrasis, Exaggeration and types of Paronomasia that we have not addressed — which require resources such as antonym lexicons and context-based analysis. One major impediment is that identifying these elements depends mainly on semantics: the system must be capable of recognising the semantic meaning of a word/expression/phrase in order to identify some of these rhetorical elements. Automatic identification of elements not addressed in the present research and the improving automatic identification of those that are, are left to future research.</p>
<p>The present system may also be used for identifying and studying rhetoric in the modern Arabic poetry. For this, poems from the 19th-21st centuries should be added to Hussein and Kuflik’s existing system. Since most rhetorical elements in Arabic culture have equivalents in other literatures (the simile for example is also used in English, German, Chinese and more), the system can be adapted, modified and improved to identify and analyze rhetoric in non-Arabic literatures. Global use will enable in-depth comparisons of rhetorical fabrics across literatures and cultures.</p>
<p>Finally, we note that the proposed approach is generic, and the same framework may be applied to any kind of literature. The issue is not the framework’s generality but the expertise, time and effort required for defining rules. We thus reiterate that the suggested approach may be used as an interim solution when there are insufficient examples of rhetoric elements to train a classical machine-learning algorithm.</p>
<h2 id="appendices">Appendices</h2>
<h2 id="appendix-1-definitions-of-the-20-rhetorical-elements-based-mainly-on-cachia1998">Appendix 1: Definitions of the 20 Rhetorical Elements (based mainly on <sup id="fnref2:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>)</h2>
<p>The definitions, most examples and verse translations (sometimes with modifications) are taken mainly from Cachia <sup id="fnref3:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. It is, to the best of our knowledge, the only existing bi-lingual dictionary for Arabic rhetoric. As the author indicates in the introduction to the book’s English-language edition, each rhetorical element has been given an English name although in some cases the Arabic element cannot be translated (p. 3). Where there is an identical or very similar rhetorical element in English, the English term is adopted. Where there is no or only partial equivalence, the term is translated by Cachia to reflect the meaning of the Arabic. The explanations of the terms clarify what it is intended by them.</p>
<ol>
<li><em>Simile</em>  (تشبيه) The indication, by the use of the word like (similar) or some such word (مثل، كأن، كأنما، كما، كـ، شبه، حسب، خال), whether an object or condition explicitly or implicitly shares an attribute with another. The former object or condition is the tenor or primum compartionis, the latter is the vehicle or secundum comparationis. This is an example from the Syrian poet Abū Tammām (d. 846 C.E.):</li>
</ol>
<blockquote>
<p>خَلَطَ الشجاعةَ بالحَيَاء فأصْبَحا &hellip; كالحُسنِ شِيبَ لِمُغْرَمٍ بدلالِ<br>
He mingled  <strong>bravery</strong>  (shajāʿa) with  <strong>reticence</strong>  (bi-l-ḥayāʾi) so that it seemed like (ka-)  <strong>beauty</strong>  (l-ḥusni) joined to  <strong>coquetry</strong>  (dalāli) in a lover’s eyes<br>
2.  <em>Repetition1</em>  (تكرار 1) This comprises two minor rhetorical elements:<br>
2.1.  <em>Repetition</em>  (تكرار ) is use of the same word or words, more than once, in the same form, and with the same meaning and context for the sake of emphasis in description, praise or another purpose. This example is from ʿAbd al-Ghanī al-Nābulsī (d. 1731 C.E.):<br>
والجِسْمُ والجسْمُ قدْ أوْدَى السّقامُ بهِ &hellip; والجَفْنُ والجفنُ طولَ اللّيل ما هَجَعا<br>
<strong>My body</strong>  (wa-l-jismu) —  <strong>My body</strong>  (wa-l-jismu) is reduced by languor,  <strong>My eyes</strong>  (wa-l-jafnu) — <strong>my eyes</strong>  (wa-l-jafnu) have known no sleep all night<br>
2.2.  <em>Ploce</em>  (ترديد) uses the same word more than once, each time with a different application or context (sometimes it is a different grammatical context; that is, each of the two repeated words is attributed to a different subject/object/pronoun etc.). This, from Sayf al-Dawla, Emir of Aleppo (d. 967 CE), describes a slave-girl whom he was sending to a fortress to protect her from the jealousy of his other favorites:<br>
رُبَّ هَجْرٍ يَكونُ مِنْ خَوْفِ هَجْر وفِراقٍ يكونُ خَوْفَ فِرَاق &hellip;<br>
<strong>A break</strong>  (hajr) may be due to the fear of  <strong>a break</strong>  (hajr), And  <strong>parting</strong>  (firāq) be caused by the fear of  <strong>parting</strong>  (firāq).<br>
2.3.  <em>Perfect Paronomasia/Pun</em>  (جناس تامّ; also  <em>Complete Paronomasia</em> ) is the use in a single context of two words pronounced and written exactly alike but carrying different meanings. This example is from the poet Abū Tammām:<br>
مَا مَاتَ مِنْ كَرَمِ الزَّمَانِ فإنَّهُ &hellip; يَحْيَا لَدَى يَحْيَى بْنِ عَبْدِ الله<br>
All generosity that have perished is still  ** <em>living</em> **  (yaḥyā) in the court of  <strong>Yaḥyā</strong>  the son of Abdallah</p>
</blockquote>
<pre><code>3.  _Repetition2_  (تكرار2) This comprises three minor rhetorical elements: 
</code></pre>
<p>3.1.  <em>Extraction</em>  (اشتقاق; also  <em>Etymology</em> ) draws from a personal name an idea that serves the poetic motif, satirical, panegyric, erotic or other. This example, from Abū l-Ḥasan ʿAlī ibn Muḥammmad al-Anṭākī (d. 988 C.E.), is to a patron called Ṣāliḥ:</p>
<blockquote>
<p>يا صالِحَ الخيراتِ ما صَلَحا &hellip; إلا لك التأييدُ والأمْرُ<br>
O  <strong>Şāliḥ</strong> , [the name of the patron], the patron of all bounties, the two virtues of ordering and being obedient  <strong>befit</strong>  (ṣalaḥa) only your personality<br>
3.2.  <em>Semblance</em>  (مشاكلة) replaces the denotative of an object or action with another word for reasons of contextual association. An example from Abū Tammām:<br>
والدّهْرُ ألأَمُ مَنْ شَرِقْتَ بِلَومِهِ &hellip; إلا إذا أشَرَقْتَهُ بكَريمِ<br>
Fate is the vilest of all that  <strong>chokes you</strong>  (shariqta) with vileness,<br>
Unless  <strong>you choke it</strong>  (ashraqtahu) with [the succour of] a generous man<br>
3.3.  <em>Free Paronomasia</em>  (جناس مطلق) uses or suggests in one context words that differ in meaning but are phonetically and/or graphically alike or nearly alike — that is, matching words differ in their letters and vocalisation but have at least two radical consonants in common, sometimes falsely making them appear derivatives from the same root. (Sometimes they do derive from the same root). For example:<br>
ذَهَبٌ حَيْثُما ذَهَبْنَا ودُرٌّ &hellip; حيْثُ دُرْنا وفضّةٌ في الفضَاء<br>
ِ  <strong>Gold</strong>  (dhahab) wherever  <strong>we go</strong>  (dhahabnā),  <strong>pearls</strong>  (durr) Wherever  <strong>we roam</strong>  (durnā), and  <strong>silver</strong>  (fiḑḑa) even  <strong>in space</strong>  (fī l-faḍāʾ)</p>
</blockquote>
<pre><code>4.  _Repetition3_  (تكرار 3) This echoes the rhyme at the beginning of the line (رد الاعجاز على الصدور). It takes two words — which are identical in pronunciation and meaning, or almost alike in pronunciation but not in meaning, or derived (either genuinely or apparently) from the same root — placing one near the beginning of the discourse and the other at its end. This example is from Ibn al Fāriḍ (d. 1235 C.E.): 
</code></pre>
<blockquote>
<p>يا ساكنِي البطْحاء هلْ من زورةٍ &hellip; أحْيا بها يا ساكنِي البطْحاءِ<br>
<strong>Desert dwellers</strong>  (yā sākinī l-baṭḥāʾi), will you not allow one visit That I may live by it,  <strong>O desert dwellers</strong>  (yā sākinī l-baṭḥāʾi)?<br>
5.  <em>Repetition4 — Key Words</em>  (كلمات مفتاح) We suggest a new rhetorical element, in which a root is repeated in different verses of the same poem. While this includes Repetition1 and 2 (repetition, ploce, extraction/etymology, semblance and paronomasia), we identify it in all verses of the poem.</p>
</blockquote>
<ol start="6">
<li><em>Flowing</em>  (اطراد) This features in a single verse the given personal name of the individual praised, as well as the name of his father and grandfather and that of the tribe, all in the appropriate order. This example is from Ibn Durayd al-Azdī (d. 933 C.E.):</li>
</ol>
<blockquote>
<p>عِيادُ بْنُ عَمْرو بْنِ الحَلِيسِ بن جابِرِ بْنِ زَيْدِ بْنِ مَنْظُورِ بْنِ زَيْدِ بْنِ وارثِ<br>
ِʿIyād,  <strong>the son of</strong>  (bnu) ʿAmr, the son of (bni) al-Ḥalīs,  <strong>the son of</strong>  (bni) Jābir,  <strong>the son of</strong>  (bni) Zayd,  <strong>the son of</strong>  (bni) Manẓūr,  <strong>the son of</strong>  (bni) Zayd,  <strong>the son of</strong>  (bni) Wārith (the u and the i at the end of the word indicate two different grammatical forms — nominative for the first, and genitive for the second).</p>
</blockquote>
<ol start="7">
<li><em>Afterthought</em>  (رجوع; also translated as  <em>Retraction</em> ) This reverses an earlier statement. The first word in the second part of the verse usually matches one of the predefined words {بل, بلى, ليس, لكن, نعم. لم، لا، لن}. This example is from the pre-Islamic poet Zuhayr ibn Abī Sulmā (d. 609 C.E.):</li>
</ol>
<blockquote>
<p>قِفْ بالدِيار التي لم يَعْفُها القِدَمُ &hellip; بَلَى وغَيّرها الأرواحُ والدَّيمُ<br>
Halt by a deserted abode that age  <strong>has not obliterated</strong>  (lam yaʿfihā l-qidamu)–<br>
<strong>Nay</strong>  (balā), that winds and rain have altered!<br>
8.  <em>Catchword Verbal</em>  (تشابه الأطراف اللفظيّ) This is of two types. We consider one type only — the verbal — which corresponds to anadiplosis, gradatio, reduplication. It starts each of a succession of verses with the preceding rhyme word, for example, from the poetess Laylā l-Akhyaliyya (d. 700 C.E.):<br>
إذا نَزلَ الحجّاجُ أرْضًا مريضةً &hellip; تَتَبَّعَ أقْصَى دائها فشفاها شَفاها من الدّاءِ العُضال الذي بها &hellip; غُلامٌ إذا هَزٌ القَناةَ سقاها سَقاها فَرَوّاها بشرْبٍ سِجالُها &hellip; دِماءُ رجالٍ يَحْلِبونَ ضَراها   Whenever al-Ḥajjāj visits a sick land,<br>
He treats its illness and  <strong>cures it</strong>  (shafāhā);<br>
<strong>It is cured</strong>  (shafāhā) of its chronic disease<br>
By a warrior who always shakes his spear, and  <strong>quenches the land’s thirst</strong>  (saqāhā);<br>
<strong>He quenches the land’s thirst</strong>  (saqāhā) by drinking buckets of the blood of his enemies.<br>
9.  <em>Distribution Characters</em>  (توزيع; also  <em>Alliteration</em> )<br>
9.1  <em>Distribution Characters/Alliteration 1</em>  (توزيع 1) This distributes to the poet or speaker the same consonant or vowel in every word of a verse. The programme checks for such a letter. This verse is by Ṣafiyy al-Dīn al-Ḥillī (d. 1349 C.E.):<br>
محمدُ المُصطَفى المُختارُ مَنْ خُتِمَتْ &hellip; بمجدِهِ مُرْسَلو الرَّحْمَنِ للأُمَمِ<br>
Muhammad the favourite and choices from all His creations.<br>
One who is the last of the messengers of the Merciful God to the nations (the translation lacks starting each word with the m consonant).<br>
9.2  <em>Distribution Characters/Alliteration 2</em>  (توزيع 2) This type distributes the same consonant or vowel in every word or most words of the entire poem. The programme checks, and we choose to record how many times the top three letters appear.</p>
</blockquote>
<pre><code>10.  _Hemming_  (تصريع) This is when the end of the first hemistich matches the end of the verse in meter and final vowel. The following verse is by Abū Nuwās (d. 814 C.E.) 
</code></pre>
<blockquote>
<p>دَعْ عَنْكَ لَوْمِي فأنّ اللَّوْمَ إِغْراءُ &hellip; وَداوِني بالّتي كانَتْ هيَ الدّاءُ<br>
Censure me not, for censure but  <strong>tempts me</strong>  (ighrāʾu); cure me rather with the cause of my  <strong>ill</strong>  (al-dāʾu).<br>
11.  <em>Unraveling</em>  (التوشيع) This is use of a noun in dual form near the end of the second hemistich, followed by two single words specifying what constitutes this duality, the second being the rhyme word. An example from Mayyās al-Mawṣilī (no date of death is given):<br>
أبيتُ في لجَج التّذْكارِ منْكَ وبي &hellip; حالان مخْتَلفانِ اليَأسُ والأمَلُ لا يَهتدي لي طيْفٌ مُذْ هجرْتَ ولا &hellip; يَزُورُني المُسلْيان الكُتْبُ والرُّسُلُ أسائلُ الدّارَ مِنْ وَجْدي عليْكَ فلا &hellip; يُجيبُني المُقْفران الرّبْعُ والطللُ<br>
I spend the night importuned by memories of you, and in me<br>
Are  <strong>two opposite conditions: despair and hope</strong> .<br>
No phantom finds its way to me since you deserted me,<br>
Nor am I visited by the  <strong>two comforters: letters and messengers</strong> .<br>
My passion for you makes me question the site where I have halted, but<br>
I get no answer from  <strong>either of the two desolate spots: the old encampment and its half-obliterated traces</strong> .<br>
12.  <em>Counterchange</em>  (عكس وتبديل) This is repetition of words in a different order. It is of two kinds: (1) a hemistich is recast to complete the verse without any change in meaning, and (2) a hemistich or part thereof is re-arranged to produce a different meaning.<br>
يا بَدَني يا بَدَني بالفِراقِ مُتْ كمدا مُتْ &hellip; كمَداً بالفراقِ فارَقَني مَنْ أحبُّ واحزَني &hellip; واحزَني مَنْ أحبُ فارَقَني<br>
Body of mine, now we are parted, die of grief!<br>
Die of grief now we are parted, o body of mine!<br>
He has left me, whom I love – O wretchedness!<br>
Wretchedness, he whom I love has left me!<br>
13.  <em>Repartee</em>  (مراجعة) This is a reported conversation, combining pithy expression, subtle ideas, elegant composition, and flowing diction. This example is from the poetry of the Egyptian Ibn Maṭrūḥ (d. 1251 C.E.):<br>
سَألتُ مَنْ أمْرَضَني &hellip; في قُبْلَةٍ تشْفي الألْمْ فقال لا لا أبداً &hellip; قُلتُ له نَعَمْ نَعَمْ<br>
I asked of him who caused my languor for a kiss to ease the pain.<br>
**He answered,  “No, no, never!” **  (faqāla: lā lā abadan)<br>
**I insisted,  “Yes, oh yes!” **  (qultu lahu: naʿam naʿam)<br>
14.  <em>Rhyming – in general – homoeoteleuton</em>  (سجع) When the discourse is divided into sections with similar-sounding last syllables, it is said to be:<br>
14.1.  <em>Congruent</em>   موازَن when the final words agree in measure as well as in rhyme, or  14.2.  <em>Terminal</em>   مطرف when they have rhyme but not measure in common. An example of congruent rhyming from the Qur`ān 88:13-14:<br>
فيها سررٌ مرفوعة وأكوابٌ موضوعة<br>
In it are thrones that  <strong>are raised</strong>  (marfūʿa), and goblets  <strong>placed ready</strong>  (mawḑūʿa).<br>
An example of terminal rhyming from al-Waʾwāʾ al-Dimashqī (d. 995 C.E.):<br>
قُمْ يا غُلامُ إلى المُدام &hellip; قُمْ داوِني منِها بِجام<br>
Up, boy! To  <strong>the wine</strong>  (al-mudām), Medicate me with  <strong>a silver goblet</strong>  (bi-jām)<br>
14.3.  <em>Tucking</em>   تشطير. The division of each hemistich into rhyming parts, but with different rhymes in each hemistich (producing the arrangement bbaa, where a is the rhyme common to all verses of the poem). An example from Abū Tammām in praise of the caliph al- Muʿtaşim bi-llāh (re. 833-842 C.E.), playing on the literal meaning of the honorific title:<br>
تَدْبيرُ مُعْتَصِم بالله مُنْتقِمٍ &hellip; للهِ مُرْتقبٍ في الله مُرْتغِبٍ<br>
He revenges [his enemies by the help of] God (bi-l-lāhi muntaqimin), and acts while finding refuge in God (tadbīru muʿtaṣimin)<br>
He places his hope in God (fī l-lāhi murtaghibin), waiting to meeting Him (li-lāhi murtaqibin)<br>
14.4.  <em>Embroidery</em>   ترصيع– Making every word in a hemistich or prose versicle agree in rhyme and possibly in measure, as well as in grammatical case with the correspondingly placed word in the next hemistich or versicle [Qurʾān 82: 13]:<br>
إنّ الأبْرارَ لَفي نَعيم, وإنّ الفُجّارَ لَفي جَحيم<br>
The (inna) righteous (abrāra) are in (la-fī) bliss (naʿīmin), and the (wa-inna) ungodly (al-fujjāra) are in (la-fī) hell (jaḥīmin)</p>
</blockquote>
<pre><code>15.  _Verbal Congruence_  (مناسبة لفظيّة) Verbal congruence is the use of two words or sets of words cast in the same metrical pattern. It is of two varieties: perfect and imperfect. In the first, congruent words or versicles rhyme with one another. In the second, they do not. We focus on one of them: the verbal congruence perfect. An example of perfect verbal congruence, nūru l-ghayāhibi ( “the light of darkness” ) and jammu l-mawāhibi ( “abounding in gifts” ) from ʿAbd al-Ghanī al-Nābulsī: 
</code></pre>
<blockquote>
<p>نُورُ الغَياهِبِ في يَوْم الوَغى بَطَلٌ &hellip; جمُّ المواهِبِ بَحْرُ الجُودِ والكَرَمِ<br>
<strong>He is a light in darkness</strong>  (nūru l-ghayāhibi), a hero on the day of strife,<br>
<strong>Abounding in gifts</strong>  (jammu l-mawāhibi), a sea of bounty and generosity<br>
16.  <em>Paronomasia/Pun</em>  (جناس) This is use or suggestion in one context of words that differ in meaning but are phonetically and/or graphically alike or nearly alike. They are of seven main types:<br>
16.1.  <em>Conjunct Paronomasia</em>  (جناس مركّب - مَرْفُوّ) A paronomasia in which a single word is matched by a combination of more than one. An example from Ibn Nubāta (d. 1366 C.E.), in which amradā,  “beardless youth”  , is matched by am radā,  “or death:”<br>
قمراً نَراهُ أمْ مليحا أمْرَدَا &hellip; ولِحاظُه بينَ الجَوانِحِ أمْ رَدَى<br>
Is it a moon that we see, or a handsome  <strong>beardless youth</strong>  (amradā)?<br>
Is it his glances [wreaking havoc] in my breast,  <strong>or is it death</strong>  (am radā)?<br>
16.2.  <em>Tipped Paronomasia</em>  (جناس ناقص - مُطَرَّف) A paronomasia in which one of the matching terms is longer than the other by at least one initial consonant. An example from Ibn al-Fāriḑ (d. 1235 C.E.):<br>
إنْ كانَ فِراقُنا مع الصُبْح بَدا لا أسْفَرَ بَعْدَ ذاكَ صُبْحٌ &hellip; أبَدا<br>
If with the dawn your parting must  <strong>occur</strong>  (badā),<br>
Then may no dawn  <strong>hereafter ever</strong>  (abadā) break<br>
16.3.  <em>Tailed Paronomasia</em>  (جناس ناقص - مُذَيَّل) A paronomasia in which one of the matching terms is longer than the other by one or more terminal consonants. An example by Ḥassān ibn Thābit (d. 674 C.E.):<br>
وُكنّا متى يَغْزُ النّبيُّ قَبيلَةًٌ &hellip; نَصِلْ جانِبيْها بالقنا والقنابِل<br>
Whenever the Prophet attacked a tribe,<br>
We struck both flanks with  <strong>lances</strong>  (qanā) and with squadrons of  <strong>horse</strong>  (qanābil)<br>
16.4.  <em>Consonantal Paronomasia</em>  (جناس مُحَرَّف; also  <em>Distorted Paronomasia</em> ) A paronomasia in which the two matching terms consist of the same letters in the same order, differing only in vocalization. An example from Sharaf al-Dīn al-Anṣārī (d. 1264 C.E.):<br>
لِعَيْني كُلّ يَوْمٍ ألفُ عَبْرَه &hellip; تُصيّرُني لأهْل العِشْق عِبْرَه<br>
My eyes shed every day a thousand  <strong>tears</strong>  (ʽabra)<br>
So that to my lovers I have become  <strong>an object lesson</strong>  (ʽibra)<br>
16.5.  <em>Substitutive and Variant Paronomasia</em>  (جناس تصريف ) A paronomasia in which one of the matching terms has one letter – initial, medial or terminal – which differs from the corresponding letter in the other term, or is similar or close to their points of emission but does not differ in its dots (so that it belongs to a different or the same phonetic category). An example from Abū Firās al-Ḥamdānī (d. 968 C.E.):<br>
تَعِسَ الحَرِيصُ وَقَلَّ ما يأتي بِهِ &hellip; عِوَضًا عنِ الإلْحاحِ وَالإلْحافِ<br>
Wretched is the miser, and he seldom gets a return for his  <strong>insistence</strong>  (ilḥāḥ) and  <strong>importuning</strong>  (ilḥāf)<br>
16.6.  <em>Metathetic Paronomasia</em>  (جناس مقلوب; also  <em>Reverse Paronomasia</em> ) A paronomasia in which the two matching terms consist of the same letters, without addition or omission, but in different orders. An example from Shams al-Dīn Muḥammad al-Bakrī (d.1060 C.E.):<br>
قلتُ مستعطفاً لساقٍ سقاني &hellip; من طلا نِيلِ مِصْرَ أعذبَ كاسِأنتَ عندي أعزّ منه ولكنْ &hellip; قلبُه ليّنٌ وقلبُكَ قاسِ<br>
Pleadingly, I said to a  <strong>cupbearer</strong>  (sāqī) who poured out to me of the liquor of Egypt’s  <strong>Nile</strong>  (nīl) a most limpid cup: You are dearer to me than it, and yet its heart is  <strong>soft</strong>  (layyin; the y in Arabic is written like the ī. Without the diacritics, the word layyin looks like līn), but yours is  <strong>cruel</strong>  (qāsī)<br>
16.7.  <em>Graphic Paronomasia</em>  (جناس تصحيف) A paronomasia such that, when written, the two matching terms are shaped alike, differing only in their dots (which, in Arabic script, differentiate many letters from one another). An example:<br>
إنْ كان شرْعُ هواك أطْلَقَ أدمُعي &hellip; فوَكيلُ شوْقي عاجزٌ عن حَبْسهأوْ كان منكَ الطَّرْفُ أسْهَرَ ناظِرِي &hellip; فَلِكُلّ شَيْءٍٍ آفَةٌ مِنْ جِنْسِه<br>
Though the law of your love set free my tears,<br>
Yet is the advocate of my yearning incapable of  <strong>restraining it</strong>  (ḥabsihi حبسه)<br>
And, if your eyes deprive mine of sleep<br>
[It is admitted that] all things are vulnerable to  <strong>kindred ill</strong>  (jinsihi جنسه)</p>
</blockquote>
<pre><code>17.  _Negative Antithesis_  (طباق سلب) Combining the object (word) and its opposite in Arabic literature produces two main kinds of antithesis — positive and negative. Our focus was the negative, which is considered a type of Repetition, with the opposite word preceded by a negation article {لا, ما, لم, لن, ليس, لات, غير}. This example is from the poem by al-Buḥturī (d. 898 C.E.) between the phrases knowing and not knowing: 
</code></pre>
<blockquote>
<p>يقيّض لي من حيث لا أعلم النوى &hellip; ويسري إليّ الشوق من حيث أعلم<br>
Separation is predestined to me from a source that  <strong>I do not know</strong>  (lā aʿlamu);<br>
But I feel the longing of a source that  <strong>I do know</strong>  (aʿlamu).<br>
18.  <em>Positive Antithesis/Oxymoron</em>  (طباق إيجاب) This is when words and their opposites appear in the same verse. Opposites formed by negation words are not positive antitheses. An example from Ibn Nubāta:<br>
دعوتُ ألْفاظ المَليح وكأسَه &hellip; فنعمْتُ بينَ حديثه وعَتيقه<br>
I call forth the fair one’s conversation and his cup, and so delight in his  <strong>present discourse</strong>  (ḥadīthihi) and  <strong>old</strong>  wine (qadīmihi).<br>
19.  <em>The Satirist’s Feint</em>  (تأكيد الذّم بما يشبه المدح) This either (a) denies that the subject has any praiseworthy quality, or (b) ascribes to the subject a pejorative attribute then, after exempting him/her from it or rectifying it, names another pejorative attribute. An example from al-Nābulsī:<br>
فإن مَنْ لامَني لا خيرَ فيه سِوَى &hellip; وصفي له بأخس الناس كًلّهِمِ<br>
My reprover  <strong>has no good qualities except</strong>  (lā khayra fīhi siwā)<br>
<strong>being the vilest among all people</strong>  (akhassa l-nāsi kullihimi).<br>
20.  <em>The Encomiast’s Feint</em>  (تأكيد المدح بما يشبه الذّم) This either (a) denies that the subject has any pejorative attributes, then exempts him/her from that denial, as if reversing it, a praiseworthy quality. Or (b) ascribes to the subject a praiseworthy quality then, after an exempting or rectifying word, names another praiseworthy quality. The following example is from the pre-Islamic poet an-Nābigha l-Dhubyānī (d. ca. 604 C.E.):<br>
ولا عَيْبَ فيهم غيرَ أنّ سُيوفَهُمْ &hellip; بهنّ فلولٌ مِنْ قِراع الكَتائبِ<br>
There is no fault in them, excepting that their swords — have<br>
Suffered dents in clashes with battalions.</p>
</blockquote>
<h2 id="appendix-2-poets-and-number-of-poems">Appendix 2: Poets and Number of Poems</h2>
<pre><code>  Name of Poet  Number of poems in training set  Number of pomes in text set      Al-Buḥturī  3        Ibn al-Rūmī  7  1      Abū Tammām  9  1      Al-Mutanabbī  2        Dīk al-Jinn al-Ḥimṣī  10        Al-Najāshī al-Ḥārithī  2        Al-Kumayt ibn Zayd  2        Ibn Qys al-Ruqayyāt  2        Al-Ṭirimmāḥ b. Ḥakīm  2        Jarīr  2        Al-Farazdaq   3        Abū Dhuʾayb al-Hudhalī   2        Bashshār b. Burd  1        Al-Aʿshā Maymūn  1  1      Imruʾ al-Qays  1        Mulayḥ b. al-Ḥakam  1        Abū Arāka  1        Ayman b. Khuraym  1        ّTaʾabbaṭa Sharran  1        Dhū l-Rumma  1        ʿUbaydallāh b. al-Ḥurr  1        ʿImrān b. Ḥiṭṭān  1        Qaṭarī b. al-Fujāʾa  1        Yazīd b. Mufarrigh al-Ḥimyarī  1        Al-Nābigha l-Dhubyānī    1      Rabīʿa b. Maqrūm    1        Al-Namir b. Tawlab    1      Al-Ḥakam b. ʿAbdal    1      Abū Dulāma    2      Anonymous (Abbasid poet)    1      Al-Ḥamdawī    3      Abū Nuwās    1      Muḥammad b. Yasīr al-Riyāshī    1      Abān al-Lāḥiqī    1      ʿAbdallāh b. ʿAbd al-Ḥamīd al-Lāḥiqī    1      Total count  58  17      
</code></pre>
<h2 id="appendix-3-number-of-rhetorical-elements-in-the-training-and-test-datasets">Appendix 3: Number of Rhetorical Elements in the Training and Test Datasets</h2>
<pre><code>  Elements  Appearances in the sets  Training set  Test set         _Simile_   تشبيه    290  37         _Repetition1_  (تكرار)   196  31         _Repetition2_  (اشتقاق)   247  40         _Repetition3_  ( _echo_   رد الاعجاز على الصدور)   131  17         _Repetition4_  – Key Words كلمات مفتاح    66  45         _Flowing_  (اطراد)   5  3         _Afterthought_  (رجوع)   5  5         _Catchword Verbal_  (تشابه الاطراف اللفظي)   4  8         _Distribution Characters1/Alliteration 1_  (توزيع 1)   5  5         _Distribution Characters2/ Alliteration2_  (توزيع 2)   174  51         _Hemming_  (تصريع)   5  5         _Unraveling_  ((توشيع)   16  14         _Counterchange_  (عكس وتبديل)   8  5         _Repartee_  (مراجعة)   6  5         _Rhyming – in general – homoeoteleuton_  (سجع)   5  24         _Verbal Congruence_  (مناسبة لفظيّة)   4  7         _Paronomasia_  (جناس)   32  21         _Negative Antithesis_  (طباق سلب)   66  7         _Positive Anthithesis / Oxymoron_  (طباق إيجاب)   245  35         _Satirist's, Encomiast's Feints_    (تأكيد الذّم بما يشبه المدحتأكيد المدح بما يشبه الذّم)   10  13      
</code></pre>
<h2 id="appendix-4-appearance-of-each-rhetorical-element-in-each-poem-rhetorical-elements-are-numbered-123459212161718">Appendix 4: Appearance of Each Rhetorical Element in Each Poem (Rhetorical Elements are numbered 1,2,3,4,5,9.2,12,16,17,18</h2>
<pre><code>  Poet  Poem number  Ele.1  Ele.2   Ele.3  Ele.4  Ele.5  Ele.9.2  Ele.12  Ele.16  Ele.17  Ele.18      Al-Buḥturī  51  8  5  4  7  0  3  0  0  3  5      256  11  3  2  0  0  3  0  0  2  3      915  10  4  15  3  0  3  1  1  1  11      Ibn al-Rūmī  9  8  2  9  3  6  3  1  0  1  6      104  4  4  2  2  0  3  1  2  0  3      343  4  2  2  1  0  3  0  0  1  3      344  3  3  3  1  0  3  0  0  0  4      539  0  2  2  4  0  3  0  0  2  8      691  1  1  2  3  0  3  0  0  1  1      701  3  5  2  7  0  3  2  0  0  2      Abū Tammām  2  10  6  6  3  0  3  0  2  1  6      5  13  12  11  14  0  3  0  0  14  9      21  2  0  2  4  0  3  0  0  0  3      71  13  6  7  4  0  3  1  0  0  12      179  9  5  1  4  0  3  0  0  2  5      393  6  3  6  5  0  3  0  1  4  10      464  1  2  2  0  0  3  0  0  4  8      470  3  6  5  0  0  3  0  0  0  3      484  4  2  6  1  2  3  0  0  3  10      al-Mutanabbī  59  21  10  7  1  0  3  0  1  1  9      209  5  9  6  2  0  3  0  0  2  17      Dīk al-Jinn al-Ḥimṣī-  13  0  3  2  2  0  3  2  0  0  2      14  0  1  0  0  1  3  0  0  2  1      9  9  6  7  6  0  3  0  0  3  5      62  4  5  3  3  0  3  1  0  0  0      11  5  2  6  3  0  3  0  0  0  7      15  0  3  1  1  0  3  0  0  0  1      2  0  4  7  2  1  3  0  0  1  3      35  0  0  0  0  1  3  0  0  0  0      38  0  8  3  1  1  3  0  0  1  2      33  1  1  1  0  0  3  0  0  0  0      Al-Najāshī al-Ḥārithī   41  4  1  1  1  0  3  0  0  0  1      62  14  4  7  1  1  3  0  0  1  3      Al-Kumayt ibn Zayd   6  5  3  4  2  0  3  0  0  0  5      8  1  2  3  0  0  3  0  0  0  0      Ibn Qys al-Ruqayyāt   40  2  0  2  0  7  3  0  0  0  2      50  1  4  4  2  0  3  0  0  0  3      Al-Ṭirimmāḥ b. Ḥakīm   22  3  1  3  1  1  3  0  0  0  1      290  1  1  3  1  3  3  0  1  1  3      Jarīr   3  4  9  3  5  2  3  0  1  4  7      11  1  3  7  0  4  3  0  0  0  1      Al-Farazdaq   35  5  0  3  1  4  3  0  0  0  6      50  0  2  3  0  2  3  0  0  1  5      181  7  4  7  1  9  3  0  0  2  8      Abū Dhuʾayb al-Hudhalī  1  12  1  7  2  0  3  0  0  0  0      2  4  2  5  1  7  3  0  0  1  6      Bashshār b. Burd   26  14  6  13  6  0  3  2  0  3  11      Al-Aʿshā Maymūn  79  13  1  2  1  0  3  0  0  1  3      Imruʾ al-Qays  8  8  1  4  2  0  3  0  0  0  0      Mulayḥ b. al-Ḥakam  2  12  3  2  1  7  3  0  0  0  2      Abū Arāka  1  0  0  0  0  0  3  0  0  0  0      Ayman b. Khuraym  17  1  2  3  2  1  3  0  0  0  1      Taʾabbaṭa Sharran  29  7  8  9  6  0  3  1  2  1  9      Dhū l-Rumma  30  10  0  5  0  0  3  0  0  0  1      ʿUbaydallāh b. al-Ḥurr  53  1  1  5  2  0  3  0  0  0  1      ʾImrān b. Ḥiṭṭān  199  1  1  4  0  6  3  0  0  1  6      Qaṭarī b. al-Fujāʾa  121  0  3  3  1  0  3  0  0  0  1      Yazīd b. Mufarrigh al-Ḥimyarī  44  1  8  3  5  0  3  0  0  1  0      Tally of poems in training set  58  290  196  247  131  66  174  12  11  66  245      Al-Nābigha l-Dhubyānī-  36  8  4  11  3  6  3  1  0  3  5      Rabīʿa b. Maqrūm  43  3  1  2  0  3  3  0  0  1  0      Al-Aʿshā Maymūn  78  6  4  5  2  1  3  0  0  0  5      Al-Namir b. Tawlab  34  2  3  3  0  2  3  0  0  1  1      Al-Ḥakam b. ʿAbdal  1  2  4  2  1  8  3  1  0  0  0      Abū Dulāma  1  4  0  1  1  0  3  0  0  0  0      Anonymous poet  9  0  0  0  0  0  3  0  0  0  1      Abū Tammām  338  0  1  3  0  4  3  0  0  1  3      Al-Ḥamdawī  12  0  1  0  0  4  3  0  0  0  0      Abū Nuwās  2  3  1  0  1  1  3  0  0  0  2      Muḥammad . Yasīr al-Riyāshī    2  2  2  0  1  3  0  0  0  1      Abū Dulāma  1  2  4  3  4  10  3  0  0  1  8      Ibn al-Rūmī   6  2  1  1  1  1  3  0  0  0  2      Al-Ḥamdawī  6  0  0  1  0  1  3  0  0  0  3      Al-Ḥamdawī  8  0  0  3  0  2  3  0  0  0  1        ʿAbdallāh b. ʿAbd al-Ḥamīd al-Lāḥiqī  4  1  3  1  1  0  3  0  0  0  2      Abān al-Lāḥiqī  1  2  2  2  3  1  3  0  0  0  1      Tally of poems in testing set  10  37  31  40  17  29  51  2  0  7  35      
</code></pre>
<h2 id="acknowledgement">Acknowledgement</h2>
<p>This research was supported by the Israel Science Foundation (grant No. 1861/14) and a Werner Otto Scholarship, University of Haifa.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Moreau, François. (2003)   <em>Al-Balāgha. Al-Madkhal li-dirāsat al-ṣuwar al-bayāniyya</em> . Trans. Muḥammad al-Walī and ʿĀʾisha Jarīr. Morocco and Beirut: Afrīqyā l-Sharq,&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Schaade, A., and G.E. von Grunebaum. (2012)  “Balāgha” ,  <em>The Encyclopaedia of Islam2</em> . Online version. 1: 981-982.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://arabic-rhetoric.haifa.ac.il/#/aboutApp.html">https://arabic-rhetoric.haifa.ac.il/</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="https://benjamins.com/online/met/">https://benjamins.com/online/met/</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Habash, N., Rambow, O., and Roth, R. (2009)  “MADA+ TOKAN: A toolkit for Arabic tokenization, diacritization, morphological disambiguation, POS tagging, stemming, and lemmatization” ,  <em>Proceedings of the 2nd International Conference on Arabic Language Resources and Tools (MEDAR)</em> , Cairo, Egypt. Vol. 41.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Hussein, Ali Ahmad. (2015)  <em>The Rhetorical Fabric of the Traditional Arabic Qaṣīda in its Formative Stages: A Comparative Study of the Rhetoric in Two Traditional Poems by ʿAlqama l-Faḥl and Bashshār b. Burd</em> . Wiesbaden: Harrassowitz Verlag.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Heinrichs, Wolfhart. (1994)  “Muslim b. al-Walīd und badīʿ”  in Wolfhart Heinrichs and Gregor Schoeler (eds.)  <em>Festschrift Ewald Wagner zum 65. Geburtstag</em> . Beirut: In Kommission bei Franz Steiner Verlag Stuttgart: 211-245.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Cachia, Pierre. (1998)  “The Arch Rhetorician or the Schemer’s Skimmer” ,  <em>A Handbook of Late Arabic Badīʿ Drawn from ‘Abd al-Ghanī al-Nābulsī’s Nafaḥāt al-azhār ʿalā nasamāt al-asḥār</em> . Wiesbaden: Otto Harrassowitz Verlag.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p><a href="https://arabic-rhetoric.haifa.ac.il/">https://arabic-rhetoric.haifa.ac.il/</a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Hayes-Roth, F. (1985)  “Rule-based systems”    <em>Communications of the ACM</em>  28(9): 921-932.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Boudchiche, Mohamed, et al. (2017)  “AlKhalil morpho sys 2: A robust Arabic morpho-syntactic analyzer” ,  <em>Journal of King Saud University-Computer and Information Sciences</em> . 29(2):141-146.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Diehl, Frank, et al. (2009)  “Morphological analysis and decomposition for Arabic speech-to-text systems” ,  <em>Tenth Annual Conference of the International Speech Communication Association</em> . Brighton, United Kingdom.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Pasha, Arfath, et al. (2014)  “MADAMIRA: A fast, comprehensive tool for morphological analysis and disambiguation of Arabic”    <em>LREC</em> . Vol. 14.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Abdul-Mageed, M., Diab, M.T., and Kübler, S. (2013)  “ASMA: A System for Automatic Segmentation and Morpho-Syntactic Disambiguation of Modern Standard Arabic” ,  <em>RANLP</em> . <a href="https://aclanthology.org/R13-1001/">https://aclanthology.org/R13-1001/</a>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Habash, Nizar and Owen Rambow. (2006) MAGEAD:  “A morphological analyzer and generator for the Arabic dialects” ,  <em>Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics</em> . Association for Computational Linguistics. Sydney, Australia.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Buckwalter, Tim. (2002)  <em>Buckwalter Arabic Morphological Analyzer Version 1.0</em> .  “LDC2002L49” . Web Download. Philadelphia: Linguistic Data Consortium.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Maamouri, Mohamed, et al. (2010)  “Standard Arabic morphological analyzer (SAMA) version 3.1” ,  <em>Linguistic Data Consortium</em> . Catalog No. LDC2010L01.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Sawalha, Majdi, Eric Atwell, and Mohammad AM Abushariah. (2013)  “SALMA: standard Arabic language morphological analysis. Communications, Signal Processing, and their Applications (ICCSPA)” ,  <em>1st International Conference on Communications, Signal Processing, and their Applications IEEE</em> . Sharjah, United Arab Emirates.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Shoukry, Amira Magdy. 2013.  <em>Arabic sentence-level sentiment analysis</em> . PhD thesis, the American University in Cairo, Cairo.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>[8] Badaro, Gilbert, et al. (2014)  “A large-scale Arabic sentiment lexicon for Arabic opinion mining” ,  <em>ANLP</em>  2014 165.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Alkhalifa, C., M., Black, W., Elkateb, S., Pease, A., Rodriguez, H., and Vossen, P. T. J. M. (2006).  “Introducing the Arabic wordnet project.”  In  <em>Third Global Wordnet Conference.</em>&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Elkateb, Sabri, et al. (2006)  “Building a WordNet for Arabic” ,  <em>Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC)</em> , Genoa, Italy.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Miller, George A. 1995.  “WordNet: a lexical database for English” ,  <em>Communications of the ACM</em> . 38(11):39-41.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Hussein, Ali Ahmad. (2018)  “Majāz῾ aqlī  intellectual trope  and the description of wine in a poem by Abū Dhuʾayb al-Hudhalī” ,    <em>Acta Orientalia Academiae Scientiarum Hungaricae</em> . 71(4):429-442.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Hussein, Ali Ahmad. (2015)  “The rhetoric of Hudhalī wine poetry” ,   <em>Oriens</em>   43(1-2):1-53.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Abuata, B., and Al-Omari, A. (2018)  “A rule-based algorithm for the detection of Arud meter in classical Arabic poetry” ,  <em>International Arab Journal of Information Technology</em> . 15(4):661-667.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Ahmed, M. A., and Trausan-Matu, S. (2017)  “Using natural language processing for analyzing Arabic poetry rhythm” ,   <em>16th RoEduNet Conference: Networking in Education and Research (RoEduNet)</em> .  <em>IEEE</em> .‏&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Abushihab, Ibrahim. (2020)  “A stylistic analysis of Arab-American poetry: Mahjar (place of emigration) poetry” ,   <em>Journal of Language Teaching and Research</em>   11(4):652-661.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Alkhatib, Manar, and Khaled Shaalan. (2017)  “Natural language processing for Arabic metaphors: a conceptual approach” ,  <em>Advances in Intelligent Systems and Computing</em>  533: 170-181.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Hussein, Ali Ahmad. No date.  “Statistical development of the use of rhetorical elements in classical Arabic poetry” , unpublished.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p><a href="https://arabic-rhetoric.haifa.ac.il/#/aboutApp.html">https://arabic-rhetoric.haifa.ac.il/</a> – link to the system&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Sasaki, Yutaka. 2007.  “The truth of the F-measure” ,   <em>Teach Tutor Mater</em> . 1(5):1-5.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Language, Materiality, and Digital Neapolitanitá</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000680/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000680/</id><author><name>Cristina Migliaccio</name></author><published>0001-01-01T00:00:00+00:00</published><updated>0001-01-01T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<blockquote>
<p>I shall try . . . to say something useful about the language of the people who speak the vulgar tongue, hoping thereby to enlighten somewhat the understanding of those who walk the streets like the blind, ever thinking that what lies ahead is behind them.<br>
<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup><br>
“De vulgari eloquentia,”  Dante Alighieri</p>
</blockquote>
<p>Southern Italian digital humanist Domenico Fiormonte has argued that  “DH is…a discipline and academic discourse dominated materially by an Anglo-American èlite and intellectually by a mono-cultural view”   <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> and has repeatedly called for a digital humanities that  “improve[s] and cultivate[s] the margins…[giving] more attention [to] variegated cultural and linguistic cultural diversity”   <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Similarly, Crystal Hall points out that both the Digital Humanities and Italian Studies  “have struggled with inclusivity and the representation for traditionally marginalized voices…[though] both fields offer tools and materials of study that can assist in [a] transformation”   <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. This article takes up the work of these scholars in its investigation of the Neapolitan language on YouTube. According to UNESCO, the Neapolitan language is a vulnerable language because the number of speakers has been decreasing steadily in Southern Italy, forecasting the eventual extinction of the Southern Italian language. UNESCO’s categorization of Neapolitan as vulnerable is problematic because it only accounts for speakers in Southern Italy and not in the Italian diaspora, which involves a physical relocation of Neapolitans to other parts of the world such as Australia and the United States. It is also problematic because it indicates that Italians either in Italy or in the diaspora may no longer  <em>want</em>  to speak Neapolitan. A Neapolitan digital diaspora, unaccounted for in UNESCO statistics, also exists on social media, which may include Neapolitans in Italy and abroad but also may include first-generation Italians, heritage-language speakers, and other-culture people fluent or familiar with the language. In this article, I explore how usages of Neapolitan-Italian language on YouTube might counter the linguistic and cultural subordination of Neapolitans.</p>
<h2 id="an-interdisciplinary-perspective">An Interdisciplinary Perspective</h2>
<p>This article is fueled by postcolonial digital humanities scholarship (a sub-strand of Disrupting DH) <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>  that engages with differences, attempts to  “tell an untold story”   <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> in the digital cultural record, and responds to calls to  “undertake the important work of digitizing under-represented cultural heritage”   <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, considering what digital work can do for and with underrepresented communities <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. In  <em>New Digital Worlds Postcolonial Theory, Praxis, and Pedagogy</em> , Roopika Risam expresses that  “as digital knowledge production has accelerated rapidly in the last few decades, the exclusions and biases that have characterized print culture — products of colonialism, racism, and patriarchy — have been reproduced in the digital cultural record”   <sup id="fnref2:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. Risam’s work dovetails with such digital humanities multilingualism scholars as Élika Ortega <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> and Alexander Gil <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, who consider how technology intersects with globalization and transnational cultural ecologies to explore why digital scholarship, like most academic scholarship, is only sanctioned or recognized if it is (a) either published in English or (b) produced by and from English-speaking nations. In particular, Risam’s work echoes Southern Italian digital humanist, Domenico Fiormente, who has repeatedly critiqued the cultural homogeneity of the digital humanities (<sup id="fnref2:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>; <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>). For Fiormonte:</p>
<p>the Anglophone dominance of DH produces a series of negative effects: (1) [it] prevents the construction of a genuinely democratic, supportive, and multilingual international community (one of the hallmarks of the human and social sciences); (2) [it] links institutional representation (mostly governed by Anglophones) with the selection and management of tools and resources, hindering methodological and epistemological pluralism; (3)&hellip;[it] changes the representation of research in the field of DH and tends to project its own monolingual nature on the entire discipline <sup id="fnref1:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.</p>
<p>My work is a response to Fiormonte’s insistence that  “the cost of Anglophone monolingualism cannot be borne entirely by non-Anglophones”   <sup id="fnref2:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> and to Risam’s call to digital humanities scholars to use their training and skills to devise local practices that  “avoid a directional politics of knowledge that flows from the top down”   <sup id="fnref3:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>; I therefore attempt to unsettle categories of difference to revise and expand the existing digital cultural record.</p>
<p>Much like digital humanities, Italian Studies has struggled with  “inclusivity and the representation of traditionally marginalized voices”   <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Italian digital humanities projects to date tend to reproduce or recover the dominant Italian cultural canon and even so, there is  “little in Italian Studies scholarship in major digital humanities journals”   <sup id="fnref2:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Crystal Hall explains that  “one of the most notable aspects of Italian digital humanities from a North American perspective is the centrality of Dante in many prominent DH projects”   <sup id="fnref3:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Digital humanities scholarship related to Southern Italy is especially uncommon. Though projects such as  <em>The Medieval Kingdom of Sicily Image Database</em>   <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> illustrate promise for the future of Southern Italian cultural recovery projects in the digital humanities, there is still much work to be done to ensure that  “the [Southern Italian] stories and voices which have been underrepresented in both print and digital knowledge production…[and] marginalized in their national contexts — can be heard”   <sup id="fnref4:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. My work is an effort to respond to this lacuna in the field.</p>
<p>Walter Mignolo explains that one’s locus of enunciation or place of speaking, involves a recognition of how her personal histories, cultural backgrounds and ideological commitments shape her current behaviors and perspectives <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. My personal experience as a second generation Neapolitan-American and as a Professor of inform this project. As a an immigrant daughter, I have often felt like a linguistic outsider in both the Italian and American culture. Through long periods of time spent in Naples, and as a heritage language speaker in the K-16 system, I have experienced firsthand the type of linguistic and cultural biases I see many students of color struggle with as they try to negotiate their accented Englishes with the privileged Standard Englishes of the academy. My position as researcher is informed by these experiences, as is my argument for linguistic justice and a translingual ideology that emphasizes all languages as emerging, fluid, and contextual. </p>
<p>This project is also informed by statistics from UNESCO’s  “Atlas of the World’s Languages In Danger”   <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> and, more recently, the Endangered Language Alliance’s proclamation that  “Neapolitan is considered vulnerable to extinction due to the declining intergenerational transmission and overwhelming power and prestige of Standard Italian. Although there is a written form of the language, the majority of speakers do not write the language, and there is disagreement on how it should be written”   <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. My focus on Naples has cultural exigence as well. As a UNESCO World Heritage Site, the city of Naples and much of its periphery have  “retained the imprint of successive cultures that emerged in Europe and the Mediterranean basin,”   <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> making it one of the most unique linguistic and cultural centers in Europe. The evolution of the city dates back to the  “Neapolis founded by Greek settlers in 470 B.C.”   <sup id="fnref1:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> and has been described by Mediterranean scholars like Iain Chambers’s as follows:  “a violent mixture of antiquated street rites and global design capitalism, Naples confronts us as a riddle. It&rsquo;s sphinx like qualities… disclose and unstable hubris dissected by different cultures and historical rhythms”   <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. This article extends Chambers’ inquiry of the riddle that is Naples into the realm of social media.</p>
<p>Much like the concept of Italianitá or Italianness was constructed at the turn of the twentieth century in Italy through printed media as a way  “to consolidate national unity in the face of emerging nations and nationalism in Europe”   <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>, this article anchors the word Neapolitanitá to illustrate how Neapolitanness, or Neapolitan identity is constructed, revised or perhaps, expanded by translingual representations on YouTube. I also envision this article as a contribution to various studies of Southern Italy and Naples that reveal the deliberate marginalization of the regionNaples and its people such as Janet Schneider’s  <em>Italy&rsquo;s &lsquo;Southern Question&rsquo;: Orientalism in One Country</em>   <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>, Pino Aprile’s  _Terroni: All That Has Been Done to Ensure that the Italians of the South Became  Southerners _   <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> and Nicola De Blasi’s  <em>Storia Linguistica Di Napoli</em>   <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>. Though Naples may not be typically regarded as postcolonial, the region of Naples was historically colonized by various feudal or monarchical systems ending with the intra-colonization by the House of Savoy and pursuant establishment of a northern, Piedmontese national government through the project of Italian unification. Pasquale Verdicchio points out that  “Italian identity was consciously built on the presumed racial alterity of southerners”  (in <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>), while Antonio Gramsci’s  <em>Prison Notebooks</em>  (written between 1929-1935 by the philosopher, during his imprisonment from the Italian Fascist regime in power) explain that the unification project undertaken by the Risorgimento, or movement for the unification and independence of Italy, consisted of three interconnected elements: the perception of southerners as biologically inferior beings; the poverty of the southern masses that was inexplicable to the northern masses; the colonial choice of post-Risorgimento governments to move the potential conflict of the unemployed southern masses further south, in order to dispossess other presumed inferior populations of their own land and political autonomy <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. Naples’s political and cultural marginalization prevails:</p>
<blockquote>
<p>Like many Mediterranean cities, Naples refers to itself and its local hinterland long before the nation-state appears in its sense of identity… Once a capital, Naples has become an eccentric city without an obvious compass. Seemingly robbed of its destiny, its trajectory has been blocked by a loss that is seemingly incapable of confronting and working out.<br>
<sup id="fnref1:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> The national and cultural imaginary of Southern Italians, particularly Neapolitans, as poor, uneducated and vulgar has persisted a century and a half since Italy became a nation, as evidenced by organizations such as the overtly anti-Southern political party, the Northern League, which advocates for economic and political autonomy of Northern regions from its Southern counterparts. Nicola De Blasi explains how linguistic disenfranchisement followed political subjugation for Naples, though Neapolitan was the most widely spread language (not dialect) in the pre-unification Kingdom of Two Sicilies, and despite the fact that the use and global circulation of the Neapolitan language in art, particularly music and opera is evident as early as the 18th century <sup id="fnref1:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> and persists in popularity today.</p>
</blockquote>
<p>Much like digital humanists, media communication scholars have also investigated the relationship between media and cultural identity. In  “Cyberethnographic Research Methods for Understanding Digitally Mediated Identities,”  Natalia Rybas and Radhika Gajjala detail participatory practices such as interviews for studying Othered cultures’ social media use <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>. My research on Neapolitan-Italians aligns with the findings of these scholars, which illustrate that media clearly shapes cultural identities and, conversely, cultural formations influence the political economy of global media <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. Linguists have extended this type of ethnographic inquiry to determine how new forms of circulation and aspects of mediatization such as sound and aesthetics materialize language and cultural signification <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. My research follows linguist Jillian Cavanaugh whose recovery work on the marginalized Bergamasco Italian language and culture in northern Italy investigates the complex relationship between language and nation <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>  In particular, Cavanaugh’s  “Anything Can Happen on YouTube (or Can It?): Endangered Language and New Media”   <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> explores the implications of social media for linguistic preservation, visibility, and signification of Bergamasco Italian, as this article does for Neapolitan Italian.</p>
<p>While postcolonial digital humanities, media communications, and linguistic scholarship work together to inform this project, methodologically I turn to translingual theory together with Laura Gonzales’s  “Revised Rhetoric of Translation”  framework. Gonzales’s  “Revised Rhetoric of Translation”  is  “a culturally situated orientation to studying linguistic fluidity, one that intentionally situates language work within broader systems of power, privilege and oppression”   <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. Building on theory in Composition and English Studies that  “conceptualize and protect language difference at the level of policy [such as] CCCCs  “Students’ Right to Their Own Language,”  and NCTE’s  “Definition of 21st Century Literacies” ,”   <sup id="fnref1:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> Gonzales’s  “translation moments” <sup id="fnref2:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> make it possible to understand  “language difference at a level of practice”  (<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> in <sup id="fnref3:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>), particularly through digital platforms and how they intersect with language and cultural identity.</p>
<p>Composition scholars have referred to translingual composing practices as interconnected and integrated, mediated through one another, and continuously emergent <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. Especially in the world of social media, communication is fostered by a combination of modalities which overturn notions of linguistic standardization, and of what constitutes communicative  “capital”   <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>. Successful understanding for the interlocutors or what Suresh Canagarajah calls  “uptake” <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> is the primary object of translingual communication. Uptake is contingent on the linguistic and digital resources available to the writer/designer of a social media object and also reflective of the time and cultural context (or place) it is produced in.</p>
<p>It is important to note that  “By exploring various moments and sites of translingual encounter, we find ourselves in a position to revisit many of our foundational assumptions about, and therefore arrive at a fuller understanding of, what might constitute culture to begin with”   <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. YouTube is not only a site rife with  “translingual encounter[s]”   <sup id="fnref1:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>, but is also a generative tool for exploring the way  “linguistic and cultural difference can be located  <em>via</em>  [these encounters]”   <sup id="fnref2:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. I selected  “Miley Cyrus - Wrecking Ball - Parody (Explicit),”  as the focus of my analysis in this article, as it is a fitting Neapolitan example of a global, translingual encounter that resists the idea of language as a  “universal epistemology of communication”   <sup id="fnref3:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>, while countering a static, emplaced, Neapolitan cultural identity.</p>
<p>This article analyzes Neapolitan, a southern Italian, vulnerable language on YouTube, through a multimodal, translingual analysis which focuses first on the video  “Miley Cyrus - Wrecking Ball - Parody (Explicit),”  and then on the comments that follow the video. I examine the way the producers of the video harness the multimodal affordances of YouTube (video, audio, transcription) to advance the language beyond Italian borders, but also to consider how Neapolitans  “wish to be portrayed as public selves (local, national, international)”   <sup id="fnref1:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. By affordances, I refer to intersecting disciplinary perspectives of the concept. Technical communications scholar Stuart Selber’s premise that  “A technological affordance, or a suite of affordances, is  <em>directional</em> , it  <em>appeals</em>  to us by making some forms of communicative interaction possible or easy and others difficult or impossible, by leading us to engage in or attempt certain kinds of rhetorical action rather than others”   <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>. Like Selber, sociolinguists David Barton and Carmen Lee argue that  “perceived affordances”   <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> are the context for the  “action possibilities”   <sup id="fnref1:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> people take up in digital spaces. The authors argue the uses of digital platforms are not a given and are not fixed. Rather, people both create and are created by these environments. In this way affordances are [also] socially constructed and change as people act on their environment&hellip;for example, on Facebook the structure of the software creates likely activities and likely pathways, but human ingenuity leads to the wide range of uses it is put to <sup id="fnref2:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>.Similarly, the technical, social and communicative affordances of YouTube facilitate a global, translingual narrative of Neapolitanitá that may not be visible in Italian mainstream media or the cultural record at large. </p>
<p>Neapolitan language practices on YouTube reflect  “the highly distributed, embodied, translingual, and multimodal aspects of communicative practice[s]”  (<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup> in <sup id="fnref4:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>) in Neapolitans’ interaction with the site and underscore Gonzales’s premise that  “translation moments are inherently multimodal and multilingual, reflecting the lived experiences of multilingual communicators who constantly think across languages, modalities, and technologies, to transform and adapt information for various audiences”   <sup id="fnref5:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. Though Gonzales applies her theory to the work of multilingual translators in professional spaces, I argue that Neapolitans have energetically harnessed  “translation… a multimodal activity… that requires the rhetorical coordination of semiotic resources beyond alphabetic language”   <sup id="fnref6:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> to remix the Neapolitan language and create cultural counternarratives that upend the national imaginary of Neapolitan as vulgar and uneducated <sup id="fnref2:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> and of the people as terroni (people of the dirt or dirtballs) <sup id="fnref1:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. The translation moments afforded to Neapolitans through the multimodal options of social media such as YouTube enable a post-national Neapolitanitá: a remixed, hybridized linguistic and cultural imaginary that extends beyond the limited geographic boundaries of Italy.</p>
<h2 id="inventing-post-national-neapolitanitá">Inventing Post-National Neapolitanitá</h2>
<p>Neapolitanitá, or the cultural essence conveyed through the Neapolitan language, is closely intertwined with performance. Gestures, facial expressions, intonations, and words crisscross to create meaning that is interdependent on the mix of modalities. In short, using Neapolitan words alone in a conversation would detract from the interlocutors’ ability to specify meaning. Simply reading Neapolitan words on a page would nearly dilute signification altogether.</p>
<p>Representations of the material disenfranchisement of Neapolitans are circulated in new, material ways through social media spaces such as YouTube, supporting Risam’s argument that  “the internet gives us opportunities to look beyond ourselves and our institutions, to partner with our local communities . . . to create spaces in which we can make legible the stories that go untold and the voices that go unheard”   <sup id="fnref5:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. The embodied features of the Neapolitan language are materialized through the translingual affordances of social media platforms. Translingual practices involve dynamic and fluid movement between linguistic knowledge, alphabetic writing, and virtual-material modalities <sup id="fnref1:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. The affordances <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>  of YouTube, in particular, helps producers underscore the Neapolitan dialect as a material form of social interaction and practice, and to strategically present narratives of Neapolitans that are absent from Italian mainstream media and the cultural record at large.</p>
<p>The stagnant political economy of Neapolitan lives in Italy is depicted in Pino Aprile’s  _Terroni: All That Has Been Done to Ensure That the Italians of the South Became  Southerners. _  For Aprile,  “when such [disparate political and economic] difference exists [in a nation] for so long, one risks to no longer correctly attribute the reasons to the causes of the current situation, but rather to the inadequacy of those who continue to tolerate the status quo”   <sup id="fnref2:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. This unchanging national positionality has important connections to the material conditions that govern the choices Neapolitans make about language. These choices are embodied through bodily gestures, intonations, and facial expressions. The affordances of YouTube intersect with the  “vulnerable”   <sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> Neapolitan language to illustrate the institutional systems (political, economic, and social) that direct Italians toward a determinate view of Neapolitans. This socio-political economy is often the content or subject of Neapolitan representations or exchanges on social media platforms such as YouTube.</p>
<p>As political scientist Michael Warner notes,  “The direction of our glance can constitute our social world”   <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>. A Neapolitan YouTube video can reconstitute the social world the Neapolitan language and people are from, enabling counternarratives of Neapolitanità that resist the national (geographically bound) imaginary of the region and its people. YouTube, a global social media platform, moves Neapolitanitá beyond Naples and Italy to a place where it can be consumed anywhere in the world, at any time of day, by Italians or anyone else. The repeated, collective consumption of YouTube videos fosters circulation and socialization about language and culture that were impossible pre-Web 2.0.</p>
<p>Jillian Cavanaugh’s analysis of the endangered Bergamasco Italian dialect on YouTube identifies categories or types of videos that contain the language: (1) videos taken from some other media source (usually television or film) and dubbed into Bergamasco, transforming the content such that the speakers speak not only Bergamasco, but  _as _ Bergamasco; and (2) originally produced videos with spoken (and sometimes written) language in Bergamasco <sup id="fnref2:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. The Neapolitan YouTube case study I describe below falls into Cavanaugh’s two categories. It remakes or remixes an originally produced film or video (Miley Cyrus’s original  “Wrecking Ball”  video) into a YouTube iteration that looks back at particular cultural inheritances Neapolitans embody, hybridizing conventional scripts of Neapolitan language and identity  <em>in Italy.</em>  In other words, the video below reimagines and revises dominant ideologies and narratives of Neapolitans, particularly those that are emplaced in the national, geographically bound context of Italy.</p>
<p>YouTube’s digital, social, and paralinguistic affordances create a post-national space where Neapolitan language and identity exceeds national or emplaced physical and ideological boundaries. Through each YouTube post, like, dislike, comment, and share — versions of the dialect can extend across objects (as hyperlinks, shares, and, indirectly, other social media platforms) and others (as viewers, followers, and content communities beyond YouTube) that may disrupt or even overturn the language’s definitely endangered status and forge a post-national Neapolitanità. Neapolitans use the affordances of YouTube to use translation as transformation and  “… think across languages, modalities, and technologies, to transform and adapt [their language and culture] for various audiences”   <sup id="fnref7:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. YouTube gives Neapolitan user/producers an opportunity to affect translation moments that redefine the uses of Neapolitan and what Italian nationalists have determined to be authentic Italian linguistic and cultural capital. The same implications apply for other vulnerable or endangered languages on YouTube, such as Bergamasco, Sicilian, and Nones, which are other minority Italian languages. Such languages, formerly regarded as emplaced and incapable of being useful or used beyond a specific national boundary or location, that are presented on YouTube through videos such as the one I describe below can challenge purist ideas of language, culture, and identity. YouTube representations of these supposed minority languages and cultures enable alternative perceptions and circulation for them, altering their positionality in a national and global context. The way producers and users engage through specific kinds of YouTube videos and other digital objects like them creates new linguistic and cultural counternarratives that rupture users’ orientations toward nation as a point of origin. Post-intercolonial, post-national conceptions of Neapolitanitá become possible through the digital and communicative affordances of YouTube.</p>
<h2 id="parodia-napoletana-di-wrecking-ball-and-remixing-neapolitanitá">Parodia Napoletana di Wrecking Ball and Remixing Neapolitanitá</h2>
<p>“Miley Cyrus-Wrecking Ball-Parody (Explicit)”   <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> is one case study of Neapolitanità on YouTube that can be classified into what compositionists have long called a remix <sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup>. Like Cavanaugh’s examples of Bergamasco on YouTube, this parody is taken from another media source and produced in Neapolitan so that the speaker sings not only in Neapolitan but  _as _ a Neapolitan, using specific language to affect Neapolitan identity. The YouTube video I discuss here does this work by parodying the iconic pop singer Miley Cyrus’s worldwide musical blockbuster video  “Wrecking Ball.”  The publishers of this YouTube channel, <a href="https://www.youtube.com/user/frankEcerrone/about">frankEcerrone </a> boast 87,900 subscribers and 32,747,359 views for this channel from the December 6, 2010 date the channel was created to the March 29, 2022 date this analysis was completed, indicating a tremendous scope of audience. The translated description of the producers’ channel states:  “Hello guys! We are Frank and Cerrone and on our channel you will find parodies of Neapolitan songs of the moment, short sketches, Jokes and videos at [and about] Naples and Neapolitans. In short, we will invent anything to make you laugh :) Have fun!!!”   <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>.</p>
<p>The FrankeCerrone YouTube channel’s many interviews, skits, and parodies are comedic in nature, and hybridize and materialize Neapolitan language and culture. More importantly, videos like the one discussed below represent Neapolitanitá in new, translingual ways that exceed notions of cultural and linguistic purity and create a post-regional, post-national Neapolitan identity — one that extends beyond the physical location of Naples and defies the national disenfranchisement of Neapolitans and creates a Neapolitan linguistic and cultural diaspora. Neapolitan producers on YouTube exploit digital and social affordances to circulate counternarratives that are often made invisible through the images of Neapolitans circulated through Italian national media (and the digital cultural record writ large).</p>
<p>Through the audio and visual affordances of YouTube,  “Miley Cyrus-Wrecking Ball-Parody (Explicit)”  astutely reimagines the use of a top-ten, global, pop video to create a tragi-comic labor advocacy video that illustrates the alienated plight of the working-class subject in Naples, Italy. frankEcerrone strategically choreograph the  “Miley Cyrus-Wrecking Ball-Parody (Explicit)”  in ways that revise the myth of language and cultural identity as nationally emplaced <sup id="fnref3:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>.  “Miley Cyrus-Wrecking Ball-Parody (Explicit)”   <sup id="fnref1:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> not only counters the national imaginary of the Neapolitan language and culture, but it also strategically repositions objects traditionally associated with male or female gender and sexuality so that these ideologies (in this case, Italian, patriarchal, heteronormative) also are disrupted. The video particularly exemplifies the cultural and linguistic potential for other minority, vulnerable, and/or endangered communities to push back at emplaced, national, patriarchal narratives that restrict the uses and experiences of their languages and communities.</p>
<p>The repurposing of objects from Cyrus’s original  “Wrecking Ball”  video in this one (e.g., blondish hair, blue eyes, clothing, tears) recasts colonial, patriarchal depictions of working-class Neapolitan men and pleads for a more egalitarian working landscape in Naples and the transnational culture that reifies these biases. A blonde and blue eyed male is much more typical of Northern Italy, therefore, superimposing Northern Italian male characteristics onto a Neapolitan body (that hybridizes the female body of a global American pop star) reflects layered  “rhetorical manipulation…by [producers] who are part of or familiar with the community for whom they are translating”   <sup id="fnref8:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> Neapolitan language  <em>and</em>  cultural identity:</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000680/resources/images/figure01.jpeg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000680/resources/images/figure01_huc2957d9a12ebd24c41addbb52d0a700d_21163_500x0_resize_q75_box.jpeg 500w,
    /dhqwords/vol/17/2/000680/resources/images/figure01_huc2957d9a12ebd24c41addbb52d0a700d_21163_800x0_resize_q75_box.jpeg 800w,/dhqwords/vol/17/2/000680/resources/images/figure01.jpeg 618w" 
     class="landscape"
     ><figcaption>
        <p>Superimposing a Northern Italian Looking Male on Miley Cyrus’s Female Body
        </p>
    </figcaption>
</figure>
<p>The producers likely use an actor with Northern Italian physical characteristics as a way to attract a Northern Italian viewing audience but also as  “rhetorical manipulation”   <sup id="fnref9:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> laced with humor that forces Northern Italians to see themselves in a socio-economic position many Neapolitan Italians experience. frankEcerrone co-author a revisionary post-national Neapolitanità that pushes back at nation-based, intra-colonial, homogenized, patriarchal views of language and identity. The translated version of Neapolitan identity and culture through frankEcerrone’s  “Wrecking Ball-Parody (Explicit)”   <sup id="fnref2:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> disrupts the intra-colonizer-colonized binary, rupturing static conceptions of Neapolitanità or Neapolitan identity for a public beyond Italy illustrated by the 1.3 million views, 9500 likes/dislikes, and 506 comment/replies as of the date of this analysis.</p>
<p>In one of the early images in the parody, the actor imitates Miley Cyrus hammering away at the metaphorical pieces of her ended relationship. The irony in the Neapolitan version is that the backdrop of the video signifies the real life and career of a typical bricklayer or muratorr as frustrated, overworked, and underpaid while Cyrus is an affluent Western celebrity who probably has never picked up a sledgehammer in her life except as a prop in her video. The words the actor sings in Neapolitan are subtitled in English throughout the video, though not the standard English <sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup> Americans might be accustomed to hearing, but an accented, or global version. This reflects deliberate translanguaging, or a multimodal and linguistic  “multicompetence that functions symbiotically for the different languages in one’s repertoire”   <sup id="fnref1:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>:</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000680/resources/images/figure02.jpeg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000680/resources/images/figure02_hu329745b9c1da51f46681577cb9dcd94e_46686_500x0_resize_q75_box.jpeg 500w,
    /dhqwords/vol/17/2/000680/resources/images/figure02_hu329745b9c1da51f46681577cb9dcd94e_46686_800x0_resize_q75_box.jpeg 800w,/dhqwords/vol/17/2/000680/resources/images/figure02.jpeg 658w" 
     class="landscape"
     ><figcaption>
        <p>Repurposed Objects, Translingual Captions
        </p>
    </figcaption>
</figure>
<p>In the above clip, the actor sings the lyrics  “stong’ na munezz’”   <sup id="fnref3:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> which translates directly as I am or I feel like garbage but is instead subtitled  “I’m a piece of sheet.”   <sup id="fnref4:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> An Other-English-variety viewer might infer that the subtitle is meant to read I’m a piece of shit, however, the seemingly inaccurate translation succeeds partly because the images, objects and other subtitles in the video co-signify to inform the meaning of this particular segment, and also because the humorous depictions of the actor detract from the awkward sounding sheet. The producers might also intend a double entendre in this case where sheet could be interpreted as the lifeless, dull sheetrock that is typically present on a construction job site as well as a reflection of the actor’s socio-economic position, one that is unacknowledged or supported by the economic framework he is stuck in.</p>
<p>The producers take a popular, global, digital object, the  “Miley Cyrus - Wrecking Ball (Official Video)”   <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup> and recreate it with an actor that not only sings in Neapolitan, but  <em>as a Neapolitan</em> , repurposing the objects of the original video to rescript a narrative that focuses on local issues which are still rampant in the region of Naples today such as the lack of employment opportunities, compensation, benefits or social safety nets for many under-educated, hard working manual laborers. The producers co-opt Cyrus’s theme of lost-love desperation, with the actor singing his local version of despair in the Neapolitan language, while his hair and clothing clearly imitate Cyrus’s in the original  “Wrecking Ball”  video:</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000680/resources/images/figure03.jpeg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000680/resources/images/figure03_hu15bde9a5d69c47f92637694fd0f460b1_30474_500x0_resize_q75_box.jpeg 500w,
    /dhqwords/vol/17/2/000680/resources/images/figure03_hu15bde9a5d69c47f92637694fd0f460b1_30474_800x0_resize_q75_box.jpeg 800w,/dhqwords/vol/17/2/000680/resources/images/figure03.jpeg 656w" 
     class="landscape"
     ><figcaption>
        <p>Cyrus’s Unrequited Labor of Love
        </p>
    </figcaption>
</figure>
<p>frankEcerrone’s deliberate use of the objects of Cyrus’s video to co-signify with the Neapolitan dialect and the narrative contained therein is pointed and also satirical, which many of the comments (discussed later in the article) reflect upon. Cyrus fetishizes the objects of working-class culture (in one part of the video she licks the sledgehammer) to eroticize her performance of heartbreak and lost love while the objects in her video — masonry tools, work boots, stark drywall — are repurposed in Frank Cerrone&rsquo;s video to reshape the significance and use of labor (emotional in Cyrus’s version but physical and emotional in frankEcerrone’s) that Cyrus represents.</p>
<p>It is important to note that the humor that frames the frankEcerrone video not only illustrates  “critical understanding of [rhetorically and culturally situated] communicative practice”   <sup id="fnref10:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> but is also a  “disruptive [strategy which facilitates] a creative engagement with others, demonstrating both a knowledge of cyberculture activities as well as a… performative complexity”   <sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>. Neapolitans love what they refer to as a chiacherr’ or the gift of gab peppered with a barzellett’, or a joke, which the producers of this video are astutely aware of. They use this situated cultural knowledge to present a light version of the repetitious, mundane routine a manual laborer in Naples might experience. The clip below is a clear instance of humor as rhetorical strategy:</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000680/resources/images/figure04.jpeg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000680/resources/images/figure04_hu59af74d6352bcfb435e4c7fbeddfb8f9_32639_500x0_resize_q75_box.jpeg 500w,
    /dhqwords/vol/17/2/000680/resources/images/figure04_hu59af74d6352bcfb435e4c7fbeddfb8f9_32639_800x0_resize_q75_box.jpeg 800w,/dhqwords/vol/17/2/000680/resources/images/figure04.jpeg 573w" 
     class="landscape"
     ><figcaption>
        <p>“I Eat the Same Sandwich Every Day”
        </p>
    </figcaption>
</figure>
<p>The lyrics in this part of the video  “me mang’ semp o stress u panin’&hellip;o speck e o galbanin’”   <sup id="fnref5:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> translate directly to  “I eat the same sandwich everyday…prosciutto and cheese,”  though the subtitles do not reflect this exact wording. The meaning is clear however: a typical, enjoyable Neapolitan snack (a sandwich is not considered a proper lunch in Naples), becomes part of the soul crushing routine the bricklayer cannot escape as part of his workday. This moment in the video reifies the lack of choice the bricklayer or murrator has in his choice of profession, especially after 30 years (as stated in later lyrics), and the feeling of entrapment that comes with that lack of choice. Unlike many white collar professionals and business owners in Italy who have a long, sanctioned midday break for a hot pranzo or lunch at home or a local restaurant, the murrator is limited in the length of his work break (only 30 minutes as later lyrics illustrate) and therefore, he is also limited in his selection of lunch foods. Humor is strategically invoked as  “performative complexity”   <sup id="fnref1:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup> in this part of the video because the sandwich disrupts the rhetorical continuity of the bricklayer/work related artifacts. The sandwich looks fresh, appetizing, and even enjoyable, so it is therefore ironic that this too is repurposed to signify part of the bricklayer’s burdensome life.</p>
<p>As evidenced earlier, some subtitles of the parody are English translations that do not always convert directly from the Neapolitan. The clip below illustrates faulty translation as well, and is one of many in the video that illustrates  “translation as a multimodal practice…with critical attention to how modes like visuals, sounds, and words work together to create meaning for various stakeholders”   <sup id="fnref11:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. The actor sings  “numé paven’ e contributt”   <sup id="fnref6:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> which translates directly to  “they don’t pay my contributions,”  a phrase that may not be clear to non-Italian viewers:</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/17/2/000680/resources/images/figure05.jpeg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000680/resources/images/figure05_hudec3b15a2ad8ae0dd1c27eaf80ac688e_34035_500x0_resize_q75_box.jpeg 500w,
    /dhqwords/vol/17/2/000680/resources/images/figure05_hudec3b15a2ad8ae0dd1c27eaf80ac688e_34035_800x0_resize_q75_box.jpeg 800w,/dhqwords/vol/17/2/000680/resources/images/figure05.jpeg 607w" 
     class="landscape"
     ><figcaption>
        <p>No Benefits or Healthcare
        </p>
    </figcaption>
</figure>
<p>Though the subtitle  “my boss even doesn’t pay my taxes”  may be an imperfect translation in this case, the actors body language, coupled with the concrete rubble and somber turn in the sounds of the music to clarify, and even amplify lyrics. Manual laborers may be hardworking and dedicated, but particularly in Naples, they are exempt from the benefits of institutional labor that is handsomely rewarded with social security, healthcare, and other employee benefits in Italy (derived by taxes the institutional owners pay on behalf of the employee to the state). The laborer who works 30 years without any of these benefits is, indeed, broken. English and Neapolitan are strategically hybridized in this digital artifact (the parody) to create a new, translanguaged  “Wrecking Ball”  video, one that ironically  <em>exceeds</em>  Cyrus’s 1.1 million video views by almost 130,000 viewers as of the date of my analysis. where Neapolitan’s presumably endangered dialect and English’s global lingua franca intersect across multiple modes to affect uptake between producers and viewers, commenters and repliers <sup id="fnref2:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>. The result is a global  “Wrecking Ball”  that demonstrates  “social-semiotic acts and moments,”  which  “produce and stabilize but more significantly, unmoor”   <sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup> static or one-sided representations of language, labor, class, gender, ethnicity, and perhaps even romantic suffering.</p>
<h2 id="transnational-translingual-transmodal-comments">Transnational, Translingual, Transmodal Comments</h2>
<p>Though the comment section of  “Miley Cyrus-Wrecking Ball-Parody (Explicit)”   <sup id="fnref7:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> video mostly illustrates translingual or mixed semiotic responses, there are certainly comments that reify stereotypes of Neapolitans. In her analysis of northern Italian Bergamasco on YouTube, Jillian Cavanaugh finds that:  “these . . . videos [reflect] the dominant Bergamasco language ideologies and social stereotypes, in which Bergamasco is associated with maleness, a working class or peasant socioeconomic position, roughness, straightforwardness, the value of hard work, as well as deep connections to the past”   <sup id="fnref4:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. The language ideologies and social stereotypes that Cavanaugh describes as tied to Bergamasco are typical associations for Neapolitans and Neapolitanità as well. These associations are depicted not only through the content of the video itself (e.g., the male actor, the video’s theme evidenced by a working class socioeconomic position), but also through the comment section. Some of the comments of this video reflect the emplacement of the Neapolitan language and the Northern-Southern binary and divide that exists in the national imaginary of Italy, also are reflected in the comments of  “Miley Cyrus-Wrecking Ball-Parody (Explicit)”   <sup id="fnref8:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> by frankEcerrone, while others represent metalinguistic and cultural analyses, often through intercultural dialogue.</p>
<p>The potential for community building is a social and communicative affordance of YouTube, one that has strong implications for the way languages and cultures are perceived. This notion of community is partly illustrated through YouTube’s digital affordance which enables producers to link their videos and channels to other social media platforms and objects in order to increase their follower base. The comment feature of YouTube is another space where users’ orientations toward the video and one another foster community and reshape Neapolitanità. The comments are one of the most visible and interactive social affordances of YouTube (unlike the share and like buttons, which may be overlooked). The interpretive frame of commenting expands social boundaries around the song and performance, fostering engagement with the Neapolitan language and Neapolitanitá (or Neapolitan identity) beyond Naples and Italy. The commenting feature of YouTube is a social and communicative affordance of YouTube that  “disrupts codes of tacit social interaction”   <sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup> because commenters’ identities are largely undisclosed, making their social interaction virtual and multimodal. Therefore, viewers might be from Italy or Naples or from the Neapolitan and/or Italian Diaspora, but they can also be from other parts of the world.</p>
<p>Although one might make some assumptions about a user/viewer’s identity by clicking on the commenter’s username and accessing their  “About”  page, YouTube users do not typically reveal detailed information on this platform as they might on Facebook where aforementioned detailed personal information categories are offered for producers to populate and Friends and Followers to view. And, while YouTube viewers can also look at video producers’ or commenters’ Home, Videos, Playlists, Community, and Channels tabs to garner more detailed information about other commenters, these objects do not always indicate clear cultural or other identity markers, and they may not serve to further a connection among the viewers. This distanced communication is important in that it differs from the tribalization often observed on gaming and other social media sites <sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>. The global community fostered through anonymity on YouTube here is more likely to ignore coercive cultural norms (though these may include politeness and interaction), in favor of freedom of speech. It is precisely this type of freedom that I argue may be necessary to reconstitute Neapolitanitá in the national and global imaginary.</p>
<p>The comment section of the video is a cultural  “contact zone”   <sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup> which enables the translingual, transmodal translation moments for Neapolitans that I address in this case study. I use Gonzales’s definition of  “translation is a multimodal practice”  as an analytical framework that reflects:</p>
<p>Decentering of alphabetic language and of alphabetic, written language in English (what some scholars describe as standardized written English) as the single or most important element of communicative practice (<sup id="fnref2:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> in <sup id="fnref12:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>);  Rhetorical awareness of how modalities and genres function in different contexts for various audiences (<sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup> in <sup id="fnref13:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>);   Purposeful and rhetorical layering of modes and media, with critical attention to how modes like visuals, sounds, and words work together in creating meaning for various stakeholders (<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup> in <sup id="fnref14:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>); and  Critical understanding of how communicative practice is always rhetorically and culturally situated (<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>; <sup id="fnref1:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>; <sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup> in <sup id="fnref15:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>).</p>
<p>Gonzales’s multimodal translation practice enables the producers and users of this YouTube video to foreground the materiality of the Neapolitan language  <em>and</em>  of the material, lived experiences of Neapolitans. Shankar and Cavanaugh’s language and materiality theory explains that  “looking at the linguistic and the material together is both a theoretical AND methodological choice . . . that takes into account material AND linguistic labor”   <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>. Translingual theory posits that  “language is constantly in motion, [and] the words that we use to describe specific concepts or ideas shift and transform with our cultural norms and practices”   <sup id="fnref16:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. Producers of multimedia, such as frankEcerrone, have to  “echo this flexibility and fluidity, constantly changing their practices as languages and linguistic patterns evolve”   <sup id="fnref17:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. Gonzales’s translation framework carefully weighs the strategic communicative choices interlocutors make in a specific context, such as the particular date and time users might access frankEcerrone’s YouTube parody. Other semiotic/rhetorical choices that  <em>A Revised Rhetoric of Translation</em>  weighs include visual, audio, gestural, and spatial decisions — choices that greatly impact the  “materiality of language”  that Shankar and Cavanaugh discuss. In this example, YouTube’s communicative affordances enable a post-national, postcolonial, translingual, transmodal dialogue through the comments section that foregrounds linguistic and cultural materiality of Neapolitans.</p>
<p>The comment/reply section of this video spans from September 9, 2013 (the date the video was first published) to March 29, 2022 (the date of access), with the most recent comments posted on March 12, 2022. I used the data sorting features of Google Sheets to categorize a total of 506 comments and replies. In their research, Halpern and Gibbs have illustrated how users’ anonymity on YouTube engenders less deliberation in the comment section and a stronger tendency to share what comes to mind <sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>. My findings through the 506 comment/reply thread illustrates a lack of deliberation in some places; however, these findings also reflect a transnational, transmodal dialogue that defies the fixed emplacement of the Neapolitan language and culture. The comment/replies whose language I could decipher on this video are written in Neapolitan, Italian, English, Dutch, Spanish, Portuguese, Norwegian, Croatian and Azerbaijani illustrating a number of YouTube viewers/users from beyond Italy and beyond an Italian/Neapolitan diaspora. Most comments are translingual, reflecting a combination of two or more languages (Neapolitan and Italian, Neapolitan and English, etc.) or transmodal (reflecting words  <em>and</em>  emojis or other non-alphabetic characters such as :). Forty percent of the comment/replies simply illustrate whether users like or dislike the video. However, a more interesting facet of this YouTube comment dialogue is how translations of either the lyrics the actor in the video uses or of the subtitles of the video rupture a singular interpretation of the video, instead offering a co-created meaning of the text, and subsequently, of Neapolitan language and identity.</p>
<p>For example, user xLinkTijgerFan’s post reflects typical translation moments in the comment/reply thread through the way they post their question in Dutch first and then follow it with an English translation; they receive a reply from an Italian user (Auroretta, whose YouTube  <em>About</em>  page only has Italian information), who opts to reply in English, misspelling the word language. Interestingly, the translingual dialogue reflects the translingual object or video as illustrated in comment examples listed below. xLinkTijgerFan3 poses his metalinguistic question in both Dutch  <em>and</em>  English:<br>
What language is this?    User  Date Stamp  Comment/Reply  Translation of Comment      xLinkTijgerFan3  4 years ago  Heyo welke taal is dit? omdat ik er niets van versta want ik ben Nederlands  What language is this? because i can’t understand what he’s saying because i speak Dutch      Auroretta 1564  4 years ago  Evelien Rostie it’s a naples leanguage  -   <br>
Other posts are also translingual, mixing languages in a singular post. For example, the user psyco_F25 in Table 2 asks  “Who, like me, was raised with this song? Like it if you are watching it in 2020”  (my translation).<br>
Who grew up listening to this song?    psyco_F2  5 months ago  Chi e come me che e cresciuto con questa canzone ? Like per chi lo vede nel 2020   <br>
The commenter in this case mixes the English word like with their Italian words, translanguaging their request for fellow commenters to like their comment if they feel a shared experience with the song.</p>
<p>Similarly, user/viewers use emojis to create affect that compliments alphabetic text or as word substitutes, in some cases. For example, the post in Table 3 translates to  “you’re a monster”  followed by two laughing emojis that extend the meaning of the words in the comment to intend sarcasm or humor versus an intentional slur. In fact, sij nu mostr is a compliment in Neapolitan slang, indicating the recipient of the compliment is huge or great. The laughing emojis emphasize the humorous use of the word monster in this case:<br>
You’re a monster    Antonio Candia  4 years ago  sij nu mostr😂😂   <br>
In Table 4, Stascema qui, posts:  “At first it looks like German”  with two laughing emojis indicating that the transcultural aspect of the video makes it humorous.<br>
At first, it looks like German     stascema qui  1 year ago  All’inizio sembra tedesco😂😂   <br>
Semiotic objects such as emojis assume the same importance as the written word, often shifting or emphasizing the signification of the comment. Without the emojis, this comment could have been interpreted otherwise.</p>
<p>Some non-Italian user/viewers announce their desire to see the video in their native tongue, such as TheDanySP whose post in Table 5 translates  “Why don’t you translate it into Spanish?”<br>
Why don’t you translate it in Spanish?    Request for translation in Spanish      TheDanySP  3 years ago  POR QUE NO LO TRADUCIERON AL ESPAÑOL &gt;:v   <br>
There is a trend in this short list of non-English users’ comments (evidenced by their names and, sometimes, the information available on their own YouTube  “About”  pages) written in English, which is unsurprising, as English is a global language (though problematically global per post-colonial theory), and therefore a cultural norm that is co-opted by the producer of the video through the subtitles intended to translate the Italian parody. Table 6 illustrates a Bulgarian name commenting in English.<br>
It’s cool parody!    Трикси Аллен  3 years ago  It’s cool parody!   <br>
Language and identity are fodder for discussion in the comments, as evidenced by some of the examples above. Some comments respond to the gender-play the video is imbued with through the male iteration of the female Cyrus’s sexy performance, as shown in Table 7.<br>
Ciccio is gay    vincenzo desiderio  4 years ago  ciccio è gay   <br>
In this comment by Vincenzo Desiderio, a person with an Italian name but whose Italian identity cannot be verified (i.e., there is no info on his YouTube  “About”  page), says the actor in the video is gay. Although the comment may appear innocuous, it is prefaced by ciccio, which can be used in a derogatory sense in Italian to mean chubby or fat or simply a rude way to summon someone over (as in saying Yo! vs. calling a person by name). However, in some Northern Italian regions, ciccio, is also used as an endearing term among friends. Either way, the user comments on the reconfiguration of male/female objects/portrayals in the video and comments on the sexual identity of the actor in the video, move beyond the focus of the majority of the comments which center on superficially liking or disliking the video.</p>
<p>For example, of the 506 comments and replies analyzed regarding this video, approximately 16% reflect metalinguistic commentary (language about language) and 16% reflect a social commentary fostered by the content of the video and either connected to local, emplaced (Italian) issues or related to a  “shared moral community…[that is] non-geographical”   <sup id="fnref5:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. For example, a particularly long, contentious comment/reply section (see Table 8) offer a metalinguistic and social commentary that constructs and maintains provincial, national tensions that  “replicate long standing prejudices that divide Italians amongst themselves and problematize the presence of non-Italian immigrants”   <sup id="fnref6:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> indicated by the word Arab in this thread which might refer to recent Italian immigrants from the Middle East  <em>or</em>  Africa <sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>.</p>
<p>The comment/reply section begins with a question that many others in the comments ask, What language is this? But, this particular comment/reply grouping begins with an assumption by commenter Matteo who asks  “what language is it arab?”  reflecting Eurocentric colonial attitudes that have historically been linked to Southern Italians <sup id="fnref3:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. The dialogue starts off contentious with Matteo Patrian replying to Ferdinando YT that the Neapolitan dialect, is in fact, Arabic (or a derivative of Arabic) with the words  “eh appunto,”  which translates  “that’s my point” :<br>
what language is it arab?    User  Date Stamp  Comment/Reply  Translation of Comment      Matteo  5 years ago  che lingua é? araba?  what language is it arab?      Ferdinando YT  5 years ago  Matteo Patrian dialetto di napoli  Matteo Patrian dialect of Naples      Matteo  5 years ago  Ferdinando YT eh appunto  Ferdinando YT that’s my point      ThomerOfficial  5 years ago  sai cosa vuol dire dialetto, o sei troppo ignorante da capirlo  you know what dialect means, or you are too ignorant to understand it      Valeria Esposito  5 years ago  Matteo Patrian napoletana lingua  Matteo Patrian Neapolitan language      Matteo  5 years ago  Tommaso Arena sono abbastanza intelligente da capire che voi e l&rsquo;Italia siete due cose ben separate  Tommaso Arena I am intelligent enough to understand that you and Italy are two very separate things      ThomerOfficial  5 years ago  Matteo Patrian infatti io non sono napoletano ma sono umano tu invece sei un razzista e pezzente  Matteo Patrian in fact I am not Neapolitan but I am human you instead are a racist and beggar   <br>
Matteo’s insistence throughout the comment thread that Naples and Italy are  “two very separate”  things incite a 14-line dialogue (one of the longest) in the comments, with users debating the Northern-Southern divide, and making assumptions about one another’s Italian origins. The dialogue reflects  “ campanilismo  or the belief that everyone who lives within the same bell-tower or  campanile  shares similar tastes, language practices, and beliefs”   <sup id="fnref7:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. Though no bell-tower is in sight on YouTube, these types of comments co-construct one and over-emphasize  “living in a place with having certain values and habits”   <sup id="fnref8:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. In this case, a metalinguistic comment becomes a social commentary that ties the Neapolitan language directly to a low-class cultural identity (see Table 9), as is evident in Matteo’s comment  “I also have many friends from the south (Calabria, Salerno ..) who have lived here for years and they are the first to say that their (ex) countrymen are low class! And also from how they speak, they only ruin Italy, which is already made of shit”  (Matteo Patrian 2017 in <sup id="fnref9:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>):<br>
What did the people of the south do to you that you hate them so much?    User  Date Stamp  Comment/Reply  Translation of Comment      ThomerOfficial  5 years ago  Matteo Patrian perche cosa ti ha fatto la gente del sud da odiarli cosi tanto, io SONO amico di tanti del sud e ti dico che sanno il significato di famiglia a differenza del nord, e gente che esprime amore , purtroppo i mass media rovinano la mente  Matteo Patrian What did the people of the south do to you that you hate them so much? I have many friends from the south and I tell you that they know the meaning of family unlike the north, and people who express love, unfortunately the mass media ruin the mind      Matteo  5 years ago  Tommaso Arena anche io ho molti amici del sud (Calabria, Salerno..) che vivono qui da anni e sono loro i primi a dire che i loro (ex) compaesani sono gentaccia! poi anche da Come parlano, rovinano solo l&rsquo;Italia, che già è messa di merda.. che poi i luoghi la al sud sono spettacolari, ci sono alcuni luoghi dove c&rsquo;è brava gente! alcuni luoghi, magari non bellissimi, dove è la gente che li anima! ma solo alcuni luoghi, niente di più!  Tommaso Arena I also have many friends from the south (Calabria, Salerno ..) who have lived here for years and they are the first to say that their (ex) countrymen are low class! And also from how they speak, they only ruin Italy, which is already made of shit .. that the places in the south are spectacular, there are some places where there are good people! some places, perhaps not beautiful, where people are the ones who animate them! but only some places, nothing more!      Stefano  5 years ago (edited)  A Mattè fa na bella cosa&hellip; Cerca di andarte a fare in cu.lo tu e tutti quelli che la pensano come te. Rompete tanto li cojo.ni eppoi siete i primi ad andare al sud a farvi le vacanze. Quando magnate tutti bravi. Ps. NON SONO NAPOLETANO, si vede MA SONO ITALIANO.. Mer.da  A Mattè does a good thing &hellip; Try to go fuck yourself, you and all those who think like you. You all break balls and then you are the first to go south to take your holidays. When you eat there all is good. Ps. I AM NOT NEAPOLITAN, you can see BUT I AM ITALIAN .. [you] Shit   <br>
Though comments like these indicate that Neapolitan and stereotypes surrounding Neapolitan identity are not necessarily transformed on social media, the total of 506 comments and replies are punctured with other rhetorical moments that help to construct both a revised Italian  <em>and</em>  post-national public  “in which the language in use is less idealized and purified than in other publics”   <sup id="fnref9:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> and also illustrate a translingual  “blending and a movement of discourses as individuals make meaning from person to person”   <sup id="fnref18:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> as illustrated in earlier examples and in Table 10, below, where a dialogue about the Neapolitan language between an Italian and a Greek user is written mostly in English, despite the users’ national ethnicities:<br>
Is he talking in Italian or another language?    User  Date Stamp  Comment/Reply (Original Language)      Konstantina Gkazou  6 years ago  Is he talking Italian or another language?      Sabrina Grimaldi  6 years ago  he&rsquo;s talking NAPOLETANO an italian dialect. I&rsquo;m italian and i talk napoletano. (sorry for my english&hellip;)      Konstantina Gkazou  6 years ago  @Sabrina Grimaldi omg ! Even the name of that dialect sounds pretty interesting ! Your English are OK I don&rsquo;t think you did a mistake ( I&rsquo;m Greek by the way so &hellip;.never mind no one will test us )   <br>
The comment/reply thread is also rife with translation moments, where users  “consider the specific histories and backgrounds of their intended audiences, understanding regional and historical variations of specific languages…that might influence how information is perceived in a particular stance or utterance”   <sup id="fnref19:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. Table 11, below, illustrates a translation of alphabetic text, correcting words in the subtitles of the video, which other commenters also pointed to as being inaccurately funny, or generated by an automated translator, and therefore faulty:<br>
When you sing  “my back is in pieces”       User  Date Stamp  Comment/Reply  Translation of Comment      Giuseppe Samo  8 years ago  When you sing  “ teng&rsquo; e rin à piezz ”  on the subtitles appear kidneys. Actually, le rin is the back.  When you sing  “my back is in pieces”  on the subtitles appear &ldquo;kidneys&rdquo;. Actually, &ldquo;le rin&rdquo; is the back.   <br>
Independent, though ideologically unified comments in Table 12 (below) reflect  “translation as a culturally situated practice, one that expands conceptions of translation from…a one to one replacement of words in the first language to words in the second language…to community-based rhetorical contextualization”   <sup id="fnref20:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. Here, users agree on a tragi-comic translation of the video based on their lived experiences and perhaps, based on the lived experiences of their fellow commenters:<br>
“The only true song about the problems of life”     User  Date Stamp  Comment/Reply  Translation of Comment      TitanKekko 34  2 years ago  L unica canzone vera che parla dei problemi della vita. Peccato che con questo caldo mio padre mette l asfalto sui tetti della gente.  The only true song about the problems of life. Too bad that in this heat my father puts asphalt on people&rsquo;s roofs.      Tonyparker88  2 years ago  Questa canzone è divertente da una parte, ma dall&rsquo;altra fa riflettere, quindi ci sta tutta.  This song is fun on the one hand, but on the other it makes you think, so it fits.      Giuseppe rossi  3 years ago  Con questa parodia c&rsquo;è da ridere, ma nello stesso tempo da piangere per la realtà dei fatti&hellip;&hellip; Si può fare insieme&hellip; Oppure alternato&hellip; Un po&rsquo; ridi e un po&rsquo; piangi&hellip;. Dipende dal fa bisogno dell&rsquo;utente 😁  With this parody there is to laugh, but at the same time to cry for the reality of the facts &hellip;&hellip; It can be done together &hellip; Or alternately &hellip; A little laugh and a little cry &hellip; It depends on the user&rsquo;s need 😁      Santolo Mele  3 years ago  Questo dovrebbe essere l&rsquo;inno mondiale del fravecatore. Fa ridere ma sul fino a nu certo punt&hellip;  This should be the world anthem of the construction worker. It makes you laugh but only up to a certain point &hellip;   <br>
This overview of the comments illustrates the exciting mixed or translingual ways people use Neapolitan and language in everyday settings, pushing back against so-called pure ideologies of Neapolitan and/or Tuscan-Italian and simultaneously countering emplaced notions of cultural identity. It also posits producers and users of media such as YouTube as translators  “constantly making rhetorical decisions as they present information to audiences from various linguistic and cultural backgrounds”   <sup id="fnref21:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>. Moments like the ones shown in Tables 8 and 9 also illustrate the concerning reality that for many, Neapolitan on YouTube (and perhaps in other digital spaces) has not engendered new depictions of the language or the culturally divided Italy in which it is used.</p>
<h2 id="codaconclusion">Coda/Conclusion</h2>
<p>In her foundational text  <em>Cybertypes</em> , Lisa Nakamura discusses how people tend to tribalize with their own kind online, reifying the same -isms and stereotypes that exist in physical realities <sup id="fnref1:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>.<sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>  Although more research is necessary to understand what the implications of a transcultural, translingual presence can do for the circulation and preservation of a vulnerable language like Neapolitan and for its attendant cultural ideologies, it is clear that the emplaced ideologies surrounding this language and other minority languages is up against some of the same barriers in social media spaces such as YouTube.</p>
<p>My analysis illustrates that a translingual, post-colonial framework that considers language and materiality offers a counternarrative analytic for considering so called vulnerable or endangered languages and cultures on social media. Cross-cultural, translingual  “response to the hierarchies of knowledge and power within the global landscape of the digital humanities . . .[through] counter-world making”   <sup id="fnref6:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> challenges the  “discursive imaginaries of the nation”   <sup id="fnref1:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup> and potentially, the political, economic, and material realities of disenfranchised groups such as Neapolitan Italians. YouTube becomes an effective medium for illustrating translanguaged Neapolitan  <em>and</em>  Italian, countering Italy’s ideology of any pure or standard Italian. YouTube’s affordances also offer culturally situated translation moments that revise Neapolitan identity and construct new publics that move Neapolitan and Neapoitanitá beyond the geographical boundaries of Italy. The dialogic, transnational public this and other YouTube videos like it<sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>  create offers possibilities for other marginalized peoples and cultures, not only those whose languages are vulnerable or endangered.</p>
<p>The case study I have described here is intended as a call for other postcolonial Italian digital humanities studies that are decidedly  “non-Anglo”  (Fiormonte in <sup id="fnref4:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>), go beyond  “a North American perspective”   <sup id="fnref5:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, and work to revise and expand the digital cultural record to include linguistic and cultural preservation for minority Italian cultures such as Neapolitan Italians, while honoring the cultural specificities of those regions and their people. More importantly, perhaps, this Neapolitan case study also illustrates how other minority and/or colonized cultures might harness the affordances of social media such as YouTube to express counternarratives of their languages and cultures that counter emplaced, national narratives that have kept them silenced and subjugated.</p>
<p>The case study I have detailed herein is homogeneous in that it represents a male-created viewpoint of labor and inequity in Naples. Also, it is not clear by my analysis who exactly the users of the page and site are (although the comments analyzed are mostly in Italian or Neapolitan) or even how far reaching the Neapolitan diaspora extends globally. Future studies that include a global mapping of Neapolitan social media users/producers and that incorporate their voices through ethnographic methods such as interviews would offer a more holistic, participatory representation of a population that is consistently referred to as a popolino (small or lesser people) in the national Italian imaginary. Still, this case offers a beginning interrogation on how to potentially extend (perhaps even preserve) a statistically derived endangered linguistic and cultural heritage beyond national boundaries, illustrates how digital Neapolitan content communities on YouTube and, perhaps, other social media platforms might work collectively against the socio-political structures that have historically silenced Neapolitans, devalued their language, and dismissed the cultural materiality that informs their lived experiences. Neapolitan on YouTube offers a way for minority cultures (Italian and other) to revise the historical and digital cultural record that has kept them on the linguistic and material periphery of their national positionality.</p>
<blockquote>
<p>to decenter the digital humanities narrative vis-à-vis new critical voices, new languages, new locations, and new methodologies that reimagine DH as not the seamless products of neoliberal governments and non-profit capitalism, but the work of people, labor, and voices at the margins creating fiction and fantasy, mapping edges and new locations, playing slanted and in glitches with distributed resources and global communities.<br>
<sup id="fnref:67"><a href="#fn:67" class="footnote-ref" role="doc-noteref">67</a></sup></p>
</blockquote>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Alighieri, Dante. (1996)  <em>Dante: De Vulgari Eloquentia</em> . Translated by Steven Botterill. Cambridge: Cambridge University Press, 1996.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Fiormonte, Domenico. (2012)  “Towards a Cultural Critique of the Digital Humanities.”    <em>Historical Social Research/Historische Sozialforschung</em> , pp. 59–76.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Hall, Crystal. (2019)  <em>Digital Humanities and Italian Studies: Intersections and Oppositions</em> . Abingdon-on-Thames: Taylor &amp; Francis.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>The <a href="https://www.disruptingdh.com/">Disrupting DH movement</a> has focused on remapping the discipline to include non-Anglo-American and historically marginalized scholars/ship. Like the scholars in this movement, my project co-opts the term disruption from feminist critical race theory&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Risam, Roopika. (2018)  <em>New Digital Worlds: Postcolonial Digital Humanities in Theory, Praxis, and Pedagogy</em> . Evanston: Northwestern University Press.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Josephs, Kelly Baker. (2019)  “DH Moments, Caribbean Considerations: On Reaction, Response, and Relevance in the Digital Humanities.”    <em>Digital Humanities Quarterly</em> , 13(3), Oct. 2019. Available at: <a href="/dhqwords/vol/13/3/000427/">https://www.digitalhumanities.org/dhq/vol/13/3/000427/000427.html</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Ortega, Élika. (2014)  “Multilingualism in DH.”    <em>Disrupting the Digital Humanities</em> , 31 Dec. 2014, <a href="http://www.disruptingdh.com/multilingualism-in-dh/">http://www.disruptingdh.com/multilingualism-in-dh/</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Gil, Alex. (2014)  “The (Digital) Library of Babel.”    <em>@elotroalex</em> , 7 June 2014, <a href="http://elotroalex.webfactional.com/digital-library-babel/">http://elotroalex.webfactional.com/digital-library-babel/</a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Fiormonte, Domenico. (2021)  “Taxation against Overrepresentation? The Consequences of Monolingualism for Digital Humanities.”    <em>Alternative Historiographies of the Digital Humanities</em> , edited by Kim, Dorothy and Koh, Adeline, 1st ed., punctum books.  <em>DOI.org (Crossref)</em> , <a href="https://doi.org/10.53288/0274.1.00">https://doi.org/10.53288/0274.1.00</a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Duke University. (2022)  “The Medieval Kingdom of Sicily Image Database.”    <em>The Medieval Kingdom of Sicily</em> , <a href="https://kos.aahvs.duke.edu/">https://kos.aahvs.duke.edu/</a>.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Mignolo, Walter D. (2007)  “Delinking: The Rhetoric of Modernity, the Logic of Coloniality and the Grammar of de-Coloniality.”    <em>Cultural Studies</em> , 21(2–3), pp. 449–514.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>The United Nations Educational, Scientific and Cultural Organization. (2010)  <em>UNESCO Atlas of the World’s Languages in Danger</em> . <a href="http://www.unesco.org/languages-atlas/index.php">http://www.unesco.org/languages-atlas/index.php</a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Endangered Language Alliance.  <em>Neapolitan | Endangered Language Alliance</em> . <a href="https://elalliance.org/languages/italian/neapolitan/">https://elalliance.org/languages/italian/neapolitan/</a>. Accessed 30 Mar. 2021.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>UNESCO World Heritage Centre. (2023)  “Historic Centre of Naples.”    <em>UNESCO World Heritage Centre</em> , <a href="https://whc.unesco.org/en/list/726/">https://whc.unesco.org/en/list/726/</a>. Accessed 2 Dec. 2022.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Chambers, Iain. (2008)  <em>Mediterranean Crossings: The Politics of an Interrupted Modernity</em> . Durham: Duke University Press.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Viola, Lorella, and Verheul, Jaap. (2019)  “The Media Construction of Italian Identity: A Transatlantic, Digital Humanities Analysis of Italianità, Ethnicity, and Whiteness, 1867-1920.”    <em>Identity</em> , 19(4), pp. 294–312.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Schneider, Jane, ed. (1998)  <em>Italy’s  Southern Question : Orientalism in One Country</em> . 1st edition. Abingdon-on-Thames: Routledge.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Aprile, Pino. (2011)  _Terroni: All That Has Been Done to Ensure That the Italians of the South Became  Southerners. _  New York: Bordighera Press.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>De Blasi, Nicola De. (2012)  <em>Storia linguistica di Napoli</em> . Rome: Carocci Editore.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Allen, Beverly, and Russo, Mary. (1997)  <em>Revisioning Italy: National Identity and Global Culture</em> . 1st edition. Minneapolis: University Of Minnesota Press.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Gramsci, Antonio, and Antonio Callari. (2011)  <em>Prison Notebooks</em> . Translated by Joseph A. Buttigieg, Slp edition. New York: Columbia University Press.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Rybas, Natalia, and Gajjala, Radhika. (2007)  “Developing Cyberethnographic Research Methods for Understanding Digitally Mediated Identities.”    <em>Forum Qualitative Sozialforschung / Forum: Qualitative Social Research</em> , 8(3), 3 Sept. 2007.  <em><a href="https://www.qualitative-research.net">www.qualitative-research.net</a></em> , <a href="https://doi.org/10.17169/fqs-8.3.282">https://doi.org/10.17169/fqs-8.3.282</a>.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Chopra, Rohit, and Gajjala, Radhika. (eds.) (2011)  <em>Global Media, Culture, and Identity: Theory, Cases, and Approaches</em> . 1st edition. Abingdon-on-Thames: Routledge.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Cavanaugh, Jillian R., and Shankar, Shalini. (2017)  <em>Language and Materiality: Ethnographic and Theoretical Explorations</em> . Cambridge: Cambridge University Press.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Cavanaugh, Jillian R. (2012)  <em>Living Memory: The Social Aesthetics of Language in a Northern Italian Town</em> . 1st edition. Hoboken: Wiley-Blackwell.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Bergamasco is spoken by people in a small town in the Northern region of Piedmont, Italy.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Cavanaugh, Jillian R. (2017)  “Anything Can Happen on YouTube (or Can It?): Endangered Language and New Media”  in Keri Vacanti Brondo (ed.),  <em>Cultural Anthropology: Contemporary, Public, And Critical Readings</em> . Oxford: Oxford University Press, pp. 88–95.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Gonzales, Laura. (2018)  <em>Sites of Translation: What Multilinguals Can Teach Us about Digital Writing and Rhetoric</em> . Illustrated edition, U OF M DIGT CULT BOOKS.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref10:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref11:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref12:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref13:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref14:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref15:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref16:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref17:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref18:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref19:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref20:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref21:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Guerra, Juan C. (2015)  <em>Language, Culture, Identity and Citizenship in College Classrooms and Communities</em> . Abingdon-on-Thames: Routledge.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Horner, Bruce, Selfe, Cynthia, and Lockridge, Tim. (2015)  <em>Translinguality, Transmodality, and Difference: Exploring Dispositions and Change in Language and Learning.</em>    <em>Enculturation</em> .&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Bourdieu, Pierre. (1984)  <em>Distinction: A Social Critique of the Judgement of Taste</em> . Cambridge: Harvard University Press.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Canagarajah, Suresh. (2011)  “Translanguaging in the Classroom: Emerging Issues for Research and Pedagogy.”    <em>Applied Linguistics Review</em> , 2(1), pp. 1–28.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Won Lee, Jerry. (2022)  <em>Locating Translingualism</em> . Cambridge: Cambridge University Press. DOI: <a href="https://doi.org/10.1017/9781009105361">https://doi.org/10.1017/9781009105361</a>.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>Selber, Stuart. (2004)  <em>Multiliteracies for a Digital Age</em> . 1st edition. Carbondale: Southern Illinois University Press.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Barton, David, and Carmen Lee. (2013)  <em>Language Online: Investigating Digital Texts and Practices</em> . 1st edition, Abingdon-on-Thames: Routledge, 2013.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Shipka, Jody. (2016)  “Transmodality in/and Processes of Making: Changing Dispositions and Practice.”    <em>College English</em> , 78(3), pp. 250–57.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>For this article, I refer to Don Norman’s definition of affordance in technological design in  <em>The Design of Everyday Things</em>  as  “the perceivable action possibilities that users consider possible based on an object’s features”   <sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>, and Ian Hutchby and Simone Barnett’s concept of communicative affordances, which emphasizes how affordances are both functional and relational; functional in the sense that they are enabling, as well as constraining and  <em>relational</em>  in terms of drawing  “attention to the way that the affordances of an object may be different for one species than for another”  (<sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>, emphasis in the original).&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Warner, Michael J. (2005)  “Ideology and Affect in Discourse in Institutions.”    <em>Journal of Language and Politics</em> , 4(2), John Benjamins, pp. 293–330.&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>frankEcerrone. (2013)  <em>Miley Cyrus - Wrecking Ball - Parody (Explicit)</em> .  <em>YouTube</em> , <a href="https://www.youtube.com/watch?v=R9bKmv2S9CE">https://www.youtube.com/watch?v=R9bKmv2S9CE</a>.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Palmeri, Jason. (2012)  <em>Remixing Composition: A History of Multimodal Writing Pedagogy</em> . Carbondale: Southern Illinois University Press.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>frankEcerrone. (2010)  “About.”    <em>YouTube</em> , <a href="https://www.youtube.com/user/frankEcerrone/about">https://www.youtube.com/user/frankEcerrone/about</a>&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Wiesen, G. (2022)  “What Is Standard English? (With Pictures).”    <em>Language Humanities</em> , 18 Mar. 2022, <a href="http://www.languagehumanities.org/what-is-standard-english.htm">http://www.languagehumanities.org/what-is-standard-english.htm</a>.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Cyrus, Miley. (2013)  <em>Miley Cyrus - Wrecking Ball (Official Video)</em> .  <em>YouTube</em> , <a href="https://www.youtube.com/watch?v=My2FRPA3Gf8">https://www.youtube.com/watch?v=My2FRPA3Gf8</a>.&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Lizárraga, José Ramón, et al. (2015)  “Translingual Literacies in a Social Media Age: Lessons Learned from Youth’s Transnational Communication Online.”    <em>Multilingual Learners and Academic Literacies</em> , Abingdon-on-Thames: Routledge, pp. 117–44.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Won Lee, Jerry. (2014)  <em>The Sovereignty of Global Englishes: Translingual Practices and Postnational Imaginaries</em> . The University of Arizona.  <em>ProQuest</em> , <a href="http://search.proquest.com.jerome.stjohns.edu:81/dissertations/docview/1537070739/2E977002F05D4A54PQ/1">http://search.proquest.com.jerome.stjohns.edu:81/dissertations/docview/1537070739/2E977002F05D4A54PQ/1</a>.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>Humphreys, Lee. (2005)  “Cellphones in Public: Social Interactions in a Wireless Era.”    <em>New Media &amp; Society</em> , 7(6). Thousand Oaks, CA and New Delhi: Sage Publications London, pp. 810–33.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Nakamura, Lisa.  <em>Cybertypes: Race, Ethnicity, and Identity on the Internet</em> . 1st edition. Abingdon-on-Thames: Routledge.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Pratt, Mary Louise. (1991)  “Arts of the Contact Zone.”    <em>Profession</em> , pp. 33–40.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Arola, Kristin, Sheppard, Jennifer, and Ball, Cheryl E. (2014)  “Multimodality as a frame for individual and institutional change.”    <em>Hybrid Pedagogy</em> .&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Selfe, Cynthia, and Takayoshi, Pamela. (2007)  “Thinking about Multimodality.”    <em>Multimodal Composition: Resources for Teachers</em> , pp. 1–12.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Kress, Gunther. (2000)  “Multimodality: Challenges to Thinking about Language.”    <em>TESOL Quarterly</em> , 34(2), pp. 337–40.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Shipka, Jody. (2011)  <em>Toward a Composition Made Whole</em> . Pittsburgh: University of Pittsburgh Press.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Shankar, Shalini, and Cavanaugh, Jillian R. (2012)  “Language and Materiality in Global Capitalism.”    <em>Annual Review of Anthropology</em> , vol. 41, pp. 355–69.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Halpern, Daniel, and Jennifer Gibbs. (2013)  “Social Media as a Catalyst for Online Deliberation? Exploring the Affordances of Facebook and YouTube for Political Expression.”    <em>Computers in Human Behavior</em> , 29(3), Elsevier, pp. 1159–68.&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Statista. (2022)  “Italy: Number of Immigrants Arrivals 2021.”    <em>Statista</em> , <a href="https://www.statista.com/statistics/779300/number-of-immigrants-landed-in-italy-by-nationality/">https://www.statista.com/statistics/779300/number-of-immigrants-landed-in-italy-by-nationality/</a>. ​​&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Nakamura is not the only cultural critic to point out the replication of real-world -isms in digital environments, from gaming spaces to coding infrastructures. See <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>, <sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>, <sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>, <sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup>, to name a few.&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p><sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup>; <sup id="fnref:65"><a href="#fn:65" class="footnote-ref" role="doc-noteref">65</a></sup>; <sup id="fnref:66"><a href="#fn:66" class="footnote-ref" role="doc-noteref">66</a></sup>.&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>Norman, Don. (2013)  <em>The Design of Everyday Things: Revised and Expanded Edition</em> . Basic books.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Hutchby, Ian, and Simone Barnett. (2005)  “Aspects of the Sequential Organization of Mobile Phone Conversation.”    <em>Discourse Studies</em> , 7(2). Thousand Oaks, CA and New Delhi: Sage Publications London, pp. 147–71.&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>McLuhan, Marshall. (1995)  “The Playboy Interview.”    <em>Essential McLuhan</em> , Anansi Concord, Ontario, pp. 233–69.&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Earhart, Amy E. (2012)  “Can Information Be Unfettered? Race and the New Digital Humanities Canon.”    <em>Debates in the Digital Humanities</em> , pp. 309–18.&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>Liu, Alan. (2013)  “Where Is Cultural Criticism in the Digital Humanities?”    <em>Debates in the Digital Humanities</em> , pp. 490–509.&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p>Everett, Anna. (2009)  <em>Digital Diaspora: A Race for Cyberspace</em> . Albany: SUNY Press.&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p>frankEcerrone. (2011)  <em>On The Floor - Parodia Napoletana -  A vì e for   - HD</em> . 2011.  <em>YouTube</em> , <a href="https://www.youtube.com/watch?v=FX-fOvPOhmw">https://www.youtube.com/watch?v=FX-fOvPOhmw</a>.&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:65">
<p>Rafelopazz. (2012)  <em>Pitbull Ft. Marc Anthony (Parodia Napoletana)</em> .  <em>YouTube</em> , <a href="https://www.youtube.com/watch?v=lDATtAAzDcI">https://www.youtube.com/watch?v=lDATtAAzDcI</a>.&#160;<a href="#fnref:65" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:66">
<p>Rafelopazz. (2014)  <em>Rafelopazz - Sudando (Enrique Iglesias - Bailando)</em> .  <em>YouTube</em> , <a href="https://www.youtube.com/watch?v=jFodeGDgMvg">https://www.youtube.com/watch?v=jFodeGDgMvg</a>.&#160;<a href="#fnref:66" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:67">
<p>Kim, Dorothy, and Stommel, Jesse, eds. (2018)  <em>Disrupting the Digital Humanities</em> . punctum books, p. 514.  <em>DOI.org (Datacite)</em> , doi:<a href="https://doi.org/10.21983/P3.0230.1.00">10.21983/P3.0230.1.00</a>.&#160;<a href="#fnref:67" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Machine Learning Techniques For Analyzing Inscriptions From Israel</title><link href="https://rlskoeser.github.io/dhqwords/vol/17/2/000681/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/17/2/000681/</id><author><name>Daiki Tagami</name></author><author><name>Michael Satlow</name></author><published>0001-01-01T00:00:00+00:00</published><updated>0001-01-01T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="1-introduction">1. Introduction</h2>
<p>The study of antiquity is full of missing data. The evidence that does survive – whether texts on papyrus or parchment; inscriptions; coins; or archaeological – frequently survives only in damaged form. That problem, however, is compounded by two additional complications. First, many of these data have been unearthed in non-controlled excavations and have taken winding paths to libraries, museums, and the hands of private collectors, along the way losing valuable contextual information. Second, scholars have used a bewildering array of conflicting and often inherently vague reporting methods. My Roman period, for example, might be your Byzantine period. As a result of this situation, scholars in ancient studies frequently find themselves unable to place or date evidence that could be critical to our deeper understanding. Given the paucity of our information, for example, dating a particularly revealing inscription to the fifth or third century BCE, or as originating from Athens or Asia Minor, could have serious scholarly ramifications.</p>
<p>Traditionally, scholars have used their own experience and specialized training to supply these missing contextual data <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Recently, however, there has been increasing interest in using machine learning techniques to supplement, or even replace, subjective and idiosyncratic (although sometimes brilliant) evaluations. For example, Niculae et al. <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> used machine learning techniques to date a corpus of older texts.</p>
<p>In 2022, Assael et al. <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> published their research into developing a machine learning platform that would aid the automated reconstruction and adding of missing contextual information to ancient Greek inscriptions. This platform, which they call Ithaca, is based on a deep neural network model. They demonstrate that such a technique greatly enhances scholarly expertise, although it cannot substitute for it.</p>
<p>As impressive as Ithaca is, deep neural network techniques presently have limited applicability to other digital humanities projects. One inherent problem with using them is that they are black box models; their processes remain opaque. Furthermore, they need both technical expertise to implement and a large sample size to train the algorithm <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. Datasets from antiquity, particularly those that exist in high-quality structured form, are rarely large enough to make this approach suitable.</p>
<p>In this paper, we explore the utility of other machine learning algorithms for predicting values in incomplete datasets. We have determined that a random forest model has the most potential to predict these values, particularly in smaller datasets with several categorical variables. While our own work was based on one dataset,  “Inscriptions of Israel/Palestine,”  we believe that our results are applicable to other datasets as well.</p>
<h2 id="2-methods">2. Methods</h2>
<h2 id="21-inscription-dataset">2.1 Inscription dataset</h2>
<p>The  “Inscriptions of Israel/Palestine”  (IIP) dataset is an online database which seeks to make all of the previously published inscriptions of Israel/Palestine from the Persian period through the Islamic conquest (ca. 500 BCE - 640 CE) freely accessible <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. This database includes approximately 4,500 inscriptions, and they are written primarily in Hebrew, Aramaic, Greek and Latin, by Jews, Christians, Greeks, and Romans. Some of the examples include imperial declarations on monumental architecture, notices of donations in synagogues and humble names scratched on ossuaries <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. Each inscription exists as a single XML file structured according to EpiDoc conventions <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<h2 id="22-variable-explanation">2.2 Variable Explanation</h2>
<p>We consider the following characteristics in the dataset:</p>
<ul>
<li>Terminus ante quem (the latest possible date)</li>
<li>Terminus post quem (the earliest possible date)</li>
<li>Text Genre</li>
<li>Language</li>
<li>Material</li>
<li>Region</li>
<li>Likely Religion</li>
</ul>
<p>It is worth noting that language, material, and region are objectively determined in most cases. Dating, on the other hand, is often determined subjectively by scholars; relatively few contain dates or were found in carefully controlled archaeological excavations. Thus, we examine how machine learning models can accurately predict the date of inscriptions given the information of other variables in the dataset. All variables inside the dataset except date are categorical, as they are not quantifiable.</p>
<h2 id="23-data-preprocessing">2.3 Data Preprocessing</h2>
<p>The IIP dataset is converted into a single csv file through using the ElementTree XML API in Python programming. One of the features of the IIP dataset, like many others in the humanities, is that it contains a number of categorical variables, that is, different phrases that occur within a single XML element. For example, there are many different cities in the location element, and over fifty different text genres (e.g., funerary, dedicatory, label, prayer) are found within the appropriate element. The result of this is an imbalanced dataset. Imbalanced datasets occur when the proportion of minority class is significantly low compared with other classes in the dataset, and creating an effective machine learning algorithm with imbalanced datasets is a very difficult problem <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. It is also important to make sure that all the possible categorical values are in the training dataset to create a good machine learning model. For example, if the training set does not include any inscriptions that has the city name Jerusalem, it would be difficult for the machine learning algorithm to use the Jerusalem information in the test dataset. Error messages can come out in many machine learning programs when they encounter some information that is not included in the training dataset. Splitting the dataset into training and test set is done randomly, so it is possible for the minority class to not appear in both training and test set if the number of observations from the minority class is small. To have enough observations in the minority class, we combine various unique terms and generate a dataset that is better suited for the machine learning algorithm.</p>
<p>We first fix spelling mistakes inside the dataset. Afterwards, we combine words that describe the same concept. For instance, Golan Heights and Golan can be grouped together as Golan and there is no need for the machine learning algorithm to consider these elements separately. There are also some phrases such as dedicatory quotation and dedicatory verse, where they describe different objects but can be grouped together as dedicatory to reduce the number of variables inside the dataset. However, we take a different approach with the City Name variable. There are 244 unique city names inside the dataset, and many of them only include a few inscriptions. Since the location of inscription is already indicated in the Region variable, we only consider Jerusalem and Other Cities to make the prediction easier to interpret. We also do not consider all variables in the dataset, such as condition of artifacts and relief style, as they have a lot of missing values.</p>
<p>We use a technique called one-hot encoding to convert the categorical features to numerical features. There are many machine learning algorithms that can only analyze numerical data, so analyzing categorical variables without one-hot encoding can cause some issues. In this technique, we create a binary column for each category, where we denote the output of the column to be 1 if the variable is present and 0 if the variable is not present. For example, we create a new variable called Language_Greek to describe if the inscription is written in Greek or not. The Language_Greek variable will be 1 if the inscription is written in Greek, but 0 otherwise.</p>
<p>These inscriptions are used to examine the performance of machine learning models to predict the time periods. The time period distribution of inscription is shown in Figure 1. The mean date is 109.68 CE with standard deviation 311.47. The large standard deviation implies that the dataset is suitable for conducting this analysis, as it has inscriptions from a wide range of time periods. After we preprocess the dataset, we select 650 inscriptions that actually contain a certain date. The overview of the steps that are taken in this research project is shown in Figure 2.</p>
<h2 id="24-machine-learning-techniques">2.4 Machine Learning Techniques</h2>
<p>We compare the performances of eleven machine learning models: linear regression, ridge regression, lasso regression, elastic net, decision tree, random forest, neural network, XGBoost, and support vector regression with linear, radial and polynomial kernel. We select these algorithms, as they require minimal hyperparameter tuning and do not require data transformation. Hyperparameters determine the overall behavior of the machine learning model, and they must be set appropriately by the user before conducting the analysis <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. Hyperparameter tuning is often performed manually, but it is impractical when we have many hyperparameters, and technical expertise is required to correctly set the hyperparameters <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. To create a simple and reproducible machine learning prediction model, we try to select models that do not require fine parameter tuning.</p>




























<figure ><img loading="lazy" alt="Bar chart showing time period of inscriptions ranging from 600 BCE to 800 CE. Most inscriptions date between 400 BCE and 600 CE" src="/dhqwords/vol/17/2/000681/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000681/resources/images/figure01_hu83fcecb428aa75adc7bfe7e7f48d936d_12402_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000681/resources/images/figure01_hu83fcecb428aa75adc7bfe7e7f48d936d_12402_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000681/resources/images/figure01.png 566w" 
     class="landscape"
     ><figcaption>
        <p>Time periods of inscriptions in the IIP dataset.
        </p>
    </figcaption>
</figure>
<p>We will provide a brief overview of these techniques with some examples of previous studies in digital humanities. Readers who are interested in further details of machine learning techniques should consult Hastie et al. <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.</p>
<h2 id="241-penalized-regression-techniques">2.4.1 Penalized Regression Techniques</h2>




























<figure ><img loading="lazy" alt="Flow chart showing the steps in data preprocessing (converting xml file, combining unique terms, obtaining inscriptions) and data analysis (chi-squared test, comparining machine learning techniques, examining random forest model)." src="/dhqwords/vol/17/2/000681/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000681/resources/images/figure02_hu3c8eba7345199ee6042eb25030dbf21e_35428_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000681/resources/images/figure02_hu3c8eba7345199ee6042eb25030dbf21e_35428_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000681/resources/images/figure02_hu3c8eba7345199ee6042eb25030dbf21e_35428_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000681/resources/images/figure02.png 1291w" 
     class="landscape"
     ><figcaption>
        <p>Workflow of the research project.
        </p>
    </figcaption>
</figure>
<p>Ordinary least squares (OLS) regression is a commonly used statistical technique in regression problems. It assumes that there is a linear relationship between the predictor and response variable. We can directly observe the regression coefficients in OLS regression, so we can understand how the model is making predictions. There are, however, some disadvantages to using OLS. When the number of predictors become large, a small change in the training dataset can cause a large change in the prediction model produced by the OLS model <sup id="fnref1:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. Thus, penalization techniques are often used to improve the predictability of OLS while retaining its linear model structure <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. These methods impose a shrinkage penalty and bring the estimated coefficients closer to zero <sup id="fnref2:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. We will be examining ridge, lasso, and elastic net, as they are commonly used penalization techniques.</p>
<p>Penalization techniques are frequently used in digital humanities research projects that contain datasets with many variables. For example, Finegold et al. <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> used Poisson Graphical Lasso to reconstruct the historical social network in early modern Britain. They have imposed the penalization technique in statistical graph learning methods to find out the relationship between people’s names inside the historical documents. Considering that the number of distinct names inside the historical documents is large, penalized regression went well for their analysis.</p>
<h2 id="242-support-vector-regression">2.4.2 Support Vector Regression</h2>
<p>Support Vector Regression (SVR) uses the same principle as Support Vector Machine (SVM), which is one of the most widely used supervised machine learning techniques <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>. It is frequently used in digital humanities, including a study by Argamon et al. <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, where they used SVM to classify author&rsquo;s gender from literary texts. The SVM algorithm conducts regression based on kernel functions, which converts the lower dimensional data into a higher dimensional feature space.</p>
<p>We consider the performances of three kernels, linear, radial and polynomial kernel, as they are commonly used kernels. The detailed information about the SVR mechanism can be found in <sup id="fnref1:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>.</p>
<h2 id="243-neural-network">2.4.3 Neural Network</h2>
<p>Deep learning algorithms make predictions based on a neural network structure, which is inspired by the human nervous system <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. It has been used in multiple algorithms in digital humanities studies, including a study by Assael et al. <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> where they had implemented a deep learning algorithm to predict contextual information based on the textual information in ancient Greek inscriptions. To examine the performance of deep learning technique, we fit a single-hidden-layer neural network, as it has been shown that low complexity deep learning models perform better when the sample size is small <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>.</p>
<h2 id="244-tree-based-approach">2.4.4 Tree Based Approach</h2>
<p>We examine three different tree based machine learning techniques, decision tree, random forest and Extreme Gradient Boosting (XGBoost). Random forest and XGBoost are tree ensemble methods, and they are considered to be the recommended tools to analyze tabular datasets <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. Ensembles are methods that combine multiple machine learning techniques to create more powerful models, and tree ensemble methods are used extensively in various digital humanities research. For example, a recent project by Baledent et al. <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> used decision trees and random forests to automatically date French documents with high predictability. Fragkiadakis et al. <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> compared the performances of various machine learning techniques to annotate video data with sign languages, and showed that the XGBoost was the optimal model to predict the begin and end frames of a sign sequence in a video.</p>
<p>Decision tree is the foundation of random forest and XGBoost model. It is considered to be one of the most interpretable machine learning methods for data analysis, as it can classify data based on a set of yes/no questions. However, decision trees can be very non-robust and a minor change in the training data can result in a large change in the final tree <sup id="fnref3:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.</p>
<p>XGBoost is a tree ensemble machine learning algorithm that uses gradient boosted decision trees. It has a tree learning algorithm that enables to learn from sparse data, and it can analyze data faster than other popular machine learning techniques <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>. The gradient boosting algorithm generates one tree at a time based on the previous model’s residuals, and then they are combined to make the final prediction. In our analysis, we generate 150 trees in the final model, where the maximum depth of each tree is three.</p>
<p>The random forest algorithm is another tree ensemble machine learning algorithm that generates hundreds of decision trees by using a random subset of predictors in the bootstrapped samples. Bootstrapping is a statistical technique that repeatedly draw samples from the data with replacement <sup id="fnref4:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. Since the same element can appear multiple times in the new sample, this technique generates a large number of new datasets that are not exactly the same as the original model. The average of the decision trees generated from the bootstrapped samples is examined to make the final prediction.</p>
<p>Random forest can also be used to rank the predictor variables based on its ability to decrease the sum of squared errors when it is chosen to split the data <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. This is an important aspect of random forest, as we can understand which variables are important in the regression model to predict the criterion variable. Due to these advantages, multiple research highlight that random forests have emerged as serious competitors to other machine learning models for predicting numerical and categorical variables <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>.</p>
<p>To implement random forests, we only need to specify the number of trees and the number of features in each split. In terms of the number of trees, it has been shown that implementing many trees will provide a stable result of variable importance <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> and using more than the required number of trees does not harm the model <sup id="fnref1:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. Many studies use p/3 number of features in each split for regression problems, where p is the number of predictor variables <sup id="fnref1:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>.</p>
<h2 id="25-metric">2.5 Metric</h2>
<p>Metrics are used to quantify the accuracy of the machine learning model once we obtain the machine learning models. We will examine three commonly used metrics to evaluate the machine learning algorithm, root mean square error (RMSE), mean absolute error (MAE), and R-squared. 10-fold cross-validation is performed to compare the performances of machine learning algorithms. In k-fold cross validation, we split the dataset into k smaller sets with equal number of elements and use k-1 sets to train the model, while the remaining set is used to evaluate the model <sup id="fnref5:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. We repeat the above iteration thirty times and compute the mean value of the determined metrics in cross validation to determine the optimal machine learning model for predicting the date.</p>
<h2 id="26-programming">2.6 Programming</h2>
<p>We use R version 4.1.3 to perform the data analysis and Python version 3.8.3 to obtain the XML dataset from the IIP database <sup id="fnref2:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. The dataset and the codes that we use to obtain the dataset are openly available to the public at <a href="https://github.com/daikitag/Inscriptions-of-Israel-Palestine">https://github.com/daikitag/Inscriptions-of-Israel-Palestine</a>.</p>
<h2 id="3-results">3. Results</h2>
<h2 id="31-variable-relationship">3.1 Variable Relationship</h2>
<p>It is important to understand the relationship between the predictor variables in the dataset before conducting machine learning analysis, as we can understand the issues behind effectively analyzing the dataset. Considering that all predictor variables are categorical, we use Pearson&rsquo;s chi-squared test of independence to examine the association between the variables in the dataset. We have examined the association between:</p>
<p>Language and Location  Religion and Location  Religion and Language  Religion and Text Genre</p>
<p>The residual plots of the chi-squared test are shown in Figure 3. Results from chi-squared test indicate that there is a significant relationship between all the examined combinations ( <em>p&lt;0.001</em> ).</p>
<p>The results imply that the predictor variables are correlated with each other, which raises the problem of multicollinearity. Multicollinearity occurs when independent variables in the regression model are correlated with each other <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. One of the key assumptions of the linear regression model is that the predictor variables are uncorrelated. Thus, multicollinearity can undermine the statistical significance of an independent variable and can give inaccurate coefficient estimates when traditional statistical techniques are used <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>.</p>




























<figure ><img loading="lazy" alt="Four matrices each comparing a set of variables. Positive or negative associations shown with colored dots of different sizes." src="/dhqwords/vol/17/2/000681/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000681/resources/images/figure03_hu6a91fce135ef3ac98bdcb29b768e2028_255097_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000681/resources/images/figure03_hu6a91fce135ef3ac98bdcb29b768e2028_255097_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000681/resources/images/figure03_hu6a91fce135ef3ac98bdcb29b768e2028_255097_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000681/resources/images/figure03.png 1428w" 
     class="landscape"
     ><figcaption>
        <p>Residual plot of chi-squared analysis of the dataset. Red color indicates that two variables are negatively associated, and blue color indicates that two variables are positively associated. (a) Chi-squared test between language and location of inscriptions. (b) Chi-squared test between religion and location. (c) Chi-squared test between religion and language. (d) Chi-squared test between religion and text genre.
        </p>
    </figcaption>
</figure>
<p>In contrast, due to recent advances in machine learning techniques, it has been reported that machine learning can better analyze data with multicollinearity than traditional statistical techniques <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>. The presence of multicollinearity suggests the usage of machine learning techniques to effectively analyze the dataset.</p>
<h2 id="32-machine-learning-model-comparison">3.2 Machine Learning Model Comparison</h2>
<p>A total of eleven regression models are compared: linear regression, ridge regression, lasso regression, elastic net, decision tree, random forest, neural network, SVR linear, SVR radial, SVR polynomial, and XGBoost. The optimal hyperparameters of the machine learning algorithms are determined through 10-fold cross-validation. The cross-validation procedure is repeated 3 times, and the machine learning model is tested by using a total of 30 different datasets, each of which are generated through cross-validation. The evaluation results are shown in Figure 4, where Figure 4 (a) shows the distribution of RMSE from 30 different datasets and Figure 4 (b) shows the mean values of MAE, RMSE and R-squared. MAE and RMSE measure the error of the machine learning model and R-squared is a goodness of fit measure. The random forest model has the lowest value for MAE and RMSE, and has the highest value for R-squared among all models that are examined. This implies that random forest model is the optimal model for predicting the date of inscriptions.</p>
<h2 id="33-random-forest-model">3.3 Random Forest Model</h2>
<p>We describe the random forest model in detail, as it is the best model that is implemented in the previous section. We initially convert the number of trees that the random forest model generates from 100 to 1000 to determine the optimal number of trees that we put inside the algorithm, but we do not observe any significant differences. Thus, we select 500 number of trees, as it is the default number of trees in R&rsquo;s randomForest package <sup id="fnref2:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>.</p>




























<figure ><img loading="lazy" alt="Two side by side figures. 4(a) is a boxplot graph for the RMSE values of each learning method. 4(b) contains MAE, RMSE, and R-squared values for each learning method." src="/dhqwords/vol/17/2/000681/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000681/resources/images/figure04_hu381569ab9d304acec4c5cc6a10638271_129730_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000681/resources/images/figure04_hu381569ab9d304acec4c5cc6a10638271_129730_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000681/resources/images/figure04_hu381569ab9d304acec4c5cc6a10638271_129730_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000681/resources/images/figure04.png 1348w" 
     class="landscape"
     ><figcaption>
        <p>Evaluation of machine learning methods from 10-fold cross validation. (a) The distribution of RMSE from cross validation. (b) Mean values of MAE, RMSE and R-squared from cross validation. The best model for each metric is colored by blue and the worst model is colored by red.
        </p>
    </figcaption>
</figure>
<p>Figure 5 (a) shows the variable importance plot of the random forest model. Variable importance is based upon the mean increase of mean squared error as a result of permuting a given variable <sup id="fnref3:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. The plot suggests that the material of inscription is the most important variable in the prediction model. The prediction plot is shown in Figure 5 (b). The machine learning model is trained based on the training dataset, which includes 70% of the randomly chosen inscriptions in the data. The prediction plot is created by using the test dataset, which is not used to train the machine learning model.</p>
<h2 id="4-discussions">4. Discussions</h2>
<h2 id="41-categorical-analysis">4.1 Categorical Analysis</h2>
<p>Every region and community in the Mediterranean in antiquity had its own epigraphic characteristics. The statistical analysis reveals some features of different communities within Judea/Roman Palestine. From the residual plot in Figure 3 (a), we can infer that inscription in Judea have a higher probability of being written in Hebrew and inscriptions in Negev have a higher probability of being written in Aramaic. There is also a very strong positive association between Aramaic and Samaria. However, there is a lower probability of Aramaic inscriptions found in the Coastal Plain.</p>




























<figure ><img loading="lazy" alt="Two side by side figures. 5(a) bar graph showing the %IncMSE value for the variables language, material, region, religion, and text genre. 5(b) scatterplot showing relationship between prediction values and actual year." src="/dhqwords/vol/17/2/000681/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/17/2/000681/resources/images/figure05_hue306da1e74082c488fa0a236bf341e2c_218606_500x0_resize_box_3.png 500w,
    /dhqwords/vol/17/2/000681/resources/images/figure05_hue306da1e74082c488fa0a236bf341e2c_218606_800x0_resize_box_3.png 800w,/dhqwords/vol/17/2/000681/resources/images/figure05_hue306da1e74082c488fa0a236bf341e2c_218606_1200x0_resize_box_3.png 1200w,/dhqwords/vol/17/2/000681/resources/images/figure05.png 1335w" 
     class="landscape"
     ><figcaption>
        <p>(a) Variable importance plot of the random forest model. (b) The relationship between prediction and actual value of the test dataset. The dashed line represents the location where the prediction and the actual value are the same.
        </p>
    </figcaption>
</figure>
<p>When we examine the residual plot in Figure 3 (b), there is a higher possibility of discovering Christian inscriptions in Coastal Plain, Galilee, and Negev. There is a higher possibility of discovering Jewish inscriptions in Judea and Galilee. However, the probability of finding Christian and Jewish inscriptions in Samaria is lower than other regions, and there are many inscriptions from other religions. These results are consistent with what we would expect from other historical sources.</p>
<p>The residual plot of language and religion is shown in Figure 3 (c). Christian inscriptions have a strong positive association with Greek, but negative association with other languages, specifically Aramaic. Inscriptions written in Aramaic and Hebrew are more likely to be Jewish inscriptions.</p>
<p>The relationship between text genre and religion is shown in Figure 3 (d). The plot implies that Christian inscriptions tend to be funerary or invocation related compared with other religions, but the probability of Christian inscription being document or legal/economic is lower. It seems that Christian inscriptions tend to be more religious and less administrative.</p>
<h2 id="42-machine-learning-model">4.2 Machine Learning Model</h2>
<p>We are able to conclude that the random forest model is the optimal machine learning model for predicting time periods of inscriptions. This is consistent with previous research, as it has been reported that tree-ensemble algorithms like random forests are better to analyze tabular data <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>, which is the data type that we use in our project. If we examine the metric values in Figure 4 (b), we see that random forest, XGBoost and decision tree perform better than other models that we have examined. This highlights the importance of using tree based machine learning algorithms to analyze tabular dataset.</p>
<p>Our study also shows that linear models do not perform well compared with other methods in analyzing tabular datasets which consists of only categorical variables. This might be due to the nonlinear interactions between the variables in the dataset. In terms of SVM, it is important to select the appropriate kernel for each dataset. In our example, we see that SVR with linear kernel performs the worst out of all three kernels that we have examined. However, there are many kinds of kernels in SVM, and it would be a challenging problem to select the optimal kernel for the dataset. The results also suggest that the predictability of neural network is not high compared with tree-based algorithms when we analyze tabular datasets. Many digital humanities datasets are tabular data and they are rarely large enough to effectively train the deep learning algorithm. Our results are consistent with the previous study by Shwartz-Ziv &amp; Armon <sup id="fnref1:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>, where they also showed that tree ensemble methods are better than deep learning techniques to analyze tabular data.</p>
<p>In contrast, a random forest model can easily be implemented by specifying two hyperparameters of the model, and it is possible for a random forest model to capture the nonlinear interactions inside the dataset. This is a major advantage of random forests, as most machine learning models require fine tuning of hyperparameters <sup id="fnref6:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.</p>
<p>In spite of advances in machine learning techniques, it is still necessary to have epigraphers to analyze inscriptions. According to the variable importance plot of the random forest model (Figure 5 (b)), material is the most important variable in making predictions, but we cannot ignore the effects of other variables, including religion and text genre. These variables are subjective, and necessitates the importance of having humans to classify the inscriptions as well. Even in the research project conducted by Assael et al. <sup id="fnref2:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, they showed that accuracy was the best when the deep learning algorithm was paired up with historians. Machine learning algorithms are still not perfect, so it would be important for us to incorporate knowledge from both human scholars and computers to analyze the dataset effectively.</p>
<h2 id="5-conclusions">5. Conclusions</h2>
<p>We show how machine learning techniques can be used to make predictions based on tabular dataset that is comprised of categorical variables. It is uncommon for humanities data to include all elements of a dataset. This could be due to the damage of artifacts over time and many texts being often only available in fragments. Instead of only using one element of the dataset to make predictions, it would be important for us to incorporate other elements in the dataset to effectively date the artifacts. As a next step, we plan to integrate the deep learning framework to the machine learning model that we have created, so that we can incorporate both textual data and tabular data of inscriptions in the prediction model to achieve better accuracy.</p>
<p>The results of our work indicate that computers can successfully be taught to predict missing characteristics of historical artifacts. The widespread use of machine learning techniques offers exciting prospects in epigraphy and related fields. Even if the dataset is not large, we provide an example in which machine learning techniques can effectively be used to make predictions. In addition to the inscription dataset, our research shows that the machine learning model could be used to analyze other digital humanities dataset which includes a wide range of categorical variables.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>We acknowledge computing resources from Columbia University&rsquo;s Shared Research Computing Facility project, which is supported by NIH Research Facility Improvement Grant 1G20RR030893-01, and associated funds from the New York State Empire State Development, Division of Science Technology and Innovation (NYSTAR) Contract C090171, both awarded April 15, 2010. We thank Brown University’s Center for Digital Scholarship for providing the valuable dataset for our research. We would also like to thank the anonymous reviewers, as their suggestions and comments have significantly improved the content and presentation of this paper.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Emmanuel, T., Maupong, T., Mpoeleng, D., Semong, T., Mphago, B., and Tabona, O. (2021)  “A survey on missing data in machine learning.”    <em>Journal of Big Data</em> , 8(1), pp. 1–37.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Niculae, V., Zampieri, M., Dinu, L., and Ciobanu, A. M. (2014)  “Temporal Text Ranking and Automatic Dating of Texts.”    <em>Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, Volume 2: Short Papers</em> , pp. 17–21. <a href="https://doi.org/10.3115/v1/E14-4004">https://doi.org/10.3115/v1/E14-4004</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Assael, Y., Sommerschield, T., Shillingford, B., Bordbar, M., Pavlopoulos, J., Chatzipanagiotou, M., Androutsopoulos, I., Prag, J., and de Freitas, N. (2022)  <em>Restoring and attributing ancient texts using deep neural networks.</em>    <em>Nature</em> , 603(7900), pp. 280–283.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>LeCun, Y., Bengio, Y., and Hinton, G. (2015)  “Deep learning.”    <em>Nature</em> , 521 (7553), pp. 436–444.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Satlow, M. L. (2022)  “Inscriptions of Israel/Palestine.”    <em>Jewish Studies Quarterly (JSQ)</em> , 29(4), pp. 349–369. <a href="https://doi.org/10.1628/jsq-2022-0021">https://doi.org/10.1628/jsq-2022-0021</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Elliott, Tom, Bodard, Gabriel, and Cayless, Hugh et al. (2006, 2022)  <em>EpiDoc: Epigraphic Documents in TEI XML</em> . <a href="https://epidoc.stoa.org/">https://epidoc.stoa.org/</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Johnson, J. M., and Khoshgoftaar, T. M. (2019)  “Survey on deep learning with class imbalance.”    <em>Journal of Big Data</em> , 6(1), 27. <a href="https://doi.org/10.1186/s40537-019-0192-5">https://doi.org/10.1186/s40537-019-0192-5</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Claesen, M., and De Moor, B. (2015)  <em>Hyperparameter Search in Machine Learning</em>  (arXiv:1502.02127). arXiv. <a href="https://doi.org/10.48550/arXiv.1502.02127">https://doi.org/10.48550/arXiv.1502.02127</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Claesen, M., Simm, J., Popovic, D., Moreau, Y., and De Moor, B. (2014)  <em>Easy Hyperparameter Search Using Optunity</em>  (arXiv:1412.1114). arXiv. <a href="https://doi.org/10.48550/arXiv.1412.1114">https://doi.org/10.48550/arXiv.1412.1114</a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Hastie, T., Tibshirani, R., Friedman, J. H., and Friedman, J. H. (2009)  <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>  (Vol. 2). Springer.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Zou, H., &amp; Hastie, T. (2005).  “Regularization and variable selection via the elastic net.”    <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> , 67(2), pp. 301–320.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Finegold, M., Otis, J., Shalizi, C., Shore, D., Wang, L., and Warren, C. (2016)  “Six degrees of Francis Bacon: A statistical method for reconstructing large historical social networks.”    <em>Digital Humanities Quarterly</em> , 10(3).&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Drucker, H., Burges, C. J., Kaufman, L., Smola, A., and Vapnik, V. (1996)  “Support vector regression machines.”    <em>Advances in Neural Information Processing Systems</em> , 9.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Argamon, S., Goulain, J.-B., Horton, R., and Olsen, M. (2009)  “Vive la différence! Text mining gender difference in french literature.”    <em>Digital Humanities Quarterly</em> , 3(2).&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Goodfellow, I., Bengio, Y., and Courville, A. (2016)  <em>Deep Learning</em> . MIT press.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Brigato, L., and Iocchi, L. (2021)  “A Close Look at Deep Learning with Small Data.”    <em>2020 25th International Conference on Pattern Recognition (ICPR)</em> , pp. 2490–2497. <a href="https://doi.org/10.1109/ICPR48806.2021.9412492">https://doi.org/10.1109/ICPR48806.2021.9412492</a>&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Borisov, V., Leemann, T., Seßler, K., Haug, J., Pawelczyk, M., &amp; Kasneci, G. (2022)  “Deep Neural Networks and Tabular Data: A Survey.”    <em>IEEE Transactions on Neural Networks and Learning Systems</em> , pp. 1–21. <a href="https://doi.org/10.1109/TNNLS.2022.3229161">https://doi.org/10.1109/TNNLS.2022.3229161</a>&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Baledent, A., Hiebel, N., and Lejeune, G. (2020)  “Dating ancient texts: An approach for noisy French documents.”    <em>Language Resources and Evaluation Conference (LREC) 2020</em> .&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Fragkiadakis, M., Nyst, V., and Putten, P. van der. (2021)  “Towards a User-Friendly Tool for Automated Sign Annotation: Identification and Annotation of Time Slots, Number of Hands, and Handshape.”    <em>Digital Humanities Quarterly</em> , 15(1).&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Chen, T., and Guestrin, C. (2016)  “XGBoost: A Scalable Tree Boosting System.”    <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> , pp. 785–794. <a href="https://doi.org/10.1145/2939672.2939785">https://doi.org/10.1145/2939672.2939785</a>&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Breiman, L. (2001).  “Random forests.”    <em>Machine Learning</em> , 45(1), pp. 5–32.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Belgiu, M., and Drăguţ, L. (2016) Random forest in remote sensing: A review of applications and future directions.  <em>ISPRS Journal of Photogrammetry and Remote Sensing</em> , 114, pp. 24–31.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Liaw, A., and Wiener, M. (2002)  “Classification and regression by randomForest.”    <em>R News</em> , 2(3), pp. 18–22.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Alin, A. (2010)  “Multicollinearity.”    <em>Wiley Interdisciplinary Reviews: Computational Statistics</em> , 2(3), pp. 370–374.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Allen, M. P. (1997)  “The problem of multicollinearity” . In Allen, M.P.  <em>Understanding Regression Analysis</em> . Berlin: Springer, pp. 176-180.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Chan, J. Y. L., Leow, S. M. H., Bea, K. T., Cheng, W. K., Phoong, S. W., Hong, Z. W., and Chen, Y. L. (2022)  “Mitigating the multicollinearity problem and its machine learning approach: a review” .  <em>Mathematics</em> , 10(8), 1283.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Shwartz-Ziv, R., and Armon, A. (2022)  “Tabular data: Deep learning is not all you need.”    <em>Information Fusion</em> , 81, pp. 84–90.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry></feed>