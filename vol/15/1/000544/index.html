<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#3D206C"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel=apple-touch-icon sizes=180x180 href=/img/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/img/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/img/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=384x384 href=/img/favicon/android-chrome-384x384.png><link rel=icon type=image/png sizes=192x192 href=/img/favicon/android-chrome-192x192.png><link rel=icon type=image/png sizes=150x150 href=/img/favicon/mstile-150x150.png><link rel="shortcut icon" href=/favicon.ico><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/img/favicon/safari-pinned-tab.svg color=#3d206c><link rel=schema.dc href=http://purl.org/DC/elements/1.0/><meta name=citation_public_url content="https://startwords.cdh.princeton.edu/vol/15/1/000544/"><meta name=citation_title content="Inferring standard name form, gender and nobility from historical texts using stable model semantics"><meta name=citation_date content="2021/05"><meta name=citation_author content="Davor Lauc"><meta name=citation_author content="Darko Vitek"><meta name=citation_abstract content="Introduction The necessary condition of many endeavours in the digital humanities domain is the preparation of data in a suitable form. In the case of historical demography, this means extracting structured data about people from sources like national censuses, cadastral data, tax lists, etc. These sources are unstructured information, concealed formats that are hard to decode and laden with ambiguity. This task is often performed manually by a trained historiographical researcher, who scrutinizes archived documents."><meta name=citation_journal_title content="DHQwords"><meta name=citation_issn content="2694-2658"><meta name=citation_issue content="15.1"><meta name=citation_publisher content="Center for Digital Humanities, Princeton University"><meta name=DC.rights content="http://creativecommons.org/licenses/by/4.0/"><meta name=author content="Davor Lauc, Darko Vitek"><meta name=generator content="Center for Digital Humanities, Princeton University"><meta name=dcterms.created content="2021-05"><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-regular.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-italic.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-regular.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-300.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-700.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-300italic.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-500italic.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-700italic.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-500.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/Source_Sans_Pro/source-sans-pro-v13-latin-regular.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/Source_Sans_Pro/source-sans-pro-v13-latin-900.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/Source_Sans_Pro/source-sans-pro-v13-latin-300.woff2 crossorigin><title>Inferring standard name form, gender and nobility from historical texts using stable model semantics</title><meta name=description content="DHQwords Issue 15.1, May 2021. A research periodical irregularly published by the Center for Digital Humanities at Princeton. "><meta property="og:title" content="Inferring standard name form, gender and nobility from historical texts using stable model semantics"><meta property="og:description" content="Introduction The necessary condition of many endeavours in the digital humanities domain is the preparation of data in a suitable form. In the case of historical demography, this means extracting structured data about people from sources like national censuses, cadastral data, tax lists, etc. These sources are unstructured information, concealed formats that are hard to decode and laden with ambiguity. This task is often performed manually by a trained historiographical researcher, who scrutinizes archived documents."><meta property="og:type" content="article"><meta property="og:url" content="https://startwords.cdh.princeton.edu/vol/15/1/000544/"><meta property="og:image" content="https://startwords.cdh.princeton.edu/social.png"><meta property="article:section" content="vol"><meta property="article:published_time" content="2021-05-21T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-04T13:14:15-04:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://startwords.cdh.princeton.edu/social.png"><meta name=twitter:title content="Inferring standard name form, gender and nobility from historical texts using stable model semantics"><meta name=twitter:description content="Introduction The necessary condition of many endeavours in the digital humanities domain is the preparation of data in a suitable form. In the case of historical demography, this means extracting structured data about people from sources like national censuses, cadastral data, tax lists, etc. These sources are unstructured information, concealed formats that are hard to decode and laden with ambiguity. This task is often performed manually by a trained historiographical researcher, who scrutinizes archived documents."><link rel=stylesheet href=/style.css><link rel=stylesheet href=/print.css media=print><script src=/js/polyfills.js></script><script defer src=/js/bundle.js></script></head><body class=article><header><nav class=main aria-label=main><ul><li class=home><a href=/>dhq</a></li><li class=issues><a href=/vol/>volumes</a></li></ul></nav></header><main><article><div class=grid><header><p class=number><a href=/vol/15/1/>Issue 15.1</a></p><p class=theme>Göttingen Dialogues in Digital Humanities</p><h1>Inferring standard name form, gender and nobility from historical texts using stable model semantics</h1><p><ul class=authors><li><address>Davor Lauc</address></li><li><address>Darko Vitek</address></li></ul></p><p><time class=pubdate datetime=2021-05>May 2021</time></p><ul class="categories tags"></ul><ul class=tags><li><span class=tag>sequence tagging</span></li><li><span class=tag>proper name normalisation</span></li><li><span class=tag>answer set programming</span></li></ul><p class=formats></p></header><section class=print-only><a class=first-page-header href=/ aria-label=Startwords><img alt=Startwords src=/pdf-logotype.svg></a>
<a class=page-header href=/ aria-label=Startwords><img alt=Startwords src=/pdf-logo.svg></a>
<a href=http://doi.org/ rel=alternate class=page-doi>doi:</a></section><div class=text-container><h1 id=heading></h1><h2 id=introduction>Introduction</h2><p>The necessary condition of many endeavours in the digital humanities domain is the preparation of data in a suitable form. In the case of historical demography, this means extracting structured data about people from sources like national censuses, cadastral data, tax lists, etc. These sources are unstructured information, concealed formats that are hard to decode and laden with ambiguity. This task is often performed manually by a trained historiographical researcher, who scrutinizes archived documents. It is an extremely tedious exercise that is prone to error.</p><p>Due to the availability of many historiographical sources in various digital formats – from scans to transcripts – it is possible that a computation model able to achieve this task could be developed. Ideally, this system would be able to transform unstructured data, like scans of historical documents, into structured formats. In this sense, it would be great to have historical data in highly structured form, with ambiguity reduced on every level – the semantic web is a good representational format to do this.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><p>However, the implementation of such models comes with many challenges, even when transcripts of sources are available in digital or printed formats, and the problematic recognition of indecipherable handwritten text<a class=footnote-ref href=#vamvakas2008> [vamvakas2008] </a>can be omitted.</p><p>One of the first, seemingly trivial, challenges relates to parsing name expressions that include individuals’ names, titles and occupations, and inferring basic facts about persons, such as gender and some aspects of their social statuses. This is often a prerequisite for more advanced processing, for example named entity resolution (record linkage), ontology construction, etc. Even when more contemporary data sources are involved, the ambiguity, multitude and various combinations of first name/last name/titles that are in use can make this task quite difficult to model. Sometimes, there is just not enough information available in text to reach reliable conclusions, and only an educated guess is possible. In the case of historical source transcripts, the task is even more challenging because many of the names and personal titles involved are now extinct and cannot be found in modern dictionaries. Furthermore, there are no standard transcriptions of names, and those transcripts that exist are often mottled and dirty.</p><p>Not much research on this particular topic has been done within the digital humanities community, but the authors expect that this will become an active field of research. As Anna Foka claims:</p><blockquote><p>The imminent assessment and representation of historical data has admittedly challenged the boundaries of historical knowledge and generated new research questions.<br><a class=footnote-ref href=#foka2018>[foka2018] </a>The related problem of entity resolution, and its importance to digital humanities for have been has been researched more extensively<a class=footnote-ref href=#johannessen2005> [johannessen2005] </a><a class=footnote-ref href=#boren2007>[boren2007] </a><a class=footnote-ref href=#heckmann2014>[heckmann2014] </a><a class=footnote-ref href=#dewilde2017>[dewilde2017] </a>. Proper solution of this particular problem of structuring proper names can have important application to many digital humanities endeavours, from improvements of handwriting recognition systems where correct parse of a proper name can be used to improve the loss function, to usage in multilingual family narrative generation from genealogical data<a class=footnote-ref href=#lauc2018> [lauc2018] </a>.</p></blockquote><h2 id=materials>Materials</h2><p>The primary type of the historical sources in the scope of this research are the so-called serial sources. These are sources like parish books (one of the biggest serial sources in European history), tax lists, and censuses. One of their important characteristics is systematic repetition of structure, which makes them a kind of predecessors of modern database systems, but unfortunately not in a modern structured format. Typical historiographical method of processing such sources includes a taxing process of translating them into structured forms, and it often happens that even when this is done, data are underused due to number of reasons, such as low-tech solution, large number of errors, etc. It often takes a lifetime of one lonely researcher to finish analysing just one such source, for example one tax census<a class=footnote-ref href=#vrbanus2010> [vrbanus2010] </a>.</p><h2 id=characteristics-of-serial-sources-in-croatian-demography>Characteristics of Serial Sources in Croatian Demography</h2><p>During the Middle Ages, Croatian state had undeveloped state institutions, which was mostly caused by weak central government. This was the main reason why Ottoman Empire successfully conquered it in the 15th and 16th century. Therefore, the number of sources from that period is quite limited and they are almost exclusively in Latin.<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><h2 id=test-case>Test Case</h2><p>The test case used for the research was from the middle 19th century census for the old town centre of Zagreb. This census, which was performed in 1857, was the first modern census in Croatia. It is a valuable source of information about the social structure of the 19th century Zagreb. A systematic analysis of the data has yet to be performed due to a number of difficulties. At the time of the census, Croatia was a part of the Habsburg monarchy and the language of the census is German. As the Latin language was dominant in the public service, many Latin name forms were Germanized, and many Czech, Slovak, Italian and German names were Croatized or Latinized. Additionally, there was no standard order of first and last names, many of the first and last names were not separated, and various additional notes were not clearly separated from names, especially when it comes to members of the nobility. Because of all these difficulties, the manual transformation of this source into structured data represents a very tedious and error-prone task.</p><p>Our goal was to develop a highly accurate model that can parse name expressions and infer standard names from Zagreb’s middle 19th century census and similar historical texts. There was also a requirement to predict gender and nobility of the person from the name expression. The transcription was available as a text file, and after some standard pre-processing and chunking, 1755 records were extracted, including expressions of person names, dates of births, occupation and similar. We decided to apply standard natural language processing tools to this text.</p><h2 id=methods-and-methodology>Methods and Methodology</h2><p>Our hypothesis was that the best model for this task could be achieved by combining a probabilistic approach with a rule-based approach in the framework of Answer Set Programming.</p><h2 id=applying-standard-nlp-pipeline-in-a-historical-text>Applying Standard NLP Pipeline in a Historical Text</h2><p>A common approach to tackle the problem of transforming unstructured images to structured information is designing a natural language programming (NLP) pipeline, wherein the first step includes optical character recognition (OCR)/handwriting recognition (HWR) or transcription. Unfortunately, both of these processes are laden with challenges, and more than often they include a lot of decrypting. The result of converting a historical source to text is usually very messy, and it is commonly referred to as adirtytext. As further processing requires relatively clean text, the dirty text usually needs to be corrected – this includes spell-checking, joining separated word parts, etc.</p><p>The next phase is tokenisation, i.e. splitting text into tokens, usually words. However, the situation is often quite complicated. Defining what exactly counts as a token (e.g. does it include full stops) is an important decision that can have big impact on further steps. Ready-available tokenizers (usually rule-based) did not perform well on our test case. Therefore, we have applied an aggressive tokenisation in our research, splitting everything into sequences of letters vs. non-letters. Another connected step in the NLP pipeline is the segmentation of text, usually into sentences. Although this step is not exactly applicable to our test set, it is a well-known fact that sentence splitters do not perform well on historical texts, as they are trained on the modern ones<a class=footnote-ref href=#petran2012> [petran2012] </a>.</p><p>The following step would be name-entity recognition (NER), i.e. marking the beginning and end of named entities and classifying each such expression as person, organisation, place, temporal expression, etc. Since serial sources consist mostly of such named entities, successful NER would chunk almost the entire text. Unfortunately, modern NER systems do not perform well on historical text. We have tested some of the best NER systems like Stanford NER, which has an f-score of over 90% on modern texts, but it has performed badly on our test case. We have not the calculated exact measure, but the results were so flawed that it seemed needless to do a formal evaluation.</p><p>Another important standard task in this context would be Entity resolution, also called record linkage or record deduplication, where different occurrences of the name of same entities are connected. For example, in parish church books, one person might first be baptised, then married, then mentioned as godfather and finally be deceased. It is worth identifying all these names as referencing the same object, in this case the same person.</p><p>Finally, the last phase would be relation or relationship extraction, i.e. extracting relations among entities in the text, for example if a person is born at some place, married to someone, etc. In the broader sense, relation extraction can also include inferring the relationships. For example, if we have a relation being <em>father of</em> between a father and two daughters, we can infer relation <em>being sister</em> between them. Similarly, as the relation <em>being mother of</em> is functional, when it occurs between one entity and two different entities, the system can identify those entities as the same. This is something that is standardly done by semantic web technologies.</p><p>Naturally, since the NER systems did not perform well on the test case, it was impossible to apply the existing relationship extraction systems.</p><p>It is worth mentioning than an alternative approach to a segmented NLP pipeline could be a technique called joint inference<a class=footnote-ref href=#poon2007> [poon2007] </a>. In joint inference all levels of processing are performed in the same time, with constraints and information on all levels used for inferring the most probable inference. This approach is more similar to the process of analysis performed by a human researcher.</p><h2 id=proper-names-parsing>Proper Names Parsing</h2><p>The segmented parts of the census were available, so our research started with analysing what would a historian working with such data do with them. We first wanted to understand how this process is performed by a human, in order to build an effective computational model. The first obstacle we encountered was understanding proper names. When historians analyse such sources, they often unconsciously extract a lot of information from the name, and these information constrain their search by reducing ambiguity. For example, if two persons in the same part of the text have the same surname, they are probably related; if someone has a female name, it is very improbable that that person is a godfather, etc. Therefore, it is worth extracting these information from the name, especially in the context of joint inference, where all available information should be used to resolve ambiguity.</p><p>Parsing of proper names, such as analysing inner structure of names, is not a standard part of NLP pipeline. Parts of text containing proper names are usually recognised by a NER subsystem, and other techniques are used for entity resolution and relation extraction subsystems. The task of parsing proper names does seem to be easy; in the case of personal names, one just has to use regular expressions – first token is first name and second token is last name. After that, the only thing left to do is to check the ending of the first name to classify the person as a female or a male. In reality, situation is much more complex. Even when only the modern names are analysed, there is no easy solution to the name parsing, at least no ready-available system.</p><p>To illustrate the problem, even in modern languages there is a great variety of names, name forms and cultural conventions. In the case of famous Icelandic singer Björk Guðmundsdóttir, her second name is not really a surname and one should address her with full name. This means that you would find her listed in address book under letter B not G. Similar case is with Arabic, Chinese, Russian, Polish, Serbian and other names that usually start with the last name. Spanish people traditionally have four names, and are addressed by the third one, and the situation in even more complicated in Brazilian Spanish.</p><p>The situation with names is even more complex in historical contexts. Until the second half of the 18th century, which is relatively recent, there were no standard name forms in many European countries. In the example of the first Croatian king, Kralj Tomislav,Kraljmeans king – it is a title, not a first name, andTomislavis the first name. In the modern language, however,Kraljis a quite common last name. The situation gets even more complicated with noble titles, maiden names, etc.</p><p>It would be very helpful to have an accurate proper name parser, the results of which could be used in a more advanced analysis. To the best of the authors’ knowledge, this problem did not receive much attention in NLP related communities.</p><h2 id=proper-names-parsing-state-of-the-art>Proper Names Parsing State of the Art</h2><p>Parsing name records into constituent parts can be modelled as a sequence labelling problem, viewed as a special case of part-of-speech tagging and shallow parsing. Although this particular problem has not received much attention in recent literature, extensive work has been done on the related and more general problems of Part-Of-Speech (POS) tagging, shallow parsing and named entity recognition<a class=footnote-ref href=#graves2012> [graves2012] </a><a class=footnote-ref href=#osborne2000>[osborne2000] </a><a class=footnote-ref href=#nadeau2007>[nadeau2007] </a>.</p><p>Early sequence labelling systems were rule-based; for example, those developed by Brill<a class=footnote-ref href=#brill1992> [brill1992] </a>, which are still used in some application domains<a class=footnote-ref href=#chiticariu2010> [chiticariu2010] </a>. Today, the best performing models are probabilistic, and are generally based on probabilistic graphical models. In particular, models that use conditional random fields represented the state-of-the-art models<a class=footnote-ref href=#sha2003> [sha2003] </a><a class=footnote-ref href=#viet2014>[viet2014] </a>, until the recent usage of deep learning models<a class=footnote-ref href=#devlin2018> [devlin2018] </a>.</p><p>However, studies on the application of probabilistic models on historical texts have yet to yield satisfactory results. It is very tedious to annotate historical texts, especially when many different sources have to be analysed and the reuse of existing training datasets is not a feasible option. Another reason why there is a need to consider alternatives to the probabilistic approach is that, due to the noisiness of historical sources, the integration of sequence labelling with a joint inference model<a class=footnote-ref href=#sha2003> [sha2003] </a>is promising as an alternative to the use of a traditional language processing pipeline. Joint inference can reduce OCR ambiguities, and an approach that combines text correction and sequence labelling with the higher-level syntax, semantics and historiographical constraints is more representative of the way in which a human historiographer would perform the task. For example, the probability of social status depends on location, members of the household and place of origin, and ambiguous last names can be resolved by family member records. Although joint inference is compatible with the probabilistic approach<a class=footnote-ref href=#mccallum2009> [mccallum2009] </a>, the rule-based approach seems more promising in this domain. As the Markov Logic Networks, a framework that Sha and Pereira<a class=footnote-ref href=#sha2003> [sha2003] </a>used, does not readily scale to this kind of problem, we selected a rule-based framework that was based on stable model semantics.</p><h2 id=answer-set-programming>Answer Set Programming</h2><p>Stable model semantics can be viewed as the semantics of logic programming. So the rules can use (almost) the full expressivity power of the first-order logic. A further benefit relates to the non-monotonicity of negation as failure, which enables easy modelling of interaction among general and specific rules. Answer set programming (ASP) implements stable model semantics. Due to modern, highly optimized grounders and SAT solvers, ASP implementations are fast enough for many applications and are mostly used for high-level reasoning tasks such as planning, diagnostics, learning and scheduling<a class=footnote-ref href=#gelfond2008> [gelfond2008] </a>. This framework also looks very promising for NLP applications<a class=footnote-ref href=#balduccini2013> [balduccini2013] </a>, and especially for our problem. The leading ASP modelling language, Potassco, which was developed at the University of Potsdam<a class=footnote-ref href=#gebser2011> [gebser2011] </a>, includes support for weak constraint and optimization. This enables the formalization of the sequence labelling task as an optimization problem and, therefore, seems particularly promising in the context of the joint inference model.</p><h2 id=dataset>Dataset</h2><p>The test set for the models consisted of 1774 transcribed records from the census, including name expressions, gender and nobility labels. The available dataset of 4018 labelled modern international names (12,075 tokens) was used for the initial training and test dataset.</p><h2 id=name-parsing-models>Name parsing models</h2><p>In order to evaluate and compare the appropriateness of the probabilistic and rule-based models for the task, both conditional random field (CRF) and rule-based models based on stable model semantics (SM Rules) were developed. They shared tag set and features. The selection of a tag set is an important task, since it influences the accuracy of the learned models and the usability of the model. If there are fewer numbers of categories, the accuracy will generally improve, but less structure will be introduced and less ambiguity will be reduced.</p><p>For a tag set, the following classes were selected:</p><ul><li>N.FN.(M/F): male/female first name; e.g.,Gustav/ Josephine</li><li>N.LNlast name, e.g.,Philippovich</li><li>N.LN.PREFlast name prefix, e.g.de,von</li><li>N.TITLE: person title, e.g.,pl.(noble),dr.</li><li>N.QUAL: surname qualification, e.g.,ml(junior)</li><li>N.SALUTperson salutation, e.g.,herr(mister)</li><li>GEO:geographic/location term, e.g.,Zagreb,Ilica</li><li>OTHER, terms not in the above list, like notes, comments, etc.</li></ul><p>All tags, except OTHER, had standard –B and –I suffixes, for denoting multi-token tags.</p><p>The features for both models included token, n-grams, packed word forms (lower/upper-case combination sequence, packed to three characters), and a dictionary entry from an available international name dictionary, including estimation of monogram frequency.</p><p>The CRF model was trained in the standard way, using the CRFsuite<a class=footnote-ref href=#okazaki2007> [okazaki2007] </a>.</p><h2 id=rule-based-system>Rule based-system</h2><p>The rule-based model was implemented in the Potassco ASP system<a class=footnote-ref href=#leuschel2014> [leuschel2014] </a>.</p><p>Head of the rules were in the following form: <code>tag(I,P,</code> _ <code>[tag],[weight], [level]</code> _ ) where <code>I</code> is id of record, <code>P</code> is position of token in name expression, <code>[tag]</code> is one of the tags from the tag set, <code>[weight]</code> is an estimation of certainty of the rule, and <code>[level]</code> represents generality of the rule, as explained below. Rule body is a set of (possible negated) features. An example of this rule is:</p><pre tabindex=0><code>tag(I,P,n_title_b,70,1) :- lexc(I,P,n_title_b,_,_), wordform(I,P,&#34;LlLlLl&#34;), wordform(I,P-1,&#34;LuLlLl&#34;), lexc2(I,P-1,n_fn,_,1), lexc2(I,P+1,n_ln,_,1), not specExists(I,P,1).
</code></pre><p>It defines that token at position <code>P</code> is a title if it has a dictionary entry for title at any frequency, it is lowercase (LlLlLlwordform), token before it is capitalized and the most frequently used first name, and the token after is the most frequently used last name according to the dictionary.</p><p>The last atom in the rule ( <code>specExists</code> ) used the non-monotonic nature of stable model semantics, stating that the rule is satisfied only if there is no other rule for the same token that is more specific. The most general (default) rules were on level 1, more specific on level 2, etc.</p><p>Some of the initial rules were hand-coded, but the majority of them were learned from the initial training dataset. Although much research has been performed on rule induction<a class=footnote-ref href=#muggleton2015> [muggleton2015] </a>, there is no suitable rule learning system available for ASP; as such, a rudimentary one was developed, inspired by Inductive logic programming algorithms.</p><h2 id=learning-rules>Learning rules</h2><p>The pseudo code for the preliminary rule induction system was as follows.</p><pre tabindex=0><code>Generate all features of examples in the training set Generalize features [replace constants with variables, relativize positions] Select top-n features (eliminate all with low chi-square in the training set) for lev in 1 to maxLevel predicted = tag training set with rules up to level lev-1 for tag in tag-set for x in power set of features up to length maxCardinality gain = count false negative matching x in predicted loss = count true negative matching x in predicted if gain&gt;loss add x to rules candidates for y in rules candidates sorted by gain-loss if rules does not overlap with rules add y to rules
</code></pre><p>The hyper-parameters <code>maxLevel</code> and <code>maxCardinality</code> control the number of level of specific rules and the number of atoms in rules. For performance reasons, the learning system was implemented in Python and Potassco ASP. Trained on the modern language training set, the system generated 218 rules on four levels of generality. Token level f1-score, measured on 20% of the modern data-set was 0.95.</p><h2 id=results>Results</h2><p>We were interested to see whether the model could correctly classify all the parts of a record; i.e., name expressions. Therefore, instead of the more common precision/recall/f-score measure of token level classification accuracy, only the items where all tokens were correctly classified were counted as correct. Therefore, the parsing accuracy was defined as the percentage of test records for which the test results were identical to the manually parsed records.</p><p>Statistical and rule-based models were evaluated as trained on initial modern language training set and after improving models. The SM Rules model was improved by hand-writing four additional rules that were obvious from the errors in the first model. The CRF model was improved by labelling 100 additional records from the source and adding these to the dataset. This task took approximately twice the time it took to write the rules. This can be considered to represent a similar investment of resources, although it is not a precise measure of the effort invested in improving the models because both procedures depended on the characteristics of the datasets and the experience of the researcher.<br>Parsing evaluationInitial modelImproved modelSM rulesCRFSM rulesCRFAccuracy rate79.82%67.93%97.01%76.21%Support1416120517211352<br>As the data in the table above clearly indicate, the models were significantly different, with the p-value of McNemar test for both being<code>lt 2.2e-16</code>.</p><h2 id=gender-and-nobility-model-results>Gender and nobility model results</h2><p>The gender and nobility prediction model was based on character n-Gram (length 1-9) of name expressions in census data. Name expressions were pre-processed by marking the beginning and end, lowercasing and stripping accents. A support vector classifier with linear kernel was used, and the parameters were obtained by grid search. As the results of k-folding cross validation were satisfactory, the initial plan for building rule-based classifiers was abandoned.<br>Gender and nobility evaluation tableNobility status predictionGender predictionClassprecisionrecallf1-scoresupportClassprecisionrecallf1-scoresupportNoble0.981.00.99321Male0.980.990.98192Common1.00.850.9234Female0.990.980.98163</p><h2 id=discussion>Discussion</h2><p>Summary of the researchers’ experience in applying statistical and rule-based approach to historical text is given in the following table:<br>Comparison between the statistical and the rule-based approachCRFRule-basedDrawbacksAdvantagesDrawbacksAdvantagesCRFs must be trained on a new training set whenever a historical source is systematically different from a previously built model.CRFs are widely used, so it is easy to use implementations of CRF models.If rules are hand-coded, it has to be done by researchers, trained and experienced in both domain specific knowledge and a rule-based system.Possibility of coding general and domain specific constraints and rules.Models are next to impossible to be modified ad hoc, in order to explore observed regularities in a new domain or historical source.Outperforms other models (including HMM) in many application domains.Learning algorithms are inferior to the ones used to train statistical models.Learning can be performed on top of the hand-coded rules.In semantically opaque models, there is no easy understandable answer to awhyquestion.Models can be developed from dataset labelled by persons lacking linguistic and/or computer science skills.Complex interaction of rules can make it difficult to understand and modify the rules ad hoc.Resulting rules are relatively semantically transparent and can be modified and improved ad hoc.</p><h2 id=conclusion-and-outlook>Conclusion and Outlook</h2><p>The preliminary results indicated that the rule-based approach, which was based on stable model semantics, is more suitable for inferring standard name forms from historical texts than the more widespread statistical approach. To confirm this result, the experiment should be repeated using additional historical sources and statistical models. To predict gender and nobility, it seems more convenient to use standard statistical classifiers when labelled data is available. The generalization accuracy of the models should be tested on additional historical sources. A model ensemble that includes both a rule-based method and the CRF model is another interesting development that is worth a future research.</p><p>In order to make the model more suitable for real-world applications in historiographical research, it would be worthwhile to develop an interactive interface that would enable incremental rule learning. It should use a simple web interface and the rule induction system should recommend source-specific rules to the researcher, hiding the underlying complexity of the rule system.</p><p>The development of a more complex system that includes joint inference from the scan of a source to a historical demography web ontology is a worthwhile longer-term goal. This research represents a small step toward the development of such a system.</p><ul><li id=balduccini2013>Balduccini, M. “Some Recent Advances in Answer Set Programming (from the Perspective of NLP),” _2013 CEUR Workshop Proceedings_ . 1044. 1-6.</li><li id=boren2007>Boren, L., e. a., “Naming the Past: Named Entity and Animacy Recognition in 19th Century Swedish Literature.” In: _ACL 2007. Proceedings of the Workshop on Language Technology for Cultural Heritage Data._ (2007) pp. 1-9.</li><li id=brill1992>Brill, E., “A simple rule-based part of speech tagger.” Stroudsburg, PA, USA, Association for Computational Linguistics, (1992) pp. 152-155.</li><li id=chiticariu2010>Chiticariu, L. a. a., 2010. “Domain adaptation of rule-based annotators for named-entity recognition tasks.” Massachusetts, USA, Association for Computational Linguistics , (2010) pp. 1002-1002.</li><li id=dewilde2017>De Wilde, M., “Semantic Enrichment of a Multilingual Archive with Linked Open Data.” _Digital Humanities Quarterly_ Vol 11/4 (2017).</li><li id=devlin2018>Devlin, J., Chang, M.W., Lee, K. and Toutanova, K., “Bert: Pre-training of deep bidirectional transformers for language understanding” . (2018) arXiv preprint arXiv:1810.04805.</li><li id=foka2018>Foka, A., “Digital Technology in the Study of the Past.” _Digital Humanities Quarterly_ Vol 12/2 (2018).</li><li id=gebser2011>Gebser, M. & all, a., “Potassco: The Potsdam Answer Set Solving Collection.” _AI Communications - Answer Set Programming_ , (2011) pp. 107-124.</li><li id=gelfond2008>Gelfond, M., 2008. “Answer sets.” In: _Handbook of Knowledge Representation_ . s.l.:Elsevier, p. 285–316.</li><li id=gelfond1998>Gelfond, M. L. V., “The stable model semantics for logic programming.” (1998) p. 1070–1080.</li><li id=graves2012>Graves, A., “Supervised Sequence Labelling.” In: _Supervised Sequence Labelling with Recurrent Neural Networks_ . s.l.:Springer Berlin Heidelberg, (2012) pp. 5-13.</li><li id=heckmann2014>Heckmann, D., e. a., “Citation segmentation from sparse & noisy data: A joint inference approach with Markov logic networks.” _Digital Scholarship in the Humanities_ (2014) pp. Vol 31/2. 333-356.</li><li id=johannessen2005>Johannessen, J. B., e. a., “Nemed Entity Recognition for the Mainland Scandinavian Languages.” _Digital Scholarshipin the Humanities_ , pp. (2005) Vol 20/1. 91-102.</li><li id=lauc2018>Lauc, D., Vitek, D. “From the History to the Story: Harvesting Non-Monotonic Logic and Deep Learning to Generate Multilingual Family Narratives from Genealogical Data.” DH Budapest 2018 Conference. (2018)</li><li id=leuschel2014>Leuschel, M. & Schrijvers, T., “Technical Communications of the Thirtieth International Conference on Logic Programming (ICLP'14).” s.l., s.n. (2104)</li><li id=mccallum2009>McCallum, A., “Joint inference for natural language processing.” Boulder, Colorado, Association for Computational Linguistics. (2009)</li><li id=muggleton2015>Muggleton, S. H. W. a. H. W., “Latest Advances in Inductive Logic Programming.” s.l.:Imperial College Press. (2015)</li><li id=nadeau2007>Nadeau, D. & Sekine, S., “A survey of named entity recognition and classification.” “Lingvisticae Investigationes.” (2007)</li><li id=okazaki2007>Okazaki, N., “CRFsuite: a fast implementation of Conditional Random Fields (CRFs),” s.l.: s.n. (2007)</li><li id=osborne2000>Osborne, M. “Shallow parsing as part-of-speech tagging.” s.l., ACM, (2000) pp. 145-147.</li><li id=petran2012>Petran, F., “Studies for Segmentation of Historical Texts: Sentences or Chunks?. On Annotation of Corpora for Research in the Humanities” ACRH-2, (2012) p.75.</li><li id=poon2007>Poon, H. & Domingos, P., “Joint inference in information extraction.” _AAAI_ m (2007) pp. 913-918.</li><li id=sha2003>Sha, F. & Pereira, F., “Shallow parsing with conditional random fields.” Edmonton, Canada, Association for Computational Linguistics, (2003) pp. 134-141.</li><li id=vamvakas2008>Vamvakas, G. e. a., “A complete optical character recognition methodology for historical documents.” (2008) IEEE.</li><li id=vrbanus2010>Vrbanus, M. “Skrivena povijest – tajnoviti svijet brojki.” Povijesni prilozi. Vol. 39/39., (2010) pp. 39-71.</li><li id=viet2014>Viet Cuong, N. a. a., “Conditional random field with high-order dependencies for sequence labeling and segmentation.” _The Journal of Machine Learning Research_ Vol 15/1, (2014) pp. 981-1009.</li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Although the exact boundary between structured and unstructured data is imprecise, for the scope of this research we can define structured data as those data in which ambiguity is reduced to the level where no additional human intervention is needed to perform desired processing. Ambiguity exists on different levels. In the analysis of text, one commonly distinguishes between lexical and structural ambiguity. However, in the context of analysing historical documents, semantic ambiguity is important. Even if we have, for example, a name of the person or a place in proper digital format, ambiguity of whether this person is the same one as in previous document makes this information unstructured for some purposes. Similarly, if the wordfatheroccurs in the text, it is important to distinguish whether this is a binary predicate (a relation between two individuals) or a singular predicate (property of one individual being a priest). In the context of our use case, if we have a list of only full names of persons in database and we want to make mailing labels for them, one can say that they are structured; but if we want to list them by surnames, they are unstructured because that cannot be performed easily.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>The notable exception is the Baška tablet, written in Glagolitic script. It is one of the first monuments containing an inscription in the Croatian recension of the Church Slavonic language, dating from c. 1100. However, most of the historic documents were written in the Latin language, mostly within diplomatic collections.## Bibliography&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></div></article></main><footer><nav aria-label="footer links"><ul><li><a class=highlight-focus href=/tags/>Tags</a></li><li><a class=highlight-focus href=/about/>About</a></li><li><a class=highlight-focus href=/categories/>Keywords</a></li></ul></nav><div class=icons><a class="license highlight-focus" rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons Attribution No-Derivatives 4.0 International License" src=/img/logos/license.svg width=120 height=42></a></div></footer></body></html>