<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://gohugo.io/" version="0.116.0">Hugo</generator><link href="https://startwords.cdh.princeton.edu/vol/14/4/" rel="alternate" type="text/html" title="html"/><link href="https://startwords.cdh.princeton.edu/vol/14/4/index.xml" rel="alternate" type="application/rss+xml" title="rss"/><link href="https://startwords.cdh.princeton.edu/vol/14/4/atom.xml" rel="self" type="application/atom+xml" title="Atom"/><updated>2023-08-04T17:16:50+00:00</updated><rights>This work is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License.</rights><id>https://startwords.cdh.princeton.edu/vol/14/4/</id><entry><title type="html">Automated Visual Content Analysis for Film Studies: Current Status and Challenges</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000518/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000518/</id><author><name>Kader Pustu-Iren</name></author><author><name>Julian Sittel</name></author><author><name>Roman Mauer</name></author><author><name>Oksana Bulgakowa</name></author><author><name>Ralph Ewerth</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="1-introduction">1 Introduction</h2>
<p>In contrast to the field of computer-assisted research in the arts that has been established for several years<a class="footnote-ref" href="#anitha2013"> [anitha2013] </a><a class="footnote-ref" href="#johnson2008"> [johnson2008] </a><a class="footnote-ref" href="#klein2014"> [klein2014] </a><a class="footnote-ref" href="#resig2014"> [resig2014] </a>, there is a need to catch up in scientific approaches to film (represented in the fields of New Film History and Stylometry). An important reason is the lack of practical software solutions available to date and the incompatibility of quantitative research designs with existing methodologies for film studies. In this context, some researchers criticise above all the appropriation of a technicistic, unrelated mission statement, which advocates of digital humanities apply to their own subject following other principles<a class="footnote-ref" href="#liu2012"> [liu2012] </a><a class="footnote-ref" href="#missomelius2014"> [missomelius2014] </a>. However, more recent research<a class="footnote-ref" href="#heftberger2016"> [heftberger2016] </a><a class="footnote-ref" href="#sittel2017"> [sittel2017] </a>has shown that qualitative and quantitative analysis are by no means mutually exclusive, but can be integrated in order to enrich film studies with new impulses.</p>
<p>The statistical film analysis developed by the physicist Salt thus holds the potential of a methodological guideline for quantifying filmic characteristics<a class="footnote-ref" href="#salt2006"> [salt2006] </a><a class="footnote-ref" href="#salt2009"> [salt2009] </a>. This methodology focuses on quantifiable factors in the formal structure of a film such as camera shot length, which is considered an objective unit because it can be measured over time. The various forms of camera usage and movement (such as tracking shots, pans and tilts, camera distance, i.e., shot size) as well as other techniques (such as zoom-in and -out or the use of a camera crane) are also relevant for quantification. Casting this set of techniques as measuring instruments, it is possible to obtain data that scientists can relate to verifiable criteria in terms of film production history and to formulate hypotheses that allow conclusions to be drawn about the formal stylistic development of the selected films. To this end, Salt&rsquo;s concept allows for complete traceability of the measurement results and thus also of the numerical values to a theory set.</p>
<p>The concept was criticized for its reductionism<a class="footnote-ref" href="#fluckiger2011"> [fluckiger2011] </a>, which prevents it from being connected to the qualitative research methods that dominate film studies. However, research in digital humanities has shown that quantitative parameters such as shot length are a suitable foundation for various analytical tools when it comes to the qualitative investigation of data (<a href="#tsivian2008">Tsivian 2008</a>;<a href="#buckland2009">Buckland 2009</a>; many others). In this way, quantitative research according to Salt makes it possible to validate stylistic changes in the work of emigrated European directors due to technical opportunities of the American studio system, or even to collect the average shot lengths of numerous productions from the beginning of film history to the present. Such research allows researchers to draw conclusions about the progressive acceleration of editing and thus provides information about the development of film technology and changes in our viewing habits. These questions concerning stylistic research in film studies cannot be examined without a corresponding quantitative research design, although Salt&rsquo;s concept remains too inflexible for broader application.</p>
<p>In this context,<a href="#korte2010">Korte&rsquo;s work (2010)</a>is regarded as pioneering (especially in German-speaking countries) in transferring quantitative methods into the framework of a qualitative analysis immanent in the work. An example for this is Rodenberg&rsquo;s analysis of Zabriskie Point (directed by Michelangelo Antonioni, 1970) in Korte&rsquo;s introduction to systematic film analysis (2010), which graphically depicts the stylistic structure of the film in an innovative way. Thus, for a detailed analysis Rodenberg visualises the adaption and alignment of editing rhythms to the characterisations of the persons in the narrative, and makes the alignment of music and narration comprehensible using diagrams.<a href="#heftberger2016">Heftberger (2016)</a>, for example, combines the analysis of historical sources such as editing diagrams and tables by the Russian director Vertov with computer-aided representations of digital humanities in order to provide insights into the filmmaker&rsquo;s working methods. Heftberger starts with copies of Vertov&rsquo;s films, which were analysed for structural features using the annotation software ANVIL<a class="footnote-ref" href="#kipp2001"> [kipp2001] </a>, but also for dissolves or condition-related factors (e.g. markings in the film rolls or damage to the film). Within the framework of single and overall analyses, the data serve to elucidate the director’s intentions.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Increase and decrease of shot lengths in Antonioni’s Blow Up (1966) using Videana.
        </p>
    </figcaption>
</figure>
<p><a href="#sittel2016">Sittel (2016)</a>investigated the principle of increase and decrease of shot lengths in Michelangelo Antonioni’s <em>Blow Up</em> (1966). The visualization in Figure 1 was created during this study with the video analysis software Videana<a class="footnote-ref" href="#ewerth2009"> [ewerth2009] </a>and gives an insight into this pattern. This technique, which is increasingly used in film editing, represents a structuring feature of the second half of the film and can be interpreted as a message with regard to the film content.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Average shot length of all Antonioni films in chronological order.
        </p>
    </figcaption>
</figure>
<p>Using Salt&rsquo;s paradigm as a guideline, an analysis of all Antonioni films makes it possible to identify a clear change in style based on shot sizes and camera movements, which extends existing, non-qualitative approaches in a differentiated way. Figure 2 shows that the average shot length becomes shorter across nearly all films. To this end, a principle of systematic camera movement (longer shots) and thus an abandonment of montage gradually gives way to the increasing use of editing.</p>
<p>Research efforts like this benefit from automated computer-based methods that measure basic features of filmic structure. Similar to former work<a class="footnote-ref" href="#estrada2017"> [estrada2017] </a>, we present a comprehensive survey of related software tools for video annotation, but particularly focus on methods for visual content analysis for film studies. First, we examine major software tools for video analysis with a focus on automated analysis algorithms and discuss their advantages and drawbacks. In addition, related work that applies automated video analysis to film studies is discussed. Moreover, we summarise current progress in computer vision and visual content analysis with a focus on deep learning methods. Besides, a comparison of machine vs. human performance in annotation tasks that are relevant for video content analysis is provided. Finally, we discuss future desirable functionalities for automated analysis in software tools for film studies.</p>
<p>The remainder of the paper is structured as follows.<a href="#section02">Section 2</a>reviews existing software tools and algorithms for quantitative approaches in film analysis.<a href="#section03">Section 3</a>discusses recent advancements in the field of video analysis and computer vision. A comparison of human and machine performance in different annotation tasks is provided in<a href="#section04">Section 4</a>.<a href="#section05">Section 5</a>describes requirements for software tools in scholarly film studies and outlines areas for future work.</p>
<h2 id="2-software-tools-and-algorithms-for-quantitative-film-studies">2 Software Tools and Algorithms for Quantitative Film Studies</h2>
<p>Researchers who want to utilise quantitative strategies to analyse film as presented in Figure 1 and 2 usually have to evaluate larger films or video corpora. However, existing software tools so far, with a few exceptions, require a high degree of manual annotation. As a consequence, many current film productions are difficult to evaluate due to ever shorter shot lengths. This section provides an overview of software solutions for film studies and their degree of automation in terms of capturing basic filmic features. While there are numerous existing annotation and video analysis tools, the focus lies on ready-to-use software applications most suitable for quantitative film studies. An overview of the functionalities provided by the selected applications and their current status of availability is presented in Table 1. We also distinguish between application areas in Table 1, since not all of the tools were originally proposed for scholarly film studies as targeted here.</p>
<p>Table 1. Overview of software applications for quantitative approaches in film analysis, characterised by their degree of automation regarding video content analysis tasks. Whilemdenotes manual annotation,arefers to automated annotation.<br>
ToolApplication AreaAvailabilityShot change detectionCamera motionVideo OCRFace detectionColour analysisAnnotation levelVisualisationsAdvene<br>
Film studies/</p>
<p>teaching platform</p>
<p>Desktop App</p>
<p>(free)<br>
aROI<br>
Timelines for shots &amp;</p>
<p>annotation<br>
ANVIL<br>
Psycholinguistics/</p>
<p>social sciences</p>
<p>Desktop App</p>
<p>(free)<br>
mShot<br>
Timelines for annotation tiers &amp;</p>
<p>speech track<br>
Cinemetrics<br>
Film studies<br>
Web-based crowd-sourcing platformmShotCut frequency diagramELAN<br>
Psycholinguistics/</p>
<p>social sciences</p>
<p>Desktop App</p>
<p>(free)<br>
mShot<br>
Timelines for annotation tiers &amp;</p>
<p>speech track segments<br>
Ligne de TempsFilm studies<br>
Desktop App</p>
<p>(free)<br>
amShotTimeline for cutsMedia-threadTeaching platform<br>
Web App</p>
<p>(source code available)<br>
ROIHyper video annotationsVIAN<br>
Film studies</p>
<p>(colour analysis)</p>
<p>Desktop App<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>(not publicly available yet)<br>
aa¹aROITimelines for shots &amp; annotations, colour schemes view, screenshot managerVideana<br>
Media/</p>
<p>film studies</p>
<p>Desktop App</p>
<p>(on request until 2012)<br>
aaaaaROI<br>
Timelines of detections annotations &amp; cuts,</p>
<p>cut frequency diagram, shot list</p>
<h2 id="21-cinemetrics">2.1 Cinemetrics</h2>
<p>In the Cinemetrics project<a class="footnote-ref" href="#tsivian2009"> [tsivian2009] </a>, Yuri and Gunnar Tsivian took up Salt’s methodology and used it for the first time as conceptual guidelines for the implementation of digital analytical instruments, which are freely available as a Web-based platform since 2005.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> The tool allows the user to synchronously view and annotate video material, or to systematically comb through AVI video files. In the advanced mode, customized annotation criteria can be defined in addition to basic features (e.g. frequency and length of shots). The data sets obtained are then collected within an online database according to the principle of crowdsourcing. With metadata for more than 50,000 films to date, it acts as a comprehensive research data archive that documents the development and history of film style. Cinemetrics is the only platform based on Web 2.0 principles that consistently aggregates film data and makes it publicly accessible. However, the analysis of film data is not systematic. Moreover, Cinemetrics relies exclusively on the manual acquisition of data such as shot changes, camera distances, or camera movements. The accurate evaluation of video material such as feature films therefore requires an effort of several hours and is unsuitable for broader studies. Nonetheless, the platform enjoys a high level of visitor traffic. Between 2010 and 2013, the number of users almost doubled (2010: 4,500 clicks per day, 2013: 8,326). The program is regularly used in seminars at the Universities of Chicago, Amsterdam, Taiwan and at the Johannes Gutenberg University of Mainz.</p>
<h2 id="22-anvil-elan">2.2 ANVIL, ELAN</h2>
<p>ANVIL<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> <a class="footnote-ref" href="#kipp2001"> [kipp2001] </a>and ELAN (EUDICO Linguistic Annotator)<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> <a class="footnote-ref" href="#sloetjes2008"> [sloetjes2008] </a>are visual annotation tools, which were originally designed for psycholinguistics and gesture research. They are suitable for the differentiated graphical representation of editing rhythms or for the annotation of previously defined structural features at the shot and sequence level, though it usually requires the export of the data to another statistical software or Microsoft Excel. In contrast to Cinemetrics, ANVIL and ELAN allow the user to directly interact with the video material. They offer a much greater methodological scope, especially through the option of adding several feature dimensions to the video material in the form of tracks. Both systems work according to a similar principle, to which the video segments or the collected shots can be viewed and annotated with metadata. Annotations can also be arranged hierarchically by means of multiple layers which are called tiers. Thus, annotations can be cross-referenced to other annotations or to corresponding shots or video segments, making the programs particularly suitable for a fine-grained analysis of the structure of individual works. However, if several parameters are to be recorded during an evaluation run, repeated viewing of a film is required in order to label the individual tracks with the respective characteristics and features.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of ANVIL software.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of ELAN software.
        </p>
    </figcaption>
</figure>
<h2 id="23-ligne-de-temps">2.3 Ligne de temps</h2>
<p>The analysis tool Ligne de temps<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> was developed between 2007 and 2011 by the Institut de recherche et d’innovation du Centre Pompidou. The tool provides a graphical timeline-based representation of the material and allows for selecting temporal segments in order to annotate different types of modality (video, audio, text) of the corresponding sequence in the movie, or add information in the form of images or external links. Moreover, it is possible to generate colour-coded annotations aligned with the shots by choosing from a range of available RGB colour values. This function can be implicitly used for colour analysis. However, a single colour cannot represent a holistic image or even an entire shot. Ligne de temps enables the automated detection of shot boundaries in the video, as only few of the presented tools do. But there is no information available about the algorithm used and its performance on benchmark data sets.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of Ligne de Temps.
        </p>
    </figcaption>
</figure>
<h2 id="24-advene-mediathread">2.4 Advene, Mediathread</h2>
<p>Advene (Annotate Digital Video, Exchange on the NEt)<a class="footnote-ref" href="#aubert2005"> [aubert2005] </a>is an ongoing project for the annotation of digital videos that also provides a format to share annotations. The tool has been developed since 2002 and is freely available as a cross-platform desktop application.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> It provides a broader number of functionalities compared with the former tools. In particular, the tool enables textual as well as graphical annotations to augment the video and also provides automatically generated thumbnails for each shot. Moreover, it is possible to edit and visualise hypervideos consisting of both the annotations and the video. Target groups are film scholars, teachers and students who want to exchange multimedia comments and analyses about videos such as movies, conferences, or courses. The tool has also been used for reflexive interviews of museum visitors, or with regard to on-demand video providers and movie-related social networks. However, the automatic analysis options that Advene provides are restricted to shot boundary detection and temporal segmentation of audio tracks.</p>
<p>Mediathread<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> was developed by Columbia University’s Center for Teaching and Learning (CTL)<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> and first launched in 2010. It is a web application for multimedia annotations enabling collaboration on video and image analysis. Similar to Advene, Mediathread primarily serves as a platform for collaboratively working and sharing annotations for multimedia and is therefore actively used in classroom environments at various universities, also including courses on film studies. However, it does not provide automated analysis capabilities such as shot detection. In addition, film studies researches wanting to use the web application need a certain degree of expertise to individually deploy the openly available source code.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of Advene.
        </p>
    </figcaption>
</figure>
<h2 id="25-videana">2.5 Videana</h2>
<p>The video analysis software Videana was developed at the University of Marburg<a class="footnote-ref" href="#ewerth2009"> [ewerth2009] </a>. Videana is one of the few software tools to offer more than simple analysis functions such as the detection of shot changes<a class="footnote-ref" href="#ewerth2004b"> [ewerth2004b] </a><a class="footnote-ref" href="#ewerth2009a"> [ewerth2009a] </a>. For example, the software integrates algorithms for text detection<a class="footnote-ref" href="#gllavata2004a"> [gllavata2004a] </a>, video OCR<a class="footnote-ref" href="#gllavata2004b"> [gllavata2004b] </a>, estimation of camera motion<a class="footnote-ref" href="#ewerth2004a"> [ewerth2004a] </a>and of object motion<a class="footnote-ref" href="#ewerth2007a"> [ewerth2007a] </a>, and face detection<a class="footnote-ref" href="#viola2004"> [viola2004] </a>. Further functionalities, which are however not part of the standard version, are the recognition of dominant colour values, person recognition and indexing<a class="footnote-ref" href="#ewerth2007b"> [ewerth2007b] </a>, or the temporal segmentation of the soundtrack. The many available features and the possibility to combine them allow for the flexible formulation of complex research hypotheses and their empirical verification. For example, Videana was used for a media study to investigate user behaviour in Google Earth Tours<a class="footnote-ref" href="#abend2011"> [abend2011] </a><a class="footnote-ref" href="#abend2012"> [abend2012] </a>. However, the software has not been updated since 2012 and therefore does not rely on current state-of-the-art methods in video analysis. Another drawback of the tool is the lack of enhanced visualizations that go beyond simple cut frequency diagrams and event timelines. Finally, the software is not usable through a Web browser, but only available as a desktop software.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of the main window of Videana (provided in<a href="#ewerth2009">Ewerth et al. 2009</a>).
        </p>
    </figcaption>
</figure>
<h2 id="26-vian">2.6 VIAN</h2>
<p>Within the project “Film Colors - Bridging the Gap Between Technology and Aesthetics” <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> at the University of Zurich, the tool VIAN<a class="footnote-ref" href="#fluckiger2017"> [fluckiger2017] </a>for video analysis and annotation is currently being developed with a focus on film colour patterns. In comparison to general-purpose annotation tools like ELAN, VIAN particularly addresses aesthetic analyses of full feature films. The tool is also planned to allow a variety of (semi)-automatic tools for the analysis and visualisation of film colours based on computer vision and deep learning methods such as figure-ground separation and extraction of the corresponding colour schemes. Although the tool is not released yet (announced to be open source), VIAN seems to be a very promising tool with regard to state-of-the-art visual content analysis methods.</p>
<p>Figure 8. Screenshot of VIAN temporal segmentation and screenshot manager.</p>
<h2 id="27-other-tools-and-approaches">2.7 Other Tools and Approaches</h2>
<p>There are some other tools that offer video and film analysis and (to a lesser extent) provide functions similar to the previously introduced applications for automatic film analysis. The Semantic Annotation Tool (SAT) is launched in the context of the Media Ecology Project (MEP) (<a href="http://mediaecology.dartmouth.edu/sat/">http://mediaecology.dartmouth.edu/sat/</a>). It allows for the annotation and sharing of videos on the Web in free-text form, by a controlled set of tags, or polygonal regions in a frame. It targets classroom as well as research environments. The tool itself does not provide (integrated) quantitative measures. However, it can be fed with external machine-generated metadata (by automated video analysis methods). The Distant Viewing Toolkit<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> is a python package that provides computational analysis and visualisation methods for video collections. The software extracts and visualises semantic metadata from videos using standard computer vision methods as well as exploring more high-level patterns such as screen time per character. Another project is eFilms<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> that provides a web-based film player that is supplemented with contextual meta information such as date, geolocation or visual events for the footage. Its main use case is the contextualization of historical footage of the Nazi era. The project also provides a film annotation editor to insert the context annotations. However, as for the aforementioned projects as well, the source code needs to be deployed first and thus is no off-the-shelf and ready-to-use solution for film scholars. Furthermore, the SAT and eFilms tools only offer manual annotation.</p>
<p>Many other works exist that deal with analysis and visualisation of certain filmic aspects. Some early works by Adams et al. transfer concepts of film grammar to computational measures for automated film analysis.<a href="#adams2000">Adams and Dorai (2000)</a>introduce a computational measure of movie tempo based on its filmic definition and use it to automatically extract dramatic sections and events from film. Furthermore,<a href="#adams2001">Adams et al. (2001)</a>present a computational model for extracting film rhythm by deriving classes for different motion characteristics in order to identify narrative structures and dramatic progression. Another work deals with the extraction of narrative act boundaries, in particular the 3-act-story telling paradigm using a probabilistic model<a class="footnote-ref" href="#adams2005"> [adams2005] </a>.</p>
<p><a href="#pause2016">Pause and Walkowski (2016)</a>address the characterization of dominant colours in film and discuss the limitations of the k-means clustering approach. Furthermore, they propose to proceed according to Itten&rsquo;s method of seven colour contrasts<a href="#pause1961">(1961)</a>and outline how it can be implemented algorithmically.<a href="#burghardt2016">Burghardt et al. (2016)</a>present a system that automatically extracts colour and language information using k-means clustering as well as subtitles and propose an interactive visualisation.<a href="#hoyt2014">Hoyt et al. (2014)</a>propose a tool to visualise the relationships between characters in a movie.<a href="#john2017">John et al. (2017)</a>present a visual analytics approach (for the analysis of single or a set of videos) that combines automatic data analysis and visualisation. The interface supports the representation of so-called semantic frames, simple keywords, hierarchical annotations, as well as keywords for categories and similarities. Hohman et al (2017) propose a method to explore individual videos (entertainment, series) on the basis of colour information (dominant colour, etc.) as well as texts from dialogues and evaluate the approach on the basis of two use cases for the series <em>Game of Thrones</em> .</p>
<p><a href="#tseng2013b">Tseng (2013b)</a>provides an analysis of plot cohesion in film by tracking film elements such as characters, objects, settings, and character action. Furthermore,<a href="#tseng2013a">Tseng (2013a)</a>distinguishes basic narrative types in visual images by interconnecting salient people, objects and settings within single and across sequential images.<a href="#bateman2014">Bateman (2014)</a>reviews empirical, quantitative approaches to the analysis of films and, moreover, suggests employing discourse semantics for more systematic interpretative analysis in order to overcome the difficulty of relating particular technical film features to qualitative interpretations.</p>
<h2 id="3-current-developments-in-computer-vision-and-video-analysis">3 Current Developments in Computer Vision and Video Analysis</h2>
<p>Apart from analysing film style (shot and scene segmentation, use of camera motion and colours, etc.), film studies are also concerned with question(s) such as:Who (or what) did what, when, and where?.To answer such questions, algorithms for recognising persons, location and time of shots, etc. are required. There are some state-of-the-art approaches that basically target these questions (e.g., visual concept detection, geolocation and date estimation of images) and might be applicable to film style and content analysis – at least in future work.</p>
<p>A central question in computer vision approaches is the choice of a feature representation for the visual data. Classical approaches rely on hand-crafted feature descriptors. While global descriptors likeHistogram of Oriented Gradients(HOG) are considered to represent an image holistically, descriptors based onScale Invariant Feature Transform(SIFT)<a class="footnote-ref" href="#lowe2004"> [lowe2004] </a>orSpeeded Up Robust Features(SURF)<a class="footnote-ref" href="#bay2008"> [bay2008] </a>have proven to be particularly suitable for local features since they are invariant to coordinate transformations, and robust to noise as well as to illumination changes. With the emergence of deep learning, however, feature representations based on convolutional neural networks (CNNs) largely replaced hand-crafted low-level features. Nowadays, CNNs and deep features are the state-of-the-art for many computer vision tasks<a class="footnote-ref" href="#brejcha2017"> [brejcha2017] </a><a class="footnote-ref" href="#rawat2017"> [rawat2017] </a><a class="footnote-ref" href="#wang2018"> [wang2018] </a>.</p>
<h2 id="31-shot-boundary-detection">3.1 Shot Boundary Detection</h2>
<p>Shot boundary detection (SBD) is an essential prerequisite for video processing and for video content analysis tasks. Typical techniques in SBD<a class="footnote-ref" href="#baber2011"> [baber2011] </a><a class="footnote-ref" href="#lankinen2013"> [lankinen2013] </a><a class="footnote-ref" href="#li2010"> [li2010] </a>rely on low-level features, consisting of global or local frame features that are used to measure the distance between consecutive frames. One notable approach<a class="footnote-ref" href="#apostolidis2014"> [apostolidis2014] </a>utilises both colour histograms and SURF descriptors<a class="footnote-ref" href="#bay2008"> [bay2008] </a>along with GPU acceleration to identify abrupt and gradual transitions in real time. This approach achieves a F1 accuracy score of 0.902 on a collection of 15 videos gathered from different video archives while being 3x faster than real-time processing on GPU. In order to enhance detection, especially for more subtle gradual transitions, several CNN-based proposals have been introduced. They extract and employ representative deep features for frames<a class="footnote-ref" href="#xu2016"> [xu2016] </a>or train networks that detect shot boundaries directly<a class="footnote-ref" href="#gygli2018"> [gygli2018] </a>. Xu et al. conduct experiments on TRECVID 2001 test data and achieve F1 scores of 0.988 and 0.968 for cut and gradual transitions, respectively.<a href="#gygli2018">Gygli (2018)</a>reports a F1 score of 0.88 on the RAI dataset<a class="footnote-ref" href="#baraldi2015b"> [baraldi2015b] </a>outperforming previous work, while being extremely fast (more than 120x real-time on GPU).</p>
<h2 id="32-scene-detection">3.2 Scene Detection</h2>
<p>Given the shots, it is often desirable to segment a broadcast video into higher level scenes. A scene is considered as a sequence of shots, which are related in a spatio-temporal manner. For this purpose,<a href="#baraldi2015b">Baraldi et al. (2015b)</a>detect superordinate scenes describing shots by means of colour histograms and subsequently apply a hierarchical clustering approach. The approach is applied to a collection of ten randomly selected broadcasting videos from the RAI Scuola video archive constituting the RAI dataset. The method achieves a F1 score of 0.70 at 7.7x real-time on CPU.<a href="#sidiropoulos2011">Sidiropoulos et al. (2011)</a>suggest an alternative approach, where shots constitute nodes in a graph representation and edges between shots are weighted by shot similarity. Exploiting this representation, scenes can be determined by partitioning the graph. On a test set of six movies as well as on a set of 15 documentary films, the approach obtains a F1 accuracy of 0.869 and 0.890 (F1 score on RAI dataset of<a href="#baraldi2015b">Baraldi et al. 2015b</a>: 0.54), respectively. Another solution<a class="footnote-ref" href="#baraldi2015a"> [baraldi2015a] </a>is to apply a multimodal deep neural network to learn a metric for rating the difference between pairs of shots utilizing both visual and textual features from the transcript. Similarity scores of shots are used to segment the video into scenes. Beraldi et al. evaluate the approach on 11 episodes from the BBC educational TV series <em>Planet Earth</em> and report a F1 score of 0.62.</p>
<h2 id="33-camera-motion-estimation">3.3 Camera Motion Estimation</h2>
<p>Camera motion is considered as a significant element in film production. Thus, estimating the types of camera motion can be helpful in breaking down a video sequence into shots or for motion analysis of objects. Some techniques for camera motion estimation perform direct optical flow computation<a class="footnote-ref" href="#nguyen2010"> [nguyen2010] </a>, while others consider motion vectors that are available in compressed video files<a class="footnote-ref" href="#ewerth2004a"> [ewerth2004a] </a>. On four short movie sequences Nguyen et al. individually obtain 94.04% to 98.26% precision (percentage of correct detections). The latter approach is evaluated on a video test set consisting of 32 video sequences including all kinds of motion types. It detects zooming with 99%, tilting (vertical camera movement) with 93% and panning (horizontal camera movement) with 79% precision among other motion types. This approach achieved the best results in the task of zoom detection at TRECVID 2005. More recent works in this field couple the camera motion problem with similar tasks in order to train neural networks in a joint unsupervised framework<a class="footnote-ref" href="#zhou2017"> [zhou2017] </a><a class="footnote-ref" href="#yin2018"> [yin2018] </a><a class="footnote-ref" href="#ranjan2019"> [ranjan2019] </a>.</p>
<h2 id="34-object-detection-and-visual-concept-classification">3.4 Object Detection and Visual Concept Classification</h2>
<p>Object detection is the task of localising and classifying objects in an image. Motivated by the first application of CNNs to object classification<a class="footnote-ref" href="#krizhevsky2012"> [krizhevsky2012] </a>, regions with CNN features (R-CNN) were introduced in order to (localize and) classify objects based on region proposals<a class="footnote-ref" href="#girschick2014"> [girschick2014] </a>. However, since this approach is computationally very expensive, several improvements have been proposed. Fast-R-CNNs<a class="footnote-ref" href="#girshick2015"> [girshick2015] </a>were designed to jointly train feature extraction, classification and bounding box regression in an unified network. Additionally integrating a region proposal subnetwork enabled Faster-R-CNNs<a class="footnote-ref" href="#ren2017"> [ren2017] </a>to significantly speed up the formerly separate process of generating regions of interest. Thus, Faster-R-CNNs achieve an accuracy of 42.7 mAP (mean Average Precision) at a frame rate of 5 fps (frames per second) on the challenging MS COCO detection dataset<a class="footnote-ref" href="#lin2014"> [lin2014] </a>(MSCOCO: Microsoft Common Objects in Context). Furthermore, mask R-CNNs<a class="footnote-ref" href="#he2018"> [he2018] </a>extend the Faster-R-CNN approach for pixel-level segmentation of object instances by predicting object masks. Running at 5 fps, this approach predicts object boxes as well as segments with an accuracy of 60.3 mAP and 58.0 mAP on the COCO dataset. In contrast to region proposal based methods,<a href="#redmon2016">Redmon et al. (2016)</a>introduced YOLO,  a single shot object detector that predicts bounding boxes and associated object classes based on a fixed-grid regression. While YOLO is very fast in terms of inference time, further extensions<a class="footnote-ref" href="#redmon2017"> [redmon2017] </a><a class="footnote-ref" href="#redmon2018"> [redmon2018] </a>employ anchor boxes and make several improvements on network design also boosting the overall detection accuracy to 57.9 mAP at 20 fps on the COCO dataset. In order to detect a wide variety of over 9000 object categories,<a href="#redmon2017">Redmon and Farhadi (2017)</a>also introduced the real-time system YOLO9000, which was simultaneously trained on the COCO detection dataset as well as the ImageNet classification dataset<a class="footnote-ref" href="#deng2009"> [deng2009] </a>. Apart from detecting objects, there were also many approaches and more importantly datasets introduced for classifying images into concepts. The SUN database<a class="footnote-ref" href="#zhou2014"> [zhou2014] </a>provides up to 5400 categories of objects and scenes. Current image concept classification approaches typically rely on deep models trained with state-of-the-art architectures<a class="footnote-ref" href="#he2016"> [he2016] </a><a class="footnote-ref" href="#liu2017"> [liu2017] </a><a class="footnote-ref" href="#szegedy2016"> [szegedy2016] </a>.</p>
<h2 id="35-face-recognition-and-person-identification">3.5 Face Recognition and Person Identification</h2>
<p>Motivated by the significant progress in object classification, deep learning methods have also been applied to face recognition. In this context, DeepFace<a class="footnote-ref" href="#taigman2014"> [taigman2014] </a>is one of the first approaches that is trained to obtain deep features for face verification and, moreover, enhances face alignment based on explicit 3D modelling of faces. This approach achieves an accuracy of 97.35% on the prominent as well as challenging Labeled Faces in the Wild (LFW) benchmark set. While DeepFace uses a cross-entropy loss (cost function) for feature learning,<a href="#schroff2015">Schroff et al. (2015)</a>introduced with FaceNet a novel and more sophisticated loss based on training with triplets of roughly aligned matching and nonmatching face patches. On the LFW benchmark, FaceNet obtains an accuracy of 99.63%.</p>
<p>In the context of broadcast videos, the task of detecting faces and clustering them for person indexing of frames or shots has been widely studied (e.g.,<a href="#ewerth2007b">Ewerth et al. 2007b</a>). While<a href="#muller2016">Müller et al. (2016)</a>present a semi-supervised system for automatically naming characters in TV broadcasts by extending and correcting weakly labelled training data,<a href="#jin2017">Jin et al. (2017)</a>both detect faces and cluster them by identity in full-length movies. For content-based video retrieval in broadcast videos face recognition as well as concept detection based on deep learning have also been proven to be effective<a class="footnote-ref" href="#muhling2017"> [muhling2017] </a>.</p>
<h2 id="36-recognition-of-places-and-geolocation">3.6 Recognition of Places and Geolocation</h2>
<p>Recognising a place in a frame or shot might yield also useful information for film studies. The Places database contains over 400 unique place categories for scene recognition. Along with the dataset,<a href="#zhou2014">Zhou et al. (2014;</a><a href="#zhou2018">2018</a>) provide CNN models trained with various architectures on the Places365 dataset. Using the ResNet architecture<a class="footnote-ref" href="#he2016"> [he2016] </a>, for example, a top-5 accuracy of 85.1% can be obtained on the Places365 validation set.<a href="#mallya2018">Mallya and Lazebnik (2018)</a>introduce PackNet for training multiple tasks in a single model by pruning redundant parameters. Thus, the network is trained on classes of the ImageNet as well as the Places365 dataset. Being trained on multiple tasks, the model yields a top-5 classification error of 15.6% for the Places365 classes on the validation set, while the individually trained network by<a href="#zhou2018">Zhou et al. (2018)</a>shows a top-5 error rate of 16.1%.<a href="#hu2018">Hu et al. (2018)</a>introduce a novel CNN architecture unit called SE block, which enables a network to use global information to selectively emphasise informative features and suppress less useful ones by performing dynamic channel-wise feature recalibration. This approach was trained on the Places365 dataset as well and shows a top-5 error rate of 11.0% on the corresponding validation set.</p>
<p>For the task of earth scale photo geolocation two major directions have been taken so far. Im2GPS, one fundamental proposal for photo geolocation estimation, infers GPS coordinates by matching the query image against a reference database of geotagged images<a class="footnote-ref" href="#hays2008"> [hays2008] </a><a class="footnote-ref" href="#hays2015"> [hays2015] </a>and was recently enhanced by incorporating deep learning features<a class="footnote-ref" href="#vo2017"> [vo2017] </a>. In this context, the Im2GPS test set consisting of 237 challenging photos (only 5% are depicting touristic sites) was introduced. The latest deep feature based Im2GPS version<a class="footnote-ref" href="#vo2017"> [vo2017] </a>achieves an accuracy of 47.7% at region scale (location error less than 200 km). Other major proposals cast the task as a CNN-based classification approach by partitioning the earth into geographical cells<a class="footnote-ref" href="#weyand2016"> [weyand2016] </a>and considering combinatorial partitioning of maps, which facilitate more accurate and robust class predictions<a class="footnote-ref" href="#seo2018"> [seo2018] </a>. These frameworks called PlaNet and CPlaNet achieve 37.6% and 42.6% accuracy at region scale on the benchmark, respectively. Current state-of-the-art results (51.9% accuracy at region scale) are achieved by similarly combining hierarchical map partitions and additionally distinguishing three different settings (indoor, urban, and rural) through automatic scene recognition<a class="footnote-ref" href="#muller-budack2018"> [muller-budack2018] </a>.</p>
<h2 id="37-image-date-estimation">3.7 Image Date Estimation</h2>
<p>While unrestricted photo geolocation estimation is well covered by several studies, the problem of estimating the date of arbitrary (historical) photos was addressed less frequently in the past. The first unrestricted work in this context<a class="footnote-ref" href="#palermo2012"> [palermo2012] </a>dates historical colour images from 1930 to 1980 utilizing colour descriptors that model the evolution of colour imaging processes over time. Thus, Palermo et al. report an overall accuracy of 45.7% on a set of 1375 Flickr images which are uniformly distributed across the considered decades. A recent deep learning approach<a class="footnote-ref" href="#muller2017"> [muller2017] </a>dates images from 1930 to 1999 considering the task either as a classification or a regression problem. Müller et al. introduce the Date Estimation in the Wild test set consisting of 1120 Flickr images, which cover every year uniformly, and report a mean estimation error of less than 8 years for both the classification and regression models.</p>
<h2 id="4-human-and-machine-performance-in-annotation-tasks">4 Human and Machine Performance in Annotation Tasks</h2>
<p>When applying computer vision approaches to film studies, the question arises whether their accuracy is sufficiently high. In this respect, we provide a comparison of human and machine performance based on own previous work<a class="footnote-ref" href="#ewerth2017"> [ewerth2017] </a>for some specific visual recognition tasks: face recognition, geolocation estimation of photos, date estimation of photos, as well as visual object and concept detection (<a href="#table02">Table 2</a>).</p>
<p>A major field where human and machine performance has been compared frequently is visual concept classification. For a long time human annotations were (significantly) superior to machine-generated ones, as demonstrated by many studies<a class="footnote-ref" href="#jiang2011"> [jiang2011] </a><a class="footnote-ref" href="#parikh2010"> [parikh2010] </a><a class="footnote-ref" href="#xiao2010"> [xiao2010] </a>on datasets like PASCAL VOC or SUN. However, the accuracy of machine annotations could be significantly raised by deep convolutional neural networks. The error rate of 6.7% reported with GoogLeNet<a class="footnote-ref" href="#szegedy2015"> [szegedy2015] </a>on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014 was already close to that of humans (5.1 %), until in 2015 the error rate of neural networks<a class="footnote-ref" href="#he2015"> [he2015] </a>was slightly lower (error rate: 4.94%) than human error on the ImageNet challenge. However, the human error rate is only based on a single annotator. Hence, no information about human inter-annotator agreement is available.<br>
Comparison of human and machine performance in visual recognition tasks.ApproachChallenge/test setError MetricHuman PerformanceMachine PerformanceVisual Concept Classification<br>
GoogLeNet</p>
<p><a class="footnote-ref" href="#szegedy2015"> [szegedy2015] </a><br>
ILSVRC’14Top-5 test error5.1%6.66%He et al. 2015ImageNet’12 datasetTop-5 test error5.1%4.94%Face Verification<br>
DeepFace</p>
<p><a class="footnote-ref" href="#taigman2014"> [taigman2014] </a><br>
LFWAccuracy97.53%97.35%<br>
FaceNet</p>
<p><a class="footnote-ref" href="#schroff2015"> [schroff2015] </a><br>
LFWAccuracy97.53%99.63%Geolocation Estimation<br>
PlaNet</p>
<p><a class="footnote-ref" href="#weyand2016"> [weyand2016] </a><br>
Im2GPS test set<br>
Accuracy at</p>
<p>region/continent scale<br>
3.8% / 39.3%37.6% / 71.3%<br>
Im2GPS</p>
<p><a class="footnote-ref" href="#vo2017"> [vo2017] </a><br>
Im2GPS test set<br>
Accuracy at</p>
<p>region/continent scale<br>
3.8% / 39.3%47.7% / 73.4%<br>
CPlaNet</p>
<p><a class="footnote-ref" href="#seo2018"> [seo2018] </a><br>
Im2GPS test set<br>
Accuracy at</p>
<p>region/continent scale<br>
3.8% / 39.3%46.4% / 78.5%<a class="footnote-ref" href="#muller-budack2018"> [muller-budack2018] </a>Im2GPS test set<br>
Accuracy at</p>
<p>region/continent scale<br>
3.8% / 39.3%51.9% / 80.2%Date Estimation<a class="footnote-ref" href="#palermo2012"> [palermo2012] </a>Test set crawled from Flickr<br>
Classification accuracy</p>
<p>by decade<br>
26.0%45.7%<a class="footnote-ref" href="#muller2017"> [muller2017] </a> <em>Date Estimation in the Wild</em> test set<br>
Absolute mean error</p>
<p>(in years)<br>
10.9%7.3%<br>
A comparison of face identification capabilities of humans and machines was made for the first time in a Face Recognition Vendor Test (FRVT) study in 2006<a class="footnote-ref" href="#phillips2006"> [phillips2006] </a>. Thus, it has been shown - interestingly, already nearly 15 years ago - that industry-strength methods can compete with human performance in identifying unfamiliar faces under illumination changes. On the more recent as well as more challenging Labeled Faces in the Wild (LFW) benchmark, human performance has also been reached by several approaches. Among several others, DeepFace<a class="footnote-ref" href="#taigman2014"> [taigman2014] </a>and FaceNet<a class="footnote-ref" href="#schroff2015"> [schroff2015] </a>are prominent deep learning approaches reporting human-level (97.53%) results of 97.35% and 99.63% accuracy on the benchmark, practically solving the LFW dataset.</p>
<p>While humans are relatively good at recognising persons, estimating or guessing the location and date of an image imposes a more difficult task for subtle spatial as well as temporal differences. Various systems have been proposed for earth scale photo geolocation that outperform human performance in this task. The latest of these<a class="footnote-ref" href="#seo2018"> [seo2018] </a><a class="footnote-ref" href="#vo2017"> [vo2017] </a><a class="footnote-ref" href="#weyand2016"> [weyand2016] </a>employ deep learning methods consuming up to 90 million training images for an imposed classification task of cellular earth regions and/or rely on an extensive retrieval database. Current state-of-the-art results are reached by considering hierarchical as well as scene information of photos within the established classification approach, while using only 5 million training images<a class="footnote-ref" href="#muller-budack2018"> [muller-budack2018] </a>. Since human performance reported on the established Im2GPS benchmark<a class="footnote-ref" href="#vo2017"> [vo2017] </a>is relatively poor in this task, the system clearly surpasses human ability to guess geolocation by 48.1% accuracy within a tolerated distance level of 200 km (predictions at region level).</p>
<p>The creation date of (historical) photos is very hard to judge for periods of time that are quite similar. Therefore, a fundamental work<a class="footnote-ref" href="#palermo2012"> [palermo2012] </a>predicts the decade of historical colour photos with an accuracy of 45.7% exceeding that of untrained humans (26.0% accuracy),<a href="#muller2017">Müller et al. (2017)</a>suggest a deep learning system that infers the capturing date of images taken between 1930 and 1999 in terms of 5-year periods. When comparing human and machine annotations by means of absolute mean error in years, the deep learning system achieves better results nearly at all periods and improves the overall mean error by more than three years.</p>
<p>In general, the promising performance of the computer vision approaches compared to humans in Table 2 makes a strong case for their use in film studies. Although these methods are still prone to errors (to a lesser or greater extent), they can highly raise the exploration of media sources and help in finding patterns. In spite of the impressive performance of the selected approaches, computer vision approaches still have some shortcomings. Such approaches are optimized for specific visual content analysis tasks and rely on custom training data. Therefore, they have limited flexibility and cannot adapt to arbitrary images across different genres. While they perform well in basic computer vision tasks, humans are by far superior in grasping and interpreting images in their context, for example, in identifying gradual transitions between shots or in captioning images/videos.</p>
<h2 id="5-conclusions-and-future-prospects-for-software-tools-in-film-studies">5 Conclusions and Future Prospects for Software Tools in Film Studies</h2>
<p>In this paper, we have reviewed off-the-shelf software solutions for film studies. Since quantitative approaches to film content analysis are a handy way to effectively explore basic filmic features (see<a href="#section01">Section 1</a>), we have put a focus on offered functionalities regarding automated film style and content analysis. In this respect, only the tools Videana and VIAN offer a wider range of automated video analysis methods. However, with Videana not being developed anymore and the most recent tool VIAN focusing on film colour patterns, the field still lacks available tools that provide powerful state-of-the-art methods for visual content analysis. We discuss needed functionality in detail in the latter part of this section. Furthermore, we have outlined recent advances in the (automated) analysis of film style (shot and scene segmentation, use of camera motion or colours) as well as current developments and progress in the field of computer vision. As also discussed in the beginning of this paper, quantitative approaches are partially criticised for being incompatible with qualitative film analysis. To showcase the chances of basic computer vision approaches, we have compared machine and human performance in visual annotation tasks. We have shown that machine annotations are of similar quality to those of humans for some basic tasks like object classification, face recognition or geolocation estimation. Even when these methods do not reach human abilities, they can build a valid basis for exploring media sources for further manual inspection.</p>
<p>What kind of basic and extended functionality for automated analysis and visualisation should a software tool have in order to support research in film studies? Previous practical experience with the basic functions of Videana has shown that such software is basically suitable for effectively supporting film research and teaching. However, film scholars often need more advanced functions tailored to their particular domain that allow the automatic detection of complex stylistic film elements such as the shot-reverse-shot technique. This requires, for example, detecting a series of alternating close-ups with a dialogue component and can be detected through the syntactic interaction of different factors. Starting from the smallest discontinuity in film, the cut, it is also possible to detect changing colour values or certain structural semantic properties such as the position of an object within consecutive shots. These could also allow drawing conclusions about changes within the storyline. Such forms of automatic segmentation and creating individual segments of events can be relevant in the context of narrative analyses. Researchers could be offered an effective structuring and orientation aid, which can undergo further manual differentiation based on content-related or motivic aspects. Therefore we envision a program that also offers a high degree of flexibility with regard to manual annotation opportunities. For a specific film or film corpus, individual survey parameters must be generated in order to judge their correlation with other parameters - depending on which hypotheses are to be applied to the object of investigation or can be formulated on the basis of the film material.</p>
<p>Considering, for example, a film as a system of information mediation as in quantitative suspense research<a class="footnote-ref" href="#junkerjurgen2001"> [junkerjurgen2001] </a><a class="footnote-ref" href="#weibel2008"> [weibel2008] </a><a class="footnote-ref" href="#weibel2017"> [weibel2017] </a>, individual shots and sequences could be detected using automatic methods and manually be supplemented with further content parameters. Here, classifications such as the degree of information shared between the film character and the viewer (if the film viewer knows more or less than the character), the degree of correspondence between narrative time (duration of the film) and narrated time (time period covered by the filmic narrative), or the degree of narrative relevance (is the event only of relevance within the sequence or does it affect the central conflict of the narrative) are considered in order to draw conclusions about the suspense potential of a sequence. In the outlined framework, these factors favour the exploitation of the viewer&rsquo;s anticipation of damage - in particular their emotional connection to a film character - through a principle of delay, as primarily applied in battle sequences typical of action films. Due to the principle of delaying the resolution of a conflict, they have a low information gain in view of the entire narrative. The principles of this parameterisation can now be used to check which dramaturgical context is characterised by which formal characteristics in comparison with the editing parameters of Salt. This concept of data acquisition can be extended by further parameters such as the application of digital visual effects in individual sequences, which provides a differentiated insight into the internal dynamics and proportions of filmic representation systems. Especially with regard to computer-generated imagery, which is subject to development processes spanning decades, it is possible to examine on a longitudinal scale how this process has had a concrete effect on production practices. However, such highly complex interwoven data structures require sophisticated statistical models with which these hypotheses can be tested.</p>
<p>Finally, a software tool adapted to the research object should be developed in a productive dialogue between computer science and film science. Such software for film studies could be based on experiences with software such as Videana or VIAN that allows for the evaluation of larger film corpora on a differentiated and reliable data basis, which cannot be generated with previous analysis instruments. Furthermore, it is desirable to include specific forms of information visualisations tailored to the needs of film scholars. Cinemetrics or Ligne de temps, as software designed for film studies, are also limited to a graphical representation that cannot take into account the requirements of narrative questions. Since an all-in-one approach will not fit to all analysis and visualisation requirements, such a tool should also provide an interface for plugins that offer additional functionality. Using these approaches, a large collection of research data can be gathered and exported for further processing, but the lack of a working digital environment for media science continues to be a problem. Statistical software or Microsoft Excel were not designed for the visualization of editing rhythms or narrative structures, which makes it difficult to process the corresponding data. An interdisciplinary cooperation could foster research in designing an optimal solution for scholarly film studies that allows direct interaction with the automatically determined parameters as well as their method-dependent annotation and graphical processing.</p>
<p>In summary, the development of a comprehensive software solution for scientists who systematically carry out film or video analysis would be desirable. This group includes media and film scientists, but also scientists from other disciplines (e.g., applications in journalism and media education, analysis of propaganda videos and political video works, image and educational films, television programmes). Also, empirical studies of media psychology in the field of event indexing require the annotation and analysis of structural properties of audiovisual research data. Factors such as the duration of an action segment as well as temporal, spatial, figure-related or action-related changes within the sequences (four dimension models), but also shot lengths are integrated into the research design and are prerequisites for the formulation of hypotheses and their empirical validation<a class="footnote-ref" href="#huff2014"> [huff2014] </a>.</p>
<p>An interdisciplinary all-in-one software tool of this kind should be openly available on a web-based platform, intuitive, easy to use and rely on state-of-the-art algorithms and technology. On the one hand, by providing automatic methods for the quantitative analysis of film material, large film and video corpora could become the object of investigation and hypotheses could, for example, be statistically tested; on the other hand, the interpretation would be simplified by different possibilities of visualisation. Last but not least, legal questions regarding the storage, processing and use of moving image material should be clarified and taken into account in the technical implementation.</p>
<ul>
<li id="abend2011">Abend, P., Thielmann, T.,  Ewerth, R., Seiler, D., Mühling, M., Döring, J., Grauer, M., & Freisleben, B. “Geobrowsing the Globe: A Geovisual Analysis of Google Earth Usage.” In: _Proc. of Linking GeoVisualization with Spatial Analysis and Modeling_ (GeoViz), Hamburg, (2011).
</li>
<li id="abend2012">Abend, P., Thielmann, T., Ewerth, R., Seiler, D., Mühling, M., Döring, J., Grauer, M., & Freisleben, B. “Geobrowsing Behaviour in Google Earth: A Semantic Video Content Analysis of On-Screen Navigation.” In: _Proc. of Geoinformatics Forum_ , Salzburg, Österreich, (2012), pp. 2-13.
</li>
<li id="adams2000">Adams, B., Dorai, C. & Venkatesh, S. “Towards Automatic Extraction of Expressive Elements from Motion Pictures: Tempo.”   _IEEE International Conference on Multimedia and Expo (II)_ (2000), pp. 641-644.
</li>
<li id="adams2001">Adams, B., Chitra Dorai, C. & Venkatesh, S. “Automated Film Rhythm Extraction For Scene Analysis.”   _ICME_ (2001).
</li>
<li id="adams2005">Adams, B., Venkatesh, S., Bui, H. H. & Dorai, C. “A Probabilistic Framework for Extracting Narrative Act Boundaries and Semantics in Motion Pictures.”   _Multimedia Tools Appl._  27(2) (2005): 195-213.
</li>
<li id="anitha2013">Anitha A., Brasoveanu, A., Duarte M., Hughes, S., Daubechies, I., Dik, J., Janssens, K., & Alfeld, M. “Restoration of X-ray fluorescence images of hidden paintings.”  _Signal Processing_ , 93(3) (2013): 592-604.
</li>
<li id="apostolidis2014">Apostolidis, E. & Mezaris, V. “Fast shot segmentation combining global and local visual descriptors.” In: _International Conference on Acoustics, Speech and Signal Processing_ , Florence, Italy (2014), pp. 6583-6587.
</li>
<li id="aubert2005">Aubert, O. & Prié, Y. “Advene: Active reading through hypervideo.” In: _Proceedings of ACM Hypertext '05_ (2005), pp. 235-244.
</li>
<li id="baber2011">Baber, J., Afzulpurkar, N. V., Dailey, M. N., & Bakhtyar, M. “Shot boundary detection from videos using entropy and local descriptor.” In: _Proceedings of the 17th International Conference on Digital Signal Processing_ , Corfu, Greece (2011), pp. 1-6.
</li>
<li id="baraldi2015a">Baraldi, L., Grana, C., & Cucchiara, R. A “Deep Siamese Network for Scene Detection in Broadcast Videos.” In _Proceedings of the 23rd Annual ACM Conference on Multimedia Conference_ , Brisbane, Australia (2015), pp. 1199-1202.
</li>
<li id="baraldi2015b">Baraldi, L., Grana,  C., & Cucchiara, R. “Shot and scene detection via hierarchical clustering for re-using broadcast video.” In: _International Conference on Computer Analysis of Images and Patterns_ (2015), pp. 801-811.
</li>
<li id="bateman2014">Bateman, J. A. “Looking for what counts in film analysis: A programme of empirical research.” In _Visual Communication_ , De Gruyter, Berlin (2014): 301-330.
</li>
<li id="bay2008">Bay, H., Ess, A., Tuytelaars, T., & Van Gool, L. “Speeded-Up Robust Features (SURF).”  _Computer Vision and Image Understanding_ , 110(3) (2008): 346-359.
</li>
<li id="brejcha2017">Brejcha, J. & Cadík, M. “State-of-the-art in visual geo-localization.”  _Pattern Analysis and Applications_ , 20(3) (2017): 613-637.
</li>
<li id="buckland2009">Buckland, W. “Ghost director.”  _Digital Tools in Media Studies_ , M. Ross, M. Grauer and B. Freisleben (eds.). Bielefeld: transcript Verlag (2009).
</li>
<li id="burghardt2016">Burghardt, M., Kao, M., & Wolff, C. “Beyond Shot Lengths–Using Language Data and Color Information as Additional Parameters for Quantitative Movie Analysis.” In: _Digital Humanities 2016: Conference Abstracts_ . Jagiellonian University & Pedagogical University, Kraków (2016): 753-755.
</li>
<li id="deng2009">Deng, J., Dong, W., Socher, R., Li, L., Li, K., & Fei-Fei, L. “ImageNet: A large-scale hierarchical image database.” In: _Proceedings of the Conference on Computer Vision and Pattern Recognition_ (2009), pp. 248–255.
</li>
<li id="estrada2017">Estrada, L. M, Hielscher, E. Koolen, M., Olesen, C. G., Noordegraaf, J. & Jaap Blom, J. “Film Analysis as Annotation: Exploring Current Tools.”  _The Moving Image - Special Issue on Digital Humanities and/in Film Archives_ (Vol 17, no 2) (2017): 40-70.
</li>
<li id="ewerth2004a">Ewerth, R., Schwalb, M., Tessmann, P., & Freisleben, B. “Estimation of Arbitrary Camera Motion in MPEG Videos.” In: _Proceedings of 17th Int. Conference on Pattern Recognition_ , (2004), pp. 512–515.
</li>
<li id="ewerth2004b">Ewerth, R. & Freisleben, B. “Video Cut Detection without Thresholds.” In: _Proc. of 11th Workshop on Signals, Systems and Image Processing_ , Poznan, Poland (2004), pp. 227-230.
</li>
<li id="ewerth2007a">Ewerth, R., Schwalb, M., Tessmann, P., & Freisleben, B. “Segmenting Moving Objects in the Presence of Camera Motion.” In: _Proc. of 14th Int. Conference on Image Analysis and Processing_ , Modena, Italy (2007), pp. 819-824.
</li>
<li id="ewerth2007b">Ewerth, R., Mühling, M., & Freisleben, B. “Self-Supervised Learning of Face Appearances in TV Casts and Movies.” Invited Paper (Best papers from IEEE International Symposium on Multimedia ‘06): _International Journal on Semantic Computing, World Scientific_ (2007), pp. 185-204.
</li>
<li id="ewerth2009a">Ewerth, R. & Freisleben, B. “Unsupervised Detection of Gradual Shot Changes with Motion-Based False Alarm Removal.” In: _Proceedings of 8th International Conference on Advanced Concepts for Intelligent Vision Systems (ACIVS)_ , Bordeaux, France, Springer (2009), pp. 253-264.
</li>
<li id="ewerth2009">Ewerth, R., Mühling, M., Stadelmann, T., Gllavata, J., Grauer, M., & Freisleben, B. “Videana: A Software Toolkit for Scientific Film Studies.”  _Digital Tools in Media Studies – Analysis and Research. An Overview._ Transcript Verlag, Bielefeld, Germany (2009): 101-116.
</li>
<li id="ewerth2012">Ewerth, R., Ballafkir, K., Mühling, M., Seiler, D., & Freisleben, B. “Long-Term Incremental Web-Supervised Learning of Visual Concepts via Random Savannas.”  _IEEE Trans. on Multimedia_ , 14(4) (2012): 1008-1020.
</li>
<li id="ewerth2017">Ewerth, R., Springstein, M., Phan-Vogtmann, L. A., & Schütze, J. “ Are Machines Better in Image Tagging? – A User Study Adds to the Puzzle.” In:   _Proceedings of 39th European Conference on Information Retrieval (ECIR)_ , Aberdeen, UK (2017), pp. 186-198
</li>
<li id="fluckiger2011">Flückiger, B. “Die Vermessung ästhetischer Erscheinungen.”  _ZfM_ 5 (2011): 44-60.
</li>
<li id="fluckiger2017">Flückiger, B.,  Evirgen, N., Paredes, E. G., Ballester-Ripoll, R.,  & Pajarola, R. “Deep Learning Tools for Foreground-Aware Analysis of Film Colors.” In: _Computer Vision in Digital Humanities_ , Digital Humanities Conference, Montreal (2017).
</li>
<li id="girschick2014">Girshick R. B., Donahue, J., Darrell, T., & Malik, J. “Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation.” In _Proceedings of the Conference on Computer Vision and Pattern Recognition_ , Columbus, OH, USA (2014), pp. 580-587.
</li>
<li id="girshick2015">Girshick, R. B. “Fast R-CNN.” In _Proceedings of the International Conference on Computer Vision_ , Santiago, Chile (2015), pp. 1440-1448.
</li>
<li id="gllavata2004a">Gllavata, J., Ewerth, R., & Freisleben, B. “Text Detection in Images Based on Unsupervised Classification of High-Frequency Wavelet Coefficients.”  _ICPR_ (2004), pp. 425-428.
</li>
<li id="gllavata2004b">Gllavata, J., Ewerth, R., & Freisleben, B. “Tracking text in MPEG videos.” In: _ACM Multimedia_ (2004), pp. 240-243.
</li>
<li id="gygli2018">Gygli, M. “Ridiculously Fast Shot Boundary Detection with Fully Convolutional Neural Networks.” In: _International Conference on Content-Based Multimedia Indexing_ , La Rochelle, France (2018), pp. 1-4.
</li>
<li id="hays2008">Hays, J. & Efros, A. A. “IM2GPS: estimating geographic information from a single image.” In _Proceedings of the Conference on Computer Vision and Pattern Recognition_ , Anchorage, Alaska, USA (2008).
</li>
<li id="hays2015">Hays, J. & Efros, A. A. “Large-Scale Image Geolocalization.”  _Multimodal Location Estimation of Videos and Images_ (2015): 41-62.
</li>
<li id="he2015">He, K., Zhang, X., Ren, S., & Sun, J. “Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.” In _Proceedings of ICCV_ (2015), pp. 1026-1034.
</li>
<li id="he2016">He, K., Zhang, X.,  Ren, S., & Sun, J. “Deep Residual Learning for Image Recognition.” In _Proceedings of CVPR_ (2016), pp. 770-778.
</li>
<li id="he2018">He, K., Gkioxari, G., Dollár, P., & Girshick, R. B. “Mask R-CNN.” In _International Conference on Computer Vision_ , Venice, Italy (2018), pp. 2980-2988.
</li>
<li id="heftberger2016">Heftberger, A. _Kollision der Kader: Dziga Vertovs Filme, die Visualisierung ihrer Strukturen und die Digital Humanities_ , München: edition text+kritik (2016).
</li>
<li id="hohman2017">Hohman, F., Soni, S., Stewart, I., & Stasko, J. “A Viz of Ice and Fire: Exploring Entertainment Video Using Color and Dialogue.” In _2nd Workshop on Visualization for the Digital Humanities_ , Phoenix, Arizona, USA (2017).
</li>
<li id="hoyt2014">Hoyt, E., Ponot , K . and Roy, C. “Visualizing and Analyzing the Hollywood Screenplay with ScripThreads.”  _Digital Humanities Quarterly_ , 8(4) (2014).
</li>
<li id="hu2018">Hu, J., Shen, L., & Sun, G. “Squeeze-and-Excitation Networks.” In: _Proceedings of the Conference on Computer Vision and Machine Learning_ (2018), pp. 7132-7141.
</li>
<li id="huff2014">Huff, M., Meitz, T., & Papenmeier, F. “Changes in Situation Models Modulate Processes of Event Perception in Audiovisual Narratives.”  _Journal of Experimental Psychology - Learning, Memory, and Cognition_ , 40(5) (2014): 1377-1388.
</li>
<li id="itten1961">Itten, J. _Kunst der Farbe_ . Ravensburg: Otto Maier Verlag (1961).
</li>
<li id="jiang2011">Jiang, Y. G., Ye, G., Chang, S. F., Ellis, D., & Loui, A. C. “Consumer video understanding: a benchmark database and an evaluation of human and machine performance.” In: _Proceedings of the International Conference on Multimedia Retrieval_ (2011), p. 29.
</li>
<li id="jin2017">Jin, S., Su, H., Stauffer, C., & Learned-Miller, E. G. “End-to-End Face Detection and Cast Grouping in Movies Using Erdös-Rényi Clustering.” In: _Proceedings of the International Conference on Computer Vision_ , Venice, Italy (2017), pp. 5286-5295.
</li>
<li id="john2017">John, M., Kurzhals, K., Koch, S., & Weiskopf, D. “A Visual Analytics Approach for Semantic Multi-Video Annotation.” In: _2nd Workshop on Visualization for the Digital Humanities_ , Phoenix, Arizona, USA (2017).
</li>
<li id="johnson2008">Johnson, C. R., Hendriks, E., Berezhnoy, I. J., Brevdo, E., Hughes, S. M., Daubechies, I., & Wang, J. Z. “Image processing for artist identification.”  _IEEE Signal Processing Magazine_ , 25(4) (2008): 37-48.
</li>
<li id="junkerjurgen2001">Junkerjürgen, R. _Spannung – narrative Verfahrenweisen der Leseraktivierung: eine Studie am Beispiel der Reiseromane von Jules Verne._ Frankfurt am Main; Berlin; Bern; Bruxelles; New York; Oxford; Wien: Lang (2001).
</li>
<li id="kipp2001">Kipp, M. (2001). “Anvil - A Generic Annotation Tool for Multimodal Dialogue.” In: _Proceedings of the 7th European Conference on Speech Communication and Technology_ (Eurospeech) (2001), pp. 1367-1370.
</li>
<li id="klein2014">Klein C., Betz J., Hirschbuehl M., Fuchs C., Schmiedtová B., Engelbrecht M., Mueller-Paul, J., & Rosenberg, R. “Describing Art – An Interdisciplinary Approach to the Effects of Speaking on Gaze Movements during the Beholding of Paintings.”  _PLoS ONE_ 9(12) (2014).
</li>
<li id="korte2010">Korte, H. _Einführung in die systematische Filmanalyse_ . Berlin: Schmidt (2010).
</li>
<li id="krizhevsky2012">Krizhevsky, A., Sutskever, I., & Hinton, G. E. “ImageNet Classification with Deep Convolutional Neural Networks.” In: _Proc. of 26th Conf. on Neural Information Processing Systems 2012_ . Lake Tahoe, Nevada, United States (2012), pp. 1106–1114.
</li>
<li id="lankinen2013">Lankinen, J., & Kämäräinen, J. “Video Shot Boundary Detection Using Visual Bag-of-Words.” In: _Proceedings of the International Conference on Computer Vision Theory and Applications_ (1), Barcelona, Spain (2013), pp. 788-791.
</li>
<li id="li2010">Li, J., Ding, Y., Shi, Y., & Li, W. “A divide-and-rule scheme for shot boundary detection based on sift.”  _Journal of Digital Content Technology and its Applications_ (2010): 202–214.
</li>
<li id="lin2014">Lin, T., Maire, M., Belongie, S. J., Hays, H., Perona, P., Ramanan, D., Dollár, P., & Zitnick, L. “Microsoft COCO: Common Objects in Context.” In: _Proceedings of ECCV_ (2014), pp. 740-755.
</li>
<li id="liu2012">Liu, A. “Where Is Cultural Criticism in the Digital Humanities?” [Online] (2012). Available at:<a href="http://dhdebates.gc.cuny.edu/debates/text/20">http://dhdebates.gc.cuny.edu/debates/text/20</a>(Accessed: 19 December 2018)
</li>
<li id="liu2017">Liu, C., Zoph, B., Shlens, J., Hua, W., Li, L., Fei-Fei, L., Yuille, A., Huang, J., & Murphy, K. _Progressive Neural Architecture Search_ (2017).
</li>
<li id="lowe2004">Lowe, D. G. “Distinctive Image Features from Scale-Invariant Keypoints.”  _International Journal of Computer Vision_ , 60(2) (2004): 91–110.  
</li>
<li id="mallya2018">Mallya, A. & Lazebnik, S. “PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning.” In _Proceedings of the Conference on Computer Vision and Pattern Recognition_ , Salt Lake City, UT, USA (2018), pp. 7765-7773.
</li>
<li id="missomelius2014">Missomelius, P. “Medienbildung und Digital Humanities: Die Medienvergessenheit technisierter Geisteswissenschaften.” In: Ortner, H., Pfurtscheller, D., Rizzolli, M, & Wiesinger, A. (Hg.): _Datenflut und Informationskanäle_ . Innsbruck: Innsbruck UP (2014), 101-112.
</li>
<li id="muhling2017">Mühling, M., Korfhage, N., Müller, E., Otto, C., Springstein, M., Langelage, T., Veith, U., Ewerth, R., & Freisleben, B. “Deep learning for content-based video retrieval in film and television production.”  _Multimedia Tools Appl._ 76(21) (2017): 22169-22194.
</li>
<li id="muller2016">Müller, E., Otto, C., & Ewerth, R. “Semi-supervised Identification of Rarely Appearing Persons in Video by Correcting Weak Labels.” In _Proceedings of the ACM on International Conference on Multimedia Retrieval_ , New York, New York, USA (2016), pp. 381-384.
</li>
<li id="muller2017">Müller, E., Springstein, M., & Ewerth, R. “ When Was This Picture Taken? - Image Date Estimation in the Wild.” In: _Proceedings of the European Conference on IR Research_ , Aberdeen, UK (2017), pp. 619-625.
</li>
<li id="muller-budack2018">Müller-Budack, E., Pustu-Iren, K., & Ewerth, R. “Geolocation Estimation of Photos Using a Hierarchical Model and Scene Classification.” In: _Proceedings of the European Conference on Computer Vision_ , Munich, Germany (2018), pp. 575-592.
</li>
<li id="nguyen2010">Nguyen, B. T., Laurendeau, D., & Albu, A. B. “A robust method for camera motion estimation in movies based on optical flow.”  _IJISTA_ , 9(3/4) (2010): 228-238.
</li>
<li id="palermo2012">Palermo, F., Hays, J., & Efros, A. A. “Dating Historical Color Images.” In: _Proceedings of the European Conference on Computer Vision_ , Florence, Italy (2012), pp. 499-512.
</li>
<li id="parikh2010">Parikh, D. & Zitnick, C. L. “The role of features, algorithms and data in visual recognition.” In: _Conference on Computer Vision and Pattern Recognition_ (2010), pp. 2328–2335.
</li>
<li id="pause2016">Pause, J. & Walkowski, N. The Colorized Dead: Computerunterstützte Analysen der Farblichkeit von Filmen in den Digital Humanities am Beispiel von Zombiefilmen (2016).<a href="http://nbn-resolving.de/urn/resolver.pl?urn:nbn:de:kobv:b4-opus4-25910">http://nbn-resolving.de/urn/resolver.pl?urn:nbn:de:kobv:b4-opus4-25910</a>
</li>
<li id="phillips2006">Phillips, P. J., Scruggs, W. T., O’Toole, A. J., Flynn, P. J., Bowyer, K. W., Schott, C. L., & Sharpe, M. FRVT 2006 and ICE 2006 Large-Scale Results (2006).
</li>
<li id="ranjan2019">Ranjan, A., Jampani, V., Balles, L., Kim, K., Sun, D., Wulff, J. & Black, M. J. “Competitive Collaboration: Joint Unsupervised Learning of Depth, Camera Motion, Optical Flow and Motion Segmentation.” In: _Proceedings of the Conference on Computer Vision and Pattern Recognition_ (2019), pp.12240-12249.
</li>
<li id="rawat2017">Rawat, W. & Wang, Z. “Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review.”  _Neural Computation_ 29(9) (2017): 2352-2449.
</li>
<li id="redmon2016">Redmon, J., Divvala, S. K., Girshick, R. B., Farhadi, A. “You Only Look Once: Unified, Real-Time Object Detection.” In: _Proceedings of the Conference on Computer Vision and Pattern Recognition_ , Las Vegas, NV, USA (2016), pp. 779-788.
</li>
<li id="redmon2017">Redmon, J. & Farhadi, A. “YOLO9000: Better, Faster, Stronger.” In: _Proceedings of the Conference on Computer Vision and Pattern Recognition_ , Honolulu, HI, USA (2017), pp. 6517-6525.
</li>
<li id="redmon2018">Redmon, J. & Farhadi, A. “YOLOv3: An Incremental Improvement.” CoRR abs/1804.02767 (2018).
</li>
<li id="ren2017">Ren, S., He, K., Girshick, R., B., & Sun, J. “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.”  _Transactions on Pattern Analysis and Machine Intelligence_ , 39(6) (2017): 1137-1149.
</li>
<li id="resig2014">Resig, J. “Using computer vision to increase the research potential of photo archives.”  _Journal of Digital Humanities_ , 3(2) (2014): 33.
</li>
<li id="rodenberg2010">Rodenberg, H.-P. “Historischer Kontext und der zeitgenössische Zuschauer: Michelangelo Antonionis ZABRISKIE POINT” (1969). In: Korte, Helmut (Hg.): _Einführung in die systematische Filmanalyse_ . Berlin: Schmidt (2010), pp. 5-118.
</li>
<li id="salt2006">Salt, B . _Moving into Pictures_ . London: Starword (2006).
</li>
<li id="salt2009">Salt, B. _Film Style and Technology: History and Analysis_ . London: Starword (2009).
</li>
<li id="schroff2015">Schroff, F., Kalenichenko, D., & Philbin, J. “FaceNet: A unified embedding for face recognition and clustering.” In: _Conference on Computer Vision and Pattern Recognition_ , Boston, MA, USA (2015), pp. 815-823.
</li>
<li id="seo2018">Seo, P. H., Weyand, T., Sim, J., & Han, B. “CPlaNet: Enhancing Image Geolocalization by Combinatorial Partitioning of Maps.” In: _Proceedings of the European Conference on Computer Vision_ , Munich, Germany (2018), pp. 544-560.
</li>
<li id="sidiropoulos2011">Sidiropoulos, P., Mezaris, V., Kompatsiaris, I., Meinedo, H., Bugalho, M., & Trancoso, I. “Temporal video segmentation to scenes using high-level audiovisual features.”  _Trans. Circuits Syst. Video Technol._ , 21(8) (2011): 1163–1177.
</li>
<li id="sittel2016">Sittel, J. Die systematische Anwendung computergestützter Verfahren in der Filmwissenschaft (2016).<a href="https://zenodo.org/record/5082167#.YObiJjNxeUl">https://zenodo.org/record/5082167#.YObiJjNxeUl</a>.
</li>
<li id="sittel2017">Sittel, J. “Digital Humanities in der Filmwissenschaft.” In: _ZfM 4_ (2017), 472-489.
</li>
<li id="sloetjes2008">Sloetjes, H., & Wittenburg, P. “Annotation by category – ELAN and ISO DCR.” In: _Proceedings of the 6th International Conference on Language Resources and Evaluation_ (2008).
</li>
<li id="springstein2016">Springstein, M. & Ewerth, R. “On the Effects of Spam Filtering and Incremental Learning for Web-supervised Visual Concept Classification.” In: _ACM Int. Conf. on Multimedia Retrieval_ , New York (2016), pp. 377-380.
</li>
<li id="szegedy2015">Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, & V., Rabinovich, A. “Going deeper with convolutions.” In _Proceedings of the Conference on Computer Vision and Pattern Recognition_ (2015), pp. 1–9.
</li>
<li id="szegedy2016">Szegedy, C., Ioffe, S., & Vanhoucke, V. “Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning.” CoRR abs/1602.07261 (2016).
</li>
<li id="taigman2014">Taigman, Y., Yang, M., Ranzato, M., & Wolf, L. “DeepFace: Closing the Gap to Human-Level Performance in Face Verification.” In: _Proceedings of the Conference on Computer Vision and Pattern Recognition_ , Columbus, OH, USA (2014), pp. 1701-1708.
</li>
<li id="tseng2013a">Tseng, C.-I. “Analyzing Characters’ Actions in Filmic Text: A Functional-Semiotic Approach.”  _Social Semiotics_ 23 (2013): 587–605.
</li>
<li id="tseng2013b">Tseng, C.-I. _Cohesion in film: Tracking film elements_ . Basingstoke: Palgrave Macmillan (2013).
</li>
<li id="tsivian2008">Tsivian, Y. “ What Is Cinema? An Agnostic Answer.” In: _Critical Inquiry_ . Vol. 34, No. 4, the University of Chicago Press (2008).
</li>
<li id="tsivian2009">Tsivian, Y. “Cinemetrics, Part of the Humanities’ Cyberinfrastructure.” In: Michael Ross, Manfred Grauer, Bernd Freisleben (eds.), _Digital Tools in Media Studies_ 9, Bielefeld: Transcript Verlag (2009): 93-100.
</li>
<li id="viola2004">Viola, P. & Jones, M. “Robust Real-Time Face Detection.”  _Int. Journal of Computer Vision_ , 57(2) (2004): 137–154.
</li>
<li id="vo2017">Vo, N., Jacobs, N., Hays, J. “Revisiting IM2GPS in the Deep Learning Era.” In: _International Conference on Computer Vision_ (2017), pp. 2640-2649.
</li>
<li id="wang2018">Wang, M. & Deng, W. “Deep Face Recognition: A Survey.” CoRR abs/1804.06655 (2018).
</li>
<li id="weibel2008">Weibel, A. _Spannung bei Hitchcock. Zur Funktionsweise auktorialer Suspense_ . Würzburg: Königshausen & Neumann (2008).
</li>
<li id="weibel2017">Weibel, A. _Suspense im Animationsfilm Band I Methodik: Grundlagen der quantitativen Spannungsanalyse. Studienbeisipiel Ice Age 3_ . Norderstedt: Books on Demand (2017).
</li>
<li id="weyand2016">Weyand, T., Kostrikov, I., & Philbin, J. “PlaNet - Photo Geolocation with Convolutional Neural Networks.” In: _Proceedings of the European Conference on Computer Vision_ , Amsterdam, The Netherlands (2016), pp. 37-55.
</li>
<li id="xiao2010">Xiao, J., Hays, J., Ehinger, K. A., Oliva, A., & Torralba, A. “SUN database: large-scale scene recognition from abbey to zoo.” In: _Conference on Computer Vision and Pattern Recognition_ (2010), pp. 3485–3492.
</li>
<li id="xu2016">Xu, J., Song, L., & Xie, R. “Shot boundary detection using convolutional neural networks.” In: _Proceedings of the International Conference on Visual Communications and Image Processing_ (2016), pp. 1-4.
</li>
<li id="yin2018">Yin, Z. & Shi, J. “GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose.” In: _Conference on Computer Vision and Pattern Recognition_ (2018), pp. 1983-1992.
</li>
<li id="zhou2014">Zhou, B., Lapedriza, A., Xiao, J.,  Torralba, A., & Oliva, A. “Learning Deep Features for Scene Recognition using Places Database.” In: _NIPS Proceedings_ , Montreal, Quebec, Canada (2014), pp. 487-495.
</li>
<li id="zhou2017">Zhou, T., Brown, B., Snavely, N. & Lowe, D. G. “Unsupervised learning of depth and ego-motion from video.” In: _Conference on Computer Vision and Pattern Recognition_ (2017), pp. 6612-6619.
</li>
<li id="zhou2018">Zhou, B., Lapedriza, A., Khosla, A., Oliva, A. & Torralba, A. “Places: A 10 Million Image Database for Scene Recognition.”  _IEEE Trans. Pattern Anal. Mach. Intell._ 40(6) (2018): 1452-1464.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>background-character/figure segmentation&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="http://www.cinemetrics.lv/">http://www.cinemetrics.lv/</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Available at<a href="http://www.anvil-software.org/">http://www.anvil-software.org/</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Available at<a href="https://tla.mpi.nl/tools/tla-tools/elan/">https://tla.mpi.nl/tools/tla-tools/elan/</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p><a href="http://www.iri.centrepompidou.fr/outils/lignes-de-temps-2/">http://www.iri.centrepompidou.fr/outils/lignes-de-temps-2/</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p><a href="https://www.advene.org">www.advene.org</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p><a href="https://mediathread.info">https://mediathread.info</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p><a href="https://ctl.columbia.edu/">https://ctl.columbia.edu/</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p><a href="https://filmcolors.org/">https://filmcolors.org/</a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p><a href="https://www.distantviewing.org/labs/">https://www.distantviewing.org/labs/</a>&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p><a href="http://efilms.ushmm.org">http://efilms.ushmm.org</a>## Bibliography&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Exploring Digitised Moving Image Collections: The SEMIA Project, Visual Analysis and the Turn to Abstraction</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000497/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000497/</id><author><name>Eef Masson</name></author><author><name>Christian Gosvig Olesen</name></author><author><name>Nanne van Noord</name></author><author><name>Giovanna Fossati</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<p>_One senior curator said that some of museum staff [sic] were skeptical of the project at first. We would get an email from Wes asking,Do you have a list of green objects? Could you send us a list of everything you have that is yellow?Our data system does not have these categories. _ <a class="footnote-ref" href="#brown2018"> [brown2018] </a></p>
<h2 id="introduction">Introduction</h2>
<p>Until late April of 2019, visitors of the Kunsthistorisches Museum in Vienna could drop in on the exhibit “Spitzmaus Mummy in a Coffin and Other Treasures” ,<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> co-curated by filmmaker Wes Anderson and designer Juman Malouf.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> The exhibit consisted of 430 relatively obscure objects selected from a collection of more than four million, spanning over 5,000 years. In putting the exhibit together, the curators had relied heavily on the museum’s curatorial staff, who had helped them navigate the collection<a class="footnote-ref" href="#brown2018"> [brown2018] </a>. Without such assistance, their task arguably would have been impossible to perform. The reason is that while most museums these days work with searchable digital catalogues (or collection management systems), the descriptions those systems contain typically neglect certain aspects of the objects represented. For example, they usually do not contain specifications of such sensory features as colour – precisely the kind which, as the epigraph to this piece suggests, Anderson and his colleague were interested in.</p>
<p>In a more general sense, this holds true also for most moving image archives. Oftentimes, such institutions house collections of many thousands of films or television episodes, composed in turn of millions of discrete images. Typically, the sensory characteristics of those objects barely feature in catalogue descriptions. While some entries contain information, either at the title or the fragment level, about the colour or sound systems used, this information tends to be fragmentary. Moreover, further specifics about the films’ or episodes’ visual features are usually absent.</p>
<p>In recent years, audiovisual heritage institutions have invested much time and resources into digitising their collections, so as to enable various kinds of reuse. Yet in spite of this, the above situation is largely unchanged. So far, attempts to improve usability have focused primarily on the searchability of collections and the retrieval of collection items through (linked) metadata. Therefore, access to digital archives is overwhelmingly governed, even today, by a logic of search – one dominant in practices of information retrieval more in general<a class="footnote-ref" href="#whitelaw2015"> [whitelaw2015] </a>. Search relies on the use of semantic descriptors: keywords or other labels produced either manually, or as (semi-)automatically generated metadata. Apart from being labour-intensive to produce, such descriptors are also highly selective. In the case of audiovisual materials, for instance, they are usually limited to facts about production, or about the people, events and geographic locations they feature. Arguably, they serve the needs of a rather limited range of reuse practices; for instance, the production of documentaries, or scholarship in socio-political history, media production or (to a lesser extent) certain forms of aesthetic analysis. The design of an exhibit like Anderson and Malouf’s, but also other kinds of more creative reuse, require different kinds of information.</p>
<p>For users, the selectiveness of catalogue descriptions poses two important problems. On the one hand, it forces them to search collections on the basis of prior interpretations, and from the perspective of those who catalogued them – rather than to more freely explore them. On the other, it prevents them from relying in the process on features that are essential to their experience of heritage objects, but inadequately captured through verbal description; for example, visual features such as colour, but also shape or movement. Such characteristics are particularly significant for historic (moving) images, as those are valued not only for the information they hold, but also for their look andfeel<a class="footnote-ref" href="#delpeut1999"> [delpeut1999] </a>(cf.<a class="footnote-ref" href="#dudley2010"> [dudley2010] </a>).</p>
<p>The research project The Sensory Moving Image Archive (SEMIA): Boosting Creative Reuse for Artistic Practice and Research<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> departs from the observation that this situation impedes the work (and play) of a range of potential users. In response to this problem, it raises the question how sensory object features can be mobilised as the driving criterion to explore – rather than search – digitised audiovisual collections.Users,in this context, are filmmakers or exhibition designers, but also scholars. It has been argued, indeed, that the work of researchers may benefit from modes of access that do not (solely) rely on search and retrieval of single items but afford a more explorative form of browsing<a class="footnote-ref" href="#flanders2014"> [flanders2014] </a>, ideally also drawing on the sensory relations between discrete items within collections.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> Beneficiaries of such an approach are scholars already concerned in their work, for instance, with colour palettes, or patterns of movement in historical film – whether considered in terms of their technological preconditions (as in<a href="#yumibe2012">Yumibe [2012]</a>), their relation to film style and aesthetics<a class="footnote-ref" href="#heftberger2009"> [heftberger2009] </a><a class="footnote-ref" href="#street2012"> [street2012] </a><a class="footnote-ref" href="#street2013"> [street2013] </a><a class="footnote-ref" href="#fluckiger2017"> [fluckiger2017] </a><a class="footnote-ref" href="#heftberger2018"> [heftberger2018] </a>or from a more experiential perspective<a class="footnote-ref" href="#mazzanti2009"> [mazzanti2009] </a>, for instance in terms of their haptic or synaesthetic aspects<a class="footnote-ref" href="#catanese2019"> [catanese2019] </a>. But arguably, also others can benefit, as it can help reveal previously unanticipated patterns or relations in or between widely divergent materials, that elicit novel research questions of their own.</p>
<p>SEMIA, a two-and-a-half year project that ran until late January 2020, was a collaboration between the University of Amsterdam (with contributions from media and audiovisual heritage scholars as well as computer scientists), the Amsterdam University of Applied Sciences (specifically, experts in the domain of data visualisation and interface design), the interaction design company Studio Louter (experienced in the development of museum presentations) and two audiovisual heritage institutions: Eye Filmmuseum (focusing on film and cinematography) and the Netherlands Institute for Sound and Vision (television).<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> The team’s overarching aim was to establish whether, and how, repurposing software for analysing and visualising colour, shape, visual complexity and movement might enable alternative forms of accessing collections of moving images. To this end, it developed a prototype tool that invites users to explore collections on the basis of those features, rather than to search them through (verbal) descriptions resulting from prior interpretations of specific objects in discrete films or film sequences. In doing so, it not only sought to delay the moment in time when significance is assigned – that is, when the meaning of specific sensory features, or of the relations between them, is determined – but also to place this task in the users’ own hands (compare<a href="#kuhn2013">Kuhn et al. [2013]</a>). The tool was designed to deal with large numbers of heterogeneous materials (in terms of production date, genre, but also medium) so as to allow for the revelation of potentially surprising connections. The corpus used for testing was made up of fragments from the collections of Eye and Sound and Vision, as featured on the open access platform Open Images.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<p>The project consisted of two phases, whose timings partly overlapped: a first, focused on image feature extraction and analysis, and a second, concerned with the development of a “generous” interface<a class="footnote-ref" href="#whitelaw2015"> [whitelaw2015] </a>, visualising the relations between fragments on the basis of analysis results. The first phase, which we elaborate on in this article, involved the use of computer vision methods.</p>
<p>In computer vision, a subdiscipline of AI, models are developed for extracting key information – so-called visualfeatures– from images, so that they can subsequently be cross-referenced. In the analysis process, images are transformed into descriptions that are used in turn to classify them. In the early years of the field, methods were developed that required humans to determine which operations systems had to perform in order to produce the intended analysis results. More recently, however, methods based on machine learning, whereby computers are trained with techniques for automatic feature learning, are becoming more popular.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></p>
<p>In SEMIA, we used a combination of both types of methods. In what follows, we explain why this is the case, and elaborate on how the computer scientists in our team aligned their work with our overall objective of enabling new forms of exploration. In doing so, we specifically focus on how we changed the preconditions for archival reuse (the scholarly kind in particular). We are motivated by the observation that reliance on visual features and relations in accessing collections not only opens up new avenues for research, but also helps challenge current understandings of how knowledge is produced – in media and heritage studies (traditional as well as digital) and in the digital humanities more broadly.</p>
<p>In our contribution, we take afunnel approach,gradually narrowing our focus to the specific extraction and analysis tasks carried out within the SEMIA project. First, we provide a broad outline, and discussion, of thelandscapeof visual analysis for media scholarly research, and developments in this area over time. We pay attention both to the interests and objectives of those active in the field (along with their epistemic underpinnings) and to their specific approaches or methods. The purpose of this exercise is twofold: to specify the project’s place among prior efforts, and to further elucidate our overall motivation in taking it on. Subsequently, we zoom in on what feature analysis means for SEMIA: first, by looking at the general principles behind our approach to feature extraction, and then, by discussing some analysis results. In our conclusions, we confront those results with our initial intent in exploring the affordances of computer vision for providing access to collections.</p>
<h2 id="visual-analysis-in-digital-scholarship-media-art-and-explorative-browsing">Visual Analysis in Digital Scholarship, Media Art and Explorative Browsing</h2>
<p>In developing a tool that supports a more unconstrained browsing of media archives than is currently available, we sought to complement existing approaches to, and methods for, the visual analysis of moving images. Those approaches and methods have emerged primarily in the context of stylometric research of the 1970s and on, and tend to be tailored to the detection of patterns in specific analytical units. In the interpretation of data, stylometric research usually adheres to semantic categories that have traditionally had relevance also for both archives and media historical research (in particular, the above-mentioned categories of director or creator, or production time). For the purposes of the SEMIA project, we needed to let go of the assumptions this implied about what ismeaningfulabout collection objects.</p>
<p>To achieve this, we followed the line of reasoning of a recent trend in digital film and media studies scholarship that seeks to reorient visual analysis methods by drawing on artistic practices of archival moving image appropriation. Such strategies are not intent on finding patterns in preselected image units, but are geared instead towards accidental or unanticipated finds that reveal more surprising similarities – or contrasts – in audiovisual materials. Those pioneering scholars, whose work we sample below, are convinced that artistic work can inspire users <em>not</em> to approach data from the perspective of specific questions or hypotheses, but to explore them more freely, also letting go in the process of more conventional categories for interpretation.</p>
<p>In order to specify the epistemological underpinnings of our own approach, it is helpful to start off with a brief consideration of the foundational assumptions of stylometry. This will help us to subsequently explain how more recent projects in visual analysis in our field draw on this tradition, while also moving it in different directions. We end the section with some further elaboration on the appropriation-indebted trend in film and media studies, explaining how it was inspirational for us.</p>
<p>In film and media studies, the visual analysis of moving images was developed as part of the intertwining stylometric research programmes commonly referred to asstatistical style analysisandcinemetrics,initiated with the pioneering work of Barry Salt and Yuri Tsivian respectively. Arguably, these programmes had their very early roots in film theory and criticism from the 1910s and 1920s, attending to the interrelations between film editing, style and perception, and gained a foothold in academic institutions in the 1970s (see<a href="#buckland2008">Buckland [2008]</a>and<a href="#olesen2017">Olesen [2017]</a>for more on those historical developments). Their objective was to discern patterns in audiovisual materials, in a way that resembles the analysis of linguistic patterns in literary computing (for instance, for the purpose of authorship attribution, for the dating of films, or for the creation of statistical profiles of directorial styles, periods or genres and their changes over time). Such research often took a deductive approach, producing data that supports stylistic analysis as a morerigorousalternative, or complement, to traditional hermeneutic approaches. In its first decades as a scholarly form of research, stylometry pursued its objectives primarily by manually annotating, coding and quantifying data on shot lengths and shot types in films and television materials, to subsequently relate the data thus obtained to known information (for instance production or release date, production company, genre or director) in an attempt to interpret significant patterns.</p>
<p>In recent years, as digital humanities methods have proliferated, stylometric research in media studies has become more complex in its methods, but also more varied in its interests. In the past, shot length and shot type were key parameters for analysis; more recently, however, attention is also being paid to colour, motion, (recurring) objects and aspects of visual composition. Projects such as Digital Formalism<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> (2007-2010) and ACTION<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> (2011-2013) are illustrative of this development. Digital Formalism (a collaboration of the University of Vienna, the Austrian Filmmuseum and the Vienna University of Technology) sought to analyse the complex formal characteristics of Soviet director Dziga Vertov’s films. To achieve this, it strongly relied on a logic of feature-learning, whereby relevant image information was extracted with the help of purpose-produced algorithms. This involved the analysis of high-level – that is, complex – semantic features, such as visual composition or motion composition<a class="footnote-ref" href="#zeppelzauer2012"> [zeppelzauer2012] </a>. The ACTION project at Dartmouth College, resulting in an open-source toolkit, expanded the scope of authorship attribution research by facilitating not only the analysis of motion, but also colour and audio features; moreover, it focused on the films of twenty-four canonical directors, rather than a more homogeneous corpus consisting of work by a single maker.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> In addition, the project relied less on purpose-produced algorithms, making use instead of existing solutions, including (but not limited to) machine learning tools<a class="footnote-ref" href="#casey2013"> [casey2013] </a>. This way, it also expanded stylometry’s scope in the technological sense, while it remained true to its foundational drive towards quantitative, empirical research.</p>
<p>In this respect, ACTION certainly paved the way for SEMIA. On the one hand, because the project relies to a considerable extent on techniques developed or used in the context of previous stylometric research. And on the other, because it likewise engages in the extraction and quantification of moving image data. In SEMIA, however, such extraction serves rather different purposes. Data analysis, in this case, is not done with the objective of authorship attribution or for the establishment of genre features dominant in a particular corpus or period. As previously explained, the project is focused rather on enabling exploratory browsing, affording (possibly incidental) discovery of similarities that do not neatly align with existing interpretative frameworks. For instance, similarities between collection items that do <em>not</em> have a maker or production time in common, or visual features that can <em>not</em> easily be understood as shared stylistic elements.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></p>
<p>To this end, the project draws inspiration from an emerging approach to visual analysis and data visualisation in digital film and media studies scholarship – an approach that is indebted in turn to media art practice and experimental filmmaking. Kevin Ferguson, a proponent of this trend, explains that there is a tradition of experimental work in media studies that “balances between [&hellip;] new media art and digital humanities scholarship” <a class="footnote-ref" href="#ferguson2016"> [ferguson2016] </a>, intent on “deforming” its object of study<a class="footnote-ref" href="#ferguson2017"> [ferguson2017] </a>. Arguably, such work challenges (especially early) stylometry’s version of visual analysis, in pursuit of “a digital humanities project that is more aleatory and aesthetic than it is formal and constrained” <a class="footnote-ref" href="#ferguson2017"> [ferguson2017] </a>. Instead of rigorously counting and then comparing calculation results to produce historical insights into film form and its development, it highlights the occurrence of highly complex formal systems (which select images features are always part of) that may meaningfully relate to each other in multifarious ways. In doing so, it demonstrates the need to pay attention also to similarities that may not be detected if one sticks to more carefully defined analytical registers.</p>
<p>As previously mentioned, film and media scholars who proceed in this way oftentimes seek inspiration in the work of artists, and specifically, those engaged in practices of archival appropriation. History has shown that these practitioners in particular have their own contributions to make to the challenging of preconceptions underpinning scholarly analysis. At times, they even use the same analytical devices for this purpose – but in methodologically less rule-bound ways. In the last few decades, this has led to productive exchanges between academics, archivists and artists – the constellation Thomas Elsaesser once dubbed the “three A&rsquo;s” <a class="footnote-ref" href="#elsaesser2009"> [elsaesser2009] </a>– and as such, produced novel interpretations of audiovisual materials.</p>
<p>For instance, in the 1970s, when film historians would use projectors and editing tables to come up with statistics providing insight into developments in film style, artists would use those same devices to visually explore archival films in more idiosyncratic ways. They would focus in the process on particular image details, or dwell on and contemplate specific temporal units by stretching them. Examples of this practice are the 1970s structural films of Ken Jacobs, Al Razutis or Ernie Gehr, who repurposed films from the early 1900s. Their oftentimes rather abstract works highlighted thedifferentformal properties of early cinema (compared to the narrative standard of later years). In bringing those to the fore, they challenged prevalent assumptions among contemporary historians, who had in fact largely neglected early cinema in their stylistic accounts to date<a class="footnote-ref" href="#testa1992"> [testa1992] </a>. While scholars may not always be able to make immediate (historiographic) sense of such work – although the contemporaries of Jacobs and others ultimately did – it may invite them to look at specific visual features with fresh eyes, or from different perspectives.</p>
<p>Ultimately, the great merit of such artistic work is that it strips archival films of the categories and interpretive frameworks with which they have previously been associated – thus opening up the possibility of applying new ones. Film scholar Michael Pigott, in this context, has credited the practice with “inducing illegibility.” In his view, this sort of work serves “the dual purpose (and double tension) of making the image illegible (again) and then attempting to read it” <a class="footnote-ref" href="#pigott2015"> [pigott2015] </a>. The potential for inducing illegibility is not exclusive to structural filmmaking (a common reference point for this purpose within film studies) but can also be found in contemporary media art. Currently, there is a small, but important body of artworks that critically explore moving image data, and prove inspirational also to film and media scholars; for instance, the film data visualisation work by such artists as Jim Campbell<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> or Jason Salavon<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> <a class="footnote-ref" href="#habib2015"> [habib2015] </a><a class="footnote-ref" href="#ferguson2017"> [ferguson2017] </a>. This work precedes contemporary digital scholarship by fifteen to twenty years, and has used different coding languages and visualisation softwares, but resulting in at times remarkably similar expressions. Likewise, artist and designer Brendan Dawes’ Cinema Redux<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> project (2004) experimented with grid visualisations of classic films, inviting gallery visitors to contemplate film data visualisations as visual compositions in their own right, rather than to use them as an empirical basis for establishing patterns along well-known interpretive lines.</p>
<p>In setting up SEMIA, the project team, while familiar with the above-mentioned examples, was more directly inspired by the work of Dutch video artist Geert Mul – a long-term collaborator of heritage partner Sound and Vision. Particularly influential for the projects’ approach was <em>Match of the Day</em> (2004-2008), an early example of an artwork produced with the help of algorithms for visual analysis, made up entirely of stills from satellite television images (see<a href="#figure01">Figure 1</a>). The piece demonstrates particularly well how artists can productively exploit similarities in image features among widely heterogeneous objects, that are too fuzzy to be meaningful for the rigorous testing of hypotheses.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://player.vimeo.com/video/7305683" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="Geert Mul, Match of the Day (2004-2008)." webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
</div>
<p>To create his work, Mul used large databases of images, for which he extracted a wide variety of visual features. Those features served in turn as the basis for a matching of images at different levels of similarity. The first part of this process was conducted automatically; however, human intervention occurred when the artist selected approximate rather than identical matches to include in his work<a class="footnote-ref" href="#mul2018"> [mul2018] </a>. In stylometric research, suchmatcheswould likely be considered errors, glitches or mismatches. But in the context of an exploratory browse through an archival collection, they are precisely the kinds of results that may yield unexpected connections or patterns, worth investigating further outside of conventional notions of authorship, genre or period.</p>
<p>The above observations informed our decision, made early on in the SEMIA project, to radically abandon those kinds of categories, as embedded in archival metadata through semantic descriptions, and to opt instead for a visual analysis approach. We did this primarily by way of experiment, and in the assumption that the explorative options it opened up would eventually prove useful primarily <em>in combination with</em> search-based approaches drawing on existing metadata. (Inducing illegibility, after all, is rarely the end of a research process, and primarily makes sense in the early, exploratory phases of study. Further on in the process, existing metadata categories may then prove productive once again.) In what follows, we discuss how we undertook this visual analysis task, paying specific attention to the choices we made in the process – conceptual as well as technical, and in light of the aforementioned principles.</p>
<h2 id="feature-extraction-in-semia-a-turn-towards-abstraction">Feature Extraction in SEMIA: A Turn towards Abstraction</h2>
<p>In addition to pursuing a different set of media scholarly objectives, the SEMIA project team also sought to engender a shift in terms of the techniques used for visual analysis. In this section, we discuss the rationale behind our choice for specific feature extraction methods, and why we chose to tweak existing ones in particular ways. The connecting links between those different choices are, first, our wish to extract features that would point to unanticipated – rather than predictable – connections among objects, and second, to do so at a higher level of abstraction than is currently considered “state of the art,” in light of the overwhelming focus in computer vision on the recognition of meaningful semantic entities.</p>
<p>To a greater extent than other projects so far – ACTION, for instance, or the Zürich-based FilmColors – SEMIA set out to explore the affordances of deep learning techniques for revealing similarity-based patterns in (large) collections of digitised moving images.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> The assumption was that those patterns would enable users to follow alternativeroutesthrough the collections,remixingthem as it were, and that this would elicit new questions about the items and their mutual relations. As we previously explained, we were specifically interested in relations inspired by the material’s visual features – rather than the sort of filmographic or technical data that make up traditional metadata categories for film and video.</p>
<p>As it happens, such metadata, in archival collections, are often also fragmentary – and therefore, hardly reliable as a starting point for an inclusive form of collection exploration. Early on in the project, we took this as a key argument for looking into the possibilities of computer vision, and specifically deep learning techniques, for the purpose of feature extraction. This approach would help us generate large quantities of new metadata that would invite, if not a more inclusive kind of exploration, then at least one that could complement approaches to access based on search. After all, a lack of metadata in the form of semantic descriptors as encountered in an institutional catalogue may render the objects in a collection invisible, and therefore unfindable. While an approach relying on visual analysis does not solve this problem – as it can create new invisibilities, which we argue elsewhere (see<a href="#masson">Masson and Olesen [2020]</a>) – it does challenge existing hierarchies of visibility.</p>
<p>Initially, the choice for a deep learning approach seemed to fit neatly with the project’s intent to refrain as much as possible from determining in advance the route a computer might take in order to identify similarities between collection items. In the alternative scenario, known asfeature engineering,it is humans who design task-specific algorithms, which are used to extract pre-defined features from the images in a database (so that they can subsequently be compared). Deep learning, which relies to an overwhelming extent on the use of Neural Networks (NNs, orneural netsfor short), involves algorithms trained with techniques for automatic feature learning (and as such, is a particular brand of machine learning). As we mentioned in the introduction, this is a more recent approach, and it entails the learning of specific data representations rather than set analysis tasks. Like feature engineering, deep learning does to some extent rely on the intervention of humans; after all, it is people who, at the training and/or retraining stages, determine which similarities do or do not make sense (see also<a href="#masson2019">Masson and van Noord [2019]</a>; in<a href="#masson2020">Masson and Olesen [2020]</a>, we elaborate on the epistemic implications for users of our tool). However, it does not require them to decide in advance <em>how</em> the task of identifying those similarities needs to be performed (that is, on the basis of which features). In principle, this opens the door for image matches unanticipated by people, and therefore, of novel routes through a database or collection.</p>
<p>However, we soon decided to only partially rely on such techniques – and the abovementioned role of human knowledge is certainly one of the reasons why. As a rule, deep learning is employed for the recognition of semantic classes, and more specifically, object categories. This is hardly surprising, as the development of such techniques is oftentimes done for purposes that involve the recognition of semantic entities: vehicles, people, buildings, and so on. (One might think here of applications for transportation and traffic control, geolocation, or biometrics; see e.g.<a href="#ucar2017">Uçar et al. [2017]</a>;<a href="#arandjelovic2018">Arandjelović et al. [2018]</a>;<a href="#taigman2014">Taigman et al. [2014]</a>). Within the SEMIA context, however, the use of conventional semantic classes does not make sense, as it is the sensory aspects of collection items – rather than the meanings we may assign to images, or image sections, on the basis of specific content – that are of interest. In fact, semantic classes commonly identified by deep learning approaches partially overlap with the sorts of categories that are used in descriptive metadata for archival collections, and that are central also to practices of search and retrieve. In performing feature extraction, we had hoped to be able to work instead with more abstract visual categories, which according to computer vision logic, involves extraction at a lower (syntactic) feature level (a point we elaborate on further below).</p>
<p>Another reason why exclusive reliance on a deep learning approach ultimately did not make sense, is that its underlying logic clashed with the requirements we had for interfacing. If our objective was to take sensory features as the point of entry into the collections, then it was imperative that our exploration tool allowed users to also take those features as the basis for digging further into the connections between items. For this purpose, we would need to at least minimally categorise, or re-categorise, those features, from the outset. The most logical choice here was to use the same intuitive classes that had also inspired the project: features such as colour, shape and visual complexity, and, for relations across time, movement.</p>
<p>One way of tackling this task with deep learning methods might have been to run successive analyses, whereby each time, the focus would be on one specific set of features, while other features would be cancelled out. For example, in order to extract information about shape, we might have deactivated the neural net’s colour ‘sensitivity’ by temporarily turning all images in the database into black-and-white, so as to focus its attention in the required direction. This type of approach is generally associated with a (fairly new) line of research in computer science, focused on learning so-called “disentangled representations” (see<a href="#xiao2018">Xiao et al. [2018]</a>;<a href="#denton2017">Denton and Birodkar [2017]</a>). So far, however, it has had limited success.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> But even aside from the issues it currently entails, it also undermines our most fundamental rationale for working with deep learning techniques: the fact that one need not determine in advance how the particular task of similarity detection is carried out, and specifically, which types of features are used in the process. For this reason, we ultimately decided on a more diversified approach, which combined the use of deep learning with feature engineering.</p>
<p>A major point of attention was the need to attain a sufficient measure of abstraction in the results of the computer vision part of the project – results that were used in the development of a tool for visualising the sensory relations between the films and fragments in our database (a process we shall discuss elsewhere). We explained that our objective within SEMIA was to inspire users by revealing potentially significant relations between database items; in doing so, however, we sought to relegate the act of assigning such significance – or in Pigott’s terms: of attempting toreadimages made illegible, through novel relations – as much as possible to users. For example, while we may want to draw attention to the circumstance that a specific set of database objects covers very similar colour schemes, or that they feature remarkably similar shapes, we leave it to the user to figure out whether, and if so how, this might be significant (that is, what questions it raises about media and their histories, or which alternative ways of researching historical film or television materials it affords). But arguably, we also withhold interpretation at a more basic level. In the above example, for instance, we leave undetermined whether similarity in colour or shape derives from the fact that the images concerned actually feature the samethings.(They might, and they often do – but it is not necessarily so.) In this respect, what we do is entirely at odds with the objectives of much machine learning practice in the field of computer vision.</p>
<p>Our search for abstraction is evidenced in a very concrete way by what happened exactly in the feature extraction process. First, the extraction of image information along the lines of colour, shape, visual complexity and movement was not followed in our case by an act of labelling: of placing an image or image section in a particular (semantic) class (we elaborate on this point in<a href="#masson2020">Masson and van Noord [2020]</a>). The reason, of course, is that we did not actually seek to identify objects. For the purposes of our SEMIA experiment, the information as such, and the relations it allowed us to infer, were all we were interested in. Second, our search for abstraction is also evident from our application of deep learning methods, which was limited to the extraction of information about shape. Here, we focus on what computer vision experts calllower-levelfeatures – a notion that requires some further elaboration.</p>
<p>In computer vision, conceptual distinctions are oftentimes made between image features at differentlevels.From one perspective, these are distinctions in terms of feature complexity. Levels of complexity range from descriptions relevant to smaller units (such as pixels in discrete images) to larger spatial segments (sections of such images, or entire images), whereby the former also serve as building blocks for the latter. From another, complementary perspective, the distinction can also be understood as a sliding scale from moresyntactic(and abstract) to moresemanticfeatures (the latter of which serve the purpose of object identification). Taking the example of shape-related information, we might think of a range that extends from unspecified shapes, for instance defined in terms of their edges (low-level), to more defined spatial segments such as contours or silhouettes (mid-level), all the way to actual object entities (e.g. things, people, faces, etc.) or relations between such entities. In SEMIA, we made use of a neural network trained for making matches at the highest (semantic) level. However, we scraped information at a slightly lower one, which generally contains descriptions of object parts. At this level, it recognises shapes, but without relating them to the objects they are part of.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></p>
<p>Arguably, this approach helped us mitigate a broader issue that the use of computer vision methods, and machine learning in general, posed for the project: that its techniques are designed, as Adrian MacKenzie puts it, to “mediate future-oriented decisions” – but by implication, also to <em>narrow down</em> a range of options by ruling other decisions out<a class="footnote-ref" href="#mackenzie2017"> [mackenzie2017] </a>. In machine learning, datasets are used to produce probabilistic models, learned rules or associations, that generate predictive and classificatory statements<a class="footnote-ref" href="#mackenzie2017"> [mackenzie2017] </a>. In the case of networks for image pattern recognition, for example, these are statements that lead to conclusions as to how much (or how little) images look alike. However, the valuation ofaccurateidentifications at the semantic level as the highest achievable goal within machine learning also imposes limitations, in that it renders meaningless all other similarities – and importantly, dissimilarities – between objects in a database. Anna Munster, therefore, argues that prediction also “takes down potential” (quoted in<a href="#mackenzie2017">Mackenzie [2017, 7]</a>). Within the SEMIA context, we expressly tried to bring back some of this potential for the user. Sometimes this required us to deviate from what was ‘state of the art’ in the field of computer vision. Only in this way, after all, we could leave room for matches that might, within a purely semantic logic, be considered mistakes but still provide productive starting points for unrestrained explorations of patterns that perhaps no one had noticed before.</p>
<h2 id="extraction-results-lesson-learnt">Extraction Results: Lesson Learnt</h2>
<p>To round off this account, we now look at the results of our feature extraction efforts, and at what we learnt about the aptness of the approach for our goals. The classes of features the SEMIA project centred on are embedded in a rich history of computer vision research, which, as we previously explained, began with a process of manually designing features for predefined analysis tasks.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> We also, however, deviated from this history, in that we did not use such algorithms for the purpose they were meant to serve: the assigning of (object) labels. Instead, we only relied on the feature descriptions they produced. Those descriptions are quite general, but still specific enough to bring out the sensory aspects of image elements that we were interested in. In what follows, we very briefly touch upon our methods (further technical details can be found in the notes) and then consider the results we obtained, evaluating their usefulness in light of the project’s goals.</p>
<p>As mentioned earlier, we chose to focus on four broad sets of image features, commonly understood as instances of shape, colour, visual complexity and movement. Shape, we explained, is the only feature for which we extract information using a neural net. The net we chose was trained for object recognition, but is commonly repurposed for other tasks.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> To make it meet our demands, we selected an intermediate feature representation rather than the uppermost layer in the net (that is, the highest complexitylevel,where, as we explained in<a href="#section">the previous section</a>, the prediction probabilities for the semantic classes it was trained on are to be found).<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> This way, we could use its description of object parts and general shape, rather than of specific objects. For colour extraction, we made use of histograms, a common method in image processing.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> Specifically, we chose histograms in CIELAB colour space (one that aligns closely with human perception) capturing the colour values used in a moving image irrespective of their spatial position. Visual complexity was understood in SEMIA as a measure of how much clutter there is in a visual scene (for instance, a highly textured or very busy scene will have a greater visual complexity than an empty scene, or one with mostly smooth surfaces). For the extraction of information of this kind, we used a method called Subband Entropy, which expresses a scene’s visual complexity as a single scalar value.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup></p>
<p>The features used to describe shape, colour, and visual complexity were all extracted with techniques that are applied to still images. In order to apply them to moving image material, we extracted feature descriptions from shots taken from the films and programmes in our corpus. Specifically, we extracted the shape, colour, and visual complexity features from five frames, evenly spaced throughout the shot, and aggregated them to create the final feature descriptions. Movement, however, is a feature specific to moving images. For extracting this kind of information, we relied on an optical flow method, measuring relative motion between two subsequent frames. In each case, we applied it to the same sets of five frames.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup></p>
<p>For the purpose of the project, we gathered approximately 7,000 videos, which we subsequently segmented into over 100,000 shots with the help of automatic shot boundary detection. Each of those shots was subjected to the four feature extraction algorithms. Altogether, this resulted in four different feature spaces, in which every shot constitutes a datapoint. By measuring the distance between all points, we could determine which other shots are most similar to a given one; the two closest points are known in this context as so-callednearest neighbours.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup></p>
<p>In<a href="#figure02">Figure 2</a>, we show three examples with theQueryshots to the left, represented here by a single still each, and the 16 shots identified as their nearest neighbours in the four different feature spaces to the right. A first possible observation concerns the diversity between the nearest neighbours for the three query shots: while all nearest neighbours share sensory aspects with their respective query image, they are considerably different from those for the other query shots. This at the very least suggests that they are not randomly selected. The second query shot, furthermore, shows a visible similarity between nearest neighbours across the four different feature spaces for each query image. This last pattern logically follows from the nature of nearest neighbours, in that shots that look similar in one sensory aspect, are likely to also look similar in others. Colours in a nature shot (such as the mushroom in the third query shot), for example, are very distinctive, making it likely that its nearest neighbours in terms of colour are also nature scenes. Similarly, the movement of leaves swaying in the wind is very distinctive, making it probable that the nearest neighbours of a shot with this element, in movement terms, also show leaf-rich scenes.</p>
<p>At the same time and in spite of other visual similarities, our query images also produce matches that are quite distinct, precisely, in terms of the semantic entities they feature. The movement feature space for the mushroom query image, for instance, features a standing man (presumably, one who moves from left to right or the other way around, in the same way that the mushroom does; however, it would require further inspection to ascertain this or to make sense of this pairing). In instances like these, the matching process has arguably yielded more unexpected or surprising results and variations. Moreover, such matches occur more often if we look beyond the closest of the nearest neighbours. For example, a desert scene is similar to a beach scene in terms of colour, but not in terms of movement; in contrast, a grassy plain has similar movement to a beach scene, but differs strongly in colour. Hence, by exploring similarities in multiple feature spaces, we are still able to uncover such relations that would otherwise remain hidden.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Sample stills of query shots from the Open Images platform with four nearest neighbours in the shape, colour, movement, and visual complexity feature spaces
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Sample stills of query shots from the Open Images platform with four nearest neighbours in the shape, colour, movement, and visual complexity feature spaces
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Sample stills of query shots from the Open Images platform with four nearest neighbours in the shape, colour, movement, and visual complexity feature spaces
        </p>
    </figcaption>
</figure>
<h2 id="conclusions">Conclusions</h2>
<p>In this article, we have argued for a reorientation of existing visual analysis methods, in response to a need for exploratory browsing of media archives. We explained how we took our cue from a recent line of digital scholarship inspired by artistic strategies in (new) media art, and how we also built on the tradition of exchange between film archives, media history and appropriation art. Historically, artists have used the analytical devices of scholars to different ends, thus engendering shifts in the latter’s working assumptions. In a similar vein, the SEMIA project team drew inspiration from the ways in which data artists repurpose existing visual analysis tools. We did so with the specific goal of enabling a transition from searching to browsing large-scale moving image collections. This way, we not only hoped to significantly expand the range of available metadata, but also to allow for the revaluation of the images’ sensory dimensions in the very early stages of research. Ultimately, we think, both approaches to collection access can very well complement each other.</p>
<p>Our goal required that for the extraction of data, we adhered to the following general guidelines. In order to reduce the system’s reliance on <em>a priori</em> interpretations, we first of all sought to avoid direct human intervention in the actual extraction process. As a matter of principle, it should be up to the algorithm to determinesimilar,somewhat similar,ordissimilar– even if, as we argue elsewhere, algorithms ultimately always rely on knowledge that originates in humans (see<a href="#masson2019">Masson and van Noord [2019]</a>). Furthermore, we tweaked the algorithm to partially prevent it from recognising (human-taught) semantic units. Consequently, it could focus on similarities at a more abstract level. At this stage, some human intervention is ultimately unavoidable, as it is the computer scientist who decides (ideally on the basis of sample testing results) at which featurelevelthe extraction takes place.</p>
<p>One conclusion that can be drawn from our review of most similar results is that extracting data with a minimum of labelling and human intervention, while also attending to intermediate similarities, never truly cancels out the detection of semantic relations and patterns altogether. In fact, this is hardly surprising, because this relation between low-level feature representations and objects – one that frames objects in terms of its facets; for instance, in the case of an orange, its colour and rounded shape – has been commonly exploited in early work on computer vision to detect semantic relations and objects. Therefore, some feature combinations are simply too distinctive to not be detected with our chosen approach – even if we do our best to block the algorithms’ semanticimpulse.<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> Yet our examples show that the analysis of query images also produces nearest neighbour matches that initially seem moreillegible,and therefore, invite further exploration. In this sense, our working method does yield surprising results, or unexpected variations. In the remainder of our project, which we report on elsewhere, our intent has been to further stimulate users in exploring those less obvious connections by extending our interface with the capacity to also browse <em>dis</em> similar results.</p>
<p>The next step, which we expand on in an upcoming piece, is to assess which kinds of questions and ideas exploratory browsing through the lens of sensory features ultimately yields, and to evaluate how this furthers the efforts of various user groups<a class="footnote-ref" href="#masson"> [masson] </a>. Throughout our research process, we have been wondering about the potential of such browsing for the purpose of what (social) scientists, and more recently also information and media scholars, have termed “serendipitous” discoveries<a class="footnote-ref" href="#vanandel1994"> [vanandel1994] </a><a class="footnote-ref" href="#foster2014"> [foster2014] </a>. The literature uses this term for chance encounters with research objects that engender new ways of explaining or thinking about problems – both known ones, and problems one was perhaps previously unaware of.</p>
<ul>
<li id="arandjelovic2018">Arandjelović, R., Gronat, P., Torii, A., Pajdla, T., and Sivic, J. “NetVLAD: CNN Architecture for Weakly Supervised Place Recognition” , _IEEE Transactions on Pattern Analysis and Machine Intelligence_ , 40.6 (2018): 1437-51. DOI: 10.1109/TPAMI.2017.2711011.
</li>
<li id="taylor2019">Taylor, Arnold, and Tilton, Lauren. “Distant viewing: analyzing large visual corpora” . _Digital Scholarship in the Humanities,_ fqz013 (2019). DOI: 10.1093/digitalsh/fqz013.
</li>
<li id="brown2018">Brown, K. “Wes Anderson’s Offbeat Debut as a Curator Drove a Storied Museum’s Staff Crazy: The Results Are Enchanting” . _Artnet News_ (2018). Available at:<a href="https://news.artnet.com/exhibitions/wes-anderson-curator-kunsthistorisches-museum-1387429">https://news.artnet.com/exhibitions/wes-anderson-curator-kunsthistorisches-museum-1387429</a>(accessed 1 March 2020).
</li>
<li id="buckland2008">Buckland, W. “What Does the Statistical Style Analysis of Film Involve?” , _Literary and Linguistic Computing_ , 23.2 (2008): 219-30. DOI: 10.1093/llc/fqm046.
</li>
<li id="casey2013">Casey, M., and Williams, M. “ACTION (Audio-visual Cinematic Toolbox for Interaction, Organization, and Navigation): an open-source Python platform” white paper, report ID 104081 (2013). Available at:<a href="https://hcommons.org/deposits/item/hc:12153/">https://hcommons.org/deposits/item/hc:12153/</a>(accessed 29 March 2020).
</li>
<li id="catanese2019">Catanese, R., Scotto Lavina, F. and Valente, V. (eds.). _From Sensation to Synaesthesia in Film and New Media._ Cambridge Scholars Publishing, Cambridge (2019).
</li>
<li id="colque2017">Colque, R. V. H. M., Caetano, C., De Andrade, M. T. L., and Schwartz, W. R. “Histograms of Optical Flow Orientation and Magnitude and Entropy to Detect Anomalous Events in Videos” , _IEEE Transactions on Circuits and Systems for Video Technology_ , 27.3 (2017): 673-82. DOI: 10.1109/TCSVT.2016.2637778.
</li>
<li id="delpeut1999">Delpeut, P. _Diva dolorosa: Reis naar het einde van een eeuw._ Meulenhoff, Amsterdam (1999).
</li>
<li id="denton2017">Denton, E., and Birodkar, V. “Unsupervised Learning of Disentangled Representations from Video” . In E. Guyon et al. (eds.), _Advances in Neural Information Processing Systems 30, Neural Information Processing Systems Foundation_ (2017). Available at:<a href="https://papers.nips.cc/paper/7028-unsupervised-learning-of-disentangled-representations-from-video.pdf">https://papers.nips.cc/paper/7028-unsupervised-learning-of-disentangled-representations-from-video.pdf</a>(accessed 29 March 2020).
</li>
<li id="dudley2010">Dudley, S. (ed.). _Museum Materialities: Objects, Engagements, Interpretations._ Routledge, London (2010).
</li>
<li id="elsaesser2009">Elsaesser, T. “Archives and Archaeology: The Place of Non-Fiction Film in Contemporary Media” . In V. Hediger and P. Vondereau (eds.), _Films That Work: Industrial Film and the Productivity of Media_ , Amsterdam University Press, Amsterdam (2009), pp. 19-34.
</li>
<li id="ferguson2016">Ferguson, K. L. “The Slices of Cinema: Digital Surrealism as Research Strategy” . In C. R. Acland and E. Hoyt (eds.), _The Arclight Guidebook to Media History and Digital Humanities_ , REFRAME Books, Sussex (2016), pp. 270-299.
</li>
<li id="ferguson2017">Ferguson, K. L. “Digital Surrealism: Visualizing Walt Disney Animation Studios” , _Digital Humanities Quarterly_ , 11.1 (2017). Available at:<a href="http://www.digitalhumanities.org/dhq/vol/11/1/000276/000276.html">http://www.digitalhumanities.org/dhq/vol/11/1/000276/000276.html</a>(accessed 29 March 2020).
</li>
<li id="flanders2014">Flanders, J. “Rethinking Collections” . In P. Longley Arthur and K. Bode (eds.), _Advancing Digital Humanities: Research, Methods, Theories_ , Palgrave Macmillan, Houndmills (2014), pp. 163-174.
</li>
<li id="foster2014">Foster, A. E., and Ellis, D. “Serendipity and its study” , _Journal of Documentation_ , 70.6 (2014): 1015-38. DOI: 10.1108/00220410310472518.
</li>
<li id="fluckiger2017">Flückiger, B. “A Digital Humanities Approach to Film Colors” , _The Moving Image_ , 17.2 (2017): 71–93.
</li>
<li id="heftberger2018">Heftberger, A. _Digital Humanities and Film Studies: Visualising Dziga Vertov’s Work_ . Springer, Cham (2018).
</li>
<li id="heftberger2009">Heftberger, A., Tsivian, Y., and Lepore, M. “Man with a Movie Camera (SU 1929) under the Lens of Cinemetrics” , _Maske und Kothurn_ 55.3 (2009): 31-50. DOI: 10.7767/muk.2009.55.3.61.
</li>
<li id="habib2015">Habib, A. _La Main gauche de Jean-Pierre Léaud_ . Les Éditions du Boréal, Montréal (2015).
</li>
<li id="he2016">He, K., Zhang, X., Ren, S., and Sun, J. “Deep Residual Learning for Image Recognition” . In _IEEE Conference on Computer Vision and Pattern Recognition_ , Computer Vision Foundation (2016), pp. 770-78. DOI: 10.1109/CVPR.2016.90.
</li>
<li id="kuhn2013">Kuhn, V., Craig, A., Franklin, K., Simeone, M., Arora, R., Bock, D., and Marini, L. “Large Scale Video Analytics: On-demand, iterative inquiry for moving image research” . In _2012 IEEE 8th International Conference on E-Science_ (2013). DOI: 10.1109/eScience.2012.6404446.
</li>
<li id="mackenzie2017">MacKenzie, A. _Machine Learners: Archaeology of a Data Practice_ . MIT Press, Cambridge, MA (2017).
</li>
<li id="masson2019">Masson, E. “Browsing Moving Image Collections” . _The Sensory Moving Image Archive_ (2019). Available at:<a href="https://sensorymovingimagearchive.humanities.uva.nl/index.php/2019/11/26/browsing-moving-image-collections/">https://sensorymovingimagearchive.humanities.uva.nl/index.php/2019/11/26/browsing-moving-image-collections/</a>(accessed 1 March 2020).
</li>
<li id="masson">Masson, E., and Olesen, C.G. “Digital Access as Archival Reconstitution: Algorithmic Sampling, Visualization, and the Production of Meaning in Large Moving Image Repositories” . _Signata: Annales des sémiotiques/Annals of Semiotics_ , 12 (2020).
</li>
<li id="masson2020">Masson, E., and van Noord, N. “Feature Extraction and Classification” . _The Sensory Moving Image Archive_ (2020). Available at:<a href="https://sensorymovingimagearchive.humanities.uva.nl/index.php/2020/01/06/feature-extraction-and-classification/">https://sensorymovingimagearchive.humanities.uva.nl/index.php/2020/01/06/feature-extraction-and-classification/</a>(accessed 1 March 2020).
</li>
<li id="mazzanti2009">Mazzanti, M. “Colours, Audiences and (Dis)Continuity in the Cinema of the Second Period ” , _Film History_ 21.1 (2009): 67-93.
</li>
<li id="mul2018">Mul, G., and Masson, E. “Data-Based Art, Algorithmic Poetry: Geert Mul in Conversation with Eef Masson” , _TMG – Journal for Media History_ , 21.2 (2018). Available at:<a href="https://www.tmgonline.nl/articles/10.18146/2213-7653.2018.375/">https://www.tmgonline.nl/articles/10.18146/2213-7653.2018.375/</a>(accessed 29 March 2020).
</li>
<li id="olah2017">Olah, C., Mordvintsev, A., and Schubert, L. “Feature Visualization: How neural networks build up their understanding of images” . _Distill_ (2017). DOI: 10.23915/distill.00007.
</li>
<li id="olesen2017">Olesen, C. G. “Towards a Humanistic Cinemetrics?” In K. van Es and M. T. Schäfer (eds.), _The Datafied Society: Studying Culture through Data_ , Amsterdam University Press, Amsterdam (2017), pp. 39-54.
</li>
<li id="pigott2015">Pigott, M. _Joseph Cornell Versus Cinema_ . Bloomsbury Academic, London (2015).
</li>
<li id="rosenholtz2007">Rosenholtz, R., Li, Y., and Nakano, L. “Measuring Visual Clutter” , _Journal of vision_ , 7.2 (2007): 17. DOI: 10.1167/7.2.17.
</li>
<li id="street2012">Street S. _Colour Films in Britain: The Negotiation of Innovation 1900-1955_ . BFI/Palgrave Macmillan, London (2012).
</li>
<li id="street2013">Street, S., and Yumibe, J. “The temporalities of intermediality: Colour in cinema and the arts of the 1920s” , _Early Popular Visual Culture_ 11.2 (2013): 140-57. DOI: 10.1080/17460654.2013.783149.
</li>
<li id="swain1991">Swain, M. J., and Ballard, D. H. “Color Indexing” , _International Journal of Computer Vision_ , 7.1 (1991): 11–32. DOI: 10.1007/BF00130487.
</li>
<li id="taigman2014">Taigman, Y., Yang, M., Ranzato, M., and Wolf, L. “DeepFace: Closing the Gap to Human-Level Performance in Face Verification” . In _2014 IEEE Conference on Computer Vision and Pattern Recognition_ , IEEE Computer Society/CPS (2014). DOI: 10.1109/CVPR.2014.220.
</li>
<li id="testa1992">Testa, B. _Back and Forth: Early Cinema and the Avant-Garde_ . Art Gallery of Ontario, Ontario (1992).
</li>
<li id="ucar2017">Uçar, A., Demir, Y., and Güzeliş, C. “Object recognition and detection with deep learning for autonomous driving applications” , _Simulation_ , 93.9 (2017): 759-769. DOI: 10.1177/0037549717709932.
</li>
<li id="vanandel1994">Van Andel, P. “Anatomy of the Unsought Finding. Serendipity: Origin, History, Domains, Traditions, Appearances, Patterns and Programmability” , _The British Journal for the Philosophy of Science_ , 45.2 (1994): 631-48.
</li>
<li id="wevers2020">Wevers, M. and Smits, T. “The visual digital turn: Using neural networks to study historical images” , _Digital Scholarship in the Humanities_ , 35.1 (2020): 194-207. DOI: 10.1093/llc/fqy085.
</li>
<li id="whitelaw2015">Whitelaw, M. “Generous Interfaces for Digital Cultural Collections” , _Digital Humanities Quarterly_ , 9.1 (2015). Available at:<a href="http://www.digitalhumanities.org/dhq/vol/9/1/000205/000205.html">http://www.digitalhumanities.org/dhq/vol/9/1/000205/000205.html</a>(accessed 29 March 2020).
</li>
<li id="xiao2018">Xiao, T., Hong, J., and Ma, J. 2018. "DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images". In _ICLR 2018_ – _Workshop track_ . ICLR, (2018). Available at: https://arxiv.org/pdf/1711.05415.pdf (accessed 29 March 2020).
</li>
<li id="yumibe2012">Yumibe, J. _Moving Color: Early Film, Mass Culture, Modernism_ . Rutgers University Press, New Brunswixck NJ/London (2012).
</li>
<li id="zeppelzauer2012">Zeppelzauer, M., Mitrović, D., and Breiteneder, C. “Archive Film Material – A Novel Challenge for Automated Film Analysis” , _Frames Cinema Journal_ , 1.1 (2012). Available at<a href="http://www.framescinemajournal.com/article/archive-film-material-a-novel-challenge/?format=pdf">http://www.framescinemajournal.com/article/archive-film-material-a-novel-challenge/?format=pdf</a>(accessed 29 march 2020).
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://www.khm.at/en/visit/exhibitions/2019/wesandersonandjumanmalouf2018/">https://www.khm.at/en/visit/exhibitions/2019/wesandersonandjumanmalouf2018/</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>The exhibit ran from 5 November 2018 until 28 April 2019.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="http://sensorymovingimagearchive.humanities.uva.nl/">http://sensorymovingimagearchive.humanities.uva.nl/</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>For further exploration of the relation between searching and browsing, and the explorative affordances of browsing, see<a href="#masson2019">Masson (2019)</a>, or<a href="#masson">Masson and Olesen (2020)</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Funding was obtained within the SMART Culture scheme of the Netherlands Organisation for Scientific Research (NWO).&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>See<a href="https://www.openbeelden.nl/">https://www.openbeelden.nl/</a>. Of course, working with digitised versions of originally analogue moving images entails that some of their potentially significant material aspects are already ‘erased’ in a process that precedes the act of engaging with a collection. In the SEMIA project, we took this to be an inevitability.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>In<a href="#masson2020">Masson and van Noord (2020)</a>, we elaborate on this history.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p><a href="https://www.ims.tuwien.ac.at/projects/digital-formalism">https://www.ims.tuwien.ac.at/projects/digital-formalism</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p><a href="https://hcommons.org/deposits/item/hc:12153/">https://hcommons.org/deposits/item/hc:12153/</a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>ACTION is short for Audio-visual Cinematic Toolbox for Interaction, Organization, and Navigation.<a href="http://digitalhumanities.dartmouth.edu/projects/the-action-toolbox/">http://digitalhumanities.dartmouth.edu/projects/the-action-toolbox/</a>&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>In this respect, the SEMIA project also differs in its intent from other initiatives that have been reported on since the writing of this piece; for instance, projects by the Distant Viewing Lab (<a href="https://www.distantviewing.org/">https://www.distantviewing.org/</a>) at the University of Richmond, reported on in<a href="#arnold2019">Arnold and Tilton (2019)</a>(focusing on narrative patterns and patterns in photographic style) or at the National Library of the Netherlands, by researchers-in-residence Melvin Wevers and Thomas Smits (on stylistic trends in newspaper visuals)<a class="footnote-ref" href="#wevers2020"> [wevers2020] </a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p><a href="http://www.jimcampbell.tv/portfolio/still_image_works/illuminated_averages/index.html">http://www.jimcampbell.tv/portfolio/still_image_works/illuminated_averages/index.html</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p><a href="http://www.salavon.com/work/Top25/">http://www.salavon.com/work/Top25/</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p><a href="http://www.brendandawes.com/projects/cinemaredux">http://www.brendandawes.com/projects/cinemaredux</a>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>The project’s full title is: <em>FilmColors: Bridging the Gap Between Technology and Aesthetics</em> . It runs until August of 2020.<a href="https://filmcolors.org/2015/06/15/erc/">https://filmcolors.org/2015/06/15/erc/</a>&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Hitherto, it has primarily been successful when applied to restricted domain and toy problems.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Many thanks to Matthias Zeppelzauer (St. Poelten University of Applied Sciences) for helping us gain a better understanding of these conceptual distinctions. For more on how neural nets specificallyunderstandimages, see also<a href="#olah2017">Olah et al. (2017)</a>.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>For example, Swain and Ballard, in the early 1990s, used colour information to identify and localise the position of objects<a class="footnote-ref" href="#swain1991"> [swain1991] </a>.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Specifically, we used ResNet-101; for more information on its repurposing, see<a href="#he2016">He et al. (2016)</a>.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>The layer we selected was the one located just below the fully connected layers, of 2048 dimensions.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>With this approach, each colour dimension is described by 16 bins, resulting in a feature representation of 4096 dimensions.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>For more information, see<a href="#rosenholtz2007">Rosenholtz et al. (2007)</a>.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>This involved constructing a histogram, for which we separately binned the angle and magnitude for a three by three grid of non-overlapping spatial regions – an approach akin to the HOFM approach described in<a href="#colque2017">Colque et al. (2017)</a>.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>The concept ofnearest neighbouris also key to the <em>Neural Neighbours: Pictorial Tropes in the Meserve-Kunhardt Collection</em> project (<a href="https://dhlab.yale.edu/projects/neural-neighbors/">https://dhlab.yale.edu/projects/neural-neighbors/</a>) conducted by the Yale Digital Humanities Lab at the Yale Beinecke Rare Book &amp; Manuscript Library. So far, however, this project has focused specifically on (originally) still images.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Exact matches rarely occur, because for the purposes of the project, the detection settings are tweaked in such a way that matches between images from the same videos are ruled out. (Therefore, only duplicate videos in the database can generate such results.)## Bibliography&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Film and Video Analysis in the Digital Humanities – An Interdisciplinary Dialog</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000532/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000532/</id><author><name>Manuel Burghardt</name></author><author><name>Adelheid Heftberger</name></author><author><name>Johannes Pause</name></author><author><name>Niels-Oliver Walkowski</name></author><author><name>Matthias Zeppelzauer</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="1-the-infrastructural-perspective-glam-institutions-and-film-archives">1. The Infrastructural Perspective: GLAM Institutions and Film Archives</h2>
<p>The computer-aided analysis of moving images is becoming an increasingly important topic within the digital humanities and it has been an interdisciplinary field since its beginnings: Computer science and media informatics, film and media studies as well as film archives and documentation centers have developed their own, independent approaches to the digital analysis of film. At the same time, however, several bridges have already been built between the individual disciplines: In computer science, for example, there has been research on automatic film and video analysis for more than 20 years, but it is still carried out without any visible connection to the field of film studies. Since the digital humanities have always been a place of interdisciplinary encounter and exchange, it is not surprising that the discovery of digital film studies (see<a href="#grant2012">Grant [2012]</a>) as a combination and continuation of the above-mentioned disciplinary traditions, has become a major topic in recent years. This special issue on “Digital Humanities &amp; Film Studies: Analyzing the Modalities of Moving Images” aims to promote an interdisciplinary dialog by presenting a variety of different articles from different fields. In order to get this dialog started, this introduction will try to work out the different disciplinary strands of computer-aided film and video analysis and to interconnect them in terms of a common digital humanities perspective.</p>
<p>A first important strand can be found in the so-called GLAM (galleries, libraries, archives, museums) institutions, with their close connection to information science. Cultural heritage institutions traditionally consider it their mission to facilitate the creation and dissemination of knowledge and works of art by providing access to their collections. This not only means engaging with academics, but also connecting with a wider community and addressing their diverse needs. In libraries, archives and museums, systems had already been established over centuries to support information retrieval in their collections, for instance bibliographies, finding aids, citation systems and concordances. This information was also made available in publications, thus linking the publishers, librarians, archivists and curators to the researchers. Film archives lag considerably behind when it comes to actively facilitate sharing their collections, but recent developments within the international film archiving community show a growing interest in exploring alternative ways of providing access to filmographic metadata, inventory information and contextual information likewise.</p>
<p>The beginnings of the fundamental restructuring of knowledge and the academic world can arguably be dated to 2003, when the National Science Foundation (NSF), the American government organization tasked with promoting basic research across disciplinary borders, commissioned a report, later colloquially named after then chairman<a href="#atkins2003">Dan Atkins (2003)</a>. In two subsequent reports from 2006 and 2007, published by the NSF and the American Council of Learned Societies (ACLS), the vision of a new “cyberinfrastructure &hellip; that supports peer-to-peer collaboration and new modes of education based upon broad and open access to leadership computing; data and information resources; online instruments and observatories; and visualization and collaboration services” was conclusively defined and disseminated<a class="footnote-ref" href="#arden2007"> [arden2007] </a>. Already in 2009, in the pivotal “Digital Humanities Manifesto 2.0” , Schnapp and Presner asked for a reevaluation of the relation between scholars and GLAM professionals and “affirm that modern universities still tend to separate scholarship from curation, a fact that is hardly deniable. The latter is normally reduced to a secondary and supportive role, thus sending curators within the museums, archives and libraries into exile” <a class="footnote-ref" href="#heftberger2014"> [heftberger2014] </a>. If we understand curation as the overarching process of taking care of the collection in various ways, it is probably closer to how the tasks in GLAM institutions have changed over the last ten years. </p>
<p>GLAM institutions are typically interested in two types of digital humanities: On the one hand, they themselves have a need for new technologies in order to be able to analyze, enrich, index and make their holdings accessible. On the other hand, they often act as consulting institutions for connected researchers to support them with knowledge, infrastructure and technology (for a comprehensive discussion of this topic, see<a href="#schaffner2014">Schaffner and Erway [2014]</a>). It is, however, still not clear where the personnel for the mentioned tasks could come from. Are new digital humanities graduates a way to fill these positions? Is it better to form tandems of humanities scholars and computer scientists, or even change archival educational programs (see<a href="#heftberger2018">Heftberger [2018]</a>)? Questions like these were openly discussed at a recent workshop (February 2020), held at the German National Library in Frankfurt, which dealt with the broader question of how cultural heritage institutions position themselves when it comes to digital humanities.</p>
<p>Nowadays, data management, data wrangling, data mapping and data sharing have become core elements of the daily work in archives, libraries or museums. As Julia Flanders describes, “most digital humanities work – as performed by library staff, IT staff, and other para-academic staff who are not faculty – is conceptualized according to one of the other models: hourly, by full-time equivalent, or as an agenda of projects that granularizes and regulates the work in quantifiable ways” <a class="footnote-ref" href="#flanders2012"> [flanders2012] </a>. According to Flanders, there is a tendency to define assignments in the framework of digital humanities (e.g. databases, online presentations, also perhaps long-term archiving) as projects and to outsource them to third parties. Although such a procedure is understandable, a chance is being missed: the opportunity to build in-house resources which would also enable engagement with collection content alongside the digital infrastructure and information management (see<a href="#heftberger2018">Heftberger [2018]: 20</a>).</p>
<p>One core task in the film archive is film identification and data enrichment via subject indexing, which is usually still done manually. In the meantime, it has become possible to annotate video files, to provide them with keywords to the precision of a frame, to annotate them with geographical data and to comment on them in free text. Potentially digital collections can be mined for patterns and objects, and research can take place at the level of content but also at the levels of metadata generation and meaningful web presentations. In recent years, in addition to an increasing tendency to aggregate metadata and inventory data (e.g.<a href="http://filmportal.de">filmportal.de</a>), it can also be observed that the topic of Linked Open Data is becoming more important. In international working groups (e.g. in the Cataloguing Commission of the FIAF), ontologies for film as well as workflows for the use of identifiers from, for example, Wikidata are being collaboratively developed, and their usage will hopefully gain momentum (see<a href="#heftberger2020">Heftberger and Duchesne [2020]</a>). If  we look at how processes of knowledge transformation in the twenty-first century can take place and how they can be understood by means of computer technology, interpretation must remain an important component of the discipline:</p>
<blockquote>
<p>What the community can do with the results of a digital humanities project is, like art, often outside what a creator or project team might have envisioned for it — and this is where the interpretation becomes important for multivalent digital humanities projects. What does it mean that a database has been structured in a certain way? What are the larger consequences for one design over another? How does a certain project push the boundaries of what we consider acceptable digital humanities work? How can new analytical processes or methodologies be applied in different contexts? These are subjective and interpretative questions that we must openly discuss.<br>
<a class="footnote-ref" href="#gibbs2011"> [gibbs2011] </a></p>
</blockquote>
<p>Institutions can usually identify relatively clearly which tasks are suitable to be supported by software. Typically, subject indexing and visualizing collections online are named by professionals. In addition to these continuous duties, there are a large number of exciting sub-projects that could be worked on in collaboration with scholars and/or artists, and which would offer tremendous added value for both groups. Film collecting institutions bring their knowledge about analog material to the table as well as a comprehensive knowledge of film titles in their holdings, which are not digitally available yet. Their staff can assist with expertise in digitization as well as opening up film collections by viewing and cataloging titles which have not been widely disseminated yet. Thus, they can contribute to broaden a so far narrow view on film history which too many times only focuses on iconic titles and male directors. Even just looking into cast and credit roles and how they changed over the course of time in different languages may change our perspective, for example on the involvement of female editors (see Pearlman and Heftberger 2018). Making more film titles available and connecting resources digitally via sharing metadata and contextual information as well as visualizing their collections is a key task for film archives nowadays. One good example would be the BFI Filmography, which so far is a rare attempt to consider filmographic metadata research data for film historians and film scholars<a class="footnote-ref" href="#pearlman2018"> [pearlman2018] </a>.</p>
<h2 id="2the-computational-perspective-multimedia-information-retrieval">2.The Computational Perspective: Multimedia Information Retrieval</h2>
<p>Film scholars have a long tradition in the qualitative and quantitative analysis of film and more recently video. The automatic and automatically assisted analysis of filmic content has – compared to that – a rather short history. Due to the large amounts of data produced by digitized film and video and the associated high computing costs as well as the initially rare availability of digitized footage, research on automatic film analysis could only slowly establish when first digital media retrieval methods started to develop in the mid 1990s. Since then, we have observed a tremendous development of automatic film and video analysis which was fueled by breakthroughs in machine learning methodology (especially deep learning) as well as in the availability of annotated training data. Today, automatic film and video analysis has achieved a certain level of maturity and — as a result — is applied more and more in the digital humanities. We describe the origins of automatic film analysis in computer science and its rather young history in the following and identify important future challenges for automatic film analysis in the context of the digital humanities.</p>
<p>The research field associated with automatic film analysis is called “Multimedia Information Retrieval” (MMIR). MMIR has originally evolved as a branch of Information Retrieval (IR) (for some early examples see<a href="#mooers1950">Mooers [1950]</a>,<a href="#salton1983">Salton and McGill [1983]</a>,<a href="#vanrijsbergen1997">van Rijsbergen [1997]</a>) and has grown to a broad and independent field of research in recent years. In the last two decades, the amount of available digital media data has increased tremendously. In addition to textual information, image, audio and video data have become omnipresent due to the availability of cheap capturing hardware, the development of efficient compression and transmission techniques and the establishment of large, publicly accessible databases and media platforms on the Internet. Still, the access to these large amounts of multimedia data is rather restricted, as media data are often lacking textual descriptions. Also, it is difficult to derive semantically meaningful information from the content itself, for instance the individual pixels of an image or the samples of an audio signal. </p>
<p>This is exactly where MMIR comes into play. MMIR aims at making sense of the raw media to make the media itself searchable by content<a class="footnote-ref" href="#lew2006"> [lew2006] </a>. Thereby, MMIR makes large media databases instantly searchable. This enables a variety of useful applications, such as finding people and objects in images, retrieving videos that show and explain certain activities, finding unusual events in long-term video sequences, but also retrieving syntactic and semantic concepts from films<a class="footnote-ref" href="#zaharieva2010"> [zaharieva2010] </a>to support qualitative and quantitative studies by film scholars and to open up large-scale film and video corpora for systematic analyses. Research on MMIR goes back to the early 1990s<a class="footnote-ref" href="#grosky1994"> [grosky1994] </a>and has grown so broad today that it has become difficult to oversee the entire field<a class="footnote-ref" href="#pouyanfar2018"> [pouyanfar2018] </a>. The great diversity of media data has led to the development of several MMIR research branches, such as Content-Based Image Retrieval (CBIR), Content-Based Audio Retrieval (CBAR), and Content-Based Video Retrieval (CBVR), which over time have become research areas that can stand for themselves.</p>
<p>Additionally, several cohesive modalities (e.g. video and its corresponding audio track) can be combined in multimodal retrieval approaches to leverage complementary information for more robust retrieval. Multimodal retrieval is often used synonymous with multimedia information retrieval and is also sometimes referred to as “MMIR” in the literature. Multimodal retrieval can be defined as follows: “A multimedia information retrieval (MMIR) problem is multimodal if it includes multiple input modalities, such as images, audio, 3D data, textual and contextual information” <a class="footnote-ref" href="#baltrusaitis2018"> [baltrusaitis2018] </a>. Multimodal retrieval can be considered an overarching branch of MMIR that combines and integrates methodology from different modality-specific branches. In multimodal retrieval, basically arbitrary data sources can be combined as long as they have a certain semantic relationship. Today&rsquo;s approaches toward automatic film and video analysis integrate methodology of all of the above-mentioned branches of MMIR. For this reason, they are briefly introduced in the following.</p>
<h2 id="21-content-based-image-retrieval-cbir">2.1 Content-based image retrieval (CBIR)</h2>
<p>CBIR focuses on the retrieval of images in an image archive or database from a given query, which can be either textual or provided as an example image (query-by-example). The first content-based retrieval systems came up in the 1990s and included systems like QBIC<a class="footnote-ref" href="#flickner1995"> [flickner1995] </a>and VIRAGE<a class="footnote-ref" href="#gupta1997"> [gupta1997] </a>, which were able to query a multimedia database by example images. Aside from finding similar images to a query, typical CBIR problems are the retrieval of objects, concepts and scene properties<a class="footnote-ref" href="#zhao2017"> [zhao2017] </a>as well as image classification<a class="footnote-ref" href="#druzhkov2016"> [druzhkov2016] </a>. CBIR is thus strongly interlinked with the fields of computer vision and machine learning. Research in CBIR focuses on the retrieval of patterns from various types of images, including medical images, remote sensing imagery and user-generated content (e.g. in personal photo collections and in social media). Broad surveys on the field of CBIR are provided by<a href="#datta2008">Datta et al. (2008)</a>and more recently by<a href="#zhou2017">Zhou et al. (2017)</a>. Automatic film analysis makes intensive use of content-based image analysis. Even though the study object are films and videos, many visual analysis problems in film analysis (e.g. object detection in movies<a class="footnote-ref" href="#fluckiger2019"> [fluckiger2019] </a>, visual composition analysis<a class="footnote-ref" href="#mitrovic2001"> [mitrovic2001] </a>and the recognition of shot size and shot type<a class="footnote-ref" href="#zaharieva2010"> [zaharieva2010] </a>) can be performed on individual images without taking the temporal dimension into account.</p>
<h2 id="22-content-based-video-retrieval-cbvr">2.2 Content-based video retrieval (CBVR)</h2>
<p>Closely related to CBIR is Content-Based Video Retrieval (CBVR). Typical problems in CBVR are the retrieval of similar videos to a query as well as temporal segmentation of a video in shots and scenes<a class="footnote-ref" href="#cotsaces2006"> [cotsaces2006] </a>, action and activity recognition<a class="footnote-ref" href="#cheng2015"> [cheng2015] </a>event recognition<a class="footnote-ref" href="#tzelepis2016"> [tzelepis2016] </a>, motion retrieval<a class="footnote-ref" href="#zeppelzauer2011a"> [zeppelzauer2011a] </a>, video summarization<a class="footnote-ref" href="#delmolino2016"> [delmolino2016] </a>and video browsing<a class="footnote-ref" href="#schoffman2010"> [schoffman2010] </a>. Content-based video retrieval integrates many techniques from CBIR and extends them with temporal analysis (e.g. motion analysis or object tracking). As a first step in CBVR, the video stream is usually partitioned into smaller units, such as key frames, shots and scenes<a class="footnote-ref" href="#rui1998"> [rui1998] </a>. Next, information at the frame as well as the shot level are extracted and aggregated for retrieval and classification. Typical types of video data include sports videos, news videos and surveillance videos. Beyond these types of motion images, there is a large corpus of literature on the automatic analysis of movies, documentaries and archive film<a class="footnote-ref" href="#ewerth2009"> [ewerth2009] </a><a class="footnote-ref" href="#zaharieva2010"> [zaharieva2010] </a>, which has developed in parallel to visual research in the digital humanities. A frequent pattern that can be observed from the literature is that a broad range of filmic concepts has been investigated already in the computer science, such as film rhythm, tempo, style and narrative structures<a class="footnote-ref" href="#adams2001"> [adams2001] </a><a class="footnote-ref" href="#adams2002"> [adams2002] </a><a class="footnote-ref" href="#choudhary2019"> [choudhary2019] </a>but with rather simplified definitions of these concepts.</p>
<h2 id="23-content-based-audio-retrieval-cbar">2.3 Content-based audio retrieval (CBAR)</h2>
<p>CBAR has developed similarly to CBIR in the early 1990s. Pioneering work is presented by<a href="#wold1996">Wold et al. (1996)</a>, with their development of an audio retrieval system called “Muscle Fish” that was able to automatically distinguish between different types of sounds (see<a href="#pfeiffer1996">Pfeiffer et al. [1996]</a>). Since then, there has been rapid development in different directions, such as audio segmentation, music information retrieval and environmental sound retrieval. Furthermore, the analysis and recognition of speech, which has developed separately, starting already in the 1950s, can be considered one sub-branch of CBAR<a class="footnote-ref" href="#juang2005"> [juang2005] </a>. Compared to the visual modality, the acoustic modality is under-represented in automatic film analysis. One reason is that the acoustic modality alone is often not sufficient for film analysis. Acoustic information is, however, highly useful when combined with visual information in a multimodal approach<a class="footnote-ref" href="#snoek2005"> [snoek2005] </a>. Information from soundtracks can significantly help to classify film genre, scene types and film style<a class="footnote-ref" href="#choudhary2019"> [choudhary2019] </a>. Furthermore, the analysis of the affective dimension of film requires acoustic and visual clues<a class="footnote-ref" href="#soleymani2009"> [soleymani2009] </a>. Finally, film montage may exhibit correlated patterns between the acoustic and visual track<a class="footnote-ref" href="#zeppelzauer2011b"> [zeppelzauer2011b] </a>.</p>
<h2 id="24-concluding-remarks-on-the-field-of-multimedia-information-retrieval-mmir">2.4 Concluding remarks on the field of multimedia information retrieval (MMIR)</h2>
<p>From the brief review of the field of MMIR, we can observe that a large body of automatic analysis approaches exists that would (at least in theory) be applicable to filmic content investigated by film scholars. Especially in the early years of MMIR, however, these methods were not powerful enough to model the complex semantic concepts investigated by film scholars. Today, automatic visual (and audio-visual) analysis is well advanced. Developments in machine learning and especially in deep learning in the last decade have made significant progress in the extraction of information from audio-visual media and in modeling semantic relationships. Certain problems which appeared unsolvable 15 years ago can now be solved automatically with almost human-level performance<a class="footnote-ref" href="#he2015"> [he2015] </a>. This has therefore changed the situation for the digital humanities fundamentally. MMIR has reached a level of maturity that can provide a real added value for film scholars and the digital humanities in general. Many previously unanswered research questions from film scholars are waiting to be (re)investigated by the support of automatic film and video analysis methods.</p>
<h2 id="3-the-media-perspective-digital-encounters-in-film-and-media-studies">3. The Media Perspective: Digital Encounters in Film and Media Studies</h2>
<p>Recapitulating the history of digital tools, methods and practices within film and media studies is a particularly challenging task. Wherever the field has dealt with this topic, reflections on the status of digital tools and technologies have often superseded their use as a facilitator of research. The reason for this situation is as simple as it is convincing: it is the very insight that “the medium is the message” <a class="footnote-ref" href="#mcluhan1964"> [mcluhan1964] </a>. Hence, we should not just consider technology a tool, a means to an end that lies at the heart, at least of media studies.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> The decision, however, to make technology, and thus digital media, a research object of epistemological, cultural and sociological enquiry itself has also another consequence. It creates awareness about the fact that common narratives about the purpose of a certain piece of technology and actual usages of the same technology can be two very different things. It therefore sensitizes to alleged misusages of technologies. These misusages often exist in the margins of those approaches that are propagated by certain tool ideologies and instigate their own techno-social configurations. The histories of digital tool usage in film and media studies are thus entangled with different perspectives on the contingent nature of digital technologies and different understandings of scholarly engagement.</p>
<h2 id="31-notions-of-the-digital-and-digital-methodologies">3.1 Notions of the digital and digital methodologies</h2>
<p>Using the plural form in histories is more than just acknowledging the democratic attitude that writing history enforces. It is a reaction to the fact that it even lacks an agreement about the same temporal dimension when researchers of the field try to systematize the history of the use of digital technologies in film and media studies. In Germany, for instance,<a href="#sittel2017">Julian Sittel (2017)</a>states that film studies lags behind when it comes to the adoption of digital humanities methods, while<a href="#vonderau2017">Patrick Vonderau (2017)</a>suggests that digital humanities is the continuity of a certain way to use digital technologies that has long been superseded by other usage types. This claim is illustrated by an analysis of the use of digital technologies in film and media studies that distinguishes three consecutive phases between 1985 and 2005: The first phase produced tools to manually annotate and segment movies. The second phase introduced database-driven quantification of annotated and classified units in moving images. The third phase gives testimony of a repurposing of the goal of databases themselves. They now shift from facilitating statistical analysis to becoming a metaphor and facilitator for the situational and explorative organization of content of any kind in research in the logic of the collage. Databases are more conceived of as an expression of an abstract notion of media practice instead of just being a tool to query and count<a class="footnote-ref" href="#bohme2012"> [bohme2012] </a>.</p>
<p>In Vonderau&rsquo;s perspective, digital humanities is just an attempt to perfect narrow use of digital technology that was predominant in the second phase. It lacks a broad theoretical framing for digital transformation and technology as such and thus misses new emerging paradigms of technology use. In Sittel&rsquo;s line of argument, however, digital humanities are the clear sign of a more fundamental shift; a shift that reconfigures the entanglement between theory, technology and research – with respect to the first paragraph the media/message relationship – itself and that, accordingly, cannot be integrated into film and media studies appropriately. Claims such as those about “the end of theory” <a class="footnote-ref" href="#anderson2008"> [anderson2008] </a>or the “fourth paradigm” <a class="footnote-ref" href="#hey2009"> [hey2009] </a>come to mind here. In summary, different notions of technology instigate different historical narratives as well as different methodological portfolios and needs. Each of these configurations are, furthermore, linked to struggles for disciplinary autonomy but also to debates about the internal structure of the field itself. This is most obvious when Vonderau declares that actually the main object of film studies – the analysis of movies – mostly disappeared in film studies with the arrival of digital technologies, while<a href="#chavez-heras2012">Chavéz-Heras (2012)</a>announces that now, with digital tools, film analysis is reborn.</p>
<p>Such media-reflexive preoccupations have caused a lot of alienation between film and media studies on the one hand and digital humanities on the other.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> It would, however, be misleading if digital humanities just considered it an internal issue of film and media studies. In fact, the digital humanities have cultivated their own version of the above-mentioned tension, a tension that recently created a schism within in the field itself. Since 2014, concepts such as the post-digital humanities<a class="footnote-ref" href="#berry2014"> [berry2014] </a>or the critical digital humanities<a class="footnote-ref" href="#grimshaw2018"> [grimshaw2018] </a><a class="footnote-ref" href="#dobson2019"> [dobson2019] </a>emerged within debates on digital humanities. The former relates to the methodological inconsistencies behind the term digital methods, while the latter stresses cultural conditions and impacts of algorithmic meaning making processes. In opposition to these branches, in 2019, the computational humanities research community spun off the field of digital humanities, preceeded by debates that digital humanities had lost its core – humanities computing – and that rathertechietopics are not sufficiently represented<a class="footnote-ref" href="#elwert2019"> [elwert2019] </a>.</p>
<h2 id="32-entanglements-with-the-digital-and-post-digital-humanities">3.2 Entanglements with the Digital and Post-Digital Humanities</h2>
<p>This example is just the entertaining expression of an open space of entanglements between digital technologies and doing research. In film and media studies these include approaches such asartistic research<a class="footnote-ref" href="#ruszev2018"> [ruszev2018] </a>,speculative computing<a class="footnote-ref" href="#drucker2009"> [drucker2009] </a>,statistics and stylometry<a class="footnote-ref" href="#casey2014"> [casey2014] </a><a class="footnote-ref" href="#baxter2017"> [baxter2017] </a>,digital surrealism<a class="footnote-ref" href="#ferguson2015"> [ferguson2015] </a><a class="footnote-ref" href="#ferguson2017"> [ferguson2017] </a>, ormultimodal storytellingandvideographic criticism<a class="footnote-ref" href="#erlend2012"> [erlend2012] </a><a class="footnote-ref" href="#keathley2019"> [keathley2019] </a>. The case of videographic criticism or thevideo-essay, as it is sometimes called, is especially interesting because it demonstrates how an object of research becomes the means of analysis itself. It investigates movies by producing short movies and follows the media reflexive idea that it might be best to represent facts of a certain modality within that same modality. Although not computational in a strict digital humanities sense, the video essay clearly is interpreted as a product of digital technologies and an established method of film studies research<a class="footnote-ref" href="#mcwhirter2015"> [mcwhirter2015] </a>. Together with the above-mentioned dispute about the obsolescence or the revival of the analysis of movies, the whole episode demonstrates very well that questions raised by digital technologies are not just questions of new methods, and even less questions of computational or statistical methods. They are, with similar importance, questions about the changing status of research objects within a changing, partially digital, environment. Accordingly, the challenge is not just to define better or new methods, but also to develop a new sense of research objects and research ecologies – all at the same time.</p>
<p>With this in mind, it is necessary to critically re-approach the notion that film and media studies lag behind. The holistic angle on digital research that not only considers new methods for known objects but also new cultural embeddings for known as well as unknown objects, suggests another kind of endeavor. In this respect it is a meaningful observation that in the history of digital humanities, fields with clearly definable and established research entities – the edition, the textual source and the artifact among others – were the most influential. It goes without saying that the analysis of our partially digital environment and its objects enforces to also apply digital humanities methods in a stricter sense of the term and cannot be carried out comprehensively without them. In consequence, film and media studies researchers that might not have welcomed these methods, due to methodological reasons, in the first place are, nevertheless, beginning to open up as has been mentioned before. The challenge, both for the digital humanities and for film and media studies, remains to integrate perspectives of method, object and ecology without creating a hierarchy among them; be it methods for the digital humanities or objects and ecology for film and media studies.</p>
<p>It was a striking feature of Vonderau’s periodization that it ended around 2005, which is more or less the same time in which the digital humanities began to aspire. Both histories, the one that ended in the article&rsquo;s narrative and the one that started with a companion, were motivated by the intent to separate one research field from the other. The first history tried to show that the newly emerging DH was in some sense always already part of the established field of film and media studies. The second history presupposes that only by creating a new field, the old will actually become the new. Comparing the history of digital humanities methods in film and media studies with the history of film and media studies topics in the digital humanities clearly shows that both lines of arguments get it wrong, because in the growing number of encounters between film and media studies and digital humanities, a new reality emerges that is both post-humanistic and post-digital<a class="footnote-ref" href="#cramer2014"> [cramer2014] </a>.</p>
<p>Certainly, film and media studies have to engage more profoundly with the methodological part of statistical and algorithmic approaches. This has slowly begun to happen throughout the last years, as projects such as the large-scale video analytics project<a class="footnote-ref" href="#kuhn2015"> [kuhn2015] </a>, activities of the scientific networks Digital Cinema Studies<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> or New Directions in Film Historiography<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> or projects like FilmColors<a class="footnote-ref" href="#fluckiger2017"> [fluckiger2017] </a>and Kinepoetics<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> suggest. At the same time, it appears to be equally important for the digital humanities to reflect on their rather broad conception of technology, in order to continue to make substantial contributions to the reconfiguration of research by digital technologies. A fuzzy reference to the “big tent” <a class="footnote-ref" href="#terras2013"> [terras2013] </a>or the “big humanities” <a class="footnote-ref" href="#svensson2016"> [svensson2016] </a>will not suffice in this respect.</p>
<h2 id="4-toward-an-integrated-perspective-digital-film-studies-and-digital-humanities">4. Toward an Integrated Perspective: Digital Film Studies and Digital Humanities</h2>
<p>In this section we bring together the individual disciplinary perspectives on digital film studies in an integrated perspective within the digital humanities. The three disciplinary perspectives of (1) GLAMs and archives, (2) computer science, and (3) film and media studies align very well with the three sub-areas of Digital Humanities as identified by<a href="#roth2019">Roth (2019)</a>: the digitized humanities, the numerical humanities and humanities of the digital. In the following, we illustrate the different variants of digital film studies with respect to the three sub-areas of digital humanities by means of concrete examples. We also use this basic classification to introduce the eight research projects and studies that are part of this special issue.</p>
<h2 id="41-digitized-humanities">4.1 Digitized humanities</h2>
<p>This branch of DH is mostly concerned with the digitization of cultural artifacts. This also includes the modeling of analog artifacts, i.e. the formal representation of a cultural object. This formalization is an important prerequisite for digital preservation and dissemination strategies, but also for computational analyses of the material. For the formal representation of film, the fundamental question is: how can we model a time-based and multimodal medium such as film to be represented in discrete categories? As this is obviously a demanding and complex task, it is important for scholars to be clear in advance – i.e. before the actual modeling – about what they want to investigate: Are setting and scene boundaries relevant for later analyses? Are they interested in constellations of characters or the use of leitmotifs? Or do they want to take a closer look at the dialog level? Due to the modeling effort involved, it is hardly possible in practice to model everything pro forma, so a prior research question is indispensable for the digitization and modeling of film and video.</p>
<p>As a consequence, it is rather challenging to create film and video resources that can be reused by a variety of scholars, as the research questions (and modeling implications, cf.<a href="#unsworth2002">Unsworth [2002]</a>) vary widely and as there are hardly any established annotation standards as known for other types of media, for instance the <em>Text Encoding Initiative</em> (TEI) or the <em>Music Encoding Initiative</em> (MEI).<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Further challenges are raised by born digital videos, for example YouTube videos or Twitch.tv streams, as specific concepts for offline storage and potential long-term preservation are needed that lead to open copyright issues and new requirements for digital infrastructure. In this special issue, Eva Hielscher contributes to the topic of modeling and representing films by presenting an extensive case study on video annotation for a corpus ofCity Symphoniesin her article titled “The Phenomenon of Interwar City Symphonies: A Combined Methodology of Digital Tools and Traditional Film Analysis Methods to Study Visual Motifs and Structural Patterns of Experimental-Documentary City Films” .<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> Another article in this special issue is on “Matching Computational Analysis and Human Experience. Performative Arts and the Digital Humanities” .<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> Here, Jan-Hendrik Bakels et al. investigate the combination and mediation of experience-based and data-driven analytical procedures in film studies. They transfer common film analytical vocabulary into a machine-readable ontology to set up a systematic annotation routine for films that can be visualized and queried.</p>
<p>Digitization of films and videos is also important for film heritage institutions, as it helps to collect filmographic information from diverse sources by means of specialized search functions, OCR or image recognition among others. This can also support digital archives withminingtheir objects, for example finding certain subjects/topics/people etc. Therefore, archives are excellent agents for advancing the standardization of filmographic metadata, for instance by benefitting from experiences with metadata standards such as EN 15907 (see<a href="#heftberger2014">Heftberger [2014]: 143</a>). Another key task here is the presentation of collections (or parts thereof) online in an appealing, sensible and effective way. Institutions are fully aware that building good interfaces is critical, but there seem to be many obstacles still in their way. Insufficient financial resources might be one of those obstacles, being stuck in building traditional entry points to collections may be another one. Masson et al. provide a deep and comprehensive discussion of traditional and new paradigms in this area in their article titled “Exploring Digitised Moving Image Collections: The SEMIA Project, Visual Analysis and the Turn to Abstraction” .<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> Additionally, they are able to substantiate this discussion by introducing the SEMIA platform, a convincing example for how adequate interfaces might be designed.</p>
<p>In the past film archives, for the most part, differentiated between technical expertise and work with content. However, a greater permeability between the areas of responsibility is required in the future in order to comply with the abovementioned challenges. It is already the case that many tasks are no longer addressable by traditional roles. Digital data management, for instance, cannot be restricted to just one area of material (e.g. films, photos or documents) and metadata must be managed across the boundaries of collections in order to use technical infrastructures and personnel resources in the best possible way among other reasons. The strategy must therefore be twofold in the future: Teaming up with researchers and artists as well as staffing their places with technically savvy people who at the same time understand archival objects and are interested in exhibition. Digital humanities as digitized humanities have organized around such entanglements for years and may, therefor, provide valuable points of reference for the field of digital film studies.</p>
<h2 id="42-numerical-humanities">4.2 Numerical humanities</h2>
<p>This second category is oftentimes also referred to ascomputational humanities, highlighting the aspect of empirical analyses by means of statistical procedures and machine learning techniques. In recent years, we have seen a gradual extension of the established formal-stylistic analyses<a class="footnote-ref" href="#salt1974"> [salt1974] </a><a class="footnote-ref" href="#tsivian2009"> [tsivian2009] </a>, which mostly relied on the lengths and frequencies of shots within a movie. Going well “beyond shot lengths” <a class="footnote-ref" href="#burghardt2016"> [burghardt2016] </a>, a whole series of studies have been carried out recently, for example to examine the color dimension<a class="footnote-ref" href="#burghardt2017"> [burghardt2017] </a><a class="footnote-ref" href="#fluckiger2017"> [fluckiger2017] </a><a class="footnote-ref" href="#pause2018"> [pause2018] </a><a class="footnote-ref" href="#pause"> [pause] </a>or the dialogs of films<a class="footnote-ref" href="#bednarek2018"> [bednarek2018] </a><a class="footnote-ref" href="#holobut2016"> [holobut2016] </a>. Another branch of work in this category can be found in the area of visual analytics<a class="footnote-ref" href="#burghardt2018"> [burghardt2018] </a><a class="footnote-ref" href="#hoyt2014"> [hoyt2014] </a><a class="footnote-ref" href="#kurzhals2016"> [kurzhals2016] </a>, as visualizations can greatly facilitate the analysis of visual time-based media such as film and video<a class="footnote-ref" href="#manovich2013"> [manovich2013] </a>.</p>
<p>This special issue features two numerical humanities studies that investigate the textual dimension of series and movies. In their article on “The Stylometry of Film Dialogue: Pros and Pitfalls” ,<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> Agata Hołobut and Jan Rybicki analyze 300 film dialogs by means of stylometry and sentiment analysis to detect patterns of similarity and difference between screenwriters and/or a priori IMDB-defined genres. Joanna Byszuk goes in a similar direction with her article called “The Voices of Doctor Who – How Stylometry Can be Useful in Revealing New Information About TV Series” .<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> More concretely, she uses stylometry to examine the changes driving the development of the &ldquo;Doctor Who&rdquo; series from a character-oriented to a showrunner-oriented series.</p>
<p>As part of the numerical humanities, deep learning approaches are also increasingly being used in the sense of “deep watching” <a class="footnote-ref" href="#howanitz2019"> [howanitz2019] </a>or “distant viewing” <a class="footnote-ref" href="#arnold2019"> [arnold2019] </a>, in order to automatically segment films and identify objects or people. In this special issue, Barbara Flückiger and Gaudenz Halter contribute an article on “Methods and Advanced Tools for the Analysis of Film Colors in Digital Humanities” ,<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> which provides an excellent example for numerical humanities, showcasing a sophisticated deep learning approach to investigate color usage in film. Another deep learning example is provided in the article “Automated Visual Content Analysis for Film Studies: Current Status and Challenges” ,<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> by Ralph Ewerth et al. The authors provide a thorough survey of approaches and tools for automated video analysis to support quantitative and qualitative analysis in film studies.</p>
<p>For digital film studies, the digital humanities as numerical humanities mostly represent methods that try to automate the identification of established entities and units within film studies research. By doing so, they mimic analytical methods of the field, but on a much larger scale than would be possible by means of qualitative analyses of – typically – just a few films. In recent time, however, there are also new approaches that aim at a semi-automatic and, thus, more interactive analysis which seem to prioritize exploration instead of extraction. This re-evaluation of priorities may well open-up the perspective for contributions to a more diverse understanding of numerical and computational approaches to the study of films.</p>
<h2 id="43-humanities-of-the-digital">4.3 Humanities of the digital</h2>
<p>This category describes humanities scholars’ broader interest for the inclusion of phenomena that emerge from thedigital culture.In the field of film studies, this might, for instance, entail the abovementioned investigation of born digital videos, which very often also brings with it a dimension of mass communication and thus big data: either, because a multitude of videos are available, or because there is additional mass communication channel available, e.g. in the form of comments about a video (reception aesthetics). It also includes an examination of digital aesthetics as well as of new forms of production and reception in an increasingly digitized, post-cinema film culture. Such changes inevitably raise theoretical questions that, at the same time, are necessarily linked to new research practices. Due to the sheer volume of digitally available material, a serious opening of the humanities towards digital culture obviously requires an increased integration of digital methods into scholarly practices as well.</p>
<p>From the perspective of film studies, the central challenge humanities of the digital imposes, is the need for a holistic instead of a pragmatic integration of digital methods, not the least because these methods have become methods of production and analysis (film essay) at the same time. A central task in this context is to reflect on the changing relationship between research instrument and research subject, to bring together quantitative and qualitative methods, to find ways to mediate between metrization and interpretation. It is important to demonstrate that approaches of data-driven research can be particularly productive in the field of film and media studies when they are conceived of as tools within the framework of a diverse practice (cf.<a href="#antonijevic2015">Antonijevic [2015]</a>) or mixed methods<a class="footnote-ref" href="#pereira2019"> [pereira2019] </a>. In this setup, digital methods are part of a practice, but not its overarching theme. One example for such a more praxeologically oriented approach to the integration of digital methods in film studies has been recently systematized under the termscalable viewing<a class="footnote-ref" href="#burghardt2018"> [burghardt2018] </a><a class="footnote-ref" href="#pause2020"> [pause2020] </a>.</p>
<p>In this context, theHumanities of the Digitalprovide theoretical foundations for new notions of the digital that have the potential to make digital methods more accessible for film studies research. Such notions root deeper in the tradition of the humanities, while at the same time highlighting the necessity and added value of algorithmic strategies. In this special issue, Sarah-Mai Dang contributes to this third sub-field of digital humanities by presenting an article on “Unknowable Facts and Digital Databases: Reflections on the Women Film Pioneers Project and Women in Film History” .<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> More concretely, she discusses the epistemological function and the scholarly implications of databases in film and media studies.</p>
<h2 id="5-conclusions">5. Conclusions</h2>
<p>The challenges that have been outlined throughout the entire editorial call for a joint interdisciplinary effort of computer scientists, film studies scholars and archivists and represent an exciting research agenda for the coming years. While it seems to be the case that each of the digital humanities sub-areas gravitates around one particular discipline – namelydigitizationwith GLAM,numericalwith computer science anddigitalwith film and media studies – it would be dangerous to just equate them with each other. Tools that are used for video criticism often build upon the same statistical and machine learning methods that are used in the numerical humanities, and without doubt, both GLAM and computer science are evaluating the broad field of new research objects in digital media. The horizon, however, that is particularly addressed by the digital humanities, is one in which one discipline is not just informed by the others but in which each discipline contributes on all levels to a shared space of insights, developments and practices.</p>
<p>The FilmColors<a class="footnote-ref" href="#fluckiger2017"> [fluckiger2017] </a>project, for example, started from the insight, that approaches for the extraction of dominant colors, common in computer science have significant drawbacks. Based on this insight, the project defined a new approach that makes use of cultural concepts about how spectators process the kinematic image. It, however, did not just provide these insights to computer scientists, it also implemented a new machine learning pipeline for colorimetric analysis that is immediately available to the field of computer science for further optimization. The project, moreover, introduced innovations to the presentation of colorimetric information on the user interface level that are certainly inspiring for the aforementioned issues in the GLAM sector. It is precisely these overlaps out of which film and moving image analysis inside the umbrella of digital humanities might emerge as a field of its own.</p>
<ul>
<li id="adams2001">Adams, B., Dorai, C., and Venkatesh, S. “Automated film rhythm extraction for scene analysis.”  _ICME 2001: Proceedings of the IEEE International Conference on Multimedia and Expo_ (2001): 1056-1059.
</li>
<li id="adams2002">Adams, B., Dorai, C., and Venkatesh, S. “Formulating Film Tempo. The Computational Media Aesthetics Methodology in Practice.” In C Dorai and S Venkatesh (eds.),  _Media Computing: Computational Media Aesthetics_ . Kluwer Academic Publishers, Norwell, MA (2002): 57-84.
</li>
<li id="atkins2003">Atkins, D. “Revolutionizing Science and Engineering through Cyberinfrastructure. Report of the National Science Foundation Blue-Ribbon Advisory Panel on Cyberinfrastructure,” US National Science Foundation (2003). [<a href="http://www.nsf.gov/cise/sci/reports/atkins.pdf">http://www.nsf.gov/cise/sci/reports/atkins.pdf</a>]
</li>
<li id="anderson2008">Anderson, C. “The End of Theory: The Data Deluge Makes the Scientific Method Obsolete.”  _Wired_ 16.7 (2008).
</li>
<li id="antonijevic2015">Antonijevic, S. _Amongst Digital Humanists. An ethnographic study of digital knowledge production_ . Palgrave Macmillan, London (2015).
</li>
<li id="arden2007">Arden, L. “Cyberinfrastructure Vision for 21st Century Discovery.” National Science Foundation. US National Science Foundation (2007). [<a href="https://www.nsf.gov/pubs/2007/nsf0728/nsf0728.pdf">https://www.nsf.gov/pubs/2007/nsf0728/nsf0728.pdf</a>]
</li>
<li id="arnold2019">Arnold, T. and Tilton, L. “Distant Viewing: Analyzing Large Visual Corpora.”  _Digital Scholarship in the Humanities_ (2019).
</li>
<li id="baltrusaitis2018">Baltrusaitis, T., Ahuja, C., and Morency, L.-P. “Multimodal machine learning: A survey and taxonomy.”  _IEEE Transactions on Pattern Analysis & Machine Intelligence_ 41.2 (2018): 423-443.
</li>
<li id="baxter2017">Baxter, M., Khitrova, D., and Tsivian, Y. “Exploring Cutting Structure in Film, with Applications to the Films of D. W. Griffith, Mack Sennett, and Charlie Chaplin.”  _Digital Scholarship in the Humanities_ 32.1 (2017).
</li>
<li id="bednarek2018">Bednarek, M. _Language and Television Series: A Linguistic Approach to TV Dialogue_ . Cambridge University Press, Cambridge (2018).
</li>
<li id="berry2014">Berry, D. M. “Post-Digital Humanities: Computation and Cultural Critique in the Arts and Humanities.”  _Educause_ 49.3 (2014): 22-26. [<a href="http://www.educause.edu/">http://www.educause.edu</a>].
</li>
<li id="bohme2012">Böhme, S., Nohr, R. F., and Wiemer, S. _Sortieren, Sammeln, Suchen, Spielen. Die Datenbank als mediale Praxis_ . LIT Verlag, Münster (2012).
</li>
<li id="burghardt2016">Burghardt, M., Kao, M., and Wolff, C. “Beyond Shot Lengths. Using Language Data and Color Information as Additional Parameters for Quantitative Movie Analysis.”  _Book of Abstracts of the International Digital Humanities Conference (DH)_ (2016).
</li>
<li id="burghardt2017">Burghardt, M., Hafner, K., Edel, L., Kenaan, S., and Wolff, C. “An Information System for the Analysis of Color Distributions in MovieBarcodes.” Proceedings of the 15th International Symposium of Information Science (ISI) (2017).
</li>
<li id="burghardt2018">Burghardt, M., Kao, M., and Walkowski, N.-O. “Scalable MovieBarcodes. An Exploratory Interface for the Analysis of Movies.”  _IEEE Vis4DH Workshop_ (2018).
</li>
<li id="casey2014">Casey, M., and Williams, M. “ACTION (Audio-Visual Cinematic Toolbox for Interaction, Organization, and Navigation): An Open-Source Python Platform.” White Paper HD-51394-11 (2014). [<a href="https://securegrants.neh.gov/publicquery/main.aspx?f=1&gn=HD-51394-11">https://securegrants.neh.gov/publicquery/main.aspx?f=1&gn=HD-51394-11</a>].
</li>
<li id="chavez-heras2012">Chávez-Heras, D. “The Malleable Computer: Software and the Study of the Moving Image.”  _Frames Cinema Journal_ 1.1 (2012). [<a href="https://framescinemajournal.com/article/the-malleable-computer/">https://framescinemajournal.com/article/the-malleable-computer/</a>].
</li>
<li id="cheng2015">Cheng, G., Wan, Y., Saudagar, A. N., Namuduri, K., and Buckles, B. P. “Advances in human action recognition: A survey.” arXiv preprint, arXiv:1501.05964 (2015).
</li>
<li id="choudhary2019">Choudhary, P., Goel, N., and Saini, M. “A Multimedia Based Movie Style Model.”  _IEEE International Conference on Multimedia & Expo Workshops (ICMEW)_ (2019): 72-77. 
</li>
<li id="cotsaces2006">Cotsaces, C., Nikolaidis, N., and Pitas, I. “Video shot detection and condensed representation. A review.”  _IEEE Signal Processing Magazine_ 23.2 (2006): 28-37.
</li>
<li id="cramer2014">Cramer, F. “What Is Post-Digital ?.”  _A Peer-Reviewed Journal About Post Digital Research_ (2014). [<a href="https://aprja.net/article/view/116068">https://aprja.net/article/view/116068</a>]
</li>
<li id="datta2008">Datta, R., Joshi, D., Li, J., and Wang, J. Z. “Image retrieval: Ideas, influences, and trends of the new age.”  _ACM Computing Surveys (CSUR)_ 40.2 (2008): 5.
</li>
<li id="delmolino2016">Del Molino, A. G., Tan, C., Lim, J.-H., and Tan, A.-H. “Summarization of egocentric videos: A comprehensive survey.”  _IEEE Transactions on Human-Machine Systems_ 47.1 (2016): 65-76.
</li>
<li id="dobson2019">Dobson, J. _Critical Digital Humanities: The Search for a Methodology_ . University of Illinois Press, Urbana (2019). [<a href="https://www.jstor.org/stable/10.5406/j.ctvfjd0mf">https://www.jstor.org/stable/10.5406/j.ctvfjd0mf</a>].
</li>
<li id="drucker2009">Drucker, J. _SpecLab: Digital Aesthetics and Projects in Speculative Computing_ . University of Chicago Press, Chicago (2009).
</li>
<li id="druzhkov2016">Druzhkov, P. and Kustikova, V. “A survey of deep learning methods and software tools for image classification and object detection.”  _Pattern Recognition and Image Analysis_ 26.1 (2016): 9-15.
</li>
<li id="elwert2019">Elwert, F. “The Sudden but Consequential Rise of the Computational Humanities. Billet.”  _A Belter's Life_ (Blog) (2019). [<a href="https://belter.hypotheses.org/64">https://belter.hypotheses.org/64</a>].
</li>
<li id="erlend2012">Erlend, L. “The Video Essay: The Future of Academic Film and Television Criticism?”  _Frames Cinema Journal_ 1 (2012). [<a href="https://framescinemajournal.com/article/the-video-essay-the-future/">https://framescinemajournal.com/article/the-video-essay-the-future/</a>]
</li>
<li id="ewerth2009">Ewerth, R., Mühling, M., Stadelmann, T., Gllavata, J., Grauer, M., and Freisleben, B. “Videana: a software toolkit for scientific film studies.” In M. Ross, M. Grauer, B. Freisleben (eds.),  _Digital Tools in Media Studies. Analysis and Research. An Overview_ . Transcript, Bielefeld (2009): 101–116.
</li>
<li id="ferguson2015">Ferguson, K. L. “Volumetric Cinema.”  _Transition: Journal of Videographic Film and Moving Image Studies_ 2 (2015).
</li>
<li id="ferguson2017">Ferguson, K. L. “Digital Surrealism: Visualizing Walt Disney Animation Studios.”  _Digital Humanities Quarterly_ 11.1 (2017). [<a href="http://www.digitalhumanities.org/dhq/vol/11/1/000276/000276.html">http://www.digitalhumanities.org/dhq/vol/11/1/000276/000276.html</a>].
</li>
<li id="flanders2012">Flanders, J. “Time, Labor, and Alternate Careers. ” In M. K. Gold (ed.), _Digital Humanities Knowledge Work. Debates in the Digital Humanities_ . University of Minnesota Press, Minneapolis (2012): 292-308.
</li>
<li id="flickner1995">Flickner, M., Sawhney, H., Niblack, W., Ashley, J., Qian Huang, Dom, B., Gorkani, M., Hafner, J., Lee, D., Petkovic, D., Steele, D., and Yanker, P. “Query by image and video content: The QBIC system.”  _Computer_ 28.9 (1995): 23-32.
</li>
<li id="fluckiger2017">Flückiger, B. “A Digital Humanities Approach to Film Colors.”  _The Moving Image: The Journal of the Association of Moving Image Archivists_ 17.2 (2017): 71-94.
</li>
<li id="fluckiger2019">Flückiger, B. “Cinematic worlds in color. Technology, aesthetics, analysis.” In _BITForum. Film techniques and technology: illusion, reality, virtuality, innovation_ . Busan, South Korea (2019): 11-39.
</li>
<li id="gibbs2011">Gibbs, F. “Critical Discourse in the Digital Humanities.”  _Journal of Digital Humanities_ 1.1 (2011)
</li>
<li id="grant2012">Grant, C. “Film and moving image studies: Re-born digital? Some participant observations.”   _Frames Cinema Journal_ 1.1 (2012).
</li>
<li id="grimshaw2018">Grimshaw, M. “Towards a Manifesto for a Critical Digital Humanities: Critiquing the Extractive Capitalism of Digital Society.”  _Palgrave Communications_ 4.1 (2018): 1-8.
</li>
<li id="grosky1994">Grosky, W. I. “Multimedia information systems.”  _IEEE Multimedia_ 1.1 (1994): 12-24.
</li>
<li id="gupta1997">Gupta, A. and Jain, R. “Visual information retrieval.”  _Communications of the ACM_ 40.5 (1997): 70-79.
</li>
<li id="he2015">He, K., Zhang, X., Ren, S., and Sun, J. “Delving deep into rectifiers: Surpassing human-level performance on imagenet classification.”  _Proceedings of the IEEE International Conference on Computer Vision_ (2015): 1026-1034.
</li>
<li id="heftberger2014">Heftberger, A. “Film archives and digital humanities - an impossible match? New job descriptions and the challenges of the digital era.”  _MedieKultur: Journal of media and communication research_ 30.57 (2014): 135-153 [<a href="http://ojs.statsbiblioteket.dk/index.php/mediekultur/issue/view/2200">http://ojs.statsbiblioteket.dk/index.php/mediekultur/issue/view/2200</a><a href="https://tidsskrift.dk/mediekultur/article/view/16487/17534">https://tidsskrift.dk/mediekultur/article/view/16487/17534</a>].
</li>
<li id="heftberger2018a">Heftberger, A. _Digital Humanities and Film Studies: Visualising Dziga Vertov's Work_ . Springer International Publishing, Cham (2018).
</li>
<li id="heftberger2018b">Heftberger, A. “The Current Landscape of Film Archiving and How Study Programs can Contribute.”  _SYNOPTIQUE - An Online Journal of Film and Moving Image Studies_ , Special Issue. _The Current Landscape of Film Archiving and How Study Programs can Contribute_ 6.1 (2018): 58-69. [<a href="http://synoptique.ca/wp-content/uploads/2018/07/9-adelheid-heftberger-the-current-landscape-of-film-archiving-and-how-study-programs-can-contribute.pdf">http://synoptique.ca/wp-content/uploads/2018/07/9-adelheid-heftberger-the-current-landscape-of-film-archiving-and-how-study-programs-can-contribute.pdf</a>]
</li>
<li id="heftberger2020">Heftberger, A. and Duchesne, P. “Cataloguing Practices in the Age of Linked Open Data: Wikidata and Wikibase for Film Archives.” International Federation of Film Archives, Brussels, Belgium (2020). [<a href="https://www.fiafnet.org/pages/E-Resources/Cataloguing-Practices-Linked-Open-Data.html">https://www.fiafnet.org/pages/E-Resources/Cataloguing-Practices-Linked-Open-Data.html</a>]
</li>
<li id="hey2009">Hey, T., Tansley, S., and Tolle, K. _The Fourth Paradigm: Data-Intensive Scientific Discovery_ . Microsoft Research, Redmond (2009).
</li>
<li id="holobut2016">Hołobut, A., Rybicki, J., and Woźniak, M. “Stylometry on the Silver Screen: Authorial and Translatorial Signals in Film Dialogue.”  _Book of Abstracts of the International Digital Humanities Conference (DH)_ (2016).
</li>
<li id="howanitz2019">Howanitz, G., Bermeitinger, B., Radisch, E., Sebastian G., Rehbein, M., and Handschuh, S. “Deep Watching - Towards New Methods of Analyzing Visual Media in Cultural Studies.”  _Book of Abstracts of the International Digital Humanities Conference (DH)_ (2019).
</li>
<li id="hoyt2014">Hoyt, E., Ponot, K., and Roy, C. “Visualizing and Analyzing the Hollywood Screenplay with ScripThreads.”  _Digital Humanities Quarterly_ 8.4 (2014). [<a href="http://www.digitalhumanities.org/dhq/vol/8/4/000190/000190.html">http://www.digitalhumanities.org/dhq/vol/8/4/000190/000190.html</a>] 
</li>
<li id="juang2005">Juang, B.-H. and Rabiner, L. R. “Automatic speech recognition - a brief history of the technology development.” Technical report. Georgia Institute of Technology, Atlanta Rutgers University and the University of California, Santa Barbara (2005).
</li>
<li id="keathley2019">Keathley, C., Mittell, J., Grant, C., Faden, E. and Lee, K.B. _The Videographic Essay: Criticism in Sound & Image_ . Caboose Books, Montréal (2019).
</li>
<li id="kuhn2015">Kuhn, V., Craig, A., Simeone, M., Satheesan, S. P., and Marini, L. “The VAT: Enhanced Video Analysis.”  _Proceedings of the 2015 XSEDE Conference on Scientific Advancements Enabled by Enhanced Cyberinfrastructure - XSEDE '15_ . Louis, Missouri (2015): 1-4.
</li>
<li id="kurzhals2016">Kurzhals, K., John, M., Heimerl, F., Kuznecov, P., and Weiskopf, D. “Visual Movie Analytics.”  _IEEE Transactions on Multimedia_ 18.11 (2016).
</li>
<li id="lew2006">Lew, M. S., Sebe, N., Djeraba, C., and Jain, R. “Content-based multimedia information retrieval: State of the art and challenges.”  _ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)_ 2.1 (2006): 1-19.
</li>
<li id="manovich2013">Manovich, L. “Visualizing Vertov.”  _Russian Journal of Communication_ 5.1 (2013): 44-55.  
</li>
<li id="mcluhan1964">McLuhan, M. _Understanding Media. The Extensions of Man_ . 1st ed. McGraw-Hill, New York (1964).
</li>
<li id="mcwhirter2015">McWhirter, A. “Film Criticism, Film Scholarship and the Video Essay.”  _Screen_ 56.3 (2015): 369-377.
</li>
<li id="mitrovic2001">Mitrovic, D., Zeppelzauer, M., Zaharieva, M., and Breiteneder, C. “Retrieval of Visual Composition in Film.”  _Proceedings of the 12th International Workshop on Image Analysis for Multimedia Interactive Services_ . Delft (2001).
</li>
<li id="mooers2007">Mooers, C. N. “The theory of digital handling of non-numerical information and its implications to machine economics.”  _Proceedings of the Association for Computing Machinery Conference_ . National Science Foundation (2007).  <a href="http://www.nsf.gov/pubs/2007/nsf0728/index.jsp?org=EEC">[</a>http://www.nsf.gov/pubs/2007/nsf0728/index.jsp?org=EEC]
</li>
<li id="pause2018">Pause, J. and Walkowski, N.O. “Everything is Illuminated. Zur Numerischen Analyse von Farbigkeit in Filmen.”  _Zeitschrift für digitale Geisteswissenschaften_ (2018).
</li>
<li id="pause2020">Pause, J. and Walkowski, N.O. “Welten abnehmenden Lichts. Ein Multi-Scale Viewing des Politthrillers im 21. Jahrhundert.”  _montage AV. Zeitschrift für Theorie und Geschichte audiovisueller Kommunikation_ 29 (2020): 59.
</li>
<li id="pause">Pause, J. and Walkowski, N.O. “Zombies, Conspiracies, and Esthetics in Crisis. A computational engagement with film genre.” In I. Ritzer (eds.), _Media and Genre. Dialogues in Aesthetics and Cultural Analysis_ . Cham (forthcoming)
</li>
<li id="pearlman2018">Pearlman, K. and Heftberger, A. “Editorial: Recognising Women’s Work as Creative Work.” In A. Heftberger and K. Pearlman (eds.), _Women at the Editing Table: Revising Soviet Film History of the 1920s and 1930s_ . Special Issue of _Apparatus. Film, Media and Digital Cultures in Central and Eastern Europe_ 6 (2018) _._ 
</li>
<li id="pereira2019">de sá Pereira, M. “Mixed Methodological Digital Humanities.” In M. K. Gold and L. F. Klein (eds.), _Debates in the Digital Humanities 2019_ . University of Minnesota Press, Minneapolis (2019): 405-412.
</li>
<li id="pfeiffer1996">Pfeiffer, S., Fischer, S., and Effelsberg, W. “Automatic audio content analysis.”  _Proceedings of the Forth ACM International Conference on Multimedia '96_ . Boston, MA (1996).
</li>
<li id="pouyanfar2018">Pouyanfar, S., Yang, Y., Chen, S.-C., Shyu, M.-L., and Iyengar, S. “Multimedia big data analytics: A survey.”  _ACM Computing Surveys (CSUR)_ 51.1 (2018): 10.
</li>
<li id="vanrijsbergen1979">van Rijsbergen, C. _Information Retrieval_ . Butterworth-Heinemann, London (1979).
</li>
<li id="roth2019">Roth, C. “Digital, digitized, and numerical humanities.”  _Digital Scholarship in the Humanities_ 34.3 (2019): 616-632.  
</li>
<li id="rui1998">Rui, Y., Huang, T. S., and Mehrotra, S. “Exploring video structure beyond the shots.”  _Proceedings of the IEEE International Conference on Multimedia Computing and Systems_ (1998): 237-240.
</li>
<li id="ruszev2018">Ruszev, S. “Rhythmic Trajectories. Visualizing Cinematic Rhythm in Film Sequences.” In Heftberger, A. and Grgic, A. (eds.), _Women Cutting Movies: Editors from East and Central Europe._ Special Issue of _Apparatus. Film Media and Digital Cultures of Central and Eastern Europe_ 7 (2018).
</li>
<li id="salt1974">Salt, B. “Statistical Style Analysis of Motion Pictures.”  _Film Quarterly_ 28.1 (1974): 13-22.
</li>
<li id="salt2006">Salt, B. _Moving into Pictures. More on Film History, Style, and Analysis_ . Starword Publishing, London (2006).
</li>
<li id="salton1983">Salton, G. and McGill, M. _Introduction to modern information retrieval_ . McGraw-Hill, New York (1983).
</li>
<li id="schaffner2014">Schaffner, J. and Erway, R. “Does Every Research Library Need a Digital Humanities Center?” OCLC Research, Dublin, Ohio (2014). [<a href="http://www.oclc.org/content/dam/research/publications/library/2014/oclcresearch-digital-humanities-center-2014.pdf">http://www.oclc.org/content/dam/research/publications/library/2014/oclcresearch-digital-humanities-center-2014.pdf</a>]
</li>
<li id="schoffman2010">Schöffmann, K., Hopfgartner, F., Marques, O., Boeszoermenyi, L., and Jose, J. M. “Video browsing interfaces and applications: a review.”  _SPIE Reviews_ 1.1 (2010).
</li>
<li id="sittel2017">Sittel, J. “Digital Humanities in der Filmwissenschaft.”  _MEDIENwissenschaft: Rezensionen | Reviews_ 4 (2017): 472.
</li>
<li id="snoek2005">Snoek, C. G. and Worring, M. “Multimodal video indexing: A review of the state-of-the-art.”  _Multimedia Tools and Applications_ 25.1 (2005): 5-35.
</li>
<li id="soleymani2009">Soleymani, M., Chanel, G., Kierkels, J. J., and Pun, T. “Affective characterization of movie scenes based on content analysis and physiological changes.”  _International Journal of Semantic Computing_ 3 _._ 2 (2009): 235-254.
</li>
<li id="svensson2010">Svensson, P. “The Landscape of Digital Humanities.”  _Digital Humanities Quarterly_ 4.1 (2010). [<a href="http://digitalhumanities.org/dhq/vol/4/1/000080/000080.html">http://digitalhumanities.org/dhq/vol/4/1/000080/000080.html</a>]
</li>
<li id="svensson2016">Svensson, P. _Big Digital Humanities: Imagining a Meeting Place for the Humanities and the Digital_ . University of Michigan Press, Ann Arbor (2016). 
</li>
<li id="terras2013">Terras, M. “Peering Inside the Big Tent.” In M. Terras, J. Nyhan and E. Vanhoutte (eds.), _Defining Digital Humanities_ , London (2013): 263-270. 
</li>
<li id="tsivian2009">Tsivian, Y. “Cinemetrics, Part of the Humanities' Cyberinfrastructure.” In M. Ross, M. Grauer and B. Freisleben (eds.), _Digital Tools in Media Studies_ . Bielefeld (2009): 93-100. 
</li>
<li id="tzelepis2016">Tzelepis, C., Ma, Z., Mezaris, V., Ionescu, B., Kompatsiaris, I., Boato, G., Sebe, N., and Yan, S. “Event-based media processing and analysis: A survey of the literature.”  _Image and Vision Computing_ 53 (2016): 3-19.
</li>
<li id="vonderaus2017">Vonderau, P. “Quantitative Werkzeuge.” In M. Hagener and V. Pantenburg (eds.), _Handbuch Filmanalyse_ . Wiesbaden (2017): 1-15.
</li>
<li id="wold1996">Wold, T., Blum, D., and Wheaton, J. “Content-based classification, search, and retrieval of audio.”  _IEEE Multimedia_ 3 (1996): 27-36.
</li>
<li id="zaharieva2010">Zaharieva, M., Zeppelzauer, M., Mitrovic, D., and Breiteneder, C. “Archive film comparison.”  _International Journal of Multimedia Data Engineering and Management_ 1.3 (2010): 41-56.
</li>
<li id="zeppelzauer2011a">Zeppelzauer, M., Zaharieva, M., Mitrovi¢, D., and Breiteneder, C. “Retrieval of motion composition in Film.”  _Digital Creativity_ 22.4 (2011): 219-234.
</li>
<li id="zeppelzauer2011b">Zeppelzauer, M., Mitrovic, D., and Breiteneder, C. “Cross-modal analysis of audio-visual film montage.”  _Proceedings of 20th International Conference on Computer Communications and Networks (ICCCN)_ (2011): 1-6. 
</li>
<li id="zhao2017">Zhao, B., Feng, J., Wu, X., and Yan, S. “A survey on deep learning-based fine-grained object classification and semantic segmentation.”  _International Journal of Automation and Computing_ 14.2 (2017): 119-135.
</li>
<li id="zhou2017">Zhou, W., Li, H., and Tian, Q. “Recent advance in content-based image retrieval: A literature survey.” arXiv preprint, arXiv:1706.06064 (2017).
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Despite the controversy about McLuhan’s concept ofmediaand the bold claim he derives from it no one, today, denies the idea that a medium significantly and often unnoticed shapes what it mediates.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>It is important to mention that in Europe this tension is stronger due to the fact that in the US there has been branch of digital humanities that for long came out of media studies and related fields<a class="footnote-ref" href="#svensson2010"> [svensson2010] </a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://www.digitalcinemastudies.com">https://www.digitalcinemastudies.com</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="https://www.uni-marburg.de/en/fb09/institutes/media-studies/research/research-projects/digitalfilmhistoriography">https://www.uni-marburg.de/en/fb09/institutes/media-studies/research/research-projects/digitalfilmhistoriography</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p><a href="http://www.cinepoetics.fu-berlin.de/en/index.html">http://www.cinepoetics.fu-berlin.de/en/index.html</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Note that there have been first steps toward establishing a <em>Film Encoding Initiative</em> (FEI) that is based on the MEI:<a href="https://github.com/cemfi/FEI">https://github.com/cemfi/FEI</a>. However, this format does not seem to be as established as TEI and MEI.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p><a href="http://www.digitalhumanities.org/dhq/vol/14/4/000495/000495.html">http://www.digitalhumanities.org/dhq/editorial/000495/000495.html</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p><a href="http://www.digitalhumanities.org/dhq/vol/14/4/000496/000496.html">http://www.digitalhumanities.org/dhq/editorial/000496/000496.html</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p><a href="http://www.digitalhumanities.org/dhq/vol/14/4/000497/000497.html">http://www.digitalhumanities.org/dhq/editorial/000497/000497.html</a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p><a href="http://www.digitalhumanities.org/dhq/vol/14/4/000498/000498.html">http://www.digitalhumanities.org/dhq/editorial/000498/000498.html</a>&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p><a href="http://www.digitalhumanities.org/dhq/vol/14/4/000499/000499.html">http://www.digitalhumanities.org/dhq/editorial/000499/000499.html</a>&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p><a href="http://www.digitalhumanities.org/dhq/vol/14/4/000500/000500.html">http://www.digitalhumanities.org/dhq/editorial/000500/000500.html</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p><a href="http://www.digitalhumanities.org/dhq/vol/14/4/000518/000518.html">http://www.digitalhumanities.org/dhq/editorial/000518/000518.html</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p><a href="http://www.digitalhumanities.org/dhq/vol/14/4/000528/000528.html">http://www.digitalhumanities.org/dhq/editorial/000528/000528.html</a>## Bibliography&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Matching Computational Analysis and Human Experience: Performative Arts and the Digital Humanities</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000496/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000496/</id><author><name>Jan-Hendrik Bakels</name></author><author><name>Matthias Grotkopp</name></author><author><name>Thomas Scherer</name></author><author><name>Jasper Stratil</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<p>Research in the humanities concerned with aesthetics and performative arts draws upon a distinct tradition of what we might callclose reading:Oscillating between formal description and hermeneutic interpretation, between shared myths, theories, codes and highly subjective lines of thought, the humanities’ analytical grasp on aesthetics and poetics is intimately tied to accounts of personal experience, rooted in the principles of exemplary study and subjective reading.</p>
<p>Over the past decades, developments within the field of computational science as well as the social and cultural shifts that are usually referred to with the broader term ‘digitalization‘ have affected core theory and methodology within the humanities. These developments provide alternatives and additions to familiar analytical approaches and give new weight to the kinds of statistical and numerical data collection that have been established with analogue means<a class="footnote-ref" href="#salt1983"> [salt1983] </a>. New software-based methods have led to a whole range of research that aims at producing machine-readable data as well as processing this data within the logics of quantitative analysis, advanced statistics or visualization. With regard to audio-visual material, Cinemetrics<a class="footnote-ref" href="#tsivian2009"> [tsivian2009] </a>, the Digital Formalism project (e.g.<a href="#gruber2009">Gruber et al. 2009</a>) and especially Adelheid Heftberger<a class="footnote-ref" href="#heftberger2018"> [heftberger2018] </a>as well as the film color projects conceived and led by Barbara Flückiger (e.g.<a href="#fluckiger2017">Flückiger 2017</a>), among others, have made groundbreaking contributions to this line of research.</p>
<p>At the same time, new possibilities for harvesting archives and metadata sets have propelled advances in historical research (e.g.<a href="#jacobs2016">Jacobs and Fyfe 2016</a>,<a href="#verhoeven2016">Verhoeven 2016</a>). Large parts of the latter development have been described and theorized convincingly under the term “distant reading” (see<a href="#moretti2013">Moretti 2013</a>). The methodology of distant reading has opened up new perspectives for research within the humanities, namely a shift from exemplary analysis to the comparative study of large corpora, while at the same time generating new modes of evidentness. For example, there are numerous approaches combining quantitative empiricism and humanities&rsquo; epistemology<a class="footnote-ref" href="#schoch2013"> [schoch2013] </a>or producing new aesthetic modes of insight by means of big data visualization (e.g., the Cultural Analytics research by Manovich’s Software Studies Initiative<a class="footnote-ref" href="#manovich2009a"> [manovich2009a] </a><a class="footnote-ref" href="#manovich2009b"> [manovich2009b] </a><a class="footnote-ref" href="#manovich2016"> [manovich2016] </a>) and other activities situated in the field of artistic and explorative research<a class="footnote-ref" href="#dawes2004"> [dawes2004] </a><a class="footnote-ref" href="#ferguson2015"> [ferguson2015] </a><a class="footnote-ref" href="#ferguson2017"> [ferguson2017] </a>.</p>
<p>There are many possible research objectives that all share the feasibility of studying large corpora as a key requirement: for example the analysis of a very productive novelist’s body of work or the comparative study of all news reports on a given topic within a certain country and time frame. In particular the compilation of large sets of art works and media by means of social sciences and neuropsychology benefits from these kinds of insights from the humanities, may they be quantitative or – as we will try to demonstrate – qualitative. Therefore, the possibility of studying large corpora, which has been considered out of reach for single scholars or small groups of researchers who work within the framework of close and detailed hermeneutical studies, promises new perspectives for research within the humanities as well as interdisciplinary research.</p>
<p>But while opening up these perspectives, the methodology of distant reading – especially the turn to quantitative methods and often highly abstracting visualizations – has also created a major challenge with regard to advancing on this path in the field of art and media studies. These epistemological principles aim at expanding humanities&rsquo; focus to larger corpora by an emphasis on thedistantpurposely transforming or even discarding thereading.It thus literally distances respective research in the field of the digital humanities from what we assume to be at the core of art and media consumption in the first place: the human experience of a given work of art or media. In this sense, “Distant reading is almost not reading at all” <a class="footnote-ref" href="#burdick2016"> [burdick2016] </a>.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> This mostly concerns studies of extensive corpora that by and large still focus on a combination of quantitative approaches and the epistemology of distant reading<a class="footnote-ref" href="#moretti2013"> [moretti2013] </a>. As a result, the methodology of distant reading has generated whole new sets of research questions and perspectives with regard to the macro structures and long term developments of certain media, formats and genres – but the underlying principles of abstraction<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> , accumulation and statistics fall short when it comes to questions of performativity, dynamics of perception, or aesthetic experience.</p>
<p>This circumstance becomes apparent in the field of performative, time-based arts like music, theatre, dance or film – especially if the respective research is shaped by a theoretical framework that draws on phenomenological approaches to aesthetics and poetics. In these cases, statistical data based on discrete entities is often of limited value. It is well possible to count how many A-minor chords are featured in a given piece of music, how often a dancer performs a certain move, or which percentage of long shots are followed by a close-up in a film. But from a certain perspective within the study of performative arts, this information is epistemologically incomplete. With regard to aesthetic experience, it is only the specific tangible context – the harmonics and dynamics of that specific piece of music, the kinaesthetics of bodily expression in that certain dance routine or the interplay of music, cutting rhythm and acting within that particular film scene – which makes these features meaningful. The very advantage of distant reading – stepping out of the tangible context of a certain point in time or space within a given work of art in order to get a grasp on overarching principles of the work as a whole (or even larger corpora) – shows its limits. Whereas a research object that is being referred to in terms of a semiotic, semantic, or syntactic paradigm can be divided into discrete entities with a fixed ‘value‘ or ‘meaning‘, the experiential quality of a certain detail within a phenomenological approach to aesthetics and performativity largely depends on the aesthetic composition as a whole. Accordingly, these research objects pose a challenge to the ways the isolation of features, the encoding of media texts and the accumulation of data are currently being conducted within parts of the methodologies of digital humanities.</p>
<p>Against this backdrop, this paper addresses a simple question: Is it possible to use tools and methods developed within the fields of computational science and digital humanities in order to carry out qualitative analysis of aesthetic compositions? How can we productively study aesthetic experience while drawing upon the informational paradigm<a class="footnote-ref" href="#coppi2002"> [coppi2002] </a>, i.e. the data driven operations of computational analysis?</p>
<p>In the following, we will present the methodological developments of the interdisciplinary project “Audio-visual rhetorics of affect” <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> (a cooperation of film studies and computational science; from here on referred to by its short title “AdA-project” ) as an exemplary approach to the computational analysis of performative arts and media. Drawing on a qualitative approach to dynamics of affect in audio-visual media<a class="footnote-ref" href="#schmitt2014"> [schmitt2014] </a><a class="footnote-ref" href="#scherer2014"> [scherer2014] </a><a class="footnote-ref" href="#kappelhoff2011"> [kappelhoff2011] </a>that combines a phenomenological understanding of film with the structural analysis of compositional patterns, this project aims at identifying rhetorical tropes within feature films, documentaries and TV reports on the global financial crisis (2007 and following). Addressing the questions posed above, this paper will focus less on specific findings (i.e. certain rhetorical tropes or a set thereof) but rather on the analytical framework that has been established in order to study a large corpus of audio-visual material with regard to aesthetic experience. This framework draws upon tools from the computational sciences, i.e. (semi-)automatic video analysis, semantic data structuring and machine learning.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
<p>On the one hand, the AdA-project has to grasp its subject matter on the micro-level of audiovisual composition – due to the focus on audio-visual rhetorics and the dynamics of affect shaped by moving images. On the other hand, this micro-level has to become graspable within an epistemological framework similar to the approach of distant reading in order to identify recurring compositional patterns.</p>
<p>This path poses two obstacles: a) the micro-level description of compositional structures has to be carried out across a corpus of films and TV reports that is well beyond the scope of what film scholars are able to analyze by themselves within the timeline of a research project; b) an approach including the scalable analysis of aesthetics and expressivity has to generate paths towards modes of abstraction that are fundamentally different to what semiotic and statistical paradigms of distant reading currently have to offer, as well as to humanities analysis approaches based solely on natural language. Against this backdrop, this paper intends to treat the AdA-project’s methodology as an example for studying performative arts and media by means of computational analysis. By discussing the specific challenges the project has to address, the paper seeks to sketch out ways towards modes of analytical abstraction and data processing that remain close to the way artworks and media are experienced by human beings. It thus contributes to the more recent trend to integrate the close, the distant and the in-between under the terms of “scalable reading” or “scalable viewing” <a class="footnote-ref" href="#mueller2012"> [mueller2012] </a><a class="footnote-ref" href="#pause2019"> [pause2019] </a><a class="footnote-ref" href="#fickers2018b"> [fickers2018b] </a>.</p>
<p>In order to exemplify the path the project has taken so far with regard to the aforementioned obstacles, this paper will present a method from the field of film studies that – aiming at the affective experience of audio-visual sequences – qualifies their affective dimension by means of qualitative description and conceptually grasps the nexus of aesthetic experience of viewers and rhythmic-kinetic figurations of audiovisual images (see Sections 1.2 and 1.3). We will then proceed to address a number of challenges we encountered on our way of remodeling this method within a computational framework; this includes a detailed video-annotation routine, semantic data structures, the integration of tools that enable semi-automatic video analysis as well as computer-generated visualizations of compositional patterns. Therefore, the main focus of this article is on the recasting of the common knowledge of basic film analytical concepts into a consistent, machine-readable data model which provides the basis to address many challenges of digital film analytical methods (see Sections 2.1, 2.2 and 2.3). Finally, we will present how the analysis of the same example mentioned above unfolds if it is performed within the methodological framework of our computer-based approach (see Section 2.4) – and reflect upon the perspectives this kind of research offers with regard to matching computational analysis and human experience in the field of art and media studies (see Section 3).</p>
<h2 id="1-a-systematic-approach-to-human-experience-the-emaex-method-and-affective-dynamics-in-film-viewing">1. A systematic approach to human experience: The eMAEX-Method and affective dynamics in film-viewing</h2>
<p>Before we discuss this paper’s main question – how to analyze arts and media on the level of human experience within a digital humanities framework – it is important to address a crucial question on the level of film theory first: Is it after all possible to address aesthetic experience on a general level, regardless of individual dispositions and differences and without postulating universal mechanisms of perceiving and processing? This question concerns any kind of research dealing with human experience of temporal arts and media, not turning to methods of self-disclosure or physiological measurements of actual empirical subjects (e.g. as applied within the social sciences and empirical psychology). In order to address it – in an exemplary way –, we are going to briefly sketch out a qualitative method developed within the field of film studies that aims at qualifying the affective experience of audio-visual segments based on film-analytical methods (see<a href="#kappelhoff2011">Kappelhoff and Bakels 2011</a>,<a href="#kappelhoff2018a">Kappelhoff 2018a</a>,<a href="#scherer2014">Scherer et al. 2014</a>).</p>
<h2 id="11-aesthetic-experience-and-intersubjectivity-in-film-viewing--theoretical-bases">1.1 Aesthetic experience and intersubjectivity in film viewing – theoretical bases</h2>
<p>As the programmatic remarks have indicated so far, we are strongly advocating for an approach to digital humanities that accentuates the theory driven and theory building aspect of humanities’ research. The following chapter serves as a brief sketch of the film theoretical background that informs both our research questions and the direction of method and tool development in the collaboration with our colleagues from the computational sciences. Even though we hope that key elements of the approach – specifically the systematic annotation vocabulary and the data visualization – are employable by different theoretical schools, they have been developed in view of a framework that focuses on the premises of embodied perception and the expressivity of movement patterns.</p>
<p>From a film studies perspective, all methodological questions concerning film analysis in the context of digital humanities are preceded by the challenge to engage descriptively with a fleeting subject matter that solely exists within the time of its perception<a class="footnote-ref" href="#bellour1975"> [bellour1975] </a><a class="footnote-ref" href="#bellour2000"> [bellour2000] </a>, and more pinpointed to our theoretical perspective: its being-viewed by an embodied spectator. Some branches of film theory tend to avoid this problem by tying the spectator’s emotions in film viewing to the cognitive apprehension of character and plot constellations<a class="footnote-ref" href="#tan1996"> [tan1996] </a><a class="footnote-ref" href="#grodal1997"> [grodal1997] </a><a class="footnote-ref" href="#grodal2009"> [grodal2009] </a>, largely leaving aside the media specific conditions of moving images and sound. While these theories have attracted a certain attention in the wake of a broader turn towards cognitive theory and neuropsychology over the past two decades, they remain in opposition to a theoretical strand that has been prominent within film studies since Hugo Münsterberg’s early psychological accounts on the “photoplay” <a class="footnote-ref" href="#munsterberg2002"> [munsterberg2002] </a>. This line of research focuses on the dynamics of movement and rhythm as the central phenomena with regard to the aesthetic experience of moving images, especially with regard to questions of mood, feeling, affect or emotion. Within the early years of the 20th century, the concept ofexpressive movementbegan to serve as a crucial node at the intersection of art theory<a class="footnote-ref" href="#fiedler1991"> [fiedler1991] </a>, social philosophy<a class="footnote-ref" href="#simmel1959"> [simmel1959] </a><a class="footnote-ref" href="#simmel1993"> [simmel1993] </a>and anthropology<a class="footnote-ref" href="#wundt1880"> [wundt1880] </a><a class="footnote-ref" href="#wundt1896"> [wundt1896] </a><a class="footnote-ref" href="#buhler1933"> [buhler1933] </a><a class="footnote-ref" href="#plessner1982"> [plessner1982] </a>. While these theories referred to the concept mainly with regard to the human body’s expressivity and its role in art and culture, Münsterberg and his successors in film theory – like Béla Balázs<a class="footnote-ref" href="#balazs2010"> [balazs2010] </a>or Sergej Eisenstein<a class="footnote-ref" href="#eisenstein1991"> [eisenstein1991] </a>– applied it to the kinetic and rhythmic patterns of the cinematic image.</p>
<p>In this tradition of thought, theories on movement and its expressive qualities have gained new attention following thebodily turnrespectivelyperformative turnwithin the humanities and social sciences that took place in the 1990s. In film theory, neo-phenomenological theories onembodimentand embodied perception once again turned the focus on movement and its crucial role at the intersection of expressivity and embodied perception (see<a href="#marks2000">Marks 2000</a>,<a href="#barker2009">Barker 2009</a>,<a href="#meunier2019">Meunier 2019</a>). Following Vivian Sobchack<a class="footnote-ref" href="#sobchack1992"> [sobchack1992] </a>, one of the most prominent voices within neo-phenomenological film theory, it is exactly this expressive quality of movement that provides the basis for an intersubjective understanding of experience in film viewing. According to Sobchack, the cinematic image presents itself as a situated seeing and hearing, a subjective perspective. In the act of film viewing, the spectator experiences the kinetic and haptic qualities of this situated viewing and hearing as an embodied being. The spectator’s perception and the cinematic image – as an expression of perception, of seeing and hearing – are intertwined in a two-fold act of perception grounded in the principle of an embodied being’s kinetic being-in-the-world:</p>
<blockquote>
<p>In a search for rules and principles governing cinematic expression, most of the descriptions and reflections of classical and contemporary film theory have not fully addressed the cinema as life expressing life, as experience expressing experience. Nor have they explored the mutual possession of this experience of perception and its expression by filmmaker, film, and spectator – all viewers viewing, engaged as participants in dynamically and directionally reversible acts that reflexively and reflectively constitute the perception of expression and the expression of perception. Indeed, it is this mutual capacity for and possession of experience through common structures of embodied existence, through similar modes of being-in-the-world, that provide the intersubjective basis of objective cinematic communication.<br>
<a class="footnote-ref" href="#sobchack1992"> [sobchack1992] </a>Sobchack’s notion of the intersubjectivity of kinetic and haptic dynamics of film resonates with thoughts on the commonalities of film and music Sergej Eisenstein has developed in the 1940s, suggesting specific compositional principles with regard to the arrangement of movement and rhythm while outlining his ideas of expressive movement and a cinematic aesthetics of effect<a class="footnote-ref" href="#eisenstein1988"> [eisenstein1988] </a>. Lately, these ideas on cinema’s audio-visual musicality have again been picked up on in theories on audience engagement<a class="footnote-ref" href="#pearlman2009"> [pearlman2009] </a>as well as with regard to dynamic affects in film-viewing<a class="footnote-ref" href="#kappelhoff2004"> [kappelhoff2004] </a><a class="footnote-ref" href="#kappelhoff2018b"> [kappelhoff2018b] </a><a class="footnote-ref" href="#bakels2017"> [bakels2017] </a>.</p>
</blockquote>
<p>This conception of the audio-visual modulation of affects grounded in the temporal shaping of intensities and rhythms has also been argued for by appealing to the work of the developmental psychologist Daniel Stern<a class="footnote-ref" href="#stern1985"> [stern1985] </a><a class="footnote-ref" href="#stern2010"> [stern2010] </a>. His theory of the vitality affects or vitality forms was introduced to the film theoretical discourse by Raymond Bellour<a class="footnote-ref" href="#bellour2011"> [bellour2011] </a>. Affects here are applied as self-contained temporal gestalts of movement, of rhythm, and of intensity, which are not linked to individual modalities of perception or forms of interaction. It is a matter of synaesthetic patterns, such as the creeping, the bulging, the explosion-like, or the fading, which can each occur as specific experiences, both in perception and in action as well as in feeling and thinking. These are derived from primordial forms of intersubjective, cross-modal interaction, like the affective reflection of an infant’s facial expression in the voice of its mother. Cinema, according to Bellour, can also be thought of as a similar interaction, constantly translating perceptions into feelings, for it produces:</p>
<blockquote>
<p>in the variety of its components (the image and the modalities of the soundtrack incorporated in it) [&hellip;] the constant illusion of a sensory attunement between the elements of the world, just as it does between the bodies that are deployed in it.<br>
<a class="footnote-ref" href="#bellour2011"> [bellour2011] </a></p>
</blockquote>
<p>Taken together, neo-phenomenological film theory’s core assumption of the audio-visual image being intersubjectively experienced as a two-fold act of kinaesthetic perception on the one hand, and theories on expressive movement, rhythm and audio-visual composition on the other, offer a way to address the aesthetic experience of moving images from an analytical perspective. Theories on movement and rhythm in audio-visual images serve as a methodological starting point for reconstructing dynamics of swelling tensions, shifting kinetic forces and the temporal shapes that emerge within these dynamics – by means of systematically describing patterns of audio-visual composition and their experiential qualities. In turn, neo-phenomenological theories on the embodied perception of movement provide the theoretical basis for assuming these experiential qualities to be experienced regardless of individual dispositions and differences, i.e. addressing human experience on a more general level without claiming universality.</p>
<p>With regard to the question raised at the beginning of this section – whether it is at all possible to address aesthetic experiences in film viewing on a general level via means of film analysis – we can now give a more nuanced answer: Of course, we do not claim to be able to predict a specific human being’s experience of a certain audio-visual sequence in detail and in total by means of film analysis. Obviously, we would never deny the notion of experience being rooted in specific cultural and historical contexts, as well as the conception that matters of feeling and understanding are highly subjective. Against the theoretical background we have sketched out here<a class="footnote-ref" href="#kappelhoff2018b"> [kappelhoff2018b] </a><a class="footnote-ref" href="#muller2018"> [muller2018] </a>, we should be able to demonstrate to what extent embodied experiences of audio-visual sequences can be reconstructed – by referring analytically to the spatial and temporal dynamics of specific rhythmic-kinetic figurations of audio-visual composition. Or to put it differently: We all do make our own experience in watching a certain film, TV series or news report. But given the basic principles of rhythm, movement and embodied perception, these individual experiences should relate to commonly shared experiential dynamics that are reflected in one way or another within our individual accounts. The aim of the method outlined within the rest of this article is to grasp this commonly shared basis of film experience and to make it accessible for comparative research. But before we get to the question of how this goal is achieved via digital tools, we first like to present a methodology that was developed with regard to this theoretical framework and exemplify it with a short analysis.</p>
<h2 id="12-emaex-qualifying-the-affective-dynamics-of-audio-visual-sequences-by-means-of-segmentation-and-description">1.2 eMAEX: qualifying the affective dynamics of audio-visual sequences by means of segmentation and description</h2>
<p>The eMAEX<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> system aims at providing a methodological framework for analyzing and qualifying the expressive and affective qualities of audio-visual material – may it be a contemporary Hollywood feature film, arthouse cinema, a screwball comedy, a war documentary or a web video.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> At the time of its initial development, it consisted of a systematic routine to segment, describe and qualify units of audio-visual composition as well as a web-based multimedia environment that enables researchers to combine analytical descriptions, film stills, data visualizations and the subject matter of analysis (i.e. video files of audio-visual source material) in order to display the results of film analytical studies. The computational approach to film analysis presented in Section 2 of this article is based on the analytical routine of the eMAEX framework and can be viewed as an advancement and adaptation of its routine in regard to the requirements of a semantically structured and machine-readable analytical vocabulary. Over the course of the following two subchapters of this section, we will exemplify the original eMAEX approach in order to a) unfold a vivid example of what we mean when referring to the aesthetic experience of moving images from a film studies perspective and b) thereby provide the necessary background for addressing this paper’s central question: how a systematised and machine-readable analytical vocabulary in combination with digital tools for video annotation can help to expand such a perspective on embodied aesthetic experience with regard to the comparative analysis of large corpora.</p>
<p>Following the theoretical concepts ofexpressive movementandembodimentoutlined above, eMAEX aims at the systematical description of spatio-temporal dynamics in moving images. Segmenting the subject matter at hand serves as the first step within the analytical routine and provides the basic temporal structure of the given subject matter. Following the intuitive elementary category of temporal segmentation within the everyday, journalistic and academic discourse, the object of study is first segmented into single scenes – conceptualized as an experiential unit.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> Within the routine’s vocabulary, this basic structure, the succession and affective interplay of scenes, is referred to as the object of research’s temporal macro level.</p>
<p>While the segmentation into scenes is a methodological consensus in various film analytical approaches and often carried out intuitively, the second level of segmentation is intimately tied to the qualitative description of the analyzed material: Within the first step of analysis, an initial short description of the scene is produced; by focusing on five formal levels of audio-visual composition (namely choreography, camera, sound, gestures and facial expressions and image composition) rather than on narration and representation, this initial description provides a first insight into the compositional principles that shape the respective scene. The grouping of the many different aspects of audio-visual composition into these five levels was based on a pragmatic reasoning that balanced the need for some kind of standardization within projects with the limited possibilities of free text annotation. The elaboration of this standardization of description routines into a workable data modelling has been one of the main foci of our subsequent developments.</p>
<p>Based on this initial description, the scene as a whole is sub-segmented into consecutiveexpressive movement units(EMUs), i.e. the interplay of different levels of staging is described asone temporal gestalt, loosely comparable to a gesture of the film itself. Two of the five formal levels of composition mentioned above are chosen as dominant levels within each EMU. Usually changes with regard to dominant levels of composition provide strong hints with regard to the scene’s segmentation into EMUs. Following this second step of segmentation, a qualitative description of the compositional dynamics shaping each EMU is produced separately, and the respective EMU is qualified with regard to its affective dynamics.</p>
<p>In a final, third step, the dynamic interplay of a scene’s EMUs forming the compositional logic of the respective scene as a whole is also subject to a qualitative description of its affective dynamics. Following this last step, qualitative data on the respective subject matter of analysis has been gathered on three levels:<br>
All scene’s sub-segments of audio-visual composition (EMUs) are qualified with regard to their affective dynamics as cross-modal temporal gestalts. This in-depth analysis constitutes the micro-level of analysis.The interplay of these sub-segments within each scene is also qualified with regard to its affective dynamics; this is referred to as the meso-level of analysis.The qualifications with regard to each scene’s affective dynamics are displayed as an affective course spanning the whole film; this course is referred to as the macro-level of analysis, revealing each research object’s basic dramaturgy of affect.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Macro, meso, and micro level of eMAEX.
        </p>
    </figcaption>
</figure>
<p>The final subchapter of this section will unfold an exemplary scene analysis according to the eMAEX system in order to provide an example of how we conceive the aesthetic experience of audio-visual images – before the next section will address the question of how such a qualitative approach can be followed up upon via digital tools of video analysis.</p>
<h2 id="13-exemplary-analysis-a-scene-from-_the-company-men_">1.3 Exemplary Analysis: A scene from <em>The Company Men</em></h2>
<p>In the following, we want to present the exemplary analysis of a scene from the AdA-project’s corpus that is supposed to serve as a tangible example for the concept of cinematic expressive movement. The film <em>The Company Men</em> (John Wells, USA 2010) addresses the consequences of the financial crisis after 2007 in everyday life. More precisely, the film focuses on job cuts due to speculations on the stock market – by following several male protagonists and their struggle to find a new job in order to provide for their families.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup></p>
<p>To give you a short overview of the exemplary scene, taken from the second half of the film: Bobby Walker – played by Ben Affleck –, who has been fired from his office job at a logistics company in Boston and lives with his family at his parent’s house, is searching urgently for a job as marketeer. After getting a phone call with the invitation to a job interview and a short discussion with his wife, we see him preparing in a dark hotel room for the job interview with a company in Chicago: the protagonist awakes at dawn, carries out his fitness routine and irons his shirt. We then see him walking amid a crowd of people in business outfits towards a high corporate building. Inside the building, in a shiny lobby, Bobby walks towards the reception counter. After announcing himself he sits down and waits nervously. When the assistant of the awaited manager appears, Bobby learns that the appointment has been mixed up and that there won’t be a job interview. The scene ends with Bobby standing disappointed in a busy crowd of passersby on the streets of Chicago.</p>
<p>In this plot summary – like in every film synopsis – the varying experiential qualities and dynamics of the scene have already been synthesized into attributions likeshiny,nervously,disappointedand so on. The following analysis is aimed at grasping the expressive qualities in which those summaries – i.e. verbal accounts of experience – are rooted. In order to make substantiated claims about the scene’s experiential quality, we will now break down the scene’s compositional structure into EMUs, drawing on the second level of temporal segmentation of the eMAEX framework as outlined above. In doing so, we will briefly describe each EMU and its affective quality with regard to the temporal gestalt that is constituted through the interplay of its dominant formal levels – in this case acoustics (especially music), image composition and camera.</p>
<h2 id="first-expressive-movement-unit-tc-011141011236">First Expressive Movement Unit (TC: 01:11:41–01:12:36)</h2>
<p>In the first EMU, a figuration of a sudden increase of vividness is created through the interplay of acting and acoustics, more specifically through harsh contrasts in the acting style – especially the bodily and facial expressivity of the main character played by Ben Affleck. At the beginning of the EMU, the fatigued protagonist walks up a driveway and enters his parents&rsquo; home’s kitchen. Laconic and with low body tension, he interacts with his family. When he’s told that there was a call in his absence from a firm in Chicago offering him a job, the film immediately cuts to the protagonist packing his suitcase while discussing the job offer with his wife. His body tension rises and his gestures become more and more energetic and extensive as he talks animatedly to his wife. The intensity of the protagonist&rsquo;s movements are highlighted by the restraint of his counterpart: His wife leans on the side of the image, half in the dark with arms crossed and a smile, she only interrupts him with brief questions or affirming comments. The increasing vitality in acting ground the experience of an abruptly emerging and then continually rising energy.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 1. TC: 01:11:41–01:12:36.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 1. TC: 01:11:41–01:12:36.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 1. TC: 01:11:41–01:12:36.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 1. TC: 01:11:41–01:12:36.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 1. TC: 01:11:41–01:12:36.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 1. TC: 01:11:41–01:12:36.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 1. TC: 01:11:41–01:12:36.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 1. TC: 01:11:41–01:12:36.
        </p>
    </figcaption>
</figure>
<h2 id="second-expressive-movement-unit-tc-011236011326">Second Expressive Movement Unit (TC: 01:12:36–01:13:26)</h2>
<p>In a nonverbal sequence, we see Bobby preparing for the interview in his hotel room and walking through Chicago until he arrives at the company building. This process is staged as a swelling movement figuration: The music becomes louder and more upbeat and the image increasingly brightens. In the last part, the camera movements, Bobby’s movement as well as those of passersby form a concerted choreography – an opening movement i.e. a cinematic gesture of widening. This choreography emphasizes the vertical axis and underlines the directedness of the whole sequence – from the hotel room to the busy streets of Chicago finally tilting up the tall corporate building. The interplay of music, movement and image composition form a swelling movement figuration that grounds an experience of vivid directedness.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 2. TC: 01:12:36–01:13:26.
        </p>
    </figcaption>
</figure>
<h2 id="third-expressive-movement-unit-tc-011326011437">Third Expressive Movement Unit (TC: 01:13:26–01:14:37)</h2>
<p>Through a repeated change between deep and flat image compositions as well as close and more distanced camera positions, Bobby’s arrival in the waiting area of the company building is staged as an emerging tension which is supported through the hasty movements of Bobby fidgeting with a magazine. An assistant enters the image through a flight of stairs in the rear of the image and tells Bobby that his appointment will not take place. The lobby that the protagonist enters is staged as a space of suppressed vividness. This is achieved through the contrast of subtle, but constant movement of the isolated protagonists on the one hand and an image space dominated by geometric, rectangular shapes and clear lines and surfaces on the other. The camera approaches the conversation before cutting out abruptly to a medium long shot while the actors nearly freeze completely in their body movements and the dialogue stops. In this way, the interplay of acting, choreography and image composition grounds the experience of a vividness that is abruptly put to rest.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 3. TC: 01:13:26–01:14:37.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 3. TC: 01:13:26–01:14:37.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 3. TC: 01:13:26–01:14:37.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 3. TC: 01:13:26–01:14:37.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 3. TC: 01:13:26–01:14:37.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 3. TC: 01:13:26–01:14:37.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 3. TC: 01:13:26–01:14:37.
        </p>
    </figcaption>
</figure>
<h2 id="fourth-expressive-movement-unit-tc-011437011456">Fourth Expressive Movement Unit (TC: 01:14:37–01:14:56)</h2>
<p>In a nonverbal succession of two shots, Bobby is standing again in the streets of Chicago. A stretched piano-and-strings arrangement sets in. The camera focuses on the protagonist, positioning him at the center of the image. His body’s immobility is in harsh contrast to the many moving passersby that crowd the image in the fore- and background. Over two shots the camera moves towards the protagonist – thus narrowing the image space continually – and singles out his face that has lost its tension staring into the offscreen space. The contrast in movement exposes the protagonist and the swelling elegiac music emphasizes his facial expression. Together these articulatory strategies form a figuration of an intensifying deceleration and contraction that grounds an experience of slowly being isolated.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 4. TC: 01:14:37–01:14:56.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 4. TC: 01:14:37–01:14:56.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 4. TC: 01:14:37–01:14:56.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Stills from The Company Men. EMU 4. TC: 01:14:37–01:14:56.
        </p>
    </figcaption>
</figure>
<h2 id="the-scenes-dynamic-pattern-as-a-whole-tc-011141011456">The Scenes Dynamic Pattern as a Whole (TC 01:11:41–01:14:56)</h2>
<p>The scene as a whole – drawing on the interplay of music, image composition and camera work – stages an affective parcours shaped by the experience of changing energetic states. Over the course of the whole scene, this affective course grounds an emerging image of disappointment.</p>
<p>After the initial sudden increase of vividness (the first EMU), a directed, swelling figuration (the second EMU) is abruptly put to rest (the third EMU). A figuration of intensifying deceleration and contraction (the fourth EMU) then closes the scene.</p>
<p>It is crucial that we are explicitly not talking about the emotions that the protagonist may feel, as if he was a person of flesh and blood – instead of being a mere composition of shapes, colors and sounds. Rather we claim that, in this scene, the unfolding of various audio-visual rhythms in the act of film-viewing<a class="footnote-ref" href="#kappelhoff2018b"> [kappelhoff2018b] </a>– i.e. the entanglement of technically animated movement images and embodied experiences – can be qualified and reconstructed as an image of disappointment; the affective course laid out over the description of the scene’s four EMUs lends this image of disappointment its temporal and energetic shape – the abrupt rise of energy that comes with the increase of vividness; the directedness this joyful expectation can generate; the abrupt putting-to-rest that comes with disappointment; and finally the inwardness and isolation that shapes the aftermath of disappointment. All this is generated here on the level of the embodied experience of rhythms and gestures the audio-visual image performs. That way Bobby’s disappointment is not simply represented, but rather made sensible to the viewer.</p>
<p>In this section we aimed at exemplifying the way in which performative arts and media directly address human capacities for embodied perception and sensation. While we hope this exemplary analysis helped in making this conceivable, succeeding in this case only means to highlight the actual problem: how the experiential dynamics described over the course of this exemplary analysis can be addressed within the informational paradigm of computational analysis. The following section will be dedicated to outlining challenges and perspectives in trying to achieve such a computational methodology.</p>
<h2 id="2-addressing-human-experience-by-means-of-computational-analysis-the-ada-framework-for-video-annotation">2. Addressing human experience by means of computational analysis: The AdA-framework for video annotation</h2>
<p>The exemplary analysis above sketched out a systematic, qualitative approach to describing and qualifying the experiential qualities of audio-visual sequences that was developed in the field of film studies. Qualitative descriptions of expressive dynamics like this highlight the complexity as well as the variety of audio-visual composition: From lighting to camera movement to image composition to color grading to sound design to cutting rhythm to acting to choreographies and so on – the audio-visual image seems to encompass a sheer endless amount of formal levels. In addition, any compositional figuration of a multimodal audio-visual composition seems to realize a distinct way of making different of these countless levels interact. Furthermore, the foregrounding of certain dynamics within this interplay, the climaxes and accents that arise from it, are from our theoretical perspective tied to genuine phenomena of embodied perception. In short: Reconstructing these expressive dynamics of human experience in the waytraditionalscholarly work has operated – film-viewing and descriptions in natural language – seems to be resistant to any implementation as digital method or tool. However, we want to present a digital approach to film analysis in this section that is concerned exactly with these expressive dynamics and experiential qualities. The starting point in addressing these problems with regard to a data-driven computational approach to studies concerned with human experience turns out to be as simple as effortful: i.e. the task of producing extensive and detailed data on various different formal levels. The aim is to be able to retrace these expressive dynamics – as patterns – in a bottom-up perspective based on this data gathered on the micro level of audio-visual composition.</p>
<p>The turn to computational tools that shapes the methodological approach of our project is motivated by a research interest that highlights the practical limits of viewing and describing as a film analytical method.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> Previous work in the many different exemplary case studies with the eMAEX methodology<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> has generated a tempting hypothesis: that the principles studied there yield generic systems of cinematic articulations on the micro-level of audio-visual composition and expressive dynamics. Taking the complexity and variety of these compositional principles into account, the concepts of repetition, variation and differentiation nevertheless open a path towards a typological study of expressive dynamics. Given the affective quality we attribute to these figurations of expressive movement, such a study aims at identifying a set of rhetorical tropes grounding audio-visual communication – i.e. at compositional gestures that mark the represented topics, constellations or concepts with affective qualities like tension, fear or euphoria, shaping the affective perspectives from which these topics emerge. To follow up on this hypothesis would require the comparative analysis of a large corpus of audio-visual material.</p>
<p>The AdA-project is dedicated to such an empirical study of a large corpus of audio-visual material – consisting of fictional feature films, documentaries and TV reports concerned with the global financial crisis (2007–) – with the aim of establishing a typological perspective on patterns of audio-visual expressivity. Given the discursive nature of crisis rhetorics – oscillating between the identification of a significant problem and the struggle for a solution – and the variety of audio-visual media, this corpus is considered suitable as an exemplary field of study. The project’s methodological approach brings together film scholars and computational scientists; it encompasses</p>
<p>the development and definition of a film analytical ontology, i.e. a systematic analytical vocabulary that follows the requirements of machine-readable semantic data management, as well as film analytical key concepts that are widely used in film studies,the annotation of extensive audio-visual material based on this vocabulary, combining tools for (semi-)automatic video analysis and manual annotations by expert annotators, as well asevaluation and application of machine learning and/or search algorithms in order to identify recurring patterns of audio-visual composition, in combination with tools for visualizing and querying complex sets of annotation data for scholars (a step that is going to be evaluated in the last phase of our project).</p>
<p>The latter step as well as the use of (semi-)automatic tools integrated within the annotation software will follow the human-in-the-loop model, i.e. all data generated by computational analysis will be corrected by film scholars in order to further train the applied tools.</p>
<p>Out of the variety of tools for manual and semi-automatic video annotation<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> , we have chosen the open-source video-annotation-software Advene, which was originally designed by Olivier Aubert, Yannick Prié and Pierre-Antoine Champin, to perform multi-author film analyses. Based on a cooperation with Olivier Aubert, Advene has been further adjusted and extended to meet the specific requirements of detailed scholarly film analysis – not only in regard to the (manual) annotation process but also regarding interfaces for a film analytical ontology, video retrieval and the support of RDF (a standard model for data interchange on the Web; see<a href="#agt-rickauer2018">Agt-Rickauer et al. 2018</a>).</p>
<p>The latter functions as the exchange format for a machine-readable film-analytical ontology, i.e. the structured vocabulary and data modelling which is the basis for the annotation process. The framework is set up to make semantically stored data readable by machines and humans. While most annotations in the AdA-project are manually created, the amount of (semi-)automated annotations is still to be expanded further within the framework of this methodology. The aim is to develop a basis for the joint integration of manual and (semi-)automatic annotations and facilitate future work on machine learning for which we have laid the groundwork by providing a structured vocabulary and the interfaces in the annotation tool.</p>
<p>In the following, we will address the challenges that arise with developing the ontology, the implication of a consistent video-annotation routine, and the development of visualizations which offer scholars a way to ‘read‘ into these extensive data sets. The section will be closed with a second look at the scene described at the end of the last section – now based on video annotation data and respective visualizations.</p>
<h2 id="21-challenge-1-establishing-a-machine-readable-vocabulary-and-data-structure">2.1 Challenge 1: Establishing a machine-readable vocabulary and data structure</h2>
<p>The main methodological goal in our project is to map reconstructions of film-viewing experience within a digital framework. We want this analytical framework to feature vocabulary that is as generic as possible in order to accommodate different strands of film and media studies, allowing all kinds of film and media scholars concerned with audio-visual material to ground their studies in empirical reconstructions of audio-visual composition. This means the innovative aspect of this line of work lies in a consistent as well as open process of data modelling that – in a best-case scenario – can serve as a fundamental starting point not only for our film analytical studies, but also for respective research projects in the field.</p>
<p>With regard to the variety of different forms of audio-visual material as well as our aim of conducting comparative corpus studies, we had to address the question of how to determine the parameters on which to analyze the flow of images and the granularity with which they are annotated.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> Moreover, the annotation process – involving a group of multiple annotators – created the need for further systematic operationalization. These methodological considerations resulted in turning the focus on three basic requirements:</p>
<p>Creating a modularly structured vocabulary that is both grounded in a broad methodological film-analytical consensus and applicable with regard to specific theories on the aesthetic experience of audio-visual images (see Section 1.1).Setting up a mode of description that is defined, operationalized and condensed to a degree that allows for the – to the greatest possible extent – impartial annotation of audio-visual corpora carried out by a group of trained annotators.Defining the terms and procedures in a way that is explicit enough to allow researchers coming from different theoretical backgrounds to relate their approach critically to the analytic data.</p>
<p>With regard to the first point, we selected the vocabulary either directly from the broad and manifold spectrum of approaches to film analysis that focus on and describe formal elements of audio-visual composition or transformed film-analytical key concepts into annotatable keyword systematics.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup></p>
<p>In order to meet the requirements outlined above, we chose to arrange our annotation vocabulary within a threefold structure:</p>
<ul>
<li>Annotation levels (namelySegmentation,Language,ImageComposition,Camera,Montage,Acoustics,BodilyExpressivityandMotifs) are the primary categories that refer to different articulatory modes of cinematic staging principles. With regard to these macro categories, we followed upon the basic levels of the eMAEX framework (see Section 1.2).<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup></li>
<li>For each level we defined a multitude of annotation types in order to systematically differentiate formal principles within these levels (e.g.CameraMovementDirectionorCameraMovementSpeed). Thus, we identified analytical subdimensions that are restricted enough to provide a set of predefined terms or in exceptional cases a focussed description in free text format. Together these various types provide a basic and many-layered impression of the overarching categories. Camera is thus described as <em>Recording/Playback Speed, Depth Of Field, Defocus, Camera Movement Unit, Camera Movement Type, Camera Movement Speed, Camera Movement Direction, Camera Angle, Camera Angle Canted, Camera Angle, Vertical Positioning, Lens</em> . Needless to say, such an approach can never provide a complete description of all stylistic nuances but is rather designed to grasp central dynamics.</li>
<li>For each annotation type, we defined annotation values, determining the vocabulary that can be annotated. This third step provides the basis for the actual annotation process, that consists of linking these values to a specific time increment of a given video file based on its timecode. For example, in the case ofCameraMovementDirectionthe values describe the basic directions a camera can move to (e.g. left, right, up, down, towards and away but also circle, canted and undirected for more complex movement patterns). Thereby the free-text-descriptions in the original eMAEX framework are replaced by data sets drawing on a (mostly) controlled vocabulary. Annotation types are based on different internal logics with regard to how they organize values. Some feature values in reference to an ordinal scale (e.g.Field Size), others follow the logic of nominal scales with no hierarchical order. This difference is especially of importance with regard to data visualization (see Section 2.3). Also, different annotation types within are based on different principles with regard to how and what vocabulary can be entered, leaving us with the possibility to work with free text when necessary.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup></li>
</ul>
<p>The resulting annotation routine encompasses 8 annotation levels, 78 annotation types and 502 annotation values. All of these different descriptive dimensions are published under creative commons license (ada.ontology.org), each accompanied by a short definition explaining the use of the vocabulary. The vocabulary is regularly updated as well as our set of annotations (including the 22.000 annotations generated over the course of our pilot case study on <em>The Company Men</em> ). So far the following films have been annotated: the feature films <em>The Company Men</em> (John Wells, USA 2010) and <em>The Big Short</em> (Adam McKay, USA 2015) as well as the documentaries <em>The Inside Job</em> (Charles Ferguson, USA 2010) and <em>Capitalism: A Love Story</em> (Michael Moore, USA 2009), furthermore a selection of features from the German TV News-Broadcast Tagesschau and the web clipsOccupy Wall Street(Sem Maltsev, USA 2011) and <em>Where Do We Go From Here? Occupy Wall St.</em> (Ed David, USA 2011). All annotations are provided under creative commons licence at<a href="https://projectada.github.io">https://projectada.github.io</a>and can be browsed and queried through the annotation explorer web app:<a href="http://ada.filmontology.org/explorer/">http://ada.filmontology.org/explorer/</a>.</p>
<p>Our vocabulary has been modelled as a machine-readable semantic data structure that is essential for intertwining manual and (semi-)automatic annotations, enabling the future application of machine learning, data evaluation, and potential exchange of annotations between different researchers. The respective machine-readable data ontology was set up by Henning Agt-Rickauer. It stores all values possible within our annotation framework – not as a mere unstructured text, but instead modelling the relations and dependencies within all annotation values, types and levels (e.g. the interior logic of ordinal scales) with technologies of the semantic web.</p>
<blockquote>
<p>We have developed an automated process to generate the project ontology and semantic metadata of the video corpus directly from the input data using the RDF mapping language and RML tools. The ontology is imported into Advene and exposes the domain-specific vocabulary with unique URIs as annotation tracks in a timeline view so that semantic annotations conforming to the ontology can be exported. Annotations, metadata, and the ontology is published via the project&rsquo;s triple store.<br>
<a class="footnote-ref" href="#agt-rickauer2018b"> [agt-rickauer2018b] </a>Drawing on this interconnection of semantic technologies and tools for film analysis<br>
“the project aims to provide an ontology for film-analytical studies complemented by a video annotation software adapted for authoring and publishing Linked Open Data by non-experts [in the field of semantic web technologies]<br>
<a class="footnote-ref" href="#agt-rickauer2018a"> [agt-rickauer2018a] </a>Hence, the adjusted version of the open-source software Advene can serve as a user-friendly interface, offering the advantages of semantically structured datasets to researchers without further programming skills. Annotating based on this semantic data ontology also provides the possibility to search and compare analyses based on complex queries, visualizations and other tools.</p>
</blockquote>
<p>Most importantly, by providing an ontological data structure a) drawing on film-analytical key concepts as well as b) featuring short definitions with regard to the whole controlled annotation vocabulary, we designed the video-annotation framework as open as possible with regard to film-analytical studies based on different theoretical frameworks and epistemologies – creating the possibility for other researchers to relate their annotations to ours and vice versa.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> Thus empirical data for the analysis of audio-visual material can potentially be exchanged between projects with different research questions, theoretical backgrounds or even languages.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></p>
<h2 id="22-challenge-2-setting-up-a-systematic-video-annotation-routine">2.2 Challenge 2: Setting up a systematic video-annotation routine</h2>
<p>With regard to the systematization of the video annotation, the goal was not to achieve a complete congruence of singular annotations but rather an intersubjective identification of the progression of several annotations. The dynamics of audiovisual expressivity unfold their meaning – like a melody – in the dynamic progressions over time and not in the attribution of singular values at static points in time. For example, a comparison of scene analyses by different annotators made us see that a common pattern of increasingly closer field sizes was clearly detectable even when singular decisions such as between medium closeup or shoulder closeup diverged. This fuzziness of individual annotation values is not an artefact of manual annotation but grounded in the nature of the object of study, since the film analytical concepts do not designate discrete entities – any computational distinction between, say, a close-up and a shoulder close-up is purely arbitrary. Spoken within the music metaphor: the aim of the systematization is the common recognition of a melody and not primarily that of individual notes.</p>
<p>In order to advance the annotation with our film-analytical vocabulary from a proof-of-concept state to an application-oriented methodological framework, we set up a systematic routine with the need to operationalize the process in a number of ways. In the development phase of this vocabulary, we regularly met with our expert annotators to ensure a high degree of (intersubjective) consistency of our annotation data as well as having immediate feedback on the practicality of the various concepts. Based on these repeated feedback loops, definitions for each level, type and value were acquired that guide analytical decisions during annotations. These definition texts constitute the first results of our ongoing research process. Additional insights are fixated in a technical and in a methodical manual that will be published and translated at the end of the project.</p>
<p>Furthermore, since annotating manually within the presented framework is very labour intensive – given the vast number of annotation types and values –, we had to speed up the annotation process. On the one hand, this became possible by adjusting the user interface (UI), particularly the manual aspects of video annotation (e.g. the input of values, but also the evaluation and correction of annotated values). On the other hand, the manifold description levels can be streamlined in order to analyze a larger amount of films for corpus studies. Finally – as mentioned in the introduction to this section –, we make use of some (semi-)automatic annotations based on digital tools, the possibilities of which are still to be evaluated further and implemented.</p>
<p>Regarding the UI, we optimized the manual input of controlled vocabulary through autocomplete and short keys. This allows for a quick enrichment of preexisting segments (e.g. shots or music pieces), especially with regard to annotation types with reduced input options. Combined with short key controls of the video player and switching between annotations, the annotation speed was increased. To offer the annotators an improved overview of the various annotation types (displayed as tracks within Advene’s timeline-view), we developed a color code for all types, grouping them visually according to the respective annotation levels.</p>
<p>Also, over the course of the annotation of <em>The Company Men</em> , we partly re-oriented the annotation process towards longer segments.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> In turn, we implemented the combination of multiple values for annotation types that can change even within small segments. Since the field size, for example, can change through camera movements or movements within the image, there was a need to implement a simple syntax of combining values within a segment. Therefore, we have established the syntax values [TO] to indicate developments between values (e.g.closeup,[TO],medium shot,indicating that all field sizes between these values are passed) and [VS] to indicate two simultaneous, conflicting dynamics within a segment (for example the expressive body language for a shot encompassing two figures can be annotated ashappy,[VS],sad).</p>
<p>But even with these simplifications, annotating large amounts of audio-visual material on about eighty different description levels remains an extremely time-consuming task. Since the importance of formal levels can vary within the context of different guiding questions and theories, we selected a subset of annotation types for the running AdA-project that allows film scholars to identify the basic compositional principles of a film based on a reduced set of twenty annotation types (with the possibility of annotating additional types for a selection of key scenes) from all annotation levels.</p>
<p>As mentioned above, (semi-)automatic video analysis tools offer another promising way of significantly speeding up video-annotation processes. Based on the interactions of expert annotators and automated tools (with the level of human interference depending on the amount of training the respective tool demands), an increasing proportion of manual annotation work on some (but not all) types could be (semi-)automatized in the long run. On the other hand, this bears the risk that automatically detectable traits are overemphasized for pragmatic reasons, thus creating a bias for easily created quantifiable metadata. In order to avoid respective data distortions, we decided to set up an analysis framework based on manual description first – and then evaluate the potentials for detector implementation step-by-step.</p>
<p>Following this approach, we want to briefly discuss a few automated features that have been integrated in the annotation process so far, with others still being evaluated or in a developmental stage. Already implemented in Advene was an open-source shot detection and a graphic user interface to correct the results manually (see Figure 6).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Advene’s shot-validation view.
        </p>
    </figcaption>
</figure>
<p>In addition, we use a second proprietary detector to analyze shot transitions which achieved much better results on fades, wipes and other continuous transitions. With approximately 1.500 frame-precise annotated shots over the course of a film with a two-hour runtime, the feature of automatically detecting cuts and shot transitions can be seen as a huge advance in comparison to manual work – especially given the essential function of theshotsegment as basic micro segmentation with regard to many other annotation types.</p>
<p>Another already widely used automated tool depicts the general volume of a video file’s audio track as a soundwave, allowing to quickly grasp which sections of a film are especially calm or loud and where sudden changes in volume occur (see Figure 7) – a feature we use, for example, in order to quickly identify peaks in volume, such as the prominent use of loud music or sudden noises like a gunshot.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Waveform implementation in Advene’s timeline-view.
        </p>
    </figcaption>
</figure>
<p>Another field with a high potential of automatization that is still in the state of evaluation concerns written and spoken words. Especially regarding audio-visual material where subtitles<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> are not available, automatic language recognition can provide a solid base for manual corrections or – at least – a general indication where language appears and where not. Since our project features non-English documentaries and German television news, the discrepancy between English and other speech-to-text tools became evident. Regardless of the technological base, a human correction of transcoded dialogue is currently still indispensable. In light of our goal to produce an open and free framework, we refrained from using language processing from Amazon or Google which might provide better results.</p>
<p>Other areas for applying computational analysis that are currently under development are color detection,<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> automatic detection of aspect ratio and optical flow-analysis. In addition, there have been convincing attempts at using algorithms for face detection in order to automatically detect field sizes<a class="footnote-ref" href="#arnold2019"> [arnold2019] </a>. But however promising the values for precision and recall may be, they are still in a range that is more feasible to statistical abstractions and distant viewing than to the needs of a precise qualitative reconstruction. Therefore, they would still need a lot of manual corrections in order to obtain continuous correct field-size-annotations for a full-length film. So far, the automatically generated annotations did in many other cases not comply with the manual annotations based on human perception in an acceptable margin. Future research will have to show which of these tools can be adjusted to the requirements of a qualitativeclose viewingto a degree that makes manual correction obsolete or manageable.</p>
<h2 id="23-challenge-3-developing-visualizations-for-patterns-of-audio-visual-composition">2.3 Challenge 3: Developing visualizations for patterns of audio-visual composition</h2>
<p>After discussing the strategies for improving the process of entering and correcting annotations, we want to discuss the challenge that arises from annotating a film extensively: How to work with this complex set of data, without leaving thereadingof data solely to algorithms and statistics? For an encompassing analytical approach, the question of assembling and relating annotations becomes relevant. As mentioned before, the film The Company Men was annotated<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> across 66 different annotation types which led to a data set of approximately 22.000<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> annotations for a single feature film.</p>
<p>This amount of metadata of course raises the question ofreadabilitywhich we will be discussing in the following by describing our visualization efforts. The visualization of our complex data sets can produce immediate insight into a composition and provide the involved film scholars with the possibility of guiding software-based searches for recurring compositional patterns.</p>
<p>Referring to the arrangement of a timeline with x and y axis, such areadingof annotations has a horizontal and a vertical dimension. In this context,horizontalrefers to the temporal succession of annotations, whereasverticalrefers to the synchronicity of annotations (i.e. values) assigned to different annotation types. In terms of this basic distinction, different forms of visualization with different advantages are possible and necessary for specific purposes. Thus, not a single visualization paradigm (e.g. multilayered timeline, histogram of a single type, etc.) can be singled out. In turn, a toolbox of different ways to enter and read annotation data has to be provided, that varies according to the respective research interest and theoretical framework. For example, data may be presented in a table or a timeline.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup></p>
<p>The visualization of values in a timeline allows for a quick and intuitive understanding of the length of single annotations as well as the rhythm and the compositional patterns they form together with other annotations. With regard to our research on audio-visual rhetorics of affect and the comparative analysis of compositional patterns, this contextualization of single values is crucial.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup></p>
<p>In our joint efforts with Olivier Aubert, a visualization feature was developed that is precisely adapted to our research project’s comparative scope: the AdA-timeline (demo:<a href="https://olivieraubert.net/hpi/timeline.html">https://olivieraubert.net/hpi/timeline.html</a>).<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> The respective diagrams (see Figure 8) can be directly generated with Advene, offering the possibility to instantly adapt to changing or developing sets of annotations.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of the AdA-timeline generated with Advene.
        </p>
    </figcaption>
</figure>
<p>The basic idea behind this mode of visualization can be described as making a selection of annotation types readable like a musical score of an orchestra piece, displaying audio-visual rhythms as graphical patterns. Here we draw on film scores from theorists like Sergej Eisenstein<a class="footnote-ref" href="#eisenstein2006"> [eisenstein2006] </a>, but also newer examples developed in projects like “Digital Formalism” or “Cinemetrics” as well as on scores Jan-Hendrik Bakels developed in his book on audio-visual rhythms<a class="footnote-ref" href="#bakels2017"> [bakels2017] </a>.</p>
<p>For example, the dynamics ofFieldSizein Figure 9 can be grasped visually; extrema are more easily and quickly detected than in a single-line depiction.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Single line of Advene timeline view vs. multiple lines in the AdA-timeline.
        </p>
    </figcaption>
</figure>
<p>The AdA-timeline (as seen in Figure 8) features at the top a timeline of the whole film (see Figure 10), indicating different scenes in various color shades. By marking a segment in this timeline, it is possible to zoom into the respective subsegment – switching from a micro-perspective of a few seconds to an overview of the whole film within an instance. Below this zoom bar is a histogram of shot length (similar to Cinemetrics’ visualizations) displayed for the currently selected segment.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of histogram in the AdA-timeline.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of zoom bar in the AdA-timeline.
        </p>
    </figcaption>
</figure>
<p>This offers the possibility to quickly navigate across different points within the running time of the film at hand as well as across different annotation levels, types and the respective values. Furthermore, it is possible to choose and display only a selection of annotation types within the diagram, to change their color palettes, to switch between different representations (such as single line, horizontal bar graph and, in some types, histograms and waveforms), and to connect the browser-based visualization with an embedded video player, so that by clicking on an annotation, the respective segment can be watched.</p>
<p>Another way to navigate and/or filter the diagram could be to combine it with query interfaces, identifying scenes across the corpus based on complex sets of search parameters (e.g. a search for all segments where closeups occur while sad music is playing). Currently, Henning Agt-Rickauer is developing such an interface in cooperation with Joscha Jäger – the annotation explorer,<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> which is based on FrameTrail – for the AdA-project.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> In combination with graphical evaluations of visualizations and query tools, an image search developed by Christian Hentschel is another useful tool for a comparative navigation of the corpus in regard to motif studies and the analysis of the modulation of affective profiles.</p>
<p>In this section’s last subchapter, we will take a second and last look into the scene from <em>The Company Men</em> described within the eMAEX framework above (see Section 1.3) in order to present a short use case for the methodology outlined in this section.</p>
<h2 id="24-exemplary-analysis-ii-studying-the-company-men-based-on-visualized-video-annotation-data">2.4 Exemplary Analysis II: Studying The Company Men based on visualized video-annotation data</h2>
<p>Over the course of this second look at our exemplary scene, we want to show how the outlined affective parcours (from excitement, joyful expectation, and bafflement to sad isolation), as well as the described EMUs and their figurations, can be detected and substantiated within a bottom-up perspective by retracting compositional patterns from our annotation data or its visualization. The initial and decisive step, i.e. the segmentation of the scene into four EMUs, can already be retraced within a brief overview of a selection of annotation types and the respective annotations. Figure 11 shows an excerpt from the Advene timeline view, depicting annotations according to annotation types and in their temporal expansion.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Advene timeline view of the scene “Wrong Date” TC 01:11:41–01:14:56. <em>The Company Men</em> . John Wells, USA 2010.
        </p>
    </figcaption>
</figure>
<p>Already at first glance, the on- and offset of music (green annotation typesMusicMoodandMusicIntensityin the middle of the Advene timeline view), as well as the dialogue on- and offset and the use of shot-reverse shot-montage (purple annotation typeDialogueTextand blue annotation typeMontageFigureMacro) indicate a clear structuring of the scene into four parts based on rhythmic patterns (see Figure 12).<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup></p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Segmentation of the scene “Wrong Date” on the basis of annotations TC 01:11:41–01:14:56. <em>The Company Men</em> . John Wells, USA 2010.
        </p>
    </figcaption>
</figure>
<p>In the following, we will take a closer look at the four EMUs and explain how we can build our film-analytical claims bottom-up, drawing on our annotations.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The first expressive movement of the scene “Wrong Date” TC 01:11:41–01:14:56. <em>The Company Men</em> . John Wells, USA 2010.
        </p>
    </figcaption>
</figure>
<p>We described the first EMU – which we qualified as an abruptly emerging, then continually rising energy – as a figuration of suddenly increasing vitality that is predominantly shaped through bodily expressivity,<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> montage<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> and the acoustic composition<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup> of the segment. The drastic change in the acting style can be observed in the annotation typeBodyLanguageIntensity<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> (see Figure 13) in which the intensity is rated on a scale from 1 (low) to 5 (high intensity). Whereas the first shot is rated low (1) and in the second shot a low (1) and a medium (3) intensity are confronted, the intensity rises again – rather abruptly – in the third shot with the contrast of 5 and 4, i.e. a discussion between the protagonist and his wife. This gradual rise ofBodyLanguageIntensityoverall, as well as the sudden significant increase – which can be ascribed to Bobby’s (Ben Affleck)BodyLanguageIntensity– is accompanied by an increase in volume that can be traced in the waveform depiction. In this second half, theShotDuration<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> shows a particular rhythm: several short shots with closer field sizes showing Bobby or his wife are followed by a longer medium shot of the bedroom (each with Bobby’s wife facing the camera in the background). This specific pattern repeats and gradually accelerates during this segment – with a slight deceleration at the end of the scene.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The second expressive movement of the scene “Wrong Date” TC 01:11:41–01:14:56. <em>The Company Men</em> . John Wells, USA 2010.
        </p>
    </figcaption>
</figure>
<p>We described the second EMU – which we qualified as vivid directedness – as a swelling figuration. Based on the annotations it becomes apparent how the music is dominant in this regard: i.e. its increasing volume which can be deduced again from the waveform and that correlates with an increasingMusicIntensity.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> The latter was annotated as rising from 1 to 3 (on a scale from 1 to 5). Furthermore, this music piece was qualified by our annotators as upbeat, happy music.</p>
<p>In addition, the swelling dynamics of the music piece interact with other annotation types. As the bottom of the Advene timeline view in Figure 14 shows, the image brightens<sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> continually from dark shots (black) over bright-dark shots (contrast of bright and dark parts of the image depicted in light grey annotations) to consistently medium light sequences (in medium grey annotations), while at the same time theColourRange<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup> used by the film changes distinctly. Furthermore, the swelling movement is constituted through an increasingly dynamic cinematography, identifiable by the use of faster camera movements at the end (see the red annotation typeCameraMovementSpeed<sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup> that changes from slow to medium).</p>
<p>In the last part of the segment, the camera interacts with the image intrinsic movement (see the yellow annotation typeImageIntrinsicMovement<sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup> that describes the perceived degree of movement within a shot on a scale from 0 to 3; in this segment, the dynamicity varies between 1 and 2 before reaching its climax with 3 shortly before the end of the sequence). Overall, the image intrinsic movement thus shows a course of increasing intensity, that comes to an abrupt halt when the last shot of the segment depicts in an extreme low angle a static shot of the company building that was qualified as a 0.</p>
<p>We can summarize this second expressive movement as a swelling movement, where the music intensity, the camera movement speed, as well as the image intrinsic movement jointly rise over the course of the segment. The brightening of the image, the upbeat music, as well as the facial expression together with the directedness of the camera movement and the general vividness of the image shape this swelling as a vivid directedness, finding its finale in front of the seemingly gigantic company building (extreme low angle).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The third expressive movement of the scene “Wrong Date” TC 01:11:41–01:14:56. <em>The Company Men</em> . John Wells, USA 2010.
        </p>
    </figcaption>
</figure>
<p>The third expressive movement – which we qualified as vividness put abruptly to rest – stages a figuration of abrupt change. Within theFieldSize<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> annotations, a shifting dynamic between closeness and abrupt distancing can be retraced. This happens twice in this EMU: a first instance briefly in the beginning, and a second more emphasized one in the last shot. At the first instance (see dark purple annotation in Figure 15), a medium long shot of Bobby standing at the reception desk is followed by a closer medium shot of him sitting down (pink annotation). By again jumping away in the third shot (green annotation), the cinematography creates a tension.</p>
<p>This pattern is repeated in a rather emphasized manner and prolonged at the second instance towards the end of the EMU: The camera approaches the conversation between the protagonist and the assistant in a series of medium closeups, before returning abruptly to a medium long shot in the very last shot of the segment (see Figure 15). This second distancing movement is accompanied by a sudden silence on the level of dialogue (see the absence of purple annotations in the typeDialogueText<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup> in Figure 15). We qualify this moment of irritation, the abrupt change by means of a distancing movement accompanied by a sudden silence, as the experience of vividness put abruptly to rest.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The fourth expressive movement of the scene “Wrong Date” TC 01:11:41–01:14:56. <em>The Company Men</em> . John Wells, USA 2010.
        </p>
    </figcaption>
</figure>
<p>The fourth and last EMU of this scene – which we qualified as an experience of slowly being isolated – is identified as a figuration of an intensifying deceleration and contraction which can be substantiated as follows: Reversing the distancing movement of the last segment, this expressive movement is characterized by a gesture of approaching, realized through montage and camera movement. The camera approaches the protagonist until we see him in a shoulder closeup (the closest field size used in this scene; see Figure 16). On the acoustic level, music sets in – which is qualified as sad and intense. The observed movement dynamics within the frame at this moment are especially interesting: Two separate movement intensities are identified, so that two separate values are given and related via a [VS] syntax element. This derives from the harsh contrast between the static protagonist in the image centre and his dynamic surrounding (various moving passersby). Whereas the interplay of moving image parts was perceived before as directed or harmonic, it is now classified as chaotic, thus changing the underlying impression. Overall, we can describe this movement figuration of a camera closing in on the protagonist’s tensionless face accompanied by sad and intense music and with a diverging movement dynamicity within the frame as figuration of an intensifying deceleration and contraction.</p>
<p>In summary, the scene as a whole creates an image of disappointment, realized by the succession of an abruptly emerging, then continually rising energy and vivid directedness, over a constricted vividness that is abruptly put to rest, before slowly retreating into isolation. This affective course can, as we hope to have shown, easily be identified on the basis of the compositional patterns that appear in the structured annotation of the scene. This bottom-up perspective enables even scholars not trained in qualitative description of expressive movements to identify the respective patterns.</p>
<p>The systematic description of these audiovisual patterns is no end in itself, but should enable us to search for similar patterns in the wider corpus of films. Drawing on the presented analysis, we can hypothesize that scenes of experiencing disappointment are recurring throughout our corpus. We can now condense the observed pattern in our annotation data to some core traits: a shift fromhappytosadmusic mood<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup> (with a pause in-between); closer field sizes at the end and a high image intrinsic movement correlating with the annotation of happy music. In Figure 17, a responsive and zoomable timeline view (see Section 2.3) of the scene (titled) “Wrong Date” shows some of these key traits. For example, a blue-coloured bar in the annotation typeMusicMoodat the bottom visualizing the valuehappyis followed by a short segment without annotation, then a red-coloured bar visualizing the valuesad.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Reduced overview of the scene “Wrong Date” TC 01:11:41–01:14:56. <em>The Company Men</em> . John Wells, USA 2010. AdA-timeline.
        </p>
    </figcaption>
</figure>
<p>Our growing annotation database allows us to query for scenes that meet these criteria. In Figure 18 below, you can see a graphical comparison with a second scene from <em>The Company Men</em> . The scene “Bobby’s last paycheck” (bottom) occurs earlier in the film, meeting the same criteria regarding the happy-sad change in music as well as the approaching camera at the end of the scene. Synchronously with the annotatedhappymusic you see as in the other scene a high intensity (value:3) ofImageIntrinsicMovementas well as more (shoulder)closeupsin the segment withsad MusicMood. In our exemplary scene we saw that this pattern was an indicator and element of the scene’s affective parcours (of excitement, joyful expectation, bafflement to sad isolation). A further in-depth analysis of this second scene would show that it does indeed stage – a slightly varied – image of disappointment.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Comparison of two scenes in <em>The Company Men</em> . John Wells, USA 2010.
        </p>
    </figcaption>
</figure>
<p>This analysis so far has shown that we can conduct a detailed analysis of spatio-temporal dynamics in moving images on the micro level based upon empirical data from the annotation of a largely controlled vocabulary. Over the course of this exemplary study, we hope to have shown how to determine key characteristics of single analyses and search for these characteristics within the film (and throughout a larger corpus) in order to find similar scenes. This enables us to identify recurring affective profiles within a corpus and thus allows us to make detailed and empirically-based claims about larger groups of films – focusing on the dynamic unfolding of scenes and their experiential quality.</p>
<h2 id="3-matching-computational-analysis-and-human-experience--conclusion-and-perspectives">3. Matching Computational Analysis and Human Experience – Conclusion and Perspectives</h2>
<p>In this article we have focused on the requirements, challenges and proposed solutions we have identified within the research goal of matching computational means of analysis and interpretation with the theoretically deduced primacy of experience in media reception. The sketched-out film analytical framework is no one-fits-all-solution for analyzing audiovisual media, and there are still many questions unanswered – and even not yet asked. But we hope that this is also read as a contribution to the ongoing development of Digital Humanities methodologies which are – at least with regard to audio-visual images – still largely in a phase of fast development.</p>
<p>Apart from the concrete hypotheses, measures and findings that we have presented, we want to outline in this conclusion the underlying epistemological and disciplinary principles that are of importance to us and that also resonate in some recent debates about the directions that the field of Digital Humanities is taking:</p>
<p>The dichotomy between the close and the distant, the qualitative and the quantitative – as well as between the digital and the analog, incidentally – should not be considered as mutually excluding and framed in a discourse that emphasizes deficiency. We rather have to find means to foreground the inherent hybridity and scalability that works within the Digital Humanities and make it productive in as many ways as we can<a class="footnote-ref" href="#fickers2018a"> [fickers2018a] </a>. It is thus important to us to emphasize the circumstance that this kind of research program is not proposed as a substitution to established methods and frameworks, but rather as a promising addition to the methodological toolboxes of the different disciplines.</p>
<p>It has also been established quite often, that the hybridity of the Digital Humanities necessitates (at least) two translation efforts and literacies<a class="footnote-ref" href="#jones2012"> [jones2012] </a>: One concerns humanities scholar who may not have to become a programmer but at least has to develop a basic understanding of how codes, databases and interfaces work. But the other translation is equally important: The possibilities of computation are highly problematic from a techno-political point of view, as long as they are not viewed from specific theoretical perspectives and research questions that are derived from concrete problems of knowledge and understanding. In order to relate aesthetic theory of embodied perception and methods from computational sciences, a common ground has to be found that deviates from the standards of the involved disciplines and always runs the risk to seem incompatible with conventional self-understandings – a predicament that a lot of inter- and transdisciplinary research has to face.</p>
<p>In our case, we proceeded from a theoretical concept of embodied experience and expressive movement patterns in audio-visual images. We were confronted with the task to translate this into a data structure that was accessible to computational processing. One important side effect of this and other frameworks is that it encourages collaborative research – annotating together, re-using analytical data with new questions – even though a lack of universal file formats and standard software still makes the exchange and implementation in the scholarly communities difficult. We followed the idea that ways of grasping compositional patterns in fine-grained analytical reflection certainly exceed human capacities when they are applied to larger corpora, but that this could be achieved by combining a systematic, theory-guided production of large amounts of data. This implied a different look at data as compared to previous, digital and non-digital modes of data collection in film and media studies, which did not start from the maximum of fine-grained analytical access but from a minimum of easily quantifiable features<a class="footnote-ref" href="#salt1983"> [salt1983] </a>. It also implied a changing perspective on computational methods since it emphasizes a holistic consideration of formal structures within audio-visual material that overarches the enterprise of formalizing any individual feature for algorithmic detection. (So far, our experience in the implementation of automatic feature detection has highlighted the need for further development in this field, but we are convinced that this is a question of time and appropriate training data that ideally also takes into account manual annotations that are collected with a view towards aesthetic structures. The flipside of this assessment is the fact that the time effort of largely manual annotations and the training of expert annotators is still a disadvantage considering the average infrastructure of research projects.)</p>
<p>We want to propose our Data Model as a possible framework for such a holistic consideration that not only provides a modular, structured coding system for the many levels of audio-visual analysis, but also offers a view on connecting these levels in order to achieve the further application of methods like search algorithms and machine learning. One future direction of this research lies in the further use of manually gathered annotation data to train algorithms not only in the detection of single features but in the identification of recurring patterns. The other – associated – field of application is the further development of standardized visualizations and the implementation of complex cross-modal queries.</p>
<p>The basic framework provided by the AdA filmontology aims at providing a first encompassing data structure for the various stylistic levels of cinematic expressivity – with all the advantages and disadvantages that come with such an ambitious ‘global’ approach. We still hope that the general steps that we tried to sketch out over the course of this article can serve as orientation for similar endeavors in other disciplines of performative, time-based arts and media. These programmatic steps involve identifying possible starting points with regard to addressing intersubjective bases of experience, setting up a systemized machine-readable vocabulary addressing these bases, making use of visualizations and computational methods in order to identify complex, recurring patterns. With regard to these epistemological steps, temporality and patterning could serve as a common denominator for the larger field of integrating digital tools and the study of performative, time-based arts and media.</p>
<p>With these preliminary results, we hope to give new impulses for the nexus between film analytical research and the implementation of digital tools based on a machine- and human-readable defined vocabulary. We started from the finding that algorithms are not profound in reconstructing the bases of experiential qualities like feelings. But when confronted with a research question that takes a look at a larger corpus of audio-visual material, one soon finds that it is not strictly speaking possible to objectify and empirically compare these experiential qualities apart from the compositional patterns in which they are grounded. It is this diversion via setting up a systemized machine-readable vocabulary addressing the intersubjective bases of film-viewing on the level of modeled data, that makes it possible to match algorithmically interpreted and generated annotations with research interested in the experiential qualities of film.</p>
<ul>
<li id="agt2013">Agt, H. and Kutsche, R. D. “Automated construction of a large semantic network of related terms for domain-specific modeling” . International Conference on Advanced Information Systems Engineering, Berlin/Heidelberg (2013), pp. 610-625.
</li>
<li id="agt-rickauer2018a">Agt-Rickauer, H., Aubert, O., Hentschel, C., and Sack, H. “Authoring and Publishing Linked Open Film-Analytical Data” ,<a href="https://www.olivieraubert.net/doc/2018-ekaw-demo.pdf">https://www.olivieraubert.net/doc/2018-ekaw-demo.pdf</a>.
</li>
<li id="agt-rickauer2018b">Agt-Rickauer, H., Hentschel, C., and Sack, H. “Semantic Annotation and Automated Extraction of Audio-Visual Staging Patterns in Large-Scale Empirical Film Studies” . In _Proceedings of the 14th International Conference on Semantic Systems_ (SEMANTICS). Vienna (2018).
</li>
<li id="apostolidis2014">Apostolidis, E. and Mezaris, V. “Fast Shot Segmentation Combining Global and Local Visual Descriptors” . In _Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing_ (ICASSP), Florence (May 2014).
</li>
<li id="arnold2019">Arnold, T., Tilton, L. “Distant viewing: Analyzing large corpora” . _Digital Scholarship in the Humanities_ , 34 (2019): i3-i16. fqz013,<a href="https://doi.org/10.1093/digitalsh/fqz013">https://doi.org/10.1093/digitalsh/fqz013</a>
</li>
<li id="bakels2017">Bakels, J-H. _Audiovisuelle Rhythmen. Filmmusik, Bewegungskomposition und die dynamische Affizierung des Zuschauers_ . De Gruyter, Berlin/Boston (2017, english translation in prep.).
</li>
<li id="bakels">Bakels, J., Grotkopp, M., Scherer, T. and Stratil, J. “Digitale Empirie? – Computergestützte Filmanalyse im Spannungsfeld von Datenmodellen und Gestalttheorie” . Montage AV, 21.1 (in preparation).
</li>
<li id="balazs2010">Balázs, B. _Early Film Theory. Visible Man and The Spirit of Film_ . Berghahn Books, Oxford (2010[1924/1930]).
</li>
<li id="barker2009">Barker, J. M. _The Tactile Eye. Touch and the Cinematic Experience_ . University of California Press, Berkeley/Los Angeles/London (2009).
</li>
<li id="bellour1975">Bellour, R. “The Unattainable Text” , _Screen_ 16.3 (1975): 19–28.
</li>
<li id="bellour2000">Bellour, R. _The Analysis of Film_ . Indiana University Press, Blumington, IN (2000).
</li>
<li id="bellour2011">Bellour, R. “Going to the Cinema with Guattari and Stern” . In E. Alliez and A. Goffey (eds.), _The Guattari Effect_ . Continuum, London/New York (2011): 220-234.
</li>
<li id="berger2019">Berger, H. “Film denkt Revolution. Zu audiovisuellen Inszenierungen politischen Wandels” . _Vorwerk_ 8, Berlin (2019).
</li>
<li id="bordwell2013">Bordwell, D., Thompson, K. _Film Art. An Introduction_ . McGraw-Hill, New York (2013).
</li>
<li id="buhler1933">Bühler, K. Ausdruckstheorie. _Das System an der Geschichte aufgezeigt_ . Fischer, Jena (1933).
</li>
<li id="burdick2016">Burdick, A., Drucker, J., Lunenfeld, P., Presner, T. and Schnapp, J.. _Digital_Humanities_ . MIT Press, Cambridge (MA)/London (2016).
</li>
<li id="coppi2002">Coppi, R. “A theoretical framework for Data Mining: The Informational Paradigm ” , _Computational Statistics and Data Analysis_ , 38.4 (2002): 501–515.
</li>
<li id="corrigan2012">Corrigan, T., White, P. _The Film Experience. An Introduction_ . Bedford/St. Martin’s, Boston/New York (2012).
</li>
<li id="datta2006">Datta, R., Joshi, D., Li, J. and Wang, J. Z. “Studying aesthetics in photographic images using a computational approach” . In _ECCV_ (3) (2006): 288–301.
</li>
<li id="dawes2004">Dawes, B. Cinema Redux.<a href="http://www.brendandawes.com/projects/cinemaredux">http://www.brendandawes.com/projects/cinemaredux</a>(2004).
</li>
<li id="drucker2016">Drucker, J. “Graphical Approaches to the Digital Humanities” . In S. Schreibman, R. Siemens and J. Unsworth (eds.), _A New Companion to Digital Humanities_ . Chichester: John Wiley & Sons, Chichester (2016): 238–250.
</li>
<li id="eisenstein1988">Eisenstein, S. “Die vierte Dimension im Film” . In O. Bulgakowa (ed) _Das dynamische Quadrat. Schriften zum Film_ . Hochmuth, Köln (1988): 90–108.
</li>
<li id="eisenstein1991">Eisenstein S. _Towards a Theory of Montage_ . M. Glenny and R. Taylor (eds.). BFI Publishing, London (1991).
</li>
<li id="eisenstein2006">Eisenstein, S. M. “Die Vertikalmontage (1940-1941)” . In F. Lenz (ed) _Jenseits der Einstellung. Schriften zur Filmtheorie_ . Suhrkamp, Frankfurt /M. (2006): 238-300.
</li>
<li id="ferguson2015">Ferguson, K. L. “Volumetric Cinema” , _Transition: Jornal of Videographic Film and Moving Image Studies_ 2.1 (2015).
</li>
<li id="ferguson2017">Ferguson, K. L. “Digital Surrealism: Visualizing Walt Disney Animation Studios” , _DHQ: Digital Humanities Quarterly_ , 11.1 (2017).
</li>
<li id="fickers2018a">Fickers, A. “Hybrid Histories. Versuch einer kritischen Standortbestimmung der Mediengeschichte” , _Annali dell'Istituto Storico Italo-Germanico in Trento (Jahrbuch des Italienisch-Deutschen Historischen Instituts in Trient)_ , 44.1 (2018): 117-132.
</li>
<li id="fickers2018b">Fickers, A., Snickars, P. and Williams, M.J. “Editorial Special Issue Audiovisual Data in Digital Humanities” , _VIEW Journal of European Television History and Culture_ , 7.14 (2018): 1-4. DOI:<a href="http://doi.org/10.18146/2213-0969.2018.jethc149">http://doi.org/10.18146/2213-0969.2018.jethc149</a>
</li>
<li id="fiedler1991">Fiedler, K. “Moderner Naturalismus und künstlerische Wahrheit” . In G. Boehm, _Schriften zur Kunst I_ . Wilhelm Fink, Munich (1991[1881]): 82–110.
</li>
<li id="fluckiger2017">Flückiger, B. “A Digital Humanities Approach to Film Colors” , _The Moving Image_ , 17.2 (2017): 71-93.
</li>
<li id="gaertner2016">Gaertner, D. “Tickets to War. Demokratie, Propaganda und Kino in den USA bis 1945” . Ph.D. thesis, Freie Universität (2016).
</li>
<li id="greifenstein2020">Greifenstein, S. _Tempi der Bewegung – Modi des Gefühls. Expressivität, heitere Affekte und die Screwball Comedy_ . De Gruyter, Berlin/Boston (2020).
</li>
<li id="grodal1997">Grodal, T. K. _Moving Pictures. A New Theory of Film Genres, Feelings and Cognition_ . Clarendon Press, Oxford (1997).
</li>
<li id="grodal2009">Grodal, T. K. _Embodied Visions. Evolution, Emotion, Culture and Film_ . Oxford University Press, Oxford (2009).
</li>
<li id="grotkopp2017">Grotkopp, M. _Filmische Poetiken der Schuld. Die audiovisuelle Anklage der Sinne als Modalität des Gemeinschaftsempfindens_ . De Gruyter, Berlin/Boston (2017).
</li>
<li id="gruber2009">Gruber, K., Wurm, B. and Kropf, V. (eds.). _Digital Formalism: Die kalkulierten Bilder des Dziga Vertov, Maske und Kothurn_ , 55 (2009).
</li>
<li id="heftberger2018">Heftberger, A. _Digital Humanities and Film Studies. Visualising Dziga Vertov’s Work_ . Springer, Cham (2018).
</li>
<li id="hentschel2013">Hentschel, C., Blümel I. and Sack H. “Automatic Annotation of Scientific Video Material based on Visual Concept Detection” . _Proc. 13th Int. Conf. Knowl. Manag. Knowl. Technol. - i-Know ’13_ , 1-8 (2013).
</li>
<li id="hochschild">Hochschild, B. “Die Wahrnehmung des Anderen: Zur Begegnung mit Figuren im Verhalten von Filmen und Comics” . Ph.D. thesis, Freie Universität Berlin (in preparation).
</li>
<li id="horst2018">Horst, D. _Meaning-Making and Political Campaign-Advertising_ . De Gruyter, Berlin/Boston (2018).
</li>
<li id="jacobs2016">Jacobs, L. and Fyfe, K. “Digital Tools For Film Analysis: Small Data” . In C. R. Acland and E. Hoyt (eds.), _The Arclight Guidebook to Media History and the Digital Humanities_ . Falmer; REFRAME/Project Arclight, (2016)<a href="http://projectarclight.org/book">http://projectarclight.org/book</a>.
</li>
<li id="jones2012">Jones, R. and Hafner, C. (2012). _Understanding Digital Literacies: A Practical Introduction_ . Routledge, London/ New York (2012).
</li>
<li id="kappelhoff2004">Kappelhoff, H. _Matrix der Gefühle. Das Kino, das Melodrama und das Theater der Empfindsamkeit_ . Vorwerk 8, Berlin (2004).
</li>
<li id="kappelhoff2018a">Kappelhoff, H. _Front Lines of Community. A Postscript to Hollywood War Cinema_ . De Gruyter, Berlin/Boston (2018).
</li>
<li id="kappelhoff2018b">Kappelhoff, H. _Kognition und Reflexion: Zur Theorie filmischen Denkens_ . De Gruyter, Berlin/Boston (2018).
</li>
<li id="kappelhoff2011">Kappelhoff, H. and Bakels, J.-H. “Das Zuschauergefühl. Möglichkeiten qualitativer Medienanalyse” , _Zeitschrift für Medienwissenschaft_ , 5.2 (2011): 78-95.
</li>
<li id="kappelhoff2013">Kappelhoff, H., Gaertner, D. and Pogodda, C. (eds.). _Die Mobilisierung der Sinne. Der Hollywood-Kriegsfilm zwischen Genrekino und Historie_ . Vorwerk 8, Berlin (2013).
</li>
<li id="kinkle2011">Kinkle, J, and Toscano, A. “Filming the Crisis: A Survey” , _Film Quarterly_ 65.1 (2011): 39–51.
</li>
<li id="krizhevsky2012">Krizhevsky, A., Sutskever, I. and Hinton, G. E. “ImageNet Classification with Deep Convolutional Neural Networks” . In _dv. Neural Inf. Process. Syst._ (2012): 1097–1105.
</li>
<li id="lehmann2017">Lehmann, H. _Affektpoetiken des New Hollywood. Suspense, Paranoia und Melancholie_ . De Gruyter, Berlin/Boston (2017).
</li>
<li id="li2010">Li, N., Motta, E. and Zdrahal, Z. “Evaluation of an Ontology Summarization” . (2010).
</li>
<li id="manovich2009a">Manovich, L. _Cultural Analytics: Visualising Cultural Era of More Media _ . Milan (2009).
</li>
<li id="manovich2012">Manovich, L. “How to compare one million images?” In D. Berry (ed.), _Understanding Digital Humanities_ , Palgrave Macmillian, London (2012): 249-278.
</li>
<li id="manovich2016">Manovich, L. “The Science of Culture? Social Computing, Digital Humanities and Cultural Analytics” , _Journal of Cultural Analytics_ , May 23 (2016).
</li>
<li id="manovich2009b">Manovich, L., Douglas, J. “Visualizing temporal patterns in visual media: computer graphics as a Research Method” .<a href="http://softwarestudies.com/cultural_analytics/visualizing_temporal_patterns.pdf">http://softwarestudies.com/cultural_analytics/visualizing_temporal_patterns.pdf</a>(2009).
</li>
<li id="marks2000">Marks, L. U. _The Skin of the Film: Intercultural Cinema, Embodiment, and the Senses_ . Duke University Press, Durham/London (2000).
</li>
<li id="mashtalir2014">Mashtalir, S. and Mikhnova, O. “Key Frame Extraction from Video: Framework and Advances” . In _Int. J. Comput. Vis. Image Process_ . 4 (2014).
</li>
<li id="meunier2019">Meunier, J.P. “The Structures of the Film Experience: Filmic Identification” . In J. Hanich, D. Fairfax (eds.). _The Structures of the Film Experience by Jean-Pierre Meunier. Historical Assessments and Phenomenological Expansions_ . Amsterdam University Press, Amsterdam (2019), pp. 32-156.
</li>
<li id="moretti2013">Moretti, F. _Distant Reading_ . Verso, London/New York (2013).
</li>
<li id="mueller2012">Mueller, M. _Scalable Reading_ .<a href="https://scalablereading.northwestern.edu/?page_id=22">https://scalablereading.northwestern.edu/?page_id=22</a>(2012).
</li>
<li id="muller2018">Müller C. and Kappelhoff H. _Cinematic Metaphor. Experience – Affectivity – Temporality_ . De Gruyter, Berlin/Boston (2018).
</li>
<li id="munsterberg2002">Münsterberg, H. “The Photoplay – A Psychological Study” . In A. Langdale (ed.), _Hugo Münsterberg on Film. The Photoplay – A Psychological Study and Other Writings_ . Routledge, New York/London (2002[1916]): 45-162.
</li>
<li id="pause2019">Pause, J. and Walkowski, N.-O. “SCALABLE VIEWING – Johannes Pause und Niels-Oliver Walkowski zu digitalen Methoden und den Digital Humanities” , _Open Media Studies-Blog_ .<a href="https://mediastudies.hypotheses.org/1219">https://mediastudies.hypotheses.org/1219</a>(2019).
</li>
<li id="pearlman2009">Pearlman, K. _Cutting rhythms: Shaping the film edit_ . Focal Press, New York/London (2009).
</li>
<li id="petersohn2008">Petersohn, C. “Logical unit and scene detection: a comparative survey” . In _Proceedings SPIE 6820, Multimedia Content Access: Algorithms and Systems II_ , 682002 (2008).
</li>
<li id="petersohn2009">Petersohn, C. “Temporal video structuring for preservation and annotation of video content” . In _16th IEEE International Conference on Image Processing (ICIP)_ , Cairo (2009): 93–96.
</li>
<li id="plessner1982">Plessner, H. “Deutung des mimischen Ausdrucks. Ein Beitrag zur Lehre vom Bewußtsein des anderen Ichs” . In H. Plessner, _Gesammelte Schriften VII_ . Suhrkamp, Frankfurt / M. (1982): 67–130.
</li>
<li id="pogodda2018">Pogodda, C. “Medientechnologie und Affekt in den Inszenierungen des Irakkrieges” . Ph.D. thesis, Freie Universität Berlin (2018).
</li>
<li id="russakovsky2015">Russakovsky, O. Deng, J. Su, H. Krause, J. Satheesh, S. Ma, S. Huang, Z. Karpathy, A. Khosla, A. Bernstein, M. Berg, A. C. and Fei-Fei, L. “ImageNet Large Scale Visual Recognition Challenge” . In _Int. J. Comput. Vis._ , 115.3 (2015): 211–252.
</li>
<li id="salt1983">Salt, B. _Film Style and Technology: History and Analysis_ . Starword, London (1983).
</li>
<li id="scherer2014">Scherer, T., Greifenstein, S, and Kappelhoff, H. “Expressive Movements in Audiovisual Media. Modulating Affective Experience” . In C.Müller, A. Cienki, E. Fricke, S. H. Ladewig, D. McNeill, and J. Bressem (eds), _Body – Language – Communication. An International Handbook on Multimodality in Human Interaction_ , De Gruyter Mouton, Berlin/Boston (2014): 2081–2092.
</li>
<li id="schmitt2020">Schmitt, C. _Wahrnehmen, fühlen, verstehen. Metaphorisieren und audiovisuelle Bilder_ . De Gruyter, Berlin/Boston (2020).
</li>
<li id="schmitt2014">Schmitt,C., Greifenstein, S. and Kappelhoff, H. “Expressive Movement and Metaphoric Meaning Making in Audio-Visual Media” . In C.Müller, A. Cienki, E. Fricke, S. H. Ladewig, D. McNeill, and J. Bressem (eds), _Body – Language – Communication. An International Handbook on Multimodality in Human Interaction_ , De Gruyter Mouton, Berlin/Boston (2014): 2092–2112.
</li>
<li id="schoch2013">Schöch, C. and Jannidis, F. “Quantitative Text Analysis for Literary History – Report on a DARIAH-DE Expert Workshop” . _DARIAH-DE Working Papers_ , 2 (2013).
</li>
<li id="simmel1959">Simmel, G. “The Aesthetic Significance of the Face” . In K. H. Wolff, _Georg Simmel, 1858–1901. A Collection of Essays, with Translations and a Bibliography_ . Ohio State University Press, Columbus, OH (1959[1901]): 276–281.
</li>
<li id="simmel1993">Simmel, G. “Aesthetik des Porträts” . In R. Kramme and A. Cavalli, _Aufsätze und Abhandlungen, 1901–1908_ . Suhrkamp, Frankfurt/M (1993[1905]): 321–332.
</li>
<li id="sobchack1992">Sobchack, V. _The Address of the Eye. A Phenomenology of Film Experience_ . Princeton University Press, Princeton NJ (1992).
</li>
<li id="stern1985">Stern, D. _The Interpersonal World of the Infant_ . Basic Books, New York (1985).
</li>
<li id="stern2010">Stern, D. _Forms of Vitality: Exploring Dynamic Experience in Psychology, the Arts, Psychotherapy, and Development_ . Oxford University Press, Oxford (2010).
</li>
<li id="stratil2020">Stratil, J. “ Ja es ist wieder Zeit für so ein Video . Zur rhetorischen Situation und audiovisuellen Adressierung des Rezo-YouTube-Videos Die Zerstörung der CDU ” . _mediaesthetics_ , 3 (2020),<a href="https://www.mediaesthetics.org/index.php/mae/article/view/83/207">https://www.mediaesthetics.org/index.php/mae/article/view/83/207</a>.
</li>
<li id="su2005">Su, Y., Sun, M.-T. and Hsu, V. “Global motion estimation from coarsely sampled motion vector field and the applications” . In _IEEE Transactions on Circuits and Systems for Video Technology_ , 15.2 (2005).
</li>
<li id="szeliski2011">Szeliski, R. _Computer Vision_ . Springer, London (2011).
</li>
<li id="tan1996">Tan, E. S. _Emotion and the Structure of Narrative Film. Film as an Emotion Machine_ . Erlbaum, Mahwah, NJ (1996).
</li>
<li id="tsivian2009">Tsivian, Y. “Cinemetrics, part of the humanities’ cyberinfrastructure” . In M. Ross, M. Grauer and B. Freisleben (eds.), _Digital tools in media studies: Analysis and research_ , transcript, Bielefeld (2009): 93–100.
</li>
<li id="verhoeven2016">Verhoeven, D. “Show Me the History! Big Data Goes to the Movies” . In C. R. Acland and Eric Hoyt (eds), _The Arclight Guidebook to Media History and the Digital Humanities_ , London (2016).
</li>
<li id="wundt1880">Wundt, W. _Grundzüge der physiologischen Psychologie_ . Vol 2. Wilhelm Engelmann, Leipzig (1880), 418.
</li>
<li id="wundt1896">Wundt, W. _Grundriss der Psychologie_ . Wilhelm Engelmann, Leipzig (1896), 198.
</li>
<li id="yosinski2014">Yosinski, J. Clune, J. Bengio,Y. and Lipson, H. “How transferable are features in deep neural networks?” In _Adv. Neural Inf. Process. Syst_ . 27 (Proceedings NIPS) (2014): 1–9.
</li>
<li id="zhang1999">Zhang, T. and Tomasi, C. “Fast, robust, and consistent camera motion estimation” . _IEEE Computer Society Conference on Computer Vision and Pattern Recognition_ 1999.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Burdick et al. write: “Rather than pitting distant reading against close reading, what we are seeing is the emergence of new conjunctions between the macro and the micro, general surface trends and deep hermeneutic inquiry, the global view from above and the local view on the ground” <a class="footnote-ref" href="#burdick2016"> [burdick2016] </a>. In line with this reasoning, our interest is to investigate “new conjunctions between the macro and the micro” with a focus on questions of aesthetic experience.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Of course every analytical approach to arts and media includes forms of abstraction due to the mere fact of conceptualization and verbalization, but we would like to give weight to the difference between abstractions that aim at processes of embodied and situated reception as their primary data and abstractions that treat the coded data-sets as their primary object<a class="footnote-ref" href="#drucker2016"> [drucker2016] </a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Members of the AdA-project are Jan-Hendrik Bakels, Thomas Scherer, Jasper Stratil (Freie Universität Berlin), Henning Agt-Rickauer and Christian Hentschel (Hasso-Plattner Institut) with project mentoring by Hermann Kappelhoff (Freie Universität Berlin) and Harald Sack (FIZ Karlsruhe/ Hasso-Plattner Institut). Associated Members are Matthias Grotkopp (Freie Universität Berlin) and Olivier Aubert (Université de Nantes). The project is funded by the German Ministry of Education and Research (BMBF), Dez. 2016 – Nov. 2020. See also:<a href="http://www.ada.cinepoetics.fu-berlin.de/en/index.html">http://www.ada.cinepoetics.fu-berlin.de/en/index.html</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>We draw upon a wider context of research, see e.g.<a href="#apostolidis2014">Apostolidis and Mezaris 2014</a>,<a href="#petersohn2008">Petersohn 2008</a>,<a href="#peresohn2009">Petersohn 2009</a>,<a href="#mashtalir2011">Mashtalir and Mikhnova 2011</a>,<a href="#szeliski2011">Szeliski 2011</a>,<a href="#krizhevsky2012">Krizhevsky 2012</a>,<a href="#russakovsky2015">Russakovsky et al. 2015</a>,<a href="#yosinski2014">Yosinski et al. 2014</a>,<a href="#datta2006">Datta et al. 2006</a>,<a href="#su2005">Su et al. 2005</a>,<a href="#zhang1999">Zhang and Tomasi 1999</a>,<a href="#hentschel2013">Hentschel et al. 2013</a>,<a href="#agt2013">Agt and Kutsche 2013</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>The eMAEX (short for <em>electronically based media analysis of expressive movement images</em> ) system was developed by a group of film scholars led by Hermann Kappelhoff at Freie Universität Berlin. For more information see:<a href="https://www.empirische-medienaesthetik.fu-berlin.de/en/emaex-system/emaex_kurzversion/index.html">https://www.empirische-medienaesthetik.fu-berlin.de/en/emaex-system/emaex_kurzversion/index.html</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>The following exemplary study focuses on a scene from a contemporary Hollywood feature film. However, the eMAEX system has been among others applied to feature films from different genres, regions and historical periods, documentary and propaganda films, film and TV-news, short and long web video formats, animation films and advertisements: there have been studies on Hollywood war films from the 1940s until today<a class="footnote-ref" href="#kappelhoff2018a"> [kappelhoff2018a] </a><a class="footnote-ref" href="#kappelhoff2013"> [kappelhoff2013] </a><a class="footnote-ref" href="#scherer2014"> [scherer2014] </a>, contemporary German arthouse cinema<a class="footnote-ref" href="#schmitt2020"> [schmitt2020] </a>, Hollywood auteur cinema (contemporary<a class="footnote-ref" href="#bakels2017"> [bakels2017] </a>; paranoia cinema from the 70s<a class="footnote-ref" href="#lehmann2017"> [lehmann2017] </a>), 1940s screwball comedies<a class="footnote-ref" href="#greifenstein2020"> [greifenstein2020] </a>, French silent films<a class="footnote-ref" href="#berger2019"> [berger2019] </a>, film noir<a class="footnote-ref" href="#muller2018"> [muller2018] </a>, documentaries (climate change<a class="footnote-ref" href="#grotkopp2017"> [grotkopp2017] </a>; Iraq war documentaries<a class="footnote-ref" href="#pogodda2018"> [pogodda2018] </a>); German tv news<a class="footnote-ref" href="#muller2018"> [muller2018] </a>, American newsreels from the 1940s<a class="footnote-ref" href="#gaertner2016"> [gaertner2016] </a>, commercial advertisement<a class="footnote-ref" href="#schmitt2020"> [schmitt2020] </a>, political advertisement from Germany and Poland<a class="footnote-ref" href="#horst2018"> [horst2018] </a>, as well as animation film (<a class="footnote-ref" href="#kappelhoff2018b"> [kappelhoff2018b] </a>,<a class="footnote-ref" href="#hochschild"> [hochschild] </a>) and web video formats (YouTube vlog<a class="footnote-ref" href="#stratil2020"> [stratil2020] </a>; online activism<a class="footnote-ref" href="#bakels"> [bakels] </a>).&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>In order to segment a film into scenes, at least three expert annotators with prior film analytical expertise segment each film into scenes. These protocols are then merged. Guiding for this segmentation are narrative clusters (indicated through leaps in diegetic time or a change of settings), thematic and discourse units as well as audio-visual units (e.g. with fade-to-blacks or music usage as prominent markers, but also more complex changes in the staging mode, e.g. from a fast-paced action-sequence to a shot-reverse-shot conversation). In other contexts, scenes are defined along paratexts from the production (screenplays) or publication (DVD/Bluray-chapters). Since these divisions are often not congruent with each other and exclude the viewer experience completely, they are not applicable to our research focus.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>An ideology-critical reading of the film <em>The Company Men</em> (John Wells, USA 2010) as a whole and its conservative take on gender roles and economics can be found in<a class="footnote-ref" href="#kinkle2011"> [kinkle2011] </a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>In regard to the practical limits of the film analytical method, the turn to the field of digital video-analysis tools is closely connected with the hope for saving time: the qualitative description of audio-visual sequences (e.g. within the eMAEX framework) is extremely time consuming. Analyzing a film or video in most cases takes a multiple of their running times. And the manual annotation on a high number of formal levels within a large corpus of audio-visual material threatens to be no less time-consuming. However the emerging field of video analysis and retrieval within the computational sciences has developed a lot of tools for (semi-)automatically analyzing formal aspects of audio-visual material.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>See Endnote 6.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Various video-annotation software in the past decades have developed different approaches to creating working environments with different emphases: From collaborative live-tagging of videos (LookAt, OpenVideoAnnotation, TRAVIS) to the depiction of automatic concept detection (VATIC), the coding of audiovisual data in the tradition of empirical social research (MAXQDA, AQUAD), real-time annotators for shot frequency and field size (Cinemetrics), the measurement of specific aspects of a film (e.g. shot length in Cinemetrics) to layer based tools for complex annotations with free text or controlled vocabularies (ADVENE, ANVIL, ELAN, VIAN). Researchers interested in complex, dynamic and multimodal film analysis have mainly used the latter. Especially the timeline of a film, a video player and visually separated annotation layers for observations in different description levels provide the backbone of most annotation programs used in the field. These interfaces are similar to those of popular video editing programs like Adobe Premiere, Final Cut or Avid (that are also sometimes transformed into annotation programs by scholars, c.f.<a href="#jacobs2016">Jacobs and Fyfe 2016</a>). The timeline indicates in this sense the relevance of the aspect of temporality for the analysis of audiovisual images that can be also seen governing the central principle of (temporal) segmentation put at work in our praxis of video annotation. Besides the graphically adjustable timeline especially the in-application generation of visualizations and multimedia publications were decisive factors for our initial choice for Advene.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>The question of segmentation is not only relevant to macro units – scenes or compositional segments that can only be grasped cross-modaly like the EMU –, but is raised by every single annotation on any level of description.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>As an example for film-analytical key concepts, the basic distinctions of mise-en-scene, cinematography, editing, sound that can be found in propaedeutic literature on film analysis<a class="footnote-ref" href="#bordwell2013"> [bordwell2013] </a><a class="footnote-ref" href="#corrigan2012"> [corrigan2012] </a>can serve as points of orientation.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>We slightly adapted the basic levels of the eMAEX framework: e.g. we transformedgestures and facial expressiontoBodilyExpressivityor added the levelLanguagefor the semantic dimension of written and spoken word, due to its heightened role in TV-news and some documentaries. The levelSegmentationaddresses macro-units (e.g. scenes and EMUs). The basic division into subunits (scenes and shots) is undertaken prior to splitting up the film into various packages along the scene-units to allow a synchronous annotation by multiple annotators; the segmentation into EMUs is carried out later in this revised process, based on the detailed annotation data.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>In some annotation types, we refer to concepts that derive from the specific films and cannot be anticipated beforehand; in other cases longer sentences are needed to describe more complex figurations that oppose the restrictions of a defined vocabulary. Also, free text can always be added for every annotation type that features fixed values in order to maintain the possibility of adding further analytical observations.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>The AdA filmontology aims at meeting the demands of a methodology based on the premises of expressive movement analysis but is not predetermined by our specific research question in such a way that it excludes researchers working with different assumptions. It is our hope that it can be deployed as a starting point for a toolbox that offers a basic framework for the empirical study of audio-visual composition or as a reference data set for film analytical tools.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Annotation levels, annotation types and annotation values are machine readable concepts with attached labels in natural language. Thus it is possible to refer in different languages to the same concepts. So far we have implemented identifiers and definitions for each concept in English and German.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>To give an example for the extension of segments: we defined guidelines for identifying shot overarching color spaces instead of annotating color types for each single shot.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Let alone the factor that subtitles often do not offer word-by-word accounts of the actually spoken dialogue.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Yet, especially the mapping of easily understandable color descriptions likedark bluewith detector results that provide numeric color ranges in different color systems remains a main obstacle on the path towards (semi-)automatization.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>We thank our student assistants and expert annotators Anton Buzal, Yvonne Pfeilschifter, João Prado, Maximilian Steck und Rebecca Zorko (all Freie Universität Berlin) for their patience, critical minds and curiosity.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>A scene segmentation that was first performed by three expert annotators independently and later combined, divided the whole film into 49 scenes. The shot recognition was done by two different shot detection logarithms. These results were corrected and merged by two annotators. This process led to a division of the film into 1206 individual shots. The whole film was then segmented in the individual scenes and shared within a group of four trained annotators.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>A table view of one single annotation type allows for an easy reading of annotation values within this type, but not for examining possible interrelations with values referring to another annotation type. Also the temporal dynamics these values reflect with regard to a larger segment will be more difficult to grasp.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Regarding the contextualization of single values for example, a two second closeup within a series of close shots is to be considered significantly different with regard to viewer addressation than a twenty second closeup after a series of long shots.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Please note that some browsers have problems loading this page. We recommend Firefox.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p><a href="http://ada.filmontology.org/explorer/">http://ada.filmontology.org/explorer/</a>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>See<a href="https://frametrail.org/">https://frametrail.org/</a>.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>It is important to note that the scene’s segmentation can be based solely on rhythmic patterns that indicate how the scene is staged, and not necessarily on represented content like the setting or narratively constructed diegetic time frames – even though these aspects often concur.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Bodily expressivityis defined in the AdA filmontology as: “Expressivity of bodies that are perceived as communicating bodies (e.g. humans, animals, anthropomorphic machines). The expressivity is not understood as a speculation about an assumed subjectivity, but as perceived surface phenomena of gestures, facial expressions and postures.”&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Montageis defined in the AdA filmontology as: “Staging strategies that only result from the interrelation of two or more shots. Montage refers here to the cutting of subsequent or co-occurring shots, as well as to the assemblage of sequences as temporal gestalts. The emphasis is on visual editing, sound editing is primarily annotated under acoustics. ”&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Acousticsis defined in the AdA filmontology as: “This level encompasses all annotation types that refer to the staging of expressive acoustic phenomena like music, sound design, or the expressive qualities of spoken language.”&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>BodyLanguageIntensityis defined in the AdA filmontology as: “Perceived degree of dynamicity and tension in an affective expression regarding the body language (gestures, posture, as well as facial expression) of central figures within the image. It can also involve an inward-oriented form of tension, such as repressed anger. This annotation type provides a scale for the intensity of body language. Conflicting intensities (e.g. different figures in the image or a difference between gestures and facial expressions) can be related as conflicting in the sense of a versus with [VS].”&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>ShotDurationis defined in the AdA filmontology as: “The temporal duration of a shot. A shot of a film is a perceivable continuous image and is bound by a discontinuation of the entire composition. (Fuxjäger: Wenn Filmwissenschaftler versuchen, sich Maschinen verständlich zu machen, 2009, own translation). In this annotation type, the shot duration is stated in seconds.”&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>MusicIntensityis defined in the Ada filmontology as: “Perceived degree of the intensity of an (affective) expression of music, e.g. regarding volume, dynamics, instrumentation. This annotation type provides a scale for the intensity in a coherent segment of music (either a piece or a part of it).”&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Image Brightness is defined in the AdA filmontology as: “Perceived light intensity of a shot. This annotation type provides a rating scale for image brightness that refers to film-intrinsic variations and not to absolute values.”&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>ColourRangeis defined in the AdA filmontology as: “The perceived range of (main) colours in a sequence. In this annotation type, for the purpose of comparability, colours have to be picked from a reduced set of colours. A description of the colour impression is combined with a hex color code of the corresponding colour value as a reference.”&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>CameraMovementSpeedis defined in the AdA filmontology as: “Perceived degree of the (relative) movement speed of the camera. This annotation type provides a scale for the perceived camera speed from slow to fast.”&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>ImageIntrinsicMovementis defined in the AdA filmontology as: “Perceived overall degree of movement of all things within the frame. This annotation type provides a scale from static to very dynamic for the rating of image-intrinsic movement.”&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Defined in the AdA filmontology as: “The Field Size is determined by the perceived size relation between a central object and the framing of a shot. This relation can be perceived as the distance towards an object of reference or how much of the centred subject in a shot and its surrounding is visible and thereby establishes the distance/proximity of the spectator to the events. Besides human bodies, reference objects can also be other figures (e.g. animals, machines). The spectrum is divided into 8 different field sizes from wide to near in accordance with Faulstich: Grundkurs Filmanalyse, 2002, Hickethier: Film- und Fernsehanalyse, 2001, Mikos: Film- und Fernsehanalyse, 2003. Additionally, there is a category for shots without a distinct reference object.” For further definitions of each value see<a href="http://ada.filmontology.org/resource/2020/03/17/AnnotationType/FieldSize.html">http://ada.filmontology.org/resource/2020/03/17/AnnotationType/FieldSize.html</a>.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Defined in the AdA filmontology as: “ Dialogue Text refers to the understandable, spoken language on the audio track of a film. This usually refers to dialogue, off-commentary, but also spoken chorus. This annotation type provides a transcript of these utterances. A change of speaker or a pause marks the beginning of a new transcription unit.”&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>Defined in the AdA filmontology as: “ Music Mood refers to the perceived emotional state conveyed in a music piece. This annotation type provides a basic classification of the general mood that is conveyed in a coherent segment of music (either a piece or a part of it).” ## Bibliography&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Methods and Advanced Tools for the Analysis of Film Colors in Digital Humanities</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000500/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000500/</id><author><name>Barbara Flueckiger</name></author><author><name>Gaudenz Halter</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="1-introduction">1 Introduction</h2>
<p>Film colors are one of the most difficult aspects for the analysis of film style, but — as this paper will elaborate — also a most rewarding one. A long neglected topic in film studies, film colors have gained increasing attention during the last decade. Following the advent of digital methods in recent years, in-depth studies about the history, uses, underpinning concepts and their theoretical and epistemological reflection in digital humanities have been published by<a href="#stutz2016">Olivia Kristina Stutz (2016)</a>,<a href="#heftberger2016">Adelheid Heftberger (2016</a>,<a href="#heftberger2018">2018</a>),<a href="#olesen2017">Christian Gosvig Olesen (2017)</a>. Increasingly there is a discourse around the development of digital approaches, methods, and tools for film analysis. Stutz (2016) and Olesen (2017) pay specific attention to the question of color analyses.<a href="#ferguson2013">Kevin Ferguson (2013</a>and<a href="#ferguson2015">2015</a>),<a href="#manovich2013">Lev Manovich (2013</a>and<a href="#manovich2015">2015</a>) and<a href="#reyes-garcia2014">Everardo Reyes-García (2014</a>and<a href="#reyes-garcia2017">2017</a>) have developed specific visualization methods for art works, paintings and film in particular. Pause and Walkowski’s work on computer-assisted color analysis is drawing on our own work<a class="footnote-ref" href="#pause2018"> [pause2018] </a>.</p>
<p>Traditional analyses of film colors were mostly based on verbal description. They showed a tendency toward hermeneutical interpretation while aesthetic and affective dimensions were often neglected.</p>
<p>With the development of database-driven analysis, deep-learning tools and a large range of visualizations the research project ERC Advanced Grant <em>FilmColors</em> (see<a href="#acknowledgements">Acknowledgements</a>) aims at providing a more comprehensive approach to analyze the manifold aspects of color in film.</p>
<p>Therefore the central argument of this paper focuses on the combination of a set of strong theoretical and analytical concepts including human interpretation that connects the various instances of film colors’ stylistic, expressive and narrative dimensions to the development and evaluation of digital methods.</p>
<p>It is a widespread misconception that digital tools generate meaningful results in an automated fashion. Theoretically sound reasoning and the constant reflection of visualization methods, their epistemological and perceptual underpinnings is a mandatory requirement that must govern any interdisciplinary collaboration between film studies and computer science, see our previous papers for a more extended discussion of these prerequisites and their connection to experimental aesthetics<a class="footnote-ref" href="#flueckiger2011"> [flueckiger2011] </a><a class="footnote-ref" href="#flueckiger2017"> [flueckiger2017] </a><a class="footnote-ref" href="#flueckiger2018"> [flueckiger2018] </a>. By contrast to the previous papers, this article intends to provide insights into the many methods, obstacles, advances, problems and lessons learned during the collaborative development of the tools.</p>
<p>Integral part of the research projects is the <em>Timeline of Historical Film Colors</em> (<a href="https://filmcolors.org">https://filmcolors.org</a>) — an interactive, comprehensive web resource on film colors that has been created and curated by Barbara Flueckiger since 2012<a class="footnote-ref" href="#flueckiger2012"> [flueckiger2012] </a>.</p>
<h2 id="2-database-driven-analysis-analytical-concepts-and-evaluation">2 Database-driven Analysis, Analytical Concepts and Evaluation</h2>
<p>Overarching goal of the research project’s interdisciplinary perspective is the investigation of the relationship between the aesthetics and technology of film colors. To this end, a large group of more than 400 films produced between 1895 and 1995 were analyzed in a highly detailed way with a computer-assisted approach. It combined temporal segmentation by the video annotation tool ELAN (first released in 2002) with a database-driven protocol consisting of a controlled vocabulary of around 1.200 theoretical and analytical concepts for the annotation of each segment. A network of custom-made relational databases for the analysis, filmographic data, glossary and evaluation of results (see<a href="#figure07">Figure 7</a>) was programmed in FileMaker to a large extent by the PI herself with input from her team. Despite the fact that FileMaker has its weaknesses and limitations in terms of programmability and flexibility the self-sufficient adaptation and development of the databases according to the evolving requirements of the analyses remained the most significant advantage throughout the project. Increasingly, the databases were linked with each other by relational connections to deliver meaningful results and to provide instant access to a variety of evaluation methods of the data gathered (see<a href="#section03">Section 3</a>).</p>
<p>The team distinguished several levels of analysis, from screenshots to temporal segments of individual films ( “micro level” ), individual films as a whole ( “meso level” ), and over the whole corpus or selected sub-corpora ( “macro level” ), see<a href="#olesen2016">Olesen (2016)</a>.</p>
<p>Filmographic data has been collected to represent the whole corpus of films, to define corpus selection and assignment to individual researchers and to keep track of the processing state. Corpora were selected based on research into monographs and articles on film colors, with each of the PhD candidates’ setting their own focus in the three periods1895 to 1930, 1930 to 1955, and 1955 to 1995. Guiding principles for selection criteria aim at a comparison between canonical works, famous for their elaborate or bold color design with lesser known works to form sub-groups for specific film color processes, genres, for individual filmmakers, cinematographers, color consultants, or countries. In line with historical poetics<a class="footnote-ref" href="#bordwell1989"> [bordwell1989] </a>and neo-formalist analysis established by the Wisconsin school of Kristin Thompson and David Bordwell<a class="footnote-ref" href="#thompson1988"> [thompson1988] </a><a class="footnote-ref" href="#bordwell1985"> [bordwell1985] </a>, the corpora should enable thediachronic analysisof personal styles, institutional contexts — for instance changing professional norms, cultural preferences, notions of taste — or technological innovation over time, but also asynchronic comparisonbetween these different instances at a given period.</p>
<p>Stock identification, research into technical innovation, detailed information about color processes applied to each film play an important part for a better understanding of these connections and allow to circumvent misconceptions present in previous literature. These research methods are completed by scientific measurements of film stocks’ spectral characteristics to enable improved methods for the digitization and restoration of analog film colors. Such a comprehensive approach that connects insights into aesthetic developments with a deep investigation into technological innovation has been called a “technobole approach” by Frank Beau (2002). Contrary to technical determinism thetechnobole approachthat stays at the center of our method is paying attention to epistemological, institutional, social, cultural and economic factors that govern technical advances and how technology in turn feeds back into culture and society. This cultural perspective is investigated thoroughly in the PI’s second research project <em>Film Colors. Technologies, Cultures, Institutions</em> .</p>
<p>A three-level model that complies with recommended metadata schemes established for film archives by standardization entities such as FIAF or<a href="http://www.filmstandards.org">filmstandards.org</a>has been implemented into the corpus database by team member Joëlle Kost. It allows the allocation of individual tokens of a single film, such as DVDs, Blu-ray or various historical film prints and negatives inspected and documented in film archives in Europe, Japan and the United States and assigns a specific tri-partite item ID to each one of them. From the start, this database was hosted on a FileMaker server provided by the University of Zurich.</p>
<p>All the films chosen for analysis were digitized and then temporally segmented with the video annotation tool ELAN (see<a href="#section04">Section 4</a>for approach and description). The resulting information — mostly time codes and numbering of the segments plus optionally basic descriptions according to a template — was then exported to an analysis database for close reading, which in turn was connected to the corpus DB for filmographic data, based on the item ID.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Sketch of the analysis and evaluation workflow with the database architecture.
        </p>
    </figcaption>
</figure>
<p>Theoretical and analytical concepts were mostly elaborated before the start of the project, during the PI’s teaching and research activities in the field of color theory, film aesthetics, semantics and narration — with a focus on film colors in the last decade. Accordingly, they were already part of the research proposal. Submitted to the ERC. During half a year of coaching and training at the beginning of the project, the team members were introduced into the concepts and were given room for extended discussions. Some concepts evolved bottom-up during the analyses and were contributed by team members based on their observations. For instance, a catalogue of basic terms for characters’ affective or emotional states were part of the initial glossary, but continuously extended by postdoc researcher Bregt Lameris who focuses on the relationship between film colors and affects. Motifs and themes were also evolving bottom-up for certain standard situations — for instance ceremonies, show numbers, metamorphoses — or topics such as exoticism, architecture, self-reference etc. They were organized in a keyword database connected to the analysis DB.</p>
<p>Eleven different registers contained a taxonomy with classes of analytical concepts, ranging from verbal descriptions of colors, color contrasts, image composition, depth-of-field, lighting, textures and patterns, surface properties and materials of characters, objects or environments in the diegesis including their tactile properties, to the materiality of films analyzed with the concept offaktura, plus movements of camera, characters, objects, and lighting.</p>
<p>For each temporal segment of the films — usually between 50 and 70 segments per film — the team went through the whole range of analytical concepts in the analysis DB and added up to 32 relevant screenshots into media containers.</p>
<p>All the theoretical and analytical concepts of the controlled vocabulary — more than 1.200 including hues — were continuously defined in a glossary database with references to sources, if available, and illustrated with exemplary screenshots gathered during the analyses.</p>
<p>From the start we were thinking about how these concepts could be processed with advanced tools for automatic data extraction, and this question guides the development of deep learning tools to this day (see Sections 4 to 9). It goes without saying that not all of them can easily be solved with the current state-of-art and limited resources even within an ERC research project of this scope. On the other hand — as stated above — it is the central credo of the project’s comprehensive approach that it aims at a qualitative analysis that focuses on the contextualization of observations by human intervention and interpretation. By their very nature, automatic approaches to image processing are not able to identify subtle details and idiosyncrasies, for instance that curtains moving slightly in the wind might be a metaphor for the heroine’s inner turmoil as in the Japanese film Jigokumon.</p>
<p>Narratologic concepts are especially challenging for automatic assessment. Point-of-view structures that operate with the concept offocalization(<a class="footnote-ref" href="#genette1972"> [genette1972] </a><a class="footnote-ref" href="#genette1983"> [genette1983] </a>to differentiate between instances of narration, so-called focalizers or filters, are possibly very hard to identify for non-human observers, but they are very important for the investigation of film colors, including characters’ mental states in dreams or hallucinations, alignment with characters<a class="footnote-ref" href="#smith1995"> [smith1995] </a>, temporal organization of the narration such as flashbacks, summaries, mise-en-abyme, parallel montage or montage sequences, non-narrative situations, turning points, suspense and foreshadowing etc.</p>
<p>Similar challenges are in operation for phenomena of higher order semantics. By higher order semantics we understand all forms of modification of meaning that are established through intra-textual relationships, intertextual and inter-medial references or cultural uses, such as cultural contexts, milieu, taste, sociopolitical markers, stereotypes, genre conventions, character relationships, race, gender, symbols, signals, metaphors and isotopies / rhyming. Intertextual and inter-medial references for connections to other films, media or art works through pastiche, allusion, citation, irony, parody etc.<a class="footnote-ref" href="#genette1992"> [genette1992] </a><a class="footnote-ref" href="#jameson1991"> [jameson1991] </a><a class="footnote-ref" href="#dyer2006"> [dyer2006] </a>.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Higher order semantics in color design: pastiche in Blood and Sand (USA 1941, Rouben Mamoulian)(left)  and sociopolitical markers that indicate status and period  in <em>The Private Lives of Elizabeth and Essex</em> (USA 1939, Michael Curtiz) (right).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Higher order semantics in color design: pastiche in Blood and Sand (USA 1941, Rouben Mamoulian)(left)  and sociopolitical markers that indicate status and period  in <em>The Private Lives of Elizabeth and Essex</em> (USA 1939, Michael Curtiz) (right).
        </p>
    </figcaption>
</figure>
<p>Emotions and affects relate to characters’ inner states — joy, sadness, anger, hate, disgust — or emotional relationships such as love, conflict, sex, but also for cross-modal relationships of visual representations to smell, taste or touch. In addition, there are basic theoretical concepts for emotional and affective responses such as direct affect<a class="footnote-ref" href="#plantinga2009"> [plantinga2009] </a>, contagion, artefact emotion, mimicry, plus aesthetic categories that address the senses such as excess<a class="footnote-ref" href="#thompson1986"> [thompson1986] </a>, artefact emotion<a class="footnote-ref" href="#tan1996"> [tan1996] </a>, atmosphere,Stimmungor mood.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Excess in <em>King of Jazz</em> (USA 1930, John Murray Anderson; Pál Fejös) (above) and   <em>Die bitteren Tränen der Petra von Kant</em> (GER 1972, Rainer Werner Fassbinder) (below).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Excess in <em>King of Jazz</em> (USA 1930, John Murray Anderson; Pál Fejös) (above) and   <em>Die bitteren Tränen der Petra von Kant</em> (GER 1972, Rainer Werner Fassbinder) (below).
        </p>
    </figcaption>
</figure>
<p>In the domain of color identification, however, computer-based approaches are superior to human observation, even if it is necessary to stress the fact that the results of these analyses also need human interpretation.</p>
<p>In our analysis DB, colors were verbally described as dominant hues for the entire scene, female and male protagonists and supporting characters, background and foreground, inter-titles and letters, including general observations on saturation, lightness etc. It is obvious that such verbal descriptions are very limited, they do not take into account the subtle shades of each color of a certain range as various types of hues, levels of saturation or brightness.</p>
<p>By color schemes — often calledcolor palettes— we denote the overall distribution of color in an image or in a temporal segment according to the variations of hues, saturation, warmth or lightness, such as monochrome restrictive, muted, gaudy, saturated etc. Types can occur simultaneously, for instance a monochrome color scheme can also be warm or saturated. As we will elaborate in a later section (see<a href="#section07">Section 7</a>) our methods for the identification of color schemes with deep learning tools are both superior, more refined than verbal descriptions and yield highly significant results, if, again, they are connected to the concepts elaborated above.</p>
<p>Color contrasts refer to an established set defined by artist and scholar Johannes Itten to describe specific relationships of color harmonies, color “chords,” or spatial distribution, again correlated to the dimensions of hue, saturation and lightness as organized in Itten’s “Farbstern” (color star)<a class="footnote-ref" href="#itten1970"> [itten1970] </a>. For instance, the most ubiquitous color contrast in the recent decade has been the orange–teal combination that is both a cold–warm and complementary contrast plus it contains a light–dark variation since yellow is perceived as brighter than blue.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Some exemplary screenshots for the conceptcold-warm contrastin the glossary DB.
        </p>
    </figcaption>
</figure>
<p>The identification of color contrasts and color schemes has long been a field of computer analysis. As we will discuss (see<a href="#section07">Section 7</a>), however, most of these approaches do not comply with the demands of aesthetic analysis in terms of differentiation, flexibility and subtlety. Some of them were established for normative purposes, to identify ‘good’ uses of color harmonies for design, or to give a rough, albeit pleasing visualization for film geeks, such as MovieBarcodes.</p>
<h2 id="21-problems">2.1 Problems</h2>
<p>Consistently the biggest challenge was the level of complexity for all the team members working on the film analyses. Overall the process was perceived as extremely time consuming. Following a first evaluation after several months into the project, the concepts were separated into the most relevant ones vs. the rarer ones. Team members also showed difficulties to work on such extended catalogues of concepts that were only randomly ordered by relevance. Therefore they devised ordered lists sorted according to thematic coherence, which helped finding the checkbox in a more intuitive way. Finally we ended up establishing individual layouts for each team member to take their personal focus into account. However, this approach resulted in a much more complex database architecture to collect and evaluate all the data.</p>
<h2 id="22-lessons-learned">2.2 Lessons learned</h2>
<p>Informed by the constantly evolving workflow and database architecture the crowdsourcing platform for external users<a class="footnote-ref" href="#flueckiger2018"> [flueckiger2018] </a><a class="footnote-ref" href="#halter2019"> [halter2019] </a>has been developed in a modular fashion, again by Gaudenz Halter with support by Silas Weber. First, concepts are being sorted according to inner relationships, for instance positive affects related to joy vs. negative affects related to depression or aggression as elaborated and refined during the development of the workflow and following the final evaluation. Second, levels of significance of concepts and levels of complexity have been established for each area of analysis, as for instance lighting or image composition. This modular design will give users the possibility to select from a menu of concepts not only the topics they are interested in, for instance color contrasts or costume design, but also the level of complexity for each of those modules individually so that the controlled vocabulary matches best their research interest.</p>
<h2 id="3-evaluation-of-the-data-gathered">3 Evaluation of the Data Gathered</h2>
<p>Resulting from the manual analysis was a massive quantity of data and screenshots, amounting to more than 17.000 segments with about 170.000 screenshots assembled in a master analysis DB and more than half a million of summations gathered in an evaluation database. This evaluation database has been connected to the glossary DB and the corpus DB, based on the glossary ID and the Item ID (see<a href="#figure01">Figure 1</a>). With these identifiers we were able to then display the results directly in the glossary DB and corpus DB respectively by portals and scripts, which turned out to be the biggest advantage of the relational database architecture. As will be discussed in a later paragraph (see<a href="#section03.1">Section 3.1</a>) there were also many problems and challenges to master.</p>
<p>In principle the results can be accessed by three ways through the FileMaker architecture and in many additional, more complex ways through the analysis and annotation tool VIAN and the online platform VIAN WebApp. The VIAN WebApp is a crowdsourcing portal that currently contains all the more than 400 analyzed films for evaluation and visualizations on segment, film and corpus level<a class="footnote-ref" href="#flueckiger2018"> [flueckiger2018] </a><a class="footnote-ref" href="#halter2019"> [halter2019] </a>. In the future, external users will have the possibility to commit their own VIAN projects. Since the database for the VIAN WebApp hosts both qualitative and numeric color information, the developers decided on a diploid database architecture for the online platform. Most of the data is hosted on a Postgres SQL database; for fast querying and processing numeric information they use a HDF5 file structure (see<a href="#halter2019">Halter et al. 2019</a>). Data are processed by cloud computing on Microsoft Azure.</p>
<p>The offline analysis VIAN is integrated into an ecosystem (see<a href="#figure05">Figure 5</a>). Individual projects are uploaded to the online platform VIAN WebApp. In return, users can download projects from the VIAN WebApp to adjust it to their own interests. In addition, the VIAN WebApp connects projects to the corresponding galleries from the <em>Timeline of Historical Film Colors</em> . Finally, the ColorMania app became an extension for visitors of the <em>Color Mania</em> exhibition at Fotomuseum Winterthur (see<a href="#figure05">Figure 5</a>).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Increasingly VIAN became part of an ecosystem consisting of the offline tool VIAN analysis and annotation software, the online platform VIAN WebApp, connected to the <em>Timeline of Historical Film Colors</em> and to the <em>ColorMania</em> exhibition app.
        </p>
    </figcaption>
</figure>
<p>All the FileMaker DBs have been exported to the VIAN WebApp database architecture. Each of the individual DBs is thus mirrored in the WebApp.</p>
<p>The corpus DB contains the results listed for each individual film, i.e. on the meso level. It corresponds to the project page on the VIAN WebApp. For each field the corpus DB lists all the occurrences within this film, including a list of all the comments made in the remark fields with the corresponding segment ID. This overview provides an instant footprint for each film and is the basis for hypotheses that lead to further investigations.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>VIAN WebApp project overview of the more than 400 analyzed films. Each project has its own page with detailed analysis and visualizations, see screen video of Paris, Texas<a href="https://vimeo.com/396548709">https://vimeo.com/396548709</a>.
        </p>
    </figcaption>
</figure>
<p>From a different angle, the results are reflected in the glossary DB based on each individual concept, with many custom-made filters for periods, corpus assignment, genres, country etc. With this perspective, it is possible to get instant information about the dominance of a narrative, semantic or aesthetic feature, a motive or location on the macro level, sorted by frequency. The glossary DB corresponds to the concepts page on the VIAN WebApp.</p>
<p>Finally the evaluation DB itself where all these results are stored allows the diachronic analysis also on the macro level across the whole corpus. It delivers diagrams of developments over time for the whole period spanning the first 100 years of film history from 1895 to 1995. For instance the development of certain lighting styles such as colored light, mood lighting or mixed lighting, of types of depth of field, of layered and complex image compositions become visible at a glance. These trends are then the foundation for hypotheses that have to be investigated in detail in the analysis DB. It is also crucial to keep in mind — as we will discuss in more detail in the problems section (see<a href="#section03.1">Section 3.1</a>) — that these results are not necessarily hard facts. They provide insights into tendencies that have then to be investigated in more detail and tested with other means of evaluation. But the results by far exceed previous traditional, often anecdotal approaches that yielded much less evidence of historical developments.</p>
<p>In line with the goal of the research project to identify correlations between technical innovation and aesthetics, the identification of diachronic patterns through digital humanities tools is the single most important foundation for new insights that surpass previous findings. It displays important connections between the technology and stylistic forms but makes also very clear that often such causal connections were overstated in the past while cultural or inter-medial influences were largely neglected. As several recent studies have shown, careful integration of colorimetric visualizations into reflections on the material aesthetics of films yield new insights into the material aesthetics of film, for instance in a recent study of Len Lye’s experimental color films of the 1930s<a class="footnote-ref" href="#flueckiger2019"> [flueckiger2019] </a>Flueckiger 2019).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Comparison of colorimetric analysis performed in VIAN gives insights into the material aesthetics of historical color films: Dufaycolor’s muted, brownish hues in <em>A Colour Box</em> (GBR 1935, Len Lye) vs. high saturation and color separation in a Gasparcolor print of <em>Colour Flight</em> (GBR 1937, Len Lye), see galleries on the <em>Timeline of Historical Film Colors</em> <a href="https://filmcolors.org/filter/?_sft_ubercategory=lye&amp;post_types=gallery">https://filmcolors.org/filter/?_sft_ubercategory=lye&amp;post_types=gallery</a>.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Comparison of colorimetric analysis performed in VIAN gives insights into the material aesthetics of historical color films: Dufaycolor’s muted, brownish hues in <em>A Colour Box</em> (GBR 1935, Len Lye) vs. high saturation and color separation in a Gasparcolor print of <em>Colour Flight</em> (GBR 1937, Len Lye), see galleries on the <em>Timeline of Historical Film Colors</em> <a href="https://filmcolors.org/filter/?_sft_ubercategory=lye&amp;post_types=gallery">https://filmcolors.org/filter/?_sft_ubercategory=lye&amp;post_types=gallery</a>.
        </p>
    </figcaption>
</figure>
<p>Increasingly the screenshots themselves became an important part of the investigation. Initially only three exemplary screenshots were embedded into the first version of the glossary DB to illustrate the concepts. Once it turned out that the glossary database is also a perfect way to organize screenshots its architecture had to be completely refurbished to embed the screenshots dynamically via a second database, glossary images DB, all of which was connected to the corpus DB. With this database architecture it became possible to write scripts for portals and to sort images according to periods, corpus assignments or typology. For the VIAN WebApp, it is mandatory to select a sample of the most representative images for external users, which is done by assigning priorities to the screenshots to sort them out. Now the FileMaker DB architecture also allows to embed the screenshots into the corpus DB to provide a selection of the most significant forms of expression through color in a specific film.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Glossary DB: Extract of a representative selection for the conceptcolored light, sorted according to different periods, sub-corpora or typologies.
        </p>
    </figcaption>
</figure>
<p>Since the team aims at capturing historical film prints of the analyzed films to get a better reference for the analyses, these photographs are then published on the <em>Timeline of Historical Film</em> . As shown in the VIAN Ecosystem the <em>Timeline</em> has been integrated into the workflow as well. A script in FileMaker connects the corresponding galleries from the <em>Timeline</em> and displays them in a browser window directly in the databases to compare the photo documentation of one or more historical film prints with the analyzed digitization from DVDs and Blu-rays. The browser window enables immediate frontend tagging of the <em>Timeline</em> photos with the thesaurus that is organizing the historical color film processes, the media, quotes, and galleries by a tagging system in the <em>Timeline</em> (see<a href="#figure09">Figure 9</a>). Furthermore, the links to the galleries on the <em>Timeline</em> are embedded into the project page of the VIAN WebApp.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Glossary images DB: Comparison of DVD screenshot (left) with photograph of historical film print of <em>Salomé</em> (USA 1922, Charles Bryant) from the <em>Timeline of Historical Film Colors</em> , integrated into the DB. Credit: George Eastman Museum. Photograph by Barbara Flueckiger.
        </p>
    </figcaption>
</figure>
<p>Increasingly all the facets of analysis have been integrated into the overarching eco system (see<a href="#figure05">Figure 5</a>and<a href="#section04">Sections 4 to 9</a>) that has guided the development of the crowd-sourcing platform and the implementation of all the facets of our research.</p>
<h2 id="31-problems">3.1 Problems</h2>
<p>As mentioned above, resulting from this work was a massive quantity of data and screenshots assembled in a master analysis DB supposed to be hosted on the FileMaker server of UZH. It turned out, however, that the server was not configured for such a demanding task, which necessitated that all the screenshots were exported, down-sized and reimported what seemed like an unsurmountable task for FileMaker due to the non-standardized nomenclature for the image files. Therefore, we ultimately decided to export each screenshot into an individual folder with a defined nomenclature consisting of item ID, image ID and shot ID that were then processed externally by Gaudenz Halter and reimported automatically with a script in FileMaker. Processing included the resizing and compression of the images as well as finding the timestamps of the screenshots within the movie. Since the exported screenshots did not exactly match the content of their corresponding frame, due to resizing and compression earlier in the pipeline, the best matching frame has been determined by application of the mean squared error. This mechanism also allows to import already existing screenshots into a VIAN project and assign them to the correct locus in the video.</p>
<p>Similar problems occurred with the evaluation of the data. Scripts in FileMaker to assemble the data in summations for each film became too complex and the process incredibly slow and vulnerable. Even the in-house FileMaker specialists and external experts could not offer solutions. Therefore, we turned to a similar workflow to export all the data, process them externally in several Python scripts organized in a pipeline. In a first step we had to migrate the complete dataset exported from FileMaker into the VIAN WebApp database architecture. We then calculated the frequencies of keywords on a per-movie basis and related correlation matrices between keywords. This step was followed by a set of successively performed steps to enrich the existing dataset with numeric color features, including the computation of color histograms, color palettes and average color values for each segment and screenshot in a figure/ground separated manner. Finally the per-movie frequencies of keywords have been reimported into FileMaker for the evaluation. Again due to the fact that each team member received their own analysis layer organized with respect to their preferences and interests there were many inconsistencies that affected minutiae such as spelling, local and global concepts etc. Even complicated by the fact that the glossary was extended over time there were internal inconsistencies affecting the connection between the tri-partite logic of the taxonomy in the glossary consisting of classes, fields and concepts, and the organization of the values in fields of the database.</p>
<h2 id="32-lessons-learned">3.2 Lessons learned</h2>
<p>To gather consistent and significant data it is mandatory to coach users as much as possible and to illustrate concepts with precise visualizations from screenshots. The glossary database thus contains a priority field to select the most informative and clear-cut screenshots for each concept, ideally at least six screenshots from different periods for each one of them. As stated before, these screenshots are instantly available on the concepts page of the VIAN WebApp (see<a href="#figure10">Figure 10</a>), so that users get a very good idea what each keyword is referring to. These catalogues of screenshots might be extended by short video clips taken from the corpus in case where movement or other changes over time are central to the concept.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>VIAN WebApp concept page: collection of exemplary screenshots for the conceptpop-out effectattributed to a figure (as opposed to objects).
        </p>
    </figcaption>
</figure>
<h2 id="4-development-of-a-visual-annotation-analysis-and-visualization-platform">4 Development of a Visual Annotation, Analysis and Visualization Platform</h2>
<p>Based on the manual annotations executed in 2016 and 2017 with the combination of ELAN and the FM DBs, a set of tools for semi-automatic and automatic color analyses and visualization of results have been developed since 2017. These tools make use of computer vision and deep learning to provide meaningful results<a class="footnote-ref" href="#flueckiger2017"> [flueckiger2017] </a><a class="footnote-ref" href="#flueckigeretal2017"> [flueckigeretal2017] </a><a class="footnote-ref" href="#flueckiger2018"> [flueckiger2018] </a><a class="footnote-ref" href="#halter2019"> [halter2019] </a>.</p>
<p>Video annotation tools were among the first approaches to apply digital methods to segment and annotate films with a set of tools, see for instance<a href="#gruber2019">Gruber et al. (2009)</a>, investigations in Giunti (<a href="#giunti2010">2010</a>;<a href="#giunti2014">2014</a>), a detailed assessment by<a href="#melgar2017">Melgar et al. (2017)</a>.</p>
<p>In 2016 we executed an extended research into all the available tools, many of which were not running on newer operating systems anymore, due to the termination of funding (see<a href="#flueckiger2017">Flueckiger 2017</a>). Finally we decided to use ELAN (see<a href="#figure11">Figure 11</a>), a video annotation tool that offers a great variety of options and is very sophisticated, but was developed with a focus on the analysis of language by the Max Planck Institute for Psycholinguistics in Nijmegen.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Video annotation system ELAN interface and template for segmentation and annotation,   <em>Pierrot le fou</em> (FRA 1965, Jean-Luc Godard).
        </p>
    </figcaption>
</figure>
<p>To overcome the limitations of this approach and to shift focus more to the perspective of visual forms of expression, a new visual video annotation system VIAN has been developed by Gaudenz Halter. In addition to several layers of video segmentation and annotation it integrates advanced methods for the analysis and visualization of film colors and is suited for large scale classification of film content.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>VIAN segmentation layer with screenshot manager, <em>Sedmikrásky</em> [ <em>Daisies</em> ] (CZE 1966, Vera Chytilová).
        </p>
    </figcaption>
</figure>
<p>VIAN is a tier-based film annotation software that places emphasis on visual aspects of film style and its color aesthetics, allowing the user to perform general annotation tasks as well as numeric analysis of film material. VIAN has been developed to not only provide data for the crowd-sourcing tool VIAN WebApp that combines our developed analysis pipeline into one software, but also to be flexibly used in other research projects with different film-analytical topics. In essence it consists of several crucial ingredients: Screenshot management, classification by large vocabularies, a toolset for color analysis and visualizations, for a basic overview see several tutorials for the VIAN annotation tool:<a href="vimeo.com/user/70756694/folder/1220854">vimeo.com/user/70756694/folder/1220854</a>.</p>
<p>Previous annotation tools do, to the best of our knowledge, not implement ascreenshot management system, thus screenshots usually have to be exported and managed by the user in the file system, an obviously difficult and error prone task with an increasing number of screenshots. However, as stated earlier, screenshots play a key role in the visual assessment of films. Therefore, screenshots have become a central type of annotation that can be created in VIAN. Apart from screenshots, VIAN also provides temporal segments and vector graphic annotations. The latter describe annotations that can be drawn directly on screen, currently these are ellipses, rectangles, images, text and free-hand drawings.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>VIAN&rsquo;s analysis widget contains the controlled vocabulary developed during the manual analyses  and defined in the glossary DB and on the concept page on the VIAN WebApp. _ Paris, Texas_ (DEU / FRA 1984, Wim Wenders).
        </p>
    </figcaption>
</figure>
<p>As mentioned before (see<a href="#section02">Section 2</a>), our project included the classification of a large amount of segments by over 1.200 concepts using FileMaker. With respect to the VIAN WebApp crowd-sourcing tool, this functionality has been implemented into VIAN also. By contrast to many other film annotation software packages, VIAN makes a clear distinction between natural language-based annotation andclassificationbased on vocabularies that have been established and tested in the manual corpus analysis. Descriptions are performed by simply typing the respective annotation into the temporal segment or as vector graphic annotation onto the screen. The latter, however, is performed within VIAN’s classification system. Once a user has created one or several annotations consisting of screenshots, temporal segments or vector graphic annotations they can be classified by the vocabularies defined in the glossary. VIAN also allows the user to define the conceptual entity, so calledclassification objectsthat are classified explicitly with one or more vocabularies. For example, the conceptsaturatedcould target the classification objectmale protagonistandfemale protagonist.Color features can be extracted for an annotation to create visualizations that yield insights into the colorimetric context of screenshots, temporal segments or regions within the frame. Furthermore, VIAN automatically computes several measures in an evenly spaced manner for the complete movie to directly display the most important color features while scrubbing through or watching a video.</p>
<p>Implemented in Python, we have put strong focus into the extendibility such that scholars can easily extend VIAN’s functionality to suit the needs of their research questions or using it as a Python API.</p>
<h2 id="41-problems">4.1 Problems</h2>
<p>The development of VIAN has been an iterative process of development and testing with the research team. Obviously, a large number of design questions arise during such a process, especially when the number of requirements and tasks are as large as in the case of the film colors research. Clearly, there are numerous questions related to the software architecture and implementation of tools, but we have also found that developing an easy to use software can be challenging. One of the major difficulties regarding the architecture of VIAN has been to develop a software that solves the very specific need of our research project while remaining generic to be used for other projects and research topics.</p>
<p>Another difficulty was related to the efficient storage of the data. Most annotation tools use a human-readable file format such as XML or JSON to store the generated data permanently. These formats have the advantage that the data can easily be read even without the source tool at hand and improve interoperability. However, numeric data as generated and operated by VIAN had to be stored in a faster accessible file format. During the development we tried several approaches. We started with a simple JSON file. Once the numeric data became too large, we migrated to an SQLite database. This approach did however not scale well enough, finally we implemented a hybrid system using a human-readable JSON file for the annotations and project structure and an optimized HDF5 file for numeric data.</p>
<h2 id="42-lessons-learned">4.2 Lessons learned</h2>
<p>We have found that the most important part about the development is a short feedback loop between the developer and the users, film scholars, students or other researchers. Since there is a huge palette of statistical and analytical methods that could be implemented into VIAN. It turned out that developing in a user-centered fashion is favorable over implementing a large range of possible features. As such we tried to create a solid architectural foundation and remain generic whenever possible without introducing too much complexity.</p>
<h2 id="5-temporal-segmentation-extraction-and-organization-of-screenshots">5 Temporal Segmentation, Extraction and Organization of Screenshots</h2>
<p>Approaches to the parsing of films vary greatly depending on a researcher’s interest:</p>
<blockquote>
<p>They can be parsed meaningfully into a hierarchy that has units within units within units [&hellip;]. Within this hierarchy, some units have the psychological stature of being events. That is, viewers judge them to have beginnings, middles, and ends, with boundaries that are often denoted by changes in time and place, and that form separable segments within the ongoing audiovisual stream.<br>
<a class="footnote-ref" href="#cutting2012"> [cutting2012] </a>What sounds relatively simple, turns out to be rather complex, especially when we consider tools for (semi-)automatic segmentation (Hahn 2009). Ambiguities increase when we define temporal units by the consistency of color schemes, which is the aim of the film colors study. Even if the camera angle varies or if the camera moves in tracking or crane shots the colors dominating the scene can vary significantly, albeit continuously. Therefore it becomes difficult to identify the temporal segments in a consistent way. Some montage patterns — such as parallel montage — require sub-segmentations that consider both event boundaries and temporal units conflicting with each other. While silent films with their intertitles and / or uniformly tinted segments often signpost their structural organization in a rather distinct way, more recent films have more fluidly overlapping scenes. The classical Hollywood continuity system, on the other hand, has established a number of enunciation marks that communicate scene changes or temporal ellipses such as dissolves, fades, or wipes.</p>
</blockquote>
<p>Temporal segmentation of a film by human observers — and especially those trained as film scholars or advanced students in film studies — take all these various, historically established cues into account, even if the task is connected to mainly the dimension of film color. On average the team identified between 50 to 70 temporal units with sufficiently consistent color schemes within feature-length films.</p>
<p>To accelerate this time-consuming process, VIAN provides an auto-segmentation functionality that computes a temporal segmentation by means of agglomerative clustering of evenly spaced color histograms. The result can then be fine-tuned by the user using the merge and cut tool of VIAN’s timeline.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Comparison manual (top) vs. four types of automated temporal segmentation with 30 to 60 segments in   <em>Une femme est une femme</em> (FRA 1961, Jean-Luc Godard).
        </p>
    </figcaption>
</figure>
<p>As elaborated above (see<a href="#section04">Section 4</a>), an informed selection of screenshots is paramount as a heuristic tool to reduce the complexity of the time-based video stream by picking out the most relevant moments. Therefore, it became mandatory to establish a fast and flexible process not only to extract screenshots with a simple command but also to organize them instantly in relation to the temporal segmentation of the film in individual bins and with consistent nomenclature. In ELAN, each screenshot extraction required several steps from 5 to 12 commands plus manually naming the image files and defining the image format. VIAN, by contrast, treats screenshots as an integral type of annotation, their creation and management are therefore key functionalities. Screenshots are created with a simple hotkey and displayed in several ways within VIAN including temporal alignment in the timeline and grouped by segmentation in the screenshot manager.</p>
<h2 id="51-problems">5.1 Problems</h2>
<p>Many video annotation software solutions have been established in the past that fulfil basic needs. But there is a big leap to developing more sophisticated tools that respond to more complex requirements. Bottom line: the devil is in the details. A very fine framework that integrates several types of players for different zoom-out functions is a powerful start to segment movies temporally, to verbally annotate these units and to extract screenshots. How well does the integrated player process diverse codecs and aspect ratios? What options does it offer to adjust segmentations and to add sub-segmentations for discontinuous entities such as parallel montage? How does it prevent overlapping segments or, by contrast, enable them? What options are there to correct existing segmentations?</p>
<p>Automatic temporal segmentation proved to deliver surprisingly good results that in certain instances challenged human approaches to subdivide the video stream into consistent chunks. On the negative side, auto-segmentation seemed to be much more finely grained in dark scenes and some segments were too long, especially when compared to the average lengths of segments.</p>
<h2 id="52-lessons-learned">5.2 Lessons learned</h2>
<p>To develop a robust video annotation system constant user feedback from experienced users is a necessary requirement. For the next step of auto-segmentation we envision to take music cues and sound design into account, see for instance<a href="#burghardt2016">Burghardt et al. (2016)</a>for a very original approach to combine image and dialogue in film analysis with digital tools. Very often onset or termination of diegetic music indicate shifts in locale or time. Sound design is expressive of certain locations or temporal cues as well.</p>
<p>Furthermore, so-called enunciation marks such as fades to black or white, cross-fadings or intertitles should be incorporated into the system of rules for the parsing of units. Significant deviations in the resulting length of segments compared to the average should force the system to process these extremely long or short chunks again.</p>
<h2 id="6-figure-ground-separation">6 Figure-Ground Separation</h2>
<p>Very early in the project, a figure–ground separation tool was established<a class="footnote-ref" href="#flueckiger2017"> [flueckiger2017] </a>to extract characters from the background using a current, deep-learning semantic segmentation technique<a class="footnote-ref" href="#long2015"> [long2015] </a><a class="footnote-ref" href="#zhao2016"> [zhao2016] </a>. With the rationale to assign to each frame pixel a label this approach indicates the most probable object it represents. It aims at investigating the aesthetics of color attribution through costume and set design in conjunction with other parameters of the mise-en-scène. In the project the method has been constantly improved for speed and performance and provides the basis for all the other color analysis tools —LAB plots(see<a href="#figure18">Figures 18</a>and<a href="#figure21">21</a>etc.),Color_dTplots (see<a href="#figure15">Figures 15</a>and<a href="#figure17">17</a>) — that consider characters independent from their backgrounds.</p>
<p>Aesthetics of figure-ground separation varies greatly during the course of film history, depending on many factors such as color processes, cinematography, mise-en-scène including lighting, staging, materiality of costumes, objects and environments, but also notions of taste and professional norms. For instance strong figure–ground separation was a typical stylistic means to enhance instant legibility in the context of the so-calledcontinuity systemestablished in classical Hollywood films from the mid-1920s onward.</p>
<p>In this production context there was often a hierarchy that attributed the most visually compelling colors to the female star and to reduce color difference between characters and backgrounds for supporting characters. Saturation is mostly attributed to female characters while male characters only wore colorful dresses when they were playing certain parts that were framed within cultural norms, by historical distance — for instance royalty or uniforms — , by certain milieus such as the entertainment industry or the arts, by cultural othering such as exoticism or individual personality traits such as queerness or non-conformist attitudes (see<a href="#bohn2000">Bohn 2000</a>,<a href="#vanska2017">Vänskä 2017</a>) or genre conventions. Strong figure–ground separation as a trend can be observed again in the emerging contexts of the first auteur-centered color films in European and for instance Japanese productions that feature a sober modernist style.</p>
<p>To investigate these stylistic and culturally justified changes in a clear-cut way we established a typology that took the following dimensions into account: strong vs. weak, silhouettes, figure–ground inversion, and separation by hue, saturation or lightness. By figure–ground inversion we denote relationships where the background is either more saturated or brighter than the background.</p>
<p>These distinctions have then become the underlying concepts for the visualizations that came out of the figure–ground separation pipeline.</p>
<p>Referring to the annotation and classification system explained earlier, VIAN allows the user to define <em>classification objects</em> to express a conceptual entity of his or her interest, in this casefigureandground.VIAN uses a deep learning based semantic segmentation to interpret the content of a frame (see<a href="#figure15">Figure 15</a>). The output of such a segmentation is a grayscale image, where each pixel of the input image is assigned to a gray value, so called <em>labels</em> , which correspond to defined objects the model has been trained on. VIAN now allows to assign a set of labels to each classification object, creating a semantic link between the content of the frame and the classification performed by the researcher. Arnold and Tilton’s studies of visual culture also applied image recognition with deep learning tools<a class="footnote-ref" href="#arnold2020a"> [arnold2020a] </a><a class="footnote-ref" href="#arnold2020b"> [arnold2020b] </a>.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Semantic segmentation performed in VIAN.
        </p>
    </figcaption>
</figure>
<p>The results of this figure–ground pipeline are highly significant, especially when combined with the <em>Color_dT</em> visualization (see Figure 15). An instant fingerprint of a film’s aesthetic development emerges when we compare the varying relationships between color attribution to characters vs. environment in the course of a film’s narrative unfolding. As will be elaborated in Section 7 Colorimetric <em>Analyses and Visualizations</em> , the resulting types of visualizations differ profoundly from established ones. Mapping the results still raises some questions for scaling. For instance, we found that humans perceive saturation levels attributed to characters as higher when the rest of the image is less saturated, a difference that cannot be rendered accurately with our current visualization and colorimetry methods yet.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Figure–ground separation in VIAN, <em>Jigokumon</em> (JAP 1953, Teinosuke Kinugasa).
        </p>
    </figcaption>
</figure>
<h2 id="61-problems">6.1 Problems</h2>
<p>While we expected this task to be very demanding it turned out that — because this is one of the most important tasks in autonomous driving — deep-learning methods are currently in a very dynamic state especially with regard to extracting characters from backgrounds. YOLO<a class="footnote-ref" href="#redmon2015"> [redmon2015] </a>was the first object recognition software applied. It provided very reliable results for the identification of humans while other objects were often misinterpreted, especially when they were partially occluded or cut off at the frame’s edges.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Object identification in YOLO: while persons are identified consistently,  errors occur when objects are partially occluded or fragmented.
        </p>
    </figcaption>
</figure>
<p>YOLO was combined with GrabCut<a class="footnote-ref" href="#rother2004"> [rother2004] </a>. GrabCut works as follows: the user initially draws a rectangle around the object to be in the foreground, GrabCut will then try to directly segment the frame, and return the result. The user can then iteratively optimize the result by marking regions that have not been identified correctly using strokes. Performing this process for each image manually would not have been feasible because of the time constraints, we thus used YOLO, an object recognition neural network to draw the initial bounding box and the strokes. However, this pipeline did not scale well enough for our purposes, demanding a large amount of resources and time. We therefore decided to use a deep-learning convolutional network to perform the pixelwise segmentation directly with semantic segmentation<a class="footnote-ref" href="#long2015"> [long2015] </a>rather than the YOLO and GrabCut based approach.</p>
<h2 id="62-lessons-learned">6.2 Lessons learned</h2>
<p>A collaborative, interdisciplinary approach that connects high levels of expertise both in the domain of aesthetic analysis and computer science has proven to be mandatory for the elaboration of an analysis and visualization pipeline that respects both fields and connects them in a convincing manner. While such a statement may seem banal, in fact the actual exchange between different disciplines has been much more demanding and requires continuous adjustments from both sides. Experts from the field of humanities must be able to understand the requirements of informatics and to describe the task in a highly formalized manner. Scientists on the other hand need to be open to integrate a sense for the subtleties of aesthetic concepts to understand why minor details unexpectedly can have a significant impact on the results. The resulting pipeline should produce visualizations that respect the rigorous demands of science while also considering instant accessibility for human observers and knowledge of aesthetic distinctions at the same time.</p>
<h2 id="7-colorimetric-analyses-and-visualizations">7 Colorimetric Analyses and Visualizations</h2>
<p>Previous approaches to visualizations of color schemes were surprisingly reduced in their scope and were not sophisticated enough to do justice to aesthetic subtleties of color design in film.</p>
<p>Currently available tools to devise color schemes are often applying K-means<a class="footnote-ref" href="#brodbeck2011"> [brodbeck2011] </a><a class="footnote-ref" href="#rosebrock2014"> [rosebrock2014] </a>and thus are limited to the depiction of a fixed set of hues. Color schemes in VIAN, by contrast, are extracted to match spatial distribution and can be edited according to the needs of the color analysis for a certain film. Some films apply very distinct hues to their color schemes while others resort to minute shifts to display developments in character relationships. Color schemes can express a character’s inner states or personal developments, relationship to other characters or a given environment, again norms of taste and milieus, or cultural conventions. Socio-political markers indicate characters’ connection to a certain class or social function in a socially or culturally pre-defined way as for instance in uniforms.</p>
<p>From the start, we therefore envisioned a different approach that allows for a flexible fine-tuning of color schemes to match the specific style of a given film. A second basic requirement was the representation of the spatial distribution of colors in a way that is instantly displaying the quantitative allocation of colors in an image or temporal segment. Thirdly, we aimed at visualization methods of color schemes that show their development in a film over time according to the temporal segmentation executed in the pipeline.</p>
<p>Typical time-based representations such as movie barcodes or mosaics provide plenoptic overviews of films (for a discussion see<a href="#heftberger2016">Heftberger 2016</a>,<a href="#stutz2016">Stutz 2016</a>,<a href="#olesen2017">Olesen 2017</a>,<a href="#flueckiger2017">Flueckiger 2017</a>) but they do not represent the finely grained shifts and relationships that are fundamental for an in-depth study of aesthetics. Frederic Brodbeck arranged color schemes in circles to give an overview of what he called a fingerprint of a film’s color scheme<a class="footnote-ref" href="#brodbeck2011"> [brodbeck2011] </a>. Z-projections have become a main part of Kevin L. Ferguson’s visualizations<a class="footnote-ref" href="#ferguson2013"> [ferguson2013] </a><a class="footnote-ref" href="#ferguson2016"> [ferguson2016] </a>who also proposed a volumetric approach to visualize an entire film’s color on the time axis in 3D<a class="footnote-ref" href="#ferguson2015"> [ferguson2015] </a>. James E. Cutting and his team at Cornell University devised many methods to visualize movies, among others a movie barcode that implemented color schemes from warm to cold colors<a class="footnote-ref" href="#cutting2016"> [cutting2016] </a>. From 2013 onwards Lev Manovich<a class="footnote-ref" href="#manovich2013a"> [manovich2013a] </a><a class="footnote-ref" href="#manovich2013b"> [manovich2013b] </a>and his Software Studies lab applied a range of visualizations to Dziga Vertov’s films for Adelheid Heftberger’s research project<a class="footnote-ref" href="#heftberger2015"> [heftberger2015] </a><a class="footnote-ref" href="#heftberger2016"> [heftberger2016] </a>, some of them based on ImagePlot and ImageJ that were used previously for the visualizations of artworks<a class="footnote-ref" href="#manovich2012"> [manovich2012] </a><a class="footnote-ref" href="#reyes-garcia2014"> [reyes-garcia2014] </a><a class="footnote-ref" href="#reyes-garcia2017"> [reyes-garcia2017] </a>. ImageJ, initially introduced for bio-medical research<a class="footnote-ref" href="#ross2007"> [ross2007] </a>, has since been used by several researchers for film analysis (<a href="#olesen2016">Olesen 2016</a>,<a href="#heftberger2016">Heftberger 2016</a>, see several chapters in<a href="#hoyt2016">Hoyt et al. 2016</a>). Casey et al. compared temporal segments in films based on histograms visualized in a similarity matrix<a class="footnote-ref" href="#casey2014"> [casey2014] </a>.</p>
<p>As elaborated in Halter et al. (2019), the team defined a set of requirements for the visualizations. They should<br>
Represent visual impressions true to human perception;Represent subtle aesthetic nuances in figure and ground separately;Visualize the films at the micro (screenshot, temporal segment), meso (individual film) and macro (corpus) levels.</p>
<p>And in addition they should be interactive and flexible for adjustment to an individual researcher’s interest<a class="footnote-ref" href="#halter2019"> [halter2019] </a>.</p>
<p>Therefore, as elaborated in previous papers<a class="footnote-ref" href="#flueckiger2011"> [flueckiger2011] </a><a class="footnote-ref" href="#flueckiger2017"> [flueckiger2017] </a>, the relationships of colors need to be mapped into a perceptually uniform color space to provide visualizations that match human vision. In VIAN, both the screenshots and the color schemes are thus transformed into the perceptually uniform CIE L<em>a</em>b* (referred to as LAB in this paper) color space needed for meaningful representation of the color distribution in a given film. Contrary to most established visual representations such as image plots, z-projections, color palettes or barcodes, a visual representation in a perceptually uniform color space pays attention to the relational nature of colors with regard to the visual system. Chromaticity and lightness plots provide an overview of a film’s color distribution, see Figure 18.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Chromaticity plots in CIE L<em>a</em>b* (LAB) for <em>Pierrot le fou</em> (FRA 1965, Jean-Luc Godard),  image plot (above) vs. palette dot plot (below) The comparison shows that chroma extends much further in palette dot plots without averaging effects caused by the representation of images.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Chromaticity plots in CIE L<em>a</em>b* (LAB) for <em>Pierrot le fou</em> (FRA 1965, Jean-Luc Godard),  image plot (above) vs. palette dot plot (below) The comparison shows that chroma extends much further in palette dot plots without averaging effects caused by the representation of images.
        </p>
    </figcaption>
</figure>
<p>While visualizing color schemes in a strip of color patches sorted by frequency is generally well established and gives a good overview, they are often hard to compare and hide how the palette has been assembled during the clustering process. To compare color distribution in relation to human perception the color scheme is displayed in the LAB color space as a palette dot plot. With this method small changes as well as color contrasts within the chroma or hue between different color patches become directly visible (see<a href="#figure19">Figure 19</a>, right). The tree palette (<a href="#figure19">Figure 19</a>, above, middle) should help the user to understand into which final cluster the colors of the input image have been merged. To this end, palettes are stacked in different merge steps corresponding to increasing levels of granularity on top of each other and the color patches sorted within the palette by the order resulting from the clustering. Thus all colors merged into a cluster are visualized directly below it.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color palettes for individual shots: tree diagram with increasing levels of detail (above, middle) and LAB (right); selection of 7 hues for layer palette sorted by frequency (below, middle). <em>Blade Runner 2049</em> (USA 2017, Denis Villeneuve),  see interactive visualization methods in the screen video<a href="https://vimeo.com/299804415">https://vimeo.com/299804415</a>.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color palettes for individual shots: tree diagram with increasing levels of detail (above, middle) and LAB (right); selection of 7 hues for layer palette sorted by frequency (below, middle). <em>Blade Runner 2049</em> (USA 2017, Denis Villeneuve),  see interactive visualization methods in the screen video<a href="https://vimeo.com/299804415">https://vimeo.com/299804415</a>.
        </p>
    </figcaption>
</figure>
<p>Applying color-related computational methods, such as clustering or statistics on the raw frames of a film is often not feasible because of the sheer amount of data. It is thus often a necessity to extract feature vectors adequately representing the content through a color histogram that is regularly used within VIAN. However, color spaces are three-dimensional and so are their color histograms, making visualization of color histograms a difficult task. A naive approach would be to visualize the histograms as point clouds in a three-dimensional space but this method doesn’t yield good comparability. We therefore developed a bar-chart like representation of a color histogram by sorting the colors of the three-dimensional histogram into a one-dimensional list using a room-filling curve, namely the Hilbert curve. Intuitively, this room-filling curve describes a path, by which any point of a given space is visited, in our case the bins of the three-dimensional color histogram. By unraveling this curve, we can align the bins of the three-dimensional color histogram in a one-dimensional row. We use Hilbert curves, because this type of room-filling curve has shown to preserve the specific locality well, in our case this means that color bins which are close in the three-dimensional histogram, will also be close in the unraveled, one-dimensional, histogram bar plot.</p>
<p>Color_dT is an advanced method to visualize the color development of a film over time on the meso level with regard to its temporal unfolding, again for figure, ground and whole screenshots independently. It is currently implemented for saturation contrasts, contrast of hue, chroma or light-dark contrast, but could also include cold–warm contrast. Shifts in figure–ground relationships become instantly evident, so do overall developments with regard to the narrative events in the course of a film.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color_dT plot development of saturation (y-axis) over time (x-axis) for figure (above) and background (below) in <em>Jigokumon</em> (JAP 1953, Teinosuke Kinugasa), visualization by Noyan Evirgen for ERC Advanced Grant <em>FilmColors</em> .
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color_dT plot development of saturation (y-axis) over time (x-axis) for figure (above) and background (below) in <em>Jigokumon</em> (JAP 1953, Teinosuke Kinugasa), visualization by Noyan Evirgen for ERC Advanced Grant <em>FilmColors</em> .
        </p>
    </figcaption>
</figure>
<p>One significant example is the Japanese film <em>Jigokumon</em> , produced as one of the first Japanese color films shot in the then new chromogenic process Eastmancolor. In the first half of the film we see a pronounced figure ground separation with the characters, especially the female love interest standing out in colorfully patterned, saturated kimonos in front of subdued backgrounds. In the middle of the film a peripety occurs during a horse race where the two male opponents fight each other. This scene is set in broad daylight with conflicting colors in background and foreground. After this turning point, the tragedy sets in with a markedly different color design and mise-en-scène characterized by dark scenes in low-key lighting, which by its very nature reduces figure–ground separation.</p>
<p>With early applied colors such as tinting and toning, the LAB chromaticity plots look decidedly different due to the mostly monochrome color schemes. As becomes evident from a comparison between <em>L’Inhumaine</em> (FRA 1923, Marcel L&rsquo;Herbier) and <em>Das Cabinet des Dr. Caligari</em> (GER 1919, Robert Wiene), the digitization of <em>L’ Inhumaine</em> differs substantially by the detached distribution of chroma — there is no continuity from the center to the higher levels — which could result from problems in digital color management.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Chromaticity plots in the CIE L<em>a</em>b* space for the tinted films <em>L’Inhumaine</em> (FRA 1923, Marcel L&rsquo;Herbier) (above)  and <em>Das Cabinet des Dr. Caligari</em> (GER 1919, Robert Wiene).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Chromaticity plots in the CIE L<em>a</em>b* space for the tinted films <em>L’Inhumaine</em> (FRA 1923, Marcel L&rsquo;Herbier) (above)  and <em>Das Cabinet des Dr. Caligari</em> (GER 1919, Robert Wiene).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color_dT plot development of saturation (y-axis) over time (x-axis)  for the tinted film <em>L’Inhumaine</em> (FRA 1923, Marcel L&rsquo;Herbier), a tinted film.
        </p>
    </figcaption>
</figure>
<h2 id="features-tool">Features Tool</h2>
<p>Correlations between concepts are displayed in two ways. The <em>features tool</em> enables users to select the concepts from the menu. Consequently the occurrence of these concepts are then displayed over time related to the segments where they occur. Connected to the exemplary screenshots this type of visualization instantly builds the foundation to establish and test hypotheses.</p>
<p>The correlation between different keywords within a project or corpus-wide can be investigated using the co-occurrence matrix plots, which indicates how often every combination of keywords occurs within the scope.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>VIAN features tool visualizes co-occurrences of concepts organized on the time axis with regard to the temporal segmentation in <em>Do the Right Thing</em> (USA 1989, Spike Lee), see screen video<a href="https://vimeo.com/292861139">https://vimeo.com/292861139</a>.
        </p>
    </figcaption>
</figure>
<p>In the screen video the features tool is tested with Spike Lee’s Do the Right Thing. Several typical features of this film have been selected in this visualization. In addition to the leitmotif that establishes the dominant red spectrum of the film and associates it to the topic of heat in its double sense as a temperature and as a metaphor for the rising racial tensions, the film’s aesthetics is informed by a dichotomy between the private sphere and the public space. The private sphere in interiors is often shown suffused in atmospheric diffusion again associated to the hazy damp caused by the heat in warm monochrome red tones with shafts of light filling the room, all of which are associated to a romantic tradition dating back to the early 19th century. By contrast, the aesthetics of the film’s public sphere follows a much more sober style connected to traditions of social realism with extended depth of field in wide-angle shots that show the characters in relationship to each other and to their environment. In terms of color design, the film makes use of what we call socio-political markers, culturally established conventions to denote certain social strata or official functions. For instance the protagonist played by Spike Lee himself is a pizza delivery boy and wears clothes in the colors of the Italiantricolore, white, green and red. His encounters are also defined by the central topic of race that is connected to the various ethnic groups, the Puerto Ricans, the Jamaican, the Koreans, the Italians, and the Afro-Americans, each of which is associated to different sets of hues by socio-political markers. Such a pattern of color aesthetics and meaning can easily be confirmed or further elaborated with the <em>features tool</em> (<a href="#figure23">Figure 23</a>).</p>
<h2 id="71-problems">7.1 Problems</h2>
<p>Image plots are fantastic tools for visualizations when a researcher aims at keeping the connection to the source material. By zooming into the plots, users can look at the screenshots and see where and why a certain screenshot is present in the plot and how it is related to the film. However, because image plots’ colorimetric values are calculated based on the average of the screenshot’s color distribution, monochrome color schemes distort the visualization by being too dominant. Screenshots with more than one hue or a multitude of hues aggregate at the center of the LAB visualization or at the bottom of aColor_dTplot. Therefore, this type of visualization is best suited for early applied colors such as tinting and toning with their monochrome color distribution or for films with stark color designs in mostly one dominant hue per segment such as for instance Suspiria or Slawomir Idziak’s camerawork whose signature style often applies colored illumination and monochrome or graduated lens filters.</p>
<h2 id="72-lessons-learned">7.2 Lessons learned</h2>
<p>For many films that are not rendered well in image plots we devised an alternative solution by consecrating the full image rendition and separated the individual color values (comparison see<a href="#figure18">Figure 18</a>). That is, instead of using the average color values, we computed the color palette for a given screenshot and visualize it in the AB plane of the LAB color space. A jitter effect is applied to add some noise, making the amount of a specific hue visible within the color space. These palette dot plot visualizations now show the color schemes represented by dots for each of the colors present in a screenshot. We had to devise a method to include the spatial percentage into the dot plots. Dot plots have also become a means to show color schemes in a different way than with the typical color bars, see<a href="#figure19">Figure 19</a>. Different methods to scale and distribute colors in visualizations are offered such as zoom functions or range adjustments. Rotation is crucial for visualizations related to the L axis in the LAB space to show the distribution of hues in a meaningful way. While palette dot plots display a film’s color distribution in an intuitive way, they do not take the relative incidence into account. Therefore yet another type of visualization was introduced: heat maps that show the color distribution by means of levels of transparency corresponding to the incidence (<a href="#figure24">Figure 24</a>).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Palette dot plots (left) vs. heat maps (right): while palette dot plots visualize the occurrence of a certain color, heat maps indicate the incidence by different levels of transparency. VIAN WebApp querydisgust.
        </p>
    </figcaption>
</figure>
<h2 id="8-visualizations-concepts-and-correlations-on-the-macro-level">8 Visualizations, Concepts and Correlations on the Macro Level</h2>
<p>One of the biggest gains of our investigation is the massive dataset created by the analysis team. As written above, (see<a href="#section03">Section 3</a>) it amounts to more than 17.000 segments with more than 170.000 screenshots for more than 400 films, each of which are connected to the meticulous manual analysis and annotation presented in detail in the previous sections of this paper (see<a href="#section02">Sections 2</a>to<a href="#section05">5</a>).</p>
<p>One way to display the amount of associations between different keywords within a dataset this large and complex, is to follow a network visualization approach. Every keyword is represented as a node and its connections to other keywords as edges. The more these keywords appear in the same segment the closer they are placed together within the network using the Fruchterman-Reingold force-directed graph drawing algorithm provided by the NetworkX Python library<a class="footnote-ref" href="#hagberg2008"> [hagberg2008] </a>.</p>
<p>With the integration of this dataset into the VIAN WebApp we open up a broad range of opportunities for queries on the segment, film and corpus level to combine the manual annotation with all the colorimetric analysis and visualization methods elaborated in sections 6 and 7 (see<a href="#section06">Section 6</a>, see<a href="#section07">Section 7</a>). By such a comprehensive approach we enable users to combine all the three different levels, from the micro level (close reading, for instance individual screenshots or segments) to the meso level of individual films to the macro levels (distant reading) of the full corpus or selected subcorpora. Such selected corpora can be queried by any concept regarding narrative aspects, characters’ emotional states, motives or themes, and all the aesthetic and stylistic dimensions mentioned in section 2 (see<a href="#section02">Section 2</a>).</p>
<p>Two concept queries are displayed here, the search for dream sequences in the three periods 1895–1930 and the search for night sequences in early film. When we compare the visualization of dream sequences in early film with the period from 1930–1955 two insights emerge, dream sequences are often marked by monochrome color schemes, and often the dominant color is red. In the second plot (1930–1955) the relatively prominent incidence of green is related almost exclusively to the <em>Wizard of Oz</em> where the concept of dream applies to the primary narrative of the film (see<a href="#figure25">Figure 25</a>below).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Visualizations on corpus level for the narrative conceptdream, 1895–1930 (left) and 1930–1955 (right), AB image plots.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Visualizations on corpus level for the narrative conceptdream, 1895–1930 (left) and 1930–1955 (right), AB image plots.
        </p>
    </figcaption>
</figure>
<p>Applied colors in films produced during the first three decades of film history — such as tinting and toning with their monochrome color schemes — followed loosely a set of conventions, which then have to be tested in individual films or over a certain period. Because there were many ambiguities, each film’s color schemes and attribution of hues to different locations, times, narrative strands, genre or gender conventions has to be carefully investigated for film scholars and restorers alike to understand the guiding rules of one particular historical film print<a class="footnote-ref" href="#ledig1988"> [ledig1988] </a>(<a class="footnote-ref" href="#mazzanti1998"> [mazzanti1998] </a><a class="footnote-ref" href="#mazzanti2009"> [mazzanti2009] </a>. For instance <em>Das Cabinet des Dr. Caligari</em> has survived in five differently tinted and toned versions, see gallery on the <em>Timeline of Historical Film Colors</em> ,<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> but a reference print of the initial German premiere version has not been found yet<a class="footnote-ref" href="#wilkening2014"> [wilkening2014] </a>, see<a href="#figure09">Figure 9</a>for the comparison of a DVD vs. historical print.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Corpus visualization exterior night in films from 1895–1930, with fire scenes excluded.
        </p>
    </figcaption>
</figure>
<p>One of the most stable associations of specific hues to a certain narrative dimension is blue tinting to exterior night scenes, because limited speed of early film stocks did not allow for night scenes to be actually shot by night. Therefore these scenes needed to be marked by typical hues. The visualizations show that blue is indeed one of the dominant hues with green almost as wide-spread as blue. Amber and red are the third dominant range. Amber is often associated to tungsten or candle light in interior scenes, so segments that contain connections between interior and exterior scenes in a certain sense contaminate the result. Fire scenes, by contrast, are typically tinted in red, so they were eliminated the query, see<a href="#figure20">Figure 20</a>.</p>
<p>In general, LAB image plots and palette dot plots are limited in informative value on corpus level as opposed to their usefulness on the film level, especially when displayed in print. They only indicate trends that then have to be confirmed by looking deeper into the films and segments where they occur. To this end, all the visualizations on the query page of the VIAN WebApp are highly interactive. When hovering over the plots, the researcher gets shown the corresponding segments of the film including screenshots and a scene description. In addition, all the segments and films are displayed with the corresponding color palettes in the form of coarse barcodes.</p>
<p>See screen video of the query page:<a href="https://vimeo.com/402360042">https://vimeo.com/402360042</a></p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>On the query page of the VIAN WebApp, all the segments and projects detected in the query are displayed with a coarse color palette (above). By clicking on a segment, the screenshots, a short scene description  and a summary visualization are displayed. <em>Possession</em> (FRA / DEU 1981, Andrzej Żuławski).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>On the query page of the VIAN WebApp, all the segments and projects detected in the query are displayed with a coarse color palette (above). By clicking on a segment, the screenshots, a short scene description  and a summary visualization are displayed. <em>Possession</em> (FRA / DEU 1981, Andrzej Żuławski).
        </p>
    </figcaption>
</figure>
<p>To investigate the diachronic development, an additional method for corpus visualizations called <em>Color_dY</em> was implemented that considers the temporal distribution over years instead of plotting a selected period into an overview in LAB that obscures the color schemes of individual films.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color_dY plots saturation (y-axis) over time (x-axis) for colored lights,  1895–1930 (top), 1930–1955 (middle), 1955–1995 (bottom).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color_dY plots saturation (y-axis) over time (x-axis) for colored lights,  1895–1930 (top), 1930–1955 (middle), 1955–1995 (bottom).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Color_dY plots saturation (y-axis) over time (x-axis) for colored lights,  1895–1930 (top), 1930–1955 (middle), 1955–1995 (bottom).
        </p>
    </figcaption>
</figure>
<p>For instance in the middle plot the animation film <em>Fantasia</em> (USA 1940, James Algar et. al.) sticks out with extremely high levels of saturation, and again also for an animation film <em>Die Abenteuer des Prinzen Achmed</em> (GER 1925, Lotte Reiniger; Carl Koch) in the first plot on the right hand side. Film titles, segments and screenshots in combination with a scene description are again displayed by a hover function (see<a href="#figure27">Figure 27</a>).</p>
<h2 id="81-problems">8.1 Problems</h2>
<p>In the course of developing these visualization methods on corpus level we noticed difficulties to receive clear-cut pictures. One of the problems resulted from the fuzziness of the concepts that generated quite a high amount of noise, as elaborated in the previous section, see<a href="#section07">Section 7</a>. However the most persistent issue that has been identified is the dominance of monochrome color schemes in the LAB visualizations, in the same fashion as in the image plots per film discussed in the previous section (see<a href="#section07.1">Section 7.1</a>). Because of high levels of chromaticity in some monochrome screenshots as compared to averaging effects by variegated hues these images always stick out and therefore distort the result. This effect is even stronger in image plots that represent data on corpus level, because of the variations in different films’ color designs.</p>
<h2 id="82-lessons-learned">8.2 Lessons learned</h2>
<p>One of the first measures we took was to clean up the data. Secondly we also integrated the dot plots explained in the previous section (see<a href="#section07">Section 7</a>) into the corpus visualizations. One of the most helpful parts of visualizations on corpus levels is the integration of the temporal segments including scene descriptions and screenshots in a sidebar next to the plots. Since the relationship between different keywords becomes complex in such a large corpus, we have implement more types of visualizations to convey the correlation and connections between concepts, the color-features associated to them and the temporal distribution over time in image plots and palette dot plots.</p>
<h2 id="9-spatial-variations-identification-and-analysis-of-patterns-and-textures">9 Spatial Variations, Identification and Analysis of Patterns and Textures</h2>
<p>In general, colors are conceived as defined by the dimensions of hue, saturation and lightness. However, from the point of view of perception, there are many more factors that influence color appearance and the perception of colors correspondingly<a class="footnote-ref" href="#katz1911"> [katz1911] </a><a class="footnote-ref" href="#katz1930"> [katz1930] </a><a class="footnote-ref" href="#hurlbert2013"> [hurlbert2013] </a>.</p>
<p>One of the most significant, but hitherto overlooked features of color appearance is <em>spatial variation</em> . By spatial variation we understand the change of hues related to spatial frequency in a given image. Such variations are related to several factors. Image complexity can be caused by cluttered image compositions with many small details, either in different or similar hues. Massive crowds of characters dressed in different colors are one type of subject that causes a high amount of spatial variation. Another type are layered image compositions with occlusion generated by objects in the foreground.</p>
<p>Visual complexity is connected to texture analysis in so far as spatial variations can be one feature that affects the legibility of image compositions (for a digital humanities approach to the investigation of image composition and style see<a href="#benini2016">Benini et al. 2016</a>). An additional factor is the distribution of hues, with a high level of varying hues adding to visual complexity. At the same time an extremely uniform color distribution can lower legibility as well, if it is combined with a low degree of spatial variations and / or with darkness. Color separation and color attribution are a strong cue for object recognition and for scene detection<a class="footnote-ref" href="#hurlbert2013"> [hurlbert2013] </a><a class="footnote-ref" href="#hansen2017"> [hansen2017] </a>.</p>
<p>In our aesthetic analyses the distinction between patterns and textures has been fundamental from the start, for several reasons. <em>Patterns</em> denote surface variations based on color attribution, for instance printed or woven patterns on fabrics, painted surfaces with patterns such as wallpapers etc. <em>Textures</em> , by contrast, refer to three-dimensional surface variations, such as knit-wear, rocks, brick walls, coarse unpolished wooden log structures. They invariably address tactile perception<a class="footnote-ref" href="#liu2015"> [liu2015] </a><a class="footnote-ref" href="#zuo2016"> [zuo2016] </a>.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Patterns (left) in <em>Jigokumon</em> (JAP 1953, Teinosuke Kinugasa)  vs. textures (right) in <em>Pierrot le fou</em> (FRA 1965, Jean-Luc Godard).
        </p>
    </figcaption>
</figure>
<p>One guiding hypothesis of our research was a strong connection between the materiality of color film stocks and material properties of the <em>diegesis</em> , the spatio-temporal universe depicted in a film whose materials are selected and orchestrated by costume and production design. For instance half-tone printing as applied in Technicolor No. III to V dye-transfer processing is lacking definition due to problems to perfectly register the three printing dyes, which would be a prerequisite for spatial resolution of small-scale color variations. As a result we expected these films to omit patterns in their color design. Tinted films by contrast, lack spatial variation based on hues as they are uniformly colored by being submerged into dye baths, see <em>Timeline of Historical Film Colors</em> <a class="footnote-ref" href="#flueckiger2012"> [flueckiger2012] </a>.</p>
<p>There is also a strong connection between affective modes of film perception and visual complexity or reduced legibility respectively. For instance in stressful scenes image complexity can increase substantially Layered image compositions are one form to obstruct the automated perception of films that was regarded to be a cornerstone of the Hollywood system. As team member Michelle Beutler’s research has shown, however, the Hollywood system itself was much less normative than previously assumed. The increase in tactile properties and affectively laden subjectivity noticed in the films of the 1960s onwards are at the center of Bregt Lameris’s investigation on film colors and affect (see Lameris 2019). In Joëlle Kost’s study of chromogenic film stocks visual complexity is one of the main topics as it relates to the improved resolution in these stocks.</p>
<p>By training a deep learning network to perform pixelwise sub-figure segmentation using the LIP dataset<a class="footnote-ref" href="#gong2017"> [gong2017] </a>we will be able to analyze both features.</p>
<p>One possibility to assess the spatial frequency within a frame, is to use an edge detection algorithm, the intention is the more edges there are, the busier the region is. This has already shown to be a robust measure for spatial complexity, does however not cover solely hue and chroma related variance. VIAN currently visualizes three different measures as a heatmap over the player: The convolved edge density and the pixelwise luminance and a<em>b</em> channel variance.</p>
<h2 id="91-problems">9.1 Problems</h2>
<p>Differentiation between patterns and texture computationally is a non-trivial task. A naïve approach would be to assume that variance in luminance tendentially indicates a tactile quality while high variance in hue and chroma would indicate patterns. However, since patterns are not excluded from high variance in the luminance channel, this approach does not yield accurate results. Furthermore, many materials that have a tactile quality for humans often do not differ significantly numerically from flat surfaces. Co-variance of spatial frequency, color values (hue, lightness, saturation) and textures vs. patterns is tightly connected to higher order processes in human visual perception, for instance color memory and cross-modal integration, i.e. the connection of tactile experience to visual and auditory perception. As shown previously in Flueckiger’s investigation of sound design, material properties are often best detected by their acoustic cues. For a future, more elaborate system it would be an asset to include sound.</p>
<h2 id="92-lessons-learned">9.2 Lessons learned</h2>
<p>Spatial frequency and the differentiation and assessment of patterns and textures are still part of our current research. Visual complexity is one of the most important factors when it comes to style and diachronic developments. Therefore we associated an eye-tracking study to the project to gain empirical insights into the topic (see<a href="#smith2013">Smith / Mital 2013</a>;<a href="#rubo2018">Rubo / Gamer 2018</a>). The study was conducted by Miriam Loertscher in cooperation with Bregt Lameris. For this study we chose a set of exemplary scenes for different types of image composition and complexity, for instance the clear cut type without patterns and textures as in Une femme est une femme, the type “overwhelming object world” as in <em>Morte a Venezia</em> with completely cluttered, layered image compositions, or <em>Sayat Nova</em> (The Color of Pomegranates), a film that works with many textures and material variations, often by excluding the human figure.</p>
<p>Results are currently being processed, but from a brief look at the heatmaps, image parts with small-scale variations detract the viewers’ gaze the most from the dominant focus on characters and most of all on faces. As Rubo and Gamer state “The influence of social stimuli and visual low-level saliency on eye movements have only recently been studied within the same datasets, and rarely in direct juxtaposition. During face perception, it was shown that facial regions diagnostic for emotional expressions received enhanced attention irrespective of their physical low-level saliency” <a class="footnote-ref" href="#rubo2018"> [rubo2018] </a></p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Heatmaps from the eye tracking study: Strong figure-ground separation and lack of spatial variation in the background in <em>Une femme est une femme</em> (above), textures 8 and patterns in combination with no humans in <em>Sayat Nova</em> (middle) plus the overwhelming object world with a high level of obstruction and visual complexity in <em>Morte a Venezia</em> (below). Study conducted by Miriam Loertscher and Bregt Lameris, ERC Advanced Grant <em>FilmColors</em> .
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Heatmaps from the eye tracking study: Strong figure-ground separation and lack of spatial variation in the background in <em>Une femme est une femme</em> (above), textures 8 and patterns in combination with no humans in <em>Sayat Nova</em> (middle) plus the overwhelming object world with a high level of obstruction and visual complexity in <em>Morte a Venezia</em> (below). Study conducted by Miriam Loertscher and Bregt Lameris, ERC Advanced Grant <em>FilmColors</em> .
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Heatmaps from the eye tracking study: Strong figure-ground separation and lack of spatial variation in the background in <em>Une femme est une femme</em> (above), textures 8 and patterns in combination with no humans in <em>Sayat Nova</em> (middle) plus the overwhelming object world with a high level of obstruction and visual complexity in <em>Morte a Venezia</em> (below). Study conducted by Miriam Loertscher and Bregt Lameris, ERC Advanced Grant <em>FilmColors</em> .
        </p>
    </figcaption>
</figure>
<p>The resulting hypotheses have to be tested to identify regions of high spatial frequency and by comparison with the manually gathered data to assess if these regions represent pattern or textures.</p>
<h2 id="10-conclusion">10 Conclusion</h2>
<p>In this article we discussed the potential and limitations of digital tools for the analysis of film aesthetics and narration based on the use case of research on the technology and aesthetics of film colors. Following the central argument established in the introduction, namely that such tools require a robust theoretical foundation, human interpretation, constant discussion and thorough reflection of the epistemological assumptions embedded in the tools, we explored various approaches to connect the humanities perspective with methods from data and computer science.</p>
<p>Our research has shown that we need to resort to a broad spectrum of finely grained analysis and visualization methods to avoid pitfalls of unfounded generalizations and anecdotal studies. On the downside of such a large dataset and sophisticated range of theoretical and analytical concepts there is a considerable amount of complexity and noise that tends to obscure clear-cut results. We found that for each of the research questions we need to take the full range of visualizations into account and re-evaluate the results on a case by case basis.</p>
<p>Compared to traditional, mostly language-dominated approaches to the aesthetics, technology and narratology of film colors, the digital humanities tools create evidence through the mapping of results into an instantly accessible array of visual representations. By relating detailed human annotation and interpretation to these visual representations, the integrated workflow consisting of the VIAN visual analysis software in combination with the crowdsourcing portal VIAN WebApp has created a comprehensive ecosystem for the investigation of film aesthetics and narration. Therefore it significantly extends established methods in film studies.</p>
<p>In currently running or planned cooperation projects we aim at exploring and extending this approach beyond the topic of film colors, in teaching, research and citizen science.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme, grant agreement No 670446 <em>FilmColors</em> . Analyses were executed by the PhD candidates Olivia Kristina Stutz, Michelle Beutler, Joëlle Kost, PostDoc researcher Bregt Lameris, PI Barbara Flueckiger, and three student assistants Manuel Joller, Valentina Romero, Ursina Früh. Visualization and Multimedia Lab VMML at the University of Zurich directed by Renato Pajarola with Enrique Paredes and Rafael Ballester-Ripoll.</p>
<ul>
<li id="arnold2020a">Arnold, Taylor; Tilton, Lauren (2020): “Enriching Historic Photography with Structured Data using Image Region Segmentation” . In: _Proceedings of the First Artificial Intelligence for Historical Image Enrichment and Access (AI4HI)_ . Marseille, France: Association for Computational Linguistics.
</li>
<li id="arnold2020b">Arnold, Taylor; Tilton, Lauren (2020 b): “Distant Viewing Toolkit. A Python Package for the Analysis of Visual Culture” . In: _Journal of Open Source Software_ , 5,45. _The Open Journal_ , S. 1800, (<a href="ttps://doi.org/10.21105/joss.01800">https://doi.org/10.21105/joss.01800</a>).
</li>
<li id="beau2002">Beau, Frank (2002): “La solitude du technobole. Puissance politique des effets spéciaux” . In: _CinémAction_ , 102, pp. 196–207.
</li>
<li id="benini2016">Benini, Sergio; Svanera, Michele; Adami, Nicola; Leonardi, Riccardo; Kovács, András Bálint (2016): “Shot Scale Distribution in Art Films” . In: _Multimedia Tools Appl._ , 75,23, Dez., pp. 16499–16527, (<a href="https://doi.org/10.1007/s11042-016-3339-9">https://doi.org/10.1007/s11042-016-3339-9</a>, accessed 11/17/2019).
</li>
<li id="bohn2000">Bohn, Cornelia (2000): “Clothing as Medium of Communication” . In: _Soziale Systeme_ , 6,1, pp. 111–137.
</li>
<li id="bordwell1989">Bordwell, David (1989): “Historical Poetics of Cinema” . In: Barton Palmer (ed.): _The Cinematic Text. Methods and Approaches_ . New York: ASM Press.
</li>
<li id="bordwell1985">Bordwell, David; Staiger, Janet; Thompson, Kristin (1985): _The Classical Hollywood Cinema. Film Style and Mode of Production to 1960_ . London: Routledge.
</li>
<li id="brodbeck2011">Brodbeck, Frederic (2011): “Cinemetrics. Film Data Visualization” . In: _Cinemetrics_ , (<a href="http://cinemetrics.fredericbrodbeck.de/">http://cinemetrics.fredericbrodbeck.de/</a>, retrieved 05/30/2016).
</li>
<li id="burghardt2016">Burghardt, Manuel; Kao, M.; Wolff, C. (2016): “Beyond Shot Lengths. Using Language Data and Color Information as Additional Parameters for Quantitative Movie Analysis” . In: Maciej Eder and Jan Rybicki (eds.): _Digital Humanities 2016. Conference Abstracts_ . Kraków: Jagiellonian University & Pedagogical University, p. 753‒755.
</li>
<li id="burghardt2017">Burghardt, Manuel; Hafner, Katharina; Edel, Laura; Kenaan, Sabrin-Leila; Wolff, Christian (2017): “An Information System for the Analysis of Color Distributions in MovieBarcodes” . In: Maria Gäde (ed.): _Proceedings of the 15th International Symposium of Information Science (ISI 2017), Berlin, Germany, 13th-15th March 2017_ . Glückstadt: Verlag Werner Hülsbusch, pp. 356–358, (<a href="ttps://epub.uni-regensburg.de/35682/">https://epub.uni-regensburg.de/35682/</a>, retrieved 09/08/2017).
</li>
<li id="casey2014">Casey, Michael; Williams, Mark (2014): “Action. Audio-visual Cinematics Toolbox for Interaction, Organization, and Navigation of Film” (White Paper Report No. HD5139411), Hanover, Dartmouth College (<a href="https://hcommons.org/deposits/item/hc:12153/">https://hcommons.org/deposits/item/hc:12153/</a>, retrieved 07/12/2020)
</li>
<li id="cutting2016">Cutting, James E. (2016): _Perception, Attention, and the Structure of Hollywood Film_ . (<a href="http://people.psych.cornell.edu/~jec7/curresearch.htm">http://people.psych.cornell.edu/~jec7/curresearch.htm</a>, retrieved 01/10/2018).
</li>
<li id="cutting2012">Cutting, James E.; Brunick, Kaitlin L.; Candan, Ayse (2012): “Perceiving Event Dynamics and Parsing Hollywood Films” . In: _Journal of Experimental Psychology_ , Advance online publication, (<a href="http://people.psych.cornell.edu/~jec7/pubs/jephppscenes.pdf">http://people.psych.cornell.edu/~jec7/pubs/jephppscenes.pdf</a>, retrieved 10/15/2016).
</li>
<li id="dyer2006">Dyer, Richard (2006): _Pastiche_ . New York: Routledge.
</li>
<li id="elan">ELAN. (<a href="https://tla.mpi.nl/tools/tla-tools/elan/">https://tla.mpi.nl/tools/tla-tools/elan/</a>, retrieved 10/15/2016).
</li>
<li id="ferguson2013">Ferguson, Kevin L. (2013): “Western Roundup” . (<a href="http://typecast.qwriting.qc.cuny.edu/2013/10/07/western-roundup/">http://typecast.qwriting.qc.cuny.edu/2013/10/07/western-roundup/</a>, retrieved 07/11/2016).
</li>
<li id="ferguson2015">Ferguson, Kevin L. (2015): _Volumetric Cinem_ a. (<a href="https://vimeo.com/119790662">https://vimeo.com/119790662</a>, retrieved 11/07/2016).
</li>
<li id="ferguson2016">Ferguson, Kevin L. (2016): “The Slices of Cinema. Digital Surrealism as Research Strategy” . In: Charles R. Acland and Eric Hoyt (eds.): _The Arclight Guidebook to Media History and the Digital Humanities_ . Reframe Books, pp. 270–299, (<a href="ttp://projectarclight.org/book/">http://projectarclight.org/book/</a>).
</li>
<li id="flueckiger2011">Flueckiger, Barbara (2011): “Die Vermessung ästhetischer Erscheinungen” . In: _Zeitschrift für Medienwissenschaft_ , 5, pp. 44–60.
</li>
<li id="flueckiger2012">Flueckiger, Barbara (2012): _Timeline of Historical Film Colors._ (<a href="http://filmcolors.org">http://filmcolors.org</a>).
</li>
<li id="flueckiger2017">Flueckiger, Barbara (2017): “A Digital Humanities Approach to Film Colors” . In: _The Moving Image_ , 17.2, pp. 71–94.
</li>
<li id="flueckigeretal2017">Flueckiger, Barbara; Evirgen, Noyan; Paredes, Enrique G.; Ballester-Ripoll, Rafael; Pajarola, Renato (2017): “Deep Learning Tools for Foreground-Aware Analysis of Film Colors” . In: _AVinDH SIG_ , Digital Humanties Conference Montreal.
</li>
<li id="flueckiger2018">Flueckiger, Barbara; Halter, Gaudenz (2018): “Building a Crowdsourcing Platform for the Analysis of Film Colors” . In: _The Moving Image_ , 18.1, pp. 80–83.
</li>
<li id="flueckiger2019">Flueckiger, Barbara (2019): “The Material Aesthetics of Len Lye‘s Experimental Color Films in the 1930s” . Presentation _Len Lye Symposium_ , Tinguely Museum Basel.
</li>
<li id="genette1972">Genette, Gérard (1972): _Figures III_ . Paris: Seuil.
</li>
<li id="genette1983">Genette, Gerard (1983): _Nouveau Discours du récit_ . Paris: Le Seuil.
</li>
<li id="genette1992">Genette, Gérard (1992): _Palimpsestes. La littérature au second degré_ . Paris, Seuil.
</li>
<li id="giunti2010">Giunti, Livia (2010): _Problemi dell’analisi del testo di finzione audiovisivo. Verifica e sviluppo di un modello analitico e interpretativo con strumenti digitali_ . Università degli Studi di Pisa.
</li>
<li id="giunti2014">Giunti, Livia (2014): “L’analyse du film a l’ère numérique. Annotation, geste analytique et lecture active” . In: _Cinéma & Cie_ , 14,22/23, pp. 127–143.
</li>
<li id="gong2017">Gong, Ke; Liang, Xiaodan; Zhang, Dongyu,; Shen, Xiaohui; Lin, Liang (2017): “Look into Person. Self-supervised Structure-sensitive Learning and A New Benchmark for Human Parsing.” In: arXiv:1703.05446, (2017). (<a href="http://arxiv.org/abs/1703.05446">http://arxiv.org/abs/1703.05446</a>, retrieved 07/12/2020)
</li>
<li id="gruber2009">Gruber, Klemens; Wurm, Barbara; Kropf, Vera (eds.) (2009): _Digital Formalism. Die kalkulierten Bilder des Dziga Vertov._ Wien: Böhlau Verlag.
</li>
<li id="hagberg2008">Hagberg, Aric A.; Schult, Daniel A.; Swart, Pieter J. (2008): “Exploring Network Structure, Dynamics, and Function using NetworkX” . In: Gaël Varoquaux, Travis Vaught and Jarrod Millman (eds.): _Proceedings of the 7th Python in Science Conference_ . Pasadena, CA USA, pp. 11–15.
</li>
<li id="hahn2009">Hahn, Stefan (2009): “Filmprotokoll Revisited. Ground Truth in Digital Formalism” . In: Klemens Gruber, Barbara Wurm and Vera Kropf (eds.): _Digital Formalism: Die kalkulierten Bilder des Dziga Vertov_ . Wien: Böhlau Verlag, pp. 129‒136.
</li>
<li id="halter2019">Halter, Gaudenz; Ballester-Ripoll, Rafael; Flueckiger, Barbara; Pajarola, Renato (2019): “VIAN. A Visual Annotation Tool for Film Analysis” . In: _Computer Graphics Forum_ , 38,3, pp. 119–129.
</li>
<li id="hansen2017">Hansen, Thorsten; Gegenfurtner, Karl R. (2017): “Color contributes to object-contour perception in natural scenes” . In: _Journal of Vision_ , 17,3, März, pp. 14–14.
</li>
<li id="heftberger2015">Heftberger, Adelheid (2015): “ “Die Verschmelzung von Wissenschaft und Filmchronik” . Das Potenzial der Reduktionslosen Visualisierung am Beispiel von Das Elfte Jahr und Der Mann mit der Kamera von Dziga Vertov” . In: _La Visualisation des Données en Histoire = Visualisierung von Daten in der Geschichtswissenschaft_ , pp. 229–263.
</li>
<li id="heftberger2016">Heftberger, Adelheid (2016): _Kollision der Kader. Dziga Vertovs Filme, die Visualisierung ihrer Strukturen und die Digital Humanities_ . München: Edition Text + Kritik. [English translation: Heftberger, Adelheid (2018): _Digital Humanities and Film Studies. Visualising Dziga Vertov’s Work_ . Berlin: Springer International Publishing.]
</li>
<li id="hurlbert2013">Hurlbert, Anya (2013): “The Perceptual Quality of Color” . In: Liliana Albertazzi (ed.): _Handbook of Experimental Phenomenology. Visual Perception of Shape, Space and Appearance_ . New York: John Wiley & Sons, Ltd SN, pp. 369–394.
</li>
<li id="itten1970">Itten, Johannes (1970): _Kunst der Farbe_ . Ravensburg: Ravensburger Buchverlag.
</li>
<li id="jameson1991">Jameson, Fredric (1991): _Postmodernism. Or, the Cultural Logic of Late Capitalism_ . London: Verso.
</li>
<li id="katz1911">Katz, David (1911): _Die Erscheinungsweisen der Farben und ihre Beeinflussung durch die individuelle Erfahrung_ . London: Kegan Paul, Trench, Trubner & Co. Ltd.
</li>
<li id="katz1930">Katz, David (1930): _Der Aufbau der Farbwelt_ . Leipzig: Johann Ambrosius Barth.
</li>
<li id="lameris2019">Lameris, Bregt (2019): “Hallucinating Colours. Psychedelic Film, Technology, Aesthetics and Affect” . In: _Cinéma & Cie. Special Issue Cinema and Mid-Century Colour Culture_ , 32, Spring.
</li>
<li id="ledig1988">Ledig, Elfriede; Ullmann, G.erhard (1988): “Rot wie Feuer, Leidenschaft, Genie, Wahnsinn. Zu einigen Aspekten der Farbe im Stummfilm” . In Elfriede Ledig (ed.): _Der Stummfilm. Konstruktion und Rekonstruktion_ . München, Schaudig, Bauer, Ledig, pp. 89‒116.
</li>
<li id="liu2015">Liu, Jianli; Lughofer, Edwin; Zeng, Xianyi (2015): “Aesthetic Perception of Visual Textures. A Holistic Exploration Using Texture Analysis, Psychological Experiment, and Perception Modeling” . In: _Frontiers in Computational Neuroscience_ , 9, p. 134.
</li>
<li id="long2015">Long, Jonathan; Shelhamer, Evan; Darrell, Trevor (2015): “Fully Convolutional Networks for Semantic Segmentation” . pp. 3431–3440, (<a href="https://arxiv.org/abs/1411.4038">https://arxiv.org/abs/1411.4038</a>, retrieved 07/12/2020).
</li>
<li id="manovich2012">Manovich, Lev (2012): “How to Compare One Million Images?” In: D. Berry (ed.): _Understanding Digital Humanities_ . London: Palgrave Macmillan UK, pp. 249‒278.
</li>
<li id="manovich2013a">Manovich, Lev (2013): “Kino-Eye in Reverse. Visualizing Cinema” . In: Jeffrey Geiger and Karin Littau (eds.): _Cinematicity in Media History_ . Edinburgh: Edinburgh University Press, pp. 211–234.
</li>
<li id="manovich2013b">Manovich, Lev (2013): “Visualizing Vertov” . In: _Russian Journal of Communication_ , 5,1, pp. 44–55.
</li>
<li id="mazzanti1998">Mazzanti, Nicola (1998): “The Colours of the Film d’Arte Italiana” . In: Luciano Berriatúa, et al., _Tutti i colori del mondo. Il colore nei mass media tra 1900 e 1930. = All the colours of the world_ . Reggio Emilia, Edizioni Diabasis, pp. 141–146.
</li>
<li id="mazzanti2009">Mazzanti, Nicola (1998): “Colours, Audiences, and (Dis)Continuity in the Cinema of the Second Period ” . In: _Film History_ , 21,1, pp. 67‒93.
</li>
<li id="melgar2017">Melgar Estrada, Liliana; Hielscher, Eva; Koolen, Marijn; Olesen, Christian Gosvig; Noordegraaf, Julia; Blom, Jaap (2017): “Film Analysis as Annotation. Exploring Current Tools” . In: _The Moving Image: The Journal of the Association of Moving Image Archivists_ , 17,2, pp. 40–70.
</li>
<li id="olesen2017">Olesen, Christian Gosvig (2017): _Film History in the Making. Film Historiography, Digitised Archives and Digital Research Dispositifs_ . Amsterdam: University of Amsterdam, (<a href="https://dare.uva.nl/search?identifier=ad68a275-e968-4fce-b91e-4783cd69686c">https://dare.uva.nl/search?identifier=ad68a275-e968-4fce-b91e-4783cd69686c</a>, retrieved 10/07/2017).
</li>
<li id="olesen2016a">Olesen, Christian Gosvig; Gorp, Jasmijn van; Fossati, Giovanna (2016): “Datasets and Colour Visualizations for ‘Data-Driven Film History. A Demonstrator of EYE’s Jean Desmet Collection” . In: _Creative Amsterdam. An E-Humanities Perspective. A Research Program at the University of Amsterdam_ , (<a href="http://www.create.humanities.uva.nl/results/desmetdatasets/">http://www.create.humanities.uva.nl/results/desmetdatasets/</a>, retrieved 11/11/2016).
</li>
<li id="olesen2016b">Olesen, Christian Gosvig; Masson, Eef; Gorp, Jasmijn van; Fossati, Giovanna; Noordegraaf, Julia (2016): Data-Driven Research for Film History. Exploring the Jean Desmet Collection. In: _The Moving Image_ , 16,1, (<a href="https://muse.jhu.edu/article/640569">https://muse.jhu.edu/article/640569</a>).
</li>
<li id="plantinga2009">Plantinga, Carl (2009): _Moving Viewers. American Film and the Spectator’s Experience_ . Berkeley: University of California Press.
</li>
<li id="pause2018">Pause, Johannes; Walkowski, Niels-Oliver (2018): “The Colorized Dead. Computerunterstützte Analysen der Farblichkeit von Filmen in den Digital Humanities am Beispiel von Zombiefilmen” , (<a href="https://edoc.bbaw.de/frontdoor/index/index/docId/2591">https://edoc.bbaw.de/frontdoor/index/index/ docId/2591</a>).
</li>
<li id="redmon2015">Redmon, Joseph; Divvala, Santosh; Girshick, Ross; Farhadi, Ali (2015): You Only Look Once. Unified, Real-Time Object Detection. In: _arXiv:1506.02640 [cs]_ , Jun., (<a href="http://arxiv.org/abs/1506.02640">http://arxiv.org/abs/1506.02640</a>, retrieved 05/29/2017).
</li>
<li id="reyes-garvia2013">Reyes-García, Everardo (2013): “On Visual Features and Artistic Digital Images” . New York: ACM, (<a href="http://dl.acm.org/citation.cfm?id=2466835">http://dl.acm.org/citation.cfm?id=2466835</a>).
</li>
<li id="reyes-garcia2014">Reyes-García, Everardo (2014): Explorations in Media Visualization. New York: ACM, (<a href="ttp://www.academia.edu/download/35860006/Reyes_2014-Explorations_in_Media_Visualization.pdf,%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20http://ceur-ws.org/Vol-1210/datawiz2014_11.pdf">http://www.academia.edu/download/35860006/Reyes_2014-Explorations_in_Media_Visualization.pdf,%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20http://ceur-ws.org/Vol-1210/datawiz2014_11.pdf</a>, retrieved 07/12/2020).
</li>
<li id="reyes-garcia2017">Reyes-García, Everardo (2017): _The Image-interface. Graphical Supports for Visual Information_ . Hoboken, NJ: Wiley-ISTE.
</li>
<li id="reyes-garciabouhai2017">Reyes-García, Everardo; Bouhai, Nasreddine (2017): _Designing Interactive Hypermedia Systems_ . In: Nasreddine Bouhai (ed.). Wiley-ISTE.
</li>
<li id="rosebrock2014">Rosebrock, Adrian (2014): “How-To. OpenCV and Python K-Means Color Clustering” . In: _PyImageSearch_ , (<a href="http://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/">http://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/</a>, retrieved 06/26/2017).
</li>
<li id="ross2007">Ross, Jacqui (2007): _Colour Analysis Tools in ImageJ_ . (<a href="https://www.fmhs.auckland.ac.nz/assets/fmhs/sms/biru/docs/Colour_Analysis_Tools_in_ImageJ.pdf">https://www.fmhs.auckland.ac.nz/assets/fmhs/sms/biru/docs/Colour_Analysis_Tools_in_ImageJ.pdf</a>, retrieved 0/12/2020).
</li>
<li id="rother2004">Rother, Carsten; Kolmogorov, Vladimir; Blake, Andrew (2004): “GrabCut. Interactive Foreground Extraction using Iterated Graph Cuts” . In: _ACM Transactions on Graphics (SIGGRAPH)_ , Aug.
</li>
<li id="rubo2018">Rubo, M. and Gamer, M. “Social Content and Emotional Valence Modulate Gaze Fixations in Dynamic Scenes” , _Scientific Reports_ , 8.1 (2018): 1–11. (<a href="https://doi.org/10.1038/s41598-018-22127-w">https://doi.org/10.1038/s41598-018-22127-w</a>, retreived 07/12/2020)
</li>
<li id="smith1995">Smith, Murray (1995): _Engaging Characters. Fiction, Emotion, and the Cinema_ . Oxford, New York: Oxford University Press.
</li>
<li id="smith2013">Smith, Tim J.; Mital, Parag K. (2013): “Attentional Synchrony and the Influence of Viewing Task on Gaze Behavior in Static and Dynamic Scenes” . In: _Journal of Vision_ , 13,8, Juli, S. 16–16, (<a href="https://jov.arvojournals.org/article.aspx?articleid=2193975">https://jov.arvojournals.org/article.aspx?articleid=2193975</a>, abgerufen 03/31/2020).
</li>
<li id="stutz2016">Stutz, Olivia Kristina (2016): _Algorithmische Farbfilmästhetik. Historische sowie experimentell-digitale Notations- und Visualisierungssysteme des Farbfilms im Zeichen der Digital Humanities 2.0 und 3.0_ . Zürich: Universität Zürich, (<a href="http://www.film.uzh.ch/dam/jcr:bed543b6-4a67-4ff8-8f51-b85a739417d5/MA_AlgorithmischeFarbfilmaesthetik_Stutz_HS2016_def.pdf">http://www.film.uzh.ch/dam/jcr:bed543b6-4a67-4ff8-8f51-b85a739417d5/MA_AlgorithmischeFarbfilmaesthetik_Stutz_HS2016_def.pdf</a>, retrieved 04/09/2017).
</li>
<li id="tan1996">Tan, Ed (1996): _Emotion and the Structure of Narrative Film. Film as an Emotion Machin_ e. Mahwah, N.J, Lawrence Erlbaum Assoc Inc (1996).
</li>
<li id="thompson1986">Thompson, Kristin (1986): “The Concept of Cinematic Excess” . In: Philip Rosen, Leo Braudy and Marshall Cohen (eds.): _Film Theory and Criticism. Introductory Readings_ . New York: Columbia University Press, pp. 487–498.
</li>
<li id="thompson1988">Thompson, Kristin (1988): _Breaking the Glass Armor_ . New Jersey: Princeton University Press.
</li>
<li id="vanska2017">Vänskä, Annamari (2017): “Gender and Sexuality” . In: Alexandra Palmer (ed.): _A Cultural History of Dress and Fashion_ . Bloomsbury Academic, pp. 107–129.
</li>
<li id="wilkening2014">Wilkening, Anke (2014): “Die Restaurierung von Das Cabinet des Dr. Caligari” . In: _VDR Beiträge zur Erhaltung von Kunst- und Kulturgut_ , 2, pp. 27–47.
</li>
<li id="zhao2016">Zhao, Hengshuang; Shi, Jianping; Qi, Xiaojuan; Wang, Xiaogang; Jia, Jiaya (2016): “Pyramid Scene Parsing Network” . In: _arXiv:1612.01105 [cs]_ , Dec., (<a href="http://arxiv.org/abs/1612.01105">http://arxiv.org/abs/1612.01105</a>, retrieved 03/27/2018).
</li>
<li id="zuo2016">Zuo, Hengfeng; Jones, Mark; Hope, Tony; Jones, Robin (2016): “Sensory Perception of Material Texture in Consumer Products” . In: _The Design Journal_ , 19.03, pp. 405–427.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://filmcolors.org/galleries/das-cabinet-des-dr-caligari-1919/">https://filmcolors.org/galleries/das-cabinet-des-dr-caligari-1919/</a>## Bibliography&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Playing With Unicorns: AI Dungeon and Citizen NLP</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000533/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000533/</id><author><name>Minh Hua</name></author><author><name>Rita Raley</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<blockquote>
<p>Over the years, you have trained yourself to understand the human language.<br>
<em>AI Dungeon 2</em></p>
</blockquote>
<h2 id="1-magical-unicorn-blood">1. Magical Unicorn Blood</h2>
<p><em>AI Dungeon 2</em> was a minor sensation almost immediately after it was released as a Google Colab notebook on December 5, 2019. In the weeks prior, designer Nick Walton, then a student at BYU, had teased the launch of themagical world,but it was only once people could themselves play that the AI text adventure game truly caught fire<a class="footnote-ref" href="#walton2019c"> [walton2019c] </a>. An independent subreddit began the very next day; gaming journalists and tech bloggers picked it up; exuberant reactions and playthroughs circulated widely on social media; and within a week the game had 100,000 players. So spirited was the hype of this weird game, so insistent the recommendations, that the data egress charges for the notebook reached an unsustainable $50,000 within three days, and BYU’s Perception, Control and Cognition Lab, which had provided the support, had to shut it down. Particularly striking, and apposite for the story that we will tell in this article, was the response from the nascent AID community, which developed a peer-to-peer hosting solution within 12 hours of the take-down. But for a more sustainable path forward, and in order to expand the user base beyond those who could work with Colab notebooks, Walton and his startup company needed a browser implementation and mobile apps, which were made possible with Cortex, an open-source tool for building the infrastructural support to deploy machine learning models<a class="footnote-ref" href="#walton2020"> [walton2020] </a>. By mid-February, then, there were upwards of 1,000,000 players writing millions of stories in collaboration with a language model that had been fine-tuned on the archive of choose-your-own-adventure stories, Chooseyourstory.com, and an entire game universe, complete with animations and reenactments, was underway, with Patreon subscriptions soon to follow.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>The success of <em>AI Dungeon 2</em> is partly attributable to its underlying language model: OpenAI’s GPT-2.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Language models perform probabilistic calculations of word sequences based on training data; such calculations are now baked into our communication environments, from predictive text to application features such as Google’s Smart Compose. GPT-2 was pronounced as different — “better” but potentially dangerous — because of the size and scope of its training corpus (40GB of English-language data) as well as its parameters (1.5 billion)<a class="footnote-ref" href="#openai2019a"> [openai2019a] </a>. In the fanfare and documentation attending its partial release in February 2019, GPT-2 was said to perform almost too well, thus necessitating the withholding of the full parameter model and securing its mystique as a black box too powerful and risky for public use.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> The model’s capability could thus only be assessed through the company’s reported “synthetic text samples of unprecedented quality,” the most famous of which narrated the discovery of a herd of unicorns in the Andes Mountains<a class="footnote-ref" href="#openai2019a"> [openai2019a] </a>. Both skeptical and enthusiastic experimentation to assess whether GPT-2 was indeed as advertised abetter modelbegan almost immediately. Gwern, for example, retrained the smallest 117 million parameter model on the Project Gutenberg poetry corpus; David (Jhave) Johnston initiated a collaborative writing project entitled <em>ReRites</em> after fine-tuning the medium-sized model on a custom poetry corpus; and Adam King’s “Talk to Transformer” site invited everyone to try the model at different stages of the release with text prompts of their choosing<a class="footnote-ref" href="#branwen2019"> [branwen2019] </a><a class="footnote-ref" href="#johnston2019"> [johnston2019] </a>. Walton entered the fray with <em>AI Dungeon</em> , which he built during a hackathon in March 2019<a class="footnote-ref" href="#walton2019b"> [walton2019b] </a>. If as Walton noted of the first iteration, there was “still a ways to go before AI will be your group’s dungeon master,” the full release of GPT-2 made it possible to abandon pre-generated and cached actions, and the truly open and unscripted <em>AI Dungeon 2</em> debuted one month later<a class="footnote-ref" href="#walton2019a"> [walton2019a] </a>.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> This then is our object of study in a nutshell: a 1.5 billion parameter language-model-turned-game distributed across one of the biggest cloud computing infrastructures in the world, Amazon Web Services Cloud.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<p>As with the now-renowned species, Ovid’s Unicorn, the proof of concept is in the text samples, so we will begin with a darker version of the story, revealing what might have happened had the Americans arrived in the valley before Dr. Jorge Pérez and his team (<a href="#figure01">Figure 1</a>).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Sample <em>AI Dungeon 2</em> game play (customadventure)
        </p>
    </figcaption>
</figure>
<p>What you have just read is a sample of a custom AID adventure, which we initialized with the same seed text the OpenAI team used to generate their report of “Ovid’s Unicorn” for GPT-2’s public debut.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Althoughcustomin this context means the game can build a choose-your-own-adventure story around any starting prompt,customis also an appropriate description for the nonlinear mode of playing. Our playthrough was not the first thing the game generated in response to OpenAI’s unicorn prompt. In a shocking finding, rumblings of a herd of English-speaking unicorns were at first met with an explorer who decided to massacre them all! Since the game runs incrementally and depends on player input, every line the game generates or the player inputs can be undone using therevertcommand. Therefore, whenever the story started to devolve into nonsense, instead of generating a new story, and risk losing our progress, all we had to do was revert back a few lines and continue in a different direction. We next tried (and failed) to roleplay as the lone surviving unicorn seeking revenge against the explorer. As a last-ditch effort, we used thealtercommand to directly incorporate the fact that the explorer was talking to a unicorn into the story, but the game had a difficult time recognizing us, the second-person addressee, as anything other than human, so we had to walk all the way back to the beginning prompt, which then led to our sample playthrough.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> Compare our line-by-line rewriting to OpenAI’smeta-cherry-pickingthe story of “Ovid’s Unicorn” from a set of generated samples, and you begin to get a sense of the real possibilities of AID’s mechanics<a class="footnote-ref" href="#openai2019a"> [openai2019a] </a>.</p>
<p>The allure of AID is palpable through our own and the community’s experimentation with the game. But the source of the appeal, AID’s novelty, is not necessarily the structure of an AI-driven text adventure — after all, a PhD student had earlier implemented the partial language model asGPT Adventureto little fanfare<a class="footnote-ref" href="#whitmore2019"> [whitmore2019] </a>.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> From the start the centerpiece of popular reaction has been, as a <em>Daily Beast</em> journalist remarked, AID’s “capacity to slip into grim, hilarious, or bluntly surreal terrain” — the seemingly limitless expanse that opens up for each player with each game<a class="footnote-ref" href="#hitt2019"> [hitt2019] </a>. Not only does it offer players the opportunity to work with genre stories, but it also allows them to scriptcustomscenarios about weaponizing unicorn blood, which goes some way toward fulfilling its marketing promise:Anything is possible. Literally anything.Thus was it conceivable for <em>The Verge</em> ’s Adi Robertson to write metafiction by getting the game to write about writing about the game, for <em>Medium</em> ’s Seb Chan to roleplay as a worker at an art museum, and author Janelle Shane to become a dragon and eat the moon<a class="footnote-ref" href="#vincent2019"> [vincent2019] </a><a class="footnote-ref" href="#chan2019"> [chan2019] </a><a class="footnote-ref" href="#shane2019"> [shane2019] </a>. Shane’s assertion that “the real gold is the custom adventure prompt” underscores the point that AID might have been a flash in the pan — another momentarily fun, but ultimately minor and forgettable adaptation of GPT-2 — had it not been for Walton’s decision to add the custom option and innovative gameplay mechanics that reimagine how we interact with and assess language models<a class="footnote-ref" href="#shane2019"> [shane2019] </a>.</p>
<p>It is worth underscoring the extent to which players can build and manipulate to their own specifications a multitude of game universes. Because AID’s inferences about our world are only those that GPT-2 has gleaned from its 40GB training data (and the subsequent fine-tuning with the choose-your-story corpus), the game cannot completely replicate Newtonian physics; thus players can experience, and exploit, absurdly malleable environments, the distinction between each one perhaps hinging solely on the edibility of the moon.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> It is difficult to imagine a more enticing sandbox than one that allows players not just to build within it but to remake the thing itself. The migration of player preference from popular genres such as fantasy and mystery to a more open, literary mode, is evinced not only by the growing archive of custom stories on the AID site but also by all the formal means by which people communicate enjoyment now, from the vernacular idioms of social media to screams of delight during a video stream.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> What players are clearly riveted by is the surreal and the absurd, paradoxically presented as lexical sense, as well as the game engine or entity’s range of knowledge and linguistic competence.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> Not only does it make correct use of the past subjunctive, but it seems to know a great deal about popular culture, Internet trivia, and obscure Japanese animated serials, and it can more than plausibly engage the subject of coronaviruses.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> In this respect, the game is also an application in that it has demonstrated, in its pantological ability to complete software code, top ten lists, and how-to tutorials, its legacy as an application built on top of and driven by an all-purpose text-completion algorithm. The content that AID can output is expansive and made even more so by the game’s constant updates and changing player preferences, its capacity for linguistic fluidity somewhat belied by its appearance as a basic command-line text-adventure game.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> We might thus say thatcustomis an apposite classification for AID as a whole: a build-your-own-world text adventure game, general purpose text generator, and collaborative writing platform.</p>
<p>Both the procedural and the unstructured mode of playing lay bare a gap in our understanding of the game, and, by extension, the language model running in the backend. Our research questions, then, are these: by what means, with what critical toolbox or with which metrics, can AID, as a paradigmatic computational artifact, be qualitatively assessed, and which communities of evaluators ought to be involved in the process? Parsing the code would be an integral aspect of any assessment exercise, but technical analysis alone is not adequate, as we will suggest. An internal study of a language model, which regardless would be counter-intuitive because of the nature of its design, does not necessarily enable prediction of its decision-making<a class="footnote-ref" href="#kurzweil2012"> [kurzweil2012] </a><a class="footnote-ref" href="#knight2017"> [knight2017] </a>. Moreover, as we shall see, understanding the functioning of a language model is not the same as knowing it.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> Certainly one can read the generated stories in an ordinary sense, to determine their formal properties and evaluate their aesthetic merits. Our presupposition, however, is that it is not by itself sufficient to bring to bear on the textual output of a machine learning system the apparatus of critical judgment as it has been honed over centuries in relation to language art as a putatively human practice. What is striking even now is the extent to which humanistic evaluation in the domain of language generation is situated as a Turing decision: <em>bot or not</em> . We do not however need tales of unicorns to remind us that passable text is itself no longer a unicorn. And, as we will suggest, the current evaluative paradigm of benchmarking generated text samples — comparing output to the target data to assess its likeness — falls short when the source for generated samples is neither stable nor fully knowable.</p>
<p>It would seem that to reach an understanding of AID is to venture into the deep dark caves of the giant itself, and to proceed with an ever-present awareness that its corridors are constantly changing, perhaps even all different. It would be best to bring a friend along, and to heed the warnings and sign posts erected by adventurers that have preceded you. They are a crucial part of your exploration, offering field knowledge to which the most expensive maps by the best cartographers cannot compare. Dramatization aside, our suggestion will be that the best path towards a holistic evaluation of AID is to do a different kind of code studies, different because the object of inquiry is no longer code alone, but rather statistical distribution as well as sociotechnical assemblage. Our challenge will be to articulate the scalar, technological, and epistemological differences that AID presents, while still allowing for its unstable, virtuallyungrokkable, quality, an attribute the game shares with the content it outputs.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> Our premise is that the fast-growing AID presents an opportunity for researchers to study language models in part through the lens of the experiences of its players, who together form a dedicated, distributed community whose enthusiastic engagement reskins the real work happening in the background: the training and assessment of a machine learning system by ordinary users.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> This engagement does not contest or seek to displace the current paradigm of scholarly assessment of language models, but rather functions as a supplement to the sought-after automated, yet qualitative, scheme of evaluating natural language generation.</p>
<p>There is no shortage of material endeavoring to explain language models and machine learning for general audiences, from blog posts (e.g.<a href="#alammar2019">Alammar [2019]</a>) to podcasts and instructional videos. Although this material is indisputably effective — as we can ourselves attest — it is an open question as to whether a more interactive, hands-on, and targeted approach is more instructive, even more enjoyable, for budding machine learning practitioners.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> Our contention then will be that AID provides different means and modes of explaining Natural Language Processing (NLP) that are all the more powerful for their activation of a communal sensibility and a spirit of play. What AID affords is not unlike the “SimCity effect” that Noah Wardrip-Fruin outlines in <em>Expressive Processing</em> , for it too helps its players to understand complex software processes<a class="footnote-ref" href="#wardrip2012"> [wardrip2012] </a>. And if there is to be anAID effectwith respect to a game built on top of a neural network, it would be a prying open of the proverbialblack boxesof machine learning, and a summons not just to experience them firsthand, but also to affect their decision making at the command line, a site where human language practice is undergoing radical transformation.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> As large language models continue to grow in complexity and necessitate compute resources not readily available to ordinary users, we can look to a GPT-2 implementation such as AID for the charting of a more accessible and even responsible direction for user-oriented, <em>citizen NLP</em> .</p>
<h2 id="2-how-to-understand-large-language-models">2. How to understand large language models</h2>
<p>In order to articulate how <em>AI Dungeon 2</em> reimagines the parameters of our relationship with machine learning, we must first establish a current picture of the means by which experts and non-experts alike engage with and attempt to understand language models (LMs).<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> We begin then with a basic description by way of the Jorge Luis Borges fable, “The Library of Babel,” the once-fictional and now-actual analog for digital text. How else to explain AID’s promise of “infinite adventures” than with the idea of a Library (universe) that contains books of all possible combinations of 25 orthographic symbols — a library in which the vast majority of books are gibberish but in which there must also exist every permutational possibility, from copies of “Sonnet 18” not written by Shakespeare to versions of the <em>Odyssey</em> without Odysseus as the hero?</p>
<p>Language modeling is a subtask of natural language processing that aims to predict the ‘next step’ in a sequence of words by calculating the maximum likelihood of the next word given the previous ones, with the maximum likelihood subject to a probability distribution learned from the training corpus: Wikipedia, Project Gutenberg, or in the case of GPT-2, WebText, a corpus of some 8 million web pages scraped from Reddit posts with a minimal number of karma points.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> For language models at their current scale, Wikipedia and Gutenberg are too small, delimited, and paradoxically singular, their relationship to language too proprietary and protocological. WebText, by contrast, buries any trace of a source text and results in non-indexical output, language that does not point back to a discrete place of origin.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> As researchers have shown, what is particularly counter-intuitive is that the highest quality GPT-2 samples result from a degree of randomness rather than maximum likelihood, as one would expect to be the case for predictive text<a class="footnote-ref" href="#holtzman2019"> [holtzman2019] </a>. Adhering to rules and patterns is a common strategy of maximal probability, so the less probable the move, the greater the surprise.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> (Another way in which GPT-2, as well as RNNs, are distinct from early autocomplete models, is that the predicted tokens are fed back into the model as input for future calculations.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> )</p>
<p>Given that language models are material entities — after all, neural networks are collections of data points (often numbers) that are manipulated and stored via computer code — it seems that we simply need to read, analyze, and study the code in order to understand these models.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> Here we invoke Critical Code Studies (CCS), a reading practice that has emerged from the humanistic disciplinary formations of textual analysis and cultural studies<a class="footnote-ref" href="#marino2006"> [marino2006] </a><a class="footnote-ref" href="#marino2020"> [marino2020] </a>.<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> The premise of CCS is that computational literacy is empowering: if applied to language models, the argument would be that prying open the black box and facilitating an elementary understanding of some of the technical aspects of deep learning (e.g. Jupyter notebooks, Python, linear algebra) may enable the transfer of this understanding to other contexts and help illuminate some of the logics of choice and decision making.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> With Software Studies and Platform Studies now fully established as fields of inquiry, it can be taken as a given that code is a “cultural text,” that it can be made “knowable,” and that, for example, examining a single line of BASIC can, like its object, itself generate a labyrinthine world<a class="footnote-ref" href="#montfort2012"> [montfort2012] </a>. But for this new moment, or new situation, of deep learning, which generally presents less interpretable problems and has sparked the important field of interpretability studies, CCS may not on its own be sufficient as a means of evaluating large language models.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> Mechanistic explanations for their operations are not unimportant and indeed the evolving scholarly conversation on the architecture of neural networks, learning rules, and loss functions indicates the extent to which what we might call a grammar of machine learning has already emerged.<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> But absent an analysis of the relations between these components or objects and the training datasets — and absent an analysis of these systems in the wild, as they are used — then the study could really only be statistical and functional.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> This then raises the question of what it means to understand a deep learning system: we can understand their operations in a technical or grammatical sense <em>in silico</em> , but CCS implicitly relies upon a notion of understanding — drawing as it does on an Enlightenment discourse of what is entailed in “study,” as a practice that accounts for and systematizes the material properties of discrete entities — that is not available for deep learning systems, if for no other reason the fact that we do not yet have a consensus about either understanding neural networks or the meaning of interpretability (cf.<a href="#lillicrap2019">Lillicrap and Kording [2019]</a>).</p>
<p>More plainly, CCS has historically worked with a fundamentally different understanding of code: one that is <em>programmed</em> rather than <em>trained</em> . The academic study <em>10 PRINT</em> (in shorthand) remains the gold standard for code studies, not least because of its modeling of collective authorship<a class="footnote-ref" href="#montfort2012"> [montfort2012] </a>. And precisely because of its field-defining status, it allows for a heuristic with which we can mark this moment, and AID, as different: compare a one-line program that contains and generates multitudes (10 PRINT will not stop drawing mazes unless it is interrupted) and multitudes (training data, compute resources, parameters, lines of code) synthesized by an application so subject to continual variability that it cannot be stabilized as an artifact, except insofar as it is made athingby brand identity and common use.<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> On the one hand we have a determinist model, the notion that a computer program’s next state can be predicted via its previous state, and on the other, an autoregressive language model, the training of which entails stochastic and parallel processes that open up a variety of possible configurations in which the model could exist. Add to this the continual retraining cycle and the capricious human component across all domains of play, from unit inputs and player discussion tocustomstories, and it becomes clear that studying the code of AID alone would not be especially revelatory, which reinforces the need for new critical frameworks and methods.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup></p>
<p>It is then an understatement to say that the language models that increasingly inform and populate our computational environments are no longer subject to the simple input-output relations of something like Tristan Tzara’s “Dadaist poem.” They have evolved to encompass interconnected parts and switches with asynchronous mechanics both multifaceted and complex, and they are themselves plugged into processing engines and distributed platforms more complex by orders of magnitude.<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> However, to simply declare that language models are too complex to understand is in our view an abdication of critical responsibility, particularly in light of growing recognition of their susceptibility to adversarial training and weight poisoning — more broadly, their potential for misuse<a class="footnote-ref" href="#alzantot2018"> [alzantot2018] </a><a class="footnote-ref" href="#viswanathan2020"> [viswanathan2020] </a>. If a complete mode of understanding is as-yet unachievable, then evaluation is the next best thing, insofar as we take evaluation, i.e. scoring the model’s performance, to be a suitable proxy for gauging and knowing its capabilities. In this endeavor, the General Language Understanding Evaluation benchmark (GLUE), a widely-adopted collection of nine datasets designed to assess a language model’s skills on elementary language operations, remains the standard for the evaluation of GPT-2 and similar transfer learning models<a class="footnote-ref" href="#wang2018"> [wang2018] </a><a class="footnote-ref" href="#radford2019"> [radford2019] </a>.<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> GLUE aggregates and displays a model’s performance across all nine tasks on a public leaderboard, which was quickly dominated by the Sesame Street Transformer models (ERNIE and copious variations of BERT) that beat even the human baselines (a woeful rank 12 out of 33), thus engendering the creation of SuperGLUE, an even harder benchmark that featured more challenging and diverse tasks<a class="footnote-ref" href="#wang2019"> [wang2019] </a>.</p>
<p>Especially striking, and central to our analysis, are two points: a model’s performance on GLUE is binary (it either succeeds in the task or it does not) and GPT-2 is notably absent from the public leaderboards (although the original GPT was also beaten by Google’s BERT on GLUE).<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> The absence follows from the model’s primary talent: text generation, the evaluation of which is a bit more muddled.<sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> Historically, the work of evaluating free-form text generation has been done by expert human evaluators and is considered costly, labor-intensive and susceptible to subjectivity, motivating first the use of the crowdsourcing platform Mechanical Turk and then the search for an automated scheme for evaluation. N-gram metrics such as BLEU, ROGUE, and METEOR automate lexical matching exercises via different scoring formulas, although it can be, and has been, argued that these metrics pale in comparison to human evaluation<a class="footnote-ref" href="#novikova2017"> [novikova2017] </a>.<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup> Furthermore, although these metrics fall under the umbrella of NLG, they are used for specific tasks, with BLEU and METEOR used to evaluate machine translation and ROGUE used for summary evaluation<a class="footnote-ref" href="#see2019"> [see2019] </a>. In a blog citing the limitations of a metric-based evaluation, computer scientist Ehud Reiter remarks that “we ultimately care about whether an NLG system produces high-quality texts, not what its BLEU score is,” which is to say that scoring may have no necessary relation to the more abstract, intangible, and even incalculable quality, which is “quality” itself<a class="footnote-ref" href="#reiter2017"> [reiter2017] </a>. Because metric-based evaluations of NLG can only function as surrogate endpoints — a measuring of what practically can be measured — Reiter goes on to advise that these evaluations be verified with “human-based study” and that researchers take care to curate a dataset of “multiple high-quality reference texts” for benchmarking<a class="footnote-ref" href="#reiter2017"> [reiter2017] </a>. What then are the reference texts that inform AID?</p>
<p>There are numerous dedicated language models, from the emulative Obama-RNN to “Deep-speare,” which was trained to produce Shakespearean sonnets the crowdworking evaluators attributed to the bard himself with 50% accuracy<a class="footnote-ref" href="#hanlau2018"> [hanlau2018] </a>. The efficacy and aesthetic capacity of such models can thus be evaluated with the benchmarks of the original, i.e. if the speech sounds as if it could belong to President Obama’s archive or if the quatrains read like a newly discovered 17th-century manuscript, then the model can be said to work. But if the training corpus is not univocal — if there is no single voice or style, which is to say no single benchmark — because of its massive size, it is as yet unclear how best to score the model. Along the same lines, given the generic templates for much of AID’s game play, it is also possible to assess whether it is producing, for example, good or bad mystery, even strong or weak fantasy, with an accounting for the formal elements of its output, as different structural analyses of narrative might guide us to do (cf. Vladimir Propp, Claude Lévi-Strauss, Roland Barthes).<sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup> We might even try to assess the similarities and differences between the output of AID and the story corpus used in the fine-tuning and devise a formula for calculating the match percentage.<sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup> But if a model might be said to succeed or fail simply on the basis of imitation ( <em>imago</em> , or <em>image</em> ), a concept that preserves not only the copy but also the referent, the thing that is being copied, then a new mode and manner of critical judgment is required when neither source nor target is either stable or fully knowable. It would seem that much work in NLG evaluation operates with the assumption that there must be so-termed model texts with which to compare a model’s output, yet AID’s genre-bending capacity complicates the exercise, as does its community’s constantly-changing practices.</p>
<p>Readers for whom the benchmarking exercise is new information might well have heard in this account of textual imitation echoes of another Borges story, “Pierre Menard, Author of the Quixote,” and found themselves wondering if one of its central lessons — that reading and writing are fundamentally historical — has been forgotten. What of the insight that materially identical works can have different aesthetic properties because they were produced by different authors in different moments, which is to say that the quality of artworks cannot be determined apart from socio-cultural context? This question among others highlights for us the need for more direct humanistic engagement in the development of language models, from idea to artifact, and from training to evaluation. Humanists, we maintain, should not be content to function as end-stage participants in advanced NLP research, appearing on the scene simply to judge the quality of output from a language model as if judging entries for a creative writing award. AID, as an experiment with GPT-2, provides a model for how humanists might more meaningfully and synergistically contribute to the project of qualitative assessment going forward, and to do so in a manner not reducible to accreditation or legitimation. If humanistic scholarship in the domains of science and technology has generally tended toward an explanation of scientific phenomena and practices for other humanists, what AID offers is a means by which humanistic techniques, concepts, and modes of thought can be fed back into a machine learning system, and by extension into the research domains of science and technology.</p>
<h2 id="3-experimenting-with-gpt-2">3. Experimenting with GPT-2</h2>
<p>NLP was said to have achieved itsImageNet momentonce language modeling, like computer vision, embarked on thepre-train first, fine-tune laterphase of work.<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> Indeed, soon after the full release of GPT-2, a Google Colab notebook allowed for free and easy fine-tuning, and the work of updating a neural network’s weights became akin to a few presses of a button<a class="footnote-ref" href="#ruder2018"> [ruder2018] </a><a class="footnote-ref" href="#woolf2019"> [woolf2019] </a>. What resulted was a remarkable creative burst from people able to tweak their own copy of the model to generate, for example, “Ghost Flights” for NaNoGenMo<a class="footnote-ref" href="#goodwin2019"> [goodwin2019] </a>, and in Walton’s case, to gamify the language model. Although fine-tuning did not fundamentally alter GPT-2’s architecture, it did allow for an embodied understanding of the language model itself.</p>
<p>In this same spirit, we eagerly conducted our own fine-tuning experiments as part of the process of thinking through our research questions.<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup> To start, we wondered, if GPT-2 were fed nonsense, would it generate more nonsense? Using an excerpt from the online implementation of Borges’ “The Library of Babel” (<a href="https://libraryofbabel.info">https://libraryofbabel.info</a>) for fine-tuning led to the generation of what can only be called garbage and thus taught us the concept of overfitting, which is a model’s tendency to overmatch a limited training dataset. We also used our nonsense dataset to study the precedence of fine-tuning over pre-training — in other words, given that GPT-2 was pre-trained using almost 40GB of putatively sensical English-language data, could one hour of training it on gibberish make it forget all of its training? In a shocking finding, we found that this was indeed possible, and we were able to coax the 355 million parameter model to generate nonsense even when prompted with sense. For another experiment, we wanted to see how GPT-2 manipulated and preserved semantic structure, so we fed GPT-2 samples of visual poetry from George Herbert and Lewis Carroll to Lorna Dee Cervantes’ “Valentine” and found that GPT-2 was able to preserve the look and structure of a visual poem with new semantic content (<a href="#figure02">Figure 2</a>).<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup> (A failure to get GPT-2 to produce its own version of Carroll’s “Jabberwocky” made us aware of how much data a language model needs to function properly; for this purpose, a much larger corpus of nonsense literature would be required.) These experiments, which are admittedly not groundbreaking, were nonetheless valuable to us as exercises and thus key to the matter at hand. The true lesson, then, was that the missing tool from our evaluative toolbox was actual, hands-on practice and play, which is precisely what AID, a gamified language model, affords.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Perturbing Shakespeare’s plays by shifting each line one space further to the right allowed us to coax GPT-2 to generate new plays that reflected this same visual structure.
        </p>
    </figcaption>
</figure>
<p>We will not be the first to observe that this is the era of accessible machine learning, but we can make this observation more precise by noting that in one hour, in mid-2019, it was possible to retrain a 5GB language model on the cloud to generate any text one chose, with no charge beyond now-baseline compute resources.<sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup> Such capability has truly opened the door for amateurs, hobbyists, and autodidacts who want to study machine learning and NLP and led to the emergence of an extra-institutional culture of expertise. Telling the full story of this phenomenon is beyond the scope of this article, but we can point to the exponential growth of the arXiv repository, along with the collapse of the Courseware industry and the concomitant rise of YouTube as a learning center that substitutes on-demand access of multiple domainhow tovideos for sequential instruction.<sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup> The shift to a more open culture of machine learning can further be attributed to the Python programming language (because of its readability and widespread use), Jupyter notebooks, APIs, deep learning frameworks such as TensorFlow, and the public release of pre-trained learning models that necessitate minimal fine-tuning and updating is necessary in order to achieve good performance. We can recall AID’s origins as a collaborative student hackathon project and now grasp the technological, economic, and cultural conditions that made the game possible, while at the same time understanding it to be part of a fairly long-term tradition of amateur and hobbyist experimentation with computational technologies and techniques, from the Homebrew Computer Club to the<a href="https://creativecodecollective.github.io">Creative Code Collective</a>.</p>
<h2 id="4-_ai-dungeon_-as-case-study">4. <em>AI Dungeon</em> as case study</h2>
<p>Underlying the different affective reactions to AID is a remarkably consistent, almost-formulaic mode of analysis: commentators explain the game and how it works, describe a few noteworthy playthroughs (with an emphasis on the aforementioned <em>surrealness</em> ), and then perhaps offer some reflections on collaborative writing and artificial intelligence more generally (e.g.,<a href="#ars2020">Ars [2020]</a>). This template for the game’s reception, a paradoxically non-formalized but uniform exercise of critical judgement, opens a window onto the means by which AI enthusiasts — a category that names hobbyists and supposed non-experts — have endeavored to assess novel technological artifacts such as AID. More specifically, the template tells a story about how machine learning is understood and evaluated by audiences outside the labs. There are two significant motifs that we can detect in the otherwise MacGyvered disciplinary hodgepodge of statistical model evaluation, media analysis, narratology, and game studies. First, because GPT-2 in particular was from the start mystified as a black box, too mad and dangerous to know, there is a sense that people wanted to pry it open, to get under the proverbial hood and exploit its flaws and capabilities.</p>
<p>In an interview with Walton, <em>Gamasutra</em> ’s John Harris indirectly raises the black box problem with questions about “how [the game] works” and the “data massage needed to produce usable input and/or output” <a class="footnote-ref" href="#harris2020"> [harris2020] </a>. There are many such questions in what is evolving to become a discourse on the game, with much of the activity playing out on the r/aidungeon subreddit.<sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup> Begun on December 6, a day after the game’s release and unbeknownst to Walton, the Reddit community boasts 31,000 members as of this writing.<sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup> Although wacky playthroughs dominate the forum’s top posts (and themselves constitute a mode of evaluation), the frequently asked questions list pinned to the top of the page is particularly instructive and demonstrates the community’s systematic process of collaboratively discovering the game’s — and the language model’s — quirks. A simple search within the subreddit for permutations of the phrasehow does <em>x</em> workreturns a plethora of game mechanics-related questions and a corresponding laundry list of answers; even more significant is the game’s presence on other Reddit communities such as r/learnmachinelearning. As we will outline in this section, AID’s mechanics make a compelling contribution to the theory and practice of explainable machine learning because they allow players to interact with, and subsequently understand and exploit, the underlying language model in nontrivial ways.</p>
<p>As might be expected, playing has itself been a crucial part of understanding the game.<sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup> There is a clear parallel here between the engagement of language models via gameplay and Colin Milburn’s research on play as a means by which amateurs apprehend, and become participants in, the research domain of nanotechnology. As he argues in <em>Mondo Nano</em> , “play is a form of engagement, a manner of learning, experiencing, and experimenting from the bottom up, little by little, bit by bit&hellip;[W]hen it is no longer possible to imagine sufficient mastery of anything, having fun becomes a significant alternative to having formal expertise, an alternative to being totally on top of things” <a class="footnote-ref" href="#milburn2015"> [milburn2015] </a>. Fundamental to Milburn’s analysis, and indeed to AID, is the notion that “the play’s the thing” — in other words, players may profess an interest in the game rather than laboratory research, but gameplay in fact serves as a mask for the real work of model training, evaluation, and improvement.<sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup> The extent to which OpenAI has itself constructed the stage here should not be overlooked. Although OpenAI did partner with institutional entities to perform post-release analysis, their decision to make GPT-2 available to the public points to the value, and indeed necessity, of amateur participation for machine learning research.<sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup> Technical model evaluation cannot of course fully anticipate how the model will perform and be used — racist Twitter bots might be Exhibit A here<sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup> — so public release clearly benefits researchers, but at the same time helps to develop the general intellect, that techno-social formation that animates production. While we do not seek in this article to formalize a method for extra-institutional evaluation, we nonetheless wish to highlight AID gameplay as an assessment practice that extends well beyond the control of a small number of data scientists and in this regard participates in the larger realignment of experts and amateurs vis-à-vis applied research.<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup></p>
<p>AID’s free, user-friendly, point-and-click web interface (it is not necessary to download a model or to install programming distributions) contributes to the game’s accessibility, but the true invitation to participate is extended by the mechanics themselves. Thecustomscenarios option further frees players from the need to be proficient, or even familiar, with the canonical text adventure genres as a prerequisite for engagement. Indeed, all it takes is imaginative seed text to experience the game as, for example, a crazed inventor weaponizing a unicorn’s blood, as Aragon on his journey from <em>The Lord of the Rings</em> , or even as a livestreamer who has hit a bit of bad luck.<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup> Even then, AID’s unstructured mode of playing ensures that the underlying language model is never locked into any one mode of content generation, effectively expanding the picture of GPT-2’s supposed ceiling of fine-tuning<a class="footnote-ref" href="#radford2019"> [radford2019] </a>. By allowing players to play with the language model not only through a text adventure game, but also through conversation, coaxing it for example to describe non-existent memes and whatever future forms of content they might imagine, Walton is thus indirectly helping OpenAI benchmark GPT-2’s capabilities, albeit in a less formalized fashion.<sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup> In this respect, it can take its place alongside the puzzle game Borderlands Science, the playing of which contributes to the mapping of the gut microbiome.</p>
<p>If the end goal of NLG evaluation is to produce high-quality text that benefits the end user, then AID is a model of personalized content generation that ensures the user is in direct control of the generation. This creative writing process, and latent evaluative process, is developed by an array of advanced commands that reward discovery and experimentation and at the same time discretize the process of neural text generation. These commands, which used to take the archaic form of console commands but have now been replaced by user-friendly buttons, give players direct control of both text and world generation.<sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup> But they also directly invite player feedback, criticism, and ideas for improvements, and it is on this basis that we can claim that Walton and his team are indirectly prototyping models of automated evaluation, human-machine collaboration, and ethical machine learning research.</p>
<p>To start, therevertcommand allows players to undo and return to any previous instance of the ongoing narrative, effectively partitioning the collaborative writing process into unit utterances, as opposed to a traditional input-output pipeline. In this sense, AID emphasizes processes of revision and serves as a compelling model of an ethical approach to Artificial Intelligence, one that prioritizes means over outcomes. Stuart Russell makes the case for a reorientation of the field of AI on this basis, the necessity of which becomes starkly apparent if one considers that a hypothetical problem such as “solve global warming” would not preclude a strategy of “killing all the humans” in order to achieve that goal<a class="footnote-ref" href="#russell2019"> [russell2019] </a>. In that AID shifts the focus away from a final revelation or resolution and instead foregrounds step-by-step moves, plays, and utterances that can be revoked, it similarly takes an incremental rather than ends approach to machine learning. It is also meaningfully collaborative: helping the system learn what is good and what works requires that players continually think about the criteria they are using for model evaluation and about what they want from the text generator.</p>
<p>AID’s availability for responsible machine learning is further evinced by the memory feature. An experimental command of AID’s, rather than OpenAI’s innovation, “remember” allows users to specify bits of information that are continually fed into GPT-2 at each step of the prediction, effectively forcing the language model to always remember. Our test story of Ovid’s Blood is again instructive. In another round of play, we committed to memory the identity of the player as a unicorn and were subsequently able to prompt the language model to generate text that plausibly assumed a nonhuman subject of the story (<a href="#figure03">Figure 3</a>). Although research on implementing memory for neural networks is not novel<a class="footnote-ref" href="#weston2014"> [weston2014] </a>and theremembercommand does not actually change GPT-2’s architecture, nonetheless, it is at the very least reimagining how we interact with the language model. Thatremembershould be a hobbyist solution to one of machine learning’s more pressing concerns speaks to the value of <em>citizen NLP</em> and validates OpenAI’s indeed-open model of research. It is not difficult to see the science-fictional possibilities inremember— imagine committing Isaac Asimov’s Three Laws to memory — but in practical and concrete terms it does shift the Overton window on our expectations of machine learning, which a game like AID is training us to understand as a more deliberate, responsive, and collaborative research activity.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Playthrough of Ovid’s Blood as a unicorn (subject position established withremembercommand)
        </p>
    </figcaption>
</figure>
<p>Even more on point is thealtercommand, which allows the players to directly edit the textual output and guide the narrative forward in whichever manner or direction is desirable. While line edits might seem initially as another version of the fork-in-the-road structure of a traditional text adventure game — if the story does not take you where you want to go, you return to a control point and make another decision — what is at stake with this mechanic goes well beyond syntactic sense and narratological completion, as we learned while working on our story of Ovid’s Blood.<sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup> From the start, without any gender specified, AID assumed the American inventor was male, and thus provided a textbook instance of the doctor : man :: nurse : woman bias problem<a class="footnote-ref" href="#buonocore2019"> [buonocore2019] </a>. To remedy this, we altered the pronoun in the output line, “The inventor succeeds, but unfortunately <em>his</em> invention,” from male to female and were then able to coax the model to independently generate the subsequent line, “After several years, the inventor finally announces that <em>she</em> has bred the first unicorn calves” (<a href="#figure04">Figure 4</a>). Although we are under no illusions about our ability to redress the underlying language model’s biases comprehensively, it is not insignificant that a human can both explicitly revise a machine learning decision and implicitly train a system to (appear to) think differently.<sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup> Whataltermakes apparent is that NLG processes do not need to be closed to the public and that automation need not entail the exclusion of humans. It reminds us then that we have the capacity to intervene and shape machinic text <em>in actual collaboration</em> with machines. It is up to players to determine what the process of writing with a language model should involve, whether that be concession to a machine decision or substantive revision. And, to return to the figure of the ouroboros, what results is a hybrid corpus of high quality machine-human text that can be further regressively used for training.<sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup></p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Sample <em>AI Dungeon 2</em> game play (gender bias correction usingaltercommand)
        </p>
    </figcaption>
</figure>
<p>Apart from its multiplayer mode, the collaborative aspect of AID is perhaps nowhere more apparent than in its contributor studio, through which players can provide feedback on the game.<sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup> (Popups during gameplay additionally ask players to evaluate the game’s performance in its current state, albeit with a limited set of descriptors, e.g.greatandoffensive,from which to choose). Through the studio, players can also importantly create labels for quests, characters, and action difficulty. Such labels help the narrator identify quests that organically spawn during play, maintain dossiers on non-player characters, and even begin to tighten AID’s outlaw system of physics. It must be acknowledged that the addition of labeling is symptomatic of the ongoing fetishization of unsupervised learning, and it also buys into the tacit quid-pro-quo contract that lies behind social media: free use in exchange for labor and data.<sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup> Nonetheless, the labeling feature attests to the open, distributed, and relatively accessible culture of NLP research and makes an implicit but strong case for continuing down the path of the hackathon rather than the closed lab.</p>
<p>All very interesting as an exercise in distributed and crowdsourced machine learning research, the skeptic might protest, but is the writing any good in the end? It is this question that led us to consider the extent to which the tools and paradigms of qualitative evaluative judgment from the scientific and humanistic disciplines alike might fall short in relation to an artifact such as AID. A technical analysis of the model’s internals, albeit necessary, looks only at the building blocks and hypothesizes its use cases. And to simply assess the output in relation to benchmarks is to overlay a static, even mechanical, in-out, copy-original structure on top of a machine learning system with internal data flows taking the form of a byzantine network of zigzagging numbers in a state of continuous transformation.<sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup> Add to this the complexity of a game that is itself evolving by the day, leading to ever deeper entanglements between human and machine writers, and it becomes clear that a binary evaluation (good story, bad story) can tell us little about the material circumstances of the text’s production.</p>
<p>It turns out then that the best evaluation is done by and with AID itself. If human-based studies and the qualitative metrics currently in use in NLG research — readability, likeability, utility — can only ever be subjective, thus necessitating the forging of a kind of consensus through crowdsourcing, an even more powerful and persuasive evaluative scheme can be found in a game that gives players the tools not only to shape the very content they will consume, and thus implicitly assess, but also to train and modify the system that is producing that same content. AID crystallizes for us the potential of an open model of machine learning research: an exponential number of people are able to create new knowledge, and in some cases, be legitimized by the very institutions that granted them access, as with OpenAI recognizing Gwern and AID. But what such a mutable and mobile culture of NLP demands is an evaluation scheme that can scale and keep pace — in other words, a unicorn.</p>
<h2 id="5-gpt-3-and-beyond">5. GPT-3 and beyond</h2>
<p>When we began this article, speculations about GPT-3 were simply that, speculations. The speed of machine learning research should surprise no one, but on May 28, 2020, GPT-3 surprised us nonetheless, not simply with its size but also with its text samples of (again) “unprecedented quality,” the most startling of which must surely be its continuation of Trurl’s Electronic Bard, prompted by but not fine-tuned on Stanislaw Lem<a class="footnote-ref" href="#openai2019a"> [openai2019a] </a><a class="footnote-ref" href="#branwen2020"> [branwen2020] </a>. The model, which was announced without public release, crystallized for us, and for the researchers themselves, the ongoing problem of interpretability and training data bias<a class="footnote-ref" href="#brown2020"> [brown2020] </a>. But we took particular note of the departure from the fine-tuning paradigm, given our advocacy for accessibility and experimentation by end users, and found our investment in AID’s mechanics as models for more responsible machine learning affirmed<a class="footnote-ref" href="#openai2020"> [openai2020] </a>. After all, the initial training data for GPT-2 and GPT-3 isours— and we therefore have a significant stake in how this archive is modified, curated, and used to model normative language processes.<sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup> We have a stake as well in training, evaluating, and collaborating with the autonomous systems that will continue to speak and write on our behalf. Part of the purpose of this article has been to describe a site in which this work is already well underway.</p>
<p>Central to our thesis is the claim that citizen NLP is fundamental to maintaining public purchase on the dizzying pace of the <em>development</em> and subsequent <em>deployment</em> of machine learning models. Indirect support for this claim came from Chief Facebook AI scientist Yann LeCun, in a speech on our campus, the University of California, Santa Barbara. Riffing on Richard Feynman, LeCun professed that “you don’t really understand something until you build it yourself” and directly called for engineers and tinkerers alike to continue to build the models that will inform the theory of artificial intelligence<a class="footnote-ref" href="#lecun2018"> [lecun2018] </a>. This is precisely the lens through which to view the remarkable creative exploits of AID: as procedural literacy practices that enable the transfer of human decisions to machine learning systems and help us to build worlds, from the command line to the moon.</p>
<ul>
<li id="adadi2018">Adadi, A. and M. Berrada. “Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI).”  _IEEE Access_ 6 (2018).<a href="https://ieeexplore.ieee.org/document/8466590">https://ieeexplore.ieee.org/document/8466590</a>
</li>
<li id="alammar2019">Alammar, J. “The Illustrated GPT-2 (Visualizing Transformer Language Models).”  _Jay Alammar Blog_ (August 2019).<a href="http://jalammar.github.io/illustrated-gpt2/">http://jalammar.github.io/illustrated-gpt2/</a>.
</li>
<li id="alexander2019">Alexander, S. “GPT-2 As Step Toward General Intelligence.”  _Slate Star Codex_ (February 19, 2019).<a href="https://slatestarcodex.com/2019/02/19/gpt-2-as-step-toward-general-intelligence/">https://slatestarcodex.com/2019/02/19/gpt-2-as-step-toward-general-intelligence/</a>.
</li>
<li id="alzantot2018">Alzantot, M. et al. “Generating Natural Language Adversarial Examples.”  _Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing_ (October-November 2018).<a href="https://www.aclweb.org/anthology/D18-1316.pdf">https://www.aclweb.org/anthology/D18-1316.pdf</a>
</li>
<li id="ars2020">Ars Staff. “The machines are whispering: We tested _AI Dungeon 2_ and cannot stop laughing.”  _Ars Technica_ (January 20, 2020).<a href="https://arstechnica.com/gaming/2020/01/we-test-ai-dungeon-2-a-text-adventure-that-creates-itself-with-your-help/">https://arstechnica.com/gaming/2020/01/we-test-ai-dungeon-2-a-text-adventure-that-creates-itself-with-your-help/</a>.
</li>
<li id="ashby1957">Ashby, R. _An Introduction to Cybernetics_ . Chapman & Hall, London (1957).
</li>
<li id="aws2020"> “The Digital Download.” Amazon Web Services Game Tech (May 20, 2020).<a href="https://aws.amazon.com/gametech/events/digital-download-online/">https://aws.amazon.com/gametech/events/digital-download-online/</a>.
</li>
<li id="banko2001">Banko, M. and E. Brill. “Scaling to very very large corpora for natural language disambiguation.”  _ACL '01: Proceedings of the 39th Annual Meeting on Association for Computational Linguistics_ (July 2001), pp. 26–33.
</li>
<li id="bender2018">Bender, E. and B. Friedman. “Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science.”  _Transactions of the Association for Computational Linguistics_ 6 (2018): pp. 587–604.<a href="https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00041">https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00041</a>.
</li>
<li id="bengio2003">Bengio, Y., et al. “A neural probabilistic language model.”  _Journal of Machine Learning Research_ , 3 (2003), pp. 1137–1155.
</li>
<li id="berry2018">Berry, D. “Explainable Aesthetics.”  _Stunlaw_ (October 2, 2018).<a href="http://stunlaw.blogspot.com/2018/10/explainable-aesthetics.html">http://stunlaw.blogspot.com/2018/10/explainable-aesthetics.html</a>.
</li>
<li id="bogost2015">Bogost, I. “The Cathedral of Computation.”  _The Atlantic_ (January 15, 2015).<a href="https://www.theatlantic.com/technology/archive/2015/01/the-cathedral-of-computation/384300/">https://www.theatlantic.com/technology/archive/2015/01/the-cathedral-of-computation/384300/</a>.
</li>
<li id="branwen2019">Branwen, G. “GPT-2 Neural Network Poetry.”  _Gwern.net_ (March 2019).<a href="https://www.gwern.net/GPT-2">https://www.gwern.net/GPT-2</a>.
</li>
<li id="branwen2020">Branwen, G. “GPT-3 Creative Fiction.”  _Gwern.net_ (June 2020).<a href="https://www.gwern.net/GPT-3">https://www.gwern.net/GPT-3</a>.
</li>
<li id="brown2020">Brown, T.B., et al. “Language Models are Few-Shot Learners.” arXiv repository (2020).<a href="https://arxiv.org/abs/2005.14165">https://arxiv.org/abs/2005.14165</a>.
</li>
<li id="buonocore2019">Buonocore, T. “Man is to Doctor as Woman is to Nurse: the Gender Bias of Word Embeddings.” Towards Data Science (March 8, 2019).<a href="https://towardsdatascience.com/gender-bias-word-embeddings-76d9806a0e17">https://towardsdatascience.com/gender-bias-word-embeddings-76d9806a0e17</a>.
</li>
<li id="chan2019">Chan, S. “AI Dungeon 2: generative Cattelan & the art museum.”  _Medium_ (December 2019).<a href="https://medium.com/@sebchan/ai-dungeon-2-generative-cattelan-the-art-museum-af16eac989ec">https://medium.com/@sebchan/ai-dungeon-2-generative-cattelan-the-art-museum-af16eac989ec</a>
</li>
<li id="collins2007">Collins, H. and R. Evans. _Rethinking Expertise_ . University of Chicago Press, Chicago (2007).
</li>
<li id="galloway2004">Galloway, A. _Protocol: How Control Exists After Decentralization_ . MIT Press, Cambridge (2004).
</li>
<li id="gillespie2016">Gillespie, T. “Algorithm.” In B. Peters (ed), _Digital Keywords: A Vocabulary of Information Society and Culture_ , Princeton UP, Princeton (2016), pp. 18–30.
</li>
<li id="goodwin2019">Goodwin, R. “Ghost Flights.” GitHub repository (2019).<a href="https://github.com/NaNoGenMo/2019/issues/46">https://github.com/NaNoGenMo/2019/issues/46</a>.
</li>
<li id="guzdial2015">Guzdial, M., et al. “Crowdsourcing Open Interactive Narrative.” <a href="https://www.cc.gatech.edu/~riedl/pubs/guzdial-fdg15.pdf">https://www.cc.gatech.edu/~riedl/pubs/guzdial-fdg15.pdf</a>
</li>
<li id="halevy2009">Halevy, A. et al. “The Unreasonable Effectiveness of Data.”  _IEEE Intelligent Systems_ (2009), vol. 24, no. 02, pp. 8–12.
</li>
<li id="hanlau2018">Han Lau, J. et al. _Deep-speare: A joint neural model of poetic language, meter and rhyme._  _Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)_ (2018), pp. 1948–1958.
</li>
<li id="harris2020">Harris, J. “Creating the ever-improvising text adventures of AI Dungeon 2.”  _Gamasutra_ (January 2020).<a href="https://www.gamasutra.com/view/news/356305/Creating_the_everimprovising_text_adventures_of_AI_Dungeon_2.php">https://www.gamasutra.com/view/news/356305/Creating_the_everimprovising_text_adventures_of_AI_Dungeon_2.php</a>
</li>
<li id="hitt2019">Hitt, T. “Meet the Mormon College Student Behind the Viral A.I. Game That Took Dungeons & Dragons Online.”  _Daily Beast_ (December 2019).<a href="https://www.thedailybeast.com/meet-the-mormon-college-student-behind-viral-artificial-intelligence-game-ai-dungeon">https://www.thedailybeast.com/meet-the-mormon-college-student-behind-viral-artificial-intelligence-game-ai-dungeon</a>
</li>
<li id="holtzman2019">Holtzman, A., et al. “The Curious Case of Neural Text _De_ generation.” arXiv Preprint (April 2019).<a href="https://arxiv.org/abs/1904.09751">https://arxiv.org/abs/1904.09751</a>.
</li>
<li id="jing2019">Jing, K. and Xu J. “A Survey on Neural Network Language Models.” arXiv repository (2019).<a href="https://arxiv.org/abs/1906.03591">https://arxiv.org/abs/1906.03591</a>.
</li>
<li id="johnston2019">Johnston, D. _ReRites_ . _Glia: Digital Poetry_ (2019).<a href="http://glia.ca/rerites/">http://glia.ca/rerites/</a>.
</li>
<li id="karpathy2015">Karpathy, A. “The Unreasonable Effectiveness of Recurrent Neural Networks.” Andrej Karpathy Blog (May 21, 2015).<a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">https://karpathy.github.io/2015/05/21/rnn-effectiveness/</a>.
</li>
<li id="knight2017">Knight, W. “The Dark Secret at the Heart of AI.”  _MIT Technology Review_ (April 11, 2017).<a href="https://www.technologyreview.com/2017/04/11/5113/the-dark-secret-at-the-heart-of-ai/">https://www.technologyreview.com/2017/04/11/5113/the-dark-secret-at-the-heart-of-ai/</a>.
</li>
<li id="kurzweil2012">Kurzweil, R. _How to Create a Mind: The Secret of Human Thought Revealed_ . Viking Penguin, New York (2012).
</li>
<li id="lecun2018">Yann, L. “Self-Supervised Learning.” Distinguished Lecture Series in Data Science, UC Santa Barbara (November 8, 2018).
</li>
<li id="lillicrap2019">Lillicrap, T. and K. Kording. “What Does It Mean to Understand a Neural Network?” arXiv preprint (July 2019).<a href="https://arxiv.org/abs/1907.06374">https://arxiv.org/abs/1907.06374</a>
</li>
<li id="marcus2018">Marcus, G. “Deep Learning: A Critical Appraisal.” arXiv preprint (January 2018).<a href="https://arxiv.org/abs/1801.00631">https://arxiv.org/abs/1801.00631</a>.
</li>
<li id="marino2006">Marino, M. “Critical Code Studies.”  _Electronic Book Review_ 4 (December 4, 2006).<a href="https://electronicbookreview.com/essay/critical-code-studies/">https://electronicbookreview.com/essay/critical-code-studies/</a>.
</li>
<li id="marino2020">Marino, M. _Critical Code Studies_ . MIT Press, Cambridge (2020).
</li>
<li id="mateas2005">Mateas, M. “Procedural Literacy: Educating the New Media Practitioner.”  _On the Horizon_ 13.2 (2005), pp. 101–111.
</li>
<li id="mccormick2019">McCormick, C. and N. Ryan. “GLUE Explained: Understanding BERT Through Benchmarks.” Chris McCormick Blog (November 5, 2019).<a href="https://mccormickml.com/2019/11/05/GLUE/">https://mccormickml.com/2019/11/05/GLUE/</a>.
</li>
<li id="mcgillivray2020">McGillivray, B., et al. “Digital Humanities and Natural Language Processing: Je t’aime... Moi non plus. ”  _Digital Humanities Quarterly_ , 14.2 (2020).<a href="http://www.digitalhumanities.org/dhq/vol/14/2/000454/000454.html">http://www.digitalhumanities.org/dhq/vol/14/2/000454/000454.html</a>
</li>
<li id="milburn2015">Milburn, C. _Mondo Nano: Fun and Games in the World of Digital Matter_ . Duke UP, Durham (2015).
</li>
<li id="montfort2003">Montfort, N. _Twisty Little Passages: An Approach to Interactive Fiction_ . MIT Press, Cambridge (2003).
</li>
<li id="montfort2012">Montfort, N., et al. _10 PRINT CHR$(205.5+RND(1));:GOTO 10_ . MIT Press, Cambridge (2012).
</li>
<li id="novikova2017">Novikova, J. “Why We Need New Evaluation Metrics for NLG.” Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2241–2252 Copenhagen, Denmark, (September 2017).<a href="https://nld.ict.usc.edu/cs644-spring2020/discussions/novikova-etal-emnlp2017.pdf">https://nld.ict.usc.edu/cs644-spring2020/discussions/novikova-etal-emnlp2017.pdf</a>
</li>
<li id="openai2019a"> “Better Language Models and Their Implications.”  _OpenAI Blog_ (February 2019).<a href="https://openai.com/blog/better-language-models/">https://openai.com/blog/better-language-models/</a>.
</li>
<li id="openai2019b"> “Release Strategies and the Social Impacts of Language Models.” arXiv preprint (November 2019).<a href="https://arxiv.org/pdf/1908.09203.pdf">https://arxiv.org/pdf/1908.09203.pdf</a>
</li>
<li id="openai2020"> “OpenAI API.” (June 2020).<a href="https://openai.com/blog/openai-api/">https://openai.com/blog/openai-api/</a>
</li>
<li id="pasquale2016">Pasquale, F. _The Black Box Society: The Secret Algorithms That Control Money and Information_ . Harvard UP, Cambridge (2016).
</li>
<li id="radford2018">Radford, A. “Improving Language Understanding by Generative Pre-Training.”  _OpenAI Blog_ (2018).<a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf</a>
</li>
<li id="radford2019">Radford, A. “Language Models are Unsupervised Multitask Learners.”  _OpenAI Blog_ (2019).<a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</a>
</li>
<li id="reiter2017">Reiter, E. “How to do an NLG Evaluation: Metrics.”  _Ehud Reiter’s Blog_ (May 3, 2017).<a href="https://ehudreiter.com/2017/05/03/metrics-nlg-evaluation/">https://ehudreiter.com/2017/05/03/metrics-nlg-evaluation/</a>
</li>
<li id="ruder2018">Ruder, S. “NLP’s ImageNet moment has arrived.”  _Sebastian Ruder Blog_ (July 12, 2018).<a href="https://ruder.io/nlp-imagenet/">https://ruder.io/nlp-imagenet/</a>.
</li>
<li id="russell2019">Russell, S. _Human Compatible: Artificial Intelligence and the Problem of Control_ . Viking, NY (2019).
</li>
<li id="sarkar2018">Sarkar, D. “A Comprehensive Hands-on Guide to Transfer Learning with Real-World Applications in Deep Learning.”  _towards data science_ (November 14, 2018).<a href="https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a">https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a</a>
</li>
<li id="sample2020">Sample, M. “AI Dungeon and Creativity.”  _SAMPLE REALITY_ (January 2020).<a href="https://www.samplereality.com/2020/01/28/ai-dungeon-and-creativity/">https://www.samplereality.com/2020/01/28/ai-dungeon-and-creativity/</a>.
</li>
<li id="see2019">See, A. “Natural Language Generation.” CS224N/Ling 284: Natural Language Processing with Deep Learning (2019).<a href="https://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture15-nlg.pdf">https://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture15-nlg.pdf</a>.
</li>
<li id="sellam2020">Sellam, T. et al. “BLEURT: Learning Robust Metrics for Text Generation.” arXiv preprint (May 2020).<a href="https://arxiv.org/abs/2004.04696">https://arxiv.org/abs/2004.04696</a>
</li>
<li id="shane2019">Shane, J. “Play AI Dungeon 2. Become a dragon. Eat the moon.”  _AI Weirdness_ (December 2019).<a href="https://aiweirdness.com/post/189511103367/play-ai-dungeon-2-become-a-dragon-eat-the-moon">https://aiweirdness.com/post/189511103367/play-ai-dungeon-2-become-a-dragon-eat-the-moon</a>.
</li>
<li id="short2007">Short, E. “Conversation.”  _Emily Short’s Interactive Storytelling_ (2007).<a href="http://emshort.wordpress.com/writing-if/my-articles/conversation/">http://emshort.wordpress.com/writing-if/my-articles/conversation/</a>.
</li>
<li id="tenen2017">Tenen, D. _Plain Text: The Poetics of Computation_ . Columbia UP, New York (2017).
</li>
<li id="tenney2019">Tenney, I., et al. “BERT Rediscovers the Classical NLP Pipeline.”  _Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics_ (2019): pp. 4593–4601.
</li>
<li id="vadde2017">Vadde, A. “Amateur Creativity: Contemporary Literature and the Digital Publishing Scene.”  _New Literary History_ , 48.1 (Winter 2017): 27–51.
</li>
<li id="vincent2019">Vincent, J. “This AI text adventure game has pretty much infinite possibilities.”  _The Verge_ (December 2019).<a href="https://www.theverge.com/tldr/2019/12/6/20998993/ai-dungeon-2-choose-your-own-adventure-game-text-nick-walton-gpt-machine-learning">https://www.theverge.com/tldr/2019/12/6/20998993/ai-dungeon-2-choose-your-own-adventure-game-text-nick-walton-gpt-machine-learning</a>
</li>
<li id="viswanathan2020">Viswanathan, S. “Beware of Weight Poisoning in Transfer Learning.”  _Towards Data Science_ (May 4, 2020).<a href="https://towardsdatascience.com/beware-of-weight-poisoning-in-transfer-learning-4c09b63f8353">https://towardsdatascience.com/beware-of-weight-poisoning-in-transfer-learning-4c09b63f8353</a>.
</li>
<li id="walton2019a">Walton, N. “About _AI Dungeon_ .” <a href="http://ai-adventure.appspot.com/about.html">http://ai-adventure.appspot.com/about.html</a>
</li>
<li id="walton2019b">Walton, N. “AI Dungeon 2: Creating Infinitely Generated Text Adventures with Deep Learning Language Models.”  _Perception, Control, Cognition_ (November 21, 2019).<a href="https://pcc.cs.byu.edu/2019/11/21/ai-dungeon-2-creating-infinitely-generated-text-adventures-with-deep-learning-language-models/">https://pcc.cs.byu.edu/2019/11/21/ai-dungeon-2-creating-infinitely-generated-text-adventures-with-deep-learning-language-models/</a>
</li>
<li id="walton2019c">Walton, N. Twitter post, November 23, 2019.<a href="https://twitter.com/nickwalton00/status/1198295331449888768">https://twitter.com/nickwalton00/status/1198295331449888768</a>
</li>
<li id="walton2019d">Walton, N. “AI-Dungeon.” GitHub repository (2019).<a href="https://github.com/AIDungeon/AIDungeon">https://github.com/AIDungeon/AIDungeon</a>.
</li>
<li id="walton2020">Walton, N. “How we scaled AI Dungeon 2 to support over 1,000,000 users.”  _Medium_ (February 11, 2020).<a href="https://medium.com/@aidungeon/how-we-scaled-ai-dungeon-2-to-support-over-1-000-000-users-d207d5623de9">https://medium.com/@aidungeon/how-we-scaled-ai-dungeon-2-to-support-over-1-000-000-users-d207d5623de9</a>
</li>
<li id="wang2018">Wang, A., et al. “GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.”  _Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP_ (November 1, 2018), pp. 353–355.<a href="https://www.aclweb.org/anthology/W18-5446.pdf">https://www.aclweb.org/anthology/W18-5446.pdf</a>.
</li>
<li id="wang2019">Wang, A., et al. “SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems.” arXiv preprint (May 2019).<a href="https://arxiv.org/abs/1905.00537">https://arxiv.org/abs/1905.00537</a>
</li>
<li id="wardrip2012">Wardrip-Fruin, N. _Expressive Processing: Digital Fictions, Computer Games, and Software Studies_ . MIT Press, Cambridge (2012).
</li>
<li id="we1s2020">WE1S. “Bibliography – Interpretability and Explainability.” WE1S: A 4Humanities Project (2020).<a href="https://we1s.ucsb.edu/research/we1s-bibliography/bibliography-interpretability-and-explainability/">https://we1s.ucsb.edu/research/we1s-bibliography/bibliography-interpretability-and-explainability/</a>.
</li>
<li id="weston2014">Weston, J., et al. “Memory Networks.” arXiv preprint (2014).<a href="https://arxiv.org/abs/1410.3916">https://arxiv.org/abs/1410.3916</a>.
</li>
<li id="whitmore2019">Whitmore, N. “GPT2 Adventure.” Google Colaboratory Notebook (2019).<a href="https://colab.research.google.com/drive/1khUaPex-gyk1wXXLuqcopiWmHmcKl4UP">https://colab.research.google.com/drive/1khUaPex-gyk1wXXLuqcopiWmHmcKl4UP</a>.
</li>
<li id="woolf2019">Woolf, M. “How To Make Custom AI-Generated Text With GPT-2.”  _Max Woolf’s Blog_ (September 4, 2019).<a href="https://minimaxir.com/2019/09/howto-gpt2/">https://minimaxir.com/2019/09/howto-gpt2/</a>.
</li>
<li id="xu2000">Xu, and Rudnicky. “Language Modeling for Dialog System.”  _Sixth International Conference on Spoken Language Processing_ (ICSLP 2000).<a href="https://www.isca-speech.org/archive/icslp_2000/i00_1118.html">https://www.isca-speech.org/archive/icslp_2000/i00_1118.html</a>.
</li>
<li id="yang2017">Yang, Z. “Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent.” arXiv preprint (November 2017).<a href="https://arxiv.org/abs/1711.07950">https://arxiv.org/abs/1711.07950</a>
</li>
<li id="yang2019">Yang, Y., et al. “A Study on Interaction in Human-in-the-Loop Machine Learning for Text Analytics.”  _IUI Workshops 2019_ (March 2019).<a href="http://ceur-ws.org/Vol-2327/IUI19WS-ExSS2019-9.pdf">http://ceur-ws.org/Vol-2327/IUI19WS-ExSS2019-9.pdf</a>.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>To the best of our knowledge, there has to date been just one description of AID in humanities scholarship. In his overview of the game, Mark Sample proposed it as “a perfect object of study for so many disciplines in the humanities” <a class="footnote-ref" href="#sample2020"> [sample2020] </a>. Our article shows why that is indeed the case.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>GPT is short forGenerative Pretrained Transformer.The model was trained on a massive quantity of linguistic data to predict the next token in a sequence; this learning was unsupervised, which means the data was unlabeled and the model discovered within it the rules, patterns, and statistical features that then determined the generation of tokens.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>In August 2019, two graduate students replicated the 1.5b parameter model (as did others), and OpenAI soon thereafter did its 50% release (774m parameters). In November 2019, they released the full model, citing an only marginally better credibility score assigned to its output, after which it became possible for the public to verify the claims for GPT-2’s capability. Throughout our text,GPT-2refers to the full 1.5b model unless otherwise noted.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><em>AI Dungeon 2</em> is hereafter abbreviatedAID.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Cf.<a href="#bogost2015">Bogost (2015)</a>on Google as a “confluence of physical, virtual, computational, and non-computational stuffs.”&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Text preceded by&gt;is our input and the game’s responses follow after the paragraph breaks, although the observation that it is difficult to differentiate between our writing and that of AID is apropos. Hereafter, our experimentation with this seed text is identified as “Ovid’s Blood.”&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>The game assumes the player is a human male unless otherwise specified, as we will discuss below.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>The idea of a narrative generating system that could learn from previously written stories, and thus has theoretically limitless potential, has been realized as “Scheherazade-IF” <a class="footnote-ref" href="#guzdial2015"> [guzdial2015] </a>. Natural language researchers have also used text adventure games to train machine learning systems<a class="footnote-ref" href="#yang2017"> [yang2017] </a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>As<a href="#marcus2018">Marcus (2018, 11)</a>explains, deep learning models can only approximate physical laws because they are learned rather than encoded.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>AIPDon Twitch is a streaming channel dedicated to playing and streaming AID.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>It is unclear whether theEliza effect,the “illusion that an interactive system is more intelligent (or substantially more complex and capable) than it actually is,” pertains in the instance of an unsupervised learning model like GPT-2<a class="footnote-ref" href="#wardrip2012"> [wardrip2012] </a>. If a non-trivial aspect of theEliza effectis test subjects’ tacit willingness to overlook obvious conceptual and syntactic errors in order to believe in the intelligence of an agent, perhaps we need a new critical vocabulary to account for the hedging we must now do on the question of actual, as opposed to illusory intelligence. Regardless of whether or not GPT-2 understands in the full sense the symbols it is processing, it is indisputable that it “has [untaught] faculties&hellip; specific skills, that require a certain precision of thought,” as the Slate Star Codex blogger delineates<a class="footnote-ref" href="#alexander2019"> [alexander2019] </a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>In the Spring of COVID-19, the game introduced weekly scenarios on quarantine and Tiger King that reflected the zeitgeist of the moment. These adventures now appear as archived genre options.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>If interactive fiction as evinced most notably by <em>Adventure</em> and <em>Zork</em> relies on the structure of the puzzle to control the unfolding of the narrative, AID, both in its generic template andcustommodes, offers what might be generally characterized as free play<a class="footnote-ref" href="#montfort2003"> [montfort2003] </a>. The difference is most stark at AID’s command line, where input is not constrained by pre-scripted actions, allowing players’ flights of fancy to translate more or less seamlessly into the game world. Narrative progression thus depends less on puzzle solving and critical thinking and more on the players’ own writing.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>If we only do a rules-based evaluation, either statistical or linguistic, in order to try to understand a large language model, we risk missing what is happening at the level of rhetoric (for translator Gayatri Spivak, rhetoric is the plane or dimension of language that one has to access in order to know and sense the voice of a text in a different language; it is what makes it possible to inhabit someone else’s umwelt). A purely technical analysis would also sideline the element of social contract and reduce language to a set of rules only. As we will later note with respect to its probability distributions, what makes GPT-2 work are the moments when it breaks with the rules of grammar and logic and becomes rhetorical, the best example of which is “Ovid’s unicorn.”&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>The release of GPT-3, the next iteration of the model, on May 28, 2020, when we were in the end stages of writing this article, has made us even more acutely conscious of the difficulties of stabilizing our object of inquiry. Six months on, regular AID gameplay is still limited to GPT-2, but GPT-3 has been made available for some creative experimentation (e.g.<a href="#branwen2020">Branwen [2020]</a>) and can now be accessed as aDragon modelwith an AID premium subscription.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>GPT-2, and Transformer models more generally, are examples of <em>deep</em> learning, the operations of which are generally held to be less interpretable than supervised learning models with algorithms such as k-nearest neighbors and linear regression.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>See<a href="#yang2019">Yang et al. (2019)</a>for an argument for making machine learning models accessible and interactive, albeit not playable.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>As befits its history as a fundamental concept for cybernetics<a class="footnote-ref" href="#ashby1957"> [ashby1957] </a>, theblack boxmetaphor is ubiquitous in discussions of artificial intelligence and often used as a shorthand for the problems of explainability and interpretability<a class="footnote-ref" href="#adadi2018"> [adadi2018] </a><a class="footnote-ref" href="#russell2019"> [russell2019] </a>. It is interesting to consider the relations between this notion of obscuration and the more sinister, political usages of the concept in, for example, <em>The Black Box Society</em> <a class="footnote-ref" href="#pasquale2016"> [pasquale2016] </a>.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Our article was written before the publication of<a class="footnote-ref" href="#mcgillivray2020"> [mcgillivray2020] </a>, but it aligns with their call for more collaborations and connections between the Natural Language Processing and Digital Humanities communities.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>If prior training data from Project Gutenberg and Wikipedia tacitly suggested, in T.S. Eliot’s language, “the common word exact without vulgarity,” which is to say standard English, with all the notions of the proper and the correct that implies, the WebText corpus suggests instead that there is no common word. It is training for a language model that does not itself model communication.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>We note that GPT-3 is so large that OpenAI had to guard against an ouroboros problem by vetting its training data to ensure that datasets used for evaluation were not themselves incorporated into the training data<a class="footnote-ref" href="#brown2020"> [brown2020] </a>. This indicates the extent to which language models perform exponentially better as the datasets become more comprehensive<a class="footnote-ref" href="#halevy2009"> [halevy2009] </a><a class="footnote-ref" href="#banko2001"> [banko2001] </a>.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>The uncanny liveliness of AID’s writing about magical unicorn blood, then, results not only from its adherence to genre templates, but also from its slight break from the obvious and the expected. One conclusion to draw from this: humans may seem to display a preference for appropriation, mimesis, and memetic expression — everyone is always copying everyone else — but in actual linguistic practice, turbulent distribution is the mark of an authentichumanstyle.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>On autoregression, see<a href="#karpathy2015">Karpathy (2015)</a>. When it was released, the game fed GPT-2 up to the last eight pairs of player input and game response for prediction, but this has since been expanded<a class="footnote-ref" href="#walton2019d"> [walton2019d] </a>. The game also allows players to pin certain lines to the language model’s memory context, which are always fed into the model at each prediction step.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Work by<a href="#bengio2003">Bengio et al. (2003)</a>and<a href="#xu2000">Xu and Rudnicky (2000)</a>has seen LMs in recent years take the form of a neural network<a class="footnote-ref" href="#jing2019"> [jing2019] </a>, and work by<a href="#vaswani2017">Vaswani et al. (2017)</a>has seen the network architecture (or type) of the best LMs at present to be Transformers.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Mark Marino’s initial articulation ofCritical Code Studies,which synthesized a range of practices and conversations aboutcodeworkand how the humanities ought to think about programming languages, proposed “that we no longer speak of the code as a text in metaphorical terms, but that we begin to analyze and explicate code as a text, as a sign system with its own rhetoric, as verbal communication that possesses significance in excess of its functional utility” <a class="footnote-ref" href="#marino2006"> [marino2006] </a>. In the book form of the argument, the call to “read code the way we read poetry,” which summons the entire critical apparatus of textual studies, semiotics, deconstruction, critical theory, and cultural studies for this purpose, is presented in the form of the manifesto<a class="footnote-ref" href="#marino2020"> [marino2020] </a>. Marino is on this point following Alexander Galloway’s articulation of computers as “fundamentally a textual medium&hellip;based on a technological language called code” <a class="footnote-ref" href="#galloway2004"> [galloway2004] </a>. So, too, Dennis Tenen encourages those who might regard themselves as mere users of computational technology “to apply the same critical acuity they employ in the close reading of prose and poetry to the understanding of code and machine” <a class="footnote-ref" href="#tenen2017"> [tenen2017] </a>. Foundational for this vein of thought is Michael Mateas’ concept of “procedural literacy,” which he defines as “the ability to read and write processes, to engage procedural representation and aesthetics, to understand the interplay between the culturally-embedded practices of human meaning-making and technically-mediated processes” <a class="footnote-ref" href="#mateas2005"> [mateas2005] </a>.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>One of the most influential versions of this literacy argument is made by Noah Wardrip-Fruin in his aforementioned inaugural work of software studies<a class="footnote-ref" href="#wardrip2012"> [wardrip2012] </a>.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>For a general catalog of research on the epistemological problem of interpretable machine learning, see<a href="#we1s2020">WE1S (2020)</a>.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>One field of study that works toward a technical understanding of NLP operations isBERTology,which investigates large Transformer-based language models like BERT and GPT-2. Common research in this field attempts to interpret how a model processes data while revealing their inner representation (parameters, weights, hidden states) (e.g<a href="#tenney2019">Tenney et al. [2019]</a>).&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>David Berry makes the additional point that complex math itself presents a high bar, thus necessitating analogies and explanatory models whose aesthetics or metaphorical functioning will also require examination<a class="footnote-ref" href="#berry2018"> [berry2018] </a>.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>As of this writing, there are 446 forks of AID’s GitHub repository, the most notable of which are cloveranon and thadunge2, the two most popular unofficial releases of the game that implemented their own features. Additionally, an app- and ad-based copycat of the game ( “The Infinite Story” ) has prompted a debate within the community about IP and AID’s open-source model.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Fixing the random seed of a specific instantiation of GPT-2, and sampling only the most probable sequence, will result in reproducible results. Because a trained neural network is still necessarily deterministic by its algorithmic design, it would in fact be possible to perform a limited close reading of a specific instantiation of GPT-2 or AID, but this would be to miss the forest for a tree branch.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>It is on this basis that we suggest that examining a language model necessarily requires considering it both as a statistical distribution and a sociotechnical assemblage, with the recognition, as Tarleton Gillespie argues, that this runs the risk of obscuring the “people involved at every point: people debating the models, cleaning the training data, designing the algorithms, tuning the parameters, deciding on which algorithms to depend on in which context” <a class="footnote-ref" href="#gillespie2016"> [gillespie2016] </a>.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>The benchmarking tasks range from linguistic acceptability (determining whether a sentence makes linguistic sense) to coreference inference (reading a sentence with a pronoun and choosing the correct referent from a list, akin to the Winograd Schema Challenge). GLUE results from the paradigm shift from single, task-specific language models to transfer learning models that have demonstrated a general understanding of a “broad range” of “canonical and fine-grained linguistic tasks” <a class="footnote-ref" href="#mccormick2019"> [mccormick2019] </a>.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>Fine-tuning on GLUE was delegated as future work in the conclusion of the GPT-2 paper<a class="footnote-ref" href="#radford2019"> [radford2019] </a>.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>We take text generation to mean content generation, i.e. news articles, narratives, software code.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Recently, the Google team released a new BERT-based metric that achieved results closer to human performance. Aptly named BLEURT, the metric was pre-trained like BERT and then fine-tuned on an NLG evaluation dataset<a class="footnote-ref" href="#sellam2020"> [sellam2020] </a>.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>The use of AID to produce descriptions of hypothetical memes brings a provocative question for future research to the fore: what would a formalization for good versus bad memes look like? An institutional decision not to evaluate non-formal textual outputs might, we anticipate, be made on the basis of sociocultural value, which would presume a greater significance for news reports or code completions than for memes. Part of the significance of AID, however, is that it reminds us (again) how arbitrary such distinctions truly are, and not simply because of the vernacular content of the story archive used for fine tuning.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>It is possible to do a limited evaluation of AID in terms of interactive fiction benchmarks, in the vein of scholarship on the believability of autonomous agents; for example, one could consider sample AID playthroughs in terms of Emily Short’s guidelines for conversation model design<a class="footnote-ref" href="#short2007"> [short2007] </a>. As we will demonstrate in Section 4, however, AID has only a family resemblance to parser adventure stories, so using IF as a benchmark would necessarily be a limited exercise.&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>The process involves initializing the language model’s weights by the pre-training corpus; in more basic terms, the model first learns the syntactic and grammatical nuances of language<a class="footnote-ref" href="#ruder2018"> [ruder2018] </a><a class="footnote-ref" href="#sarkar2018"> [sarkar2018] </a>, which are then updated accordingly by a fine-tuning corpus. Fine-tuning here means shaping the model’s output toward a specific mode or genre of writing, e.g. computer code, recipes, Chinese classical poetry, video game walkthroughs, or Reddit submission titles.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>We used Woolf’s (2019) simplification of GPT-2 to conduct our experiments, fine-tuning the 355m parameter model with its parameters’ factory settings. The kernel of the work was the formulation of our speculative queries — for example,if we fine-tuned GPT-2 on <em>x</em> and gave it input <em>y</em> , would it generate <em>z</em> ?— and the formatting of our training data accordingly. So that our work can be verified and developed further, we refer readers to our Google Colab notebook (<a href="https://colab.research.google.com/drive/1obL0qdJRyF9KQYiDkRCwjKWhTnwYBrhd?usp=sharing">https://colab.research.google.com/drive/1obL0qdJRyF9KQYiDkRCwjKWhTnwYBrhd?usp=sharing</a>) for the exact parameters used in the experiment represented in<a href="#figure02">Figure 2</a>.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>We were guided here by Shawn Presser’s heuristic for forcing stanzaic line breaks, via<a class="footnote-ref" href="#branwen2019"> [branwen2019] </a>.&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>As an example of the financial and compute resources required to pre-train a large language model, OpenAI reports that the pre-training of GPT-3, its 175B parameter model, cost $4.6 million, and would have taken 335 years without advanced computing<a class="footnote-ref" href="#brown2020"> [brown2020] </a>.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>With a specific focus on authorship, Aarthi Vadde provides an account of the phenomenon of “mass amateurization” in the “critical, creative, and communicative arts, allowing amateurs to bypass the gatekeeping practices of specific institutions” <a class="footnote-ref" href="#vadde2017"> [vadde2017] </a>.&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Players can also seek explanations of AID through its community on the Discord server, via gameplay itself, and the “Help” section.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>For perspective on the scale of the user base, we note that in May 2020, the AID subreddit had approximately the same number of subscribers as the subreddit for the Democratic presidential candidate, Vice President Joe Biden. For up-to-date statistics for r/AIDungeon, see<a href="https://subredditstats.com/r/aidungeon">https://subredditstats.com/r/aidungeon</a>.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>Posts on the game’s social media communities are disproportionately dominated by screen captures of gameplay, with players trying to outdo each other’s weirdness with posts of novel outputs, from the mildly amusing to the shockingly hilarious. Competitive creativity has by no means been absent from the journalistic coverage of the game either, with the discussion almost resembling teams of scientists trying to outdo each other’s findings: Shanediscoveredthat you can roleplay as a nonhuman character, Robertson pushed the game towards the meta, and almost everyone playing has soon learned for themselves that the game’s AI is quite depraved.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>Consider in this regard how AID allows players to tweak the language model’s randomness in the settings, or, players are able to tune one of many of GPT-2’s hyperparameters, all without needing further knowledge of deep learning. Thattemperatureis advertised asrandomnessis just the start of how AID gamifies working with language models.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>OpenAI’s report of GPT-2 cites<a href="#branwen2019">Branwen (2019)</a>as a literary implementation and AID as a gaming implementation of GPT-2<a class="footnote-ref" href="#openai2019b"> [openai2019b] </a>.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>Partnering with the University of Oregon, OpenAI claims to be developing a battery of “bias probes” or “input[s] to a model designed to elucidate the model’s disposition towards producing certain kinds of outputs” in order to map GPT-2’s racial, gender, and even “conspiracy theories” biases<a class="footnote-ref" href="#openai2019b"> [openai2019b] </a>.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>On informal, hands-on, or experiential forms of expertise, also see<a href="#collins2007">Collins and Evans (2007)</a>.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>For an archive, see the subreddit’s custom prompt megathread at<a href="https://www.reddit.com/r/AIDungeon/comments/e82ia5/custom_prompt_megathread/">https://www.reddit.com/r/AIDungeon/comments/e82ia5/custom_prompt_megathread/</a>.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>It is striking that players use AID to test GPT-2’s ability to generate content distinct from text adventures, which suggests that it is not simply genre that engages and retains users. This line of thought is underscored by the fact that King’s Talk to Transformer implementation remains available, yet most of the experimentation with GPT-2 continues to be performed and documented on AID’s platform.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Because AID seems to have evolved almost by the hour throughout the first half of 2020, our analysis of its features, modes, and commands should be read with a date-timestamp. We can though speak to that class of tools that allow for editing and revision because their function has been continuous and they are integral to our argument about AID as an model of and for citizen NLP. Future research can focus on new developments such as a scripting feature that allows users to write custom JavaScript code to modify the game’s logic.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>Many aspects of AID evoke the legacy of IF, most notably its command line aesthetic and generic templates. In actual practice, however, AID is markedly different, because of both the lack of restrictions on player input and the mechanics, particularlyalter,which is experienced as a writing <em>with</em> rather than <em>against</em> the game. Although a strict comparative schema for each is outside of our purview here, we can still point to AID as a model for a potential future of IF in its offering of “a more profound and responsive type of systematic world,” as<a href="#montfort2003">Montfort (2003)</a>puts it.&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>For attempts at solving bias in NLP see<a href="#openai2019b">OpenAI (2019b)</a>and<a href="#bender2018">Bender and Friedman (2018)</a>.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>We might remark as well on the extent to which the WebText corpus is already a human-machine hybrid, given the array of algorithmic writing assistants now in common use.&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>Walton has claimed that the team has a variety of metrics derived from player engagement, including explicit feedback and user behavior, that are used to determine whether a particular iteration of GPT-2 is working<a class="footnote-ref" href="#aws2020"> [aws2020] </a>.&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>In 2018, GPT-1 fell under the broad category of semi-supervised learning, in which the model was pre-trained in an unsupervised manner but later fine-tuning saw influences from supervised learning<a class="footnote-ref" href="#radford2018"> [radford2018] </a>. Fast forward two years and GPT-3 does away with the supervised learning portion, with researchers decrying the difficulty of obtaining high-quality fine-tuning datasets<a class="footnote-ref" href="#brown2020"> [brown2020] </a>. The vision for the team was text generation without the need for fine-tuning, or at least with very limited fine-tuning, but AID’s model demonstrates that there is still value in gathering user feedback. After all, as we have noted, the language models of today are not standalone text generators, but consumer products, the revision and improvement of which has material value.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>To sum up the argument against using IF as a benchmark: AID is not a goal-oriented game that can be won or lost but rather an experimental sandbox that can produce not just stories but also code, recipes, and music.&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>The OpenAI team extends its gratitude to “the millions of people who created content that was used in the training of the model, and to those who were involved in indexing or upvoting the content (in the case of WebText)” <a class="footnote-ref" href="#brown2020"> [brown2020] </a>but a meaningful contrast can be drawn between this bracketing of citizen participation and AID’s inviting of meaningful and continuous evaluation from its players.## Bibliography&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Review of Sean Cubitt’s Finite Media: Environmental Implications of Digital Technologies</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000437/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000437/</id><author><name>Richard Snyder</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h1 id="heading"></h1>
<p>In the midst of what may now certainly be termed a climate crisis, Sean Cubitt’s conclusions in <em>Finite Media</em> remind digital humanists once again that all DH must be Eco-critical DH, because each film strip, each Tweet, and each transmission sent within our network have material consequences for this planet Earth. Backing his analyses of this current state of affairs with myriad examples of the material impact of digital technologies, the author argues that this appreciation of media materiality must come to the forefront if we are to overcome a worldwide ecological disaster which refuses a traditional political or economic solution. Cubitt contends that today’s “environmental criticism requires an elaborated theory of mediation, a concept that <em>Finite Media</em> attempts to refine by testing it against the story of the materials that media are made of” <a class="footnote-ref" href="#cubitt2016"> [cubitt2016] </a>. <em>Finite Media</em> is Sean Cubitt’s latest book, following projects like <em>Ecomedia</em> , <em>Digital Aesthetics</em> , and <em>The Practice of Light: A Genealogy of Visual Technologies from Prints to Pixels</em> , in which he has previously explored questions of media, ecology, technology, and culture.</p>
<p>Cubitt illustrates that media are finite in their ties to material resources which are themselves finite; recognition of this fact and its implications for the planet and its inhabitants then serves as a foundation for a new eco-political aesthetic, a “revolution in communications” <a class="footnote-ref" href="#cubitt2016"> [cubitt2016] </a>.To this end, in the first half of the book, the chapters “Energy” and “Matter” greet the reader with a deluge of thorough examples of how our media is affecting our world and its ecological resources, as well as those Native and Indigenous peoples and communities in the Global South who are most immediately, tragically, and too often quietly impacted by the material aspects of our media consumption. Cubitt approaches such various topics as the mining and refining of heavy metals and the creation of the Green Mpeg video codec primarily through the lens of political economy, and in a pattern which continues for the length of the book, his argument fluctuates deftly between highly complex theoretical work to concrete case studies. Upon concluding “Matter” , the reader is left with a distinct impression not only of our urgent ecological crisis and its ties to our media environment, but also of the inadequacy of the technological, economic, and political solutions with which humans have thus far reassured themselves that things will improve. In the latter two chapters, “Eco-Political Aesthetics” and “Ecological Communication as Politics” , case studies recede in favor of a complex work of criticism which begins by asserting that “the usual levers we pull are not going to work” <a class="footnote-ref" href="#cubitt2016"> [cubitt2016] </a>.In this second half of the book, Cubitt steadily builds momentum, relying upon the previous stories of our media and their materiality in “Energy” and “Matter” to suggest that real change can only come from “a politics rebuilt on aesthetic principles” <a class="footnote-ref" href="#cubitt2016"> [cubitt2016] </a>.For Cubitt, this means a new appreciation for “the unimagined beauty of a processual artifact in which the human encounters and engages with ungoverned technological and natural process” <a class="footnote-ref" href="#cubitt2016"> [cubitt2016] </a>.</p>
<p>Far from a work which espouses and explores a single point of view, <em>Finite Media</em> instead embraces the truly complex nature of a difficult problem — one which defies an easy answer. Cubitt weaves together not only insights from political economy and the study of media as material, but aesthetics, environmental science, and postcolonialism as well. His success in doing so is paralleled by an extreme attention to detail. Few will be able to finish the first half of this book without feeling as though Cubitt has thoroughly done his homework, and that lends his arguments in the second half — which would otherwise at times appear quite abstract — clarity, immediacy, and tangibility.</p>
<p>The book’s writing and structure itself occasionally distracts from this admirable accomplishment, however, as many readers — especially those unfamiliar with Cubitt’s theoretical foundations in political economy and materialism — may find that they must retrace the argument’s steps. This is not to say that the book is not well-written; on the contrary, Cubitt’s command of language makes itself evident in a concise and eloquent prose, one that encourages deep reading and reflection. The problem for many readers will instead lie in the sense that ideas often seem simply disconnected. Readers face this particularly in the first two chapters, “Energy” and “Matter” , where the core ideas that drive them may be lost amid a sea of case studies and subheadings which too often fail to declare their intentions or connections with each other, and the goals of the chapter. Fortunately, Chapter Three, “Eco-political Aesthetics” , and Four, “Ecological Communication as Politics” , are more clearly focused, tying all of the book’s constituent elements and examples together skillfully in its concluding pages.</p>
<p>In 2014, having stated the current and future impacts of human activity on the planet and its nonhuman inhabitants with shocking clarity, Bethany Nowviskie asked, “what is a digital humanities practice that grapples constantly with little extinctions and can look clear-eyed on a Big One?” <a class="footnote-ref" href="#nowviskie2014"> [nowviskie2014] </a>. Cubitt’s take on media in the anthropocene contributes to ongoing conversations within the digital humanities which seek to address this question. Cubitt sees his work in <em>Finite Media</em> following that of Grossman (2007), Feilhauer and Zehle (2009), Gabrys (2010), Maxwell and Miller (2012), and Parikka (2015). Parikka’s <em>A Geology of Media</em> pairs particularly well with <em>Finite Media</em> due not only due to timing, but due to a shared sense of scope and magnitude of humanity’s influence on the planet, past and present. Where Cubitt stays focused on the Anthropocene in its present reality as he tells the “story of the materials that media are made of” — the impact of matter and energy on people and environments today — Parikka tells similar stories in long-form by zooming out to the scale of deep geological time, much like Jeffrey Jerome Cohen does with a singular focus in <em>Stone</em> . Nicole Starosielski’s <em>The Undersea Network</em> , also published in 2015, focuses intensely on one aspect of the vast media architecture laid out by books like <em>Finite Media</em> and Parikka’s <em>Geology</em> , that of the political and ecological consequences of our reliance upon large fiber cables for high-speed internet. Like Cubitt, Starosielski considers the political, economic, and ecological impacts of our desire for swift communication — one sees the potential for treatments of each of the topics that Cubitt investigates in his chapters “Energy” and “Matter” in similar detail. Ultimately, and in conjunction with works such as these, <em>Finite Media</em> ’s most stirring contribution to digital humanities in the Anthropocene is the idea of an eco-political solution which involves revising our aesthetic relationships to media.</p>
<p>In endeavoring to prove and define a colossal, looming problem for humanity and offer a real solution, <em>Finite Media</em> attempts a great task in exactly 200 pages — and it ultimately succeeds. Cubitt’s accomplished project will provide a new perspective and inform the work of scholars across the Digital Humanities, and in disciplines as varied as media studies, political economy, eco-criticism, critical theory, and postcolonialism. Moreover, in its focus on an aesthetic solution, it will inform and empower artists and media scholars who seek tangible ways to engage with the current ecological crisis.</p>
<h2 id="bibliography">Bibliography</h2>
<ul>
<li id="cubitt2016">Cubitt, Sean. _Finite Media: Environmental Implications of Digital Technologies_ . Durham: Duke University Press, 2016.
</li>
<li id="nowviskie2014">Nowviskie, Bethany. “Digital Humanities in the Anthropocene” . 10 July 2014. Accessible at:<a href="http://nowviskie.org/2014/anthropocene">http://nowviskie.org/2014/anthropocene</a>.
</li>
</ul>
]]></content></entry><entry><title type="html">The Phenomenon of Interwar City Symphonies: A Combined Methodology of Digital Tools and Traditional Film Analysis Methods to Study Visual Motifs and Structural Patterns of Experimental-Documentary City Films</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000495/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000495/</id><author><name>Eva Hielscher</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="city-symphonies-and-a-halfblind-spot-in-film-history">City Symphonies and a (Half‑)Blind Spot in Film History</h2>
<p>This article is based on my PhD dissertation <em>Rewinding the City Symphony: Historiography, Visual Motifs and Structural Patterns of Interwar City Symphony Films</em> (Ghent University, 2018) and reflects on the methodology applied for the analysis of visual material. In this regard, what follows can be considered as a research report – with a special focus on the methods chosen and put into practice to study and analyze city symphonies, making use of digital humanities tools in a film studies research. Particularly, the digital film/video annotation software ELAN, the Cinemetrics method, a bar chart representation of shot lengths, and the grid visualizations of multiple film frames created as image montages with ImageJ play a role in this case study.</p>
<p>City symphonies are experimental-documentary city films of the 1920s and 1930s that take the modern metropolis as their protagonist and present it in its multiple facets and kaleidoscopic nature. Often described as cross-section or montage films (e.g.<a href="#kracauer1947">Kracauer, 1947</a>;<a href="#weihsmann1997">Weihsmann, 1997</a>;<a href="#koeck2010">Koeck and Roberts, 2010</a>), they combine a great number of visual urban motifs and themes with a highly complex editing structure. The most famous examples are Walther Ruttmann’s <em>Berlin. Die Sinfonie der Grosstadt</em> ( <em>Berlin, Symphony of a Great City</em> , 1927) and Dziga Vertov’s <em>Chelovek s kinoapparatom</em> ( <em>Man with a Movie Camera</em> , 1929). To this day, these films exert a considerable influence on filmmaking and the cinematic language in general. Recent city films such as <em>London Symphony</em> (Alex Barrett, 2017), <em>Symphony of Now</em> (Johannes Schaff, 2018), or Mark Cousins’s <em>I am Belfast</em> (2015) and <em>Stockholm My Love</em> (2017) are just the most obvious indications for this impact and popularity.</p>
<p>However, despite the ongoing (or reviving) influence on the production of urban films and the canonical status of Ruttmann and Vertov’s films, the city symphony has remained a somewhat downplayed and neglected phenomenon in film history. While, on the one hand, in fact, it <em>is</em> considered as a crucial part of canonical film history today and as a basis for the fast-growing scholarship on city films in general (see e.g.<a href="#bordwell2019">Bordwell and Thompson, 2019</a>;<a href="#nowell-smith1997">Nowell-Smith, 1997</a>;<a href="#koeck2010">Koeck and Roberts, 2010</a>;<a href="#mazierska2003">Mazierska and Rascaroli, 2003</a>), on the other hand, it has never really been more than “a colorful footnote to film history” <a class="footnote-ref" href="#kinik2008"> [kinik2008] </a>. Indeed, besides the handful of well-known titles, which include also <em>Manhatta</em> (Paul Strand and Charles Sheeler, 1921) and <em>Rien que les Heures</em> ( <em>Nothing But Time</em> , Alberto Cavalcanti, 1926), there have been more than eighty films made around the globe in the interwar period.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> Many of these films fell into oblivion and have received little or no scholarly attention at all. Hence, the city symphony phenomenon was much more complex, widespread and diverse than generally assumed and acknowledged in film historiography. Moreover, even the canonical examples have never systematically and structurally been analyzed in detail in a comparative way. While there have been studies on individual titles, publications putting the city symphony in context of the broader field of the city film, and a few attempts mentioning and discussing a group of films together and highlighting <em>some</em> features (rough descriptions and short characterizations), a comprehensive analysis concerning shared visual and structural qualities and the central characteristics of the city symphony has never been made.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> The result is the lack of a sophisticated and clear definition of the city symphony, based on both the canonical films and the greater city symphony corpus, that is still missing after decades of film studies. This blind spot is striking since it does not concern obscure films fromthe edgeof film history, but a vast international phenomenon and films that were highly celebrated at their time and – once more – whose popularity and influence are recognizable to this very day.</p>
<p>What constitutes the city symphony looking at shared elements of the canon films <em>Berlin</em> , <em>Man with a Movie Camera</em> , <em>Rien que les Heures</em> and <em>Manhatta</em> as well as the bigger corpus? What are the visual motifs, formal and structural features of the city symphony? My research sets in at this point, addressing the conspicuous absence of an analysis of city symphony characteristics, as it delves deeper into the phenomenon by examining the films themselves.</p>
<h2 id="a-perfect-fit-city-symphonies-and-computational-analysis-methods">A Perfect Fit: City Symphonies and Computational Analysis Methods</h2>
<p>With their highly complex structure, dense imagery and themes as well as their experimental techniques and striking editing patterns, city symphonies are a perfect fit for a computational film analysis, which in segmentations and annotations allows to structurally, precisely and in detail identify individual elements (such as motifs), break down the complexity of these films into separate component parts, and makes it possible to see how different aspects are linked to each other. Moreover, city symphonies do not only share the fractured nature and overwhelming, chaotic impressions with the modern city<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> – their very subject matter – they also relate to the database logic of the computer. According to<a href="#manovich2001">Manovich (2001)</a>, the database as a cultural form introduced the “correlate” to the linearity and cause-and-effect trajectory of the logic of the narrative and a new way of structuring our experiences, presenting the world as a list of items and refusing to order this list. Every item possesses the same significance as any other. In addition, Manovich explicitly describes Man with a Movie Camera as “perhaps the most important example of a database imagination in modern media art,” which anticipated the database logic of digital media in presenting an almost “linear printout [&hellip;] of a database” and “a catalog of subjects that one could expect to find in a city of the 1920s,” supplemented with “the most amazing catalog of film techniques.” <a class="footnote-ref" href="#manovich2001"> [manovich2001] </a><sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> Similarly (and following Manovich’s ideas), Cowan integrates Ruttmann’s <em>Berlin</em> and the city symphony form in general in the same tradition of the database logic as it emphasizes “paradigmatic over syntagmatic relations, presenting the world as an inventory of possible choices rather than a causal chain of narrative events” <a class="footnote-ref" href="#cowan2014"> [cowan2014] </a>. Moreover, apart from their form underlining and embracing the database logic,<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> both <em>Man with a Movie Camera</em> and Berlin were based on actual databases documenting city life. Vertov, as we can see in his film, arranged his film reels on shelves according to keywords, such ascity traffic,factory,machines,andmarket,while Ruttmann used a card catalogue system for organizing his footage (see Figure 1 and Figure 2). In this regard, a computational study of city symphonies also comprises a self-reflexive moment as it shares its database logic with its very subject of research and aims to build a catalogue or database of city symphony features itself by looking at individual component parts of the films as equal items.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Vertov&rsquo;s film reels archive in <em>Man with a Movie Camera</em>
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Example of Ruttmann&rsquo;sKartothekused for <em>Berlin</em> , published in <em>Film-Kurier</em> (1926, September 11)
        </p>
    </figcaption>
</figure>
<p>Finally, city symphonies are a perfect case study for exploring the possibilities and applications of computational methods for film analysis as they allow for a variety of research questions, including the issue of film style (editing patterns, experimental techniques etc.), questions of content (motifs, themes), and specific aspects concerning the representation of people and the city.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Analysis scheme for the city symphonies research
        </p>
    </figcaption>
</figure>
<h2 id="film-analysis-step-1-elan">Film Analysis Step 1: ELAN</h2>
<p>For the study of visual motifs and structural patterns of interwar city symphonies, I made use of the digital video annotation software ELAN.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> More precisely, ELAN formed the center and very fundament of the bottom-up analysis, based on which further analysis steps followed in terms of data evaluation and visualizations (see Figure 3).</p>
<p>Created by the Language Archive of the Max Planck Institute for Psycholinguistics in the Netherlands, ELAN was originally developed for a community of linguists and communication scholars. Nevertheless, this free and open-source tool can also be used in film studies and for visual and structural analysis, as it belongs to a group of professional video annotation programs that support manual annotation tasks, based on a tiered or layered timeline approach to segmentation and annotation. Put differently, a media stream can be divided into multiple segments grouped in categories. ELAN supports this via horizontal rows (or tiers) organized vertically under each other. Each tier corresponds to an annotation type or category the user can define herself according to specific needs and research questions. Within the individual tiers, segments can be defined and annotated, which appear in a horizontal, time-based distribution on the particular tier (see Figure 4).<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>ELAN interface with tiers and annotations (example <em>Berlin</em> )
        </p>
    </figcaption>
</figure>
<p>As single stand-alone platform, ELAN facilitates the analysis of visual material by providing the digital video file (the film), the timeline, segmentation, and annotations in one and the same platform, thereby directly linking these elements to each other so that jumping in the timeline (respectively a tier) brings one to the corresponding fragment and vice versa. What you see is directly where and what you segment and annotate. Moreover, it provides a visualization of the film, its timeline, and the segments and annotations, thus making visible in the same platform the film picture and a visualization of its analysis.</p>
<p>There are other digital video annotation tools, including Anvil, Advene, and Lignes de temps, which follow a comparable approach as ELAN and allow for similar analysis operations and options.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> However, a brief exercise with these four software programs demonstrated that ELAN was the most convenient and most suitable for my research endeavor. This concerned the media player with its playback rate possibilities, its media control panel, and viewing options as well as the handling and viewing possibilities of the timeline, tiers, and annotation sections. More precisely, ELAN facilitates to speed up the playback rate of the video up to 200% and slow it down to 10%. Moreover, the media control panel supports to jump ahead or back in the video (and the timeline) from one second down to one millisecond,<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> while the video image can also be enlarged and presented in a separate window, unlocked from the control panel and annotation sections. In addition, the tiers can be zoomed in and out, which makes also the segmentation and annotation of extremely small or short segments in a detailed and precise way possible. Indeed, ELAN was also the most convenient of the four tested tools in the manner how it facilitates the creation of segments and the adding of annotations and comments in a very detailed way. As the focus of the analysis in my case lay both on the visual content and structural patterns of city symphonies, the latter for which montage plays a key role, a shot-based segmentation and annotation was the desired goal. In this regard, with its slow playback options of the video and zoom-in display of the timeline and tiers, ELAN allowed to identify and mark also extremely short takes of only a few (or even a single) frame(‑s) and analyze sections of extremely fast editing. In fact, city symphonies are often marked by such a fast and rhythmic editing, for which <em>Berlin</em> ’s opening sequence with a train approaching the city and <em>Man with a Movie Camera</em> ’s cross-cutting of telephone operators and a factory worker putting cigarettes into boxes are emblematic examples (see Figure 5 and Figure 6). ELAN’s option to set a shot change on the timeline linked to the picture (while the film is playing or pausing) in a very detailed and controlled way made it possible to create a shot-based segmentation also of these more challenging parts of city symphonies that one can go back to and replay at every point on the timeline as often as necessary.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>ELAN screen shot of <em>Berlin</em> &rsquo;s opening train-ride sequence
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>ELAN screen shot of <em>Man with a Movie Camera</em> &rsquo;s telephone-operators-and-cigarette-boxes sequence (reel 4)
        </p>
    </figcaption>
</figure>
<p>Moreover, its flexibility of defining multiple tiers according to one’s own research purposes, the option to use the same (self-defined) template of tiers as a blueprint for various films, the possibility of creating and using predefined vocabularies for individual tiers,<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> and the combination of these aspects were advantages of ELAN. Another benefit is the tool’s search function, which allows to easily find a specific fragment – without scrolling, clicking, or reeling through the film – and get a list of all annotations, shots or segments including a particular search word. In this way, if a certain consistency is applied in the annotation process, one can, for instance, find all the shots containing a traffic policeman in <em>Berlin</em> in a single search request (see Figure 7). Finally, ELAN’s complete and detailed user manual, its support of various digital video file formats and codecs, its export options, and its computer system requirements as an actively supported and maintained tool contributed to the decision to work with this software.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>ELAN screen shot of search results for shots including a traffic policeman in <em>Berlin</em>
        </p>
    </figcaption>
</figure>
<p>For the analysis of city symphonies, I manually segmented the four films <em>Berlin</em> , <em>Man with a Movie Camera</em> , <em>Rien que les Heures</em> , and <em>Manhatta</em> and added descriptions, words, and keywords to the segments in a number of tiers focusing on motifs and visual elements, bigger thematic sequences, people, the cityscape, specific locations, and filmic techniques such as fades, multiple exposures, split screens, and fast motion (see Figure 4).<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> As mentioned above, segmenting in this case meant a very fine-grained segmentation at shot level as the basis for adding annotations to the individual tiers.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> Hence, I identified all shots and marked all shot changes,<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> and used the same self-defined tier template for segmenting and annotating all four films in order to make a structural and precise comparison of their data possible.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup></p>
<h2 id="film-analysis-step-2-word-and-shot-lists-excel-sheets-cinemetrics-and-imagej">Film Analysis Step 2: Word and Shot Lists, Excel Sheets, Cinemetrics, and ImageJ</h2>
<p>After the segmenting and annotating operation in ELAN, a time-consuming activity that took four weeks for the four canon films and required a high level of concentration to guarantee consistency and accuracy, further analysis steps followed. Basically, there were two tasks that required a couple of additional steps. The four data sets from ELAN (each corresponding to one of the films) had to be merged into one, allowing for a direct comparison and combined data evaluation. Following my research questions, I was interested in the <em>shared</em> features of the city symphony films rather than in detailed analyses of individual titles. Moreover, this data merging into a combined data set of city symphony films should happen according to the foci on visual motifs and structural patterns.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> Consequently, the analysis should result in two lists: one for visual motifs, one for structural patterns. In this regard, annotations from the tierimagery/visual shot elementswere used for the motif analysis, while the very segmentation, the tiershot list,as well as the tierfilmic techniques,and the timeline visualization in ELAN formed the basis for the structural analysis (see Figure 3). Nevertheless, it needs to be said that both parts of the analysis, lists, and sections also stand in dialogue with each other and cannot be split that strictly. Indeed, it is also not desirable to do so as visual motifs and structural patterns, content and form are interrelated.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></p>
<h2 id="motif-analysis">Motif Analysis</h2>
<p>For the analysis of visual motifs, I exported the tier on visual elements from ELAN. More precisely, ELAN provides an export option calledList of Words,for which one can select a single or several tiers. The software compiles a wordlist in alphabetic order from all annotations in the selected tier(‑s) in a text file, optionally accompanied by the occurrences of the words. In this way, I was able to get an overview of all annotated visual shot elements of the four canon films.</p>
<p>Moreover, the occurrences gave me an idea about important aspects. However, while an appearance of trams in at least 68 shots in <em>Berlin</em> hints at a rather important and recurring visual element, the amount of only one shot presenting a street cleaning vehicle does not necessarily lead to the opposite conclusion of a minor motif. In fact, theoretically, all trams could have been visible in the background of the frame, whereas the street cleaning vehicle in a single shot of three minutes could have been in the very center of attention. In this regard, the street cleaning vehicle would form an essential visual motif too, even though it occurs only in a single shot. This, of course, depends also on the way and detail of analysis and the guidelines the scholar defines and applies in the annotation process.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> Nevertheless, the example demonstrates that the occurrences exported from ELAN can be considered as indications in terms of importance rather than as absolute entities. Indeed, quantitative and qualitative aspects have to go together, since the trained eye and viewing experience of the film scholar can identify nuances and decide about emphases, thereby enriching, correcting, or verifying results from a strictly formal analysis of visual shot elements.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup></p>
<p>Based on the exported word lists of the four canon films, I clustered the individual elements per film to motif groups and added a number of further aspects from the tiers relating to questions of people, elements of the cityscape (e.g. streetscape, industrial site, specific building or monument), and greater narrative sequences and themes, such as commute, morning routines or lunch break. Subsequently, these processed word lists were merged manually into a master list of visual motifs, indicating if a specific motif identified in this bottom-up approach could be found in one, several, or all four canon films as shared feature of city symphonies (see Figure 8).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Excerpt of motifs list
        </p>
    </figcaption>
</figure>
<h2 id="structure-analysis">Structure Analysis</h2>
<p>The analysis of structural patterns and filmic (montage) techniques was more complex than the motif analysis as it required further sub-steps and introduced two additional computational analysis tools: Cinemetrics (or better: the Cinemetrics approach) and ImageJ in combination with the plug-in ImageMontage. Before explaining what these two analysis methods comprise, there is another step to mention, which forms the fundament for both of these methods.</p>
<p>While for the motif analysis I exported alphabetic word lists from ELAN, for the structure analysis I exported shot lists with timecodes. In fact, when identifying shot boundaries on the timeline with the cursor during the segmentation process, ELAN notes the timecodes, which can be exported (via thetab-delimited textoption and text files) into Excel spreadsheets as timecoded shot lists.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> Hence, the fine-grained segmentation on shot level was the basis for this export option and, subsequently, for a film rhythm and montage analysis both in the Cinemetrics tradition and with the software ImageJ. Both of these tools rely on timecodes and shot durations, supplemented, in the case of ImageJ, by a precise indication of frame numbers.</p>
<p>Yuri Tsivian and Gunars Civjans (later joined by Daria Khitrova) launched Cinemetrics in 2005, a software that supports the measurement of films by counting the length, (type), and number of shots and presenting the results of these measurements in bar charts – as visual representation of the rhythm and editing patterns of films.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> In these charts, the shots are arranged according to their succession in the film on the x-axis, while the height of the individual bars on the y-axis visualizes the duration of each shot (see Figure 9). Such an analysis and representation of shot durations is especially valuable for city symphonies, since these films – as montage films – are concerned with both the tempo of the city and the rhythm of the films themselves, a rhythm created purely by visual means and by translating musical guidelines into the visual language of cinema.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Cinemetrics shot length and film rhythm analysis of <em>Man with a Movie Camera</em>
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Shot length and rhythm analysis of <em>Rien que les Heures</em> in Excel (with ELAN data)
        </p>
    </figcaption>
</figure>
<p>In this regard, I combined an analysis in the Cinemetrics tradition with data compiled in ELAN. The emphasis lies on <em>tradition</em> (or the Cinemetrics approach) since I did not use the very Cinemetrics software itself, but took the data exported from ELAN, the start times and durations of shots, to compile comparable bar charts of shot lengths in Excel (see Figure 10). The motivation to work with Excel and ELAN instead of Cinemetrics was to combine the analysis work in one tool and avoid segmenting and analyzing the same material multiple times in different programs. Moreover, Excel in combination with ELAN guaranteed a higher degree of accuracy, as shot changes can be identified more precisely in ELAN than with the Cinemetrics tool, and all four films were analyzed and measured exactly in the same way.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> In fact, it needs to be said that ELAN itself in its timeline approach offers a representation of rhythm and shot lengths, too, as it displays shots (or segments) in their respective length horizontally next to each other, split by vertical lines representing shot changes (see Figure 5 and Figure 6). However, the tool does not allow to zoom out as far as to see an entire act or even the whole film.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> The bar charts in Cinemetrics and Excel, on the other hand, support such a complete (over‑)view.</p>
<p>In the end, film rhythm and editing do not only rely on shot length, but also relate to alternation between shot distances, movements within shots, camera movements, and the content of shots. As Vertov himself put it, montage is “the sum of various correlations,” including “the correlation of planes” (shot distances), “the correlation of movement within the frame, the correlation of light and shadow,” and “the correlation of recording speed” <a class="footnote-ref" href="#vertov1984"> [vertov1984] </a>.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> In this regard, ImageJ with the plug-in ImageMontage provides an analysis and visualization form that takes these elements into account and complements the graphical Cinemetrics analysis with a more figurative expression. More precisely, in its specific application developed by Manovich’s Software Studies Initiative,<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> this software allows to combine a selection of individual film frames into a single image as a grid – as a montage of images. As Olesen explains:</p>
<blockquote>
<p>As a cinemetric tool, the ImageJ/ImagePlot software developed within Cultural Analysis distinguishes itself by processing films as image sets to create visualisations, instead of extracting metadata to produce reduced, statistical representations. ImageJ breaks down video files into sequences of separate images and seriates them according to specific image features in various visualization types. For example, the Montage visualisation type orders frames onto a grid according to their sequential order, in rows from left to right, enabling a quick, comprehensive overview of movements between shots.<br>
<a class="footnote-ref" href="#olesen2017"> [olesen2017] </a></p>
</blockquote>
<p>Indeed, by breaking down video files into separate still images, ImageJ recreates (more or less accurately) the individual frames of a film in digital form, comparable to their analogue equivalents on the film stip. Via a text file with a list of file names corresponding to individual images in the total number of images of a film, the ImageMontage plug-in allows to define a very specific selection of pictures to be compiled into such a montage visualization. For the analysis of city symphony structures, film rhythm, and editing patterns, I defined and produced three different types of image montages: Either a montage consisted of all individual frames of a shot or sequence (see Figure 11) or it represented a selection of frames from a specific scene or sequence: This selection presented one frame per second (see Figure 12) or it displayed one frame per shot (see Figure 13 and Figure 14).<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> Together, these three montage types, used depending on the length and complexity of the specific shot or sequence to analyze, facilitated a deeper and more nuanced study of film rhythm and different editing patterns by taking a look at the visual material of the films in a <em>condensed</em> or compact way.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Image Montage of <em>Rien que les Heures</em> &rsquo;s newspaper sequence (all frames of the shots, 31'10&rsquo;&rsquo;-31'26&rsquo;')
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Image Montage of <em>Berlin</em> &rsquo;s newspaper headlines, rollercoaster, merry-go-round and spiral sequence (one frame per second, 46'55&rsquo;&rsquo;-47'34&rsquo;')
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Image Montage of <em>Manhatta</em> &rsquo;s crowds in the city sequence (one frame per shot, 1'41&rsquo;&rsquo;-2'59&rsquo;')
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Image Montage of <em>Man with a Movie Camera</em> &rsquo;s train ride sequence (one frame per shot, 10'16&rsquo;&rsquo;-11'14&rsquo;')
        </p>
    </figcaption>
</figure>
<p>To be able to produce these image montages and define specific frames to be included in the grids, it was essential to convert ELAN’s timecodes of shots and shot changes into frame numbers corresponding to the numbers of individual images in the film (or video file respectively). In fact, if ELAN would have had an option to define specific segments (or shots) not only in a time structure but also in frames,<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> this converting step could have been skipped. Either way, the importance of ELAN and segmentation as basic step once more becomes obvious here.</p>
<p>Finally, for the analysis of structural patterns, the timeline representation and visualization in ELAN itself was essential as well. Above, I have already mentioned the visualization of film rhythm and editing in the horizontal timeline approach. Moreover, the timeline and annotation options in various tiers make it possible to see how different elements are linked to each other and to detect relations, recurring elements, and patterns. In addition, the tierfilmic techniquescontributed to the identification of structural patterns as it gave an overview of experimental techniques and shot changes per film.</p>
<p>In the end, all these analysis steps together, from ELAN via Excel to Cinemetrics and ImageJ, made it possible to compile a master list of shared structural patterns of <em>Berlin</em> , <em>Man with a Movie Camera</em> , <em>Rien que les Heures</em> , and <em>Manhatta</em> (see Figure 15). However, as it has become obvious from the various analysis steps, this list was created in a less straightforward way than the master list of visual motifs and required a higher degree of interpretation.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Excerpt of structures list
        </p>
    </figcaption>
</figure>
<h2 id="from-the-canon-to-the-broader-corpus-of-city-symphonies">From the Canon to the Broader Corpus of City Symphonies</h2>
<p>In a final analysis step, the two master lists of visual motifs and structural patterns were expanded to the broader corpus of city symphony films. Regarding this greater corpus, I used the overview of identified shared characteristics of <em>Berlin</em> , <em>Man with a Movie Camera</em> , <em>Rien que les Heures</em> , and <em>Manhatta</em> to check, based on viewings, if and to what extent they could be found in these titles, too. This means that I did not start from a detailed in-depth close reading of each film in ELAN, as I did with the canon films, but used the canon features as a check list to analyze to what extent these features are applicable to a bigger group of films and thereby can be defined as characteristics for the interwar city symphony phenomenon in general.<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup></p>
<h2 id="city-symphony-features-motifs-and-structures-results-1">City Symphony Features, Motifs, and Structures (Results 1)</h2>
<p>Through the methodology described above, I could indeed identify an extensive catalogue of shared visual motifs and structural patterns of interwar city symphonies and their presentation of the modern city.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> In fact, while, on the one hand, I could underpin certain aspects emphasized in scholarship and film historiography, on the other hand, I could also revise other elements and mark them as misreadings or (over‑)hasty conclusions. Moreover, I could also add new findings. The result is a much more nuanced, detailed and sophisticated picture of the phenomenon of city symphonies, of which this article includes just a small fraction.<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup></p>
<h2 id="supporting-lights-on-garbage-minding-crowds-and-rhythmic-montage">Supporting Lights on Garbage-Minding, Crowds, and Rhythmic Montage</h2>
<p>My analysis, for instance, confirmed the “garbage-minding” discussed by<a href="#kracauer1960">Kracauer (1960, p. 54)</a>in relation to <em>Berlin</em> and <em>Rien que les Heures</em> , and I could identify it as a general feature of city symphonies.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup> I could do so by detecting and analyzing the application of this motif in the canon films, which does not only concern the actual depiction of waste and dirt,<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> but also includes (and overlaps with) the elements of street cleaning and waste collection as city activities that are presented especially as morning routines (see Figure 16). Moreover, I could find similar shots and scenes in the bigger city symphony corpus. At least twenty other titles include a focus on waste.<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> The same is true for the depiction of street cleaning activities.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Waste collection in <em>Berlin</em> (top row) as well as street cleaning and “garbage-minding” in <em>Berlin</em> (left), <em>Man with a Movie Camera</em> (middle), and <em>Rien que les Heures</em> (right)
        </p>
    </figcaption>
</figure>
<p>A second feature often associated with city symphonies in the literature I could support and strengthen by my analysis is the films’ focus on crowds (see e.g.<a href="#barsom1973">Barsam, 1973</a>;<a href="#weiss1995">Weiss, 1995</a>;<a href="#weihsmann1997">Weihsmann, 1997</a>;<a href="#dahne2013">Dähne, 2013</a>). While the look at the greater city symphony corpus revealed that crowds play an important role in at least forty-four of the sixty-seven titles studied, the ELAN analysis of the canon films allowed to take a closer look at the construction of these crowds – thus how visual content and cinematic techniques create this motif together. In this regard, it is remarkable that there are not too manyrealcrowd shots with masses of people. Instead, we can often speak of an accumulation technique, by with the impression of crowds is created visually through editing. In the case of <em>Berlin</em> , seventy-two shots display more than fifty people, which is about 6.5% of the entire film. The crowd-effect, however, arises significantly from the sum of street shots with a few people as well as smaller groups (see Figure 17).<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> Edited together, they form the city crowds and huge movements within the cityscape. The same is true for <em>Man with a Movie Camera</em> , which contains fifty-sixrealcrowd shots (3.3% of the entire film), while presenting 705 shots with a single person (41.1% of the entire film). Put together by means of montage, these individuals merge into the urban crowd of the cinematically created new Soviet city, that combines the cityscapes of Moscow, Odessa, and Kiev.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Example of crowd construction by accumulation in <em>Berlin</em> (one frame per shot)
        </p>
    </figcaption>
</figure>
<p>In combination with the Cinemetrics approach and ImageJ, ELAN also allowed to underline the symphonic form and rhythmic montage of city symphonies, described, among others, by<a href="#grierson1933">Grierson (1933)</a>,<a href="#rotha1936">Rotha (1936)</a>,<a href="#kracauer1947">Kracauer (1947)</a>,<a href="#jacobs1949">Jacobs (1949)</a>,<a href="#barsam1973">Barsam (1973)</a>,<a href="#weihsmann1997">Weihsmann (1997)</a>, and<a href="#dahne2013">Dähne (2013)</a>. Indeed, the analysis of the canon films showed in detail how the well-calculated and -structured alternation of shot lengths and the varying duration of shots together with associative editing, analogous and contrasting montage, as well as cross-cutting strategies generate this rhythmic form (see Figures 5-6 and Figures 10-14). In addition, the visual elements of opening, closing, starting, stopping, arriving/entering, and leaving activities (motifs list) also greatly contribute to city symphonies’ rhythmic form and general pulse of the city. There are, for example, shots of opening doors, gates, blinds, and rolling shutters in <em>Rien que les Heures</em> , <em>Berlin</em> , <em>Manhatta</em> , and <em>Man with a Movie Camera</em> , particularly presented in the morning. Moreover, there are scenes of people arriving at work, entering buildings, cafés, shops, elevators, telephone boxes, cars, busses, taxis, and various types of trains. The opposite activities of leaving and de-boarding are depicted in combination with the same elements and situations.</p>
<h2 id="the-myths-of-the-nature-free-industrial-city-without-landmarks">The Myths of the Nature-Free Industrial City without Landmarks</h2>
<p>I could also rectify certain aspects that had been introduced in the literature. For instance, intertitles and hired actors (or better: staged scenes) are not as unusual as often claimed (see e.g.<a href="#jacobs1949">Jacobs, 1949</a>;<a href="#uricchio1982">Uricchio, 1982</a>;<a href="#urvey2011">Turvey, 2011</a>).<sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> Though, while these points could be supported especially through the look at the greater city symphony corpus, the aspect of natural elements in the city as a focus in city symphonies could be identified and revised particularly through the act of <em>doing</em> the ELAN analysis and studying the compiled (and exported) data with regard to <em>Berlin</em> , <em>Man with a Movie Camera</em> , <em>Rien que les Heures</em> , and <em>Manhatta</em> . More specifically, during the activity of marking shots and adding notes to the visual elements in these shots, I realized the recurrence of aspects such as clouds and sky, water and trees. A focus on these phenomena was further confirmed in the wordlists exported from ELAN and merged into the motifs master list. In addition, the step of checking the greater city symphony corpus also underlined the presence and focus on these natural elements in city symphonies. There are at least thirty-six titles depicting aspects such as clouds, water and trees in the city. Moreover, the detailed ELAN analysis of the canon films showed that these elements often function as atmospheric shots and images of transition or introduction. Clouds and water also work as indicators of the passing of time. While this might not be too surprising, the close reading of the films also stressed both the aspect ofurbanizednatural elements and the coexistence of natural and urban aspects in the city. Indeed, especially water appears in the city as civilized orurbanizedwater – in relation to street cleaning, wet streets, gutters and sewerage as well as in combination with water fountains and, in the case of <em>Man with a Movie Camera</em> , the waterfall of the Dneiper electricity power station (see Figure 18). Here, a natural source is transformed into a modern and industrialized energy force (see also<a href="#roberts2000">Roberts, 2000</a>). Moreover, natural elements exist <em>in</em> the city, such as trees that often appear in street scenes at the line between sidewalk and street, especially in Vertov and Ruttmann’s urban universes.<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup> In addition, natural elements exert an influence on urban structures and, in this way, make part of the urban environment, permeate urban structures, and become interwoven with the city. This is especially the case of wind, rain, and thunderstorm in <em>Berlin</em> , <em>Man with a Movie Camera</em> , and <em>Rien que les Heures</em> (see Figure 19). Natural elements and organic forces are thus introduced to the city in these films, which show that the modern and industrialized city is anything but nature-free. This stands in contrast to<a href="#horak1995">Horak (1995)</a>, who states that the role of nature in city symphonies is basically limited to its role in leisure-time activities, especially in the European films.<sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup> However, while natural elements, indeed, also appear in relation to sports and the recreation sector in many city symphonies, the ELAN analysis shows that they play a much more prominent and complex part – also (and especially) in the European films. They permeate the city just like the city permeates and <em>urbanizes</em> nature and coexist with urban structures.<sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup></p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>UrbanizedWater in <em>Rien que les Heures</em> , <em>Manhatta</em> , <em>Man with a Movie Camera</em> , and <em>Berlin</em>
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Wind in <em>Berlin</em> , <em>Man with a Movie Camera</em> , and <em>Rien que les Heures</em>
        </p>
    </figcaption>
</figure>
<p>Another shortcoming resulting from literature and film historiography my analysis could revise is the assumption that city symphonies exclude landmarks and monuments.<a href="#weihsmann1997">Weihsmann (1997)</a>, for example, claims regarding <em>Berlin</em> that the film makes no reference to actual places. Balázs also points into that direction as he describes <em>Berlin</em> as a non-touristic film “with little use as a guide to a stranger arriving in the city for the first time” and sees both Ruttmann and Cavalcanti’s films as “mental associations” that have nothing to do with presenting reality or specific places<a class="footnote-ref" href="#balazs2010"> [balazs2010] </a>. From discussions like these and the undeniable focus of city symphonies on everyday life (hence, they <em>are</em> non-touristic films),<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup> the general assumption emerged that these films do not present landmarks, specific buildings, and monuments in favor of an abstract presentation of a generic cityscape.<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup> Nevertheless, while city symphonies also present numerous rather unspecific street scenes and city views, recognizable landmarks and monuments <em>are</em> included in quite a number of these films (at least in twenty-four titles). I could specifically mark and analyze these landmarks in ELAN regarding <em>Berlin</em> , <em>Man with a Movie Camera</em> , <em>Rien que les Heures</em> , and <em>Manhatta</em> . In this context, it is remarkable that all four canon films do not only present recognizable constructions like the Woolworth Building, Brooklyn Bridge, or Trinity Church ( <em>Manhatta</em> ), the Place de la Concorde with the Luxor Obelisk and the contours of the Eiffel Tower in the background ( <em>Rien que les Heures</em> ), the Berliner Dom, the Berliner Funkturm, or the Rotes Rathaus ( <em>Berlin</em> ), or the Bolshoi Theatre in Moscow ( <em>Man with a Movie Camera</em> ),<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup> but they also do so in the very first minutes. This can also be seen in the light of introducing the cityscape. As a sort ofestablishing shots, these images function as structuring devices of introducing and establishing space. They anchor the generic and often anonymous streets and squares that follow in a concrete and identifiable place.<sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup></p>
<h2 id="horizontal-and-vertical-city-explorations-and-temporal-phasing">Horizontal and Vertical City Explorations and Temporal Phasing</h2>
<p>Closely linked to the identification and revision of certain aspects as shortcomings or myths, I could finally also find aspects that were not greatly paid attention to so far or even completely overlooked. For instance, by the close analysis of the canon films in ELAN in combination with the examination of the greater city symphony corpus, I could discover the prominence of harbors (and harbor cities)<sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup> and the extensive depiction of swimming as the most popular sports and leisure activity. Moreover, once again by the act of <em>doing</em> the analysis in ELAN as well as the resulting data and motifs list, I could identify an attention given to the depiction of wet streets (with their reflecting surfaces). I observed this first in <em>Berlin</em> (especially at night and in combination with electric lighting, neon signs, and vehicles’ headlights), but could also detect wet street scenes in the other canon films and the extended city symphony corpus.<sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup> Similarly, the focus on stairs came above water as well as their function to underline the verticality of the city – its above and below, including subways, streets, bridges, viaducts, and tall buildings.</p>
<p>Some of the most interesting findings also resulted from the in-depth exploration of the structuring patterns. Indeed, while generally the city in city symphonies is perceived as chaotic and overwhelming, there is a highly organized structure to create and emphasize this effect, among others through cross-sectional and rhythmic editing.<sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup> However, to keep a balance with the turbulent and fragmented city impressions, city symphonies also apply a number of ordering strategies to structure the city experiences and keep things from becoming overly abstract. Literature has frequently (and often exclusively) referred to the day structure or dawn-to-dusk form (see e.g.<a href="#grierson1933">Grierson, 1933</a>;<a href="#rotha1936">Rotha, 1936</a>;<a href="#noguez1985">Noguez, 1985</a>;<a href="#weihsmann1997">Weihsmann, 1997</a>;<a href="#macdonald2001">MacDonald, 2001</a>;<a href="#vogt2001">Vogt, 2001</a>;<a href="#dahne2013">Dähne, 2013</a>), but, as my analysis demonstrates, the ordering strategies are much more substantial and include both temporal and spatial structures.</p>
<p>Regarding spatial structuring patterns, I want to focus here on the horizontal and vertical establishment of space and city explorations identified and analyzed in ELAN in all four canon films.<sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup> The arrival-into-the-city subject is part of the horizontal explorations.<sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup> This is also true for rides through the city, that give the viewer an idea about the spatial dimensions of the city that unfolds in front of her eyes.<sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup> Moreover, <em>Berlin</em> , <em>Manhatta</em> , <em>Rien que les Heures</em> , and <em>Man with a Movie Camera</em> also establish the city in a vertical perspective. Above, I have already mentioned the visual motif of stairs that underlines verticality. Moreover, in a sort of <em>zoom-in</em> or <em>cut-down</em> effect by means of montage, <em>Berlin</em> presents high angle panorama shots of the area around the Berliner Dom after the initial arrival into the city – with each shot presenting the city from a slightly closer and more tilted perspective. Subsequently, Ruttmann shows shots of lower angles looking up at the clock tower of the Rotes Rathaus, followed by ground level shots of deserted streets. These images provide a certain overview of the cityscape and add to a sense of orientation.<sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup> Strand and Sheeler, too, present high-angle perspectives and panorama shots from a greater distance before they get closer to street level in shots of the Staten Island Ferry and crowds walking in the streets of lower Manhattan. The same is true for Cavalcanti, who first introduces the city by a high (and abstracted) perspective of maps before switching to the urban space of Paris and, subsequently, the borrow of Montmartre on ground level (see Figure 20). Vertov, in contrast, does not really make use of such acut-downeffect, but, nevertheless, visually hints at verticality throughout his film – from a coal mine underground to a bridge and factory chimneys reaching high in the air. Moreover, he exemplarily explores urban space vertically and horizontally in a sequence in reel three, in which he presents images of a wildly titling and panning camera showing streets, junctions, and squares intercut with images of a looking and blinking eye (see Figure 21). While this sequence reflects on human vision, it also demonstrates both the vertical and horizontal filmic depiction of the city. Moreover, Vertov elaborately makes use of extremely high and low camera angles as well as tilted shots, that further emphasize verticality. The ELAN analysis of shot distances, camera angles, perspectives, and montage techniques demonstrates that these cinematic devices are also part of the other canon films and their investigation and presentation of urban space.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Vertical city introductions in <em>Rien que les Heures</em> (top), <em>Berlin</em> (middle), and <em>Manhatta</em> (bottom)
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Eye-and-urban-panning-and-tilting sequence in <em>Man with a Movie Camera</em> , excerpt with all frames of the shots
        </p>
    </figcaption>
</figure>
<p>Concerning temporal structuring patterns going beyond the well-known chronological day-structure,<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup> the ELAN analysis particularly showed the aspect of the linear organization of events and activities into phases of before, during, and after (see Figure 22). To be clear, this is not the overall rule, but it is applied deliberately in a selective way and in combination with the chaotic and dizzying city impressions.<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup> More precisely, there are two forms of this structuring technique. The first one refers to linear development (orphasing) within a single (continuing) scene, sequence, or section – thus by means of linear editing that ELAN accentuates in its timeline visualization. An example is the murder scene in <em>Rien que les Heures</em> or the sports-races-and-matches episode in <em>Berlin</em> , which Ruttmann explicitly structures into shots presenting starting moments, followed by shots presenting the middle part of competitions, followed by shots presenting the final moment of a marathon with the winner crossing the finish line. In <em>Man with a Movie Camera</em> the ambulance-and-fire-brigade-operations episode is presented with an introductory, operational and anextroductoryphase in one continuing sequence. The second form is the organization of events and activities into different phases stretched out over greater parts of the film. This is especiall used by Ruttmann and Vertov. For instance, they both present the beginning, during and end of work spread out over their films, combined with the activity cluster of machines at rest, starting to move, moving, stopping to move and at rest again.<sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup> Moreover, Ruttmann displays the before, during and after of a thunderstorm, interrupted by (and joined with) both a suicide and a fire-brigade-operation sequence. Vertov, too, presents the operations of the cameraman often in a preparatory, an executing and a concluding phase, as he shows him, intercut with other scenes, riding to the location of the film shoot, the actual act of filming and the departure from the location. These elements that are paused and picked up later – not seldomly to underline simultaneity – could be examined in detail especially through the non-linear analysis of keywords and individual component parts of the films that ELAN facilitates to disassemble and reassemble in a highly structured way.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>TemporalPhasingin <em>Berlin</em> (top), <em>Man with a Movie Camera</em> (middle), and <em>Rien que les Heures</em> (bottom)
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Cross-sectional editing and thematic clustering in <em>Berlin</em> (cleaning activities)
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Cross-sectional and associative editing in <em>Rien que les Heures</em> (men-sleeping-in-the-streets sequence, one frame per shot)
        </p>
    </figcaption>
</figure>
<h2 id="database-and-narrative">Database and Narrative</h2>
<p>The temporal structures – both the linear organization of activities and events into phases and the chronological day structure – introduce, to a certain degree, narrative aspects to city symphonies. More precisely, coming back to Manovich’s logic of the database versus the logic of the narrative, we can conclude from the analysis that city symphonies, in fact, relate to <em>both</em> of these logics, combining, merging, and interweaving a catalogue of (unordered) equal items with elements of linearity and a certain cause-and-effect trajectory. Indeed, in their wide, extensive, and diverse visual material and the accumulation of numerous urban impressions and phenomena organized in cross-sections, city symphonies anticipate the logic of the database. They collect and present an enormous catalogue of urban subjects and cross-sections of the modern city and modern urban life, which I have analyzed (and put into a database myself) in the motif analysis. Cross-sectional editing strategies and thematic clustering, which evoke simultaneity across space, make part of this database logic or aesthetic, too<sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup> – hence the coming together of visual content and filmic techniques and structing patterns (see Figure 23 and Figure 24). City symphonies present the modern city as an inventory. However, this is only one side since, as elaborated above, there is also the structuring of urban events and activities into phases, which introduces linearity and a certain chain of cause and effect, of before, during, and after. Moreover, the day structure also causes a chronological/linear development.<sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup> Therefore, in their highly complex structuring and in their extensive urban material, city symphonies anticipate and reflect on the issue of database and narrative and play on tensions between a catalogue of motifs versus a structured history based on chronology and linearity. We can consider these films as both databases <em>and</em> narratives.<sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup> The ELAN analysis supports a study of both logics in the combination of its linear/chronological timeline approach and its data production, listing and cataloguing options. In this regard, the digital analysis tool itself also relates to both logics of the database and the narrative.</p>
<h2 id="reflections-on-digital-tools-research-transparency-and-manual-digital-analysis-results-2">Reflections on Digital Tools, Research Transparency, and Manual Digital Analysis (Results 2)</h2>
<p>I would like to conclude this research report with a couple of reflecting remarks that exceed the city symphony focus and underline some benefits of digital tools like ELAN and Cinemetrics, that might have a relevance for the entire field of film and media studies.</p>
<p>The first one concerns budget and research frameworks. My project did not provide specific funding for the use of digital tools or a close collaboration with software developers or IT engineers, who might have come up with a different solution for my research endeavor. In fact, the use of digital tools was not part of the initial research plan of the umbrella project “City Symphonies: Urban Modernity, Film, and Avant Garde (1920-1940)” , funded by the Special Research Funds of Ghent University, but came later by my own initiative.<sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup> Therefore, the application of ELAN and the Cinemetrics approach in combination with excel sheets and ImageJ can be considered as <em>a</em> best practice for getting my analysis done within the available recourses and timeframe.<sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup> As I only used free and open-source software (compatible with most computer operating systems) as well as programs that were provided as part of the work package for researchers at Ghent University,<sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup> this approach should be widely accessible and might be interesting also for other scholars with little funding. Moreover, with their variable, flexible, and open form, the tools I used are applicable and customizable for a great variety of research questions.</p>
<p>The second remark is about research transparency and visual argumentation. ELAN allows for highly structured annotations, segmentations and systematic annotation protocols, which can be considered as externalizations of the observations that normally take place inside the scholar’s mind during close analysis<a class="footnote-ref" href="#melgar2017"> [melgar2017] </a>. Moreover, they can easily be shared with other researchers, who load them, together with the corresponding video files, in their own ELAN version on their computer. In this way, the analysis process and research, including various steps, collected data, findings, and conclusions, become more transparent, retraceable, and shareable. Moreover, the ELAN software and interface as well as the Cinemetrics concept provide visualization methods that support statements, which, with traditional film analysis methods, are harder to underpin, generally only by written explanations. In fact, these data visualizations become visual arguments themselves. This is also true for the image montages made with ImageJ. The film or media scholar receives new powerful tools to illustrate, underline, and fortify findings and observations in a direct visual way.</p>
<p>The final comment concerns a significant benefit of using a tool such as ELAN in a manual way, which might also make us rethink the notion of digital analysis. From the methodology described in this article, the impression might arise that I have mainly reproduced manual film analysis practices in a digital environment: I noted shot changes and added descriptions about visual and filmic aspects to this shot-based protocol. While one could indeed question the advantage of ELAN applied this way, there is the very activity of <em>doing</em> ELAN – the very experience of segmenting and annotating – that leads to an in-depth knowledge of the film and a level ofhands-onresearch and learning that neither a traditional film analysis nor a digital analysis with automatic shot detection alone can provide.<sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup> This is probably most obvious for editing techniques and montage patterns, as theELAN experiencecan, to a certain degree, be considered as a recreation or reconstruction of the film editing process, starting in reverse from the end product of the final film. In fact, in its design, timeline approach, segmentation, and annotation possibilities, ELAN resembles digital film and video editing platforms, such as Final Cut Pro or Avid Media Composer.<sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup> In this regard, manually segmenting and annotating in ELAN on the level of shots imitates or retraces the editing process (in digital form) and, in so doing, provides an empirical way of analyzing a film in its structures and motifs. We can speak of a reverse-engineering scholarly experience. More precisely, it is an experience that – as ahands-onactivity – includes both eyes and hands (or better: fingers), which results in a more intimate interaction with the material instead of <em>just</em> watching the film. Simply speaking, by using your eyes and fingers in tandem, you get to see things and observe connections and interrelations between various elements you would not be able to see otherwise – or might easily miss. In this article, I have discussed a couple of findings regarding city symphonies that surfaced this way, such as the construction of crowds out of individuals and small groups, the prominence of wet streets and stairs, the interweaving of natural elements with urban structures or the adroit horizontal and vertical city explorations. Moreover, to be clear, the fingers aspect does not only concern the reverse editing activity as detecting shot boundaries, but also the descriptive part of adding keywords and describing shots that contributes to the increased examination of the material and in-depth knowledge of the films. This hands-on angle of using digital tools is an underestimated aspect in digital humanities as <em>digital</em> is increasingly understood as <em>automatic</em> as opposed to <em>manual</em> . Large bodies of automatically acquired data became available and, as a result, the trend is distancing scholars from their material. However, as I have shown, especially the manual hands-on use of digital tools such as ELAN or Cinemetrics can be extremely beneficial in giving film and media scholars (and students!) an invaluable experience of more intimately interacting with their material. This might also lead to a rethinking of the idea what digital analysis is or can be. In the end, the manual fingers-eyes use of ELAN can be considered digital in two respects and, if you will so, in its purest way: It is digital because it produces numbers; it is also digital, etymologically, because you do it <em>with your fingers</em> .<sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup></p>
<h2 id="appendix">Appendix</h2>
<h1 id="links-to-tools">Links to Tools:</h1>
<p>Advene<a href="https://www.advene.org/">https://www.advene.org/</a>[last consulted on November 29th 2018].Anvil<a href="http://www.anvil-software.org/">http://www.anvil-software.org/</a>[last consulted on November 29th 2018].Cinemetrics<a href="http://www.cinemetrics.lv/index.php">http://www.cinemetrics.lv/index.php</a>[last consulted on February 6th 2017].ELAN<a href="https://tla.mpi.nl/tools/tla-tools/elan/">https://tla.mpi.nl/tools/tla-tools/elan/</a>[last consulted on November 29th 2018].ImageJ and ImageMontage<a href="http://lab.softwarestudies.com/2014/03/how-to-visualize-4512-instagram-selfies.html">http://lab.softwarestudies.com/2014/03/how-to-visualize-4512-instagram-selfies.html</a>[last consulted on July 20th 2018].Lignes de temps<a href="https://www.iri.centrepompidou.fr/outils/lignes-de-temps/">https://www.iri.centrepompidou.fr/outils/lignes-de-temps/</a>[last consulted on November 29th 2018].</p>
<ul>
<li id="altman1984">Altman, R. “A Semantic/Syntactic Approach to Film Genre” , _Cinema Journal_ 23, 3 (1984): 6-18.
</li>
<li id="auge1995">Augé, M. _Non-places: Introduction to an Anthropology of Supermodernity_ . Verso, London (1995).
</li>
<li id="balazs2010">Balázs, B. “The Spirit of Film” . In E. Carter (ed), _Béla Balázs: Early Film Theory. Visible Man and The Spirit of Film _ , Berghahn Books, New York, Oxford (2010), pp. 91-230.
</li>
<li id="barsam1973">Barsam, R. _Nonfiction Film. A critical History_ . E.P. Dutton, New York (1973).
</li>
<li id="benjamin1999">Benjamin, W. _The Arcades Project_ . Harvard University Press, Cambridge (1999).
</li>
<li id="bollerey2014">Bollerey, F. and A. Föhl (eds). _City Symphonies. Film Manifestos of Urban Experiences. Eselsohren_ . Journal of History of Art, Architecture and Urbanism, 1+2 (2014).
</li>
<li id="bordwell2019">Bordwell, D. and K. Thompson. _Film History. An Introduction_ . Fourth Edition. McGraw-Hill, New York (2019).
</li>
<li id="cowan2014">Cowan, M. _Walter Ruttmann and the Cinema of Multiplicity. Avant-Garde, Advertising, Modernity_ . Amsterdam University Press, Amsterdam (2014).
</li>
<li id="dahne2013">Dähne, C. _Die Stadtsinfonien der 1920er Jahre. Architektur zwischen Film, Fotografie und Literatur_ . Transcript, Bielefeld (2013).
</li>
<li id="grierson1933">Grierson, J. “Documentary (2): Symphonics” , _Cinema Quarterly_ 1, 3 (1933): 135-139.
</li>
<li id="heftberger2016">Heftberger, A. _Kollision der Kader. Dziga Vertovs Filme, die Visualisierung ihrer Strukturen und die Digital Humanities_ . Edition Text + Kritik, Munich (2016).
</li>
<li id="hielscher2018">Hielscher, E. _Rewinding the City Symphony: Historiography, Visual Motifs and Structural Patterns of Interwar City Symphony Films_ . Ph.D. thesis, Ghent University (2018).
</li>
<li id="horak1995">Horak, J. “The First American Film Avant-Garde, 1919-1945” . In J. Horak (ed), _Lovers of Cinema: The First American Film Avant-Garde, 1919-1945_ , University of Wisconsin Press, Madison (1995), pp. 14-66.
</li>
<li id="jacobs1949">Jacobs, L. “Avant-Garde Production in America” . In R. Manvell (ed), _Experiment in the Film_ , Grey Walls Press, London (1949), pp. 113-152.
</li>
<li id="jacobs2016">Jacobs, L. and K. Fyfe. “Digital Tools for Film Analysis: Small Data” . In C. Acland and E. Hoyt (eds), _The Arclight Guidebook to Media History and the Digital Humanities_ , REFRAME Books, Falmer (2016), pp. 250-251.
</li>
<li id="jacobs2018">Jacobs, S., A. Kinik, and E. Hielscher (eds). _The City Symphony Phenomenon. Cinema, Art, and Urban Modernity between the Wars_ . Routledge, New York (2018).
</li>
<li id="kinik2008">Kinik, A. _Dynamic of the Metropolis: The City Film and the Spaces of Modernity_ . Ph.D. thesis, McGill University (2008).
</li>
<li id="koeck2010">Koeck, R. and L. Roberts (eds). _The City and the Moving Image. Urban Projections_ . Palgrave MacMillan, Basingstoke, New York (2010).
</li>
<li id="kolaja1965">Kolaja, J. and A. Foster. “ Berlin, the Symphony of a City as a Theme of Visual Rhythm” , _The Journal of Aesthetics and Art Criticism_ 23, 3 (1965): 353-358.
</li>
<li id="kracauer1947">Kracauer, S. _From Caligari to Hitler. A Psychological History of the German Film_ . Princeton University Press, Princeton (1947).
</li>
<li id="kracauer1960">Kracauer, S. _Theory of Film. The Redemption of Physical Reality_ . Oxford University Press, New York (1960).
</li>
<li id="macdonald2001">MacDonald, S. _The Garden in the Machine. A Field Guide to Independent Films about Place_ . University of California Press, Berkeley, Los Angeles, London (2001).
</li>
<li id="manovich2001">Manovich, L. _The Language of New Media_ . MIT press, Cambridge (2001).
</li>
<li id="manovich2013">Manovich, L. “Visualizing Vertov” . Manovich.net (2013). Available at:<a href="http://manovich.net/content/04-projects/078-visualizing-vertov/74_article_2013_sm.pdf">http://manovich.net/content/04-projects/078-visualizing-vertov/74_article_2013_sm.pdf</a>[last consulted June 5, 2018].
</li>
<li id="mazierska2003">Mazierska, E. and L. Rascaroli. _From Moscow to Madrid. Postmodern Cities, European Cinema_ . Tauris, London, New York (2003).
</li>
<li id="melgar2017">Melgar, L., E. Hielscher, M. Koolen, C. Olesen, J. Noordegraaf, and J. Blom. “Film Analysis as Annotation: Exploring current Tools and their Affordances” , _The Moving Image_ , Special Issue: Digital Humanities and/in Film Archives, 2 (2017): 40-70.
</li>
<li id="noguez1985">Noguez, D. “Paris – Moscou – Paris. Paris et les symphonies de ville” . In P. Hillairet, C. Lebrat and P. Rollet (eds), _Paris vu par le cinéma d’avant-garde 1923-1983_ , Paris Expermental, Paris (1985), pp. 31-37.
</li>
<li id="nowell-smith1997">Nowell-Smith, G. (ed). _The Oxford History of World Cinema_ . Oxford University Press, London (1997).
</li>
<li id="olesen2017">Olesen, C. _Film History in the Making. Film Historiography, Digitised Archives and Digital Research Dispositifs_ . Ph.D. thesis, University of Amsterdam (2017).
</li>
<li id="roberts2000">Roberts, G. _The Man with the Movie Camera_ . Tauris, London, New York (2000).
</li>
<li id="rotha1936">Rotha, P. _Documentary Film_ . Faber and Faber, London (1936).
</li>
<li id="simmel1997">Simmel, G. “The Metropolis and Mental Life [1903]” . In D. Frisby and M. Featherstone (eds), _Simmel on Culture. Selected Writings_ , Thousand Oaks, London (1997), pp. 174-185.
</li>
<li id="tsivian2004">Tsivian, Y. “Dziga Vertov and His Time” . In Y. Tsivian (ed), _Lines of Resistance: Dziga Vertov and the Twenties, Le Giornate del cinema muto_ , Gemona, Udine (2004), pp. 1-28.
</li>
<li id="turvey2011">Turvey, M. “City Symphony and Man with a Movie Camera” . In M. Turvey, _The Filming of Modern Life. European Avant-Garde Film of the 1920s_ , MIT Press, Cambridge/Massachusetts (2011), pp. 135-162.
</li>
<li id="uricchio1982">Uricchio, W. _Ruttmann's Berlin and the City Film to 1930_ . PhD dissertation. New York University, New York (1982).
</li>
<li id="vertov1984">Vertov, D. “From Kino-Eye to Radio-Eye” . In A. Michelson (ed), _Kino-Eye: The Writings of Dziga Vertov_ , University of California Press, Berkeley (1984), pp. 85-92.
</li>
<li id="vogt2001">Vogt, G. _Die Stadt im Film. Deutsche Spielfilme 1900-2000_ . Schüren, Marburg (2001).
</li>
<li id="weihsmann1997">Weihsmann, H. “The City in Twilight. Charting the Genre of the City Film 1900-1930” . In F. Penz and M. Thomas (eds), _Cinema and Architecture. Méliès, Mallet-Stevens, Multimedia_ , BFI, London (1997), pp. 8-27.
</li>
<li id="weiss1995">Weiss, P. _Avantgarde Film_ . Suhrkamp, Frankfurt (1995).
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>For a comprehensive survey of interwar city symphony films, see<a href="#jacobs2018">Jacobs, Kinik and Hielscher (2018)</a>. In fact, apart from<a href="#dahne2013">Dähne (2013)</a>, this edited volume can be considered as the first book-length publication and overview on the topic.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>This conclusion, though, should not deny the importance of key texts such as<a href="#dahne2013">Dähne (2013)</a>and<a href="#weihsmann1997">Weihsmann (1997)</a>, who made a start in changing this situation. This is also true for<a href="#bollerey2014">Bollerey and Föhl (2014)</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>They create these impressions by cinematic means.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="#manovich2013">Manovich (2013)</a>also did pioneering work in visualizing Vertov’s films by digital means, as did<a href="#heftberger2016">Heftberger (2016)</a>and the project “Digital Formalism” . In fact, my methodology builds on both Manovich and Heftberger’s research. Another relevant study, to which I will return later, is<a href="#olesen2017">Olesen (2017)</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>This happens, among others, through cross-sectional editing and thematic clustering. I will come back to this.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>I made use of ELAN 4.9.4. for Mac OS X. For the software and additional information see<a href="https://tla.mpi.nl/tools/tla-tools/elan/">https://tla.mpi.nl/tools/tla-tools/elan/</a>(last consulted on November 29th 2018).&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>In addition, it is possible to mark and define hierarchical relationships and dependencies between tiers and annotations, a feature I have not made use of in my study. In fact, this article discusses the way I used ELAN for my research endeavor, whereas there are more functionalities, including also the possibility to generate different queries or retrieve more complex annotation statistics. For a more general discussion of ELAN, see<a href="#melgar2017">Melgar et al. (2017)</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>For the individual tools, see<a href="http://www.anvil-software.org/">http://www.anvil-software.org/</a>,<a href="https://www.advene.org/">https://www.advene.org/</a>, and<a href="https://www.iri.centrepompidou.fr/outils/lignes-de-temps/">https://www.iri.centrepompidou.fr/outils/lignes-de-temps/</a>(last consulted on November 29th 2018). For a further elaboration of ELAN and other digital video annotation tools for film analysis, see<a href="#melgar2017">Melgar et al. (2017)</a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>This depends on the zoom factor of the timeline viewer. When the zoom factor is at its maximum (1000), the control buttons, which enable to go to the next or the previous pixel, will make the video jump ahead or back one millisecond. Of course, jumping from frame to frame would be more accurate, which corresponds to jumping ahead or back 41.67 milliseconds (in case of a framerate of 24 frames per second).&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>This is also an advantage of ELAN’s computer-based analysis in contrast to an analogue film analysis. While an analysis of extremely fast editing is not impossible in an analogue way when working with the film material itself on a montage bench, or by using a VCR or DVD player (see<a href="#kolaja1965">Kolaja and Foster, 1965</a>), ELAN facilitates such an analysis in a feasible and time-saving way. This, of course, could be made even more time-efficient when shot changes would be detected automatically. In fact, some of the tools, including Linges de temps, provide such an automatic or semi-automatic segmentation. However, according to my knowledge, there is no satisfactory tool including a reliable and error-free automatic shot boundary detection at this moment. Lignes de temps, for example, fails when it comes to extremely short segments, as is often the case in experimental films. Moreover, there is the general issue of fades, since the software cannot detect these soft changes. In addition, there is a crucial benefit of manually segmenting, to which I will come later in more detail.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>I used the option of predefined vocabularies especially for filmic techniques and shot distances.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>I also looked into camera angles, shot distances, camera and object movements. However, this was rather done in a selective way.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Shotis understood here as the basic unit of the film, being characterized by a unity of time and space, a continuously exposed and uncut piece of film – a series of film frames without cuts.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Shot changes included hard cuts, dissolves, fade-ins and fade-outs.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>The digital video files used for the analysis (mpeg-4-films, codecs H.264, AAC, and QuickTime Text) had their origins in the following DVDs: <em>Berlin</em> , <em>die Sinfonie der Großstadt</em> and <em>Melodie der Welt</em> , Walther Ruttmann, 1927, 1929 (Edition Filmmuseum 39, 2008), <em>Man with a Movie Camera</em> , Dziga Vertov, 1929 (Image Entertainment, 1998), <em>Masterworks of American Avant-Garde Experimental film</em> (1920-1970), including 2K restoration of <em>Manhatta</em> , Paul Strand and Charles Sheeler, 1921 (Flicker Alley, 2015), and <em>Avant-Garde 3: Experimental Cinema 1922-1954</em> , including <em>Rien que les Heures</em> from the collection of the George Eastman House, Alberto Cavalcanti, 1926 (Kino International, 2009). Unfortunately, the Masters of Cinema/Eureka Blu-ray of <em>Man with a Movie Camera</em> (2016) had not yet been released when I started my analysis, which presents the new Lobster Film/EYE Filmmuseum restoration from 2014, the uncut, most complete, and full-frame version of Vertov’s film. It needs to be said that the digital video files as well as their source DVDs differ from the original 35mm film material in terms of absolute frame accuracy. As silent films were shown at rates between 16 and 24 frames per second, these original rates have to betransformedto the DVD standard of 25 frames per second (European PAL format) respectively 30 frames per second (American NTSC format), otherwise the films look speeded up. This film-to-video transfer happens either by interpolating frames, selectively and consistently repeating frames to convert to the video frame rate, or (in the case of a DVD based on a progressive frame by frame digital scan) by flags in the DVD instructing the player to generate extra frames during playback. I won’t go into more detail here but underline that I am aware of the issue of frame (in‑)accuracy with regard to digital video files and that ideally, one would aim to use frame-accurate digital versions of the films. However, for the purpose of my analysis of city symphonies’ features, an absolute frame accuracy was not necessary. Therefore, I went with the “unclean” digital video files without aiming to eliminate the interpolated or doubled frames first – simply for pragmatic reasons. For a frame accurate process, see<a href="#jacobs2016">Jacobs and Fyfe (2016)</a>.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>This double focus was also related to a further research sub-question: if the city symphony can be considered as a film genre or a film cycle. I approached this issue by using Altman’s semantic/syntactic approach to film genre (1984) as a heuristic tool for the analysis, which resulted in a split of the analysis and city symphony features into visual motifs (the city symphony semantics) and structural patterns (the city symphony syntax).&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>In the analysis scheme, this is represented by the orange double arrows (see Figure 3).&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>In fact, the more detailed the level of annotating, the more difficult it becomes to identify greater motifs. In this regard, elements such as cars, trams, taxis and trains can be combined under the common denominator of modern means of transportation.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Moreover, the combination of the tierimagery/visual shot elementswith other tiers, especially the row on shot distances, gives indications about the role of visual elements in the picture. Further aspects include shot length, position in the entire film, within a specific sequence etc.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>More precisely, thistab-delimited textexport option allows to select specific tiers and present them in the resulting text file in separate columns per tier, including (if selected) columns for start time, end time and duration of segments or shots. The data and columns can easily be transferred into Excel spreadsheets by copying and pasting.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>See<a href="http://www.cinemetrics.lv/index.php">http://www.cinemetrics.lv/index.php</a>(last consulted on February 6th 2017). On the Cinemetrics tool and method, see also<a href="#heftberger2016">Heftberger (2016)</a>and<a href="#olesen2017">Olesen (2017)</a>.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Apart from the analysis tool, the Cinemetrics website actually also provides a growing database of films measured and analyzed with the Cinemetrics software by scholars all over the world. This database comprises shot length analyses of <em>Man with a Movie Camera</em> and <em>Berlin</em> . However, to guarantee comparability and accuracy, I used the data from all your films compiled in ELAN.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>At least, this is the case in version 4.9.4. for Mac OS X.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>He speaks about “the visual correlation of shots,”  “the visual interval ” and “movement between shots” that is montage. In fact, later he refers to the “montage battle.”&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Manovich developed the plug-in ImageMontage and the software extension ImagePlot for the open-source scientific visualization software ImageJ, which was originally introduced by the National Institute of Mental Health in the US. Following Olesen it “advanced the combination of modern computation techniques with microscopy and gained widespread success in a broad range of disciplines in the natural sciences” <a class="footnote-ref" href="#olesen2017"> [olesen2017] </a>. See also<a href="http://lab.softwarestudies.com/2014/03/how-to-visualize-4512-instagram-selfies.html">http://lab.softwarestudies.com/2014/03/how-to-visualize-4512-instagram-selfies.html</a>(last consulted on July 20th 2018).&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Normally the tenth frame was selected to avoid imprecisions in shot changes, fades etc. See also<a href="#heftberger2016">Heftberger (2016)</a>and<a href="#manovich2013">Manovich (2013)</a>and their earlier analyses and visualizations of Vertov’s films.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>With one second consisting of 24 frames or less (in the case of silent films).&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>The strong focus on the canon films as prototypical examples was particularly motivated within the greater objective of my dissertation: an examination and critical reflection of the city symphony historiography. Therefore, the analysis also takes historiography and the city symphony as the product it became throughout historiography as its center of focus: How can the city symphony be defined according to the construct it became in film historiography – and from there expanding to the greater corpus of these films, which have only marginally been mentioned in film history writings? Moreover, there was also a very pragmatic reason as the level of detail applied in the analysis of the canon films could not have been extended to a greater corpus of sixty to eighty-five titles.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Moreover, by arriving at a list of visual motifs and structural patterns – or semantic and syntactic features – shared by a great number of films, I could also fortify the idea of considering the city symphony as a full-fledged film genre rather than a limited cycle. Obviously, not every feature is present in every film, but this is precisely an observation that can be made for every film that is considered in the context of a broader genre.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>For a complete overview and extensive discussion of city symphony features, see<a href="#hielscher2018">Hielscher (2018)</a>. Since my analysis focused on <em>shared</em> features of the canon films and the broader corpus (thus the city symphony phenomenon as a whole), it excluded the comprehensive examination of individual films and the filmmaker’s individual projects. This means also that individual intellectual arguments remained in the background, even though they make part of these films.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>When discussing the revealing functions and capacity of the film medium to make things visible that are usually overseen, Kracauer refers to the “wealth of sewer grates, gutters, and streets littered with rubbish” in <em>Berlin</em> before turning to Cavalcanti, who “in his <em>Rien que les Heures</em> is hardly less garbage-minded” <a class="footnote-ref" href="#kracauer1960"> [kracauer1960] </a>.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p><em>Berlin</em> , <em>Man with a Movie Camera</em> and <em>Rien que les Heures</em> all depict waste objects – quite often as atmospheric images. While <em>Manhatta</em> forms rather an exception, Strand and Sheeler’s film also depicts smoke as waste product of heating and the maritime industry.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Georges Lacombe even uses waste, waste collection and recycling as main theme and structuring element in <em>La Zone</em> (1928).&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>I identified these groups in ELAN by ascribing each shot to one of the following categories: (1) a single person visible in the shot, (2) two people, (3) a small group of three to ten people, (4) a larger group of up to fifty people, (5) a crowd of more than fifty people.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>These texts particularly refer to <em>Berlin</em> and <em>Man with a Movie Camera</em> regarding the deliberate avoidance of intertitles. In terms of the refusal of staged scenes and hired actors, it is especially Vertov’s film that is highlighted, while Ruttmann’s film is often criticized exactly for the integration of staged scenes, most prominently by<a href="#kracauer1947">Kracauer (1947)</a>.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>This modern urban street construction aspect belongs to the modern metropolitan streetscape in general since Haussmann’s restructuring of Paris.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>More precisely, he opposes <em>Manhatta</em> and the American film avant-garde of the 1920s and 1930s with their longing for the city’s (re‑)unification with nature to the European city films of that time, which, according to Horak proudly celebrate urbanism and the machine age and praise the urban environment “for its excitement, speed, and modernity, with few references to nature, beyond its role in leisure-time activities for Sunday picknickers” <a class="footnote-ref" href="#horak1995"> [horak1995] </a>&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>This becomes even more obvious in city symphonies like <em>Regen</em> (Joris Ivens and Mannus Franken, 1929) and <em>Images d’Ostende</em> (Henri Storck, 1929).&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Interestingly enough, this does not mean that they do not take tourism as a theme. All four canon films (as well as a handful of other titles) present hotels, guests and travelers. Also the famous arrival in the city, depicted in at least twenty-three films, can be seen in light of a touristic aspect.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>The prologue of <em>Rien que les Heures</em> might have also contributed to this assumption, in which Cavalcanti states in intertitles that all cities are the same, once we ignore their monuments, and that his film does not claim to synthesize any city as it is only a sequence of impressions of the passing of time. Moreover, the notion of the generic and unspecific makes sense also in light of city symphonies’ focus on streets and various means of transportation – places that<a href="#auge1995">Augé (1995)</a>would later call non-places without identity in the postmodern city. City symphonies anticipate these later non-lieux of post-modernity. Nevertheless, it should be added that there are also some rare remarks on urban specificity and recognizable urban and architectural constructions (see e.g.<a href="#dahne2013">Dähne, 2013</a>and<a href="#macdonald2001">MacDonald, 2001</a>).&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>In <em>Berlin</em> buildings receive a definition and recognition as city markers also via written signs and boards on their façades, such as the Gloria Palast at Kurfürstendamm, the Hotel Excelsior, or the Pschorr-Haus at Potsdamer Platz. Vertov’s film also includes a couple of textual signifiers, by which buildings become identifiable, like the Lenin Club building and the Club Vladimir Ilyich Ulyanov (aka Lenin) at Odessa Station, the Kiev Proletarian Film Theatre the camera pans across, the All-Union newspaper building (the Izvestiya building), and the Bakhmetievsky district bus depot in Moscow. Going beyond buildings as specific markers in the city and taking a closer look at the street scenes in <em>Man with a Movie Camera</em> , it stands out that Vertov chose only five or six urban locations to which he returns repeatedly throughout his film – depicted in similar or (slightly) different camera positions. In this way, they become urban markers and specific locations too. One of these streets is Tverskaia Street in Moscow, the street with the Gorky banner spanning the street, which we see deserted in the morning and later with the traffic policeman doing his work. Nevertheless, the most recognizable location and landmark in <em>Man with a Movie Camera</em> remains the Bolshoi Theatre, which Vertov makes visually collapse by a split screen shot in the climax of the film, according to Tsivian a “symbolic destruction” <a class="footnote-ref" href="#tsivian2004"> [tsivian2004] </a>Though, he also presents it in the first minutes of his film as an urban signifier.&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Nevertheless, even though Ruttmann, Cavalcanti, Vertov, Stand and Sheeler do include city markers and specific buildings, it needs to be said that they all exclude the most famous sights of their respective city/-ies at the time, including the Brandenburger Tor, the Statue of Liberty, the Louvre or Notre Dame de Paris, and Red Square with Kremlin, St. Basil Cathedral, and the Lenin’s Mausoleum. Indeed, it is not the touristic city the films focus on, but certain landmarks and monuments appear as part of the cities’ everyday life.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Moreover, there is a great variation of cities thematized in city symphonies. While the literature generally speaks about metropolises such as New York, Paris, or Berlin, city symphonies of the extended corpus also focus on somewhat smaller, mid-sized cities, including Rotterdam, Porto, and Ostend. In addition, the greater city symphony corpus also demonstrates that Vertov’s concept to cinematically merge and spatially organize the visual material of several cities into a newly created filmic city, was not picked up. It was only once more realized in <em>Les Nuits Élecriques</em> (1929), in which Eugène Deslaw combines material of nocturnal Berlin and Paris.&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Of course, this feature was most elaborately deployed by Joris Ivens and Mannus Franken in <em>Regen</em> (1929) as the entire film is structured around the visual impacts a rain shower has on the city. Regarding the canon films, <em>Manhatta</em> is an exception as wet streets cannot be identified due to the film’s high camera angles, extreme long and panorama shots and great distance to the streets on ground level. Moreover, the depiction of wet (reflecting) streets is present in virtually all films of the genre that include street scenes at night.&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>Montage forms such as rhythmic, fast, associative, metaphorical and cross-sectional editing as well as experimental techniques like unusual camera angles, extremely short takes, kaleidoscopic images, split screens, multiple exposures and manipulations of speed increase and cinematographically (re‑)create the intoxicating and overwhelming impressions in the modern city. They underline particularly the frenetic pace, highly fragmented nature and the contrasting features of urban modernity and modern urban life. In so doing, city symphonies can be considered as visualizations of the theories of<a href="#benjamin1999">Benjamin (1999)</a>and<a href="#simmel1997">Simmel (1997)</a>and their ideas about the modern urban shock experiences and the overstimulation of the senses.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>We can find those vertical and horizontal city explorations and establishments of space also in at least twenty other titles of the extended city symphony corpus.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>The city is spatially introduced by an arrival into that urban space. <em>Berlin</em> and <em>Man with a Movie Camera</em> present arrivals into the city by train; <em>Manhatta</em> starts with an arrival by a local ferry boat. <em>Rien que les Heures</em> presents a rather conceptual and vertical arrival into the city as in the prologue Cavalcanti shows maps (and miniature monuments), from which he cuts to a shot of the Place de la Concorde on street level. Moreover, he switches from the idea of general city life in the prologue to the specific portrait of Montmartre in the main part. These arrivals into the city, which often stand at the beginning of the films, are also a pragmatic way of getting a film on a topic as huge as the metropolis started.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>There are rides through the city especially in <em>Berlin</em> and <em>Man with a Movie Camera</em> , such as in the horse-carriage-ride-through-the-city-and-filming sequence in Vertov’s film and nocturnal taxi rides in Ruttmann’s Berlin portrait.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>In this regard, they also go together the aforementioned recognizable landmarks and monuments, which, too, add to such a sense of spatial orientation.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p><em>Berlin</em> , <em>Man with a Movie Camera</em> , <em>Rien que les Heures</em> and <em>Manhatta</em> show this linear structuring element, even though not all parts of the day are presented and made equally explicit in all four films.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p><em>Manhatta</em> is an exception as it does not apply this temporal structuring element. Moreover, it needs to be said that <em>Rien que les Heures</em> includes a certain linear narrative development as it shows several urban types and their doings in the course of one day presented in episodes with beginnings and endings, that happen one after the other. Though, it is an experimental and fragmented narrative structure as the different narrative threads constantly interrupted each other and the characters (and their stories) remain underdeveloped.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Of course, this also emphasizes the chronological day structure and is also interwoven with the aforementioned numerous shots depicting acts of opening and closing, arriving and entering, leaving and de-boarding, and (re‑)starting and stopping.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Indeed, while film itself as a time-based medium presents pictures one after the other in chronological time, city symphonies employ strategies to evoke the idea of simultaneity resulting in cross-sections across space.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>In addition, there are also mini-narratives that further underline the logic of the narrative. In <em>Man with a Movie Camera</em> , for instance, there is the mini-thriller narrative of the cameraman getting stuck with his foot under the rails when the train is approaching or the story of the accident, the fire brigade and ambulance operations. An example from <em>Berlin</em> is the mini-narrative of the femaleflâneusesin the streets (there is a sequence of similarly looking women), which turns into the story of a woman (a cocotte) and a man coupling.&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>Manovich, in fact also points toward the interweaving of both logics as he describes <em>Man with a Movie Camera</em> not only as a film anticipating the database logic but also as a work merging “database and narrative into a new form” <a class="footnote-ref" href="#manovich2001"> [manovich2001] </a>. Besides the “catalog of subjects that one could expect to find in a city of the 1920s – running trams, city beach, movie theatres, factories &hellip;,” and “the most amazing catalog of film techniques,” there is also the narrative of modern urban life and the “gradual process of discovery,” which, according to Manovich, “is film’s main narrative, and it is told through a catalog of discoveries.” Similarly, other city symphonies also include a narrative – the story of the city and modern urban life in a day – while they also present a cross-sectional database of modern urban material of the era between the wars.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>The fortunate encounters with other scholars from the field of media studies and information science, particularly L. Melgar and A. Heftberger, introduced me to various digital tools and inspired me to investigate benefits and options of applying those tools for my own research purposes.&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>There are further interesting analysis methods and data evaluation/visualization types that could be very fruitful for a study of urban films. For example, in a cloud or network representation, relations between motifs could be highlighted or the manner specific features (re‑)appear in a number of films. Moreover, an online database project could be interesting, which would allow to provide access to findings and research results in an interactive and a rather non-linear way.&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>I refer here especially to the MS-Office package, including Word and Excel.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>No doubt, an automatic shot detection would be more time-efficient, but it would also eliminate this empirical aspect. As important part of the analysis, the experience of segmenting and annotating in ELAN and the pure viewing observations are indicated in the center of the analysis scheme, contributing to both sides of the study of motifs and structures (see Figure 3).&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Moreover, it also recalls the analogue film strip.&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>I am very grateful to [reviewer 1] for the description of the hands-on recreation of the editing process in ELAN as a reverse-engineering scholarly experience, the underrated aspect of manual digital analysis in digital humanities and for stressing and reminding me of the etymological relation of <em>with your fingers</em> and <em>digital</em> .## Bibliography&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The Stylometry of Film Dialogue: Pros and Pitfalls</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000498/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000498/</id><author><name>Agata Hołobut</name></author><author><name>Jan Rybicki</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="film-dialogue">Film dialogue</h2>
<p>Although dialogue has been integral to film structure since the introduction of sound in the 1920s and used in silent film intertitles at least since 1904<a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a><a class="footnote-ref" href="#pitera1979"> [pitera1979] </a>, it has garnered relatively little attention from film scholars. Stylistic immaturity and technical imperfections of the first talkies made early theorists, such as Rudolf Arnheim, Sergei Eisenstein or Siegfried Krakauer bemoan the loss of artistry inherent to silent films<a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a>and encouraged others to describe the compositional complexity of the new invention in contrast to its silent, though hardly wordless, predecessor<a class="footnote-ref" href="#hendrykowski1999"> [hendrykowski1999] </a>. Still, as Sarah Kozloff argues in her ground-breaking monograph <em>Overhearing Film Dialogue</em> (2000), Western film scholarship has long been marked byverbo-immunityor evenverbophobiain its approach to cinematic art, privileging the visual over the auditory and the non-verbal over the verbal:</p>
<blockquote>
<p>Although what the characters say, how they actually say it, and how the dialogue is integrated with the rest of the cinematic techniques are crucial to our experience and understanding of every film since the coming of sound, for the most part analysts incorporate the information provided by a film’s dialogue and overlook the dialogue as signifier. Canonical textbooks on film aesthetics devote pages and pages to editing and cinematography but rarely mention dialogue. Visual analysis requires mastery of a recondite vocabulary and trained attentiveness; dialogue has been perceived as too transparent, too simple to need study<br>
<a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a></p>
</blockquote>
<p>This apparent disregard may have stemmed from a number of reasons, one of them being a deeply-grounded belief in the autonomy of various art forms. Scholars intent on presenting film as primarily a visual medium deemed dialogue negligible, because they considered it too closely related to other forms of expression, such as stage drama or prose-writing and hence unspecific to cinema<a class="footnote-ref" href="#piazza2011"> [piazza2011] </a>. Film talk, however, differs considerably from verbal exchanges intended for the page or for the stage, as it is always affected by performers’ interpretive choices and the “simultaneous signification of camerawork/mise-en-scene/editing” <a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a>. It is an integral element of fiction film and, as Sarah Kozloff argues, it performs unique narrative functions: (1) it anchors the diegesis and the characters, (2) it explains causal links between events presented onscreen, (3) it enacts narrative events, such as professing feelings, setting up deadlines or passing sentences, (4) it reveals the characters’ personalities, (5) it controls the viewers’ emotional and axiological reactions and (6) it helps create the impression of realism. It also plays an important aesthetic role, exploiting the artistic potential of language, conveying ideological messages and giving stars an opportunity to show off their skills<a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a>. Since the publication of Kozloff’s book a number of film scholars have pursued her line of study, tracing the evolution of screenwriting styles in America, emphasizing the requirements of particular genres (e.g. screwball comedy, science fiction, gangster film, western), investigating the idiom of selected auteurs (Cassavetes, Hawks, Welles, Sturges) and typical verbal representations of different social groups. The most important contribution to the field has been arguably the collected volume <em>Film Dialogue</em> edited by Jeff Jaeckle (2013).</p>
<p>Telecinematic dialogue has also received in-depth attention from linguists working within the fields of stylistics, pragmatics, sociolinguistics and discourse analysis (e.g.<a href="#bobrowski2015">Bobrowski 2015</a>;<a href="#piazza2011">Piazza 2011</a>;<a href="#piazza2011a">Piazza 2011a</a>;<a href="#richardson2010">Richardson 2010</a>), as well as audiovisual translation experts interested in different techniques, strategies and modes of language transfer. Most research has been driven by qualitative approaches, yet quantitative measures have also been adopted by scholars using monolingual, as well as multilingual and multimedia corpora to investigate the relationship of scripted speech to real-life conversation, to examine the stylistics of television dialogue and the consistency of character identity revealed through language (e.g.<a href="#bednarek2010">Bednarek 2010</a>;<a href="#bednarek2011">2011</a>;<a href="#bednarek2018">2018</a>;<a href="#quaglio2009">Quaglio 2009</a>;<a href="#zago2016">Zago 2016</a>;<a href="#zago2018">Zago 2018</a>), to explore verbal discourse in different film genres<a class="footnote-ref" href="#verianopinto2014"> [verianopinto2014] </a>, to analyze the sociolinguistic and pragmatic idiosyncrasies of interlingual dubbing (e.g.<a href="#freddi2009">Freddi 2009</a>;<a href="#freddi2013">Freddi 2013</a>) and its relationship to spontaneous speech (e.g.<a href="#heiss2005">Heiss 2005</a>;<a href="#romerofresco2009">Romero Fresco 2009</a>) or to study interlingual translation in the visual context (e.g.<a href="#valentini2006">Valentini 2006</a>;<a href="#valentini2008">2008</a>;<a href="#valentini2009">2009</a>).<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>What many of these approaches demonstrate is that film and television genres are characterized by distinctive language patterns; dialogues in screwball comedy, melodrama, western, sitcom or police procedural are endowed with genre-specific functions and genre-specific stylistic, pragmatic and rhetorical features (such as the literary stylization of classic novel adaptations, the use of slang and jargon in gangster films or the omnipresence of techno-bubble in science fiction). As Kozloff explains:</p>
<blockquote>
<p>Partially, they [these verbal genre conventions] are motivated by the subject matter. Screenwriters are always concerned that dialogue be appropriate to characters’ social backgrounds, and thusrealistic(&hellip;). Partially, films are clearly copying preexisting expectations created by other forms of representation (&hellip;). And partially, I believe, dialogue patterns are related to the underlying gender dynamics of each genre: whether the genre is primarily addressed to male or female viewers and how each genre treats its male and female characters are crucial factors in its use of language.<br>
<a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a>What some of the qualitative analyses (e.g.<a href="#jaeckle2013">Jaeckle 2013</a>;<a href="#milawskaratajczak2019">Miławska-Ratajczak 2019</a>) also show is famous writer-directors&rsquo; signature verbal style. All these insights have led us to believe that these gene- andauteur- specific verbal patterns, described by scholars and noticed by average viewers, may be further explored by stylometric measures.</p>
</blockquote>
<h2 id="research-objectives">Research objectives</h2>
<p>In our research, we decided to adopt a variety of procedures, using quantitative textual analysis tools derived from stylometry (a.k.a. computational stylistics) and from automated sentiment analysis, a significant subdiscipline of text mining. As these approaches rely on computational work, they allow to analyze large sets of texts in ways similar to distant reading<a class="footnote-ref" href="#moretti2007"> [moretti2007] </a>Moretti 2007). Used on diverse corpora of literary and non-literary texts, they have already proven helpful in plagiarism detection, authorship attribution, as well as genre- and diachrony research, as will be explained below. Their application to film dialogue, however, has so far been limited<a class="footnote-ref" href="#mckie2014"> [mckie2014] </a><a class="footnote-ref" href="#holobut2016"> [holobut2016] </a><a class="footnote-ref" href="#holobut2017a"> [holobut2017a] </a><a class="footnote-ref" href="#vanzyl2016"> [vanzyl2016] </a><a class="footnote-ref" href="#byszuk2017"> [byszuk2017] </a><a class="footnote-ref" href="#holobut2017b"> [holobut2017b] </a><a class="footnote-ref" href="#holobut2018"> [holobut2018] </a>and it certainly merits further attention for a nuber of reasons. Firstly, stylometric analysis can complement other advancements in the realm of cinemetrics<a class="footnote-ref" href="#baxter2014a"> [baxter2014a] </a><a class="footnote-ref" href="#baxter2014b"> [baxter2014b] </a>by bringing neglected cinematic speech to film scholars’ attention. Secondly, it provides yet another level of potential comparison between film dialogue and other dialogic genres, stage drama in particular. Both theatre and screen plays combine literary and performative dimensions. Stage drama has already been analyzed in its literary dimension by qualitative and quantitative means, with obvious precedence to, often, heated arguments on Shakespearean authorship attribution (to name but a few of the latest:<a href="#vickers2002">Vickers 2002</a>;<a href="#craig2009">Craig and Kinney 2009</a>;<a href="#vickers2011">Vickers 2011</a>,<a href="#rudman2016">Rudman 2016</a>). Equally obviously, this leaves the space open for the stylometry of filmic speech. Thirdly, stylometry and automated sentiment analysis can open new avenues for qualitative research, revealing “patterns overlooked in close reading” <a class="footnote-ref" href="#hayles2010"> [hayles2010] </a>. That is why in our research we intended to test the usefulness of the mentioned tools in identifying the potential stylometric similarities or differences between film fictional dialogues, revealing regularities typical of a given genre, theme, historical context, writer, director- and/ or film cycle. In our previous studies, we focused exclusively on historical films and literary adaptations, combining quantitative stylometric with qualitative stylistic and pragmalinguistic analysis of filmic speech (cf.<a href="#holobut2017b">Hołobut 2017b</a>). This time, we collected a multigeneric corpus of transcribed dialogue lists to 278 Anglophone productions, spanning over eighty-four years of cinematic art (for a complete list of productions included, see<a href="#appendix01">Appendix 1</a>), running a pilot quantitative analysis, to be potentially elaborated by qualitative means.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> We labelled each dialogue list with the name of the screenwriter and the date of release and divided them into six rough generic/thematic categories following IMDb listings: chick flick, vampire, superhero (as distinguished by the dominant theme); romance, thriller, action (as distinguished by the dominant genre). This division is admittedly provisory and tentative for several reasons:</p>
<ul>
<li>film genres are in themselves fuzzy categories, as suggested by film scholars and experts in media semiotics (cf.<a href="#chandler1997">Chandler 1997</a>;<a href="#altman1999">Altman 1999</a>;<a href="#grant2003">Grant 2003</a>;<a href="#bondebjerg2015">Bondebjerg 2015</a>);</li>
<li>most productions included in the corpus evade easy categorization, being best ascribed to a number of major film genres simultaneously and fitting better more precise sub-generic distinctions (for example, IMDb classifies many superhero films as action/adventure/fantasy or action/adventure/science-fiction hybrids, yet some productions, such as <em>Deadpool</em> or <em>Thor: Ragnarok</em> have an additional comedic twist, while others, like Christopher Nolan’s visions of <em>Batman</em> , qualify as thriller/crime);</li>
<li>thematic groupings obviously intersect with major generic ones; for example, some vampire films reveal horror and some – dominant romance features, as do a number of releases stereotypically categorized by IMDb viewers as “chick flicks”, although many of the latter belong to the sub-genre of romantic comedy; that is why we have decided to keep this dubious appellation;</li>
<li>some productions included in the corpus conform better toauteurthan genre classifications imposed on them, hence their status may be considered dubious.</li>
</ul>
<p>Still, we did not consider these complexities and inconsistencies in categorization as detrimental to our stylometric analysis. On the contrary, we hoped that by inspecting in detail the correlations between particular film scripts, we may detect certain genre-, theme-, diachrony- or author-related regularities which would allow us to revise or reshuffle the adopted categories. We therefore subjected the corpus to a number of quantitative procedures, the origin and methodology of which will be explained below.</p>
<h2 id="introducing-stylometry-and-sentiment-analysis">Introducing stylometry and sentiment analysis.</h2>
<p>Quantitative research on literary language has been developing at least since John Burrows studied character idiolects in Jane Austen, showing that her major characters with similar functions in different novels tend to use the most common words of their lexicon in similar ways (Burrows 1989). This was an early application of multivariate analysis of word frequencies that had already been around since Mosteller and Wallace showed that authors differ in this respect strongly enough to allow attribution (1964). We now know that minute differences in individual usage of very frequent and seemingly very insignificant words such asthe,a,in,and,suchandas– when treated with appropriate statistical tools – are enough to tell authors apart; or, more precisely, to point out which of several candidate writers is the real author of an anonymous text. These authorship attribution methods, sometimes still called non-standard authorship attribution methods, have in fact become a standard approach whenever the hand that held the pen (or that tapped on the keyboard) is obscured for any reason: plagiarism, publishers’ promotional policy or mere authorial whims. They have been recently used to check that Harper Lee did in fact write both <em>To Kill a Mockingbird</em> and <em>Go Set a Watchman</em> <a class="footnote-ref" href="#choinski2019"> [choinski2019] </a>; that Robert Galbraith and J.K. Rowling are one and the same person<a class="footnote-ref" href="#juola2015"> [juola2015] </a>; and that Elena Ferrante, the bestselling yet non-existent Italian woman, writes suspiciously like the real Italian man, Domenico Starnone<a class="footnote-ref" href="#tuzzi2018"> [tuzzi2018] </a>.</p>
<p>But many other stylometric experiments in method have also shown that what stylometrists call the authorial signal (meaning nothing more, in fact, than the authors’ individual idiosyncrasies in word usage that can be made evident through statistics) is just one of the classifications that can be made on any sets of texts. Not only texts by the same authors are similar in this respect. On another level, texts written by authors writing over several literary periods tend to exhibit a chronological “evolution” <a class="footnote-ref" href="#burrows1994"> [burrows1994] </a><a class="footnote-ref" href="#rybicki2017a"> [rybicki2017a] </a>, and while this can be easily explained by simple evolution of language over centuries, it is also a fact that many writers (including Shakespeare, Dickens, James and Conrad) exhibit a chronological progression within their ownoeuvre<a class="footnote-ref" href="#hoover2007"> [hoover2007] </a><a class="footnote-ref" href="#rybicki2017b"> [rybicki2017b] </a>. Works of the same writer in two different genres exhibit different stylometric traits; this has already been shown for Shakespeare and Molière<a class="footnote-ref" href="#rybicki2011"> [rybicki2011] </a><a class="footnote-ref" href="#rybicki2017b"> [rybicki2017b] </a>; what is more, genre can be a factor in large-scale comparisons of authorial word usage<a class="footnote-ref" href="#mealand1999"> [mealand1999] </a>. Interestingly, there is much less of thisstylometric universalin translation: some translators seem to exhibit their own and stablestylometrywhile others have a different word usage for each author they translate<a class="footnote-ref" href="#burrows2002"> [burrows2002] </a>, and translations in a large set tend to group more often by their original authors than by translators<a class="footnote-ref" href="#rybicki2012"> [rybicki2012] </a>; nevertheless, traces of translators can be traced within a collaborative work<a class="footnote-ref" href="#rybicki2013"> [rybicki2013] </a>.</p>
<p>That such results are stable, reproducible and robust in terms of statistics is obviously due to the fact that the features of text used for counting are very simple and, at the same time, very numerous. The first hundred most frequent word-types in any collection of texts (which usually account for as much as a half of every text) contains little more than various function words;meaningfulwords – the usual stuff of literary study – are still a minority in the first thousand. This could suggest that stylometry based on most frequent word counts misses the crucial element of literary texts, meaning, or <em>what</em> , and focuses on style, or <em>how</em> ; but, on the one hand, word counts alone are hardly style, and, on the other, Hough insisted that style is just “an aspect of meaning” <a class="footnote-ref" href="#hough1969"> [hough1969] </a>. Attempts to bridge the gap between stylistics and stylometry continue (c.f.<a href="#hermann2015">Hermann 2015</a>), but there is still much work to do; one explanation of the power of the most frequent words is that they “do not function as discrete entities. Since they gain their full meaning only through the different sorts of relationship they form with each other, they can be seen as markers of those relationships and, accordingly, of everything that those relationships entail” <a class="footnote-ref" href="#mckenna1999"> [mckenna1999] </a>.</p>
<p>The reason why most-frequent-word stylometry, and not some other types of textual analysis, has been such a powerful newcomer into (digital) literary studies is perhaps just one of the many examples that computer-based methods – especially unsupervised ones – are notoriously fallible when dealing with the semantics of the literary text. This is very visible in the tribulations of sentiment analysis, which has been a focus of much quantitative textual research at least since Stone et al. made it one of the objects of their study<a class="footnote-ref" href="#stone1966"> [stone1966] </a>. It must be said that while sentiment analysis can be of use, and is often used, in large-scale browsing of non-literary texts and/or to gauge the overall mood of large sections of the Internet, news etc., its application to artistic writing is somewhat more problematic due to the features of the literary text that define it as literary. Ambiguity, irony, metaphor or even simple negation all cause problems in disambiguating the sentiment/emotionalvalueof words and phrases.</p>
<p>Despite this problem, the presence of some interest in sentiment in literature can be attested to by the numerous software packages that try to make it possible. One of the most recent, Jockers’ssyuzhetpackage<a class="footnote-ref" href="#jockers2016"> [jockers2016] </a>for R<a class="footnote-ref" href="#rcore2014"> [rcore2014] </a>, employs a number of lexicons of sentiment-related terms to trace curves of negative and positive emotions in single novels, associating lexical items found in individual texts to emotive categories. Among these, the NRC Word-Emotion Association Lexicon<a class="footnote-ref" href="#mohammad2010"> [mohammad2010] </a>has already been used to trace the evolution of sentiment across larger literary corpora and follows Plutchik’s concept of eight “basic emotions” (anger, disgust, fear, sadness and anticipation, joy, surprise, trust;<a class="footnote-ref" href="#plutchik1991"> [plutchik1991] </a>; alternatively, it also identifies two “sentiments,” respectively: negative and positive<a class="footnote-ref" href="#mohammad2011"> [mohammad2011] </a>. A similar approach has been adopted by Acerbi et al. for English novels of the 20th century, who observed a general decrease, with time, of terms of emotion by tracing the evolution of terms related to some general categories such as fear or joy<a class="footnote-ref" href="#acerbi2013"> [acerbi2013] </a>. An even more extensive chronological study performed on three hundred years of English and Polish fiction showed a steady growth of negative sentiments and “negative” emotions with time<a class="footnote-ref" href="#rybicki2018"> [rybicki2018] </a>.</p>
<p>The main drawback sentiment analysis has is that most of the readily-available methods use a lexicon approach, where individual words are assigned a sentiment/emotion value. The NRC Word-Emotion Association Lexicon, which we used here, was a major crowdsourcing venture using Amazon’s Mechanical Turk, where numerous users contributed to produce a statistics-based system of evaluating and quantifying emotion; yet even this tool may cause a variety of problems. Consider the following examples from the NRC Lexicon (Table 1):<br>
Example of emotional valence/sentiment values in the NRC Lexicon. Grey background applied for items discussed in the text.emotion/sentimentbaboondentistrypolishanger000anticipation000disgust100fear010joy000sadness000surprise000trust000negative100positive001<br>
Thebaboonexample shows how a lexical item is assigned a value ofdisgustandnegativedespite the fact that, in a text about theriology or even Africa, these associations should be made perfectly neutral; the Lexicon also seems to ignore the fact that presence of baboons may just as plausibly triggerfear,or that one may thus address a human being inangeras well as indisgust.The example ofdentistryseems to take into consideration the most stereotypical reaction to that noble profession; more importantly, the choice of this very rare word and the absence, in the Lexicon, of the much more frequent worddentistis an illustration of the numerous issues of representativeness in this approach. The final example, that ofpolish,shows an even moremechanicalproblem and the extent to which mere linguistic ambiguity may be a distorting factor: this word, when capitalized, may well require a very different sentiment/emotion value. More generally, distribution of emotions and sentiments within the literary text is uneven; smoothing any results may be risky, as evidenced by the difficulties with this problem in thesyuzhetpackage (cf.<a href="#swafford2015">Swafford 2015</a>,<a href="#jockers2017">Jockers 2017</a>).</p>
<p>Despite these pitfalls, our attempt to measure sentiment and emotion in film dialogue seems worthwhile. After all, while the lexicon-based method may be wrong at times, it is important that it is wrong in a consistent way. Much as the tool is imprecise, there is no reason to suppose different texts will be treated in any different way.</p>
<h2 id="methods">Methods</h2>
<p>For most-frequent-word-based stylometric analysis, the texts were treated with the well-established Delta procedure<a class="footnote-ref" href="#burrows2002"> [burrows2002] </a>implemented in thestylopackage for R<a class="footnote-ref" href="#eder2016"> [eder2016] </a>, the statistical programming environment<a class="footnote-ref" href="#rcore2014"> [rcore2014] </a>. The entire ensemble of texts in electronic form serves as input forstylo, which then tokenizes the text (separates it into words). The word tokens are then counted in the whole set to produce a descending frequency list of word-types, so that the 100 or more of these may be identified. A given number of those very frequent words (usually, from 100 to 1000) is used as the features of the analysis: their frequency is now counted in each individual text to create a frequency table; its columns are treated as sequences of numbers that can be compared using an appropriate distance (dissimilarity) measure. Our study uses the so-called Cosine Delta distance, which has been shown to work best in authorship attribution<a class="footnote-ref" href="#evert2017"> [evert2017] </a>. It is based on cosine similarity of the angle between two vectors, x = z(T) and y = z(T1), and is calculated according to the formula:cos∝=∑i=1nsxiyi(∑i=1nsxi2)(∑i=1nsyi2)where ns is the number of most-frequent word-types used in the analysis, while z(T) and z(T1) are z-score values for the frequency of a word in, respectively, texts T and T1. Z-scores are calculated with the usual formula:zT=fsT-μsσswhere fs(T) denotes relative frequency of word s in text T, µs is mean frequency of word s in the entire set of texts, and σs is standard deviation of frequency of word s in the same set<a class="footnote-ref" href="#smith2011"> [smith2011] </a>.</p>
<p>This produces a distance matrix: a square table ofdistances,or degrees of dissimilarity, between each pair of texts – the smaller the value, the more similar the two texts are. Usually, at least in literary texts of some length, the smallest values are those between texts written by the same author; our studies have shown that this is a much less marked phenomenon in film dialogue, and even less so in TV series<a class="footnote-ref" href="#holobut2016"> [holobut2016] </a><a class="footnote-ref" href="#holobut2017a"> [holobut2017a] </a>. While this is already the kind of output that may be examined, analyses of larger numbers of texts require visualization of the patterns of similarity and difference between the texts, which can be achieved with further statistical procedures. We use Ward’s hierarchical cluster analysis to draw tree diagrams that bring together the nearest neighbors (texts most similar to each other); usually, for greater reliability of the results, this is repeated for different numbers of most-frequent word types (in our study, for 100, 200, 300, … 1000) most frequent words, and the results are further processed in consensus network analysis<a class="footnote-ref" href="#eder2017"> [eder2017] </a>in <em>Gephi</em> <a class="footnote-ref" href="#bastian2009"> [bastian2009] </a>.</p>
<p>While the stylometric part of the analysis was performed on all grammatical word forms, sentiment analysis requires that the texts be lemmatized, or converted to their basic grammatical forms. This was done with the standard automatic tool, Treetagger<a class="footnote-ref" href="#schmid1994"> [schmid1994] </a>. Sentiments and emotions (as defined by<a href="#mohammad2011">Mohammad 2011</a>) were counted using the “NRC Lexicon” within thesyuzhetpackage<a class="footnote-ref" href="#jockers2016"> [jockers2016] </a>. Counts of emotions were summed for each text and proportions between positive and negative sentiments established for each text. Graphs were produced to visualize the results; the Lexicon’s eight emotions were treated similarly but relative to individual text lengths.</p>
<h2 id="results">Results</h2>
<p>Figure 1 presents a network analysis performed with the above-mentioned method on the full set of film dialogues.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Network analysis of the entire set of film dialogues, color-coded by (principal) genre: action/adventure, red; chick flick, yellow; romance, grey; superhero, orange; thriller, blue and vampire, green).
        </p>
    </figcaption>
</figure>
<p>As can be seen, clustering by generic-thematic grouping is especially successful for thrillers (blue), with particularly strong connections visible among films sharing sub-generic properties. For instance, Brian Singer’s crime/drama/thriller <em>The Usual Suspects</em> (1995) written by Christopher McQuarrie shows on the one hand strong connections to David Fincher’s crime/mystery drama <em>Seven</em> (1995) and on the other – to Quentin Tarantino’s <em>Reservoir Dogs</em> (1993), the Coen brothers’ <em>Fargo</em> (2006), and Martin Scorsese’s <em>The Departed</em> (2006), thus demonstrating close stylometric affinities between different productions combining elements of crime, drama and thriller and raising interesting questions about the sensitivity of stylometric tools to the exponents of low register (possibly reflected in the grammatical simplicity of utterances affecting the frequency of function words) and the pragmatics of deduction and threat (cf.<a href="#kozloff2000">Kozloff 2000: 220</a>) typical of crime films.</p>
<p>John McTiernan’s <em>Die Hard</em> (1988), classified by IMDb as action/thriller, shows strong ties to both genres, being much closer to other action productions (such as Steven Spielberg’s <em>Jaws</em> , 1975), but at the same time showing surprisingly tight stylometric bonds to Tarantino’s <em>Pulp Fiction</em> (1994), Michael Mann’s <em>Heat</em> (1995) and Luc Besson’s <em>Leon</em> (1994), classified as crime/drama/thrillers.</p>
<p>A separate sub-area on our map is occupied by Alfred Hitchcock’s masterpieces intertwined with classic noir productions. <em>Dial M for Murder</em> (crime, thriller 1954), written by a British playwright Frederick Knott, links strongly to Hitchcock’s <em>Psycho</em> (an adaptation of Robert Bloch’s novel; horror, mystery, 1960) and <em>Rebecca</em> (an adaptation of Daphne du Maurier’s novel; drama, mystery, romance,1940), as well as to Carol Reed’s <em>The Third Man</em> , written by Graham Greene (film-noir, mystery, thriller, 1949). <em>Rebecca</em> is closely related to his <em>Psycho</em> and <em>Vertigo</em> (an adaptation of Boileau-Narcejac’s novel; mystery, romance, thriller, 1958), as well as to Billy Wilder’s film noir <em>Double Indemnity</em> co-authored by the director and Raymond Chandler (crime, drama, film noir, 1944). At the same time, it connects strongly to David Lean’s romance <em>Brief Encounter</em> and other representatives of the romance genre, such as Sydney Pollack’s <em>Out of Africa</em> (1985) or Edward Zwick’s <em>Legends of the Fall</em> (1994). Hitchcock’s <em>Rear Window</em> (mystery, thriller 1954) is bonded with <em>Psycho</em> , as well as <em>The Third Man</em> and <em>Double Indemnity</em> . They constitute quite a tight-knit area in the diagram, allowing the diachronic, generic andauteurdirector signals to collude and encouraging further qualitative research into how Hitchcock’s belief in the subservience of dialogue topure cinemamay have affected his collaborator’s screenwriting style and reflected earlier film-making conventions. The only Hitchcock production that does not blend in with the other scripts analyzed is <em>North by Northwest</em> (adventure, mystery, thriller, 1959), written by Ernest Lehman and apparently intended by the writer as “the Hitchcock picture to end all Hitchcock pictures” (qtd. in<a href="#freedman2015">Freedman 2015: 36</a>). The dialogue lines demonstrate closer links to Roman Polański’s neo-noir <em>Chinatown</em> (1974), and Jacques Tourneur’s noir <em>Out of the Past</em> (1947) than to Hitchcock’s other films. These neighbor with two representatives of the gangster genre in our corpus, Francis Ford Coppola’s <em>Godfather</em> (1972, 1974). An in-depth inspection of this grouping suggests that further sub-division into mystery, gangster and film noir might reveal additional patterning in dialogue techniques. This supports Sarah Kozloff’s “close-reading” observations on the functional and pragma-stylistic distinction to be made between noirs and gangster films, the former featuring characters who are “middle-class,” solitary, “cynical and deliberately hardboiled ” and the latter featuring self-educated “groups of confederates” <a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a>. It is interesting, however, that films directed by Alfred Hitchcock (and written by different acclaimed authors) display stronger stylometric bonds than those both written and directed by other acclaimedauteurs, such as Quentin Tarantino or the Coen brothers.</p>
<p>Another grouping that forms a successful cluster is the thematic category “chick flick”. As listed by IMDb users, it is dominated by romcoms, but it also contains romance drama and family drama, films that demonstrably tap into the realm of human emotions and range from humor to pathos. They consistently occupy the right-hand side of the map and intermingle with productions categorized asromances,a grouping that clearly overlaps with the one discussed. Thus, the greyintrusionsinto the yellow-dominated area on the diagram are allauteurromances: John Carney’s romantic musical dramas <em>Once</em> (2007) and <em>Sing Street</em> (2016), Damien Chazelle’s <em>La La Land</em> (2016) and Bradley Cooper’s most recent remake of <em>A Star is Born</em> (2018), as well as critically acclaimed verbal masterpieces: Richard Linklater’s romantic drama trilogy <em>Before Sunrise</em> (1995), <em>Before Sunset</em> (2004) and <em>Before Midnight</em> (2013) co-created with performers Julie Delpy and Ethan Hawke, Woody Allen’s <em>Manhattan</em> (1979) and <em>Annie Hall</em> (1977) and Spike Jonze’s <em>Her</em> (2013), the last two presented with the Academy Award for Best Original Screenplay and clearly devoid of melodramatic traces typical of many representatives of the “romance” category.</p>
<p>Another interesting regularity to be observed in this area of the diagram is the clustering of films written or co-authored by Richard Curtis: <em>Four Weddings and a Funeral</em> (1994), the two Bridget Jones films (2001, 2004), <em>Notting Hill</em> (1999), <em>Love, Actually</em> (2003) and <em>About Time</em> (2013). The only aberration on the romcom/romance map is James Cameron’s <em>Titanic</em> (1997), hidden in the depths of action/adventure/thriller, in the neighborhood of Spielberg’s <em>Jaws</em> (1975) and Inarritu’s <em>Revenant</em> (2015). It seems that James Cameron’s unsentimental provenance and interest in non-romantic genres may have left stylometric traces in his dialogue technique.</p>
<p>Vampire films (green), by contrast, reveal their individual and complex generic affinities. The <em>Twilight</em> saga, spread around the central part of the diagram, shows marked stylometric affinities across the episodes, yet it clearly demonstrates the gradual loss of romantic undertone, with the first two episodes: <em>Twilight</em> (2008) and <em>New Moon</em> (2009) classified as fantasy/drama/romance showing bonds with romantic comedies and romances and the more recent parts of the series uniting with classic thriller productions. Another area is occupied by horror rather than fantasy representations of the vampire theme: Coppola’s <em>Dracula</em> (1992), Burton’s <em>Dark Shadows</em> (2012), Jordan’s <em>Interview with the Vampire</em> (1994) and dated horrors: Sangster’s <em>Lust for a Vampire</em> (1971) and Francis’s <em>Dr Terror’s House of Horrors</em> (1965). These regularities may, indeed, suggest that stylometric measures based on most frequent word frequencies are sensitive to the changing functionalities of filmic speech, romance depending more on the explicit expression of emotion<a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a>and horror – on the implicit build-up of suspense.</p>
<p>As for other groupings, action/adventure films, including superhero productions, all cluster to the left-hand side of the diagram. What merits attention is the stylometric consistency of big franchises, with particular episodes clustering regardless of their authorial parentage. Some blockbuster series can be attributed to the same screenwriter throughout, allowing the authorial and thematic signals to coincide: for instance, the <em>Pirates of the Caribbean</em> swashbucklers (written by Ted Elliott and Terry Rossio), the <em>Matrix</em> trilogy (by Lana and Lilly Wachowski), the <em>Lord of the Rings</em> and the <em>Hobbit</em> series, which intertwine in our analysis (written by Fran Walsh, Philippa Boyens, Peter Jackson).</p>
<p>The Batman series is clearly divided into two main areas: a cluster of Christopher Nolan’s most recent productions: <em>Batman Begins</em> (2005), <em>The Dark Knight</em> (2008) and <em>The Dark Knight Rises</em> (2012) and another cluster of three older episodes: <em>Batman Returns</em> (1992) directed by Tim Burton as well as <em>Batman Forever</em> (1995) and <em>Batman and Robin</em> (1997) directed by Joel Schumacher. Tim Burton’s original <em>Batman</em> (1989), however, occupies a distant location on the map, tied closely to thriller films, and showing little stylometric relation to the following pictures, possibly inspired more by the gangster/crime genre to which it visually alludes.</p>
<p>The <em>Star Wars</em> franchise is, unsurprisingly, separated into three areas. The two oldest episodes: <em>Star Wars</em> (1977) and <em>The Empire Strikes Back</em> (1980) are united with a strong stylometric bond. Lawrence Kasdan and George Lucas’s <em>Return of the Jedi</em> (1983) connects them to the more recent trilogy: <em>The Phantom Menace</em> (1999), <em>Attack of the Clones</em> (2002) and <em>Revenge of the Sith</em> (2005), written by George Lucas. They neighbour closely with Lucas’s other productions, namely Steven Spielberg’s <em>Indiana Jones and the Raiders of the Lost Ark</em> (written by Kasdan, 1982) and <em>Indiana Jones and the Last Crusade</em> (written by Boam, 1989). The most recent <em>Star Wars</em> incarnations produced by Disney: <em>The Force Awakens</em> (2015), <em>The Last Jedi</em> (2017) and <em>Rogue One</em> (2016) form a separate cluster, showing a different dialogue technique. Interestingly, Lawrence Kasdan’s most recent addition to the series, <em>Solo: A Star Wars Story</em> (2018) does not reveal any stylometric affinities to the remaining pictures; indeed <em>Solo</em> does seem to fly solo.</p>
<p>As for other series, <em>Jurassic Park</em> and <em>Jurassic World</em> episodes show stylometric links. Richard Donner’s <em>Superman</em> (1978) bonds with its recent remake, <em>Superman Returns</em> (2006) are Richard Lester’s <em>Superman II</em> (1980). Significantly, the comedic third episode, <em>Superman III</em> (1983) is separated from the remaining ones. Other remakes, such as <em>The Last of the Mohicans</em> (1937, 1992) and two out of the four versions of <em>A Star is Born</em> (1937; 1954) also demonstrate marked stylometric similarity.</p>
<p>When isolated from other categories, the sub-generic nuances of action/adventure productions become somewhat more marked (<a href="#figure02">Figure 2</a>). This configuration also exhibits a strong authorial signal and, very characteristically for film dialogues, a tendency to cluster by thematic universe<a class="footnote-ref" href="#holobut2016"> [holobut2016] </a><a class="footnote-ref" href="#holobut2017a"> [holobut2017a] </a>H. As a result, the mob-ridden environment of Gotham and Spiderman’s New York becomes very similar to that of the more direct depictions of the mafia by Coppola.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Network analysis of the action/adventure (red) and superhero (orange) genre.
        </p>
    </figcaption>
</figure>
<p>Sentiment analysis can be mostly presented with much less statistical manipulation, simply by plotting the various sentiment/emotion scores against time of film release. Figure 3 shows the proportion of positive to negative sentiments in our entire set of film dialogues (data points) and the linear trend (lines) of this ratio. In the figure, balanced positive-to-negative contents would place a given film at 0.5 on the vertical scale; anything above that value contains more positive than negative terms; anything below 0.5 descends into negativity. As can be seen, values for all groupings are highly scattered; nevertheless, some trends in the appearance of positive and negative sentiments may be observed. The oldest genres in this set, romances and thrillers, exhibit a fairly stable proportion, with, unsurprisingly, a much higher participation of the positive despite a slight downwards trend. By contrast, the initially much more negative thrillers rise slightly from darker to lighter moods. A much more marked fall in positive sentiments can be observed in the dialogues of action/adventure films and even more so in the superhero subgenre; in the second decade of the 21st century, they are more negative in sentiment than even the thrillers. Still, negativity flourishes the most in an entirely different class: in the vampire movies; their verbally expressed positive sentiments dwindle almost to 0.5 at the end of the timeline, perhaps not unrelatedly to a very marked and mirror-image ascent of positive values in chick flicks. </p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Positive-to-negative sentiment ratio in the entire set of film dialogues, color-coded by (principal) genre, with linear trendlines.
        </p>
    </figcaption>
</figure>
<p>Numeric results for the eight basic Plutchik emotions are consistent with both those for positivity/negativity and with each other. Based on the results of the Kruskal-Wallis tests obtained for each pair of emotions (well below any values that could suggest statistical insignificance), their representation in the boxplots in Figure 4 shows a very strong correlation for high levels of anticipation and joy between chick flicks and romances. These two categories are also very much alike in their equally low values of anger, disgust, and fear. At the same time, in terms of these five emotions, both romances and chick flicks differ with very high statistical significance from the other genres. Sadness and fear are also statistically higher in films about vampires; this grouping is also significantly deficient in trust. It may be said more generally that, in terms of sentiment and emotion analysis, three rather than six categories are discernible here: 1) chick flicks and romances, 2) vampire films, 3) action, superhero and thriller movies.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Relative frequencies of words associated with the eight basic emotions in the entire set of film dialogues. Boxes denote the range of the 25th-75th percentiles; the short horizontal line inside each box is the median; whiskers and circles denote outlying (extreme) values.
        </p>
    </figcaption>
</figure>
<h2 id="discussion">Discussion</h2>
<p>Several interesting observations can be made on the basis of this study. Not the least of these is that the tentative theme/genre classifications that we have started with have been verified by our quantitative approach in both stylometry and sentiment analysis. Our most-frequent-word analysis shows that while some of our initial groupings do seem to create discernible communities, individual films do not seem to care. These stylometricmisclassifications(such as the affinity of Woody Allen’s sophisticated comedies to other comedic productions rather than for instance period romance dramas) are understandable and attest to the inadequacy of our <em>a priori</em> film classification rather than that of the stylometric approach; indeed, these misclassifications often correct the rough pigeon-holing that we used, revealing the influence of authorial and sub-generic nuance on the measurable features of film dialogue style and mutual relationships between dialogue techniques in different groups of films considered.</p>
<p>Film dialogue seems to successfully reflect the fact that individual films rarely conform to the requirements of a single, unadulterated, major-level genre such as action films or thrillers. This becomes quite evident when one views in detail the network analysis graph in full complexity of its signals. At times, films cluster by screenwriter as if in accordance with theSchreibertheory of film authorship; at times, the director’s choices seem to bring together different screenwriters’ efforts, as if to vindicate the claims ofauteurtheorists who believe in the director’s influence over the collective work of different specialists, screenwriters included. Then there are mainstream films that do cluster by genre. Elsewhere, the collaborative nature of making movies takes over to create a strong franchise signal, which in turn may be overridden by that of the studio: after all, in our graphs, Disney <em>Star Wars</em> have left the orbit of their predecessors. Diachrony is another significant element which deserves more in-depth qualitative analysis, possibly looking at the evolution of non-verbal cinematic techniques; the language of film dialogue in the 1940s and the 1950s stands apart from later productions. What is more, the diachronic element is not limited to the date of the films’ release; our stylometric results can also reflect their temporal setting, quite plausibly due to archaic stylization of the spoken parts. This has already been noted in an earlier study on historical films and series<a class="footnote-ref" href="#holobut2017a"> [holobut2017a] </a>.</p>
<p>It is quite remarkable that, despite all the above caveats against lexicon-based sentiment analysis, much of our results of this type of distant reading agrees with what we know about the genres fromclose viewing.The fact that computational sentiment analysis agrees so well, indeed so boringly, with human presuppositions might be a result of the somewhat crude approach – through decontextualized lexical items. At the same time, however, the crude nature of the lexicon approach may be reflected in the fact that, contrarily to most-frequent-word stylometry, sentiment analysis shows fewer, rather than more, valid divisions: chick flicks merge with romances, action/superhero films with thrillers. Meanwhile, vampire movies, an internally conflicted category according to Delta, acquires a separate status due to higher levels offearand lower levels oftrust.This quantitative procedure can act as a starting point for more in-depth qualitative evaluation of emotions (both those expressed by characters and those evoked in viewers) and the dominance of particular speech acts in the verbal exchanges on screen (such as teasing in comedy, threatening in gangster films, commanding in drama or explaining in science-fiction, cf.<a href="#kozloff2000">Kozloff 2000</a>).</p>
<p>It may seem paradoxical that of the two approaches used in this study, the one that seems to have less to do with semantics – the comparison of frequencies of very frequent words, grammatical words, function words,synsemanticwords – also seems to reflect, albeit indirectly, the semantics of the film dialogues – their differing functionalities, their stylistic patternings, their themes, their thematic subgenres, their implied audience. At the same time, an approach more directly aimed at meaning: the search for terms of sentiment,syuzhet, emotion, suffers from the computers’ still-underdeveloped ability tounderstandthe meaning of literary texts and can only confirm – at best – what we already know about film genres. In fact, the little information we obtain from this latter part of the study makes our flawed (oversimplified) classification seem almost adequate – which it certainly is <em>not</em> . Still, it is enough to teach us never to trust a vampire&hellip;</p>
<p>Dialogue is only a small part of film. At first glance – and for quite a long time in the history of film studies – it seemed much less important to the overall form and meaning of the art than image or non-verbal sound. Film scholars, cognitive scientists and digital experts have already undertaken extensive research into film narrative structure (e.g.<a href="#murtagh2009">Murtagh 2009</a>;<a href="#mckie2014">McKie 2014</a>), film digital archiving (e.g.<a href="#bateman2016">Bateman 2016</a>) and othermeasurableparameters of cinematic art, such as shot lengths, types of shots, motion types and/or visual characteristics of the image onscreen such as light intensity (e.g.<a href="#salt2007">Salt 2007</a>;<a href="#cutting2011">Cutting 2011</a>;<a href="#suchan2016">Suchan 2016</a>;<a href="#heftberger2018">Heftberger 2018</a>). Our study shows that results of these more standard digital film studies could be interestingly confronted with quantitative analysis of films’ textual layer for better insight into the specificities and the mutual influences of film genres, authorialoeuvreor chronology; if only to see to what extent the sentiments and the emotions and the style in film dialogue go hand in hand – or not – with the visual and the non-verbal auditory components in various film genres and periods of film history.</p>
<p>Such a multifaceted analysis of film would be a dream interdisciplinary project, and, in Shakespearean phrase, devoutly to be wished. The fact that it has not been yet done, at least to our knowledge, is a result of obvious difficulties. It is possible to produce a large corpus of film dialogue texts, for instance editing the screenplays available online (cf.<a href="#murtagh2009">Murtagh 2009: 302</a>); distant reading was made for big data (in this case, textual data too extensive to be processed by the naked eye); once the texts are acquired, the machines do the rest. However, the same can hardly be said of the moretechnicalsides of filmmaking listed in the preceding paragraph: there, each item would require much annotation and coding, resulting in a much higher complexity of the project. The good news is that now that (we believe) interesting textual features of film dialogue have been found, the incentive to combine it with other features of film may result in a much larger project than the one that could be described within the limited space of this paper.</p>
<h2 id="appendix-1">Appendix 1.</h2>
<h1 id="list-of-films-included-in-the-corpus-divided-into-subcategories-following-imdbs-classifications-and-ordered-chronologically">List of films included in the corpus divided into subcategories (following IMDBs classifications) and ordered chronologically:</h1>
<ul>
<li></li>
</ul>
<h1 id="action">Action</h1>
<ul>
<li>
<p>The Godfather, dir. F. F. Coppola, USA (1971) [crime, drama]</p>
</li>
<li>
<p>The Godfather, dir. FF. Copola, USA (1974) F. F. Coppola [crime, drama]</p>
</li>
<li>
<p>Jaws, dir. S. Spielberg, USA (1975) [adventure, drama, thriller]</p>
</li>
<li>
<p>Star Wars, dir. G. Lucas, USA (1977) [action, adventure, fantasy]</p>
</li>
<li>
<p>Star Wars Episode V: The Empire Strikes Back, dir. I. Kershner, USA (1980) [action, adventure, fantasy]</p>
</li>
<li>
<p>Raiders of the Lost Ark, dir. S. Spielberg, USA (1981) [action, adventure]</p>
</li>
<li>
<p>Star Wars Episode VI: Return of the Jedi, dir. R. Marquand, USA (1984) [action, adventure, fantasy]</p>
</li>
<li>
<p>Indiana Jones and the Temple of Doom, dir. S. Spielberg, USA (1984) [action, adventure]</p>
</li>
<li>
<p>Indiana Jones and the Last Crusade, dir. S. Spielberg, USA (1989) [action, adventure, fantasy]</p>
</li>
<li>
<p>Jurassic Park, dir. S. Spielberg, USA (1993) [adventure, sci-fi, thriller]</p>
</li>
<li>
<p>The Lost World: Jurassic Park, dir. S. Spielberg (1997) [action, adventure, sci-fi]</p>
</li>
<li>
<p>The Matrix, dir. L. and L. Wachowski, USA (1999) [action, sci-fi]</p>
</li>
<li>
<p>Lord of the Rings: The Fellowship of the Ring, dir. P. Jackson, News, Zealand, USA (2001) [adventure, drama, fantasy]</p>
</li>
<li>
<p>Star Wars Episode I: The Phantom Menace, dir. G. Lucas, USA (2001) [action, adventure, fantasy]</p>
</li>
<li>
<p>Jurassic Park III, dir. J. Johnston, USA (2001) [action, adventure, sci-fi]</p>
</li>
<li>
<p>Lord of the Rings: The Two Towers, dir. P. Jackson, New Zealand, USA (2002) [adventure, drama, fantasy]</p>
</li>
<li>
<p>Star Wars Episode II: Attack of the Clones, dir. G. Lucas, USA (2002) [action, adventure, fantasy]</p>
</li>
<li>
<p>The Lord of the Rings: The Return of the King, dir. P. Jackson, New Zealand, USA (2003) [action, adventure, drama]</p>
</li>
<li>
<p>The Matrix Reloaded, dir. L. and L. Wachowski, USA (2003) [action, sci-fi]</p>
</li>
<li>
<p>The Matrix Revolutions, dir. L. and L. Wachowski, USA (2003) [action, sci-fi]</p>
</li>
<li>
<p>The Pirates of the Caribbean: he Curse of the Black Pearl, dir. G. Verbinski, USA (2003) [action, adventure, fantasy]</p>
</li>
<li>
<p>Star Wars Episode III: Revenge of the Sith, dir. G. Lucas, USA (2005) [action, adventure, fantasy]</p>
</li>
<li>
<p>The Pirates of the Caribbean: The Dead Man’s Chest, dir. G. Verbinsku, USA (2006) [action, adventure, fantasy]</p>
</li>
<li>
<p>Pirates of the Caribbean: At World’s End, dir. G. Verbinski, USA (2007) [action, adventure, fantasy]</p>
</li>
<li>
<p>Indiana Jones and the Kingdom of the Crystal Skull, dir. S. Spielberg, USA (2008) [action, adventure, fantasy]</p>
</li>
<li>
<p>Pirates of the Caribbean: On Stranger Tides, dir. R. Marshall, USA (2012) [action, narrative, fantasy]</p>
</li>
<li>
<p>The Hobbit: An Unexpected Journey, dir. P. Jackson, USA, New Zealand (2012) [adventure, family, fantasy]</p>
</li>
<li>
<p>The Hobbit: The Desolation of Smaug, dir. P. Jackson, USA, New Zealand (2013) [adventure, fantasy]</p>
</li>
<li>
<p>Rush, dir. R. Howard, UK, Germany, USA (2013) [action, biography, drama]</p>
</li>
<li>
<p>Hobbit: The Battle of the Five Armies, dir. P. Jackson, USA, New Zealand (2014) [adventure, fantasy]</p>
</li>
<li>
<p>Jurassic World, dir. C. Trevorrow, USA (2015) [action, adventure, sci-fi]</p>
</li>
<li>
<p>Star Wars Episode VII: The Force Awakens, dir. J. J. Abrams, USA (2015) [action, adventure, fantasy]</p>
</li>
<li>
<p>The Revenant, dir. A. G. Iñárritu, USA, Hong Kong, Taiwan (2015) [action, adventure, biography]</p>
</li>
<li>
<p>Rogue One, dir. G. Edwards, USA (2016) [action, adventure, sci-fi]</p>
</li>
<li>
<p>Star Wars: The Last Jedi, dir. R. Johnson, USA (2017) [action, adventure, fantasy]</p>
</li>
<li>
<p>Jurassic World: The Fallen Kingdom, dir. J. A. Bayona, USA (2018) [action, adventure, sci-fi]</p>
</li>
<li>
<p>Solo: A Star Wars Story, dir. R. Howard, USA (2018) [action, adventure, fantasy]</p>
</li>
<li></li>
</ul>
<h1 id="chick-flick">Chick flick</h1>
<ul>
<li>
<p>Ice Castles, dir. D. Wrye, USA (1978) [drama, romance, sport]</p>
</li>
<li>
<p>Terms of Endearment, dir. J.L. Brooks, USA (1983) [comedy, drama]</p>
</li>
<li>
<p>Splash (1984), dir. R. Howard, USA [comedy, fantasy, romance]</p>
</li>
<li>
<p>Pretty in Pink, dir. H. Deutch, USA (1986) [comedy, drama, romance]</p>
</li>
<li>
<p>Dirty Dancing, dir. E. Ardolino, USA (1987) [drama, music, romance]</p>
</li>
<li>
<p>Moonstruck, dir N. Jewison, USA (1987) [comedy drama, romance]</p>
</li>
<li>
<p>Beaches, dir. G. Marshall, USA (1988) [comedy, drama, music]</p>
</li>
<li>
<p>Steal Magnolias, dir. H. Ross, USA (1989) [comedy, drama, romance]</p>
</li>
<li>
<p>When Harry Met Sally, dir. R. Reiner, USA (1989) [comedy, drama, romance]</p>
</li>
<li>
<p>Ghost, dir. Jerry Zucker, USA (1990) [drama, fantasy, romance]</p>
</li>
<li>
<p>Pretty Woman, dir. G. Marshall, USA (1990) [comedy, romance]</p>
</li>
<li>
<p>Father of the Bride, dir. Ch. Shyer, USA (1991) [comedy, family, romance]</p>
</li>
<li>
<p>Fried Green Tomatoes, dir. J. Avnet, USA (1991) [drama]</p>
</li>
<li>
<p>Thelma and Louise, dir. R. Scott, USA (1991) [adventure, crime, drama]</p>
</li>
<li>
<p>Indecent Proposal, dir. A. Lyne, USA (1993) [drama, romance]</p>
</li>
<li>
<p>Sleepless in Seattle, dir. N. Ephron, USA (1993) [comedy, drama, romance]</p>
</li>
<li>
<p>Untamed Heart, dir. T. Bill (1993), USA [comedy, drama, romance]</p>
</li>
<li>
<p>Four Weddings and a Funeral, dir. M. Newell, UK [comedy, drama, romance]</p>
</li>
<li>
<p>Boys on the Side, dir. H. Ross, USA, France (1995) [comedy, drama]</p>
</li>
<li>
<p>Clueless, dir. A. Heckerling, USA (1995) [comedy, romance]</p>
</li>
<li>
<p>A Month by the Lake, dir. J. Irvin, UK, USA (1995) [comedy, drama, romance]</p>
</li>
<li>
<p>While You Were Sleeping, dir. J. Turteltaub, USA (1995) [comedy, drama, romance]</p>
</li>
<li>
<p>The Truth About Cats and Dogs, dir. M. Lehmann, USA (1996) [comedy, romance]</p>
</li>
<li>
<p>Romy and Michele’s High School Reunion, dir. D. Mirkin, USA (1997) [comedy]</p>
</li>
<li>
<p>My Best Friend’s Wedding, dir. P.J. Hogan, USA (1997) [comedy, drama, romance]</p>
</li>
<li>
<p>Titanic, dir. J. Cameron, USA (1997) [drama, romance]</p>
</li>
<li>
<p>Home Fires, dir. D. Parisot, USA (1998) [comedy, romance, drama]</p>
</li>
<li>
<p>Hope Floats, dir. F. Whitaker, USA (1998) [drama, romance]</p>
</li>
<li>
<p>Ever After, dir. A. Tennant, USA (1998) [comedy, drama, romance]</p>
</li>
<li>
<p>Stepmom, dir. Ch. Columbus, USA (1998) [comedy, drama]</p>
</li>
<li>
<p>How Stella Got Her Groove Back, dir. K. R. Sullivan, USA (1998) [comedy, drama, romance]</p>
</li>
<li>
<p>Practical Magic, dir. G. Dunne, USA (1998) [comedy, drama, fantasy]</p>
</li>
<li>
<p>The Wedding Singer, dir. F. Coraci, USA (1998) [comedy, music, romance]</p>
</li>
<li>
<p>You’ve Got Mail, dir. N. Ephron, USA (1998) [comedy, drama, romance]</p>
</li>
<li>
<p>Notting Hill, dir. R. Curtis, UK, USA (1999) [comedy, drama, romance]</p>
</li>
<li>
<p>Forces of Nature, dir. B. Hughes, USA (1999) [comedy, romance]</p>
</li>
<li>
<p>10 Things I Hate About You, dir. G. Junger, USA (1999) [comedy, drama, romance]</p>
</li>
<li>
<p>Never Been Kissed, dir. R. Gosnell, USA (1999) [comedy, drama, romance]</p>
</li>
<li>
<p>She’s All That, dir. R. Iscove, USA (1999) [comedy, romance]</p>
</li>
<li>
<p>Runaway Bride, dir. G. Marshall, USA (1999) [comedy, romance]</p>
</li>
<li>
<p>Miss Congeniality, dir. D. Petrie, USA (2000) [action, comedy, crime]</p>
</li>
<li>
<p>Save the Last Dance, dir. T. Carter, USA (2000) [drama, music, romance]</p>
</li>
<li>
<p>The Wedding Planner, dir. A. Shankman, Germany, USA (2001) [comedy, romance]</p>
</li>
<li>
<p>Serendipity, dir. P. Chelsom, USA (2001) [comedy, romance]</p>
</li>
<li>
<p>Bridget Jones’ s Diary, dir. S. Maguire, UK, France, USA (2001) [comedy, drama, romance]</p>
</li>
<li>
<p>The Princess Diaries, dir. G. Marshall, USA (2001) [comedy, family, romance]</p>
</li>
<li>
<p>Legally Blonde, dir. R. Luketic, USA (2001) [ comedy, romance]</p>
</li>
<li>
<p>Maid in Manhattan, dir. W. Wang, USA (2002) [comedy, drama, romance]</p>
</li>
<li>
<p>Sweet Home Alabama, dir. A. Tennant, USA (2002) [comedy, romance]</p>
</li>
<li>
<p>My Big Fat Greek Wedding, dir. J. Zwick, Canada, USA (2002) [comedy, drama, romance]</p>
</li>
<li>
<p>Crossroads, dir. T. Davies, USA (2002) [comedy, drama, romance]</p>
</li>
<li>
<p>Divine Secrets of the Ya-Ya Sisterhood, dir. C. Khouri, USA (2002) [ drama]</p>
</li>
<li>
<p>A Walk t Remember, dir A. Shankman, USA (2002) [ drama, romance]</p>
</li>
<li>
<p>How to Lose a Guy in 10 Days, dir. D. Petrie, USA (2003) [comedy, romance]</p>
</li>
<li>
<p>Uptown Girls, dir. B. Yakin, USA (2003) [ comedy, drama, romance]</p>
</li>
<li>
<p>Le Divorce, dir. J. Ivory, USA (2003) [ drama, romance, comedy]</p>
</li>
<li>
<p>Love, Actually, dir. R. Curtis, UK, USA, France (2003) [comedy, drama, romance]</p>
</li>
<li>
<p>Alex and Emma, dir. R. Reiner, USA (2003) [comedy, romance]</p>
</li>
<li>
<p>Under the Tuscan Sun, dir. A. Wells, USA, Italy (2003) [comedy, drama, romance]</p>
</li>
<li>
<p>Legally Blonde 2, dir. Ch. Herman-Wormfeld, USA (2003) [comedy]</p>
</li>
<li>
<p>Love Don’t Cost a Thing, dir. T. Byer, USA (2003) [comedy, romance, drama]</p>
</li>
<li>
<p>Bridget Jones: The Edge of Reason, dir. B. Kidron, UK, USA (2004) [comedy, drama, romance]</p>
</li>
<li>
<p>The Notebook, dir. N. Cassavetes, USA (2004) [drama, romance]</p>
</li>
<li>
<p>13 Going on 30, dir. G. Winick, USA (2004) [comedy, fantasy, romance]</p>
</li>
<li>
<p>50 First Dates, dir. P. Segal, USA (2004) [comedy, drama, romance]</p>
</li>
<li>
<p>Raisin Helen, dir. G. Marshall, USA (2004) [comedy, drama, romance]</p>
</li>
<li>
<p>The Little Black Book, dir. N. Hurran, USA (2004) [comedy, romance, drama]</p>
</li>
<li>
<p>Mean Girls, dir. M. Waters, USA (2004) [comedy]</p>
</li>
<li>
<p>Fever Pitch, dir. B and P. Farelly, USA (2005) [comedy, drama, romance]</p>
</li>
<li>
<p>Monster-in-Law, dir. R. Luketic, USA, Germany (2005) [comedy, romance]</p>
</li>
<li>
<p>The Wedding Date, dir. C. Kilner, SUA (2005) [comedy, romance]</p>
</li>
<li>
<p>The Perfect Man, dir. M. Rosman, USA (2005) [comedy, family, romance]</p>
</li>
<li>
<p>Hitch, dir. A. Tennant, USA (2005) [comedy, romance]</p>
</li>
<li>
<p>Prime, dir. B. Younger, USA (2005) [comedy, drama, romance]</p>
</li>
<li>
<p>The Sisterhood of the Travelling Pants, dir. K. Kwapis (2005) [comedy, drama, romance]</p>
</li>
<li>
<p>Must Love Dogs, dir. G. D. Goldberg, USA (2005) [comedy, romance]</p>
</li>
<li>
<p>Last Holiday, dir. W. Wang, USA (2006) [comedy]</p>
</li>
<li>
<p>Failure to Launch, dir. T. Dey, USA (2006) [comedy, romance]</p>
</li>
<li>
<p>The Break-Up, dir. P. Reed, USA (2006) [comedy, drama, romance]</p>
</li>
<li>
<p>The Devil Wears Prada, dir. D. Frankel, USA, France (2006) [comedy, drama]</p>
</li>
<li>
<p>P.S. I Love You, dir. R. LaGravenese, USA (2007) [drama, romance]</p>
</li>
<li>
<p>Enchanted, dir. K. Lima, USA (2007) [animation, comedy, family]</p>
</li>
<li>
<p>Music and Lyrics, dir. M. Lawrence, USA (2007) [comedy, music, romance]</p>
</li>
<li>
<p>Mamma Mia!, dir. Ph. Lloyd, USA, UK, Germany (2007) [comedy, musical, romance]</p>
</li>
<li>
<p>Definitely, Maybe, dir. A. Brooks, USA (2008) [comedy, drama, romance]</p>
</li>
<li>
<p>Made of Honor, dir. P. Weiland, USA, UK (2008) [comedy, romance]</p>
</li>
<li>
<p>27 Dresses, dir. A. Fletcher, USA (2008) [comedy, romance]</p>
</li>
<li>
<p>Sex and the City, dir. M. P. King, USA (2008) [comedy, drama, romance]</p>
</li>
<li>
<p>The Sisterhood of the Traveling ants 2, dir. S. Hamri, USA (2008) [comedy, drama, romance]</p>
</li>
<li>
<p>The Time Traveler’s Wife, dir. R. Schwentke, USA (2008) [drama, fantasy, romance]</p>
</li>
<li>
<p>Bride Wars, dir. G. Winick, USA (2009) [comedy, romance]</p>
</li>
<li>
<p>He’s Just Not That Into You, dir. K. Kwapis, Germany, USA (2009) [comedy, drama, romance]</p>
</li>
<li>
<p>The Proposal, dir. A. Fletcher, USA (2009) [comedy, drama, romance]</p>
</li>
<li>
<p>Couples Retreat, dir. P. Billingsley, USA (2009) [comedy]</p>
</li>
<li>
<p>Julie and Julia, dir. N. Ephron, USA (2009) [biography, drama, romance]</p>
</li>
<li>
<p>The Ugly Truth, dir. R. Luketic, USA (2009) [comedy, romance]</p>
</li>
<li>
<p>Labor Pains, dir. L. Shapiro, USA (2009) [comedy, romance]</p>
</li>
<li>
<p>Valentine’s Day, dir. G. Marshall, USA (2009) [comedy romance]</p>
</li>
<li>
<p>The Switch, dir. J. Gordon, W. Speck, USA (2010) [comedy, drama, romance]</p>
</li>
<li>
<p>Letters to Juliet, dir. G. Winnick, USA (2010) [adventure, comedy, drama]</p>
</li>
<li>
<p>Dear John, dir. L. Hallström, USA (2010) [drama, romance, war]</p>
</li>
<li>
<p>The Back-Up Plan, dir. A. Poul, USA (2010) [comedy, romance]</p>
</li>
<li>
<p>Sex in the City, dir. M. P. King, USA (2010) [comedy, drama, romance]</p>
</li>
<li>
<p>Easy A, dir. W. Gluck, USA (2010) [comedy, drama, romance]</p>
</li>
<li>
<p>Something Borrowed, dir. L. Greenfield, USA [comedy, drama, romance]</p>
</li>
<li>
<p>Love, Wedding, Marriage, dir. D. Mulroney, USA (2011) [comedy]</p>
</li>
<li>
<p>Bridesmaids, dir. P. Feig, USA (2011) [comedy, romance]</p>
</li>
<li>
<p>Crazy, Stupid Love, dir. G. Ficarra, J. Requa, USA (2011) [comedy, drama, romance]</p>
</li>
<li>
<p>What to Expect When You’re Expecting, dir. K. Jones, USA (2012) [comedy, drama, romance]</p>
</li>
<li>
<p>Pitch Perfect, dir. J. Moore, USA (2012) [comedy, music, romance]</p>
</li>
<li>
<p>Safe Have, dir. L. Hallström, USA (2012) [drama, romance, thriller]</p>
</li>
<li>
<p>About Time, dir. R. Curtis, UK (2013) [comedy, drama, fantasy]</p>
</li>
<li>
<p>The Other Woman, dir. N. Cassavetes, USA (2014) [comedy, romance]</p>
</li>
<li>
<p>The Single Moms Club, dir. T. Perry, USA (2014) [comedy, drama]</p>
</li>
<li>
<p>Lila and Eve, dir. Ch. Stone III, USA (2015) [crime, drama, mystery]</p>
</li>
<li>
<p>How to Be Single, dir. Ch. Ditter, USA (2016) [comedy, drama, romance]</p>
</li>
<li>
<p>Home Again, dir. H. Meyers-Shyer, USa (2017) [comedy, drama, romance]</p>
</li>
<li>
<p>Crazy Rich Indians, dir. J. M. Chu, USA (2018) [comedy, romance]</p>
</li>
<li>
<p>Book Club, dir. B. Holderman, USA (2018) [comedy, drama, romance]</p>
</li>
<li></li>
</ul>
<h1 id="romance">Romance</h1>
<ul>
<li>
<p>It happened One Night, dir. F. Capra, USA (1934) [comedy, romance]</p>
</li>
<li>
<p>The Last of the Mohicans, dir. G. B. Seitz, USA (1936) [adventure, drama, history]</p>
</li>
<li>
<p>A Star is Born, dir. W. W. Wellman, J. Conway, USA (1937) [drama]</p>
</li>
<li>
<p>Gone with the Wind, dir. V. Flemming, G. Cukor, USA (1939) [drama, history, romance]</p>
</li>
<li>
<p>Rebecca, dir. A. Hitchcock, USA (1940) [drama, mystery, romance]</p>
</li>
<li>
<p>Casablanca, dir. M. Curtiz, USA (1942) [drama, romance, war]</p>
</li>
<li>
<p>Brief Encounter, dir. D. Lean, USA (1945) [drama, romance]</p>
</li>
<li>
<p>The Best Years of Our Lives, dir. W. Wyler, USA (1946) [drama, romance, war]</p>
</li>
<li>
<p>Out of the Past, dir. J. Tourneur, USA (1947) [crime, drama, film-noir]</p>
</li>
<li>
<p>Singin’ in the Rain, dir. S. Donen, G. Kelly, USA (1952) [comedy, musical, romance]</p>
</li>
<li>
<p>Roman Holiday, dir. W. Wyler, USA (1953) [comedy, romance]</p>
</li>
<li>
<p>A Star is Born, dir. G. Cukor, USA (1954) [drama, musical, romance]</p>
</li>
<li>
<p>Vertigo, dir. A. Hitchcock, USA (1958) [mystery, romance, thriller]</p>
</li>
<li>
<p>Some Like It Hot, dir. B. Wilder, USA (1959) [comedy, romance]</p>
</li>
<li>
<p>The Apartment, dir. B. Wilder, USA (1960) [comedy, drama, romance]</p>
</li>
<li>
<p>Charade, dir. S. Donen, USA (1963) [comedy, mystery, romance]</p>
</li>
<li>
<p>Doctor Zhivago, dir. D. Lean, USA, Italy, UK (1965) [drama, romance, war]</p>
</li>
<li>
<p>Sounds of Music, dir. R. Wise, USA (1965) [biography, drama, family]</p>
</li>
<li>
<p>The Gradate, dir. M. Nichols, USA (1967) [comedy, drama, romance]</p>
</li>
<li>
<p>Fiddler on the Roof, dir. N. Jewison, USA (1971) [drama, family, musical]</p>
</li>
<li>
<p>Harold and Maude, dir. H. Ashby, USA (1971) [comedy, drama, romance]</p>
</li>
<li>
<p>A Star is Born, dir. F. Pierson (1976) [drama, music, romance]</p>
</li>
<li>
<p>Annie Hall, dir. W. Allen, USA (1977) [comedy, romance]</p>
</li>
<li>
<p>Manhattan, dir. W. Allen, USA (1979) [comedy, drama, romance]</p>
</li>
<li>
<p>Out of Africa, dir. S. Pollack, USA, UK (1985) [biography, drama, romance]</p>
</li>
<li>
<p>The Princess Bride, dir. R. Reiner, USA (1987) [adventure, family, fantasy]</p>
</li>
<li>
<p>The Last of the Mohicans, dir. M. Mann, USA (1992) [action, adventure, drama]</p>
</li>
<li>
<p>Groundhog Day, dir. H. Ramis, USA (1993) [comedy, fantasy, romance]</p>
</li>
<li>
<p>Forrest Gump, dir. R. Zemeckis, USA (1994) [drama, romance]</p>
</li>
<li>
<p>Legends of the Fall, dir. E. Zwick, USA (1994) [drama, romance, war]</p>
</li>
<li>
<p>Before Sunrise, dir. R. Linklater, USA (1995) [drama, romance]</p>
</li>
<li>
<p>Good Will Hunting, dir. G. Van Sant, USA (1997) [drama, romance]</p>
</li>
<li>
<p>The English Patient, dir. A. Minghella, USA, UK (1997) [drama, romance, war]</p>
</li>
<li>
<p>The Horse Whisperer, dir. R. Redford, USA (1998) [drama, romance, western]</p>
</li>
<li>
<p>Big Fish, dir. T. Burton, USA (2003) [adventure, drama, fantasy]</p>
</li>
<li>
<p>Before Sunset, dir. R. Linklater (2004), USA [drama, romance]</p>
</li>
<li>
<p>Eternal Sunshine of the Spotless Mind, dir. M. Gondry, USA (2004) [drama, romance, sci-fi]</p>
</li>
<li>
<p>Once, dir. J. Carney, Ireland (2007) [drama, music, romance]</p>
</li>
<li>
<p>Slumdog Millionaire, dir. D. Boyle, L. Tandan, UK, USA, France, Germany, India (2008) [drama, romance]</p>
</li>
<li>
<p>Mr Nobody, dir. J. Van Dormael, USA (2009) [drama, fantasy, romance]</p>
</li>
<li>
<p>The Perks of Being a Wallflower, dir. S. Chbosky, USA (2012) [drama, romance]</p>
</li>
<li>
<p>Before Midnight, dir. R. Linklater, USA (2013) [drama, romance]</p>
</li>
<li>
<p>Her, dir. S. Jonze, USA (2013) [drama, romance, sci-fi]</p>
</li>
<li>
<p>Sing Street, dir. J. Carney, Ireland, UK, USA (2016) [comedy, drama, music]</p>
</li>
<li>
<p>La La Land, dir. D. Chazelle, USA, Hing Kong (2016) [comedy, drama, music]</p>
</li>
<li>
<p>A Star is Born, dir. B. Cooper, USA (2018) [drama, music, romance]</p>
</li>
<li></li>
</ul>
<h1 id="superhero">Superhero</h1>
<ul>
<li>
<p>Superman, dir. R. Donner, USA, UK, Switzerland, Canada, Panama (1978) [action, adventure, drama]</p>
</li>
<li>
<p>Superman II, dir. R. Lester, R. Donner, USA, UK, Canada (1980) [action, adventure, sci-fi]</p>
</li>
<li>
<p>Superman III, dir. R. Lester, UK, USA (1983) [action, comedy, sci-fi]</p>
</li>
<li>
<p>Batman, dir. T. Burton, USA (1989) [action, adventure]</p>
</li>
<li>
<p>Batman Returns, dir. T. Burton, USA (1992) [action, crime, fantasy]</p>
</li>
<li>
<p>Batman Forever, dir. J. Schumacher, USA (1995) [action, adventure, fantasy]</p>
</li>
<li>
<p>Batman and Robin, dir. J. Schumacher, USA, UK (1997) [action, sci-fi]</p>
</li>
<li>
<p>Spider-Man, dir. S. Raimi, USA (2002) [action, adventure, sci-fi]</p>
</li>
<li>
<p>Spider-Man 2, dir. S. Raimi, USA (2004) [action, adventure, sci-fi]</p>
</li>
<li>
<p>Batman Begins, dir. Ch. Nolan, USA (2005) [action, adventure, thriller]</p>
</li>
<li>
<p>V for Vendetta, dir. J. McTeigue, USA (2005) [action, drama, sci-fi]</p>
</li>
<li>
<p>Superman Returns, dir. B. Singer, USA (2006) [action, adventure]</p>
</li>
<li>
<p>Spider-Man 3, dir. S. Raimi, USA (2007) [action, adventure, sci-fi]</p>
</li>
<li>
<p>The Dark Knight, dir. Ch. Nolan, USA (2008) action, crime, drama]</p>
</li>
<li>
<p>Iron Man, dir. J. Favreau, USA (2008) [action, adventure, sci-fi]</p>
</li>
<li>
<p>Thor, dir. K. Branagh, USA (2011) [action, adventure, fantasy]</p>
</li>
<li>
<p>The Amazing Spider-Man, dir. M. Webb, USA (2012) [action, adventure, fantasy]</p>
</li>
<li>
<p>The Avengers, dir. J. Whedon, USA (2012) [action, adventure, sci-fi]</p>
</li>
<li>
<p>The Dark Knight Rises, dir. Ch. Nolan, USA (2012) [action, thriller]</p>
</li>
<li>
<p>Thor: The Dark World, dir. A. Taylor, USA (2013) [action, adventure, fantasy]</p>
</li>
<li>
<p>The Amazing Spider-Man 2, dir. M. Webb, USA (2014) [action, adventure, sci-fi]</p>
</li>
<li>
<p>The Avengers: Age of Ultron, dir. J. Whedon, USA (2015) [action, adventure, sci-fi]</p>
</li>
<li>
<p>Deadpool, dir. T. Miller, USA (2016) [action, adventure, comedy]</p>
</li>
<li>
<p>Doctor Strange, dir. S. Derrickson, USA (2016) [action, adventure, fantasy]</p>
</li>
<li>
<p>Logan: Wolverine, dir. J. Manglod, USA (2017) [action, drama, sci-fi]</p>
</li>
<li>
<p>Thor: Ragnarok, dir. T. Waititi, USA (2017) [action, adventure, comedy]</p>
</li>
<li>
<p>The Avengers: Infinity War, dir. A. Russo, J. Russo, USA (2018) [action, adventure, fantasy]</p>
</li>
<li></li>
</ul>
<h1 id="thriller">Thriller</h1>
<ul>
<li>The Third Man, dir. C. Reed, UK (1949) [film-noir, mystery, thriller]</li>
<li>Dial M for Murder, dir. A. Hitchcock, USA (1954) [crime, thriller]</li>
<li>Double Indemnity, dir. B. Wilder, USA (1954) [crime, drama, film-noir]</li>
<li>On the Waterfront, dir. E. Kazan, USA (1954) [crime, drama, thriller]</li>
<li>Rear Window, dir. A. Hitchcock, USA (1954) [mystery, thriller]</li>
<li>North by Nothwest, dir. A. Hitchcock, USA (1959) [adventure, mystery, thriller]</li>
<li>Psycho, dir. A. Hitchcock, USA (1960) [horror, mystery, thriller]</li>
<li>What Ever Happened to Baby Jane?, dir. R. Aldrich, USA (1962) [drama, horror, thriller]</li>
<li>Chinatown, dir. R. Polanski, USA (1974) [drama, mystery, thriller]</li>
<li>Blade Runner, dir. R. Scott, USA, Hong Kong (1982) [sci-fi, thriller]</li>
<li>Die Hard, dir. J. McTiernan, USA (1988) [action, thriller]</li>
<li>Silence of the Lambs, dir. J. Demme, USA (1991) [crime, drama, thriller]</li>
<li>Reservoir Dogs, dir. Q. Tarantino, USA (1992) [crime, drama, thriller]</li>
<li>Léon, dir. L. Besson, France, USA (1994) [crime, drama, thriller]</li>
<li>The Heat, dir. M. Mann, USA (1995) [crime, drama, thriller]</li>
<li>Pulp Fiction, dir. Q. Tarantino, USA (1994) [crime, drama]</li>
<li>The Usual Suspects, dir. B. Singer USA, Germany (1995) [crime, mystery, thriller]</li>
<li>Fargo, dir. J. and E. Coen, USA (1996) [crime, drama, thriller]</li>
<li>L.A. Confidential, dir. C. Hanson, USA (1997) [crime, drama, mystery]</li>
<li>Seven, dir. D. Fincher, USA (1997) [crime, drama, mystery]</li>
<li>The Sixth Sense, dir. M. Night Shyamalan, USA (1999) [drama, mystery, thriller]</li>
<li>Memento, dir. Ch. Nolan, USA (2000) [mystery, thriller]</li>
<li>Donnie Darko, dir. R. Kelly, USA (2001) [drama, sci-fi, thriller]</li>
<li>Mulholland Drive, dir. D. Lynch, USA (2001) [drama, mystery, thriller]</li>
<li>Kill Bill dir. Q. Tarantino, USA (2003) [action, crime, thriller]</li>
<li>The Departed, dir. M. Scorsese, USA (2006) [crime, drama, thriller]</li>
<li>The Prestige, dir. Ch. Nolan, USA, Hong Kong (2006) [drama, mystery, sci-fi]</li>
<li>No Country for Old Men, dir. A. and J. Coen, USA (2007) [crime, drama, thriller]</li>
<li>Shutter Island, dir. M. Scorsese, USA (2010) [mystery, thriller]</li>
<li>Prisoners, dir. D. Villeneuve, USA (2013) [crime, drama, mystery]</li>
<li>Gone Girl, dir. D. Fincher, USA (2014) [crime, drama, mystery]</li>
<li>Room, dir. L. Abrahamson, USA (2015) [drama, thriller]</li>
<li>Vampire</li>
<li>Dr Terror’s House of Horrors, dir. F. Francis, UK (1965) [horror]</li>
<li>Lust for a Vampire, dir. J. Sangster, UK (1971) [horror]</li>
<li>Dracula, dir. F. Ford Coppola, USA (1992) [horror]</li>
<li>Interview with the Vampire: The Vampire Chronicles, dir. N. Jordan, USA (1994) [drama, horror]</li>
<li>From Dusk till Dawn, dir. R. Rodriguez, USA (1996) [action, crime, horror]</li>
<li>Blade, dir. S. Norrington, USA (1998) [action, horror, sci-fi]</li>
<li>Underworld, dir. L. Wiseman, USA, UK, Germany, Hungary (2003) [action, fantasy, thriller]</li>
<li>Van Helsing, dir. S. Sommers, USA, Czech Republic (2004) [action, adventure, fantasy]</li>
<li>Twilight, dir. C. Hardwicke, USA (2008) [drama, fantasy, romance]</li>
<li>Jennifer’s Body, dir. K. Kusama, USA (2009) [comedy, horror]</li>
<li>The Twilight Saga: New Moon, sir. Ch. Weitz, USA (2009) [adventure, drama, fantasy]</li>
<li>The Twilight Saga: Eclipse, dir. D. Slade, USA (2010) [adventure, drama, fantasy]</li>
<li>The Twilight Saga: Breaking Dawn Part 1, dir. B. Condon, USA (2011) [adventure, drama, fantasy]</li>
<li>The Twilight Saga: Breaking Dawn Part 2, dir. B. Condon, USA (2012) [adventure, drama, fantasy]</li>
<li>Dark Shadows, dir. T. Burton, USA, Australia (2012) [comedy, fantasy, horror]</li>
<li>The Mortal Instruments: City of Bones, dir. H. Zwart, USA, Germany, Canada, UK (2013) [action, fantasy, horror]</li>
<li>Vampire Academy, dir. M. Waters, USA, UK (2014) [action, comedy, drama]</li>
<li>Goosebumps, R. Letterman, USA, Australia (2016) [adventure, comedy, family]</li>
</ul>
<ul>
<li id="acerbi2013">Acerbi A, Lampos V., Garnett P., and Bentley A. R. “The Expression of Emotions in 20th Century Books” , _PLoS ONE_ 8(3) (2013): e59030, doi: 10.1371/journal.pone.0059030.
</li>
<li id="altman1999">Altman, R. _Film/Genre_ . British Film Institute, London (1999).
</li>
<li id="banos-pinero2013">Baños-Piñero, R., Bruti, S. and Zanotti, S (eds) _Perspectives: Studies in Translatology. Special Issue: Corpus Linguistics and Audiovisual Translation: In Search of an Integrated Approach_ , 21(4) (2013).
</li>
<li id="bastian2009">Bastian, M., Heymann, S. and Jacomy, M. “Gephi: An Open Source Software for Exploring and Manipulating Networks” , _Proceedings of the International AAAI Conference on Weblogs and Social Media_ , San Jose, Ca (2009).
</li>
<li id="bateman2016">Bateman, J. A., Tseng, Chiao-I., Seizov, O., Jacobs, A., Lüdtke, A., Müller, M. G. and Herzog, O. “Towards Next-generation Visual Archives: Image, Film and Discourse” , _Visual Studies_ 31 (2016); pp. 131-154.
</li>
<li id="baxter2014a">Baxter, M. “Cinemetric Data Analysis” (2014),<a href="http://www.cinemetrics.lv/dev/Cinemetrics_Book_Baxter.pdf">http://www.cinemetrics.lv/dev/Cinemetrics_Book_Baxter.pdf</a>.
</li>
<li id="baxter2014b">Baxter, M. “Quantitative Film Studies [a bibliography]” (2014),<a href="http://www.cinemetrics.lv/dev/bibliography_with_essay_Baxter.pdf">http://www.cinemetrics.lv/dev/bibliography_with_essay_Baxter.pdf</a>.
</li>
<li id="bednarek2010">Bednarek, M. _The Language of Fictional Television. Drama and Identity_ , Continuum, London – New York (2010).
</li>
<li id="bednarek2011">Bednarek, M. “The Stability of the Televisual Character: A Corpus Stylistic Case Study” . In R. Piazza, M. Bednarek and F. Rossi F. (eds), _Telecinematic Discourse_ . Approaches to the Language of Films and Television Series, John Benjamins, Amsterdam – Philadelphia (2011), pp.185–204.
</li>
<li id="bednarej2017">Bednarek and M., Zago, R. “Bibliography of Linguistic Research on Fictional (Narrative, Scripted) Television Series and Films/Movie, Version 1” (2017),<a href="http://unipv.academia.edu/RaffaeleZago">http://unipv.academia.edu/RaffaeleZago</a>
</li>
<li id="bednarek2018">Bednarek, M. _Language and Television Series: A Linguistic Approach to Television Dialogue_ . Cambridge University Press, Cambridge (2018).
</li>
<li id="bondebjerg2015">Bondebjerg, I. “Film: Genres and Genre Theory” . In J. D. Wright (ed.), _International Encyclopedia of the Social and Behavioral Sciences_ , 2nd edition, Vol 9, Oxford (2015), pp. 160–164.
</li>
<li id="bobrowski2015">Bobrowski, J. “Płaszczyzny stylizacji językowej w dialogu filmowym” , _Polonica_ , 35 (2015): 179–189.<a href="http://dx.doi.org./10.17651/POLON.35.14">http://dx.doi.org./10.17651/POLON.35.14</a>.
</li>
<li id="burrows2002">Burrows, J. “The Englishing of Juvenal: Computational Stylistics and Translated Texts” , _Style_ 36 (4) (2002): 677-698.
</li>
<li id="burrows1987">Burrows, J. _Computation into Criticism: A Study of Jane Austen's Novels and an Experiment in Method_ , Clarendon, Oxford (1987).
</li>
<li id="burrows1994">Burrows, J. “Tiptoeing into the Infinite: Testing for Evidence of National Differences in the Language of English Narrative” , _Research in Humanities Computing_ 2 (1994): pp 1-33.
</li>
<li id="byszuk2017">Byszuk, J. _The Voices of Doctor Who_ 2017.<a href="https://ruj.uj.edu.pl/xmlui/handle/item/222426">https://ruj.uj.edu.pl/xmlui/handle/item/222426</a>
</li>
<li id="chandler1997">Chandler, D. _An Introduction to Genre Theory_ (1997),<a href="http://www.aber.ac.uk/media/Documents/intgenre/chandler_genre_theory.pdf">http://www.aber.ac.uk/media/Documents/intgenre/chandler_genre_theory.pdf</a>.
</li>
<li id="craig2009">Craig, H. and Kinney, A. “Shakespeare, Computers, and the Mystery of Authorship” , Cambridge University Press, Cambridge (2009).
</li>
<li id="cutting2011">Cutting, J. E., Brunick, K. L., DeLong, J. E. and Iricinschi, C. “Quicker, Faster, Darker: Changes in Hollywood Film over 75 Years” , _i-Perception_ 2 (2011): pp 569-576.
</li>
<li id="choinski2019">Choiński, M., Eder, M. and Rybicki, J.  “Harper Lee and Other People: A Stylometric Diagnosis” ,  _Mississippi Quarterly_ , 70(3): 355-374.
</li>
<li id="eder2016">Eder, M., Rybicki and J., Kestemont, M. “Stylometry with R: A Package for Computational Text Analysis” , _R Journal_ 8 (1) (2016): 107-121.
</li>
<li id="eder2017">Eder, M. “Visualization in Stylometry: Cluster Analysis Using Networks” , _Digital Scholarship in the Humanities_ 32 (1) (2017): 50-64
</li>
<li id="evert2017">Evert, S., Proisl, T., Jannidis, F., Reger, I., Pielström, S., Schöch, C. and Vitt, T. “Understanding and Explaining Delta Measures for Authorship Attribution” , _Digital Scholarship in the Humanities_ 32 (sup. 2) (2017): 4-16.
</li>
<li id="freddi2013">Freddi M. “Constructing a Corpus of Translated Films: A Corpus View of Dubbing” , _Perspectives: Studies in Translatology_ , 21 (4) (2013): 491–503. DOI: 10.1080/0907676X.2013.831925.
</li>
<li id="freddi2009">Freddi M. and Pavesi M. “The Pavia Corpus of Film Dialogue: Methodology and Research Rationale” . In M. Freddi, M. Pavesi (eds), _Analysing Audiovisual Dialogue: Linguistic and Translational Insights_ , Clueb, Bologna (2009), pp. 95–100.
</li>
<li id="freedman2015">Freedman, J. _The Cambridge Companion to Alfred Hitchcock_ , Cambridge University Press, Cambridge, 2015.
</li>
<li id="grant2003">Grant, B.K. (ed.). _Film Genre Reader_ . University of Texas Press, Austin ([1984] 2003).
</li>
<li id="heiss2005">Heiss, Ch. and Soffritti, M. “Parallelkorpora gesprochener Sprache aus Filmdialogen? Ein multimedialer Ansatz für das Sprachenpaar Deutsch-Italienisch” . In J. Schwitalla, E. Wegstein (eds) _Korpus Linguistik Deutsch – synchron, diachron, kontrastiv_ , Niemeyer, Tübingen (2005): 207-217.
</li>
<li id="heftberger2018">Heftberger, A. _Digital Humanities and Film Studies_ , Springer, Berlin (2018).
</li>
<li id="hendrykowski1999">Hendrykowski, M. _Język ruchomych obrazów_ , Ars Nova, Poznań (1999).
</li>
<li id="hermann2015">Herrmann, J. B., van Dalen-Oskam, K. and Schoech C. “Revisiting Style, a Key Concept in Literary Studies” , _Journal of Literary Theory_ 9 (1) (2015): 25-52.
</li>
<li id="hayles2010">Hayles, K. N. “How We Read: Close, Hyper, Machine” , _ADE Bulletin_ , 150, (2010): 62-79.
</li>
<li id="holobut2016">Hołobut, A., Rybicki, J. and Woźniak, M. “Stylometry on the Silver Screen: Authorial and Translatorial Signals in Film Dialogue” , Digital Humanities 2016: Conference Abstracts, Jagiellonian University and Pedagogical University, Krakow (2016): pp. 561–565.
</li>
<li id="holobut2017a">Hołobut, A., Rybicki, J. and Woźniak, M. “Old Questions, New Answers: Computational Stylistics in Audiovisual Translation Research” . In M. Deckert (ed), _Audiovisual Translation: Research and Use_ , Peter Lang, Frankfurt (2017): pp. 203-216.
</li>
<li id="holobut2017b">Hołobut, A. and Woźniak, M. _Historia na ekranie: Gatunek filmowy a przekład audiowizualny_ , Wydawnictwo UJ, Kraków.
</li>
<li id="holobut2018">Hołobut, A. and Rybicki, J. “Pride and Prejudice and Programming: A Stylometric Analysis” . In L. Raw (ed), _Adapted from the Original: Essays on the Value and Values of Works Remade for a New Medium_ , McFarland, Jefferson (2018): pp. 134-147.
</li>
<li id="hoover2007">Hoover, D. “Corpus Stylistics, Stylometry, and the Styles of Henry James” , _Style_ 41(2) (2007): 174-203.
</li>
<li id="hough1969">Hough, G. _Style and Stylistics_ , Routledge & Kegan Press, London (1969).
</li>
<li id="jaeckle2013">L. Jaeckle (ed), _Film Dialogue_ , Wallflower Press, London – New York (2013).
</li>
<li id="jockers2016">Jockers, M. L. “Syuzhet: Extracts Sentiment and Sentiment-Derived Plot Arcs from Text” (2016) _,_ <a href="https://cran.r-project.org/web/packages/syuzhet/index.htm">https://cran.r-project.org/web/packages/syuzhet/index.htm</a>.
</li>
<li id="jockers2017">Jockers, M. L. “Resurrecting a Low Pass Filter (well, kind of)” , Matthew L. Jockers Blog (2017),<a href="http://www.matthewjockers.net/2017/01/12/resurrecting/">http://www.matthewjockers.net/2017/01/12/resurrecting/</a>
</li>
<li id="juola2015">Juola, P. “The Rowling Case: A Proposed Standard Analytic Protocol for Authorship Questions” , _Digital Scholarship the Humanities_ 30 (supp. 1): 100-113.
</li>
<li id="kozloff2000">Kozloff, S. _Overhearing Film Dialogue_ , University of California Press, Berkeley (2000).
</li>
<li id="mckenna1999">McKenna, W., Burrows, J. and Antonia, A. “Beckett’s Trilogy: Computational Stylistics and the Nature of Translation” , _Revue Informatique et Statistique dans les Sciences humaine_ s 35 (1999): 151-171.
</li>
<li id="mckie2014">McKie, S. _Screenwriting 2.0: What Are the Possibilities of Screenplay Datafication ? How the Screenplay as Sata Can Impact Creating and Managing, Presenting and Sharing, Analyzing and Visualizing Textual Screenplay Content_ , PhD thesis, Royal Holloway College, London (2014).
</li>
<li id="mealand1999">Mealand, D. “Style, Genre, and Authorship in Acts, the Septuagint, and Hellenistic Historians” , _Literary and Linguistic Computing_ 14 (4) (1999): 479-506.
</li>
<li id="milawska-ratajczak2019">Miławska-Ratajczak, M. _Dialog w roli głównej. Polszczyzna we współczesnym kinie na przykładzie wybranych utworów_ , Universitas, Kraków (2019).
</li>
<li id="mohammad2011">Mohammad, S. “From Once Upon a Time to Happily Ever After: Tracking Emotions in Novels and Fairy Tales” , _Proceedings of the ACL 2011 Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities_ (LaTeCH), Portland, OR, June 2011.
</li>
<li id="mohammad2010">Mohammad, S., and Turney P. “Emotions Evoked by Common Words and Phrases: Using Mechanical Turk to Create an Emotion Lexicon” , _Proceedings of the NAACL-HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text_ , Los Angeles, June 2010.
</li>
<li id="moretti2007">Moretti, F. _Graphs, Maps, Trees: Abstract Models for Literary History_ , Verso, London, New York (2007).
</li>
<li id="mosteller1964">Mosteller, F. and Wallace, D. “Inference and Disputed Authorship: The Federalist” , Addison-Wesley, Reading (1964).
</li>
<li id="murtagh2009">Murtagh, F, Ganz, A. and McKie, S. “The Structure of Narrative: The Case of Film Scripts” , _Pattern Recognition_ , 42 (2009): 302 –312.
</li>
<li id="piazza2011">Piazza, R. _The Discourse of Italian Cinema and Beyond: Let Cinema Speak_ , Continuum, London–New York (2011).
</li>
<li id="piazza2011a">Piazza, R., Bednarek, M. and Rossi, F. (eds). _Telecinematic Discourse: Approaches to the Language of Films and Television Series_ , John Benjamins, Amsterdam–Philadelphia (2011).
</li>
<li id="pitera1979">Pitera, Z. _Miłe kina początki_ . Wydawnictwa Artystyczne i Filmowe, Warszawa (1979).
</li>
<li id="plutchik1980">Plutchik, R. “A General Psychoevolutionary Theory of Emotion” . In R. Plutchik and H. Kellerman (eds), _Emotion: Theory, Research, and Experience: Vol. 1. Theories of Emotion_ , Academic, New York (1980), pp. 3-33.
</li>
<li id="plutchik1991">Plutchik, R. “The Emotions” . University Press of America (1991).
</li>
<li id="quaglio2009">Quaglio, P. _Television Dialogue: The Sitcom Friends vs Natural Conversation_ , John Benjamins, Amsterdam–Philadelphia (2009).
</li>
<li id="rcore2014">R Core Team. _R: A Language and Environment for Statistical Computing_ , R Foundation for Statistical Computing, Wien (2014),<a href="http://www.R-project.org/">http://www.R-project.org/</a>.
</li>
<li id="richardson2010">Richardson, K. _Television Dramatic Discourse: A Sociolinguistic Study_ , Oxford University Press, Oxford (2010).
</li>
<li id="romerofresco2009">Romero Fresco, P. “Naturalness in the Spanish Dubbing Language: A Case of Not-so-close Friends” , _Meta_ 54(1) (2009): 49–72. doi:10.7202/029793ar
</li>
<li id="rudman2016">Rudman, J. “Non-Traditional Authorship Attribution Studies of William Shakespeare’s Canon: Some Caveats” , _Biblioteca di Studi di Filologia Moderna: Collana_ , Riviste e Laboratorio (2016).
</li>
<li id="rybicki2012">Rybicki, J. “The Great Mystery of the (Almost) Invisible Translator: Stylometry in Translation” . In M. Oakes, M. Ji, _Quantitative Methods in Corpus-Based Translation Studies_ , John Benjamins, Amsterdam (2012), 231-248.
</li>
<li id="rybicki2017a">Rybicki, J. “A Second Glance at a Stylometric Map of Polish Literature” , _Forum of Poetics_ 10 (2017): pp. 6-21.
</li>
<li id="rybicki2017b">Rybicki, J. “Reading Novels with Statistics: What Numbers of Words Tell Us about Authorship, Genre, or Chronology” . In J.A. Dobelman (ed), _Models and Reality: Festschrift For James Robert Thompson_ , T&NO Company, Chicago (2017), pp. 207-224.
</li>
<li id="rybicki2018">Rybicki, J. “Sentiment Analysis Across Three Centuries of the English Novel: Towards Negative or Positive Emotions?” EADH Conference Abstracts, Galway (2018).
</li>
<li id="rybicki2011">Rybicki, J.and Eder, M. “Deeper Delta Across Genres and Languages: Do We Really Need the Most Frequent Words?” , _Literary and Linguistic Computing_ 26 (3) (2011): 315-332.
</li>
<li id="rybicki2013">Rybicki, J. and Heydel, M. “The Stylistics and Stylometry of Collaborative Translation: Woolf's Night and Day in Polish” , _Literary and Linguistic Computing_ 28 (4) (2013): 708-717.
</li>
<li id="schmid1994">Schmid, H. “Probabilistic Part-of-Speech Tagging Using Decision Trees” . _Proceedings of International Conference on New Methods in Language Processing_ , Manchester, UK, 1994.
</li>
<li id="salt2007">Salt, B. _Moving into Pictures: More on Film History, Style, and Analysis_ , Starword, London (2007).
</li>
<li id="schmidt2012">Schmidt, B. “Making Downton More Traditional” (2012),<a href="http://www.prochronism.com/2012/04/making-downton-more-traditional.html">http://www.prochronism. com/2012/04/making-downton-more-traditional.html</a>.
</li>
<li id="smith2011">Smith, P. and Aldridge, W. “Improving Authorship Attribution: Optimizing Burrows’ Delta Method” , _Journal of Quantitative Linguistics_ , 18(1) (2011): 63–88.
</li>
<li id="stone1966">Stone, P. J., Dunphy, D.C., and Smith, M. S. _The General Inquirer: A Computer Approach to Content Analysis_ , MIT Press, Cambridge, MA (1966).
</li>
<li id="suchan2016">Suchan, J. and Bhatt, M. “The Geometry of a Scene: On Deep Semantics for Visual Perception Driven Cognitive Film Studies” , _2016 IEEE Winter Conference on Applications of Computer Vision (WACV)_ , Lake Placid, NY (2016), pp. 1-9.
</li>
<li id="swafford2015">Swafford, A. “Problems with the Syuzhet Package” , Anglophile in Academia: Annie Swafford’s Blog (2015),<a href="https://annieswafford.wordpress.com/2015/03/02/syuzhet/">https://annieswafford.wordpress.com/2015/03/02/syuzhet/</a>
</li>
<li id="tuzzi2018">Tuzzi, A. and Cortelazzo, M. (eds), _Drawing Elena Ferrante’s Profile_ , Padova University Press, Padova (2018).
</li>
<li id="valentini2008">Valentini, C. “Forlixt1: The Forli Corpus of Screen Translation: Exploring Macrostructures” . In D. Chiaro, D. Heiss, Ch. Bucaria (eds), _Between Text and Image: Updating Research in Screen Translation_ , John Benjamins, Amsterdam–Philadelphia (2008), pp. 37–51.
</li>
<li id="valentini2009">Valetini, C. and Linardi S. “Forlixt 1: A Multimedia Database for AVT Research” , _inTRAlinea_ , Special Issue: The Translation of Dialects in Multimedia (2009),<a href="http://www.intralinea.org/specials/article/Forlixt_1_A_multimedia_database_for_AVT_research">http://www.intralinea.org/specials/article/Forlixt_1_A_multimedia_database_for_AVT_research</a>.
</li>
<li id="vanzyl2016">Van Zyl, M. And Botha Y. “Stylometry and Characterisation in _The Big Bang Theory_ ” , _Literator_ , 37 (2), a1282 (2016),<a href="http://dx.doi.org/10.4102/lit.v37i2.1282">http://dx.doi.org/10.4102/lit.v37i2.1282</a>.
</li>
<li id="verianopinto2014">Veirano Pinto M. “Dimensions of Variation in North American Movies” . In T. Berber Sardinha, M. Veirano Pinto (eds), _Multi-Dimensional Analysis, 25 Years On: A Tribute to Douglas Biber_ , John Benjamins, Amsterdam–Philadelphia (2014), pp. 109–147.
</li>
<li id="vickers2002">Vickers, B. _ Counterfeiting Shakespeare: Evidence, Authorship, and John Ford's Funerall Elegye_ , Cambridge University Press, Cambridge (2002).
</li>
<li id="vickers2011">Vickers, B. _Authorship Attribution Studies and Shakespeare's Canon (A Review of Shakespeare, Computers, and the Mystery of Authorship_ , _Shakespeare Quarterly_ 62 (1) (2011): 106-142.
</li>
<li id="zago2016">Zago, R. _From Originals to Remakes. Colloquiality in English Film Dialogue Over Time_ , Bonanno Editore, Acireale/Roma (2016).
</li>
<li id="zago2018">Zago, R. _Cross-Linguistic Affinities in Film Dialogue_ , Sike, Roma (2018).
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>For an overview of corpus research into audiovisual translation, see<a href="#banos-pinero2013">Baños-Piñero 2013</a>. For an overview of research into scripted speech, see<a href="#bednarek2017">Bednarek 2017</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>These were edited intralingual subtitles, randomly checked with the screen version for accuracy. It goes without saying that intralingual subtitles may occasionally involve the simplification of screen exchanges to match an average reading speed. As all forms of transcription of scripted speech back into writing, it also requires the sanitation of overlapping fragments and intrusive repetitions. However, the dialogue lists we randomly compared with complete audiovisual material revealed only minimal traces of condensation, quite insignificant for the procedures we applied and the methods used are insensitive to the edition techniques usually used to condense dialogues in captions (such as grammatical tense revision).## Bibliography&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">The Voices of Doctor Who – How Stylometry Can be Useful in Revealing New Information About TV Series</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000499/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000499/</id><author><name>Joanna Byszuk</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction1">Introduction<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></h2>
<p>Distant reading, or more generally: exploration of large collections of cultural objects with quantitative methods, has long been successfully applied not only in its original literary (prose) scope as proposed by<a href="#moretti2000">Moretti (2000)</a>but also in texts from other domains, e.g. journalistic reviews (e.g.<a href="#benatti2015">Benatti and Tonra 2015</a>), poetry (e.g.<a href="#plechac2017">Plecháč and Flaišman 2017</a>), blog posts (e.g.<a href="#schler2006">Schler et al. 2006</a>), tweets (e.g.<a href="#juola2011">Juola et al. 2011</a>) etc. This paper seeks to explore the possible application of methods established in stylometry, such as hierarchical clustering, network analysis (both discussed e.g. in<a href="#eder2017">Eder 2017</a>) or contrastive analysis with Zeta (<a href="#craig2009">Craig and Kinney 2009</a>,<a href="#burrows2007">Burrows 2007</a>), to audiovisual works, or, more precisely, to their textual layer alone. Furthermore, the paper aims to establish some conditions that need to be fulfilled to conduct such studies with respect to the existing traditions in both film studies and linguistics research.</p>
<p>The main substantive interest of this paper lies in presenting creative relations within television series production teams, with specific focus on the shift from character- to author-oriented script-writing. The first section of the paper sketches relations between distant reading and television studies, and summarizes existing research on quantitative studies of television discourse. The second section briefly sketches the outline of the show discussed in the case study in section three, a British science-fiction series Doctor Who. The third section proposes possible applications of quantitative methodology, namely stylometry, to exploring inter- and intra-textual relations in television shows, and the fourth presents the results of the case study, verifying the usefulness of the approach proposed here.</p>
<p>It is true that a focus on the textual layer alone may seem as anathema to both traditional and digital film scholars. Not for a moment can one forget that there is more to moving (as well as talking) pictures than whatever their characters have to say. This does not mean, however, that quantitative analysis of that one aspect of film is insufficient or frivolous. At worst, the text of film dialogue may be examined quantitatively as any other text and thus constitutes a valid area of study in this limited scope. More hopefully, however, holistic approaches to film text – approaches that could combine the study of its textual and its visual aspects – may be devised in time. Even the most ambitious specialists in quantitative analysis of text do not pretend that literary novels are just about word counts. This is even more true of theatre, and yet theatre is a major object of textual studies: to cite the most obvious example, quantitative analysis of word frequencies is now an accepted method – and indeed the most reliable – in Shakespearean authorship attribution, and its importance is further highlighted by the oftentimes heated disputes between its practitioners.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></p>
<p>Still, the text of film dialogue alone is of interest to quantitative literary studies. It is exactly this doubtful state of authorship concept and execution in television series that seems provocation enough to address some of the inescapable questions. For instance, is it at all possible to observe and to measure authorial impact in the textual layer of film alone? Can computational methods help us shed some light on the validity of the concept of authorship as argued by<a href="#martin2013">Martin (2013)</a>and<a href="#jensen2017">Jensen (2017)</a>and as summarized below? While we know that authorship attribution methods can help us distinguish between authors in the difficult contexts of short or multi-authored texts, are they also effective with texts that undergo many editions and possibly have writers imitate the style of a showrunner; with texts that are but one of the many aspects – some may say, a fairly insignificant one – of the multifaceted medium that film undoubtedly is?</p>
<h2 id="1-distant-reading-and-television-studies">1. Distant reading and television studies</h2>
<h2 id="11-quantitative-approaches-to-television-studies">1.1 Quantitative approaches to television studies</h2>
<p>Development of efficient image processing methods in recent years brought rising interest in application of quantitative methods to television and film works. As evidenced by papers presented during meetings of ADHO Special Interest Group Audio Visual Material in Digital Humanities, this concerns especially their visual layer. Hitherto-conducted studies range from cinemetrics (e.g. works of Mike Baxter and Yuri Tsivian) to applications of high-level computer vision methods to the study of moving images (e.g. the Distant Viewing TV project:<a href="#arnold2017">Arnold and Tilton 2017</a>) to whole systems dedicated to archiving and analyzing of videos (CLARIAH Media Suite). Unsurprisingly, the analysis of the audio layer is yet to be undertaken on a larger scale – state of the art solutions to problems such as speaker diarization are still far from useful, and, like computer vision, this type of analysis is greedy in terms of computational power. Comprehensive studies examining all multimodal aspects of films and TV series still belong to the future.</p>
<p>While the above-mentioned studies are of great importance, they align more with the term ofdistant watchingordistant viewing,and in this paper I aim to draw attention to another aspect of audiovisual creations: to the textual layer of dialogue.<a href="#kozloff2000">Sarah Kozloff (2000)</a>noted that film dialogue is often overlooked and considered of little importance and interest to both film scholars or linguists. She argued in favor of the usefulness of such studies, providing relevant examples and encouraging further ventures into linguistic aspects of audiovisual creations. Later years brought noteworthy projects on both film and television dialogue, most notably numerous works in corpus linguistics and discourse analysis, produced, among others, by Monika Bednarek, whose 2010 and 2018 books provide the most comprehensive review of the research that combines linguistics and television studies.</p>
<p>In the latter book, Bednarek noticed the rise of popularity of more formalized research on TV dialogue, including quantitative studies using corpora of transcribed dialogues, and pointed to the examples of TV series studied within various linguistic frameworks, including sociolinguistics (discussion in<a href="#richardson2010">Richardson 2010</a>), corpus linguistics (multiple examples for this and other linguistic branches in the extensive bibliography by<a href="#bednarek2018">Bednarek and Zago 2018</a>), multimodal discourse analysis (<a href="#bateman2012">Bateman and Schmidt 2012</a>,<a href="#bateman2014">Bateman and Wildfeuer 2014</a>, and<a href="#wildfeuer2014">Wildfeuer 2014</a>) and audiovisual translation (<a href="#holobut2016">Hołobut et al. 2016</a>,<a href="#holobutr2018">2018a</a>,<a href="#holobut2018">2018b</a>,<a href="#bruti2016">Bruti and Vignozzi 2016</a>). TV series in their textual layer also become an object of research on narratives and themes, e.g. topic modeling-based plot explorations conducted by<a href="#schmidt2015">Benjamin M. Schmidt (2015)</a>on a corpus of 80,000 film and television series scripts.</p>
<p>Significantly for this study, the research project conducted by Hołobut and her team is also one of the first to apply stylometry to the exploration of stylistic similarities in audiovisual data. In one of their first papers,<a href="#holobut2016">Hołobut, Rybicki and Woźniak (2016)</a>discovered that, in the case of television series, genre was likely to overshadow stylistic features specific to the author. In their further research, namely a stylometric analysis of <em>Pride and Prejudice</em> and its adaptations, Hołobut and Rybicki found that television series were “imitating Jane Austen’s verbal style more suggestively than the cinema productions” <a class="footnote-ref" href="#holobutr2018"> [holobutr2018] </a>. Another attempt at applying stylometric methods to television series dialogues was made by<a href="#zyl2016">van Zyl and Botha (2016)</a>, whose study of <em>The Big Bang Theory</em> dialogue lists confirmed the existence of clear character idiolects in television discourse.</p>
<h2 id="12-authorship-in-television">1.2 Authorship in television</h2>
<p>Due to the multimodal nature of audiovisual works, in contrast to typical practice in literary and linguistic studies, the concept of authorship is very difficult to attach to one person in television. In fact, the issue of authorship “has been rarely associated with television” at all, as authorship “was diffused among many individuals and may more properly have been claimed by a studio, company, or channel than by a person” <a class="footnote-ref" href="#hartley2004"> [hartley2004] </a>. Collaborative storytelling and the number of people involved in the process of writing, rewriting and changes introduced during shooting and even in post-production, are often emphasized by both television creators and scholars.</p>
<p>While since the 1950s, film directors have been widely accepted as authors (orauteurs) of their works, and much attention is given to analyzing the works of such as directorial starts as Quentin Tarantino or David Lynch, the directors of television series have had a much smaller influence and typically only work on one up to a few episodes per season. Mittel also notes that while</p>
<blockquote>
<p>the literary writer is ultimately celebrated for <em>authorship by origination</em> , assumed (however erroneously) to have written every word as an individual, a film&rsquo;s director is granted <em>authorship by responsibility</em> , ultimately making the necessary creative choices by supervising and guiding all of the film&rsquo;s many collaborators, even if much of the specific work was done by others.<br>
<a class="footnote-ref" href="#mittell2017"> [mittell2017] </a>This perspective on authorship by responsibility is also often linked to television, however, in relation not to directors but to showrunners (e.g.<a href="#steiner2015">Steiner 2015</a>,<a href="#jensen2018">Jensen 2018</a>,<a href="#lavik2015">Lavik 2015</a>). A showrunner is an informal term used to describe a person who holds most creative power in the show, usually combining the duties of main scriptwriter and executive producer. The concept is used mostly in relation to American culture (e.g. David Chase, Joss Whedon, Shonda Rhimes, David Simon), but there are also examples of showrunners in the UK (e.g. Russell T Davies, Charlie Brooker) and Scandinavia (Hans Rosenfeldt). Detailed origin and characteristics of this job have so far been subject to few studies, with the most comprehensive analyses by<a href="#martin2013">Brett Martin (2013)</a>and<a href="#lavik2015">Erland Lavik (2015)</a>. In his book, Martin looks into the phenomena associated with the popularity of series authored by some of the earliest openly-appointed showrunners and, based on conversations with them and their collaborators, he details existing forms of this mode of work. With all the information he collected, Martin does not hesitate to refer to TV showrunners (such as David Chase) as authors, comparing the conditions of their work to serial Victorian writers, such as Charles Dickens, Anthony Trollope or George Eliot. He also points out that given their decision-making over “story direction to casting to the color of seemingly insignificant characters’ shirts” <a class="footnote-ref" href="#martin2013"> [martin2013] </a>they seem “all-knowing deit[ies].” Martin also observes that showrunners are typically writers (with few examples of showrunners holding only producer credits) and that they tend to emphasize their power over words and world-shaping. While typically there are many writers involved in the writing of a series, there are various ways their work can be organized: collaboration can include awriters’ room,where a showrunner meets with writers to pass/develop ideas together in detail before designating a team member to transform such detailed vision into actual script and again to discuss it in the room; in another manner, writers contribute episodes based on a general season narrative arch developed by a showrunner, who supervises execution and introduces corrections and changes to maintain consistency. In turn, in his book Lavik compares American, Dutch and Norwegian styles of showrunning and argues that outside of the American perspective detailed by Martin, showrunners in Europe give their writers much more authorial freedom and have themselves more creative than administrative responsibilities. Interestingly, Lavik also distinguishes between focused (one showrunner for the whole production of the show) or distributed (showrunners changing every (few) seasons) overarching authorship of showrunners, and actual authorship of writers.</p>
</blockquote>
<p>The exact scope of influence of a showrunner is unclear and varies from series to series. A script is usually rewritten many times at various points before, during and after production, and, as noted by Jensen:</p>
<blockquote>
<p>other writers work to support the vision founded by the showrunner, or creator. That, however, does not mean that these writers (&hellip;) do not make a difference in the final outcome of a series (they most certainly do), but they do so within a paradigm laid down by the creator(s) of the show.<br>
<a class="footnote-ref" href="#jensen2017"> [jensen2017] </a>Jensen also notes that despite this complex authorship of television productions, the works of particular showrunners bear similarities across various series, both in style and in specific interests of the authors<a class="footnote-ref" href="#jensen2017"> [jensen2017] </a>. He emphasizes interest in “seeing how the various works across an <em>oeuvre</em> depict a topic in different ways, maybe even in contradictory ways” <a class="footnote-ref" href="#jensen2017"> [jensen2017] </a>– this is to be expected from an author able to create well-developed characters that differ in their ideas and nature as expressed in their dialogue lines, and can be used to evaluate character-building skills of the author. One method to do so may consist in contrastive analysis discussed later in this paper.</p>
</blockquote>
<p>The concept of authorship of audiovisual works as adapted from literature poses even more problems, as discussed in detail by<a href="#steiner2015">Steiner (2015)</a>on the example of <em>Game of Thrones</em> and its “showrunner- auteur troika:” of author of the novels adapted into the series and series’ two showrunners, all participating in writing of the stories. Determining the scope of influence of any of them is a task posing a great challenge to quantitative and qualitative approaches alike. Again, I will argue that one of stylometric methods, sequential analysis, can facilitate this task, at least when it comes to the authorship of the textual layer.</p>
<h2 id="2-doctor-who--the-background-of-the-series">2. Doctor Who – the background of the series</h2>
<h2 id="21-about-the-show">2.1 About the show</h2>
<p>The British television series Doctor Who is a phenomenon for a number of reasons, and a perfect subject for a study applying a variety of quantitative methods. Broadcast since 1963 (with a break between 1989 and 2005), it is one of the most popular science fiction series, critically acclaimed, with generally a mainstream status (at least in Britain), and with a cult following.</p>
<p>The basic assumptions of the show are quite unique:</p>
<p>Its main character, the Doctor, travels with his companions in the TARDIS (Time and Relative Dimension in Space), a ship capable of traveling through space and time that takes the exterior form of a 1930s British police booth, but is bigger on the inside. (&hellip;) the Doctor is not consistently portrayed by the same actor; periodically the Doctor “dies” and regenerates in a new humanlike form with a new personality<a class="footnote-ref" href="#edwards2014"> [edwards2014] </a>.</p>
<p>This form certainly contributes to the popularity of the show. Frequent changes allow to keep it fresh and likely to attract both long-term fans as well as people interested in only following one specific regeneration of the Doctor. Rebuilding the show around new incarnation of the main character enables viewers to start watching the show from various episodes and seasons without normal difficulty related to following TV series from a random point, that is having to figure out previous plot twists relevant for its understanding.</p>
<h2 id="21-internal-classification-of-the-show">2.1 Internal classification of the show</h2>
<p>The show can be, and is, divided in numerous ways both by producers, fans, and scholars. The most basic division line is that between theClassic(1963-89) – and theNew,sometimes spelledNu(produced from 2005 onwards). The 1996 feature film is considered a part of the Classic Who.</p>
<p>Another division line is defined by the respective regenerations of the Doctor, thirteen as of 2018; this does not include the so-called Doctor 8.5, also known as the War Doctor, appearing in the 50th anniversary special. Since the Doctor is the main axis of the show and usually the one character who delivers most of the dialogue (in the New series, an average of 30-40% of all lines belong to the Doctor, i.e. twice as much as any of his companions), their<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> change strongly influences the overall shape of the show.</p>
<p>The 2005 revival introduced many innovations, primarily in narrative style and in the introduction of the position of a showrunner. This has been discussed as both a factor ensuring the success of the refreshed series and a reason behind a major change in narrative style<a class="footnote-ref" href="#hills2010"> [hills2010] </a><a class="footnote-ref" href="#hills2013"> [hills2013] </a>. As of 2018, the show has recently adopted its third showrunner, Chris Chibnall, with the first, Russell T Davies, serving in the years 2005-2010, and the second, Steven Moffat, between 2010 and 2017. Each of them had an established successful series writing career at the moment of taking over and was well-known by the British public. The showrunners were generally seen as bringing their individual style and vision to the show, and the years of their work on Doctor Who were marked respectively as the Davies and the Moffat eras (see e.g. in<a href="#chapman2014">Chapman 2014</a>) – a quick search reveals that aChibnall erais now also used in the Internet, though with as of yet small frequency.</p>
<p>This perspective of various strong influences offers an opportunity to examine not only the authorship of the episodes, consistency of the show and character stability, but also the relevance of particular divisions.</p>
<h2 id="3-empirical-study">3. Empirical study</h2>
<h2 id="31-problems">3.1 Problems</h2>
<h2 id="311-obtaining-the-data">3.1.1 Obtaining the data</h2>
<p>The classic problem of any quantitative study is obtaining the data, especially data of the right quality. The situation is no different if we decide to conduct an analysis of television dialogue. If anything, it is even more complex: we must first decide how we define the dialogue that is to be analyzed: the scripts or the spoken text as it was actually recorded? While some creators or broadcasters (e.g. BBC Writersroom) share scripts of their show after the series is released, such an approach is rare and usually concerns only a few sample episodes rather than a full series. Moreover, it is not clear how much such released scripts vary from the final televised versions of episodes; and since it is well known that dialogue is reworked continuously during production and post-production to meet the changing conditions of realizations, full compliance can never be assumed.</p>
<p>One tempting source of data are large amounts of subtitles available freely on the Internet. There are many arguments in favor of using subtitles: they are widely available and can be easily scraped, converted and cleaned without investing much effort and time. However, there are just as many arguments against using them. Subtitles found in popular aggregator websites, such as<a href="http://www.yifysubtitles.com/">www.yifysubtitles.com</a>or<a href="http://www.tvsubtitles.org/">www.tvsubtitles.org</a>, are usually of fairly good quality, but there is always a level of uncleanliness of the data. They are usually created by ripping original subtitles from DVD/BlueRay editions or through transcription conducted by amateur fans, both factors increasing the risk of typos and arbitrary alterations, or of missing some information.</p>
<p>It is also important to remember that subtitling is a highly conventionalized art. Professional standards (and distributors) place limitations as to the length of text displayed on the screen at the time. Common practices include rephrasing some original sentences, turning them into shorter equivalents when the pace of speech is too fast, adjusting punctuation to respond not to the actual manner of speaking but rather to the comfort of reading, or omitting content spoken in foreign languages or as part of the music soundtrack (e.g. song lyrics, even if sang by characters). Subtitles created by amateurs are also likely to present various spelling conventions requiring normalization.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
<p>Yet another approach proposes using transcriptions of the dialogue. When the transcription is performed per commission, this method allows for greater control over the text – including detailed information about who is speaking (and how), and agreeing on notation and spelling standards. Its main disadvantage is the cost in terms of time, obviously, but also money. Describing her SydTV Corpus, Bednarek explains her reasons for deciding on this solution: she was trading the size (choosing to have a 60-episode clean corpus of approximately 250k tokens rather than a larger, yet messier one) for quality – a factor crucial when conducting detailed analysis of language variation features<a class="footnote-ref" href="#bednarek2018"> [bednarek2018] </a>.</p>
<p>In this study, I too built a corpus of transcriptions, but using fan transcripts selected from one of the many websites collecting them. Fan transcripts are never perfectly clean, however they have a great advantage over subtitles: they often offer information on who speaks the particular lines, and they are a transcription of actual spoken dialogue. In this particular case, the texts were transcribed by one person, with others only pointing out corrections via e-mails to the author, which definitely helped in maintaining consistency of notation. To ensure the quality of the dataset, apart from automatic preprocessing and cleaning I conducted sample manual verification of the quality by reading the texts and listening to New Who episodes, and by skimming through the rest of the texts in the corpus, correcting an almost negligible amount of typos.</p>
<h2 id="312-dataset">3.1.2. Dataset</h2>
<p>The dataset used for this study was prepared based on the web scraped fan transcripts<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> and consisted of a total of 314 text files. The decision to use fan transcripts rather than subtitles was grounded in the corpus linguistic recommendations for research on TV series language<a class="footnote-ref" href="#bednarek2018"> [bednarek2018] </a>, as discussed in the previous section. While the corpus covers the whole show as of December 2018, the number of texts differs from the number of episodes and stories as listed e.g. on Wikipedia. Over the course of the development of the show, BBC offered various structures of a given season (or series, as this is commonly referred to in British television discourse). During Classic Who, each season was divided intoserials:longer stories of continuous narrative, which were further divided into 25-minute episodes broadcast every week. Serials varied in length, going from two to twelve episodes. In contrast, New Who consists mostly of stand-alone 45-50-minute episodes, with occasional two- or three-part episodes, typical especially for season finales, and for the Davies era. I decided against splitting Classicserialsinto episodes and against concatenating New episodes into stories; instead, I applied sampling (drawing samples of equal length from the corpus) to even out the size of the examined texts.</p>
<p>Before the analysis, the data was cleaned of html tags and of any additional information which was not a part of the actual dialogue (comments in brackets, indications of speakers, etc.). Cleaning was done semi-automatically with a number of regular expressions matching observed patterns during the manual cleanup of several randomly selected episodes. The clean dataset was used to create three types of corpora: i) all dialogue lines, ii) lines spoken by the Doctor, iii) lines solely from the New Who seasons.</p>
<h2 id="32-methods">3.2 Methods</h2>
<p>Stylometry is grounded in the observation that the distribution of certain features, most notably most frequent words, is a strong bearer of stylistic ‘signal’, which can be used to predict authorship, chronology, genre, or to lesser extent topical similarities. The earliest attempts to compare the use of words across texts date back to Lorenzo Valla in the 15th century and Augustus de Morgan and Wincenty Lutosławski in the 19th century, with the latter considered to be the first to compare top most frequent words, using this method to analyze works of Plato. The approach became more popular after Mosteller &amp; Wallace’s famous study of <em>The Federalist Papers</em> <a href="#mosteller1964">(1964)</a>, and started to develop intensely with the availability of more powerful computers and Burrows’ study of Jane Austen’s works<a href="#burrows1987">(1987)</a>, in which he introduced a more reliable method of comparing not just individual words but whole texts with his Delta measure<a href="#burrows2002">(2002)</a>.</p>
<p>A stylometric study requires a few basic items: a corpus of texts which will be turned into a frequency table detailing use of all available words, a method for calculating a distance between their use across the texts (so called distance measure) and a classification algorithm. An optional, but convenient addition is a visualization method, allowing for easier interpretation of the final outcome. All analyses in this study were performed using stylo, an R package for computational text analysis<a class="footnote-ref" href="#eder2016"> [eder2016] </a>, which includes algorithms for all these steps and offers a wide selection of types of distance measures and classification algorithms, not requiring more computational skills than preparing the corpus and making an informed choice between appropriate options.</p>
<p>One important step of preparing the experiment is choosing the right features to analyze. While Mosteller &amp; Wallace opted for using most frequent words (MFWs); later studies experimented with the use of combinations (the so-called n-grams) of subsequent characters, subsequent words or even grammatical features. While character n-grams show nice performance for some types of texts, most notably historic and poetic texts<a class="footnote-ref" href="#kjell1994"> [kjell1994] </a><a class="footnote-ref" href="#stamatatos2009"> [stamatatos2009] </a><a class="footnote-ref" href="#kestemont2014"> [kestemont2014] </a>, n-grams of words typically perform worse<a class="footnote-ref" href="#eder2011"> [eder2011] </a>, as do grammatical features, e.g. POS tags<a class="footnote-ref" href="#gorski2014"> [gorski2014] </a><a class="footnote-ref" href="#cafiero2019"> [cafiero2019] </a>, or lemmas. Given that the above studies seem to show that, in contemporary settings, most frequent words perform best, I decided to use them as features. Dismaying as such an approach may seem to the traditional humanities scholar, empirical evidence supporting it is overwhelming. The possibility of using such simple evidence for such large purposes rests upon the fact that words do not function as discrete entities. Since they gain their full meaning only through the different sorts of relationships they form with each other, they can be seen as markers of those relationships and, accordingly, of everything that those relationships entail<a class="footnote-ref" href="#mckenna1999"> [mckenna1999] </a>.</p>
<h2 id="321-conducted-types-of-analysis">3.2.1 Conducted types of analysis</h2>
<p>The first and mainly exploratory test was hierarchical clustering, one of the basic but most reliable algorithms of grouping similar texts, in its network variant of bootstrap consensus analysis. This variant is based on conducting a series of hierarchical clustering analyses with different counts of features and comparing their inter-agreement with a set threshold, so that only the texts classified as similar a set number of times are taken into account (e.g. for a threshold of 0.5, i.e. 50% and four iterations, two texts need to be classified as each other’s nearest neighbors in at least two iterations for the connection to be considered valid). It presents a more objective and reliable view of the relations in the dataset than regular cluster analysis, decreasing the risk of cherry-picking by not relying on just one best outcome, and can be visualized in a graphical form of a network, which facilitates interpretation of the results in the case of large datasets, like the one in this study.</p>
<p>Network data produced by stylo was used in Gephi to create visualizations and to conduct further analyses, e.g. community detection with the Louvain modularity algorithm<a class="footnote-ref" href="#blondel2008"> [blondel2008] </a>. Community detection is a method facilitating identification of naturally occurring groups within networks, often difficult to observe in detail with human eye, allowing for understanding their large-scale structures. The method divides a network into groups of nodes sharing strong connections between them. The Louvain algorithm is commonly used in many disciplines and was found to be the most reliably performing community detection in stylometric studies<a class="footnote-ref" href="#ochab2019"> [ochab2019] </a>as it is well adjusted to the analysis of networks that may contain small structures, which can be expected also in the case of TV dialogue data.</p>
<p>In the contrastive analysis of Doctor regenerations I used the algorithm of Craig&rsquo;s Zeta<a class="footnote-ref" href="#burrows2007"> [burrows2007] </a><a class="footnote-ref" href="#craig2009"> [craig2009] </a>, which compares which features are used significantly and consequently more often across works in each of the two examined sets.</p>
<p>For a more detailed study of authorial influence of showrunner supervising scriptwriters I used Rolling Delta algorithm<a class="footnote-ref" href="#eder2016"> [eder2016] </a>, a method that looks forsignalsof different authors within a single collaborative text. It conducts sequential classification ofslicesof such a text and allows for a fairly precise identification of authorial takeovers within one work (e.g. the case of Harper Lee in<a href="#choinski2019">Choiński et al. 2019</a>).</p>
<h2 id="322-identifying-features-to-be-used-in-the-analysis">3.2.2. Identifying features to be used in the analysis</h2>
<p>Dialogues in television series differ from both literary texts to unscripted spoken language. Awareness of this is crucial for proper performance and interpretation of a quantitative analysis. Functions of dialogue in television writing related to anchorage of the narrative, building continuity and helping viewers remember characters’ names, locations etc.<a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a>make for a higher percentage of proper names both in the overall show and in particular episodes. As observed in the frequency tables of word usage in the corpus used in this study, at least in the case of Doctor Who, especially episodes introducing new characters tend to repeat names more often, and, as evidenced by the count of number of words uttered by companion characters in Doctor Who, introductory episodes are usually also the ones in which respective characters speak the most within the whole set of their appearances in the show.</p>
<p>This nature of TV language, combined with the thematic variety of episodes, calls for implementing some sort of limit to the influence of features that may score very high in individual texts (and this way also in the list of most frequent words) but be rather non-important for the general stylistic profile of the corpus. One such solution, commonly known as culling, has long been in use in stylometry, although as of yet there are no studies determining exact conditions of its use, thus enforcing special carefulness in its application. Culling is a procedure of removing such features from the list of analyzed features that only appear in a determined percentage of analyzed texts.</p>
<p>In this study I chose to first conduct a leave-one-out cross-validation classification test on the whole corpus (classifying each text using the rest of the dataset as the training model) and discovered that culling of 20% increased the performance of my chosen classifier (Support Vector Machine) performance for all examined numbers of MFWs (100-500). While such procedure might be useful, factors to be taken into consideration before adopting it to other studies are size of the corpus, thematic variation of the texts, and their length. Finally, one should remember that the use of culling heavily decreases the number of features that can be used in the study (e.g. in case of texts composed solely of lines spoken by the Doctor, only 395 shared words remain).</p>
<p>As for other settings, I explored possibilities of using various distance measures and found Cosine Delta<a class="footnote-ref" href="#evert2017"> [evert2017] </a>, which was proven to be the most reliable in a number of recent studies, to produce most stable results across settings, with Burrows’s Classic Delta also providing fairly good results.</p>
<h2 id="4-results">4 Results</h2>
<h2 id="41-development-of-the-show">4.1 Development of the show</h2>
<p>The first experiment was set to examine the direction of the development of the show and see whether a division into Classic and New Who, or into the showrunner eras, result in the change of the stylometricsignals.For this test I used all the texts in the corpora and considered two scenarios: first, examining the whole texts; second, examining just the extracted lines of the Doctor part. For each of the scenarios I conducted two analyses: with full text, and with sampling (random sampling of four 1,000-word samples per text). The second solution was adopted as an additional safety measure due to my concerns about the uneven length of the texts: while New Who usually has 4,500-6,000 words per episode, some Classic Who stories go up to 20,000 words.</p>
<h2 id="411-episodes">4.1.1 Episodes</h2>
<h2 id="whole-episode-perspective">Whole episode perspective:</h2>
<p>The primary finding, confirming intuitive expectations, was a strong division between Classic and New Who series, and more: it is also clear at first glance that New Who also bears a strong division line, as the texts from the three respective eras form three distinct groups. As visible in Figure 1, not only does the layout of the nodes confirm the separation, it is also detected by the Louvain algorithm, with the communities it discovered marked in different colors. Interestingly, some of the episodes from Eleventh and Twelfth Doctor tenures (New Who, Moffat as showrunner) are closely connected to groups of texts from Classic Who, which can be explained by Moffat’s commonly expressed intention to draw more parallels to the Classic series. Whereas Davies was hired to reinvent the show for the 21st century and to make it attractive for contemporary viewers, Moffat seemed to have been given more artistic freedom when it comes to exploring the roots of the show, as evidenced by his bringing back classic opponents such as Ice Warriors, Mondasian Cybermen or Zygons, as well as more frequent use of longer storylines developed over two episodes and stories overlapping whole seasons.</p>
<p>The newest additions, ten episodes of the latest (2018) season created by a new showrunner, Chris Chibnall, position themselves halfway between two other New Who showrunners, and application of the Louvain algorithm reveals them to be slightly more similar to the series supervised by Moffat. This result may be somewhat surprising, given that Chibnall was one of the writers employed at the time of Davis’s tenure and also collaborated with him on the <em>Doctor Who</em> spin-off, <em>Torchwood</em> . However, as the amount of the data for the Chibnall era is still small, these particular results should not be taken as a definite marker of his preference towards the style of his colleague.</p>
<p>The network does not seem to show clear chronological progression. While the texts from particular Doctor regenerations exhibit strong internal similarity (visualized by thick lines in the figure), they are not determined to connect in the order of subsequent regenerations. While, as visualized in Figure 2, there is a clear split into three (and with increasing the resolution of Louvain algorithm, forcing greater generalization, only two, see Figure 3) New Who eras, the Classic series lack similar structure: the discovered communities are not tied to a particular regeneration or writer, but are more genre/topic-oriented.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Network analysis (bootstrap consensus tree with Cosine Delta 100-500 MFWs on all episodes. Colors indicate communities discovered by the Louvain algorithm with modularity resolution of 1. On the left, Classic Who series include four distinct communities, corresponding to genre and topics rather than the particular regenerations or writers. On the right, three communities, mostly grouping the texts from each of the three showrunners.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Network analysis (bootstrap consensus tree with Cosine Delta 100-500 MFWs on all episodes. Colors indicate communities discovered by the Louvain algorithm with modularity resolution of 3. On the left, with this level of generalization, Classic Who no longer has distinct inner groups; on the right, episodes from Chibnall era are now clustered with a larger Moffat community, Davies remains distinct.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>All episodes; colors indicate communities found by the Louvain algorithm with modularity resolution of 4. This shows the highest level of generalization, with Classic Who on the left, and New Who series on the right.
        </p>
    </figcaption>
</figure>
<h2 id="sampled-perspective">Sampled perspective:</h2>
<p>To verify that the obtained results were not skewed by varying lengths of the texts, I conducted the same analysis using randomly selected samples of the texts. I automatically selected four random samples of 1,000-word length from each of the files in the corpus without replacement (ensuring that various samples would not overlap in text). In this particular case I also had to decrease the number of examined features to 300 in the last iteration, as this was the rough number of words common for all the texts in this setting. Applying the Louvain algorithm in this case showed that resolution had to be increased to much higher values (e.g. 15 on Figure 4) to reveal a smaller number of communities and a more generalized view. While New Who episodes form strongly interconnected clusters of individual episodes but have weak intra-connection edges, the Classic Who forms a uniform massive community showing strong relations between the texts; still, many episodes are mixed and do not recognize other samples from the same text.</p>
<p>Interestingly, some episodes are outliers from their own community. The New Who 11x06 episode, for instance, a debut by Vinay Patel describing the events around the Partition of India, appears among Classic Who episodes, forming significant relations with the Seventh Doctor’s adventures that are seemingly unsimilar in language and topic. In turn, some episodes of the Seventh, and to a lesser extent of the Fourth and Sixth Doctors have stronger affinities with the New Who.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Network visualization of sampled episodes, 4 samples of 1,000 words per episode. Colors indicate communities discovered by the Louvain algorithm, with modularity resolution of 15. On the right, Classic series form a strong community with thick edges indicating strong relations. On the left, New Who series form small strongly connected groups of samples relating to a given episode, and while the Louvain algorithm distinguishes two groups, they do not indicate a particular showrunner era or a new regeneration of the Doctor.
        </p>
    </figcaption>
</figure>
<h2 id="412-doctor">4.1.2 Doctor</h2>
<p>Even though the first set of tests already confirmed two basic divisions of the show into Classic and New Who, and the Davies and Moffat/Chibnall eras within the latter, no distinction was found regarding the influence of the Doctor regeneration on the development of episodes. Therefore, since their lines on average comprise 30 to 40% percent of the whole dialogue, I decided to look at them without the noise of lines spoken by other characters, seeing also if the writers succeeded – or, maybe, simply happened – to differentiate between regenerations.</p>
<p>The results here are much more interesting. As presented in Figures 5-7, Classic series show a clear distinction between Doctors and a trace of the chronological signal: while the First Doctor is equally strongly connected to his direct replacement and to later regenerations of the Fifth and Sixth Doctors, the communities of the Second, Third and Fourth Doctors are both distinct, and the fact that they have the strongest ties with their direct predecessors and successors indicate a visible chronology. Strikingly, the Fifth, Sixth and Seventh Doctors are all heavily intertwined together, which may coincide with the decline in the popularity and perceived quality of the show during their tenures; at this time, the series began to slowly but gradually lose its appeal to viewers, resulting in lower broadcast numbers and higher criticism of show development, leading to indefinite suspension in 1989.</p>
<p>Interestingly, while an earlier version of this study not including the last two series of Doctor Who alienated the First Doctor as the most distinct regeneration in the course of the history of the show (previous unpublished study of the author), the corpus used in this study distinguishes Second and Third (together) and Fourth (on his own) Doctors as most unlike the other Classic Who Doctors (see them form separate strong communities in the left bottom corner of Figure 6).</p>
<p>As for New Who, particular regenerations do not seem to have their own voice heard so much: the influence of the showrunners overshadows them, and this is visible even with the lowest resolution of Louvain algorithm in Figure 5 (pink for Moffat and green for Davies). One exception is the Thirteenth Doctor, who seems to mostly remain detached from other New Who Doctors over the course of increasing Modularity resolution. This could be the consequence of the new showrunner, except that Chris Chibnall wrote a number of episodes for both Davies and Moffat, the texts of which cluster with their respective eras, and the whole texts of the episodes from his era showed his similarity to Moffat’s era (Figures 1-3); another hypothesis might involve the gender switch.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Doctor lines, bootstrap consensus network, Cosine Delta, 100-500 MFW. Colors indicate communities detected by the Louvain algorithm with modularity resolution of 1. On the left, the large community of Classic Who with five internal groups of First, Second, Third and Fourth Doctors separately and Fifth, Sixth, Seventh and Eighth together (blue). On the right, the community of New Who, divided further into three groups corresponding to showrunners.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Doctor lines, bootstrap consensus network, Cosine Delta, 100-500 MFW. Colors indicate communities detected by the Louvain algorithm with modularity resolution of 3. Within the Classic Who community the First Doctor is now found to be more similar to the last four Doctors, and the Second and Third are clustered together – only the Fourth Doctor has his own group. Within the New Who community, all male Doctors, who also share being written in Davies’s or Moffat’s eras, are considered as one group, the Thirteenth Doctor forms her own group.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Doctor lines, bootstrap consensus network, Cosine Delta, 100-500 MFW. Colors indicate communities detected by the Louvain algorithm with modularity resolution of 4. The division line now falls between the Classic and the New series.
        </p>
    </figcaption>
</figure>
<p>Overall, the break into Classic and New Who is the most important division, as revealed by the Louvain algorithm. However, while Finer and Pearlman state that “story is character” <a class="footnote-ref" href="#finer2004"> [finer2004] </a>, this does not seem to hold for Doctor Who: the development of the main character is slightly different than that of the whole show.</p>
<h2 id="42-authorial-influence">4.2 Authorial influence</h2>
<p>For this part of study I focused on the New Who exclusively. I started with a network analysis including only the whole texts from this time period, which was enough to form a number of observations. The first basic one is the high visibility of contributions of Steven Moffat. Most of his works cluster together, be it the ones written under supervision of Davies or during his own era, with a distinction of a few texts that cluster into other communities with a few other writers he supervised, which could be hypothesized as his influence over them (see Figure 8).</p>
<p>The situation seems quite different for the other two showrunners. Episodes written by Russell T Davies appear in all communities related to his tenure, mixing with other writers and showing strong narrative connections (in Figure 8, the group marked with light green connects mostly more dramatic two-part episodes and finales, whereas the brown one gathers more regular episodes from the middles of the seasons). Preliminary tests conducted for this study, not including the last two seasons, showed this even more sharply, with separate clusters for episodes opening and closing seasons: his writing and supervision seem to strictly control the development of the show, and while some influence of topics (e.g. episodes with traveling back in time) can be seen, the authorial control of a showrunner over writers, exhibited by strong ties between them, seems to be the main driving power behind the similarities shared by the texts.</p>
<p>Interestingly, as presented in Figure 9, the season created by Chris Chibnall clusters not only with his previous works on the show in the eras of his predecessors but also with the episodes written byusualscriptwriters earlier on, mostly from the Moffat era. This can be interpreted in a number of ways. Undoubtedly, Chibnall has a strong authorial presence, but the fact that other writers who largely contributed to the show and also built their own prominent careers such as Toby Whithouse (creator of <em>Being Human</em> ) and Matthew Graham (co-creator of <em>Life on Mars</em> ) cluster together with him could be interpreted as the community of writers who grew up in the Doctor Who writing room now finding their own voice (albeit somewhat similar when contrasted to Davies and Moffat).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Network of New Who episodes, bootstrap consensus tree, Cosine Delta, 100-500 MFW Colors indicate communities discovered by the Louvain algorithm with modularity resolution of 1. On the left and in the lower central part visible are three communities within the Moffat era. In the upper central part we find the Chibnall era, on the right, three communities form the Davies era.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Network of New Who episodes, bootstrap consensus tree, Cosine Delta, 100-500 MFW. Colors indicate communities discovered by the Louvain algorithm, with modularity resolution of 3. Visible are three communities of respectively the Moffat (red) and Davies (brown) eras, and the Chibnall era (blue) extended with some of his previous works written earlier in the history of the show and episodes written by a few other prominent writers.
        </p>
    </figcaption>
</figure>
<h2 id="detailed-study-of-authorial-influence">Detailed study of authorial influence:</h2>
<p>For a more detailed study of authorial influence, I examined selected episodes of the show to compare Davies and Moffat in their roles as showrunners with Rolling Classify<a class="footnote-ref" href="#eder2017"> [eder2017] </a>, a method for sequential detection of stylistic idiosyncrasies within a single text. When choosing the episodes I followed some basic criteria: the credited author of the episode had to contribute at least a few other texts for the show, and to be considered as fairly independent according to available data on the working processes.</p>
<p>One methodological concern for this type of study is that the exact scope of the influence of the showrunner is unknown. Using episodes from the show as training data carries the risk that all episodes written by a given person will be tainted by heavy showrunner impact, thus skewing the results in his favor. Doctor Who production does not report using Writers’ Room in the American sense, although a version of it, based on meeting to read and discuss ready scripts was mentioned to exist at least in Moffat’s time, as detailed in a special interview on their writing process.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Instead, the show employs guest writers who create their own stories fitting some basic arch vision provided by the showrunner who also has the final say over the acceptance of their ideas and shape of the scripts. In fact, Davies claims that he writes “the final draft of almost all scripts – except Steven Moffat&rsquo;s, Matthew Graham&rsquo;s, Chris Chibnall&rsquo;s and Stephen Greenhorn&rsquo;s – and that draft becomes the Shooting Script” <a class="footnote-ref" href="#davies2008"> [davies2008] </a>. Despite these concerns, I decided to examine the situation, even if to offer doubtful findings to be further studied and verified. I present just a few cases below, with all available at the project website.</p>
<p>While in my study I also used Delta and Nearest Shrunken Centroid classifiers, here I present results obtained with Support Vector Machine (SVM) classifier, which is largely considered the most reliable classifier in stylometry<a class="footnote-ref" href="#stamatatos2013"> [stamatatos2013] </a>, and which also in this case offered most stable results across various settings and for various datasets, as did using 100 MFW as features (although wider ranges of features were also tested). As Rolling Classify uses a sliding window to provide sequential classification of an examined text, the texts were divided into 1,000 word samples, with 750 words as overlap. The visualization graph produced by Rolling Classify shows two bars of authorial influence, reflecting the percentage of probable authorship of a given slice, with the lower bar showing the more likely impact.</p>
<p>No matter the method of classification, the outcomes revealed the major influence of Davies authorial style in all examined works of his era. However, whereas (e.g. Figure 11) Davies’s influence dominates only a part of the episode written by Moffat, in case of the episodes Davies claimed in his memoir to have largely re-written (Figures 10 and 12) his style dominates the whole text, with the Rolling Delta algorithm recognizing him as their primary author. Assuming the honesty of the showrunner, this in itself is an important finding, showing that at least in the case of the texts clearly written by one scriptwriter, both his own authorial signal and that of the showrunner are easily detectable. The results for writers known to have been edited by the showrunner are less easily interpretable and reliable: while thanks to Davies’s memoir we know he corrected them in this, fourth, season, a question remains whether the texts written by regular scriptwriters for earlier seasons were just as heavily corrected. Since I used them as training data to teach the model their style, positive answer to this question would mean that in the examined season Davies’s impact was stronger than the combination of writers’ style and his editorial impact as evidenced in earlier seasons. In the event that the earlier texts present pure style of particular authors, results such as obtained would mean that in this season showrunner’s stylistic impact completely overshadows most of the credited authors. The case of Moffat’s episode, unedited by Davies but still showing his stylistic impact is particularly interesting, giving grounds to raise the question how much of showrunner’s stylistic fingerprint can be carried by others through imitation or following set tone of the show? While we know imitation is still detectable in literature despite best efforts (e.g. a case of translation by two people in<a href="#rybicki2013">Rybicki and Heydel 2013</a>), perhaps the more controlled medium of TV series, or some of its features, like creating character idiolects, allows for easier speaking in someone else’s voice?</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The Doctor’s Daughter (4x06) contrasted sequentially against R.T Davies (red) and M. Gatiss (green); 100 most frequent words.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Silence in the Library (4x08) contrasted sequentially against R.T Davies (green) and S. Moffat red); 100 most frequent words.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The Unicorn and the Wasp (4x07) contrasted sequentially against R.T Davies (green) and G. Roberts (red); 100 most frequent words.
        </p>
    </figcaption>
</figure>
<p>Insofar as Moffat has published no memoir describing his writing and showrunning process and does not discuss the issue at length, with but occasional mentions that he justsets the toneof the show, I decided to examine episodes which co-credited him as an author, as well as some randomly selected works from his era. As visible in Figures 13-14, his impact as a showrunner was determined to be less visible, although still significant. However, his impact when sharing authorial credits (Figure 15) seems to be quite dominating, even if still far from the influence executed by Davies.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The God Complex (6x11) contrasted sequentially against T. Whithouse (green) and S. Moffat (red); 100 most frequent words.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The Rebel Flesh (6x05) contrasted sequentially against S. Moffat (green) and M. Graham (red); 100 most frequent words.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>The Caretaker (8x06) contrasted sequentially against S Moffat (green) and G. Roberts (red); 100 most frequent words. This episode credits them both as authors.
        </p>
    </figcaption>
</figure>
<h2 id="43-character-features">4.3 Character features</h2>
<p>The analysis of sole lines of the Doctor revealed a level of distinction between the Thirteenth and other New Who Doctors. The easiest hypothesis would be the impact of gender – the new female Doctor versus all men – or distinct impact of the showrunner. However, at least the Davies era episodes written by Chibnall show the latter’s stylisticsubmissionrather than his own vision of the Doctor.</p>
<p>To verify this, I conducted contrastive analysis with Craig’s Zeta<a class="footnote-ref" href="#craig2009"> [craig2009] </a>to compare the Thirteenth Doctor against her four direct predecessors, considered together and separately. Additionally, I also ran another test comparing Doctors created by Davies and by Moffat. Craig’s Zeta allows for comparing two groups of texts to find words used consistently throughout texts in one of the groups, and consistently avoided by the other, and vice versa. Obviously, the most frequent words disappear, while content medium-frequency words come to the surface; this is also the reason why this version of quantitative analysis becomes (at least slightly) more similar to the traditional/qualitative approach.</p>
<p>As contrastive analysis was performed without culling, meaning that all words were included as they were, one immediate feature of lists of words characteristic to the particular regenerations is the high position of the proper names relating to companions – which is caused by frequent addressing of the given character or talking about them. This is true in most cases, but reveals various relations between the Doctor and their sidekicks: the names of all companions of the Ninth and Thirteenth Doctor are at the top of the list, but other Doctors show their preference towards a particular companion, e.g. Tenth to Rose over Martha and Donna, Eleventh to Amy over Rory and Clara.</p>
<p>On the first look, it would be easy to interpret the results as presenting a gendered portrayal of characters – the new female Doctor sayslove,woman,together,andpleasemore often than other Doctors. However, a deeper analysis of preferred words of her and other Doctors shows that it is not that simple.Loveis more characteristic for the Eleventh Doctor, known for his expressive and emotional attitude to the world, and whilepleaseis high on the Thirteenth’s most used list, its only seems high in comparison to Ninth and Twelfth Doctors, arguably more stereotypically male and harsher in behavior than the other two male Doctors.Pleaseis also a word preferred by Moffat Doctors over Davies Doctors.</p>
<p>One characteristic feature of the language of the Thirteenth Doctor is a high ratio of elliptic adverbs such asobviously,presumably,definitely,possibly,as well as the adjectivesure.Also, regenerations written by Moffat use them more often than Davies, which may influence the pattern of relative frequencies in the corpus enough to partly explain the fact that, in the network studies presented above, Louvain Modularity recognizes Chibnall as closer to Moffat than to Davies. When analyzed in context, this use of adverbs reveals an interesting conclusion for the first female Doctor: compared to her predecessors who were largely explaining the world to their companions, the Thirteenth Doctor is more likely to engage in a discussion that may lead to her questioning hypotheses of her team or confirming their intuition and reasoning.</p>
<p>This is where knowledge of the audiovisual material and the whole corpus is helpful in the interpretation of the results: of the five New Who Doctors who struggle with posttraumatic stress disorder<a class="footnote-ref" href="#gibbs2013"> [gibbs2013] </a>caused by their regeneration, loss of home planet and subsequent companions, the Thirteenth Doctor is the one who healed best and looks forward to a major change in her attitude. In the past, through travels with various companions, the Doctor often relied on their help, but at the end of the day the higher (intellectual) position of the Doctor was always clear. The last season shows the Doctor who chooses to engage into a team relationship rather than create a strong bond with an individual or duo of characters, and to give them more space for their own agenda. She takes on three companions (and only one of them is a young woman, which was a given for her predecessors), and while at various points of her introductory season some of them seem to be more important than others, overall they have about the same number of lines per episode and (which was not measured quantitatively) seem to have about the same amount of screen time. Altogether the companions speak about 30% of all lines per episode, almost matching the part of the Doctor (~35%), and this is the highest ratio of participation of the companions in the New Who, the most talkative of whom rarely surpassed half of the lines of the Doctor during the Davies era, and 25% under Moffat.</p>
<p>The keywords obtained in the analysis also show the Thirteenth Doctor to be quite tech-savvy, even compared to the Tenth Doctor who was famous for his technobabble such as “This is my timey-wimey detector. It goes ding when there&rsquo;s stuff” (Blink, 3x10). She hasreadings,signals,etc. Finally, her list includeskill,killing,andweapons,and whilefightingandkillingare characteristic for Davies when contrasted with Moffat, the Thirteenth Doctor is the one whom these words distinguish the most. All Doctors are pacifist and opposing violence, and the show generally avoids showing death of people, even though the Doctor has to die to regenerate. Already the Moffat tenure showed some relaxation of this rule (there is a recurring fan joke saying he was never able to permanently kill off a character), frequently using death by sacrifice as a plot development tool, only to later cancel it by introduction of a workaround. The Thirteenth Doctor deals with death much more often – it concerns both major characters and random people, and it is not justified by sacrifice; in fact, it may seem almost accidental, as when a Tzim-Sha warrior kills an elderly security guard peacefully doing his watch in 11x01. The most recent Doctor and hergangfight with cruel creatures andpeople killingon a regular basis.</p>
<p>Combined, observed differences between the most recent female and the earlier male regenerations seem to be related more to the change of the mode fromlone geniustoteam leaderrather than building the character according to traditional gender roles. Considering social-emotional keywords, Thirteenth Doctor seems to be most similar to Tenth and Eleventh. Interestingly, contrastive analysis of Davies and Moffat Doctors also revealed that the former has a preference towards social sphere of life (words such asmother,family,but alsoalone,human), while the latter is distinguished by more verbs (e.g.feel,shut,forget,talking), and expressive interjections.</p>
<h2 id="5-conclusions">5. Conclusions</h2>
<p>This study allowed for automatic detection of creative forces that have a driving influence on the development of the Doctor Who TV show. It shows the basic distinction between Classic and New series and various modes of operation within them. The results of word frequency analyses show that the change the show underwent at the time of its reinvention in 2005 brought a major shift in its textual structure: while the Classic series seems to be more topic- or regeneration-oriented, the New series show a strong authorial signal of the showrunners, with the two longest-running ones being the most distinct.</p>
<p>The development of the show proceeds in a slightly different way when considering all dialogue lines rather than exclusively the lines of the protagonist. In the latter case, the Classic series exhibits well-defined communities for the first four regenerations, with this pattern breaking only for the last three Doctors, coinciding with a slow decline in the popularity of the show. In case of New Who, only Thirteenth Doctor clusters slightly apart, and the remaining four regenerations form two communities responding to showrunners creating respective regenerations. A closer analysis of the words distinguishing this first female Doctor from her male predecessors revealed that she is more of a team player who uses a higher ratio of words indicating dialogue involving exchange of opinions and cooperation. This strongly suggests that such a distinction has less to do with traditional gender perception of women and more with a more democratic attitude towards her companions.</p>
<p>While so far stylometry has rarely been used for more detailed studies of television discourse, the conducted contrastive analysis with Craig’s Zeta produced results allowing for similar analysis as those obtained with Wordsmith by other scholars such as Bednarek, likely because they both also rely on algorithms of keyword detection. Furthermore, the obtained insight into authorial structures suggests that, at least in the case of some series, the television language may not be as heavily conventionalized as it is generally thought to be, and may bear quite significant stylistic markers of particular writers, which makes for an important point to consider while building a corpus for the purpose of examining general linguistic features of television language.</p>
<p>It may seem that a quantitative analysis resulting mostly in confirmation of observations made in qualitative analysis is pointless. However, reaching the same conclusions with different means supports the usefulness and validity of such methods, making an argument for their employment to problems exceeding possibilities of close reading, such as studies of much larger series of whole television genres, and granting that observations deducted via somewhat more intuition-driven and human perception-based methods stand. The latter is especially important for studies related to popular culture, in the light of<a href="#andersen2012">Tore Rye Andersen&rsquo;s (2012)</a>hypothesis (as adapted to television discourse by<a href="#jensen2017">Jensen 2017</a>) that scholars relying solely on qualitative analysis are at greater risk of being unwillingly influenced by extensive authorial paratexts and marketing materials accompanying highly promoted works.</p>
<p>The use of stylometry for study of television dialogue requires carefulness and will certainly not be an attractive method in all kinds of studies. It should also be considered that, as explained, Doctor Who is fairly unique in many ways, which means that using similar methods with other data, and perhaps payng attention to other factors while doing so, will be needed to provide more final opinions. However, given that stylometry proved useful in various types of the analysis of Doctor Who, I dare express the hope that it can offer valid insight into stylistic relations inter and intra other works, and that hopefully with the further development of computer vision and speaker diarization methods it will soon be possible to compare the similarities between works on textual, visual and audio levels.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>I would like to thank the editorial team and the reviewers for their valueable feedback. My gratitude also goes to Jan Rybicki for his inspiring this study a few years back, and to him and Maciej Eder for consulting the project and the text of this paper. The study was conducted as part of the Large-Scale Text Analysis and Methodological Foundations of Computational Stylistics project (SONATA-BIS 2017/26/E/HS2/01019) funded by the Polish National Science Center (NCN), for whose support I am very grateful.</p>
<ul>
<li id="andersen2012">Andersen, T.R. “Judging by the Cover” . _Critique: Studies in Contemporary Fiction_ 53 (2012): 251–278.<a href="https://doi.org/10.1080/00111619.2010.484038">https://doi.org/10.1080/00111619.2010.484038</a>
</li>
<li id="arnold2017">Arnold, T., Tilton, L. “Distant Viewing: Analyzing Large Visual Corpora” . _Digital Scholarship in the Humanities_ (2017).
</li>
<li id="bateman2014">Bateman, J., Wildfeuer, J. “A multimodal discourse theory of visual narrative” . _Journal of Pragmatics_ , Vol. 74 (2014): 180-208.<a href="https://doi.org/10.1016/j.pragma.2014.10.001">https://doi.org/10.1016/j.pragma.2014.10.001</a>
</li>
<li id="bateman2011">Bateman, J.A., Schmidt, K.-H. _Multimodal Film Analysis: How Films Mean_ , Routledge Studies in Multimodality. Routledge (2011).
</li>
<li id="bednarek2018">Bednarek, M. _Language and Television Series: A Linguistic Approach to TV Dialogue. Cambridge Universit_ y Press, Cambridge (2018).
</li>
<li id="bednarek2010">Bednarek, M. _The Language of Fictional Television: Drama and Identity_ . Continuum, London/New York (2010).
</li>
<li id="bednarekz2018">Bednarek, M., Zago, R.. Bibliography of linguistic research on fictional (narrative, scripted) television series and films/movies, version 2 (2018). Available at<a href="http://unipv.academia.edu/RaffaeleZago">http://unipv.academia.edu/RaffaeleZago</a>[date of last access: 07.05.2020]
</li>
<li id="benatti2015">Benatti, F., Tonra, J. “English Bards and Unknown Reviewers: a Stylometric Analysis of Thomas Moore and the Christabel Review” . _Breac: A Digital Journal of Irish Studies_ , 4 (2015).
</li>
<li id="bhargava2013">Bhargava, M., Mehndiratta, P., Asawa, K. “Stylometric Analysis for Authorship Attribution on Twitter” . In: Bhatnagar, V., Srinivasa, S. (Eds.), _Big Data Analytics, Lecture Notes in Computer Science_ . Springer International Publishing (2013): 37–47.
</li>
<li id="blondel2008">Blondel, V.D., Guillaume, J.-L., Lambiotte, R., Lefebvre, E. “Fast unfolding of communities in large networks” . _Journal of Statistical Mechanics: Theory and Experiment Volume_ (2008)<a href="https://doi.org/10.1088/1742-5468/2008/10/P10008">https://doi.org/10.1088/1742-5468/2008/10/P10008</a>
</li>
<li id="burrows2007">Burrows, J. F. “All the way through: testing for authorship in different frequency strata” . _Literary and Linguistic Computing_ , 22(1) (2007), 27-48.
</li>
<li id="burrows2012">Burrows, J. “A Second Opinion on “Shakespeare and Authorship Studies in the Twenty-first Century” ” . _Shakespeare Quarterly_ 63 (2012), 355–392.
</li>
<li id="burrows2002">Burrows, J. “ Delta : a Measure of Stylistic Difference and a Guide to Likely Authorship,”   _Literary and Linguistic Computing_ , 17(3), (2002), 267–287.
</li>
<li id="busso2017">Busso, L., Vignozzi, G. “Gender Stereotypes in Film Language: A Corpus-Assisted Analysis” . In: Basili, R., Nissim, M., Satta, G. (Eds.), _Proceedings of the Fourth Italian Conference on Computational Linguistics CLiC-It 2017_ . Accademia University Press, (2017): 71–76.<a href="https://doi.org/10.4000/books.aaccademia.2367">https://doi.org/10.4000/books.aaccademia.2367</a>
</li>
<li id="cafiero2019">Cafiero, F., Camps, J.-B. “Why Molière most likely did write his plays”  _Science Advances_ 5, (2019)<a href="https://doi.org/10.1126/sciadv.aax5489">https://doi.org/10.1126/sciadv.aax5489</a>
</li>
<li id="chapman2014">Chapman, J. “Fifty Years in the TARDIS: The Historical Moments of Doctor Who, Fifty Years in the TARDIS: The Historical Moments of Doctor Who” . _Critical Studies in Television_ 9, (2014): 43–61.
</li>
<li id="choinski2019">Choiński, M., Eder, M. and Rybicki, J. “Harper Lee and other people: a stylometric diagnosis” . _Mississippi Quarterly_ , 70(3), (2019) forthcoming.
</li>
<li id="craig2009">Craig, H. and Kinney, A. F. eds. _Shakespeare, Computers, and the Mystery of Authorship_ . Cambridge: Cambridge University Press (2009).
</li>
<li id="davies2008">Davies, T R., Cook, B. _Doctor Who:The Writer’s Tale_ . BBC Books (2008).
</li>
<li id="eder2016a">Eder, M. “Rolling stylometry” . _Digital Scholarship in the Humanities_ , 31(3) (2016): 457-469.
</li>
<li id="eder2011">Eder, M. “Style-markers in authorship attribution: a cross-language study of authorial fingerprint” . _Studies in Polish Linguistics_ , 6 (2011): 99-114.
</li>
<li id="eder2016">Eder, M., Rybicki, J., Kestemont, M. “Stylometry with R: A Package for Computational Text Analysis” . _The R Journal_ 8, (2016): 107–121.
</li>
<li id="eder2017">Eder, M. “Visualization in stylometry: Cluster analysis using networks” . _Digital Scholarship Humanities_ 32, (2017): 50–64.<a href="https://doi.org/10.1093/llc/fqv061">https://doi.org/10.1093/llc/fqv061</a>
</li>
<li id="edwards2015">Edwards, O.D. “ As We See, So We Learn : Doctor Who as Religious Education.”  _Implicit Religion_ 18.4, (2015): 527-40.10.
</li>
<li id="edwards2014">Edwards, V.L. “Fifty Years of Science Fiction Television” . _Administrative Theory & Praxis_ 36.3, (2014): 373-97.
</li>
<li id="evert2017">Evert, S., Proisl, T., Jannidis, F., Reger, I., Pielström, S., Schöch, C., Vitt, T. “Understanding and explaining Delta measures for authorship attribution” . _Digital Scholarship Humanities_ 32, ii4–ii16 (2017)<a href="https://doi.org/10.1093/llc/fqx023">https://doi.org/10.1093/llc/fqx023</a>
</li>
<li id="finer2004">Finer, A., Pearlman, D. _Starting Your Television Writing Career: The Warner Bros. Television Writers Workshop Guide_ . Syracuse University Press (2004).
</li>
<li id="gibbs2013">Gibbs, A. “ Maybe that's what happens if you touch the Doctor, even for a second : Trauma in Doctor Who” . _Journal of Popular Culture_ , 46, (2013): 950–972.
</li>
<li id="gorski2014">Górski, R., Eder, M. and Rybicki, J. “Stylistic fingerprints, POS tags and inflected languages: a case study in Polish” . _Qualico 2014: Book of Abstracts_ (2014): 51-53.
</li>
<li id="hartley2004">Hartley, J. “From Republic of Letters to Television Republic? Citizen readers in the era of broadcast television” . In: Spigel, L. & Olsson, J. (Eds.) _Television after TV: Essays on a Medium in Transition_ . Duke University Press, (2004): 386-417.
</li>
<li id="hills2013">Hills, M. _New Dimensions of Doctor Who: Adventures in Space, Time and Television: Exploring Space, Time and Television_ . I.B. Tauris & Co. Ltd., (2013).
</li>
<li id="hills2010">Hills, M. “Triumph of a Time Lord: Regenerating Doctor Who in the Twenty-First Century” . I.B. Tauris & Co. Ltd., (2010).
</li>
<li id="holobutr2018">Hołobut, A., Rybicki, J. “Pride and Prejudice and Programming: A Stylometric Analysis” . In: Raw, L. (Eds.), _Adapted from the Original. Essays on the Value and Values of Works Remade for a New Medium_ . McFarland & Company, Inc., Jefferson, North Carolina (2018).
</li>
<li id="holobut2016">Hołobut, A., Rybicki, J. Woźniak, M. “Stylometry on the Silver Screen: Authorial and Translatorial Signals in Film Dialogue” . Digital Humanities 2016: Conference Abstracts. Kraków: Jagiellonian University (2016).
</li>
<li id="holobutw2018">Hołobut, A., Woźniak, M. _Historia na ekranie: Gatunek filmowy a przekład audiowizualny_ . Wydawnictwo Uniwersytetu Jagiellońskiego (2018).
</li>
<li id="hooever2012">Hoover D.L. 2012. “The Rarer They Are, the More There Are, the Less They Matter” , Digital Humanities Conference Abstracts, Hamburg, 218–220.
</li>
<li id="jensen2017">Jensen, M. “ From the Mind of David Simon : A Case for the Showrunner Approach” . _Series - International Journal of TV Serial Narratives_ 3, (2017): 31–42.<a href="https://doi.org/10.6092/issn.2421-454X/7610">https://doi.org/10.6092/issn.2421-454X/7610</a>
</li>
<li id="juola2011">Juola, P., Ryan, M., Mehok, M. “Geographically Localizing Tweets Using Stylometric Analysis” . In: _Proceedings of the American Association of Corpus Linguistics 2011_ (2011).
</li>
<li id="kestemont2014">Kestemont, M. “Function Words in Authorship Attribution. From Black Magic to Theory?”  _Proceedings of the 3rd Workshop on Computational Linguistics for Literature (CLFL) (2014)_ , pp. 59–66.
</li>
<li id="kjell1994">Kjell, B. “Discrimination of authorship using visualization” . _Information Processing and Management_ , 30 (1) (1994): 141–50.
</li>
<li id="kozloff2000">Kozloff, S. _Overhearing Film Dialogue_ . University of California Press (2000).
</li>
<li id="lavik2015">Lavik, E. _Forfatterskap i TV-drama_ . Universitetsforlaget (2015).
</li>
<li id="martin2013">Martin, B. _Difficult Men_ . Faber & Faber (2013).
</li>
<li id="mckenna1999">McKenna, Wayne, John Burrows, Alexis Antonia. “Beckett's Trilogy: Computational Stylistics and the Nature of Translation” . _RISSH_ , 35 (1999), pp. 151-171.
</li>
<li id="mittell2017">Mittell, J. _Narrative Theory and Adaptation_ . Bloomsbury (2017).
</li>
<li id="mittell2015">Mittell, J. _Complex TV: The poetics of contemporary television storytelling_ . NYU Press (2015).
</li>
<li id="moretti2000">Moretti, F. “Conjectures on World Literature” . _New Left Review_ 1(2000): 54–68.
</li>
<li id="ochab2019">Ochab, J. K., Byszuk, J., Pielström, S. and Eder, M. “Identifying similarities in text analysis: hierarchical clustering (linkage) versus network clustering (community detection)” . _Digital Humanities 2019: Book of Abstracts_ (2019)<a href="https://dev.clariah.nl/files/dh2019/boa/0981.html">https://dev.clariah.nl/files/dh2019/boa/0981.html</a>.
</li>
<li id="plechac2017">Plecháč, P., Flaišman, J. “Problém Barák–Neruda z pohledu současné stylometrie” . _Ceska Literatura_ 65, (2017): 743–769.
</li>
<li id="richardson2010">Richardson, K. _Television Dramatic Dialogue: A Sociolinguistic Study_ . Oxford (2010).
</li>
<li id="rybicki2013">Rybicki, J. and Heydel, M. (2013).  “The stylistics and stylometry of collaborative translation: Woolf’s “Night and Day” in Polish” .  _Literary and Linguistic Computing_ , 28(4): 708-17.
</li>
<li id="schler2006">Schler, J., Koppel, M., Argamon, S., Pennebaker, J. “Effects of Age and Gender on Blogging” . In: _AAA 1 Spring Symposium on Computational Approaches for Analyzing Weblogs_ (2006): 6.
</li>
<li id="schmidt2015">Schmidt, B.M. “Plot arceology: A vector-space model of narrative structure” . In: _2015 IEEE International Conference on Big Data (Big Data)_ . Presented at the 2015 IEEE International Conference on Big Data (Big Data), (2015): 1667–1672.<a href="https://doi.org/10.1109/BigData.2015.7363937">https://doi.org/10.1109/BigData.2015.7363937</a>.
</li>
<li id="stamatatos2009">Stamatatos, E., “A survey of modern authorship attribution methods” . _Journal of the Association for Information Science and Technology_ 60, (2009): 538–556.
</li>
<li id="stamatatos2013">Stamatatos, E. “On the Robustness of Authorship Attribution Based on Character N-gram Features” , 21 J. L. & Pol'y (2013).
</li>
<li id="steiner2015">Steiner, T. “Steering the Author Discourse: The Construction of Authorship in Quality TV, and the Case of Game of Thrones” . _Series - International Journal of TV Serial Narratives_ 1, 181 (2015).<a href="https://doi.org/10.6092/issn.2421-454X/5903">https://doi.org/10.6092/issn.2421-454X/5903</a>
</li>
<li id="tulloch1983">Tulloch, J., Alvarado, M. _Doctor Who: The Unfolding Text_ . MacMillan (1983).
</li>
<li id="vickers2011">Vickers, B. “Shakespeare and Authorship Studies in the Twenty-first Century” . _Shakespeare Quarterly_ 62 (2011): 106–142.
</li>
<li id="wildfeuer2014">Wildfeuer, J. “Coherence in Film: Analysing the Logical Form of Multimodal Narrative Discourse” . In: _Multimodal Epistemologies: Towards an Integrated Framework_ , Routledge Studies in Multimodality (2014): 260–274.
</li>
<li id="zyl2016">Zyl, M. van, Botha, Y. “Stylometry and characterisation in The Big Bang Theory” . _Literator_ 37, 11 (2016).<a href="https://doi.org/10.4102/lit.v37i2.1282">https://doi.org/10.4102/lit.v37i2.1282</a>
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Supplementary materials mentioned in this article are available at<a href="https://github.com/JoannaBy/The-Voices-of-Doctor-Who">https://github.com/JoannaBy/The-Voices-of-Doctor-Who</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>For just one instance, see Craig and Kinney’s <em>Shakespeare, Computers, and the Mystery of Authorship</em> (2009), scathingly reviewed by<a href="#vickers2011">Vickers (2011)</a>yet defended by<a href="#burrows2012">Burrows (2012)</a>and<a href="#hoover2012">Hoover (2012)</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>As of 2018, the Doctor new regeneration is female. This new Doctor, played by Jodie Whitaker, identifies as a woman while the past 12 regenerations were played by men, which is why I refer to the character using singular they/their/them pronouns unless I mean a specific regeneration.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Subtitling standards are discussed in many papers and fora, e.g. a brief summarization here:<a href="https://translationjournal.net/journal/04stndrd.htm">https://translationjournal.net/journal/04stndrd.htm</a>As a side note, the use of subtitles being a translation from the original for an analysis of film/series content makes things even more complicated, highly criticised in both translation and film studies, with Sarah Kozloff explaining: “Subtitles only translate a portion of the spoken text, and only that portion that the subtitler has decided is most important. This filters out emphases that may be unique to the film or to that national cinema. Repetitions, interruptions, slang, curses, antiquated diction, regional accents, of course, are all lost in subtitles” <a class="footnote-ref" href="#kozloff2000"> [kozloff2000] </a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Collected from<a href="http://www.chakoteya.net/DoctorWho/index.html">http://www.chakoteya.net/DoctorWho/index.html</a>[last access: 10th Jan 2019]&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p><a href="https://thescriptlab.com/features/screenwriting-101/10415-television-writing-wisdom-from-doctor-who-showrunner-and-script-editor/">https://thescriptlab.com/features/screenwriting-101/10415-television-writing-wisdom-from-doctor-who-showrunner-and-script-editor/</a>[access: 07.05.2020]## Bibliography&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Unknowable Facts and Digital Databases: Reflections on the Women Film Pioneers Project and Women in Film History</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000528/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000528/</id><author><name>Sarah-Mai Dang</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Apart from information science, the term database is used very heterogeneously and as a rather elastic concept. In the broader scholarly discourse, databases mean both collections of data in general and specific technologies and processes of gathering and accessing information in particular, as media studies scholar Marcus Burkhardt observes in his book about the history of databases<a class="footnote-ref" href="#burkhardt2015"> [burkhardt2015] </a>. In this broader sense, digital databases are technically new, but they remain in the long-standing media practice of collecting and administrating information by libraries, museums, archives, encyclopedia, registers among others<a class="footnote-ref" href="#burkhardt2015"> [burkhardt2015] </a>. Databases serve to store, organize, search, query and retrieve information. As it is explained in the UCLA Digital Humanities coursebook, “[d]atabases come in many forms, relational, object-oriented, and so on. Databases can be described by their contents, their function, their structure, their appearance, or other characteristics” <a class="footnote-ref" href="#drucker2014"> [drucker2014] </a>. Similarly, English studies scholar Stephen Ramsay points out the various aspects of how we can approach databases. According to him, “the inclusion of certain data (and the attendant exclusion of others), the mapping of relationships among entities, the often collaborative nature of dataset creation, and the eventual visualization of information patterns, all imply a hermeneutics and a set of possible methodologies that are themselves worthy objects for study and reflection” <a class="footnote-ref" href="#ramsay2004"> [ramsay2004] </a>.</p>
<p>In order to understand how digital technologies affect the production of knowledge in the context of film history, this article discusses the role of digital databases. In doing so, it focuses on the <em>Women Film Pioneers Project</em> ( <em>WFPP</em> ).<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> The WFPP is a collaborative website which aggregates digital research and provides archival and bibliographical information on women workers in film industries. Considering the current debates in feminist historiography, one of the biggest challenges for film and media historians concerns the appropriate acknowledgement of the many blind spots – theunknowabilityof history – while making historical records and research results accessible, discoverable and comprehensible. In this article, it is made the case that due to their openness and variable use, digital databases, such as the <em>Women Film Pioneers Project</em> , seem to be perfectly suited to respond to this challenge.</p>
<h2 id="databases-and-film-and-media-history">Databases and film and media history</h2>
<p>In the field of film and media history, digital databases are often described with respect to the potential opportunities of enhancing research by making sources visible that have been hitherto overlooked. One media studies project which is especially interesting in this context is the online platform <em>Media History Digital Library</em> (MHDL),<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> founded by archivist and historian David Pierce and led by media studies scholar Eric Hoyt. The freely accessible database, searchable by means of the platform Lantern, features digitized books and magazines on film, broadcasting, and recorded sound that are no longer protected by copyright or that have been licensed to share.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> The collections can be used in many ways. For instance, by comparing aggregated data of the MHDL to the JSTOR-Service <em>Data for Research</em> (DFR),<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> we can see that canonical film magazines like <em>Variety</em> or <em>Photoplay</em> are relatively often quoted in contrast to other publications which were also quite popular at those times<a class="footnote-ref" href="#hoyt2014"> [hoyt2014] </a>. This finding raises the specific question what has made <em>Variety</em> so popular among scholars and sparks a discussion about more general issues such as citation politics, bias and other reasons for neglection and marginalization.</p>
<p>Digital databases which store data at a large scale can enable film and media historians to ask new questions or to ask questions differently. They allow for observing trends in a broader context and perhaps discover new conjunctions between sources. For example, with the help of <em>Project Arclight</em> ,<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> a collaborative data mining and visualization tool initiated by Hoyt and cultural and media studies scholar Charles Acland, we can measure word frequencies in historic trade papers and fan magazines included in the MHDL. It allows us to explore developments in film and media history over a longer period of time. At the same time, the project facilitates direct access to a particular issue we might want to study more closely by providing links to the content in the <em>Internet Archive</em> .<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Thus, the application allows us to zoom in and out while retaining the entities’ integrity and historical context.</p>
<p>Databases can also help us to validate, refute or differentiate hypothesis. The online platform <em>Early Cinema History Online</em> (ECHO),<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> for instance, provides further evidence that at the beginning of the 20th century, a relatively large number of women in the US-American film industry had worked as scriptwriters<a class="footnote-ref" href="#long2016"> [long2016] </a>. In order to come to this conclusion or rather to affirm existing research, media historian Derek Long, who created this filmographic database, compared the <em>American Film-Index</em> credits of 35,000 films which appeared in the US from 1908 to 1920 to the female names gathered in the <em>Women Film Pioneers Project</em> .</p>
<p>Digital databases can foster new perspectives and insights. However, while they can enhance research by making historic developments visible on a meta level, they seem unsuited for showing ambiguities, contingencies and contradictions inherent to film history. A subjective, personal approach to the past including speculation and imagination – methods central to feminist historians who strongly oppose the concept of objective history – seems to be rather impossible. There is also the risk of favoring an institutionalized meta history to individual micro stories, as historian Kathryn M. Hunter stresses in her reflections on evidence and silence with regard to digitization<a class="footnote-ref" href="#hunter2017"> [hunter2017] </a>. In the context of empirical research, questions around the issues of visibility, absence, and evidence arise with regard to the “discursive power of records and archives,” where, according to Hunter, “non-mention was not simply invisibility but erasure” <a class="footnote-ref" href="#hunter2017"> [hunter2017] </a>. In view of that notion, how can we document individual contributions in history in the absence of historical documents? Are databases able to account for what may not be known and why it remains unknown?</p>
<h2 id="theunknowabilityof-history">Theunknowabilityof history</h2>
<p>It is a truism that the more we come to know about a particular subject, the more we realize how much we do <em>not</em> know. When it comes to history, this awareness has become a key issue of feminist debate: How can we identify and include blind spots when trying to reconstruct the past? In what way can we narrate ellipsis and absences while avoiding the pitfall of implicitly promising to grasp thewholestory once enough information will be gathered? How is it possible to explore unchartered territory when faced with the lack of historical objects?</p>
<p>The discursive formation of knowledge has been a central concern of feminism ever since. In the field of film history, the question of how to reconstruct the past while taking into account the contingent and transformative nature of history has become equally important for scholars (e.g.,<a href="#gledhill2015a">Gledhill and Knight 2015a</a>) and filmmakers (e.g.,<a href="#dang2020b">Dang and Akkermann 2020</a>). In her book about women in the silent film industries,Pink-Slipped, film historian Jane Gaines quotes famous novelist Gertrude Stein wondering about how historians “can write so knowingly about what they cannot have known” (Stein 1993 [1935], quoted in<a href="#gaines2018">Gaines 2018, p. 1</a>). Being aware of the imaginary and often intimate relationship between the researcher and their subject<a class="footnote-ref" href="#dallasta2015"> [dallasta2015] </a>, Gaines asks, following Stein: “Is there any other way to say without claiming to know?” <a class="footnote-ref" href="#gaines2018"> [gaines2018] </a>. She prompts the fundamental question of how we can narrate past events if we did not happen to be “there.” Nowadays, film history, “as both practice and product,” can hardly be grasped as a grand, coherent and evolutionary narrative but rather as an aggregation of local “micro histories” based on fragmentary, sometimes contradictory knowledge<a class="footnote-ref" href="#sobchack2000"> [sobchack2000] </a>. Yet, how are we able todohistory with respect to the “precarious relations” between the present moment and the historical past, the very past that we proceed to make<a class="footnote-ref" href="#gaines2018"> [gaines2018] </a>? In short, how can we grasp the “historical conditions of unknowability ” <a class="footnote-ref" href="#gaines2018"> [gaines2018] </a>?</p>
<p>Until only some time ago, it used to be common knowledge in film studies that women played only a minor part in the early years of filmmaking.Women’s workwas dismissed as menial labor, if at all accounted for, notwithstanding the skills of generations of women which have been essential to the film industry<a class="footnote-ref" href="#hill2016"> [hill2016] </a>. Still today, as pointed out by film and media studies scholars Shelly Stamp, Yvonne Tasker and Gaines at past <em>Doing Women’s Film and Television History Conference</em> (DWFTHC) in Lancaster in 2018, women’s contributions continue to be marginalized in footnotes or text boxes. At the same time, for about three decades now, more and more scholars have begun to explore the achievements of innumerous women in early cinema – not only as actresses before the camera, but also behind the scenes, as cutters, scriptwriters, producers, hand-colorers, operators, and directors among other indispensable occupations (e.g.<a href="#bean2002">Bean and Negra 2002</a>). From their research we have learned that women have had a surprisingly significant impact on film production all over the world from the very beginning of film history. Women have worked and collaborated globally, not merely in North America and Europe but also in Latin America, Asia, and the Middle East<a class="footnote-ref" href="#gaines2009"> [gaines2009] </a>. These unexpected findings have led historians to challenge historiography fundamentally. Concepts such asauthorship,agency,director,narration,canon,national cinema,evidenceandfactsare thereby critically scrutinized. As books such as <em>Reclaiming the Archive: Feminism and Film History</em> <a class="footnote-ref" href="#callahan2010"> [callahan2010] </a>and other recent monographs, anthologies and articles show, history and theory are no longer regarded as binary oppositions. Methodological and epistemological questions have become essential for feminist film and media historians. Telling a story differently rather than telling a different story has become a primary goal in the field of feminist film historiography. With the increasing digitization of objects, research outcomes and scholarly media practices, the interest in digital data is growing as well – data that “can be transformed, analyzed, and acted upon computationally” <a class="footnote-ref" href="#schoch2013"> [schoch2013] </a>.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> In view of this fact, the question of how to make the multifaceted influence of women visible while accounting for theunknowabilityis gaining particular importance, since digital data adds another methodological and epistemological layer of complexity to the relationship between the researchers and their subject<a class="footnote-ref" href="#schoch2013"> [schoch2013] </a>.</p>
<h2 id="the-women-film-pioneers-project">The Women Film Pioneers Project</h2>
<p>The <em>Women Film Pioneers Project</em> (WFPP) is probably one of the most well-known online platforms in the field of women in film history.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> Originally planned in the 1990s to be a multi-volume book set, it was launched in September 2013 by film theorists Gaines, Radha Vatsal, and Monica Dall’Asta as a freely accessible collaborative digital resource. Its goal is to challenge the establishedgreat male pioneers of cinemaby documenting the high influence of women who pursued a variety of professions in the silent film industries. The website serves as a database of women film pioneers worldwide. As of December 2018, it contains 276 career profiles (including images and sometimes film clips) written by scholars, curators, and archivists. The platform facilitates access to Internet sources and aggregates archival and bibliographical information on women workers as well as references for further historical research both online and offline. It features also a couple of overview essays.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>
<p>Though lots of historical records got irretrievably lost, the project seeks to foreground that “[w]hat we assume never existed is what we invariably find” <a class="footnote-ref" href="#gaines2020"> [gaines2020] </a>. As discussed by several feminist film historians, due to the focus on the representation of women in film during the 1970s and 1980s, for a long time it had been difficult to imagine that women had a huge impact on early cinema at a wide range of capacities<a class="footnote-ref" href="#dang2018"> [dang2018] </a>. In order to shift the attention towards what has been unimaginable, the WFPP points to the variety of sources which document women’s work. Instead of focusing on the lack of material, it emphasizes the abundance of material assumed to be non-existent. This approach reminds us that, as film studies scholars Christine Gledhill and Julia Knight have emphasized,factsdo not tell themselves<a class="footnote-ref" href="#gledhill2015b"> [gledhill2015b] </a>. Their existence depends on the questions we ask and on narrative conventions, on preservation politics, archival practices and, as I would like to emphasize, aesthetics of access – the various ways in which resources are presented and perceived by the users.</p>
<p>Media scholar Lev Manovich, whose reflections on the relation between database and narration has had a high impact in media and cultural studies, suggests to look at a database from the user’s experience in a more general sense. Unlike in information science, where a database is largely known as the organization of data and information, he defines the database as a cultural form of expression that fundamentally shapes our perception of the world in the computer age<a class="footnote-ref" href="#manovich1999"> [manovich1999] </a>. Contrary to the narrative which follows a cause-and-effect trajectory, according to Manovich, the database is open-ended and does not represent a certain order. A database represents a potentially growing collection of diverse elements such as texts, videos, images, and hyperlinks, which can be accessed in various ways: via viewing, navigating and searching<a class="footnote-ref" href="#manovich1999"> [manovich1999] </a>. Thus, a database offers a great deal of potential ways of meaning-making.</p>
<p>On the basis of these distinctions, Manovich imagines a combat between database and narrative, whereby each as a form of expression claims an “exclusive right to make meaning out of the world” <a class="footnote-ref" href="#manovich1999"> [manovich1999] </a>. Interestingly, even though Manovich foregrounds the different ontologies, purposes and histories of database and narrative, when reflecting on cinema, the clear-cut distinction between database and narrative begins to dissolve. His analysis of Peter Greenaway’s and Dziga Vertov’s films reveal that his concern is narration – produced by databases. Praising the specific editing style of the legendary film <em>Man with a Movie Camera</em> (1929), Manovich ennobles Vertov to be a major “database filmmaker” <a class="footnote-ref" href="#manovich1999"> [manovich1999] </a>. It is remarkably though that in fact, it was Vertov’s wife, Elizaveta Svilova, who did all the editing, as Manovich mentions on the site. This is only one of many cases where the historiographical narrative of film editing effaces women’s work<a class="footnote-ref" href="#pearlman2018"> [pearlman2018] </a>.</p>
<p>Regardless of Manovich’s inconsistent and rather metaphorical use of the database and his problematic perception of cinema as a primarily linear medium (as opposed to time-based and spatial), his approach can be fruitfully used for exploring the <em>Women Film Pioneers Project</em> . Following Manovich’s observations on the database logic with regard to cinema, a database does not necessarily represent an opposing model to narrative but can rather be viewed as a horizon of possibilities for narration in context of digital media technologies<a class="footnote-ref" href="#burkhardt2015"> [burkhardt2015] </a>. Considering the open-endedness and variable use of databases, the WFPP seems to be perfectly suited to facilitate the reconstruction of the past while taking into account the contingencies and contradictions of history. But how exactly does it shape our understanding of the women film pioneers’ influence? What kind of usage does it foster? Which questions does the website evoke and which unexpected answers can we find? To what extent does it facilitate narration?</p>
<p>As Manovich, in this article, I focus on digital database as a venue of representation and on the possible engagement of the user. Important as it is, I will leave aside the question of what lies beneath the interface, hence the technical aspects of the software which translates the invisible data into perceivable media constellations<a class="footnote-ref" href="#burkhardt2015"> [burkhardt2015] </a>. While Burkhardt rightly emphasizes that databases provide no unconditional openness but are dependent on the underlying management system<a class="footnote-ref" href="#burkhardt2015"> [burkhardt2015] </a>, I think that in addition to a technically informed analysis of programs and algorithms we also need to pay attention to the ‘content’ as well as its digital representation and the users’ media practices.</p>
<p>The type of data that is collected and the way in which it is presented, effects the potential use of it. Data can be objective but not neutral, databases can serve for research, arguments and interpretation. Organizing data by different categories and metadata, we interpret by ascribing specific meaning to discrete elements which can then serve to support an argument. One could also argue that the creation of data is always already an interpretation because we try to make sense out of the world. And “interpretation invokes narrative to achieve dramatic impact and significance,” N. Katherine Hayles contends in her article on narrative and database as “natural symbionts” <a class="footnote-ref" href="#hayles2007"> [hayles2007] </a>. In this sense, the interpretation – and imagination – of relations revealed by database queries are already a form of x meaning-making as part of a narrative<a class="footnote-ref" href="#hayles2007"> [hayles2007] </a>. Following this line of argument, it can reasonably be concluded that a database implies three levels of interpretation/narrative: 1) when producing data, 2) when categorizing data, 3) when organizing and/or linking data. That said, “databases are powerful rhetorical instruments that often pass themselves off as value-neutral observations or records of events, information, or things in the world” <a class="footnote-ref" href="#drucker2014"> [drucker2014] </a>.</p>
<p>Although digital databases appear to hold complete collections and promise definite knowledge, they are in constant transformation. Yet, in doing so, they do not only grow, as Manovich and others have emphasized, but they can also shrink. Entries can be deleted, accidentally or on purpose, tables be removed, or links be broken. Databases require coherent data and continuous adjustment. By explaining the meaning of relational database model for humanities, however, Ramsay emphasizes the intellectual value also of inadequacies and inconsistencies. While, for example, the “terms we use to describe books in a bookstore (authors, works, publishers) and the relationships among them (published by, created by, published in) posses an apparent stability for which the relational model is ideally suited,” the “most exciting database work in humanities computing necessarily launches upon less certain territory.” He thereby thinks of uncertain relations expressed by a database, such asinfluenced by,resembles,is derived from. “If the database allows one to home in on a fact or a relationship quickly,” Ramsay notes, “it likewise enables the serendipitous connection to come forth.” In this sense, databases hold out “not merely of an increased ability to store and retrieve information about a particular domain but of a critical and methodological self-awareness” <a class="footnote-ref" href="#ramsay2004"> [ramsay2004] </a>.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of the WFPP homepage (<a href="https://wfpp.cdrs.columbia.edu/">https://wfpp.cdrs.columbia.edu/</a>), taken January 2019 (for illustrative purposes, the website’s format has been adjusted for this article).
        </p>
    </figcaption>
</figure>
<p>The WFPP’s homepage offers numerous but limited ways of accessing information (see Figure 1). On top, it features four main pathways which lead to the overview essays, the pioneers’ career profiles, a list of resources, and theaboutsection. Below, a box presents a list of links which refer to the women’s various occupations (producers, directors, co-directors, scenario writers, scenario editors, camera operators, title writers, editors, costume designers, exhibitors, and actresses). It stresses that women did not only work as actresses. Furthermore, there is one selected video embedded (for as of November 2018, a trailer on the recent restoration of <em>Shoes</em> (1916) by the leading female Hollywood director-screenwriter Lois Weber). In addition, the homepage highlights one pioneer (for as of November 2018, Brazilian director Cleo de Verberena). Besides these features, the homepage includes a news section, a newsletter subscription box, and a search field. It also provides information on how to contribute to the project, where to find further resources, and how to cite the website. The footer links to the WFPP social media presentation on Twitter and Facebook. The color scheme of the website encompasses shades of gray and purple. Though the featured video is placed in the center, the homepage does not really prioritize one element to another. Since there is no obvious pre-selection made by the editors, the user has to make their own choice about which path of inquiry to follow.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of the WFPP subpagepioneers(<a href="https://wfpp.cdrs.columbia.edu/pioneers/">https://wfpp.cdrs.columbia.edu/pioneers/</a>), taken January 2019.
        </p>
    </figcaption>
</figure>
<p>Theoccupationsection (accessible at the upper right) references the wide range of women’s contribution in the silent-era, whereas the subpagepioneersdemonstrates the abundance of women workers (see Figure 2). The collection is ordered alphabetically by default but can also be sorted by geography or occupation. Each selection can be viewed both in a tiled format (and thus in a more spacial arrangement) or as a list. Remarkably, the underlying management system does not distinguish between more or less popular pioneers. All the women appear simultaneously at once. Due to their diverse activities in different countries, the women appear repeatedly in multiple lists. For example, Lotte Reiniger (1899-1981) – who has, according to the website’s profile, “made over sixty films, of which eleven are considered lost and fifty to have survived” <a class="footnote-ref" href="#guerin2016"> [guerin2016] </a>– is listed as animator, assistant director, co-director, director, film actress, illustrator, screenwriter, and in the category of special effects. Apparently, she worked in Canada, Germany, Italy, and England. The relatively extensive entry on her work includes screenshots of her silhouette films, images of her activities, and YouTube clips. Moreover, it features a selected bibliography and a large filmography (including her unfinished work) as well as a list of additional sources. Acredit reportat the bottom of the entry describes the context of research for the profile and elaborates on the creation of the archival filmography.</p>
<p>What is interesting with regard to the relational database management system is how the website presents other pioneers related to Lotte Reiniger by occupation or geography. Below the entry follows a couple of lengthy lists of other women who worked as assistant directors, co-directors, directors etc. and also in Canada, Germany, Italy, and/or England. All sections (profile, bibliography, filmography, and relations) can be accessed directly via the sidebar and do not have to be read from top to bottom. Due to the great amount of data and the way it is presented, the website enables us to follow our own path of inquiry scanning for items of interest. The hypertext structure fosters a non-linear reading of the entries which makes it possible to discover unexpected conjunctures between women, occupations and places. Thus the database interface facilitates searching for detailed information on women pioneers as well as making serendipitous discoveries. In this regard, Ramsay is right in noting that databases are “not so much pre-interpretative mechanisms as para-interpretative formations” <a class="footnote-ref" href="#ramsay2004"> [ramsay2004] </a>.</p>
<p>In the case of the WFPP, the data is structured on a very basic level, which allows for a large number of potential findings. This complies with the editors’ goal to primarily foreground the high incidence of transnational women workers in early cinema without predetermining how to make sense of these facts. One might even argue that the contingent and transformative nature of history is reflected in the arrangement of data and also in each career profile. Different to encyclopedic entries which appear to provide all basic information needed, the profiles reflect upon the very conditions of historiography. The authors explain which historical sources have probably gotten lost and, above all, highlight the wealth of surviving material which has, however, not been retrieved yet, let alone examined.</p>
<p>The website invites users to undertake further research on each woman film pioneer. It lists 623 pioneers who have beenunhistoricizedto this point, followed by a number of occupations which were held by women but have remained generally unacknowledged (such as cashier, interpreter, supervisor)<a class="footnote-ref" href="#gaines2013b"> [gaines2013b] </a>. Potentially, everyone can contribute to the database. In doing so, authors must follow detailed instructions. Several guidelines and checklists serve to ensure that the entries comply with the website’s standards, for example with regard to writing style, citation format, historiographic resources. Each entry has to be consistent in order to provide a collection of highest possible data quality. Valuable knowledge requires reliable data about data sources. This is also important for sharing research with students and colleagues and other people interested. The bigger a collection becomes, the more pitfalls occur, for example misspellings, disparate attributions, or incoherent metadata. From our own personal experience we know how easily digital data can get lost by unsystematic filing or naming, or how it can be even erased unintentionally, sometimes with no chance of restoration. The discussion about the messiness of data, and what might be gained and what be lost when implementing standards, exceeds this article’s framework but is more relevant than ever regarding the rapid growth of digital data infrastructures.</p>
<p>Like archives, databases do not store complete collections. They are neither universal nor neutral. Instead, databases reflect personal habits, institutional conventions, intellectual frameworks and hence discursive power structures. The meaning and the structure of a database is inherently connected to the results produced by categorizing and filtering the data contained in it and the nature of its visualizing interface<a class="footnote-ref" href="#mcgann2007"> [mcgann2007] </a>. Thus, while we “celebrate the branching, rooting, rhizomic, proliferating quality of database” we need to also question the choices that have gone into the making of databases<a class="footnote-ref" href="#freedman2007"> [freedman2007] </a>and their front end design. On the one hand, the increasing amount of data available in the Internet enables us to gather information and make meaning out of the world on our own. On the other hand, we become more dependent on guidance, classification and ordering due to the ways in which searches and databases are constructed for us<a class="footnote-ref" href="#freedman2007"> [freedman2007] </a>. For this reason, it is important to critically scrutinize the specific implications of database logics, hence digital representation politics.</p>
<p>In contrast to most databases, the WFPP foregrounds the transformative nature of knowledge production. It highlights gaps and absences while at the same time stressing the abundance of existing yet unexplored material on women’s contribution to cinema. Analyzing the WFPP website and its rich collection it becomes clear again what has been pointed out by a number of feminist film historians, the marginalization of women is the result of a variety of factors, which are, however, closely intertwined: the dismissal of women’s work as menial labor, insufficient documentation, lack of evidence in addition to lack of imagination due to narrative, aesthetic, and theoretical conventions.Raw datacannot serve as an argument but as a valuable starting point for further, context-based analysis. Providing all possible sources along with each entry, as in the case of the WFPP career profiles, it is possible for users to get an idea of what data was left out of a particular narrative – or even in history more general. Ideally, in doing so, users can retrace howfactshave been produced and perhaps transformed.</p>
<p>In view of these remarks, the WFPP offers the opportunity to counter a meta history and instead foster the acknowledgment of women’s contribution to film history by telling individual stories. At the same time, the website demonstrates the broad and multifaceted field of the pioneers’ transnational activities. As English studies scholar Ed Folsom notes in his article “Database as Genre: The Epic Transformation of Archives,” which has provoked a vigorous debate among scholars, “[d]atabase might initially seem to denigrate detail and demand abstract averaging and universalizing, but in fact the structure of database <em>is</em> detail; it is built of particulars” <a class="footnote-ref" href="#folsom2007"> [folsom2007] </a>. With this important observation in mind, in order to discover significant details we need to be open for new patterns and insights. Tools are, as English studies scholar Meredith L. McGill rightly points out in her response to Folsom’s article, “limited by financial and physical constraints as well as by the imagination of their creators and users” <a class="footnote-ref" href="#mcgill2007"> [mcgill2007] </a>. Other than in a cause-and-effect narrative, there is less control of meaning-making in a database. It leaves more space for unpredictability. Against this backdrop, databases can be said to offer a fascinating possibility of knowing and experiencing history in an intellectually stimulating way. However, we must take advantage of this opportunity and tell stories differently by using our imagination.</p>
<p>While the WFPP provides a large amount of information on women in early cinema, its ultimate goal is to stimulate further research on women in film history both online and offline by examining original sources in archival collections. Online databases might help disseminating information beyond institutions and transform the control over the circulation of knowledge, as English studies scholar Peter Stallybrass enthusiastically proclaims<a class="footnote-ref" href="#stallybrass2007"> [stallybrass2007] </a>. Through the careful curation of an extensive range of information on resources, such as film print collections, academic papers, video sources, film festivals, cultural organizations, the WFPP website provides an extremely helpful scholarly venue. The aggregated references show that the immediate access to material and information online is a myth. The search for historical sources and evidence used to be a costly, tedious work – and it still is (e.g.<a href="#leigh2015">Leigh [2015]</a>;<a href="#mckernon2015">McKernan [2015]</a>). But with the help of digital databases, we can open up historiographical research and share information and resources and thereby ease archival workflows and scholarly activities.</p>
<h2 id="conclusion">Conclusion</h2>
<p>There is no doubt that digital technologies can help facilitate easier access to historical source material and research output. Provided that access to a computer and to the Internet is given, knowledge can be disseminated and shared with relatively little effort and at relatively low costs. Nevertheless, we need to keep in mind that inclusion always implies exclusion – both in terms of users and content. Foregrounding certain aspects of the past by selectively digitizing and presenting some information, we inevitably omit other sources and potential discoveries. As we know, archiving means not only preservation and memory but also forgetfulness and amnesia. Deciding on what will be represented means also deciding on what will <em>not</em> be represented – and therefore <em>not</em> be remembered. This becomes even more significant in light of digitizing artifacts<a class="footnote-ref" href="#zaagsma2013"> [zaagsma2013] </a>and the investment of financial and human resources needed for preservation projects<a class="footnote-ref" href="#heftberger2014"> [heftberger2014] </a>but also when considering digital infrastructures such as searchable databases.</p>
<p>On the one hand, one could argue, while shifting our research more and more online, the risk of letting offline sources be consigned to oblivion is increasing. Because of the plethora of resources which are immediately available to us on the Internet, we tend to use what is accessible from our desktops. Due to the growing digitization of artifacts some scholars fear that funding organizations might cut their financial support for expensive research trips to archives<a class="footnote-ref" href="#zaagsma2013"> [zaagsma2013] </a>. On the other hand, online platforms provide a profound insight into which archives exist in the first place. Databases like the <em>Women Film Pioneer Project</em> can be an incitement to the use of analogue as well as digital collections. Furthermore, if someone does not live close to a library, a museum, or other knowledge-management venues and/or is not affiliated with an institution and/or lacks financial means, barrier-free online access to records and studies, without technical, financial, or legal restrictions, is critical for both academic and non-academic research<a class="footnote-ref" href="#pampel2014"> [pampel2014] </a>.</p>
<p>Since databases, such as the WFPP, often rely on collaborative contributions, they challenge the persistent concept of authorship, understood as a genius solitary achievement. In doing so, they make us reflect on the reputation economy in academia and the regime of intellectual property<a class="footnote-ref" href="#stallybrass2007"> [stallybrass2007] </a>. Furthermore, databases represent work in process, they are never asfinishedas books. As a dynamic and subjective site of representation they strengthen the argument that there is no such thing asfinal facts.</p>
<p>The WFPP editors invite contributions from various authors (which will be peer-reviewed) and allow for “a great deal of variation and creativity in terms of the topics and themes” while at the same time offering suggestions<a class="footnote-ref" href="#gaines2013c"> [gaines2013c] </a>. In terms of creation and content, the editors work towards an inclusive and diverse film historiography, whereas the potential usage of the website is limited in some aspects such as language and design. The site is entirely in English and therefore can only be accessed by a certain group of users. Multilingual entries would help both to expand the project’s outreach and bring in many more, various perspectives. Unlike current web design trends which promote the use of animations, large images, a short introduction video, serif-less fonts, bold typography and other characteristics, the WFPP website stands out with its rather simple web design. The aggregation of data, information, and knowledge has been clearly the focus of the project so far. In my view, however, engaging the user in an enjoyable manner would very much help to make history accessible while indicating blind spots. While aesthetics is a matter of taste, a stronger focus on user experience can enhance the engagement with a database tremendously. The platform convincingly illustrates that a great deal of women pioneers had played a significant role in the silent-era. Nevertheless, additional features and data visualization techniques, for example GIS (geographic information systems), could help highlighting the many interactions and entangled paths of women in history. The curatorial work which has been put into the project is of great value to feminist film history. The WFPP provides an extensive collection of high quality data to further explore the digital representation of research and data visualization – and much potential for creative experiments toward the unknown. Let us make use of it. It is time for redistributing the narrative wealth, as proclaimed at DWFTHC in Lancaster: for telling many more stories, and first and foremost, telling stories differently. History is not only about the “power of the records” <a class="footnote-ref" href="#hunter2017"> [hunter2017] </a>but also of aesthetics and access.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>I thank the two anonymous reviewers for carefully reading the manuscript, and for insightful comments and suggestions.</p>
<ul>
<li id="acland2016">Acland, C. R. and Hoyt. E. (eds) _The Arclight Guidebook to Media History and the Digital Humanities_ . REFRAME Books, Sussex (2016).
</li>
<li id="bean2002">Bean, J. M. and Negra, D. (eds) _A Feminist Reader in Early Cinema_ . Duke University Press, Durham (2002).
</li>
<li id="burkhardt2015">Burkhardt, M. _Digitale Datenbanken, Eine Medientheorie im Zeitalter von Big Data_ . transcript Verlag, Berlin, Boston (2015), doi: 10.14361/9783839430286.
</li>
<li id="callahan2010">Callahan, V. (ed) _Reclaiming the Archive: Feminism and Film History_ . Contemporary Approaches to Film and Television Series. Wayne State University Press, Detroit (2010).
</li>
<li id="dallasta2015">Dall’Asta, M. and Gaines, J. M. “Prologue. Constellations. Past Meets Present in Feminist Film History.” In Christine Gledhill and Julia Knight (eds), _Doing Women’s Film History: Reframing Cinemas, Past and Future_ , Urbana (2015), pp. 28-34.
</li>
<li id="dang2018">Dang, S.-M. “Digital Tools & Big Data: Zu gegenwärtigen Herausforderungen für die Film- und Medienwissenschaft am Beispiel der feministischen Filmgeschichtsschreibung,”  _MEDIENwissenschaft: Rezensionen | Reviews_ , 2-3 (2019): 142, doi: 10.17192/ep2018.2-3.7836.
</li>
<li id="dang2020a">Dang, S.-M. “Forschungsdatenmanagement in der Filmwissenschaft: Daten, Praktiken und Erkenntnisprozesse.” In: Johannes Pause, Niels-Oliver Walkowski (eds): “Praktiken des Digitalen” , _Montage AV_ , 29.1, (2020): 120-140.
</li>
<li id="dang2020b">Dang, S.-M. and Akkermann, M. “Inszenierte Abwesenheit – eine Frage der Perspektive? Intersektionalität im Film am Beispiel von _Watermelon Woman_ .” In A. Charton, B. Dornbuch, and K. Knaus (eds), _Marginalisierungen – Ermächtigungen. Intersektionalität und Medialität im gegenwärtigen Musikbetrieb_ , Hildesheim, Zürich, New York (2019), pp. 119-137.
</li>
<li id="drucker2014">Drucker, J., Kim, D., Salehian, I., and Bushong, A. “Data and Databases. Critical and Practical Issues.” In J. Drucker, D. Kim, I. Salehian, and A. Bushong (eds), _Introduction to Digital Humanities. Concepts, Methods, and Tutorials for Students and Instructors_ , Los Angeles (2012), pp. 28-34,<a href="http://dh101.humanities.ucla.edu/?page_id=93">http://dh101.humanities.ucla.edu/?page_id=93</a>.
</li>
<li id="folsom2007">Folsom, E. “Database as Genre: The Epic Transformation of Archives,”  _PMLA_ , 122.5 (2007): 1571-1579.
</li>
<li id="freedman2007">Freedman, J. “Whitman, Database, Information Culture,”  _PMLA_ , 122.5 (2007): 1596-1602.
</li>
<li id="gaines2009">Gaines, J. “Filmgeschichte als Kritik feministischer Filmtheorie,”  _Das Argument_ , 51.6 (2009): 926-934.
</li>
<li id="gaines2018">Gaines, J. _Pink-slipped: What Happened to the Women in the Silent Film Industries?_ University of Illinois Press, Urbana (2018).
</li>
<li id="gaines2013a">Gaines, J., Vatsal, R., and Dall’Asta, M. (eds) _Women Film Pioneers Project_ . Center for Digital Research and Scholarship. Columbia University Libraries, New York (2013),<a href="https://wfpp.cdrs.columbia.edu/">https://wfpp.cdrs.columbia.edu/</a>.
</li>
<li id="gaines2013b">Gaines, J., Vatsal, R., and Dall’Asta, M. “Unhistoricized Women Film Pioneers.” In J. Gaines, R. Vatsal, and M. Dall’Asta (eds), _Women Film Pioneers Project_ . Center for Digital Research and Scholarship, New York (2013),<a href="https://wfpp.cdrs.columbia.edu/resources/appendix-f-unhistoricized-women-film-pioneers/">https://wfpp.cdrs.columbia.edu/resources/appendix-f-unhistoricized-women-film-pioneers/</a>.
</li>
<li id="gaines2013c">Gaines, J., Vatsal, R., and Dall’Asta, M. “Call for Contributors for Overview Essays.” In J. Gaines, R. Vatsal, and M. Dall’Asta (eds), _Women Film Pioneers Project_ . Center for Digital Research and Scholarship, New York (2013),<a href="https://wfpp.cdrs.columbia.edu/call-for-contributors/">https://wfpp.cdrs.columbia.edu/call-for-contributors/</a>.
</li>
<li id="gaines2020">Gaines, J., Vatsal, R., and Dall’Asta, M. “About the Project.” In J. Gaines, R. Vatsal, and M. Dall’Asta (eds), _Women Film Pioneers Project_ . Center for Digital Research and Scholarship, New York (2013),<a href="https://wfpp.columbia.edu/about/">https://wfpp.columbia.edu/about/</a>.
</li>
<li id="gladhill2015a">Gledhill, C. and Knight, J. (eds) _Doing Women’s Film History. Reframing Cinemas, Past and Future_ . Women and film history international. University of Illinois Press, Urbana (2015).
</li>
<li id="gledhill2015b">Gledhill, C. and Knight, J. “Introduction.” In C. Gledhill and J. Knight (eds), _Doing Women’s Film History. Reframing Cinemas, Past and Future_ , Urbana (2015), pp. 1-12.
</li>
<li id="guerin2016">Guerin, F. and Mebold, A. “Lotte Reiniger.” In J. Gaines, R. Vatsal, and M. Dall’Asta (eds), _Women Film Pioneers Project_ . Center for Digital Research and Scholarship _,_ New York (2016),<a href="https://wfpp.cdrs.columbia.edu/pioneer/lotte-reiniger/#citation">https://wfpp.cdrs.columbia.edu/pioneer/lotte-reiniger/#citation</a>.
</li>
<li id="hayles2007">Hayles, N. K. “Narrative and Database: Natural Symbionts,”  _PMLA_ , 122.5 (2007): 1603-1608.
</li>
<li id="heftberger2014">Heftberger, A. “Film archives and digital humanities – an impossible match? New job descriptions and the challenges of the digital era,”  _MedieKultur: Journal of media and communication research_ , 30.57 (2014): 135-153, doi: 10.7146/mediekultur.v30i57.16487.
</li>
<li id="hill2016">Hill, E. _Never Done: A History of Women’s Work in Media Production_ . Rutgers University Press, New Brunswick (2016).
</li>
<li id="hoyt2014">Hoyt, E. “Lenses for Lantern: Data Mining, Visualization, and Excavating Film History’s Neglected Sources,”  _Film History_ , 26.2 (2014): 146-169.
</li>
<li id="hunter2017">Hunter, K. M. “Silence in Noisy Archives: Reflections on Judith Allen’s “Evidence and Silence – Feminism and the Limits of History” (1986) in the Era of Mass Digitisation,”  _Australian Feminist Studies_ , 32.91-92 (2017): 202-12, doi:<a href="https://doi.org/10.1080/08164649.2017.1357009">10.1080/08164649.2017.1357009</a>.
</li>
<li id="leigh2015">Leigh, M. “Reading between the Lines. History and the Studio Owner‘s Wife.” In C. Gledhill and J. Knight (eds), _Doing Women’s Film History. Reframing Cinemas, Past and Future_ , Urbana (2015), pp. 42-52.
</li>
<li id="long2016">Long, D. “Excavating Film History with Metadata Analysis: Building and Searching the ECHO Early Cinema Credits Database.” In C. R. Acland and E. Hoyt (eds), _The Arclight Guidebook to Media History and the Digital Humanities_ , Sussex (2016), pp. 145-164.
</li>
<li id="manovich1999">Manovich, L. “Database as Symbolic Form,”  _Convergence_ , 5.2 (1999): 80-99.
</li>
<li id="mcgann2007">McGann, J. “Database, Interface, and Archival Fever,”  _PMLA_ , 122.5 (2007): 1588.92.
</li>
<li id="mcgill2007">McGill, M. L. “Remediating Whitman,”  _PMLA_ , 122.5 (2007): 1592-96.
</li>
<li id="mckernan2015">McKernan, L. “Searching for Mary Murillo.” In C. Gledhill and J. Knight (eds), _Doing Women’s Film History. Reframing Cinemas, Past and Future_ , Urbana (2015), pp. 78-92.
</li>
<li id="pampel2014">Pampel, H. and Dallmeier-Tiessen, S. “Open Research Data: From Vision to Practice.” In S. Bartling and S. Friesike (eds), _Opening Science: The Evolving Guide on How the Internet Is Changing Research_ , Collaboration and Scholarly Publishing, Cham (2014), pp 213-224,<a href="https://doi.org/10.1007/978-3-319-00026-8_14">doi: 10.1007/978-3-319-00026-8_14</a>.
</li>
<li id="pearlman2018">Pearlman, K., and Heftberger, A. “Editorial: Recognising Women’s Work as Creative Work.”  In A. Heftberger and K. Pearlman (eds) _Women at the Editing Table: Revising Soviet Film History of the 1920s and 1930s._  Special Issue of  _Apparatus. Film, Media and Digital Cultures in Central and Eastern Europe_  6 (2018),<a href="http://dx.doi.org/10.17892/app.2018.0006.124">http://dx.doi.org/10.17892/app.2018.0006.124</a>
</li>
<li id="ramsay2004">Ramsay, S. “Databases.” In S. Schreibman, R. Siemens, and J. Unsworth (eds), _A Companion to Digital Humanities_ , Malden (2004), pp. 177-197, doi:<a href="https://doi.org/10.1002/9780470999875.ch15">10.1002/9780470999875.ch15</a>.
</li>
<li id="schoch2013">Schöch, C. “Big? Smart? Clean? Messy? Data in the Humanities,”  _Journal of Digital Humanities_ 2.3 (2013),<a href="http://journalofdigitalhumanities.org/2-3/big-smart-clean-messy-data-in-the-humanities/#to-big-smart-clean-messy-data-in-the-humanities-n-6">http://journalofdigitalhumanities.org/2-3/big-smart-clean-messy-data-in-the-humanities/#to-big-smart-clean-messy-data-in-the-humanities-n-6</a>.
</li>
<li id="sobchack2000">Sobchack, V. “What is film history?, or, the Riddle of the Sphinxes.” In C. Gledhill and L. Williams (eds), _Reinventing film studies_ , London (2000), pp. 300-315.
</li>
<li id="stallybrass2007">Stallybrass, P. “Against Thinking,”  _PMLA_ , 122.5 (2007): 1580-1587.
</li>
<li id="zaagsma2013">Zaagsma, G. “On Digital History,”  _BMGN – Low Countries Historical Review_ , 128.4 (2013): 3-29.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://wfpp.cdrs.columbia.edu/">https://wfpp.cdrs.columbia.edu/</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="http://mediahistoryproject.org/">http://mediahistoryproject.org/</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>The Media Digital History Library collaborates with the Internet Archive, the Prelinger Archive, MoMA, Margaret Herrick Library, Library of Congress among other institutional partners.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="http://dfr.jstor.org/">http://dfr.jstor.org</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p><a href="http://projectarclight.org/">http://projectarclight.org/</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p><a href="https://archive.org/">https://archive.org/</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p><a href="http://echo.commarts.wisc.edu/">http://echo.commarts.wisc.edu/</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>For a broader discussion of whatdatameans in the humanities, see, for example, the reflections of Digital Humanities scholar Christof Schöch on “smart data” and “big data” <a class="footnote-ref" href="#schoch2013"> [schoch2013] </a>. For a film and media studies perspective, see, for example,<a href="#dang2020a">Dang 2020</a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Another example worth mentioning due to its popularity is the Women’s Film &amp; Television History Network UK/Ireland (<a href="https://womensfilmandtelevisionhistory.wordpress.com/">https://womensfilmandtelevisionhistory.wordpress.com/</a>). Another project, which features digital resources is <em>SP-ARK</em> (<a href="http://www.sp-ark.org/">http://www.sp-ark.org/</a>). <em>SP-ARK</em> is the online archive of Sally Potter. It provides a selection of multi-media material related to her films (e.g. annotated scripts, costume designs, and production schedules), just to mention a few.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>After I finished the manuscript, the WFPP has been subject to a relaunch. The homepage has been slightly rearranged, and – perhaps the most interesting aspect – a “Projections” section for various forms of reflection has been added. However, no fundamental changes have been made. All my observations in this article relate to an earlier version of the website (status as of November 2018), but I believe most issues raised also apply to the present website.## Bibliography&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Vivas to those who have failed: Walt Whitman Electric and the (Digital) Humanities</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000503/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000503/</id><author><name>Nicole Gray</name></author><published>2020-12-20T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<blockquote>
<p>He sees eternity less like a play with a prologue and denouement . . . . he sees eternity in men and women . . . he does not see men and women as dreams or dots.<br>
<a href="#whitman1855">Walt Whitman, preface to <em>Leaves of Grass</em> (1855)</a></p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>The field that has emerged as the digital humanities started with dreams and dots: pixelated digits and, beyond them, the prospect of methods and archives that could encompass almost an infinite number of texts. As it has grown it has developed a reputation as one of the few comparatively well-funded, expanding fields in an increasingly de-funded, precariously or under-employed academic humanities.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> It has also been criticized for a lack of ethnic and gender diversity and an unwillingness to think across cultures or to reckon with the theoretical insights of the humanities more generally.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></p>
<p>As a result, in part, of these criticisms, the moment for work at the intersection of digital methods and the humanities has never been more exciting. Creators of forums like #TransformDH, #DHpoco, and #GlobalOutlookDH have worked to transform the digital humanities by opening up space for a more diverse set of practitioners and voices. Projects like the Colored Conventions Project and the Mukurtu CMS have built tools organized around artifacts and knowledge practices associated with African American and Indigenous communities. Scholars and programmers worldwide are engaging questions of access, training, and opportunity.</p>
<p>With these developments have also come a set of theoretical provocations, challenges to return to the difficult work of thinking about digital media and its relationship to human beings.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  “[T]he black digital humanities promotes a system of change,” Kim Gallon has written: “it is a mechanism for deregulating the tendency of technological tools, when employed in the digital humanities, to deemphasize questions about humanity itself” <a class="footnote-ref" href="#gallon2016"> [gallon2016] </a>. This transformative mode of thinking, the call to interrogate basic concepts and assumptions, shares some ground with an earlier moment in digital humanities. In the early 2000s, the SpecLab at the University of Virginia, led by Johanna Drucker and Jerome McGann, conducted a series of textual experiments with that era’s digital tools. These experiments in text and technology were informed by a methodological approach called “deformance” , a creative and playful mode of reading.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> One goal of this speculative, theoretical work was an ongoing effort to reimagine key literary terms liketextandwork.</p>
<p>As digital methods that quantify and specify have come to play a prominent role in the digital humanities, perhaps it is worth exploring a complementary return to such ludic and experimental modes.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> In the context of the transformation of the digital humanities by scholars of race and gender, however, we may need to reconceptualize the practice and the nomenclature ofdeformanceto one of transformability.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> The malleability of form, for those who study connections between the body and identity, is a politically charged matter oriented toward the future as well as the present. Transformability shifts the focus from a product or process that has happened in the past, or is happening in the present, to the crucial role of imagination in turning to what is possible in the future. Transformability involves not only the many forms the text <em>has</em> taken — the realm of book history — or the many forms the text <em>does</em> take — the realm of textual editing — but also the many forms the text <em>could</em> take, the vast scope of its potential iterations within historical fields of embodied practice.</p>
<p>Using Walt Whitman as a case study, this essay explores the ways that the dreams of an American poet have been and could be expressed in dots, presenting an opportunity and a provocation to apply the formal logic of machines to poems, and vice versa. Miriam Posner has written that a useful challenge for the digital humanities, now that many of its methods have become established, might involve rethinking some of the most basic structures and binaries enacted by data. The current political and cultural moment points to the importance of testing the logics that have made machines so functional and so central to human existence in the twenty-first century. Inseparable from such logics are complicated questions, long fundamental to poetry, about kinship, race or ethnicity, age, and gender — differences among human beings that affect the uses to which machines are put and the ways in which they have shaped and been shaped by historical narratives.</p>
<p>Whitman is a useful case study in part because his knowledge about and investment in the technologies of print so thoroughly inform both his composition practices and his poetry. Transformation, and to some extent failure, also define his engagement of race over the course of his lifetime. Recent critical assessments have shown the ways Whitman grappled with trying to develop a national poetry at a moment when the nation’s internal contradictions were tearing it apart. The opposition to slavery and the forms of identification with enslaved people visible in his early poems largely gave way, after the U.S. Civil War, to a much more lukewarm position on the rights of freed slaves and other Americans of African descent.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></p>
<p>In the poem eventually titled “Song of Myself,” Whitman calls on his readers to “Unscrew the locks from the doors! / Unscrew the doors themselves from their jambs!” <a class="footnote-ref" href="#whitman1855"> [whitman1855] </a>. If this were a hermeneutic challenge, one might propose questions tailored to our technological and philosophical moment: what would a model of criticism look like that combines a deconstruction of performative authorship, the thought-experiment of a (failed) mechanism, and a detailed attention to the material characteristics of an artifact? What lies between the sociology of the door-closer and the sociology of the text?<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> How do we map the crossroads of reparative reading and algorithmic criticism?<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> This essay draws on structures of computational processing to reimagine and ultimately transform a manuscript draft of lines that have been at the heart of critics’ discussions of Whitman’s poetic treatment of race. Combining the ludic with the Luciferic, it engages a struggle with embodiment in a text from the past in order to frame that text’s transformation and re-embodiment in a troubled present.</p>
<p>In the first section of the essay, I discuss practices of text encoding and electronic transformation in widespread use by editors of humanities texts, arguing that such practices resonate linguistically and structurally with Whitman’s own poetic and material practices. The second section of the essay situates Whitman’s poem “The Sleepers” as a model for a critical approach that taps into a dialectic of dreams and failure that has been influential in the imagination and the politics of the United States. Casting thedreamspaceWhitman creates in “The Sleepers” as an analogue of namespaces in computer and information science, I suggest that it functions as a transformative, experimental environment in which dreams, failure, contingency, and intentionality combine to produce radical insights and forms of identification. To exhibit that potential, I transform a manuscript draft fragment of “The Sleepers” into a basic script written in the programming language Python. Such transformations have much to offer the critical imagination, drawing our attention to new textual dimensions and to the points at which poetic dreams fail to become functional dots or durable reparative interventions.</p>
<h2 id="this-electric-selfmachine-logics-and-the-transformability-of-text">This electric self:Machine Logics and the Transformability of Text</h2>
<p>One of the notable revisions Whitman made to his poem “Bardic Symbols,” first published in the <em>Atlantic Monthly</em> in 1860, between that initial publication and its final version ( “As I Ebb’d With the Ocean of Life” ) in later editions of <em>Leaves of Grass</em> , was to substitute the wordelectricfor the wordeternal.Setting the stage for poetic reflection, Whitman wrote in the 1860 version:</p>
<blockquote>
<p>I, musing, late in the autumn day, gazing off southward,Alone, held by the eternal self of me that threatens to get the betterof me and stifle me<br>
<a class="footnote-ref" href="#whitman1860"> [whitman1860] </a>This self was still eternal in 1867, but by the 1881 edition of <em>Leaves</em> , published just two years after Thomas Edison filed a U.S. patent for an electric lamp with a carbon filament, Whitman had revised both lines:<br>
I musing late in the autumn day, gazing off southward,Held by this electric self out of the pride of which I utter poems<br>
<a class="footnote-ref" href="#whitman1881"> [whitman1881] </a>Now electric rather than eternal, the poet’s self has also along the way become a prideful source of utterance rather than a stifling force. In becoming electric, the self is no longer alone, no longer occupied in wrestling with itself, but now turned outward and uttering poems.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>
</blockquote>
<p>The distance from the electric to the electronic self is a matter of a century, a couple of commonplace characters, and some successful inventions. Success, a word with roots in genealogical as well as temporal succession, can be considered to drive much of the work of description and transformation that is today fundamental to electronic editing and data manipulation in computational environments. The markup language XML, with the specific vocabulary created by the Text Encoding Initiative (TEI), has come to dominate the practice of digital editorial work on humanities texts.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> As is the case with computer programming and markup languages more generally, the functionality of XML and its related languages depends on logic.</p>
<p>The wordlogicis derived from the Greekλόγος, which has often been translated asword.Logic can refer to a formal system of reasoning depending on symbolic and mathematical procedures to establish claims, or, in a more loosely defined sense, to a set of rules or structures by which argumentation, reasoning, or understanding can be enacted within a given context (logic, <em>n</em> .). Butλόγοςis a complicated concept that extends further, encompassing speech or utterance, teaching, collecting, discourse, mind, principle, law, act, reckoning, cause, form, and pattern, as well as rational (or spiritual, or divine) order, or even revelation — all with just a hint of temporality, drawing on the idea oforiginalororiginary.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> I will use logic throughout this essay to refer both to the structure of language, utterance, or argument and to this more complex sense, a spiritualized form of expression, the <em>making material</em> of structure or order in the world, divine or otherwise.</p>
<p>The logic of XML depends on breaking data into machine-readable, processable parts, enforcing the description or the creation of boundaries. These boundaries ideally correspond to clearly defined units or categories, and they enable the construction of hierarchies and relationships. In the case of TEI these categories relate to inscribed materials like manuscripts or books. TEI also often encodes other categories that have been developed over years of academic production, like categories of genre, which underwrite the coherence of the discipline of literary criticism even as they are frequently challenged in individual studies. The logics that combine in the encoding practices and syntax of TEI are thus several, including logics of inscriptive technologies like the book and the manuscript, logics of categorical differences in style observed and enacted by literary criticism, and logics of information and meta-information that developed in library and computational contexts.</p>
<p>The textual crux represented by the wordeternalin Whitman’s “Bardic Symbols,” for example, could be expressed in TEI. In a single file that described multiple versions of the poem, the tags <code>&lt;app&gt;</code> (for critical apparatus entry) and <code>&lt;rdg&gt;</code> (for reading), with the attribute <code>@wit</code> (to point to a textual witness), could be used to mark two versions of the line:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;app&gt;</span> <span style="color:#f92672">&lt;rdg</span> <span style="color:#a6e22e">wit=</span><span style="color:#e6db74">&#34;#lg1860&#34;</span><span style="color:#f92672">&gt;</span> <span style="color:#f92672">&lt;l&gt;</span>Alone, held by the eternal self of me that threatens <span style="color:#f92672">&lt;lb/&gt;</span>to get the better of me, and stifle me,<span style="color:#f92672">&lt;/l&gt;</span> <span style="color:#f92672">&lt;/rdg&gt;</span> <span style="color:#f92672">&lt;rdg</span> <span style="color:#a6e22e">wit=</span><span style="color:#e6db74">&#34;#lg1881&#34;</span><span style="color:#f92672">&gt;</span> <span style="color:#f92672">&lt;l&gt;</span>Held by this electric self out of the pride of which I utter poems,<span style="color:#f92672">&lt;/l&gt;</span> <span style="color:#f92672">&lt;/rdg&gt;</span> <span style="color:#f92672">&lt;/app&gt;</span>
</span></span></code></pre></div><p>Marking the text in this way reproduces several logics: the structural logic of the text (marking the line as a line with <code>&lt;l&gt;</code> ); the logic of the critical apparatus that describes textual revision or versions of the text over time ( <code>&lt;app&gt;</code> and <code>&lt;rdg&gt;</code> ); and the logic of the printed page, which consists of both inked characters and white space ( <code>&lt;lb/&gt;</code> or line break).</p>
<p>A transformation of the text could proceed at the level of any of these logics, or all of them together. One could produce all the different versions of the line, one after the other, so they would display sequentially in a Web browser; or compare them as text strings and generate a visualization of the differences; or show the line in the context of other lines from the poem; or create a toggle allowing users to view or eliminate the line breaks, functionally reformatting the text. Data marked in XML can be transformed into Hypertext Markup Language (HTML), which in turn can be combined with display instructions to render readable, manipulable text in Web browsers. As display technologies and standards develop, XML remains useful, in theory, because the basic assumption is that it can be transformed into any number of other languages or data formats.</p>
<p>For Whitman, as the change frometernaltoelectricwould suggest, the line from “Bardic Symbols” was transformable when he wrote it and remained so even after it was printed. He orchestrated several transformations of both wording and appearance between 1860 and the final printing of the line in his lifetime in the 1891-2 <em>Leaves of Grass</em> . To mark the line with TEI does not alter its ontological status, but it does produce new options for transformability in a digital environment. We might say that digital transformation is simply an extension of the imagination of transformability that, for Whitman, was a basic condition of textual production.</p>
<p>The syntax of transformation provides a surprisingly poetic point of continuity. The transformation of XML, like the original markup, is an interpretive act, introducing display and navigation elements that structure the reader’s experience of a text. A primary language of transformation in such cases is Extensible Stylesheet Language Transformations (XSLT), one of three recommendations that make up the broader language family XSL.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> XSL depends on kinship as its metaphor for expressing locations, finding nodes in a document tree hierarchy based on paths articulated as a matter of succession. In the case of XML Path Language (XPath), the expression language used by XSLT, succession is a means of expressing relationships between elements or nodes.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> The road from XML to HTML is navigated with siblings, parents, children, ancestors, and descendants. In order to select all of the <code>&lt;rdg&gt;</code> nodes to render a particular reading in a TEI file with an XPath that locates them in their relation to their parent <code>&lt;app&gt;</code> elements, for instance, you might use the notation: <code>&lt;xsl:apply-templates select=&quot;child::rdg&quot;/&gt;</code> . In plain (more or less) English, you could say that you are instructing the stylesheet to apply a series of transformations to any reading ( <code>&lt;rdg&gt;</code> ) that is a child of the current node.</p>
<p>The logics and syntax of modern markup and transformation languages used for editing depend on a set of technical metaphors, terms for describing relationships that, in the case of XSL and many other languages, draw from family and nature — the stuff of poetry. And Whitman thought in machine logic, too, although his machine was the printing press. The kinds of material transformations that Whitman’s texts underwent in the nineteenth century bear some resemblance to the file transformations and structural logics of the electronic age. Whitman’s poetic transformations often involved cutting and pasting.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> Modularity was key, and Whitman, a former printer, often composed with the structure of the printed text in mind. When he received proofs of a set of notes about Elias Hicks that would form part of his 1888 volume <em>November Boughs</em> , for instance, Whitman noted to the printer that he wanted the section to begin on an odd-numbered page:</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Page proof of “Notes (such as they are) founded on Elias Hicks.” Walt Whitman Papers in the Charles E. Feinberg Collection. Library of Congress, Washington, D.C.
        </p>
    </figcaption>
</figure>
<p>This move made logical sense for situating the Hicks essay as a new section of the prose in the volume — but it also reflected Whitman’s practice of repurposing sections and binding them into later book issues.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> He habitually arranged for the printing of poems and other materials independently on slips of paper, using them as the basis for proofing, sending them out for publication, circulating them among friends and acquaintances, and in some cases adding them into books. In ways that anticipated the concerns of twenty-first-century information scientists, Whitman designed his chunks of poetry and prose to be materially interoperable. If they were arranged such that they could be printed on separate sheets or gatherings, they could be assembled into other books or bound and distributed independently.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></p>
<p>Like XML-marked data today, Whitman’s modular text could be used for a number of (multimedia) futures. Both books and languages like XML depend on structured relations, definitions, hierarchies, and dependencies. And yet the imagination that selects and designs particular transformations is, as tools and books develop, an increasingly crucial component of digital processing. Whitman’s imagination of text and its possible transformations was shaped by the technologies of his time. We face a similar effect today, as critical and creative imaginations are challenged by machines that enable new forms of transformation, as humanities texts and machine languages combine in novel and interesting ways, and as practitioners are increasingly conversant in the logics of both. Conceived as a language whose use-value and sustainability were grounded in the possibility of transformation, XML is in certain ways an investment in the future of both technology and imagination.</p>
<h2 id="in-the-ruin-the-sedimentpoetic-dreams-and-electric-failures">In the ruin, the sediment:Poetic Dreams and Electric Failures</h2>
<p>In Whitman’s early, much-revised and much-discussed poem “The Sleepers,” the dreaming poet begins out of sorts: “I wander all night in my vision, / &hellip; / Wandering and confused . . . . lost to myself . . . . ill-assorted . . . . contradictory” <a class="footnote-ref" href="#whitman1855"> [whitman1855] </a>.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> And yet the poet is capable, in this dream vision, of acts of acrobatic transcendence and identification. In “The Sleepers,” Whitman first included and then edited out arguably his most striking identification across racial boundaries, lines in which the poet speaks as an enslaved person.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup></p>
<p>Whitman had explored dreams as a space for transcending boundaries as early as his pre- <em>Leaves of Grass</em> fiction, and he may have been tapping into a genre of dream visions in literature. The unsettled mental state of the dreamer at the start of the dream in Whitman’s “The Sleepers” and in his fiction is like that of other dream-vision narrators. The space of the dream for Whitman is liminal, in the sense that it seems to exist somewhere between pure presence and pure transcendence. In it the world of possibility is expanded, sometimes alarmingly.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> Critics have argued that the redemptive vision at the close of “The Sleepers,” in which the poet describes the sleepershand-in-handin a restorative sleep through which the illnesses and inequities of the world are healed, is a classicdream visionculmination of wandering in greater understanding and a sympathetic poetic enlightenment.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></p>
<p>Another way to think about Whitman’s dreamspace — one quite out of time — would be to think of it as a kind of poetic namespace. In computer and information science, namespaces denote distinctions among objects (entities) or vocabularies, establishing boundaries around a specific collection of symbolic terms and related definitions. The use of namespaces allows for combinatory worlds in which the same word, element or object might mean something different in a specified context, or have a different relationship to other words, elements, or objects. Namespaces are often expressed using prefixes. One might, for instance, distinguish between the dreamspaceI(ds:I) of “The Sleepers” and the waking space poeticI(ws:I) of the other poems in the first edition of <em>Leaves of Grass</em> . Let us say <code>&lt;ds:I&gt;</code> experiences discomfort, but possesses an ability to see and identify with the population of sleepers that extends beyond even as it informs the ability of <code>&lt;ws:I&gt;</code> .</p>
<p>The premise of namespaces and elements is the ability to declare entities like <code>&lt;ds:I&gt;</code> and distinguish them from other entities both within a namespace and outside of it. The striking thing about Whitman’s dreamspace in “The Sleepers,” however, is the very impossibility of that activity. In dreamspace, the night is a spatial as well as a temporal setting: of the sleepers, the poet writes, “The night pervades them and enfolds them” <a class="footnote-ref" href="#whitman1855"> [whitman1855] </a>. The poet, too, both penetrates and enfolds the sleepers he describes. The poem begins with description: the poet, “Pausing and gazing and bending and stopping,” simply looks at the sleepers. Next, he comes closer — “I pass my hands soothingly to and fro a few inches from them” — but still the restless sleepers sleep fitfully<a class="footnote-ref" href="#whitman1855"> [whitman1855] </a>. He then joins them, sleeping and dreaming with them — “I sleep close with the other sleepers, each in turn; / I dream in my dream all the dreams of the other dreamers” <a class="footnote-ref" href="#whitman1855"> [whitman1855] </a>. Finally, his dreaming produces a deeper identification: “And I become the other dreamers.” In this state the poet pervades the dreamers like the night, taking on their identities — “I am the actor and the actress” — and acting in their stead. The poet of dreamspace transcends the boundaries between himself and the people he describes. The descriptive work of dividing the sleepers into individuals becomes the work of drawing them together through the consciousness and the transformative dream-vision of the poet. As the poem concludes, the sleepers rest “hand in hand,” unified and beautiful in sleep, and the poet passes from night into day<a class="footnote-ref" href="#whitman1855"> [whitman1855] </a>.</p>
<p>“Elements merge in the night,” Whitman writes in “The Sleepers.”  “The antipodes, and every one between this and them in the dark, / I swear they are averaged now . . . . one is no better than the other, / The night and sleep have likened them and restored them” <a class="footnote-ref" href="#whitman1855"> [whitman1855] </a>. If the work of descriptive markup or the creation of distinct entities as part of XML namespace vocabularies involves breaking things down into parts, dreamspace might serve as an impetus to imagine ways of bringing them back together — or to recognize the artificiality of their separation. Like night in “The Sleepers,” dreamspace enables the existence, or the imagination of the existence, of two simultaneous possibilities: a difference and a cosmic averaging. Dreamspace brooks mathematical experimentation, perhaps because its elements and entities are defined contingently, in relation to deep, incomprehensible forces — not the natural forces of physics and institutional agency that guide the elements and entities of waking life, but something more inward-looking and subjective. In Whitman’s dreamspace, imaginative forays begin to mediate difference, bridging the gap between entities, even those posed as binary opposites. Transformability has both conceptual and material dimensions for Whitman, informing his dreams of poetic identification as well as his practices of revision and bookmaking.</p>
<p>If the digital humanities represents a field in which the logics of programming and machines are called upon to revise the patterns of humanistic and philosophical inquiry, where multiple namespaces may coexist and serve co-articulated purposes, perhaps dreamspace can be cast as a foil to the functional side of programming, an invocation of the vocabulary of experimentation, of margins, of imagination, and of failure. In an essay on the methodological potentials of repair, Steven Jackson casts breakdown as a starting point in thinking about new media. Noting the role of shipbreaking in Bangladesh, where the raw materials of old ships are recycled into usable products, Jackson situates failure as one stage in a longer story, one in which breakdown and decay form constitutive components of existence in the twenty-first century, and in which imagination and reconfiguration are key to building sustainable practice<a class="footnote-ref" href="#jackson2014"> [jackson2014] </a>.</p>
<p>In science and technology worlds, failure (in moderation) has long held a special status. As journalists and media scholars have pointed out, the vision of failure as a preliminary step in success continues to be lionized in thefail fast, fail oftenmantra associated with Silicon Valley, however well the mantra corresponds to actual conditions of employment and production.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> Stories of failure in a rapidly developing media world have an analogue in the newspapers and periodicals of the nineteenth-century. Frank Luther Mott’s histories of early American newspapers and magazines showcase the way such productions went under with sometimes bewildering regularity. Newspapers were not the only industry full of folds, of course — Scott Sandage, tracing the ubiquitous failures of merchants in the nineteenth-century U.S., notes that “in addition to those who went broke or bankrupt, thousands of businessmen teetered on the brink for years” <a class="footnote-ref" href="#sandage2005"> [sandage2005] </a>. Failure, according to Sandage, is the substory of the idea that came to be known as the American Dream. Constituting a central part of stories and experiences of life in the U.S., but never quite fitting into the vision the republic had of itself, failure lingered uncomfortably at the boundaries of success and identity for the American nineteenth century.</p>
<p>In the economic sense that would be associated with failure in the nineteenth-century United States, Whitman’s first edition of <em>Leaves of Grass</em> , self-published in 1855, was undeniably a failure. An unusual book in both size and manufacture, the first edition of <em>Leaves</em> lacked a formal publisher and was set in type between other non-literary jobs at Andrew Rome’s Brooklyn printing shop. Whitman’s friend Horace Traubel reported in <em>With Walt Whitman in Camden</em> that “W[hitman] spoke about the first edition of the Leaves: “It is tragic — the fate of those books. None of them were sold — practically none — perhaps one or two, perhaps not even that many. We had only one object — to get rid of the books — to get them out someway even if they had to be given away” ” <a class="footnote-ref" href="#traubel1906"> [traubel1906] </a>.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup></p>
<p>Today, copies of Whitman’s first edition of <em>Leaves of Grass</em> are listed for sale at prices that range from $50,000 to $270,000.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> The books that once failed to sell are now the most expensive and sought-after of the editions of <em>Leaves of Grass</em> . Failure has a place in the narrative of literary production, which like that of technology often centers on dreams, succession, and innovation. For Whitman, the arc of the future and its changing literary preferences fueled the popularity of his work over a century and a half of massive historical and technological changes. In the wake of a transformation in the value readers found in the poems that comprised his <em>Leaves of Grass</em> , the first edition has re-emerged as a site of interest. Its rarity, combined with critical and popular consensus about the value of Whitman’s poems, has helped to make it one of the most expensive books of American literature on the market today. In the same economic sense that once rendered it a failure, one might say that the 1855 <em>Leaves of Grass</em> has become a resounding success.</p>
<p>Discussions of the digital humanities, too, are threaded throughout with tales of failure. Failures in the collection of essays titled <em>A New Companion to Digital Humanities</em> , updated in 2016, include the failures of collaboration<a class="footnote-ref" href="#edmond2016"> [edmond2016] </a>, of fabrication<a class="footnote-ref" href="#sayers2016"> [sayers2016] </a>, of interdisciplinarity<a class="footnote-ref" href="#mccarty2016"> [mccarty2016] </a>, of technology/hardware, of the imaginers of design fictions to account for humanities concerns about ethics and culture<a class="footnote-ref" href="#jorgensen2016"> [jorgensen2016] </a>, of data to interoperate, of the search string to correspond exactly with the search meaning, and so on. Happily, in none of these cases is failure conceived as a reason not to attempt. Indeed, the failure often produces different insights and, in some cases, visions with more comprehensive impact.</p>
<p>Whitman splintered his poetry and prose into pieces, but like the shipbreakers he also brought it back together again in diverse and imaginative ways. One of his friends, Harrison S. Morris, recollected a story about the poet:</p>
<blockquote>
<p>He said an idea would strike him which, after mature thought, he would consider fit to be the “special theme” of a “piece.” This he would revolve in his mind in all its phases, and finally adopt, setting it down crudely on a bit of paper, — the back of an envelope or any scrap, — which he would place in an envelope. Then he would lie in wait for any other material which might bear upon or lean toward that idea, and, as it came into his mind, he would put it on paper and place it in the same envelope. After he had quite exhausted the supply of suggestions, or had a sufficient number to interpret the idea withal, he would interweave them in a “piece,” as he called it. I asked him about the arrangement or succession of the slips, and he said, “They always fall properly into place.”<br>
<a href="#kennedy1896">(Qtd. in Kennedy [1896], 24)</a>Did Whitman ever think about failure, as he scratched out lines, cut and pasted, shuffled scraps in envelopes, relying on, in place of the muse, the seemingly mutual co-determinative pull of randomness and data? Do we think of failure as we gather, create, and transform data, trying not to let the questions determine the answers, trying not to let the machine be too much a reflection of our own biases and preconceptions? Is there any creative or analytical work that is not haunted by failure?</p>
</blockquote>
<p>As he walks the shore, the poet of Whitman’s “Bardic Symbols” ponders the deposits of the waves, “In the ruin, the sediment, that stands for all the water and all the land of the globe.” The detritus or sediment cast onto the shore is not random (being at least in part the product of known and ordered industries or natural phenomena like shipbuilding, trade, and weather). Neither is it fully recognizable. The poet laments his inability to understand the meaning of the debris — “Oh, I think I have not understood anything, — not a single object, — and that no man ever can!” The signs or bardic symbols represent a momentary configuration, but also a cosmic and historical culmination. Recognition in this poem occurs when the poet stops trying to read, to find a pre-determined meaning, and embraces the transformative work of metaphor.</p>
<p>Struck shortly into “Bardic Symbols” by an “old thought of likenesses,” the poet begins to think about poetry as he observes the detritus. “Bardic Symbols” becomes a poem about printing and inscription as much as it is about a poet observing the sea. “I wish I could impress others,” the speaker begins, using language drawn from the technology of inscription of his time — the printed impression, the pressure of metal type on the page exerted by the printing press. Later, in an ecstasy of recognition, he exclaims “I, too, leave little wrecks upon you, you fish-shaped island!” and concludes by looking up from the page to the reader:</p>
<blockquote>
<p>We, capricious, brought hither, we know not whence, spread out before you, —you, up there, walking or sitting,Whoever you are, — we, too, lie in drifts at your feet.<br>
Capricious, brought hither, through space and time, the drifts take the shape of the inked characters on the page or — now — the pixels or dots on the screen. The “semiotic ecology” of poetry encompasses the cast-off detritus of the ocean as well as of print, and all the forms future likenesses take<a class="footnote-ref" href="#drucker2013"> [drucker2013] </a>. Whitman’s drift, a complicated co-articulation of randomness and intentionality, offers a proleptic vision of digital textuality.<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup></p>
</blockquote>
<h2 id="seized-by-the-spirit-that-trails-in-the-lines-underfootre-scripting-race">Seized by the spirit that trails in the lines underfoot:Re-scripting Race</h2>
<p>Guided by transformability and repair, we might break Whitman’s “Sleepers” back down into draft segments and imagine them further, beyond the familiar ground of TEI and namespaces, into Python, one of today’s most powerful and widely used programming languages.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> Like Emily Dickinson’s description of reading poems backward, seized by Samuels and McGann as a provocation for deformance, transforming or translating poetry into a programming script defamiliarizes elements of both, opening the door — or unscrewing it entirely — inviting insights at the intersection of digital and poetic logics.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> With particular force, this operation helps to demonstrate the ways in which what Ivy Wilson has described as “the presence of African Americans — suspended between the material and the apparitional, as it were — within the poetic space of [Whitman’s] verse and other writings” could be made to speak back to both the containment of Black U.S. citizens and deterministic, abstract narratives of technological development<a class="footnote-ref" href="#wilson2014a"> [wilson2014a] </a>.</p>
<p>The culminating dramatic moment in the poem that would be titled “The Sleepers,” more dramatic in the form of one of several manuscript drafts, has a striking conditional:</p>
<blockquote>
<p>I am a hell-name and a Curse:TheBlack Lucifer was not dead;Or if he was, I am his sorrowful, terrible heir</p>
</blockquote>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Manuscript draft of lines eventually used in “The Sleepers.” Papers of Walt Whitman, 1838-1987. Clifton Waller Barrett Library of American Literature, Albert and Shirley Small Special Collections Library, University of Virginia.
        </p>
    </figcaption>
</figure>
<p>From the narrative present of the poem, the speaker looks back to a past time: “Black Lucifer <em>was</em> not dead.” As Ed Folsom has written, the possible sources for Whitman’s Lucifer are many, from the Biblical Isaiah’s reference to “a fallen king of Babylon,&hellip;a reference that led to the mistaken notion that Lucifer was the fallen angel from heaven, Satan,” to an ignitable match, to a nineteenth-century <em>Webster’s Dictionary</em> description of Lucifer as “the planet Venus, when appearing as the morning star” <a class="footnote-ref" href="#folsom2001"> [folsom2001] </a><a class="footnote-ref" href="#folsom2000"> [folsom2000] </a>. Folsom notes that in one early notebook, “Whitman lists gods, including Lucifer, who are defined as made up of all that opposes hinders, obstructs, revolts ” <a class="footnote-ref" href="#folsom2000"> [folsom2000] </a>. Lucifer was not dead, the poet-historian, poet-interpreter, asserts — only to undercut the assertion. <em>Or if he was&hellip;</em> Neatly bifurcating historical or spiritual time with a possibility, the poet-historian-slave follows one conditional path and moves confidently into the present: “I am his sorrowful, terrible heir.”</p>
<p>Folsom situates this manuscript as one of several draft versions in which the speaker ceases to speak for the enslaved person and instead speaks <em>as</em> the enslaved person, in a culminating act of identification. The deleted line in this draft shows the speaker beginning with a declaration of identity that is at once naming and invective: “a hell-name and a Curse.” <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> The fracture or bifurcation of historical/spiritual time introduces the capacity for the speaker to transform, fully, into the divine. As (possible) heir of Black Lucifer, the speaker becomes “the God of Revolt — deathless sorrowful vast.” The draft moves then into the future: “I will either destroy them him or they he shall release me.”</p>
<p>The published versions of the lines that appeared in the 1855 edition of <em>Leaves of Grass</em> incorporate several revisions, among them the first word of theLuciferline:</p>
<blockquote>
<p>Now Lucifer was not dead . . . . or if he was I am his sorrowful terrible heir;I have been wronged . . . . I am oppressed . . . . I hate him that oppresses me,I will either destroy him, or he shall release me.<br>
<a class="footnote-ref" href="#whitman1855"> [whitman1855] </a>Whitman’s substitution ofNowforBlackis one example of his removal of explicit references to race that appeared in the manuscripts.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> Functioning as a transitional word,Nowemphasizes the temporal disjunction of this passage, moving to a new section of dreamspace in this poem about sleepers. But it also opens the door to another apparitional development: the historical moment and the institution of slavery have provoked an emergence that resurrects the God of Revolt, as undead (deathless) or in the form of succession.</p>
</blockquote>
<p>The revision between manuscript draft and published poem situates the lines within the larger temporal frame of the poem, which flits, dreamlike, among past, present, and future. Other words already in the draft describe the complicated conditions of both genealogical and temporal succession. The operators in the lines of this manuscript — OR, IF — form the axes of legibility for many programming languages. If these lines were a script written in Python, they might look like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">us_slavery</span>(year): year <span style="color:#f92672">=</span> int(year) <span style="color:#66d9ef">if</span> <span style="color:#ae81ff">1619</span> <span style="color:#f92672">&lt;=</span> year <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">1863</span>: self <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;enslaved&#39;</span> <span style="color:#66d9ef">else</span>: self <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;free&#39;</span> <span style="color:#66d9ef">return</span> self <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">heir</span>(I): I <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;his sorrowful, terrible heir&#39;</span> <span style="color:#66d9ef">return</span> I <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">lucifer</span>(state): I <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;self&#39;</span> <span style="color:#66d9ef">if</span> state <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;no&#39;</span>: lucifer <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;Black_Lucifer&#39;</span> <span style="color:#66d9ef">return</span> lucifer <span style="color:#66d9ef">else</span>: I <span style="color:#f92672">=</span> heir(I) <span style="color:#66d9ef">return</span> I <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">sleepers</span>(): I <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;hell-name&#39;</span> self <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;Curse&#39;</span> year <span style="color:#f92672">=</span> int(input(<span style="color:#e6db74">&#39;What year is it? &#39;</span>)) self <span style="color:#f92672">=</span> us_slavery(year) <span style="color:#66d9ef">if</span> <span style="color:#ae81ff">1849</span> <span style="color:#f92672">&lt;=</span> year <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">1881</span>: state <span style="color:#f92672">=</span> input(<span style="color:#e6db74">&#39;Was Black Lucifer dead? &#39;</span>) I <span style="color:#f92672">=</span> lucifer(state) <span style="color:#66d9ef">if</span> I <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#39;Black_Lucifer&#39;</span>: print(<span style="color:#e6db74">&#39;I am&#39;</span>,I) I <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;the God of Revolt&#39;</span>,<span style="color:#e6db74">&#39;deathless&#39;</span>,<span style="color:#e6db74">&#39;sorrowful&#39;</span>,<span style="color:#e6db74">&#39;vast&#39;</span>] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> I: print(<span style="color:#e6db74">&#39;I am&#39;</span>,i) <span style="color:#66d9ef">else</span>: <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> self: print(<span style="color:#e6db74">&#39;REVOLT&#39;</span>) <span style="color:#66d9ef">elif</span> year <span style="color:#f92672">&gt;=</span><span style="color:#ae81ff">1881</span>: print(<span style="color:#e6db74">&#39;A show of the summer softness</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">a contact of something unseen</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">an amour of the light and air&#39;</span>) <span style="color:#66d9ef">elif</span> <span style="color:#ae81ff">1776</span> <span style="color:#f92672">&lt;=</span>year <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">1849</span>: print(<span style="color:#e6db74">&#39;We hold these truths to be self-evident</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">that all men are created equal&#39;</span>) <span style="color:#66d9ef">else</span>: print(<span style="color:#e6db74">&#39;Replica of the Great Hole of history&#39;</span>) sleepers()
</span></span></code></pre></div><p><sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup></p>
<p>Segments of the “Sleepers” manuscript can be produced by the Python script, which enacts executable parts of the poem. Depending on the date a user enters, the execution of the script might generate parts of the draft lines of the manuscript version, or it might generate other lines completely. The parameters are time, history, and the state of existence of Black Lucifer. In this transformation, succession returns to somewhere just short of its biological roots: Lucifer’s conditional successor is a function and a refraction of American slavery. As a “hell-name and a Curse,” Lucifer or his heir is handed down across borders of time and space, iterations of manuscript and print, evolutions of communicative machinery, to emerge briefly and dramatically in a peculiar, failed, breakthrough book of American poetry — or on your computer screen.</p>
<p>The kinship of languages is framed as relations of history (origin, reproduction), but recast as a matter of space, execution, and transformation within the specific, limited temporality of the script, or of dreamspace, or of the boundaries of the logics declared in our interpretations. The program points to the significance and the operability of the conditional. The poem points to the significance and the inoperability of the past tense. For the loop, something is or is not.Wasis not operable or definable within the space of the loop. It could be argued that it is enacted by the space outside the loop, and the variables are handed down. But what must come outside the loop to begin to approximate the meaning? The entire history of U.S. slavery and oppression, condensed into a series of expressions? Would they be definitions, or descriptions, or conditionals?</p>
<p>That computers can draw critical attention to patterns that sometimes go overlooked by the human eye has formed the appeal behind many digital methods. One of the most powerful characteristics of computational analysis tools like text mining classification algorithms is that they can be trained or tweaked by programmers based on specific data or results sets. Can the attention of researchers also be trained to look more closely at the kinds of words that machines would find actionable or significant?<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup> What would it mean to experiment with training as a mutual process, a kind of projection by a human into a computational mode of processing? In a world of posthumanist criticism, the insights of macroanalysis may be used to conduct even closer readings — to see the value in Whitman’stheand hisoras well as hisleavesand hisgrass.Such attention may, as Matthew Wilkins has noted, “suggest that there’s a low-level linguistic basis for the category distinctions we’ve long been inclined to draw.” It might also help us to produce new readings of well-traveled passages.</p>
<p>Book historians and bibliographers have demonstrated that the formal and linguistic interference of the editor is a crucial component of the afterlife of the work, and therefore its continued life in time. “Acts of translation and editing are especially useful forms of critical reflection,” McGann writes, “because they so clearly invade and change their subjects in material ways” <a class="footnote-ref" href="#mcgann2016"> [mcgann2016] </a>. The heart of the way text is increasingly imagined today — the product of our data-vision — is itstransformability. This transformability is a matter of succession, but not always of success. Whitman, an early exponent of modularity or transformability as a fundamental characteristic of textual production, serves as an instructive precursor. His transformational approach is visible in the scraps he shuffled in envelopes, the many editions of <em>Leaves of Grass</em> , and his re-making of books more generally.</p>
<p>Programming, perhaps for everyone, but particularly for those of us not formally trained in the art, becomes a study in errors. In writing the sleepers.py script, I encountered a series of errors:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#a6e22e">TypeError</span>: us_slavery() missing <span style="color:#ae81ff">2</span> required positional arguments: <span style="color:#e6db74">&#39;self&#39;</span> <span style="color:#f92672">and</span> <span style="color:#e6db74">&#39;year&#39;</span> <span style="color:#a6e22e">NameError</span>: name <span style="color:#e6db74">&#39;slave&#39;</span> <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> defined <span style="color:#a6e22e">NameError</span>: name <span style="color:#e6db74">&#39;I&#39;</span> <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> defined Traceback (most recent call last): File <span style="color:#e6db74">&#34;sleepers.py&#34;</span>, line <span style="color:#ae81ff">21</span>, <span style="color:#f92672">in</span> sleepers lucifer <span style="color:#f92672">=</span> Black_Lucifer <span style="color:#a6e22e">NameError</span>: name <span style="color:#e6db74">&#39;Black_Lucifer&#39;</span> <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> defined Traceback (most recent call last): File <span style="color:#e6db74">&#34;sleepers.py&#34;</span>, line <span style="color:#ae81ff">40</span>, <span style="color:#f92672">in</span> sleepers lucifer <span style="color:#f92672">=</span> lucifer(input(<span style="color:#e6db74">&#34;Was Black Lucifer dead? &#34;</span>)) <span style="color:#a6e22e">UnboundLocalError</span>: local variable <span style="color:#e6db74">&#39;lucifer&#39;</span> referenced before assignment
</span></span></code></pre></div><p>The errors — TypeErrors, NameErrors, UnboundLocalErrors — that I produced in the making of sleepers.py mostly had to do with variables, either undefined or not included as part of the execution of a function that required them. In the case of a finished, working script, of course — or a script developed by an experienced, trained programmer — one may be less likely to encounter errors. Nor is it necessarily clear after the fact, unless a log or versioning system is associated with the development and made accessible as a complement to the resource, that they existed. Such data often fades into an invisible history of development, or it vanishes by virtue of being overwhelmed by an avalanche of incremental changes, commits, updates, migrations, transformations, deletions, and additions.<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> In this case, perhaps as a conceit, one might argue that the errors formed a layer of the transformation, the undefinedness of the variable part of its poetic interpretation. The missing definitions represent segments of American history as it is performed in Whitman’s poems: the specific identity of the reader, the ambiguity of the designations ofslaveandI.Somewhere between the failures of the programmer and the untranslatability of the poem fragment lurks the impossible largeness of poetry, its ambiguities and its historical roots, the unexecutable complicating presence of the undefined and the undefinable.</p>
<p>Before the publication of the 1881 edition of <em>Leaves of Grass</em> , Whitman returned to pages from an earlier edition to revise “The Sleepers” for republication. On those pages, Whitman created a textual event, a deletion of the “Lucifer” passage:</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>A page from “The Sleepers,” with Whitman’s edits. Walt Whitman Papers in the Charles E. Feinberg Collection. Library of Congress.
        </p>
    </figcaption>
</figure>
<p>Editing these and other lines out of his dreamspace, Whitman produced a final version of the poem tuned to a different historical present and different priorities on the part of the poet.<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> For Whitman, it would seem, the moment for the conjunction of experimental dreamspace with historical possibility had passed. If all you looked at was the 1891,authorizededition of <em>Leaves of Grass</em> , you would never know the self of “Bardic Symbols,” now titled “As I Ebb’d With the Ocean of Life,” had once been eternal — or that Lucifer had ever been there at all.</p>
<p>Luckily, Whitman’s was not the final word on the matter. Transformation is one path to the other side of determinism — a methodology that resurrects fragments, writes dysfunctional scripts, and attends to errors, absences and deletions. Media have always had to do with light and darkness, shadow and space, figures, icons, and projections. They can affect the visibility of history, passion, identification or difference. Perhaps media technologies become most apparent when the binaries break down in the act of translation, transformation, or remediation: in error, or, sometimes, in deletion. Moments at which multiple possibilities exist, suspended in space, can look suspiciously like moments of failure to the backwards glance of history: <em>Or if he was</em> . From this vantage point we watch Whitman on the verge, pencil in hand, weighing the path of erasure. The penciled bars of his hashmark deletion bought “The Sleepers” into a newNow,a post-war moment in which the promise of Lucifer’s heir — “I will either destroy him, or he shall release me” — may have echoed uncomfortably even for many former abolitionists, by then inclined toward reconciliation. The voice of the former slave and his descendants would continue to be locked away and suppressed from full political participation up to and beyond the emergence of Jim Crow in a series of criminal acts of silencing, violence, and oppression whose ongoing existence and implications are abundantly visible in our own time. But in that first conditional instant, thatNowin which the God of revolt was summoned, is alsosuccess, if only in the form of the recognition that one is part of a succession, sorrowful or otherwise.</p>
<h2 id="conclusioni-too-paumanok">Conclusion:I, too, Paumanok</h2>
<p>A 2007 <em>PMLA</em> special topic forum about the digital editorial project <em>The Walt Whitman Archive</em> exposed fundamental disagreements about the use of metaphors as substitutions for precise descriptions of digital tools.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> Demystifying the tools, however, does not rid us of metaphors, nor of the responsibility of navigating the complicated interplay of imagination, history, language, functionality, exclusion, and desire that defines the use and development of any technology. The transformative work of metaphor continues to inform the way technology functions, as well as the ways literary scholars can put it to work. Using imagination to cast seemingly competing logics against one another, to put pressure on the resonances between the words and the workings of poetic and machine language of the past and present, is one tool among many for training the attention to linger on a particular moment in a poem or other creative work and tease out some of its existing or potential implications.</p>
<p>Creative transformations applied to materials made digitally available by projects like the <em>Whitman Archive</em> can act as provocations to think and act and edit differently. In some cases, this may be a way to explore how underrepresented populations and perspectives are addressed (or erased) in historical documents. Recognition that race, gender, and other forms of diversity have shaped the historical record is finally beginning to affect textual and technological theory in ways that are slowly filtering back into editorial approaches, the digitization of literary and historical documents, and the work of thinking about the multiple versions of those documents in relation to the many different people whose histories they often imperfectly represent.</p>
<p>“If an electronic scholarly project can’t fail and doesn’t produce new ignorance,” John Unsworth wrote in a 1997 essay, “then it isn’t worth a damn.” The costs of failure or confessing ignorance, in the face of today’s confident, practiced users of digital tools and a historically bad tenure-track academic job market in the humanities, seem unusually high. Contingent, part-time, or adjunct positions can feel an awful lot like failure, without any guarantee of transformation, productive or otherwise. The current funding situation for the humanities and, increasingly, for education more broadly, is easily tied to the worst human motives — greed, racism, nativism, fear — and the darkest political prospects. Redefining the goals and parameters of success and failure for any project may be particularly necessary at such a time. Somewhere in theorizations like Sedgwick’s, or in Jackson’s repair, may be a glimmer of light, in the form of a call for the work of maintaining projects to become visible, for a broader notion ofsuccessto make that phenomenon visible in more places, for transformations of fields and texts to create the space for new voices and insights, and for the role of creation to be recognized in forms of labor other than authorship or innovation.</p>
<p>Is it time for the digital humanities to fail? As the humanities increasingly engages computation as a practice fundamental to the production of scholarship, or as the field called the digital humanities continues to splinter into method-specific approaches, we might resolutely cultivate one of its most exciting vectors: the emergence of a recuperative, radically experimental critical mode. In this mode, the imagination that fuels transformability is key, and failure holds a place of crucial importance. As Whitman’sselfbecame electrified over the course of the nineteenth-century manifestations of “Bardic Symbols,” so might we find in the digital detritus of our own day an electrifying vision of the future, a set of new critical possibilities to build out of the ships and the shipwrecks of history, as well as the transformable lines of poetry and prose to which they give rise.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>My thanks to Brett Barney, Matt Cohen, Mike Cohen, Ken Price, and Steve Ramsay for their thoughtful comments on drafts of this essay. Thanks also to the anonymous reviewers for their helpful suggestions.</p>
<ul>
<li id="allington2016">Allington, Daniel, Sarah Brouillette, and David Golumbia. “Neoliberal Tools (and Archives): A Political History of Digital Humanities.”  _Los Angeles Review of Books_ (May 1, 2016).<a href="https://lareviewofbooks.org/article/neoliberal-tools-archives-political-history-digital-humanities/">https://lareviewofbooks.org/article/neoliberal-tools-archives-political-history-digital-humanities/</a>Accessed 13 September 2020.
</li>
<li id="bailey2011">Bailey, Moya Z. “All the Digital Humanists Are White, All the Nerds Are Men, but Some of Us Are Brave.”  _Journal of Digital Humanities_ 1.1 (2011).
</li>
<li id="barnett2016">Barnett, Fiona, Zach Blas, Micha Cárdenas, Jacob Gaboury, Jessica Marie Johnson, and Margaret Rhee. “QueerOS: A User’s Manual.” Klein and Gold, 2016.<a href="dhdebates.gc.cuny.edu/debates/text/56">dhdebates.gc.cuny.edu/debates/text/56</a>. Accessed 20 July 2018.
</li>
<li id="cohen2017">Cohen, Matt. _Whitman’s Drift: Imagining Literary Distribution_ . Iowa City: University of Iowa Press, 2017.
</li>
<li id="ccp"> _Colored Conventions Project_ . University of Delaware. coloredconventions.org. Accessed 1 August 2018.
</li>
<li id="dhpoco">dhpoco.org. Curated by Adeline Koh and Roopika Risam. Accessed 10 July 2018.
</li>
<li id="draper2017">Draper, Nora. “Fail Fast: The Value of Studying Unsuccessful Technology Companies.”  _Media Industries_ , 4.1 (2017).
</li>
<li id="drucker2013">Drucker, Johanna. “From A to Screen: The Migration of Letters.”  _Comparative Textual Media_ , ed. N. Katherine Hayles and Jessica Pressman. Minneapolis: University of Minnesota Press, 2013.
</li>
<li id="drucker2009">Drucker, Johanna. _SpecLab: Digital Aesthetics and Projects in Speculative Computing_ . Chicago: University of Chicago Press, 2009.
</li>
<li id="edmond2016">Edmond, Jennifer. “Collaboration and Infrastructure.” Schreibman et al., 54-65.
</li>
<li id="eglash2007">Eglash, Ron. “Broken Metaphor: The Master-Slave Analogy in Technical Literature.”  _Technology and Culture_ 48.2 (April 2007).
</li>
<li id="xslw3c"> “The Extensible Stylesheet Language Family (XSL).” W3C.<a href="http://www.w3.org/Style/XSL/">www.w3.org/Style/XSL/</a>. Accessed 20 September 2020.
</li>
<li id="folsom2007">Folsom, Ed. “Database as Genre: The Epic Transformation of Archives.”  _PMLA_ 122.5 (October 2007): 1571-9.
</li>
<li id="folsom2014">Folsom, Ed. “Erasing Race: The Lost Black Presence in Whitman’s Manuscripts.” Wilson, ed., 3-31.
</li>
<li id="folsom2000">Folsom, Ed. “Lucifer and Ethiopia: Whitman, Race, and Poetics before the Civil War and After.”  _A Historical Guide to Walt Whitman_ , ed. David S. Reynolds. New York: Oxford University Press, 2000. 45-96.
</li>
<li id="folsom2001">Folsom, Ed. “Walt Whitman’s “The Sleepers.” ”  _The Classroom Electric: Dickinson, Whitman, and American Culture_ . 2001.<a href="http://bailiwick.lib.uiowa.edu/whitman/sleepers/">http://bailiwick.lib.uiowa.edu/whitman/sleepers/</a>. Accessed 18 April 2018.
</li>
<li id="french1990">French, R. W. “Whitman’s Dream Vision: A Reading of “The Sleepers.” ”  _Walt Whitman Quarterly Review_ 8.1 (Summer 1990): 1-15.
</li>
<li id="gallon2016">Gallon, Kim. “Making a Case for the Black Digital Humanities.” Klein and Gold, 2016.<a href="dhdebates.gc.cuny.edu/debates/text/55">dhdebates.gc.cuny.edu/debates/text/55</a>. Accessed 10 July 2018.
</li>
<li id="gilmore2009">Gilmore, Paul. _Aesthetic Materialism: Electricity and American Romanticism_ . Stanford: Stanford University Press, 2009.
</li>
<li id="gray2020">Gray, Nicole, ed. _Leaves of Grass (1855) Variorum_ . The Walt Whitman Archive, 2020.<a href="https://whitmanarchive.org/published/LG/1855/variorum/index.html">https://whitmanarchive.org/published/LG/1855/variorum/index.html</a>. Accessed 27 September 2020.
</li>
<li id="greenspan2019">Greenspan, Brian. “The Scandal of Digital Humanities.” Klein and Gold, 2019.<a href="https://dhdebates.gc.cuny.edu">https://dhdebates.gc.cuny.edu</a>. Accessed 12 September 2020.
</li>
<li id="grossman2019">Grossman, Jay. “Manuprint.”  _Walt Whitman Quarterly Review_ , 37.1 (Summer/Fall 2019): 46–65.
</li>
<li id="hayles2007">Hayles, N. Katherine. “Narrative and Database: Natural Symbionts.”  _PMLA_ 122.5 (October 2007): 1603-8.
</li>
<li id="jackson2014">Jackson, Steven J. “Rethinking Repair.”  _Media Technologies: Essays on Communication, Materiality and Society_ , ed. Tarleton Gillespie, Pablo J. Boczkowski, and Kirsten A. Foot. Cambridge: MIT Press, 2014.
</li>
<li id="jeffrey1992">Jeffrey, David Lyle and Leon Morris. “Logos.”  _A Dictionary of Biblical Tradition in English Literature_ , ed. David L. Jeffrey. Grand Rapids, MI: William B. Eerdmans, 1992. 459-61.
</li>
<li id="jockers2013">Jockers, Matthew L. _Macroanalysis: Digital Methods and Literary History_ . Champaign, IL: University of Illinois Press, 2013.
</li>
<li id="jockers2016">Jockers, Matthew L. and Ted Underwood. “Text-Mining the Humanities.” Schreibman et al., 291-306.
</li>
<li id="jorgensen2016">Jørgensen, Finn Arne. “The Internet of Things.” Schreibman et al., 42-53.
</li>
<li id="kay2008">Kay, Michael. _XSLT 2.0 and XPath 2.0: Programmer’s Reference_ . 4th ed. Indianapolis, IN: Wiley Publishing, Inc., 2008.
</li>
<li id="kennedy1896">Kennedy, William Sloane. _Reminiscences of Walt Whitman_ . London: Alexander Gardner, 1896.
</li>
<li id="klammer2006">Klammer, Martin. “Slavery and Race.”  _A Companion to Walt Whitman_ , ed. Donald D. Kummings. Malden, MA: Blackwell, 2006. 101-121.
</li>
<li id="klein2012">Klein, Lauren F., and Matthew K. Gold, eds. _Debates in the Digital Humanities_ . Minneapolis: University of Minnesota Press, 2012, 2016, and 2019.<a href="https://dhdebates.gc.cuny.edu/">https://dhdebates.gc.cuny.edu/</a>.
</li>
<li id="kirschenbaum2012">Kirschenbaum, Matthew. “Digital Humanities As/Is a Tactical Term.” Klein and Gold, 2012.<a href="dhdebates.gc.cuny.edu/debates/text/48">dhdebates.gc.cuny.edu/debates/text/48</a>. Accessed 20 July 2018.
</li>
<li id="kirschenbaum2010">Kirschenbaum, Matthew. “What Is Digital Humanities and What’s It Doing in English Departments?”  _ADE Bulletin_ 150 (2010): 55-61.
</li>
<li id="knuth1973">Knuth, Donald E. _The Art of Computer Programming_ . Vol. 1. 2nd edition. Reading, MA: Addison-Wesley Publishing Company, 1973.
</li>
<li id="koh2013">Koh, Adeline and Roopika Risam. “The Origins of #DHpoco and the Art of Play.”  _Postcolonial Digital Humanities_ (20 March 2013). Dhpoco.org.
</li>
<li id="landau2010">Landau, Elizabeth. “Tech Confronts Its Use of the Labels Master and Slave. ”  _Wired_ , 6 July 2020.<a href="https://www.wired.com/story/tech-confronts-use-labels-master-slave/">https://www.wired.com/story/tech-confronts-use-labels-master-slave/</a>. Accessed 27 September 2020.
</li>
<li id="latour1988">Latour, Bruno [as Jim Johnson]. “Mixing Humans and Nonhumans Together: The Sociology of a Door-Closer.”  _Social Problems_ 35.3 (June 1988): 298-210.
</li>
<li id="liu2004a">Liu, Alan. _The Laws of Cool: Knowledge Work and the Culture of Information_ . Chicago: University of Chicago Press, 2004.
</li>
<li id="liu2004b">Liu, Alan. “Transcendental Data: Toward a Cultural History and Aesthetics of the New Encoded Discourse.”  _Critical Inquiry_ 31 (2004): 49-84.
</li>
<li id="oed"> “logic, _n_ .”  _OED Online_ . Oxford University Press.<a href="www.oed.com/view/Entry/109788">www.oed.com/view/Entry/109788</a>. Accessed 19 April 2018.
</li>
<li id="liddell"> “λόγος.”  _The Online Liddell-Scott-Jones Greek-English Lexicon_ .<a href="http://stephanus.tlg.uci.edu/lsj/#eid=65855">http://stephanus.tlg.uci.edu/lsj/#eid=65855</a>. Accessed 19 April 2018.
</li>
<li id="mancuso1997">Mancuso, Luke. _The Strange Sad War Revolving: Walt Whitman, Reconstruction, and the Emergence of Black Citizenship, 1865-1876_ . Columbia, SC: Camden House, 1997.
</li>
<li id="mccarty2016">McCarty, Willard. “Becoming Interdisciplinary.” Schreibman et al., 67-83.
</li>
<li id="mcgann2007">McGann, Jerome. “Database, Interface, and Archival Fever.”  _PMLA_ 122.5 (October 2007): 1588-92.
</li>
<li id="mcgann2016">McGann, Jerome. “Marking Texts of Many Dimensions.” Schreibman et al., 358-76.
</li>
<li id="mcgann2001">McGann, Jerome. _Radiant Textuality: Literature After the World Wide Web_ . New York: Palgrave, 2001.
</li>
<li id="mckenzie1999">McKenzie, D. F. _Bibliography and the Sociology of Texts._ Cambridge: Cambridge University Press, 1999.
</li>
<li id="mcpherson2012">McPherson, Tara. “Why Are the Digital Humanities So White? or Thinking the Histories of Race and Computation.” Klein and Gold, 2012.<a href="dhdebates.gc.cuny.edu/debates/text/29">dhdebates.gc.cuny.edu/debates/text/29</a>. Accessed 20 July 2018.
</li>
<li id="miller2010">Miller, Matt. _Collage of Myself: Walt Whitman and the Making of Leaves of Grass_ . Lincoln, NE: University of Nebraska Press, 2010.
</li>
<li id="mott1939">Mott, Frank Luther. _A History of American Magazines_ . 4 vols. Cambridge: Belknap Press of Harvard University Press, 1939-57.
</li>
<li id="mott1941">Mott, Frank Luther. _American Journalism: A History of Newspapers in the United States through 250 Years, 1690 to 1940_ . New York: Macmillan Company, 1941.
</li>
<li id="mukurtu">Mukurtu Archive.<a href="http://www.mukurtuarchive.org/">www.mukurtuarchive.org</a>. Accessed 1 August 2018.
</li>
<li id="myerson1993">Myerson, Joel. _Walt Whitman: A Descriptive Bibliography_ . Pittsburgh, PA: University of Pittsburgh Press, 1993.
</li>
<li id="newman2017">Newman, Daniel. “Secret to Digital Transformation Success: Fail Fast to Innovate Faster.”  _Forbes_ . 16 May 2017.<a href="http://www.forbes.com/">www.forbes.com</a>. Accessed April 18, 2018.
</li>
<li id="oberhaus2018">Oberhaus, Daniel. “ Master/Slave Terminology Was Removed from Python Programming Language.”  _Vice_ . 13 September 2018.<a href="http://www.vice.com/">www.vice.com</a>. Accessed September 30, 2018.
</li>
<li id="parks1995">Parks, Suzan-Lori. _The America Play and Other Works_ . New York: Theatre Communications Group, Inc., 1995.
</li>
<li id="posner2016">Posner, Miriam. “What’s Next: The Radical, Unrealized Potential of Digital Humanities.” Klein and Gold, 2016.<a href="dhdebates.gc.cuny.edu/debates/text/54">dhdebates.gc.cuny.edu/debates/text/54</a>. Accessed 20 April 2018.
</li>
<li id="price2004">Price, Kenneth M. _To Walt Whitman, America_ . Chapel Hill, NC: University of North Carolina Press, 2004.
</li>
<li id="raley2002">Raley, Rita. “Interferences: [Net.Writing] and the Practice of Codework.”  _Electronic Book Review_ (2002).<a href="http://electronicbookreview.com/essay/interferences-net-writing-and-the-practice-of-codework/">http://electronicbookreview.com/essay/interferences-net-writing-and-the-practice-of-codework/</a>. Accessed 31 July 2018.
</li>
<li id="ramsay2011">Ramsay, Stephen. _Reading Machines: Toward an Algorithmic Criticism_ . Urbana: University of Illinois Press, 2011.
</li>
<li id="samuels1999">Samuels, Lisa and Jerome McGann. “Deformance and Interpretation.”  _New Literary History_ 30.1 (Winter 1999): 25-56.
</li>
<li id="sandage2005">Sandage, Scott A. _Born Losers: A History of Failure in America_ . Cambridge, MA: Harvard University Press, 2005.
</li>
<li id="sandler2014">Sandler, Matt. “Kindred Darkness: Whitman in New Orleans.” Wilson, ed., 54-81.
</li>
<li id="sayers2016">Sayers, Jentery, Devon Elliott, Kari Kraus, Bethany Nowviskie, and William J. Turkel. “Between Bits and Atoms: Physical Computing and Desktop Fabrication in the Humanities.” Schreibman et al., 1-21.
</li>
<li id="schloen2014">Schloen, David and Sandra Schloen. “Beyond Gutenberg: Transcending the Document Paradigm in Digital Humanities.”  _Digital Humanities Quarterly_ 8.4 (2014).
</li>
<li id="schreibman2016">Schreibman, Susan, Ray Siemens, and John Unsworth, eds. _A New Companion to Digital Humanities_ . Chichester: John Wiley & Sons, 2016.
</li>
<li id="sedgwick2003">Sedgwick, Eve Kosofsky. “Paranoid Reading and Reparative Reading, Or, You’re So Paranoid, You Probably Think this Essay is About You.”  _Touching Feeling: Affect, Pedagogy, Performativity._ Durham: Duke University Press, 2003. 123-152.
</li>
<li id="stallybrass2019">Stallybrass, Peter. “Walt Whitman's Slips: Manufacturing Manuscript.”  _Walt Whitman Quarterly Review_ , 37.1 (Summer/Fall 2019): 66–106.
</li>
<li id="stephenson1999">Stephenson, Neal. _In the Beginning was the Command Line_ . New York: Avon, 1999.
</li>
<li id="surowiecki2014">Surowiecki, James. “Epic Fails of the Startup World.”  _The New Yorker_ (19 May 2014).<a href="https://www.newyorker.com/magazine/2014/05/19/epic-fails-of-the-startup-world">https://www.newyorker.com/magazine/2014/05/19/epic-fails-of-the-startup-world</a>. Accessed 31 July 2018.
</li>
<li id="traubel1906">Traubel, Horace. _With Walt Whitman in Camden_ . 9 vols. 1906-1996.
</li>
<li id="w3c"> “Transformation.” W3C Standards (XML Technology).<a href="https://www.w3.org/standards/xml/transformation">https://www.w3.org/standards/xml/transformation</a>. Accessed 8 August 2018.
</li>
<li id="transformdh">#transformDH: This is the Digital Humanities. <a href="http://transformdh.tumblr.com/">http://transformdh.tumblr.com/</a>, transformDH.org. Accessed 20 July 2018.
</li>
<li id="unsworth1997">Unsworth, John. “Documenting the Reinvention of Text: The Importance of Failure.”  _The Journal of Electronic Publishing_ 3.2 (December 1997). www.press.umich.edu/jep/03-02/unsworth.html. Accessed 22 August 2018.
</li>
<li id="vincent1889">Vincent, Marvin R. _Word Studies in the New Testament_ . Vol. 2. New York: Charles Scribner’s Sons, 1889.
</li>
<li id="wwarchives"> _The Walt Whitman Archive_ .<a href="http://www.whitmanarchive.org/">www.whitmanarchive.org</a>. Accessed 27 September 2020.
</li>
<li id="whitman1860">Whitman, Walt. “Bardic Symbols.”  _Atlantic Monthly_ 5 (April 1860): 445-47.
</li>
<li id="whitman1842">Whitman, Walt. “Franklin Evans; or, the Inebriate. A Tale of the Times.” _The New World_ (November 1842): [1]-31.
</li>
<li id="whitman1855">Whitman, Walt. _Leaves of Grass_ . Brooklyn, NY, 1855.
</li>
<li id="whitman1860-1">Whitman, Walt. _Leaves of Grass_ . Boston: Thayer and Eldridge, 1860-1.
</li>
<li id="whitman1867">Whitman, Walt. _Leaves of Grass_ . New York: W. E. Chapin & Co., Printers, 1867.
</li>
<li id="whitman1871">Whitman, Walt. _Leaves of Grass_ . Washington, DC, 1871.
</li>
<li id="whitman1881">Whitman, Walt. _Leaves of Grass_ . Boston: James R. Osgood and Company, 1881-2.
</li>
<li id="whitman1891">Whitman, Walt. _Leaves of Grass_ . Philadelphia: David McKay, 1891-2.
</li>
<li id="whitman1888">Whitman, Walt. _November Boughs_ . Philadelphia: David McKay, 1888.
</li>
<li id="wilkins2013">Wilkins, Matthew. “An Impossible Number of Books: Matthew L. Jockers’s Macroanalysis. ”  _Los Angeles Review of Books_ . 16 August 2013.<a href="https://lareviewofbooks.org/">https://lareviewofbooks.org</a>. Accessed 18 April 2018.
</li>
<li id="wilson2014a">Wilson, Ivy G. “Looking with a Queer Smile: Walt Whitman’s Gaze and Black America.” Wilson, ed., vii-xix.
</li>
<li id="wilson2014b">Wilson, Ivay G., ed. _Whitman Noir: Black America and the Good Gray Poet_ . Iowa City: University of Iowa Press, 2014.
</li>
<li id="winship1991">Winship, Michael. “Walt Whitman.”  _Bibliography of American Literature_ , compiled by Jacob Blanck. Vol. 9. New Haven: Yale University Press, 1991. 28-103.
</li>
<li id="zhou2019">Zhou, Cathy. _The State of the Octoverse 2019._ The GitHub Blog, 6 November 2019.<a href="https://github.blog/2019-11-06-the-state-of-the-octoverse-2019/">https://github.blog/2019-11-06-the-state-of-the-octoverse-2019/</a>. Accessed 27 September 2020.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>On this phenomenon as perception and as evolving actuality, see<a href="#kirschenbaum2010">Kirschenbaum (2010)</a>and<a href="#kirschenbaum2012">(2012)</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>This criticism has prompted a series of conversations about postcolonial, feminist, and queer digital humanities, as well as meditations on the possible complicity of digital methods with neoliberal agendas. See<a href="#transformdh">#transformDH</a>and<a href="#dhpoco">#DHpoco</a>for examples of the former; for the latter, see<a href="#allington2016">Allington et al. (2016)</a>and<a href="#greenspan2019">Greenspan’s (2019)</a>response.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Bailey writes that “The move from margin to center offers the opportunity to engage new sets of theoretical questions that expose implicit assumptions about what and who counts in digital humanities as well as exposes structural limitations that are the inevitable result of an unexamined identity politics of whiteness, masculinity, and ablebodiness.” <a class="footnote-ref" href="#bailey2011"> [bailey2011] </a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Websites for SpecLab and the Applied Research in Patacriticism group are now defunct, though legacy versions are accessible through the Internet Archive’s Wayback Machine. See Samuels and McGann’s development of the term “deformance” in relation to critical interpretation, editing, and translation, and elaborations by McGann ( <em>Radiant Textuality</em> ) and Drucker ( <em>SpecLab</em> ). Later work by scholars and artists like Nick Montfort, Mez Breeze, and Alan Sondheim offers other examples of the creativity that has emerged at the intersection of art and algorithms. For further discussion of codework, the integration of programming syntax and creative expression, see<a href="#raley2002">Raley (2002)</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>QueerOS is a notable recent example of this kind of imaginative work (see<a href="#barnett2016">Barnett et al. [2016]</a>). Play was proposed as a methodology for #DHpoco, as well; see Koh and Risam.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>The “emphasis was placed on de- rather than transformance,” McGann writes, “in order to show that the object of critical reflection is not ultimately directed to the sign as such but to the rhetorical scene and its functional (social) operators, not least of all the person(s) engaged in the acts of deformance we commonly locate in a file headed Interpretation ” <a class="footnote-ref" href="#mcgann2001"> [mcgann2001] </a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>See<a href="#klammer2006">Klammer (2006)</a>;<a href="#folsom2000">Folsom (2000)</a>and<a href="#folsom2014">Folsom (2014)</a>; and<a href="#mancuso1997">Mancuso (1997)</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>See<a href="#latour1988">Latour (1988)</a>and<a href="#mckenzie1999">McKenzie (1999)</a>, respectively.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Ramsay’s algorithmic criticism is an effort to “locate a hermeneutics at the boundary between mechanism and theory” that explores transformation as key to the generation of humanities “data” <a class="footnote-ref" href="#ramsay2011"> [ramsay2011] </a>. Sedgwick’s reparative reading continues to offer a provocative possibility of thinking beyond (even computer) binaries, in part because it suggests that the fact that boundaries may structure our world in fundamental ways need not determine the kinds of actions or thoughts that must be taken in relation to or as a function of that knowledge<a class="footnote-ref" href="#sedgwick2003"> [sedgwick2003] </a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>The first substantive revision to the second line appeared in the 1867 edition of <em>Leaves of Grass</em> : “Alone, held by this eternal self of me, out of the pride of which I have utter’d my poems” <a class="footnote-ref" href="#whitman1867"> [whitman1867] </a>. See<a href="#gilmore2009">Gilmore (2009)</a>for a discussion of the electrical and technological developments that underpinned the transformation of the poem titled “Poem of the Body” in 1856 to “I Sing the Body Electric” in 1867 and later editions.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>The use of XML has been questioned, and in several cases alternatives proposed (see e.g.<a href="#schloen2014">Schloen and Schloen [2014]</a>), but as inline or embedded markup it remains a common approach to encoding data and a standard for digital scholarly editing.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>See<a href="#liddell">Liddell-Scott-Jones</a>. Biblical commentary has explored the meaning ofλόγοςin the context of John 1:1 ( “In the beginning was the Word&hellip;” ). See, e.g.,<a href="#jeffrey1992">Jeffrey and Morris (1992)</a>and<a href="#vincent1889">Vincent (1889)</a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>These include XSL-FO, XSLT, and XPath<a class="footnote-ref" href="#xslw3c"> [xslw3c] </a>.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>This language of succession was inherited from earlier markup and stylesheet languages: the development of XSL syntax was influenced by SGML and its stylesheet language DSSSL, which in turn had been based on earlier programming and query languages. On the history and development of XSL, see<a href="#kay2008">Kay (2008), 26-40,</a>and<a href="#w3c">“Transformation.”</a>For a general discussion of lineal trees (and other metaphors) in relation to algorithms and computational data structures, and within a longer history of graph theory, see<a href="#knuth1973">Knuth (1973), 305-406</a>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>For further discussion of Whitman’s collaging as fundamental to his poetry composition, see<a href="#miller2010">Miller (2010)</a>.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>In an entry in <em>With Walt Whitman in Camden</em> dated July 31, 1888, Horace Traubel noted as much: “W. has an idea of putting the Hicks-Fox matter eventually into a special pamphlet. Made many changes of the make-up in order to get the Hicks started on an odd page. This is one of his memorandums to the printer: “begin making up Elias Hicks on page 119 I will supply something for page 118” ” <a class="footnote-ref" href="#traubel1906"> [traubel1906] </a>. For another example of sheets that Whitman published independently and had bound into other volumes, see the entry for <em>Passage to India</em> (1871) in<a href="#winship1991">Winship (1991), 36</a>.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>See<a href="#winship1991">Winship (1991)</a>,<a href="#myerson1993">Myerson (1993)</a>,<a href="#stallybrass2019">Stallybrass (2019)</a>, and<a href="#grossman2019">Grossman (2019)</a>for inventories and descriptions of Whitman’s publications and printed slips. This comparison is not meant to gloss over Tara McPherson’s important points about the racial and political implications of the “lenticular” logic of modularity and interoperability in the development of modern computing<a class="footnote-ref" href="#mcpherson2012"> [mcpherson2012] </a>.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>The poem is untitled (or assigned the recurring title “Leaves of Grass” ) in the 1855 edition. It appeared in the 1856 <em>Leaves of Grass</em> as “Night Poem” and in the 1860-1 and 1867 editions as “Sleep-Chasings.” It was first titled “The Sleepers” in 1871.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>For a discussion of this poem and related manuscript drafts, see<a href="#folsom2001">Folsom (2001)</a>.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>A murder is juxtaposed to dream and sleeping scenes in Whitman’s temperance novel “Franklin Evans.”&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>See, for instance,<a href="#french1990">French (1990)</a>.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>See, for instance,<a href="#surowiecki2014">Surowiecki (2014)</a>,<a href="#draper2017">Draper (2017)</a>, and<a href="#newman2017">Newman (2017)</a>. See also<a href="#liu2004a">Liu (2004a)</a>.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Whitman probably exaggerated here, as often in his discussions with Traubel.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Estimates are based on prices and sales figures for copies listed on AbeBooks.com and sold at rare book auctions between 2018 and 2020.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>On Whitman’s concept of drift and its relation to the distribution and circulation of his writing, see<a href="#cohen2017">Cohen (2017)</a>.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>GitHub’s 2019 “Octoverse Report” ranked Python as the second most-used language in Git repositories, based on number of unique contributors<a class="footnote-ref" href="#zhou2019"> [zhou2019] </a>. Python, like other programming languages and software platforms, has recently begun to reckon with its metaphors. See<a href="#oberhaus2018">Oberhaus (2018)</a>on the use and removal of the termsmasterandslave.These terms have long been used (and recently, in some cases, deprecated) in other engineering and computational contexts, including as references to central and backup servers, primary and secondary drives, and primary and replica databases. For further discussion, see<a href="#eglash2007">Eglash (2007)</a>and<a href="#landau2010">Landau (2020)</a>.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Samuels and McGann quote Dickinson’s note, from “an undated fragment on a leaf of stationery:”  “Did you ever read one of her Poems backward, because the plunge from the front overturned you? I sometimes (often have, many times) have–a Something overtakes the Mind–” <a class="footnote-ref" href="#samuels1999"> [samuels1999] </a>.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Whitman works through this line in other drafts. For a complete list of transcriptions of the known drafts of these lines, see<a href="#gray2020">Gray (ed.; 2020)</a>line 1775<a href="https://whitmanarchive.org/published/LG/1855/variorum/main.html#l1775">https://whitmanarchive.org/published/LG/1855/variorum/main.html#l1775</a>.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>See<a href="#folsom2014">Folsom (2014)</a>;<a href="#price2004">Price (2004), 17-18</a>; and<a href="#sandler2014">Sandler (2014), 71-74</a>.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>For the line <code>elif year&gt;=1881:</code> , if the user enters a year later than or equal to 1881, she returns another line from the version of “The Sleepers” published in the 1881 edition of <em>Leaves of Grass</em> , since the “Lucifer” lines are no longer present. For the line <code>elif 1776 &lt;=year &lt;1849:</code> , if the user enters a year after the date of U.S. independence (1776) and prior to the approximate earliest probable date of the manuscript (1849), she returns a line from the Declaration of Independence. On the final print command, see<a href="#parks1995">Parks (1995), 159</a>.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>For text mining purposes, as Jockers and Underwood point out, “we know from years of authorship-attribution research that the most effective features for distinguishing one author’s style from another’s are high-frequency features such as the words the, of, him, her, and and, as well as common marks of punctuation” <a class="footnote-ref" href="#jockers2016"> [jockers2016] </a>.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>On the role of this kind of invisibility in the capitalistic exploitation of creativity, see<a href="#liu2004b">Liu (2004b)</a>.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>For a discussion of this deletion and other omissions as related to Whitman’s increasing concern about the role of Blacks in the Reconstruction and post-Reconstruction U.S., see<a href="#folsom2000">Folsom (2000), 52-77</a>. See also<a href="#klammer2006">Klammer (2006)</a>. Whitman deleted other sections from the poem, as well: see, for instance, the two sections beginning “O hot-cheek’d and blushing! O foolish hectic!”&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>See<a href="#folsom2007">Folsom (2007)</a>;<a href="#mcgann2007">McGann (2007)</a>; and<a href="#hayles2007">Hayles (2007)</a>.## Bibliography&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Decolonizing The Digital in the Classroom: Reflections on the Intersection of Colonial Latin American Art History and Digital Art History Pedagogy</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000494/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000494/</id><author><name>Lauren G. Kilroy-Ewbank</name></author><published>2020-12-15T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<p>“[D]igital media is not neutral: It impacts the represented information and the ways society interprets it” <a class="footnote-ref" href="#kalay2008"> [kalay2008] </a>.</p>
<h2 id="introduction-colonial-latin-american-art-and-the-digital">Introduction: Colonial Latin American Art and The Digital</h2>
<p>Digital visual media, such as images and videos, form an inescapable cornerstone of our lived experience. For those of us in higher education, the digital is altering not only how and what we research but also how and what we teach. In a similar vein as other specializations, the study of colonial Latin American art is being transformed.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> Art historians, finely attuned to the visual world and the meaning-making processes informing it, seem uniquely positioned to engage with and critique the digital realm that we increasingly inhabit and to teach digital, visual literacy.</p>
<p>Despite art historians’ possible role to play in shaping and framing the digital world, there is still an ambivalence about what the digital turn has to offer art history. An assessment of the impact ofthe digital,and more specifically the digital humanities (DH) and digital art history (DAH), on the field of art history reveals that there are those who believe the digital turn has the potential to positively disrupt it (e.g.,<a href="#honig2018">Honig 2018</a>) and those who feel it has the potential to problematically disturb it (e.g.,<a href="#bishop2015">Bishop 2015</a>). Regardless of where an individual’s position falls on this spectrum, the digital is here to stay, and it is reinventing art history and the manner in which we access, engage with, asses, and frame visual culture. One wonders, as Nuria Rodríguez-Ortega (<a href="#rodriguez2013b">2013b</a>) has, if Donald Preziosi (<a href="#preziosi1991">1991</a>) could have imagined the impact the digital would have on how we “rethink art history,” a suggestion he first made about the art-historical discipline in the wake of post-structuralist and post-modern critiques of art and the (im)possibility of stable meaning.</p>
<p>For all these reasons, it is important that we equip ourselves with the ability to understand how the digital frames or reframes our understanding of visual culture and to effectively critique it. As art historians know all too well, framing devices construct a visual rhetoric, one that creates certain “epistemological and methodological assumptions,” in the words of Elli Doulkaridou [<a href="#doulkaridou2015">2015</a>, 69]. Something as seemingly simple as substituting, in class, a high-resolution gigapixel panoramic 360° photo of the church of San Pablo de Ocongate in Peru<a class="footnote-ref" href="#mavcor2018"> [mavcor2018] </a>for a flat megapixel one can alter perception, experience, and belief about the object or space that the digital image indexes. The digital turn has thus prompted shifts in how we see the world and the ways in which we consume and produce knowledge. In the digital environment in which we increasingly live, learn, and, for those of us in the classroom, teach, it has become clear that we must consider digital technology as epistemology<a class="footnote-ref" href="#schilling2014"> [schilling2014] </a><a class="footnote-ref" href="#rodriguez2009"> [rodriguez2009] </a>. Digital media is, as Yehuda Kalay states, not neutral, but creates, shapes, and disseminates knowledge in different ways than a hardbound book, a DVD, or a lecture delivered in a classroom. Similarly, Rodríguez-Ortega advises us to be mindful about how we perceive of the digital realm — not as a “neutral, innocuous space that delivers information” but as a “cultural, political, and ideological venue” <a class="footnote-ref" href="#rodriguez2013a"> [rodriguez2013a] </a>.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></p>
<p>For these reasons it is imperative to think about not only the technological tools needed to engage in digital practices and meaning-making, but also the critical tools needed to think about what content to produce and how to produce it. I would add to this that we also need the critical tools to think about, assess, and communicate what and how we experience and interact with (i.e. what we consume) online. Even those of us who do not intend to make DAH tools or projects will encounter and use them, and most if not all art historians now employ digitized images for our teaching and research. The very way these digitized images are aggregated and framed has the potential to shift our field — ontologically, epistemologically, and pedagogically.</p>
<p>This essay grapples with some of the complexities that the digital poses for those of us who teach and research colonial Latin American art. It asks a number of questions: In what ways can DAH methods and tools, as well as digitized visual materials, help us to think more critically or differently about visual culture? What challenges exist when working with digital images, tools, and methods?<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> To explore these questions, I draw on responses to a questionnaire and my own pedagogical experiences. The questionnaire gathered information about how others in the field of colonial Latin American art history approach the digital in their pedagogy and research. These responses serve as a launching point for a broader discussion of the ramifications of DAH pedagogy and research as it relates to the visual culture of colonial Latin America.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> Also serving as a springboard to wrestling with these issues are my own experiences with DAH pedagogy and the challenges it has presented to both me and my students when discussing and analyzing colonial Latin American art. In particular, I describe a course project that asks students to build digital exhibitions about Spanish colonial art using the content management system (CMS) called Omeka<a class="footnote-ref" href="#omeka2018a"> [omeka2018a] </a>. Discussions about metadata and the use of digital images prompted the students and me to consider issues of digital and visual epistemology, digital visuality and storytelling, art historical nomenclature, the ontology of art history, digital colonialism and neocolonialism, accessibility, and labor — all in the course of a semester. These considerations aided students in not only thinking more critically about colonial Latin American art, but also developing digital and multimodal literacy with Web 2.0 technology.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> In focusing on these pedagogical experiences, I hope to highlight some of the greater implications of the digital world for the study of colonial Latin American visual culture and pay heed to how DAH pedagogy can both disrupt and disturb art history.</p>
<h2 id="gathering-data-from-a-questionnaire">Gathering Data from a Questionnaire</h2>
<p>To collect information from other scholars teaching and researching the visual culture of colonial Latin America, I distributed a questionnaire in English to the Association of Latin American Art (ALAA) listserv.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> The survey gathered data anonymously with both quantitative and qualitative questions to develop a mixed-methods approach.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> It asked a series of questions about how people teach or research colonial Latin American art using DAH tools or resources, and whether they use DAH projects like Smarthistory or tools like Omeka, and if so, how. It compiled information about how long a participant has taught, the subjects of courses focused on colonial Latin American visual culture, and the orientation of these classes towards DAH or DH.</p>
<p>Fourteen individuals responded to the survey, offering a small, yet useful <em>n</em> to analyze the role of the digital in teaching and researching about colonial Latin American visual culture.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> The open-ended answers varied from a few words to lengthy paragraphs. Despite this variability, the responses prompted thought-provoking reflection on the role of digitized and digital art history among those of us focused on the visual culture of colonial Latin America. The collected data revealed a number of important concerns, among them (1) the broad way in which individuals define, understand, and use “the digital” when researching or teaching about colonial Latin American visual culture; (2) the perception that digitized and digital art history have the potential to advance the study of Latin American art and to complicate or decenter the canon, even if the specific ways in which this might occur seem vague and undetermined; (3) the importance of access to high-resolution images, archival materials, and scholarship to ease financial burden and collaborate across international borders; and (4) the need for more digital resources or projects, despite the large number of perceived challenges, which include the limitations of digital technologies, the time needed to learn digital tools and skills, and the reliability and trustworthiness of these tools and projects. The remainder of this essay explores these ideas in connection to pedagogical strategies and experiences with digital art history in an undergraduate class focused on colonial Latin American visual culture.</p>
<h2 id="using-and-defining-digitized-and-digital-art-history">Using and Defining Digitized and Digital Art History</h2>
<p>The general consensus from the responses on the questionnaire is that working with digital tools and digitized visual materials offers clear benefits to any scholar or student of art history, regardless of their specialization.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> These benefits include access to materials from around the globe, the use of high-resolution images for study, the opportunity to create a visual archive of images currently split among international collections, or the invitation to engage with materials more slowly from anywhere at any time. The qualitative responses detailed the various ways respondents felt that DAH had impacted (or could impact) their research, teaching, the field of colonial Latin American art, and art history more generally. Many suggested that DAH provides new ways of interacting with data, helps us to ask new types of questions, and shifts how we understand visual culture. However, most respondents mentioned that they were unsure what these interactions or shifts might look like and whether they were sustainable. When asked if they themselves are active in DAH or DH, 42.9% responded yes, 35.7% maybe, and 21.4% no. Written responses suggested that some participants were simply unsure if what they were doing “counted” as DAH; for example, several wondered if using a university’s CMS in their colonial Latin American art classes meant they had familiarity with or practiced DAH. Others noted their reticence to answeryesbecause they were unsure how to define DAH altogether, noting that they could not align themselves with it if they do not know what it is, and if art historians more generally cannot agree how to define it.</p>
<p>Respondents relied on a wide range of digital tools and methods for their research, but this use was more limited pedagogically.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> 69.2% answered that their classes are not oriented towards DAH; remaining responses were split between yes and maybe. A follow-up question asked participants to describe those classes that foregrounded, or at least incorporated to some extent, digital methods and tools. Several individuals incorporate textual analysis, mapping, image annotation, or the creation and curation of online projects (such as the development of an online exhibition using Omeka). Most commonly, though, respondents linked students to digital image repositories, essays, and videos from sites like Vistas<a class="footnote-ref" href="#leibsohn2015"> [leibsohn2015] </a>, Smarthistory [<a href="#smarthistory2018">2018</a>], and The Metropolitan Museum’s Heilbrunn Timeline (2000–2018). These answers further highlighted the confusion (and in some cases frustration) about how to define or understand DAH or what constitutes doing it or using it in the classroom setting.</p>
<p>Digital Art History is one aspect of the Digital Humanities, and both have affected the development of the humanities more broadly. Those engaged with DAH cross disciplinary boundaries, incorporating not only art history and computer science, but also media studies and library and information science. As the questionnaire responses highlighted, defining DH or DAH is challenging, as there is no clear consensus around how to understand either<a class="footnote-ref" href="#kilroy2018"> [kilroy2018] </a>.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> Complicating matters further is that digital (or digitized) visual materials, image repositories, and databases are often not considered synonymous with DAH. Several scholars have articulated the difference between digitized art history and DAH (e.g.,<a href="#drucker2013">Drucker 2013</a>;<a href="#rodriguez2013a">Rodríguez-Ortega 2013a</a>,<a href="#rodriguez2019">2019</a>;<a href="#bishop2015">Bishop 2015</a>; see also<a href="#zorich2012">Zorich 2012</a>;<a href="#baca2013">Baca and Helmreich 2013</a>;<a href="#fletcher2015">Fletcher 2015</a>; and<a href="#drucker2015">Drucker, Helmreich, Lincoln, and Rose 2015</a>). For them, creating and using digital repositories that “simply aggregate data and/or images” are examples of digitized art history<a class="footnote-ref" href="#rodriguez2013a"> [rodriguez2013a] </a>, whereas research that uses computational analysis (e.g., GIS mapping, data visualization, topic modeling, network analysis, data mining) is an example of DAH. I am reticent to separate digitized art history entirely from digital art history, however. The digitization of materials and their manipulation — cropping, whitening, framing, straightening, and deciding what to include or exclude — affect how we understand what we are seeing, advancing certain epistemological arguments, a position Barbara Mundy and Dana Leibsohn also address in “Digital Resources: The State of Digital Research on the Visual Culture of Spanish America” (<a href="#mundy2017">2017</a>), which provides a state of the field as well as describes potential issues with accessibility, collaboration, and the effects of the digital on ways of seeing (see also<a href="#rodriguezortega2018">Rodríguez-Ortega 2018</a>,<a href="#rodriguez2019">2019</a>).</p>
<p>It is more valuable perhaps to distinguish between digital inflection and digital centeredness. The former uses certain digital technologies to create something that is similar to existing modes of writing or teaching; for instance, asking students to reflect on an artwork in a blog post. Digital centeredness suggests foregrounding digital technologies to generate new types of questions, methods, or ideas that more traditional ones cannot or have not; for instance, creating 3D models<a class="footnote-ref" href="#hoobler2018"> [hoobler2018] </a>, crowdsourcing to match print sources with colonial paintings<a class="footnote-ref" href="#pessca"> [pessca] </a>, or mapping the locations of artworks described in archival documents<a class="footnote-ref" href="#rodriguez2018"> [rodriguez2018] </a>.</p>
<p>Most questionnaire respondents insinuated that the digital turn offers important benefits for pedagogy, research, and the very manner in which we determine what constitutes colonial Latin American visual culture, even if what DAH is remains amorphous. The increase, especially in the past decade, of projects revolving around colonial Latin American art supports this claim that DAH is beneficial (see also<a href="#mundy2017">Mundy and Leibsohn 2017</a>). These projects offer specialists and students alike the ability to learn about Latin American visual culture and its history in multimodal ways (such as with photographs, video, 3D reconstructions, 360-degree panoramas, text, music, and data visualizations), and even exposure to less canonical (e.g., Vistas), partial, or destroyed objects (e.g., Digital Aponte), architecture, and primary sources related to the visual, material record.</p>
<p>A few survey responses indicated the importance of reaching out to different publics — scholars, students, anyone interested in colonial Latin American art, and those individuals who might develop interest in it as a result of searching the Web. Projects like Vistas, Digital Códice Mendoza<a class="footnote-ref" href="#codex2014"> [codex2014] </a>, Project on Engraved Sources of Spanish Colonial Art<a class="footnote-ref" href="#pessca"> [pessca] </a>, and Digital Aponte<a class="footnote-ref" href="#rodriguez2018"> [rodriguez2018] </a>also suggest the myriad ways that DAH projects can engage various types of audiences. The Digital Códice Mendoza, for instance, is bilingual (Spanish and English) and allows users to zoom in and pan across high-resolution scans of the entire codex, and offers transcriptions of the text as you hover over it. It is of interest to art historians, but also historians, paleographers, archaeologists, and so forth, and is accessible to anyone with the internet.</p>
<p>A couple respondents mentioned that DAH has the ability to challenge entrenched ideas about the field of art history, and the role of colonial Latin American art within it. For example, one noted the importance of nimble online projects like Smarthistory as alternatives to textbooks that are not updated regularly. Smarthistory is, for lack of a better term, a not-for-profit open educational resource that focuses on world art. It is the result of collaboration among more than 400 art historians. New essays and videos can be added continuously and information updated regularly, helping to dispel the notion that art history — and colonial Latin American art by extension — is fixed.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup></p>
<p>The idea that digital art history projects can reach wider audiences and disrupt the field of colonial Latin American art history is one that warrants greater discussion. Here, I would like to offer a few reflections and discussion points about how incorporating digital art history practices into undergraduate classes about colonial Latin American visual culture has encouraged better digital critical thinking by encouraging students to think about art history’s ontological issues and nomenclature, descriptive metadata, and issues of colonialism (or neocolonialism), as well as the ways in which digital images have the potential to reframe how we understand the visual culture of this region and time period.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup></p>
<h2 id="art-historys-ontological-issues-and-descriptive-metadata">Art History’s Ontological Issues and Descriptive Metadata</h2>
<p>Art history has long been about classifying art based on style and iconography. One could argue that for much of its existence, the field has been focused on cataloging works of art and architecture to create, as much as possible, neat taxonomies. If we think back to the origins of the discipline, the art historians who shaped the formation of art history in the late eighteenth, nineteenth, and early twentieth centuries, from Johann Winckelmann, Aby Warburg, and Erwin Panofsky to Alois Riegl, Hienrich Wöfflin, and George Kubler, created classification systems and vocabularies still used today to discuss form and subject matter. They are systems largely centered around and stemming from European art.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> In particular there has been a privileging of Italian Renaissance art and the stylistic terms used to describe art from the Italian Peninsula between 1400 and 1600, what Svetlana Alpers (<a href="#alpers1979">1979</a>) and others refer to as Italocentrism. Many of these stylistic labels, such as Renaissance or Baroque, have also become temporal descriptors, denoting a time period (e.g.,<a href="#maravall1986">Maravall 1986</a>) and sometimes a place, rather than a representational mode.</p>
<p>The nomenclature of art history developed to describe European art has been appended to the visual culture of areas outside of Europe, including those areas, such as Latin America, in which Europeans invaded and colonized people and introduced new visual systems. Colonial Latin American art calls into question where we have centered the canon, the terminology we use to discuss art, and even the spaces and places where art is found. Periodizations describing European artistic trends do not transplant neatly (nor should they) to the Americas, creating what Ananda Cohen-Aponte [<a href="#cohenaponte2017">2017</a>, 69] notes is one of many “unresolved issues” facing scholars who study colonial Latin American visual culture. Cohen-Aponte points to the “innocuous terminology” [<a href="#cohenaponte2017">2017</a>, 69] applied to viceregal art, seeking to problematize it in an attempt to decolonize art history. Jeanette Peterson has similarly discussed how a term such as Renaissance “advances or impedes our ability to analyze and understand visual culture from the viceregal period” [<a href="#peterson2008">2008</a>, 322]. She asks, for instance, how do we categorize an “early seventeenth-century ivory figure of the Mexican Virgin of Guadalupe made by Chinese carvers working in the Philippines, transported across the Pacific in the Manila galleon fleet bound for Acapulco and ultimately destined for American and European consumers?” [<a href="#peterson2008">2008</a>, 331–332]. Do we simply note it as Renaissance or the more generic sixteenth century? Despite the challenges with applying these terms to colonial Latin American visual culture, it has proven difficult to omit them entirely, even in instances when they do not fit comfortably (e.g.,<a href="#sullivan1996">Sullivan 1996</a>;<a href="#peterson2008">Peterson 2008</a>, 322).</p>
<p>Where does digital art history fit into these discussions about nomenclature and the ontology of art history? If we were to reconceptualize Peterson’s question about the ivory figure of Guadalupe from the point of view of DAH, we might ask, how could we translate this object, one which resists easy classification, into tidy, “objective” metadata? After all, many DAH projects necessitate the creation of metadata about images. While not speaking specifically to the potential challenges and issues of inputting descriptive metadata in a digital environment, much of Peterson’s discussion, as well as Cohen-Aponte’s, revolve around similar issues.</p>
<p>I would argue that there are DAH processes and ideas that can assist scholars and students to think more critically about the terminology used to describe colonial Latin American art in the digital environment. If one of the main reasons for engaging with the digital is to access information, as the questionnaire responses all noted, then how we input, organize, aggregate, and source that data is fundamentally significant. My own experiences with introducing students to metadata, as one step towards producing a collaborative online exhibition on Omeka, has stimulated important and thought-provoking conversations about how we describe, analyze, frame, and discuss colonial Latin American art.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> It helped students to develop digital literacy and to grasp more fully the non-neutrality of visual resources, DAH projects, and the Web more generally. It also increased their awareness of how we access information and how the presentation of that information affects what we know or think we know, how we see, and where we locate knowledge about colonial Latin American visual culture.</p>
<p>To create their online exhibition with Omeka, students must learn about metadata. In the process of creating metadata, students must weigh the eurocentric (and colonial) bias of art historical nomenclature and terminology. Metadata is data about data to help create an archive or catalogue for retrieving information. It enables us to locate, evaluate, and use specific types of visual images (including video). Omeka uses Dublin Core elements to create metadata, and these elements include title, subject, description, creator, source, publisher, date, format, type, identifier, and coverage<a class="footnote-ref" href="#omeka2018b"> [omeka2018b] </a>.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> Most of the information in these fields are what some might call “indisputable information,” or objective information akin to what we expect to find in a caption or exam slide identifications. For example, the metadata for a photographic reproduction of Manuel de Arellano’s <em>Virgin of Guadalupe</em> <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> from 1691 at the Los Angeles County Museum of Art could read as follows:</p>
<blockquote>
<p>title: Virgin of Guadalupe<br>
subject: Madonnas (using the Library of Congress Thesaurus for Graphic Materials) or perhaps Mary, Blessed Virgin, Saint — Apparitions and miracles (using the LCSH, or Library of Congress Subject Headings)<br>
author: Manuel de Arellano<br>
description: A painting of the Virgin of Guadalupe, one of the most venerated Marian advocations in the world. It replicates the original tilma worn by Juan Diego.<br>
creator: LACMA<br>
source: LACMA<br>
publisher: LACMA<br>
date: 1691 (or the date of the photograph)<br>
format: oil on canvas (or the type of digital file)<br>
identifier: a URL to the LACMA collection page<br>
coverage: Mexico<br>
Beyond these metadata fields, users can also create tags to help identify and locate items. For Arellano’s painting, these might includepainting,sacred,Marian imagery,seventeenth century, and so forth.</p>
</blockquote>
<p>Deciding what to write in each field can be complicated, and tougher still when it becomes clear that this information that seems objective is actually a fiction of objectivity. Many metadata descriptions are subjective. As several scholars remark, “ objectivity is defined by consensus, not by authority. Metadata needs to be a part of that consensus-building process” <a class="footnote-ref" href="#nilsson2004"> [nilsson2004] </a>. For example, when entering tags about an item into the Dublin Core, what someone decides to include or exclude impacts how this item is discovered and engaged with in a digital environment. This is also the case when asked to summarize the content of the item in the description. Arellano’s <em>Virgin of Guadalupe</em> could be described in any number of ways. This is not solely an issue about quality control, but also whose voice (or voices) gets to be heard.</p>
<p>Descriptive metadata is thus a crucial component for how we access and even analyze visual artifacts. Yet descriptive metadata is indexed with words that must be input by people who bring their own interpretative lens to the process. Murtha Baca describes the inherent challenges to this process, and the problems it can pose for creating “objective” metadata. In her words,</p>
<blockquote>
<p>Anyone familiar with art information knows that often the subject matter or theme of a work of art is not reflected at all in its title. . . . I can only find them [images] if the descriptive terms . . . have been applied to them by a human being who has looked at an image, interpreted the file, the visual information, and other available data, and made the decision to apply these data values to it [<a href="#baca2002">2002</a>, 34].<br>
But herein lies one of several challenges: What does this descriptive data look like? What terminology do we include or omit? Who decides what is important data to be indexed? In a specialization like colonial Latin American art history, a field filled with scholars actively critiquing the problematic terminology used to classify and analyze visual culture, how do we generate objective, consistent descriptive metadata?</p>
</blockquote>
<p>This question is repeatedly posed in my classes focused on the visual culture of the Spanish Americas. Early on in the courses, I ask students to create metadata (using the Dublin Core fields) for the open chapel murals of the convento of San Nicolás, Actopan, in Hidalgo, Mexico. This low-stakes activity, completed on paper in teams, helps them learn about Dublin Core elements before they actually complete their main course project on Omeka. They need to fill in the fields for title, subject, description, creator, source, date, format, identifier, and coverage.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> The results reveal to students the challenges with standardizing metadata and with using art historical terminology developed to describe European art primarily. For instance, for the title, most students write overly generalized descriptive titles (e.g., “Murals,”  “Open Chapel,” or “Murals with Christian Subject Matter” ). Each field presents its own challenge to students, but it is the topic of what to write for the creator that stimulates the greatest (and most passionate) debate.</p>
<p>Almost every student struggles with what to write in the creator field, with descriptors ranging from “Anonymous artist” and “People” to “Indigenous artist(s)” and “Subjugated Artist.” Students read Carolyn Dean and Dana Leibsohn’s “Hybridity and Its Discontents” (<a href="#dean2003">2003</a>), which generally sparks a heated discussion about how we talk about who produced colonial Latin American art and how we describe it. Students have not come to a consensus about what word or phrase is best to use, and by the end of class some students are visibly frustrated, confused, or even angry. One student noted in a written reflection that she felt “lied to” about the superficial objectivity of information in image captions, or in this case, with metadata found online.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> She elaborated further that the way metadata is presented gives us the impression that it is objective, suggesting it is indisputable, but now she realized that the personal biases we have inform the production of metadata.</p>
<p>In the following period, I ask students to create tags of the same image, and they have ranged fromLast Judgment,polychromy, andmendicant arttobright,damaged, andearly modern. This generates another reflective moment in the class about the usefulness of tagging, but also the limitations and potential problems of indexing images more generally. The discussion eventually turns to the possibility of social tagging, a common practice on social media sites like Tumblr and Flickr (and even among museum sites like the Brooklyn Museum). Many students have noted that social tagging might circumvent some of the problems associated with the controlled vocabulary used commonly for metadata (like the Library of Congress [LoC] subject headings). With social tagging, more voices could be represented, and in different languages, providing more opportunities to find images like the Actopan open chapel. The general idea of social tagging certainly can aid in overcoming some of the limitations of controlled vocabularies or the “trickiness” of metadata fields, even if it creates its own challenges, such as too many tags, incorrect tags (e.g., misspelled words), or inaccurate tags (see<a href="#chai2007">Chai, Zhang, and Jin 2007</a>;<a href="#menard2009">Ménard 2009</a>).<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> This user-generated tagging has been dubbed as “folksonomy,” or language created by “the masses” which in this case constitutes user-generated tags<a class="footnote-ref" href="#peters2009"> [peters2009] </a>. Despite the potential limitations of social tagging, many museums have adopted the practice as a way to further democratize museums and make museums more user-friendly<a class="footnote-ref" href="#alioto2017"> [alioto2017] </a>. The Brooklyn Museum’s <em>enconchado biombo</em> with the Siege of Belgrade and Hunting Scene, for example, currently has forty-four user-generated tags that range from the general (e.g.,screen) to the specific (oars).<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> By engaging in practices and discussions about metadata and tagging, students develop an awareness for the ways in which a single word alters meaning, and in some cases completely reframes how we understand an object or space, such as the Actopan open chapel, or allows users to locate information on the Web.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup></p>
<p>This exercise not only prompts reflection and critique about metadata and art historical nomenclature, but also reveals some of the limitations of DAH in the process. As one student in this class stated, “if we can’t agree [on] what to write in most of these [Dublin Core] elements, then how will that affect how people locate our materials?” Another noted that she felt she would have an easier time with “inputting an image of Michelangelo’s Sistine Chapel but it is really hard to create clear information about some [colonial] Mexican art.” Yet another student’s response is telling of how important these thorny questions and considerations are: “[E]ven if we can’t agree on what to write [for the metadata], we still need to move forward. . . . Otherwise, people might not even know it exists if they don’t go to college or read books.” I believe what this student was hinting at is the same idea posed by Mark Turin in his essay on “The Devil in the Digital” : the notion that much of what many people learn today is “mediated through the digital. If something [is] not discoverable through an online search or a digital catalogue, it could appear to not exist at all” [<a href="#turin2015">2015</a>, 125.] These students have determined some of the challenges of DAH. Many DAH projects rely on metadata, and metadata is created by people, with all of their biases and irrationalities. They had honed in on the very humanness of the digital humanities.</p>
<h2 id="digital-colonialism-and-the-digital-divide">Digital Colonialism and the Digital Divide</h2>
<p>Can the metadata we create about colonial Latin American objects be a form of digital colonialism? This is a question raised on several occasions in my classes. Metadata produces knowledge in the online environment, shaping how people relate to and understand Latin American visual culture. If the information that we create perpetuates colonialist discourse, overlooks the diversity of voices that lay claim to this cultural heritage, or simplifies the information so as to become anachronistic, then there is the risk of participating in acts of neocolonialism. In this complex digital world in which we live then, how do we responsibly create digital content without engaging in digital or technological colonialism? What ethical considerations are involved in the production of knowledge in the digital environment? And what does this look like for those of us who teach and research the visual culture of colonial Latin America?</p>
<p>When I first developed this project, and as students continued to learn about Omeka and the Dublin Core elements for their course project, students decided that it would be useful if everyone in the team relied on the LoC Subject Headings (LCSH) and Classification for specific elements, such as creator. The LCSH are frequently used, not only in the U.S. but also internationally, and are considered a more traditional classification system. I initially agreed with the students’ decision to proceed accordingly. However, as became clear to myself and students, even a quick scan of the LCSH reveals that they can unknowingly perpetuate colonialist, biased, and racist discourse. For instance, to familiarize students with the LCSH, I asked students to look at how monographs about Spanish colonial art incorporated them in the front matter.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> An examination of five recent monographs dedicated to the visual culture of post-conquest sixteenth-century Mexico included the LCSH “Indians of Mexico,” often with further subject headings attached such as “Indians of Mexico — ethnic identity,”  “Indian art,” or “Indians of Mexico — Missions — History — 16th century.” The terms Indigenous or First Nation do not appear, and often the specific ethnic group or groups are omitted from LCSH unless the monograph is specific to one of them (and if the term exists at all). The use of terminology likeIndian artis thus vague and reductionistic, but also reifies the colonialist discourse that so many postcolonial and decolonial thinkers have attempted to alter.</p>
<p>One way in which it is possible to rectify some of these imbalances and problems is to do what the University of Alberta’s Decolonizing Description Working Group (DDWG) has done, and what other institutions, such as the John Carter Brown Library, are seeking to do.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> The DDWG note that their aim is “to investigate, define and propose a plan of action for how UAL can more accurately, appropriately, and respectfully represent Indigenous peoples and contexts through our descriptive metadata practices” <a class="footnote-ref" href="#farnel2017"> [farnel2017] </a>. As they describe, “appropriate subject access and descriptive practices are a social justice issue and a moral imperative.” They provide examples of the transformations they have made to subject headings used in metadata, such as switching “Abused Indian children,” the LCSH, to “Abused Indigenous children.” In class, students have seemed excited about the possibility of such a project, especially the notion of descriptive metadata practices as they relate to social justice issues, and how this might alter how publics access and understand information they encounter on the Web. One student commented that she “never had thought about these things before, like how racist or gendered metadata could be. I’d really never thought about metadata at all.” She reflected that the components of the Omeka project had even caused her to rethink what she sees on her personal social media accounts (like Instagram and Facebook) and YouTube.</p>
<p>The process of creating this course project raises the question of how we can be mindful of not replicating colonialism in new ways. As discussed above, the process of metadata creation seems simple enough on the surface, but in reality is a more complex venture. As Roopika Risam advises, we must be wary of the violence that occurs in “discursive forms,” such as “reproducing colonial influences in the production of digital knowledge and centering epistemologies and ontologies of the Global North . . . which in turn decenters those of Indigenous communities and the Global South” [<a href="#risam2018">2018</a>, 2]. For those of us who practice art history, we must be cognizant of how metadata — and digital tools and projects beyond this — has the ability to act as a neocolonial dynamic, and one that situates the Global North as “the site of knowledge production.” <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup></p>
<h2 id="access-and-the-digital-divide">Access and the Digital Divide</h2>
<p>Access to materials, whether to digital photographs (or videos) or to archival or scholarly materials about colonial Latin American visual culture, impinges upon what and how we teach and research. High-resolution images are essential for teaching and research, and more than half of the survey’s respondents mentioned the need for their greater availability. Among the many reasons increased accessibility is needed, respondents listed the high cost of travel and the many international collections that now possess colonial Latin American objects, as well as the lack of high-res images in repositories like ArtStor or Bridgeman Images. For the latter, there is also a fee to acquire them. Moreover, as the academy continues to rely on adjunct labor with absurdly low pay, the need for free, open access to materials was noted as imperative. One response indicated that with greater access to objects and places that are less well known (if at all) the conversations around colonial Latin American art could also noticeably shift.</p>
<p>Besides access to high-resolution digital images, participants noted that certain digital tools or projects also could bypass pay-walled journals with costly subscriptions or academic presses that sell materials at high costs, all of which are largely inaccessible without access to a university library. As one respondent noted, DAH projects about Latin American visual culture challenge how and where knowledge is stored; rather than solely in academic journals or printed books, DAH projects have the potential to remove burdensome financial costs, to provide free access to anyone untethered to a university system, and to allow for more collaboration across international borders.</p>
<p>While access to more visual and textual materials was noted as a priority for researching and teaching about Latin American visual culture, respondents also noted that digitization initiatives and DAH projects have important limitations. One respondent worried about the implications of a project’s obsolescence. Several commented on the issue of collections (visual or archival) that do not have the funds or equipment to digitize their materials, or individuals who do not receive funding to produce and maintain a project online. Their concern is that research agendas and general trends in the field could therefore be determined on what is and is not available digitally. Mundy and Leibsohn (<a href="#mundy2017">2017</a>) agree that a canon of Latin American visual culture has formed around what has been made more available in the digital domain. This is also true for printed texts, such as those digitized for Google Books. Any library that has not provided access to Google Inc. will have considerably less traffic, which affects current and future research. This could then profoundly alter the production of knowledge about Latin American colonial history and art, as well as the cultural heritage of the many peoples and countries who have a connection to it. In my viceregal art class, this was certainly the case. Students tended to rely primarily on sources that could be found online, such as e-books through the university’s library portal, Google Books, the Getty Research Portal, or the John Carter Brown Library.</p>
<p>Open access to knowledge and to visual materials are important, and the immediacy they afford us has the potential to upset problematic aspects facing the academy (such as budget cuts, less time to travel, and the increase in adjunct labor) and the destruction or loss of cultural heritage. But who gets to grant this access? And should all knowledge and imagery be made more accessible? Risam (<a href="#risam2018">2018</a>) and Afanador Llach (<a href="#afandador2019">2019</a>) rightly remind us that the notion that information is and should be free is an assumption of the Global North, one that does not necessarily accord with Indigenous communities of the Global South. Even universal access to the Web is, as Rodríguez-Ortega states, a myth [<a href="#rodriguez2013a">2013a</a>, 131; see also<a href="#rodriguezortega2018">2018</a>]. A huge portion of the world’s population is still without access to the internet, and it is worth reflecting how the digital practices we engage in could potentially further this digital divide.</p>
<p>The issue of access is also one of language. English is the lingua franca of the Web, which can be another barrier for anyone who does not know or use English<a class="footnote-ref" href="#afandador2019"> [afandador2019] </a><a class="footnote-ref" href="#rodriguez2013a"> [rodriguez2013a] </a>. It can deepen the digital divide. Many DAH projects centered around colonial Latin American art are in English, though there are also examples of bilingual projects (e.g., Digital Códice Mendoza) that offer excellent models for moving forward. As students in my class have wondered, what attempts have been made or can be made to sidestep the perpetual dominance of the Global North as gatekeepers to knowledge? Collaboration, as noted in the questionnaire responses and among students, seems to offer an appealing solution to how we can ensure greater accessibility and perspectives.</p>
<h2 id="collaboration-image-design-and-manipulation-and-the-invisibility-of-labor">Collaboration, Image Design and Manipulation, and the (In)Visibility of Labor</h2>
<p>Final issues that warrant discussion are collaboration, image design and manipulation, and the labor involved in creating digitized materials or DAH projects. In the classes on viceregal art described above, each team crafts their own Omeka exhibition, with the team designing a theme and an introductory statement that frames each individual’s entries.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> Students are graded on both components, as well as the feedback they offer to their team members. As noted above in the metadata discussion, there are steps that students must learn before they create these online exhibitions. They need to understand how to create metadata, as well as to determine how to source images in the public domain or take their own photographs, upload images as items, create and arrange pages, and write for diverse publics<a class="footnote-ref" href="#kilroy2017a"> [kilroy2017a] </a><a class="footnote-ref" href="#kilroy2017b"> [kilroy2017b] </a><a class="footnote-ref" href="#kilroy2018"> [kilroy2018] </a>. It requires scaffolding of smaller assignments from the semester’s beginning.</p>
<p>After our discussion about metadata and how to create it, another assignment asks teams to decide on their exhibition’s theme after visiting a local museum collection of Spanish colonial art, such as LACMA’s. Students are asked to photograph their chosen objects that will form the core of their individual component. Before they observe objects on display at the museum, I initiate a conversation about what these photographs could or should look like, how many they might take, and whether the photos might need to be “corrected” or manipulated in some capacity. This conversation usually begins with quizzical looks. As one student later reflected, “I’ve never been asked before [in an art history class] to consider how I take photos or what I might need to do to make them look beautiful.” This discussion inevitably returns us to the importance of how we frame or reframe art, how digital images shift the production of knowledge and our understanding of colonial Latin American art, and how the choices we make to show or not to show specific aspects of an object or building can alter how someone understands it. We watch a Smarthistory video to discuss how the visual choices made in it might affect how we understand a specific work of art and how the visuals create an argument.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> On occasion, it has also raised thought-provoking discussions about labor, both visible and invisible, that broached larger issues involved in digitized and DAH, namely how we assign credit for the work being done.</p>
<p>To provide a brief example, one team framed their exhibition around sacred imagery. One student chose Arellano’s <em>Virgin of Guadalupe</em> to probe localized sacred imagery specifically. At LACMA, he brought his expensive camera and took dozens of photographs in the manner of Smarthistory’s Steven Zucker, the student’s cited model<a class="footnote-ref" href="#zucker2018"> [zucker2018] </a>. He not only took photographs of the entire painting but numerous details, as well as photographs of the painting from the side and in relation to objects displayed near it, from far away within the gallery space, with visitors in front of the painting, and in black-and-white. The student either already knew or learned how to use image manipulation software like Adobe Photoshop because his resulting images also included callouts, highlights, color correction, complicated cropping, and straightening.</p>
<p>During the peer review process, this student’s component was met with both wonder and anxiety by his fellow teammates. They were concerned that his images were of such high quality so as to make their own individual essays look less legitimate or less serious. Most students took photos on their smartphones and had not manipulated them; they were blurry, dark, and crooked, and some had not captured portions of the object itself. The team member with high-quality photographs offered to share his expertise but wondered if the time he spent helping his teammates to improve their resulting digital images would negatively impact his own project because he would have less time to focus on it.</p>
<p>In the end, the process prompted an unexpected but important conversation about how digitized images affect our perceptions of digital projects and about the labor involved in creating them. I was reminded of Daniela Bleichmar’s discussion of colonial Latin American art and visual epistemology, or “the role of visuality as a way of knowing, and the process of observation, collecting, representation, and circulation that were integral to the production of knowledge” [<a href="#bleichmar2015">2015</a>, 240]. Pairing Bleichmar’s essay with the work they were doing in class proved especially generative, with students finding compelling parallels between processes and projects of the past with those in their digital present. Importantly, it also encouraged students to revisit online projects that we had discussed in class to think critically about how the material is presented and how this creates a digital and visual argument. It also stimulated a great deal of dialogue about the need for more accessible high-resolution images of colonial Latin American visual culture, a point that the questionnaire’s respondents repeatedly emphasized.</p>
<p>Another important point the above example illuminates is the labor involved in digitization, whether of books or images, or in digital work, such as working collaboratively. A great deal of labor goes uncited, unnoticed, as has been addressed more recently by many working in the Digital Humanities (e.g.<a href="#keralis2016">Keralis 2016</a>;<a href="#graban2019">Graban, Marty, Romano, and Vandergrift 2019</a>]. In her written reflection, a student pointed out that the invisibility of this labor calls to mind the invisibility of labor used to create the art and architecture of the sixteenth-century Spanish Americas. Even when the creator of digital content is known, such as the photographer who took certain photos and made them available on Flickr Commons, there is a great deal of labor that might go unaccounted for. Image manipulation can be time consuming, and to get it “just right” varies depending on the creator. Individuals responsible for digitizing materials in museums, archives, or libraries, whether for an institution’s website (such as The Metropolitan Museum of Art or Mexico’s Archivo General de la Nación) or a large corporate entity (such as Google Books) are almost never named. Crowdsourcing, for projects like PESSCA or the recent ALAA digital art history resources page, is not free or visible labor, as a recent blog post on the Getty Iris also mentions<a class="footnote-ref" href="#deines2018"> [deines2018] </a>.<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> The concern of my student, who offered to share his photoshopping expertise, about his time and labor raised this issue on a micro-scale within the classroom.</p>
<h2 id="a-final-reflection">A Final Reflection</h2>
<p>“Creating metadata and making an [Omeka] exhibit were totally new experiences for me. . . . Both processes made the art [of the Spanish Americas] far more accessible to me and help[ed] me develop better critical thinking skills about what I see online. . . . They also made me feel uncomfortable because I think my generation just assumes all stuff online is true, even when teachers tell us it isn’t. But now I kinda get it.” This statement, in a student’s final reflection, sums up much of what I have been discussing here and the relationship between the digital, colonial Latin American art, and pedagogy. As is clear from this class project, digital art history can disturb and disrupt how students approach colonial Latin American art. As I hope this essay demonstrates, while the digital turn offers many positive ways in which we can rethink and reframe art history and specifically the visual culture of colonial Latin America, it seems mindful to be wary of the notion that it can create a false perception of a techno-utopia in which all creators and users are equal, and information is always readily accessible and objective.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>I dedicate this essay to Linda Rodriguez, who passed from this life too soon. She offered excellent feedback on this essay early on, for which I am so grateful. I also thank Hannah Alpert-Abrams, Clayton McCarl, and the two DHQ peer reviewers for their helpful feedback. Any errors are my own.</p>
<p>This essay was written in the spring and summer of 2018.</p>
<ul>
<li id="afandador2019">Afandador Llach, Marí José. 2019. “Tecnología al servicio de las Humanidades” . “Telos” 112. Accessed 11 April 2020.<a href="https://telos.fundaciontelefonica.com/telos-112-cuaderno-central-humanidades-en-un-mundo-stem-maria-jose-afanadortecnologia-al-servicio-de-las-humanidades/">https://telos.fundaciontelefonica.com/telos-112-cuaderno-central-humanidades-en-un-mundo-stem-maria-jose-afanadortecnologia-al-servicio-de-las-humanidades/</a>.
</li>
<li id="alioto2017">Alioto, Daisy. 2017. “Can Social Tagging Deepen the Museum Experience?”  _Hyperallergic_ . 3 November. Accessed 15 January 2018.<a href="https://hyperallergic.com/409854/can-social-tagging-deepen-the-museum-experience/">https://hyperallergic.com/409854/can-social-tagging-deepen-the-museum-experience/</a>.
</li>
<li id="alpers1979">Alpers, Svetlana. 1979. “Style is What You Make It: The Visual Arts Once Again” . In _The Concept of Style_ , edited by Berel Lang, 95–117. Philadelphia: University of Pennsylvania Press.
</li>
<li id="baca2002">Baca, Murtha. 2002. “A picture is worth a thousand words: Metadata for art objects and their visual surrogates” . In _Cataloging the Web: Metadata, AACR, and MARC 21_ , edited by Wayne Jones et al., 131–138. Lanham, MD: Scarecrow Press.
</li>
<li id="baca2013">Baca, Murtha, and Anne Helmreich. 2013. “Introduction” .  _Visual Resources_  29, nos. 1–2 (March–June): 1–4.
</li>
<li id="bishop2015">Bishop, Claire. 2015. “Against Digital Art History” . Humanities Futures: Franklin Humanities Institute. October 20.<a href="https://humanitiesfutures.org/papers/digital-art-history/">https://humanitiesfutures.org/papers/digital-art-history/</a>.
</li>
<li id="bleichmar2015">Bleichmar, Daniela. 2015. “The Imperial Visual Archive: Images, Evidence, and Knowledge in the Early Modern Hispanic World” . _Colonial Latin American Review_ 24, no. 2: 236–266.
</li>
<li id="chai2007">Chai, Joyce Y., Chen Zhang, and Rong Jin. 2007. “An empirical investigation of user term feedback in text-based targeted image search” . _ACM Transactions on Information Systems_ 25, no. 1, 1–25.<a href="https://dl.acm.org/doi/10.1145/1198296.1198299">Doi: 10.1145/1198296.1198299</a>.
</li>
<li id="cohenaponte2017">Cohen-Aponte, Ananda. 2017. “Decolonizing the Global Renaissance: A View from the Andes” . In _The Globalization of Renaissance Art: A Critical Review_ , edited by Daniel Savoy, 67–94. Leiden: Brill.
</li>
<li id="dean2003">Dean, Carolyn, and Dana Leibsohn. 2003. “Hybridity and Its Discontents: Considering Visual Culture in Colonial Spanish America” . _Colonial Latin American Review_ 12, no. 1: 5–35.
</li>
<li id="deines2018">Deines, Nathaniel, Melissa Gil, Matthew Lincoln, and Marissa Clifford. 2018. “Six Lessons Learned from Our First Crowdsourcing Project in the Digital Humanities” . _The Iris: Behind the Scenes at the Getty_ . 7 February. Accessed 3 June 2018.<a href="http://blogs.getty.edu/iris/six-lessons-learned-from-our-first-crowdsourcing-project-in-the-digital-humanities/">http://blogs.getty.edu/iris/six-lessons-learned-from-our-first-crowdsourcing-project-in-the-digital-humanities/</a>.
</li>
<li id="codex2014">Codex Mendoza Team. _Digital Códice Mendoza/Digital Codex Mendoza._ 2014. Accessed May 13 2018.<a href="http://codicemendoza.inah.gob.mx/inicio.php?lang=spanish">http://codicemendoza.inah.gob.mx/inicio.php?lang=spanish</a>.
</li>
<li id="drucker2013">Drucker, Johanna. 2013. “Is There a Digital Art History?”   _Visual Resources_ , special issue on Digital Art History, edited by Murtha Baca and Anne Helmreich, 29, nos. 1–2 (Spring): 5–13.
</li>
<li id="drucker2015">Drucker, Johanna, Anne Helmreich, Matthew Lincoln, and Francesca Rose. 2015. “Digital Art History: The American Scene” .  _Perspective_  2, December 7. Accessed October 18, 2017. <a href="http://perspective.revues.org/6021">http://perspective.revues.org/6021</a>.
</li>
<li id="doulkaridou2015">Doulkaridou, Elli. 2015. “Reframing Art History” . _International Journal for Digital Art History_ , no. 1. 67–83. Doi:<a href="https://doi.org/10.11588/dah.2015.1.21638">https://doi.org/10.11588/dah.2015.1.21638</a>.
</li>
<li id="evens2012">Evens, Aden. 2012. “Ontology of the Digital.”  _Digital Humanities Quarterly_ 6, no. 2.
</li>
<li id="farnel2017">Farnel, Sharon, Sheila Laroque, Ian Bigelow, Denise Koufogiannakis, Anne Carr-Wiggin, Debbie Feisst, Kayla Lar-Son. 2017. _Decolonizing Description: Changing Metadata in Response to the Truth and Reconciliation Commission_ . University of Alberta Libraries. Accessed 4 May 2018.<a href="https://s3.libraries.coop/download.librarytoolshed.ca/Presentations/Decolonizing_Description_Netspeed_2017.pdf">https://s3.libraries.coop/download.librarytoolshed.ca/Presentations/Decolonizing_Description_Netspeed_2017.pdf</a>.
</li>
<li id="fiormonte2016">Fiormonte, Domenico. 2016. “¿Por qué las Humanidades Digitales necesitan al Sur?”  _Humanidades Digitales: Construcciones locales en contextos globales_ . Asociación Argentina de Humanidades Digitales, Buenos Aires. Accessed 14 April 2020.
</li>
<li id="fletcher2015">Fletcher, Pamela. 2015. “Reflections on Digital Art History.”   _caa.reviews_ , June 18. Accessed April 15, 2017.<a href="http://www.caareviews.org/reviews/2726#.X9bL4NhKhPY">Doi: 10.3202/caa.reviews/2015/73</a>.
</li>
<li id="graban2019">Graban, Tarez Samra, Paul Marty, Allen Romano, Micah Vandergrift. 2019. “Introduction: Questioning Collaboration, Labor, and Visibility in Digital Humanities Research.”  _Digital Humanities Quarterly_ . 13, no. 2. Accessed 2 February 2020.<a href="https://digitalhumanities.org/dhq/vol/13/2/000416/000416.html">https://digitalhumanities.org/dhq/vol/13/2/000416/000416.html</a>.
</li>
<li id="harris2015">Harris, Beth, and Steven Zucker. 2015. “Where is the pedagogy in digital art history?”  _Smarthistory blog_ . Accessed 9 May 2020.<a href="https://smarthistoryblog.org/2015/07/13/where-is-the-pedagogy-in-digital-art-history/">https://smarthistoryblog.org/2015/07/13/where-is-the-pedagogy-in-digital-art-history/</a>.
</li>
<li id="hohensee2018">Hohensee, Naraelle. 2018. “Connecting with the world.” Smarthistoryblog.org. Accessed 6 June.<a href="https://smarthistoryblog.org/2018/06/06/connecting-with-the-world/">https://smarthistoryblog.org/2018/06/06/connecting-with-the-world/</a>.
</li>
<li id="honig2018">Honig, Elizabeth Alice. 2018. “Teaching Renaissance Workshop Practices as Network Analysis.” In _Journal of Interactive Technology & Pedagogy_ , no. 12.<a href="https://jitp.commons.gc.cuny.edu/teaching-renaissance-workshop-practice-as-network-analysis/">https://jitp.commons.gc.cuny.edu/teaching-renaissance-workshop-practice-as-network-analysis/</a>.
</li>
<li id="hoobler2018">Hoobler, Ellen, et al. 2018. “Of Software and Sepulchers: Modeling Ancient Tombs from Oaxaca, Mexico.”  _Journal of Interactive Technology & Pedagogy_ , no. 12.<a href="https://jitp.commons.gc.cuny.edu/of-software-and-sepulchers-modeling-ancient-tombs-from-oaxaca-mexico/">https://jitp.commons.gc.cuny.edu/of-software-and-sepulchers-modeling-ancient-tombs-from-oaxaca-mexico/</a>.
</li>
<li id="kalay2008">Kalay, Yehuda E. 2008. “Introduction: Preserving cultural heritage through digital media.” In _New Heritage: New Media and Cultural Heritage_ , edited by Yehuda Kalay, Thomas Kvan, and Janice Affleck. London: Routledge.
</li>
<li id="kalayetal2008">Kalay, Yehuda, Thomas Kvan, and Janice Affleck, eds. 2008. _New Heritage: New Media and Cultural Heritage_ . London: Routledge.
</li>
<li id="keralis2016">Keralis, Stephen. 2016. “Labor.”  _Digital Pedagogy in the Humanities: Concepts, Models, and Experiments_ . MLA Commons, 2016. Accessed 7 April 2020.<a href="https://digitalpedagogy.mla.hcommons.org/keywords/labor/">https://digitalpedagogy.mla.hcommons.org/keywords/labor/</a>.
</li>
<li id="kilroy2017a">Kilroy-Ewbank, Lauren G. 2017a. “What is Public Art History?” Smarthistory.org blog. 7 August 2017. Accessed 3 June 2018.<a href="https://smarthistoryblog.org/2017/08/07/what-is-public-art-history/">https://smarthistoryblog.org/2017/08/07/what-is-public-art-history/</a>.
</li>
<li id="kilroy2017b">Kilroy-Ewbank, Lauren G. 2017b. “How do we create a field of Public Art History?” Smarthistory.org bolg. 8 August 2017. Accessed 3 June 2018.<a href="https://smarthistoryblog.org/2017/08/08/how-do-we-create-a-field-of-public-art-history/">https://smarthistoryblog.org/2017/08/08/how-do-we-create-a-field-of-public-art-history/</a>.
</li>
<li id="kilroy2018">Kilroy-Ewbank, Lauren G. 2018. “Doing Digital Art history in a Pre-Columbian Art Survey Class: Creating an Omeka Exhibition Around the Mixtec Codex Zouche-Nuttall.”  _Journal of Interactive Technology & Pedagogy_ , no. 12.<a href="https://jitp.commons.gc.cuny.edu/doing-digital-art-history-in-a-pre-columbian-art-survey-class-creating-an-omeka-exhibition-around-the-mixtec-codex-zouche-nuttall/">https://jitp.commons.gc.cuny.edu/doing-digital-art-history-in-a-pre-columbian-art-survey-class-creating-an-omeka-exhibition-around-the-mixtec-codex-zouche-nuttall/</a>.
</li>
<li id="leibsohn2015">Leibsohn, Dana, and Barbara E. Mundy. 2015. _Vistas: Visual Culture in Spanish America, 1520–1820._ Accessed 15 April 2018.<a href="http://fordham.edu/vistas">http://fordham.edu/vistas</a>.
</li>
<li id="lincoln2014">Lincoln, Matthew D. 2014. “The Meta/Data of Art History.”   _Matthew Lincoln, PhD_ (blog). Original date 28 Jul 2014. Accessed 13 April 2018.<a href="https://matthewlincoln.net/2014/07/28/the-meta-slash-data-of-art-history.html">https://matthewlincoln.net/2014/07/28/the-meta-slash-data-of-art-history.html</a>.
</li>
<li id="maravall1986">Maravall, José Antonio. 1986. _Culture of the Baroque: Analysis of a Historical Structure._ Manchester: Manchester University Press.
</li>
<li id="mavcor2018">MAVCOR. 2018. “Ocongate Altar.” Center for the Study of Material and Visual Cultures of Religion. Accessed 2 June 2018.<a href="https://mavcor.yale.edu/material-objects/giga-project/ocongate-altar-360">https://mavcor.yale.edu/material-objects/giga-project/ocongate-altar-360</a>
</li>
<li id="menard2009">Ménard, Elaine. 2009. “Images: Indexing for accessibility in a multi-lingual environment — challenges and perspectives.”  _The Indexer_ 27, no. 2, 70–76.
</li>
<li id="metropolitan2018">Metropolitan Museum of Art. 2000–2018. _The Heilbrunn Timeline._ Accessed 6 June 2018.<a href="https://www.metmuseum.org/toah/">https://www.metmuseum.org/toah/</a>.
</li>
<li id="mundy2017">Mundy, Barbara E., and Dana Leibsohn. 2017. “Digital Resources: The State of Digital Research on the Visual Culture of Spanish America.”  _Oxford Research Encyclopedia of Latin American History_ .<a href="http://latinamericanhistory.oxfordre.com/view/10.1093/acrefore/9780199366439.001.0001/acrefore-9780199366439-e-117">DOI: 10.1093/acrefore/9780199366439.013.117</a>.
</li>
<li id="nilsson2004">Nilsson, Mikael, Ambjörn Naeve, and Matthias Palmér. 2004. “The Edutella P2P network: Supporting democratic e-learning and communities of practice.” In _Online Education Using Learning Objects_ , edited by Rory McGreal, 244–X. New York: RoutledgeFalmer.
</li>
<li id="omeka2018a">Omeka Team. 2018a. Omeka.net. Corporation for Digital Scholarship. Accessed 12 June.<a href="http://www.omeka.net">www.omeka.net</a>.
</li>
<li id="omeka2018b">Omeka Team. 2018b. “Working with Dublin Core.”  _Omeka Classic User Manual_ . Accessed March 29.<a href="https://omeka.org/classic/docs/Content/Working_with_Dublin_Core/">https://omeka.org/classic/docs/Content/Working_with_Dublin_Core/</a>.
</li>
<li id="pessca"> _Project for the Engraved Sources of Spanish Colonial Art (PESSCA)_ . 2005–2018. Accessed 4 April 2018.<a href="http://colonialart.org">http://colonialart.org</a>.
</li>
<li id="peters2009">Peters, Isabella. 2009. _Folksonomies: Indexing and Retrieval in Web 2.0_ , translated by Paul Becker. Berlin: DeGruyter.
</li>
<li id="peterson2008">Peterson, Jeanette F. 2008. “Renaissance: A Kaleidoscopic View from the Spanish Americas.” In _Renaissance Theory_ , edited by James Elkins and Robert Williams, 321–332. London: Routledge.
</li>
<li id="preziosi1991">Preziosi, Donald. 1991. _Rethinking Art History: Meditations on a Coy Science_ . New Haven: Yale University Press.
</li>
<li id="richardson2020">Richardson, Erica. 2020. “The Trouble with Tags: The Challenges of Collaborative Metadata and Participatory Culture in Class Blogs.”  _The Journal of Interactive Technology and Pedgagogy_ . Accessed 9 May 2020.<a href="https://jitp.commons.gc.cuny.edu/category/teaching-fails/">https://jitp.commons.gc.cuny.edu/category/teaching-fails/</a>.
</li>
<li id="risam2018">Risam, Roopika. 2018. “Decolonizing Digital Humanities in Theory and Practice.” In _The Routledge Companion to Media Studies and Digital Humanities_ , edited by Jentery Sayers, 78–86. New York: Routledge.
</li>
<li id="rodriguez2018">Rodriguez, Linda, Ada Ferrer, Kris Minhae Choe, and Eric Anderson. 2018. _Digital Aponte_ . Accessed 13 April 2018.<a href="http://aponte.hosting.nyu.edu/">http://aponte.hosting.nyu.edu/</a>.
</li>
<li id="rodriguez2009">Rodríguez-Ortega, Nuria. 2009–2010. “La cultura histórico-artística y la Historia del Arte en la sociedad digital. Una reflexión crítica sobre los modos de hacer Historia del Arte en un nuevo context.”  _Museo y Territorio_ , no. 2–3: 9–26.
</li>
<li id="rodriguez2013a">Rodríguez-Ortega, Nuria. 2013. “Digital Art History: An Examination of Conscience.”  _Visual Resources_ 29, no. 1–2: 129–133.
</li>
<li id="rodriguez2013b">Rodríguez-Ortega, Nuria. 2013. “Getty Voices: It’s Time to Rethink and Expand Art History for the Digital Age.”  _The Iris: Behind the Scenes at the Getty_ . 5 March. Accessed 13 May 2018.<a href="http://blogs.getty.edu/iris/its-time-to-rethink-and-expand-art-history-for-the-digital-age/">http://blogs.getty.edu/iris/its-time-to-rethink-and-expand-art-history-for-the-digital-age/</a>.
</li>
<li id="rodriguezortega2018">Rodríguez-Ortega, Nuria. 2018. “Desarrollos digitales de la Historia del Arte: implicaciones epistémicas, críticas y metodológicas.” In _Humanidades digitales: edición literature y arte_ , edited by Isabel Galina Russel et al., digital edition, loc. 1774–2783. Mexico City: Bonilla Artigas Editores.
</li>
<li id="rodriguez2019">Rodríguez-Ortega, Nuria. 2019. “Digital Art History: The Questions that Need to Be Asked.”  _Visual Resources_ , 35, no. 1-2, 6-20, DOI: <a href="https://doi-org.lib.pepperdine.edu/10.1080/01973762.2019.1553832">10.1080/01973762.2019.1553832</a>.
</li>
<li id="schilling2014">Schilling, Peter. 2014. “Technology as Epistemology.”  _The Academic Commons_ . Accessed 4 May.<a href="http://www.academiccommons.org/2014/09/09/technology-as-epistemology/">http://www.academiccommons.org/2014/09/09/technology-as-epistemology/</a>.
</li>
<li id="smarthistory2018">Smarthistory. 2018. _Smarthistory.org_ . Edited by Beth Harris and Steven Zucker. Accessed 6 June.<a href="https://smarthistory.org/">https://smarthistory.org/</a>.
</li>
<li id="sullivan1996">Sullivan, Edward. 1996. “European Painting and the Art of the New World Colonies.” In _Converging Cultures: Art and Identity in Spanish America_ , exh. cat.,28-41. New York: Brooklyn Museum.
</li>
<li id="turin2015">Turin, Mark. 2015. “Devil in the Digital: Ambivalent Results in an Object-Based Teaching Course.”  _Museum Anthropology_ 38, no. 2: 123–132.
</li>
<li id="zorich2012">Zorich, Diane M. 2012. “Transitioning to a Digital World: Art History, Its Research Centers, and Digital Scholarship.” A Report to The Samuel H. Kress Foundation and The Roy Rosenzweig Center for History and New Media, George Mason University.
</li>
<li id="zucker2018">Zucker, Steven. 2018. _Profzucker Flickr Account._ Accessed January 3.<a href="https://www.flickr.com/photos/profzucker/">https://www.flickr.com/photos/profzucker/</a>.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I alternate between the termsartandvisual culturewith full understanding that there are important differences between them. For the sake of space, I do not unpack the manifold meanings of either term.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>See also Rodríguez-Ortega 2018.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Conversations with Beth Harris and Steven Zucker, the founders of Smarthistory.org, have been influential on my own thinking about digital art history pedagogy. See also<a href="#harris2015">Harris and Zucker 2015</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>The questionnaire asked general questions about digitized and digital art history, teaching, and Omeka, as well as about the open-educational resource Smarthistory. Originally, this essay also addressed a case study of using the production of Smarthistory videos as a model for collaborative DAH pedagogy and practice. However, because of the limitations on length for this essay, the discussion of Smarthistory has been omitted, as have the questionnaire responses about it. This data will be used for a separate essay to be published elsewhere.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>For a useful discussion of Web 2.0 and the ontology of the digital, see<a href="#evens2012">Evens 2012</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>In hindsight, the questionnaire should have also been written in Spanish and distributed on other listservs. ALAA is a U.S.-based association but with an international reach.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Quantitative questions provided basic information in a yes/no/maybe format. Each participant’s qualitative responses were also analyzed using thematic analysis (coding of written text into themes).&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Most participants have been teaching for at least six years (more than 60%), and 38.5% for more than ten. The types of classes people teach vary from undergraduate surveys on colonial Latin American art and architecture, to smaller classes focused on a region or specific century and undergraduate or graduate seminars on a specific theme (such as portraiture in the Americas or eighteenth-century Mexican painting).&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>When asked if DAH tools and methods offer new approaches to teaching or researching the art of colonial Latin America, almost all respondents answered yes (76.9%). 23.1% answered maybe.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Responses describing the impact of the digital on research were the most varied and detailed, indicating the numerous ways in which information is searched, retrieved, collected, and analyzed. Most commonly, respondents use museum websites to source images and access digitized archival materials. Beyond these, respondents listed the importance of general Google searches, and the use of specific Google tools like Scholar and Books, as well as Wikipedia, Academia.edu, Zotero, Dropbox, Videoconferencing, spatial and textual analysis, spreadsheets, and social media (e.g., Twitter).&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>I would also argue, as others have before me, that soon thedigitalwill be dropped from digital art history<a class="footnote-ref" href="#hohensee2018"> [hohensee2018] </a>. Rodríguez-Ortega’s essay (<a href="#rodriguez2019">2019</a>) also notes that special journal volumes on DAH will likely no longer be published.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>A series of recent blog posts on Smarthistory expand on this very idea<a class="footnote-ref" href="#hohensee2018"> [hohensee2018] </a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>These classes include Spanish Colonial, Latin American (1492–present), and Global Renaissance art.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Matthew Lincoln has also made this point (<a href="#lincoln2014">2014</a>).&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>While most questionnaire respondents used (or at least knew of) Smarthistory, few used Omeka in any of their classes. 42.9% use Smarthistory in their classes. Only 7.7% employed Omeka. One participant noted that she uses it herself but had not yet introduced it to students. The two respondents who did incorporate Omeka asked students to create digital exhibitions of artworks.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Dublin Core is centered around fifteen “core” elements that were created in an attempt to standardize metadata by providing specific standards for inputting data across fields.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>For the image, see<a href="https://collections.lacma.org/node/220044?parent=589011">https://collections.lacma.org/node/220044?parent=589011</a>.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>For explanations of each of these fields, see Omeka Team 2018b.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Students were asked to write a short, written reflection after each class period.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>For more on the challenges of creating collaborative metadata in the classroom, see Richardson 2020.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>To see the image, its metadata, and social tags, visit<a href="https://www.brooklynmuseum.org/opencollection/objects/207337">https://www.brooklynmuseum.org/opencollection/objects/207337</a>.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>I am reminded of Cohen-Aponte’s recent discussion about decolonizing the global renaissance, encapsulated by her discussion about terminology. She notes the important ramifications of changing just one word, such as if we were to change the sentence “viceregal art…as art that just so happened to <em>coincide</em> with colonization” to “art produced <em>under</em> colonization” [<a href="#cohenaponte2017">2017</a>, 74].&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>The LCSH used are not determined by the authors themselves.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>In 2017, the JCBL posted a position for a postdoctoral fellow for data curation in Latin American and Caribbean Indigenous languages. As stated in the job description, “The goal of this project is to assess how digital tools and metadata created through collaborative processes across a hemispheric arc can serve scholarly and non-scholarly communities now and into the future.” See<a href="https://www.clir.org/fellowships/postdoc/applicants/john-carter-brown-library-brown-university/">https://www.clir.org/fellowships/postdoc/applicants/john-carter-brown-library-brown-university/</a>.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>See also Fiormonte 2016 for another discussion about the Global South, the production of knowledge, and DH.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>See Kilroy-Ewbank 2018 for another example of this practice.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>I typically have students watch Smarthistory videos <em>not</em> related to Spanish colonial art, including <em>Augustus of Primaporta</em> (<a href="https://youtu.be/3i8iou6tXqY">https://youtu.be/3i8iou6tXqY</a>) or Polykleitos’s <em>Doryphoros</em> (<a href="https://youtu.be/EAR9RAMg9NY">https://youtu.be/EAR9RAMg9NY</a>).&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>PESSCA is the Project on the Engraved Sources of Spanish Colonial Art (<a href="https://colonialart.org/">https://colonialart.org/</a>). ALAA is the Association of Latin American Art, and its digital resources page is found here:<a href="https://associationlatinamericanart.org/digital-resources/">https://associationlatinamericanart.org/digital-resources/</a>.## Bibliography&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Developing Geographically Oriented NLP Approaches to Sixteenth–Century Historical Documents: Digging into Early Colonial Mexico</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000490/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000490/</id><author><name>Diego Jiménez–Badillo</name></author><author><name>Patricia Murrieta–Flores</name></author><author><name>Bruno Martins</name></author><author><name>Ian Gregory</name></author><author><name>Mariana Favila-Vázquez</name></author><author><name>Raquel Liceras-Garrido</name></author><published>2020-12-15T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="1-introduction">1. Introduction</h2>
<p>This article introduces the project <em>Digging into Early Colonial Mexico: A Large–Scale Computational Analysis of Sixteenth–Century Historical Sources</em> , and describes the progress achieved so far.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> The project focuses on developing novel methods and tools for mining new knowledge from textual and pictorial historical records to facilitate the study of early Latin American history. It concentrates on one of the most important corpora related to the geography, culture, religion, economy, and history of native and Spanish peoples in Mexico and Guatemala, namely the <em>Relaciones Geográficas de la Nueva España</em> (Geographic Reports from New Spain), and specifically those compiled between 1577 and 1585, hereafter referred to as RGs.</p>
<p>The proposed methodology — called Geographical Text Analysis (GTA) — enables the automatic markup of words referring both to place names (toponyms) and analytical concepts relevant to historical research, and adds geospatial intelligence to the parsing of texts. This process is useful not only to find the most salient terms in textual corpora or to identify and disambiguate personal and geographical names, but also to facilitate the discovery of unsuspected data patterns and relationships, such as spatial correlation of events, interaction of people, links of persons and themes to places, and many others.</p>
<p>One of the main contributions of this project has been the development of an analytical model based on deep-learning and adapted to the specific challenges found in texts like the RGs. In order to achieve named entity recognition, disambiguation and classification, GTA employs methodologies from the fields of Natural Language Processing (NLP), Corpus Linguistics (CL) and Machine Learning (ML). Although NLP, CL and ML techniques are used frequently in textual analysis today, they are most commonly applied to contemporary texts composed in English. Little work has been done to adapt their use to historical corpora written in old language forms like the sixteenth–century Spanish.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> The RG corpus additionally contains other features that complicate the use of such tools, which makes very difficult the automaticreadingof the documents. These include the presence of multi-lingual expressions in Nahuatl, Zapotec, Otomi, and many other indigenous languages<a class="footnote-ref" href="#harvey1972"> [harvey1972] </a>, as well vocabulary only used in certain regions at the time.</p>
<p>A second contribution of our project has been to facilitate, using Geographical Information Systems (GIS), the automatic linking of the results of these processes of textual analysis with locational data. This combination of NLP, CL and ML techniques with spatial analysis methods creates powerful resources to discover unsuspected geographies in the textual reports. Our model will allow scholars of colonial Latin America to learn new information, extract it, cross–link it to other document resources, and, most importantly, study significant historical topics, such as those we discuss in section 3.5 below.</p>
<p>Apart from the GTA model itself, we foresee several other products of this project. The first is a digital version of the RGs corpus, annotated in accordance with analytical categories that can be applied to other corpora through an interoperable ontology. The second is a digital gazetteer containing geographic coordinates as well as political, cultural, administrative and physical data, not only of the sixteenth-century sites mentioned in the RGs, but from other relevant sources and historical periods. The third is a set of software tools that link the spatial information contained in the gazetteer with the textual and pictorial contents of the RGs in order to facilitate the discovery and analysis of geographies not immediately apprehended with normal reading.</p>
<p>In writing this paper, our goal is to raise awareness about the possibilities of applying computer-assisted methods to the analysis of historical texts. Thus, we describe every step of GTA in the context of our specific study case, hoping that this will encourage more Humanities researchers to adopt this kind of approach.</p>
<p>The rest of the article is organized as follows: Section 2 provides an overview of the <em>Relaciones Geográficas</em> corpus; Section 3 describes our analytic methodology and reports on our progress; Section 4 describes future applications to the study of history; and the final section offers a general conclusion.</p>
<h2 id="2-the-sixteenth-century-relaciones-geográficas-de-la-nueva-españa">2. The Sixteenth Century Relaciones Geográficas de la Nueva España</h2>
<p>The compilation of the <em>Relaciones Geográficas de la Nueva España</em> was part of a large, long–standing project, sponsored first by Emperor Charles V and then by King Philip II, who sought to collect geographic, economic, historic and cultural information from all the kingdoms and territories under their rule. The initiative emerged not only from the need to control the exploitation of resources and resolve important issues such as land possession, management of labor and the transfer of privileges to colonists, but also to compile scientific knowledge and fulfill intellectual curiosity<a class="footnote-ref" href="#delgadolopez2010"> [delgadolopez2010] </a><a class="footnote-ref" href="#delagarza1983"> [delagarza1983] </a>. This involved both collecting descriptions and making maps<a class="footnote-ref" href="#mundy1996"> [mundy1996] </a>. The whole project included Castile, Aragon, Italy, the Netherlands, Portugal (since its annexation in 1581), and the viceroyalties of Peru and New Spain.</p>
<p>For the New World enterprise, the Spanish king, through the Council of Indies, commissioned his leading cosmographers to gather information by means of questionnaires. These were conceived by Juan de Ovando and sent to the Indies in 1569 (37 questions), 1570 (200 questions) and 1573 (135 questions). The responses that came back to Madrid, however, were scarce, probably because the burden of collecting data was put on high-level ecclesiastical and government officials who lacked the necessary knowledge or were not willing to answer so many questions.</p>
<p>The project was revived by Juan López de Velasco, cosmographer–chronicler of Philip II, who in 1577 devised more feasible enquiries. The first one attempted to gather observations about moon eclipses from various parts of the Indies<a class="footnote-ref" href="#cline1964"> [cline1964] </a>. This would allow solving the elusive problem of determining longitude coordinates for the American territories, which in turn would make it possible to establish correctly the position of the Indies with respect to Europe in a universal map<a class="footnote-ref" href="#edwards1969"> [edwards1969] </a><a class="footnote-ref" href="#mundy1996"> [mundy1996] </a>. A second independent enquiry sought to complete the scarce descriptions received in the previous years, sending only fifty carefully formulated questions to be answered not by high-level authorities, as in previous attempts, but bycorregidoresandalcaldes mayores, the local administrative officials with direct knowledge of the situation in towns, villages and hamlets, who also received printed instructions on how to answer the survey.<a href="#figure01">Figure 1</a>shows the first page (out of three) of the printed <em>Instrucción y Memoria</em> sent as a guide to the respondents.</p>
<p>The questionnaire included very detailed information about the life in New Spain. One single query might cover topics such as demography, type of settlements, intercultural opinions, and ethnolinguistics.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> There are also questions about local history, including the names and settlement of towns, and about agricultural and mineral resources. See Appendix 1 for a complete translation of the questionnaire.</p>
<p>Responses to the questionnaire were produced between 1579 and 1585 and are now held in Spain, Scotland, and the United States. In total there are 168 written reports corresponding to an equal number of maincabeceras(head-townsor main districts). These also contain descriptions of 248 subordinate jurisdictions, 414 towns and many smaller villages and hamlets<a class="footnote-ref" href="#cline1964"> [cline1964] </a>. Together they cover more than half the political subdivisions existing in New Spain circa 1580<a class="footnote-ref" href="#cline1972c"> [cline1972c] </a>.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> <a href="#figure02">Figure 2</a>reproduces one of the manuscript pages of the Relación de Atlatlauhca (present–day Atlatlauhcán, Morelos).</p>
<p>Alongside the texts, the corpus contains 78 maps. Some were painted by indigenous artists following native representations of places and landscape (<a href="#figure03">Figure 3</a>and<a href="#figure04">Figure 4</a>), while others were clearly drawn by creoles or peninsular Spaniards (<a href="#figure05">Figure 5</a>). In the words of<a href="#robertson1972">Robertson (1972: 243)</a>, they represent “the largest single group of interrelated early colonial pictorial manuscripts which has come down to us.” <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> Of these maps, 23 came from Mexico; 3 from Michoacán; 1 from Nueva Galicia; 21 from Oaxaca; 18 from Tlaxcala; 3 from Yucatán and 2 from Guatemala. There are also accounts of 26 manuscripts and 16 maps lost centuries ago<a class="footnote-ref" href="#cline1972c"> [cline1972c] </a>;<a class="footnote-ref" href="#cline1972c"> [cline1972c] </a><a class="footnote-ref" href="#robertson1972"> [robertson1972] </a>, as well as an additional map that disappeared more recently<a class="footnote-ref" href="#mundy1996"> [mundy1996] </a>.</p>
<p>Despite the fact that some authors failed to answer several questions, both the texts and the maps offer favorable conditions to test new approaches for the analysis of large historical corpora. The corpus of RGs offers highly structured information — due to the standardized questionnaire — which gives the reports a degree of homogeneity rarely seen in other sixteenth–century collections. The geographic descriptions also cover more than half the territory of New Spain and the level of detail is remarkable not only in terms of orography, landscape, and natural resources, but also the way of life of native peoples and colonists, as well as the interactions between different social groups. Such richness, consistency, and span facilitate comparative research across small, medium, and large areas on topics of social, historical, ethnographic, linguistic, economic, and political interest.</p>
<p>A further reason for selecting the RGs is a desire to improve the accessibility and valorization of the corpus as a main source for historical enquiry. Seminal research has been conducted by<a href="#cline1972">Cline (1972)</a>,<a href="#bravo-garcia2018">Bravo-García (2018)</a>,<a href="#gerhard1972">Gerhard (1972)</a>,<a href="#gruzinski1991">Gruzinski (1991)</a>,<a href="#morenotoscano1968">Moreno Toscano (1968)</a>,<a href="#mundy1996">Mundy (1996)</a>and a few other scholars<a class="footnote-ref" href="#cacereslorenzo2013"> [cacereslorenzo2013] </a><a class="footnote-ref" href="#delgadolopez2010"> [delgadolopez2010] </a>. The publications by<a href="#cline1972">Cline (1972)</a>and<a href="#gerhard1972">Gerhard (1972)</a>, for example, were ground-breaking works of Mexican historical geography.<a href="#morenotoscano1968">Moreno Toscano (1968)</a>, on the other hand, used the complete textual information of the RGs to perform a matrix analysis oriented to reconstruct the economic geography of New Spain, whilst<a href="#mundy1996">Mundy (1996)</a>analyzed all the surviving maps to identify continuities and changes in the indigenous cartographic tradition during the colonial period. For his part,<a href="#gruzinski1991">Gruzinski (1991: 77-103)</a>has approached the corpus by studying how the contrasting — sometimes conflicting — worldview of conquistadors and native peoples shaped the responses to the questionnaire, pointing out interesting details about the colonization of the imaginary.</p>
<p>Single documents of the <em>Relaciones</em> have also been the focus of historical research<a class="footnote-ref" href="#afanadorpujol2015"> [afanadorpujol2015] </a><a class="footnote-ref" href="#ballesteros2005"> [ballesteros2005] </a><a class="footnote-ref" href="#barlow1949"> [barlow1949] </a><a class="footnote-ref" href="#fernandez2006"> [fernandez2006] </a><a class="footnote-ref" href="#morato-moreno2017"> [morato-moreno2017] </a><a class="footnote-ref" href="#mundy2013"> [mundy2013] </a><a class="footnote-ref" href="#nuttall1926"> [nuttall1926] </a>(among others), but in general the textual and cartographic documents have served as ancillary sources in regional studies, rather than as a principal mine of data<a class="footnote-ref" href="#dahlgren1954"> [dahlgren1954] </a><a class="footnote-ref" href="#brand1960"> [brand1960] </a><a class="footnote-ref" href="#gibson1967"> [gibson1967] </a>. This is due perhaps to the difficulty of cross–linking information among the many documents or to a lack of tools for uncovering non–explicit knowledge hidden in the subtext of the answers to the questionnaire.</p>
<h2 id="3-methodology-and-current-progress">3. Methodology and current progress</h2>
<p>As discussed in the introduction, we are developing advanced tools for unveiling new information from the RGs corpus by applying a methodology known as Geographical Text Analysis (GTA). The resulting digital resources and software tools will be released at the end of the project under an open-access license. The methodology was originally produced by some members of this project to reveal new, unsuspected patterns of information by focusing on the geographic components of the historical narrative<a class="footnote-ref" href="#cooper2011"> [cooper2011] </a><a class="footnote-ref" href="#murrieta-flores2015"> [murrieta-flores2015] </a><a class="footnote-ref" href="#donaldson2015"> [donaldson2015] </a><a class="footnote-ref" href="#gregory2015"> [gregory2015] </a><a class="footnote-ref" href="#porter2015"> [porter2015] </a><a class="footnote-ref" href="#martins2017"> [martins2017] </a><a class="footnote-ref" href="#murrieta-flores2017a"> [murrieta-flores2017a] </a><a class="footnote-ref" href="#gregory2018"> [gregory2018] </a>.</p>
<p>We are now in the process of refining and extending this methodology with contributions from all members of this project and from researchers engaged in parallel initiatives (e.g.,<a href="#santos2017">Santos et al. 2017</a>;<a href="#santos2018">Santos et al. 2018</a>;<a href="#won2018">Won et al., 2018</a>). In this particular project we followed four phases: obtaining a computer-readable corpus, the creation of a gazetteer, the semantic annotation and geoparsing of the corpus, and data mining and historical analysis. In the following sections, we discuss each stage in detail.</p>
<h2 id="31-first-phase-obtaining-a-computer-readable-corpus">3.1 First phase: Obtaining a computer-readable corpus</h2>
<p>The first phase of the methodology is obtaining computer–readable files from the more comprehensive editions of the RGs. We began with Francisco del Paso y Troncoso’s <em>Papeles de Nueva España</em> , which contains a significant portion of the corpus. Transcriptions from the original manuscripts were already available in electronic format, but it was necessary to identify and correct significant errors caused by the Optical Character Recognition (OCR) software. This is a common problem with old documents, to which Alpert–Abrams offers an approach in her 2016 article on the corpus known as <em>Primeros Libros</em> .</p>
<p>After completing six volumes of <em>Papeles de Nueva España</em> (Del Paso y Troncoso 1905), the work continued with the RGs from Yucatán, published in volume 11 of <em>Colección de documentos inéditos de las posesiones de España en ultramar</em> (1898). Additionally, thanks to a generous permission from the National Autonomous University of Mexico (UNAM), we were also able to digitize a more recent version of the 54 RGs from Yucatán transcribed and edited by<a href="#delagarza1983">De la Garza (1983)</a>and to acquire in a digital format 114 RGs published in ten volumes by<a href="#acuna1982">Acuña (1982–1988)</a>. In the end, we obtained two versions of the whole corpus in machine–readable format: the first one includes the notes, references and commentary from the scholars who transcribed and studied the documents, while the second contains only the transcription of the original RGs texts. A third version that includes all the NLP annotations was produced during the third phase of the project.</p>
<h2 id="32-second-phase-creation-of-a-gazetteer">3.2 Second phase: Creation of a gazetteer</h2>
<p>The second phase starts with a compilation of all the place names that exist in the corpus as well as many others from relevant sources, and then solving any linguistic and locational uncertainties that prevent their unequivocal identification.</p>
<h2 id="321-compilation-of-place-names">3.2.1 Compilation of place names.</h2>
<p>This is done by extracting toponym indices from published editions of the RGs, as well as from comprehensive studies on the historic geography of New Spain (<a href="#gerhard1972a">Gerhard 1972a</a>,<a href="#gerhard1972b">1972b</a>,<a href="#gerhard1991">1991</a>;<a href="#cline1972a">Cline 1972a</a>,<a href="#cline1972b">1972b</a>,<a href="#cline1972c">1972c</a>;<a href="#morenotoscano1968">Moreno Toscano, 1968</a>;<a href="#tanck2005">Tanck de Estrada et al., 2005</a>). Through this procedure, the UK and Mexican teams were able to compile a list of 14,654 place names (<a href="#liceras-garrido2019">Liceras-Garrido et al. 2019</a>).</p>
<h2 id="322-linguistic-disambiguation">3.2.2 Linguistic disambiguation.</h2>
<p>The resulting list was then subjected to a linguistic disambiguation process, during which the most difficult challenges were dealing with place names found in different native languages, as well as resolving name variations and spelling inconsistencies. Important names of cities, like Tlaxcala, have remained in original form since the sixteenth century, but many others have changed significantly over time for a variety of reasons, including: historic causes;<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> renaming due to changes in the boundaries of original settlements;<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> and addition of words such as the name of a patron saint to an indigenous toponym.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> Another problem relates to spelling variations of the same toponym,<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> the application of Castilian transliterations to the names of ancient settlements,<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> or dealing with homonymies.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></p>
<p>State–of–the–art methods to tackle these challenges are discussed in<a href="#nick2017">Nick and Tent (2017)</a>and<a href="#santos2015">Santos et al. (2015</a>,<a href="#santos2017">2017</a>,<a href="#santos2018">2018</a>). Additionally, there is a valuable body of research on the subject of Mexican toponomy, so we have benefited from publications by<a href="#anayamonroy1960">Anaya Monroy (1960)</a>,<a href="#guzmanbetancourt1987">Guzmán Betancourt (1987</a>,<a href="#guzmanbetancourt1989">1989</a>,<a href="#guzmanbetancourt1998">1998</a>),<a href="#lefevre2017">Lefevre and Paredes Martínez (2017)</a>,<a href="#leonportilla2002">León Portilla (2002)</a>,<a href="#marquez1998">Márquez and Ramos Navarro Wold (1998)</a>,<a href="#mundy2014">Mundy (2014)</a>,<a href="#muntzel2010">Muntzel and Villegas Molina (2010)</a>, etc. This adds to the exhaustive research done by the editors of the RGs, especially<a href="#acuna1982">Acuña (1982–1988)</a>,<a href="#delagarza1983">De la Garza (1983)</a>and<a href="#delpaso1905">Del Paso y Troncoso (1905)</a>.</p>
<h2 id="323-geographic-disambiguation">3.2.3. Geographic disambiguation.</h2>
<p>Another challenge at this stage is finding latitude and longitude coordinates of towns and villages. The solution involves, first, detecting and merging duplicate entries by comparing the place name list with records found in online geographical databases, such as the catalogue of indigenous localities, produced by Instituto Nacional de Estadística Geografía a Informática (INEGI) and Comisión Nacional para el Conocimiento y Uso de la Biodiversidad (CONABIO);<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> the geographic dataset created for the cartography of Mexico by INEGI; the general registrar of archaeological sites compiled by Instituto Nacional de Antropología e Historia (INAH);<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> the GeoNames geographical database;<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> and the Getty Thesaurus of Geographical Names.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> Through both linguistic and locational disambiguation, we were able to obtain 12,748 correct names. Of these, we have so far been able to pin-point 3919 physical locations (<a href="#figure06">Figure 6</a>), which are the entries used for the gazetteer.</p>
<p>The structure of the gazetteer complies with Linked Open Data standards to guarantee its interoperability between different systems and repositories and facilitate its application into other projects. We have relied on the experience of massive reference resources like the Getty Thesaurus of Geographical Names<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> and especially the Alexandria Digital Library Gazetteer (ADL), from which we adopted the relational database schema<a class="footnote-ref" href="#hill2000"> [hill2000] </a><a class="footnote-ref" href="#hill1999"> [hill1999] </a>. For importing and exporting data, we adopted the file format JSON, created by the World Historical Gazetteer<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> , which is now an accepted standard in many textual annotation and analysis platforms, such as Recogito. The database of our gazetteer will be made available through the World Historical Gazetteer, the Pelagios Network, and through Recogito. In addition, the gazetteer will be also available in a standalone downloadable GIS format from the project’s website and repositories.</p>
<h2 id="33-third-phase-semantic-annotation-of-the-corpus">3.3 Third phase: Semantic annotation of the corpus</h2>
<p>The third stage comprises four tasks: defining an annotation schema by selecting the most relevant analytic categories for the intended historical analysis; annotating manually, and in accordance with the previously defined annotation schema, two different samples of documents: one for training the NLP deep-learning model and another one to validate it; tuning the deep-learning model to automatically perform name entity recognition, disambiguation and classification, in order to obtain a fully annotated corpus; and assessing the performance of the model in accordance with the gold-standard validated by experts.</p>
<h2 id="331-defining-the-annotation-schema-ontology">3.3.1 Defining the annotation schema (ontology).</h2>
<p>The selection of the ontology categories can be done by consensus among expert linguists and historians, or with the help of automatic computer methods that extract a “seed ontology” directly from the corpus<a class="footnote-ref" href="#eynard2012"> [eynard2012] </a>. The first method is more time-consuming, but it is simpler and on many occasions yields better results, so this was the approach we followed.</p>
<p>The RGs ontology contains 21 entity classes and many more sub-categories relevant to social, political, territorial and economic terms appearing recurrently through the RGs (Table 2). For example, the general entity classarchitectureincludes sub-categories such asdomesticandreligious,which offers the possibility to distinguish between house and convent buildings described in texts. Another classcosmogonyincludes sub-categories such asritual,festivity,deity,etc. Each entity type follows the definitions and linked-data standards of DBpedia to ensure the interoperability of our dataset.</p>
<h2 id="332-manual-annotation-of-text-samples-for-training-the-nlp-model">3.3.2 Manual annotation of text samples for training the NLP model.</h2>
<p>Using such entity classes we carried out a manual annotation of two samples of 18 out of 168 documents (10% of the corpus) from the RGs using the online tagging tools developed by Tagtog, a commercial company that generously provided a free license to our project.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> In order to ensure the quality of the annotated samples, five experts tagged the same documents independently. We then obtain statistics on the level of consensus among the experts by using the inter-annotator agreement tool from Tagtog.<a href="#figure07">Figure 7</a>illustrates an annotated document.</p>
<h2 id="333-development-of-the-nlp-deep-learning-model">3.3.3 Development of the NLP deep-learning model.</h2>
<p>Once the training and gold-standard sample data are available, the actual development of the NLP model can begin. Our team in Portugal, led by Bruno Martins, combined two state-of-the-art approaches of deep-learning: neural networks and word embedding.</p>
<h2 id="3331-neural-networks">3.3.3.1 Neural networks.</h2>
<p>A neural network is a computational model, loosely inspired on the neural structure of the brain, that is able tolearn by examplehow to perform repetitive complex tasks. In the NLP and CL fields, it is applied, among other things, to perform word classification, or the assigning of a label to each word in an input text, indicating whether it belongs to a certain semantic category (e.g. toponym, person, animal, plant, institution, cultural concept), or to apart-of-speechsyntactic category (i.e. noun, pronoun, adjective, determiner, verb, adverb, preposition, conjunction, and interjection).</p>
<p>Modern NLP software libraries leverage such statistical models<a class="footnote-ref" href="#goldberg2017"> [goldberg2017] </a>, making probabilistic decisions on the best annotations for previously unseen texts. One of the best is SpaCy. To run a deep-learning model in SpaCy we need to conduct a training phase during which the software is fed with the training data sample (in our case 10% of the corpus). This annotated training sample contains many known examples of the kind of words expected in the unannotated text (the remaining 90% of the corpus).</p>
<p>Because we know the correct answers — thanks to the gold-standard data sample — , we can give the model feedback on its predictions in the form of an error gradient or the loss function that calculates the difference between the training example and the expected output. If the accuracy of the annotations is not sufficient, then an iterative refining process can be carried out until accomplishing satisfactory results.</p>
<p>Then, to link the gazetteer with the corpus texts, it is necessary to assign correct longitude and latitude coordinates to each toponym recognized by the neural network. The Mordecai geoparsing library<a class="footnote-ref" href="#halterman2017"> [halterman2017] </a>is a good tool for that job. It takes as input the place names recognized by SpaCy, and uses an index over the contents of the gazetteer to find the potential coordinates of extracted place names. In other words, the names recognized in the text are matched against similar names in the gazetteer. Through this process the gazetteer and the corpus are finally linked and ready for the implementation of query tools.</p>
<h2 id="3332-word-embedding">3.3.3.2 Word-embedding.</h2>
<p>Complementing the above procedures, the word–embedding algorithm makes it easier for the neural network to distinguish all of the different semantic contexts in which a word might be used. This process follows the idea that “a word is characterized by the company it keeps” <a class="footnote-ref" href="#firth1957"> [firth1957] </a>. For example, in the phrase “[t]he order of San Francisco was established in these lands in 1524,” the termSan Franciscorefers to an institution, but in “[t]he mendicant friars helped the poor following the teachings of San Francisco,” the same term refers to a person. In another context, it could mean a geographic location, as for instance in the sentence “San Francisco Tlalcilalcalpan is inhabited at the present by 18,721 people.”</p>
<p>We specifically pre-trained a word–embedding algorithm in an unsupervised way to statistically predict the meaning of words in the context of real natural language utterances. Thus, we needed training data sufficiently big and varied to tackle the specific challenges of the RGs. One is that the spelling in the corpus varies considerably among the many authors. This is sometimes, in part, because words are spelled in accordance with their Latin origin, rather than their actual pronunciation. Another is that the corpus borrows heavily on vocabulary from indigenous languages, especially place names, and terms to identify flora, fauna, cultural concepts, etc.</p>
<p>Given the fact that the structure of modern Spanish still resembles to a high degree the language recorded in the RGs, we decided to combine modern and historical data sources to train our model. Contemporary data came from several Spanish corpora such as ANCora<a class="footnote-ref" href="#taule2008"> [taule2008] </a>, IMPACT-es<a class="footnote-ref" href="#sanchez-martinez2013"> [sanchez-martinez2013] </a>, or the <em>Corpus del Español</em> ,<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> while numerous examples of sixteenth–century Spanish texts from different archives and ten dictionaries of indigenous languages<a class="footnote-ref" href="#garciacubas1888"> [garciacubas1888] </a><a class="footnote-ref" href="#penafiel1897"> [penafiel1897] </a><a class="footnote-ref" href="#robelo1897"> [robelo1897] </a><a class="footnote-ref" href="#robelo1900"> [robelo1900] </a><a class="footnote-ref" href="#robelo1902a"> [robelo1902a] </a><a class="footnote-ref" href="#robelo1902b"> [robelo1902b] </a><a class="footnote-ref" href="#robelo1904"> [robelo1904] </a><a class="footnote-ref" href="#robelo1905"> [robelo1905] </a><a class="footnote-ref" href="#starr1920"> [starr1920] </a>provided resources to deal with the language complexities particular to New Spain.</p>
<p>By thus leveraging modern and historical data in a combined training dataset, we can simultaneously benefit from having large amounts of contextual information from which the model can learn more easily, together with some data representing the specificities of historical Spanish. Furthermore, to avoid problems with out-of-vocabulary words, such as those brought forward by the inconsistent spelling or cultural expressions, we used a word–embedding method that also creates representations for sub-words, and which is able to reconstruct entire word representations from such sub-words<a class="footnote-ref" href="#bojanowski2017"> [bojanowski2017] </a>.</p>
<h2 id="4-future-work-data-mining-and-historical-analysis">4. Future Work: Data mining and historical analysis</h2>
<p>At this stage, several data mining and analysis procedures can be carried out. The first is an adaptation of collocation analysis — a technique from Corpus Linguistics (CL) — which allows for extracting the most statistically significant phrases that are found next to a term or keyword of interest (thecollocates,in CL jargon). Our variant of the technique isgeographic collocation analysis, originally developed by the research group at Lancaster<a class="footnote-ref" href="#gregory2015"> [gregory2015] </a><a class="footnote-ref" href="#murrieta-flores2015"> [murrieta-flores2015] </a><a class="footnote-ref" href="#murrieta-flores2017a"> [murrieta-flores2017a] </a><a class="footnote-ref" href="#murrieta-flores2017b"> [murrieta-flores2017b] </a>. This facilitates the recognition and retrieval, across the corpus, of all place names that collocate or are close to a keyword of interest according to a predefined proximity threshold, usually defined in terms of the maximum number of words between the search–term and the collocate. In this manner, if a researcher is interested in investigating economic aspects related to agriculture, they could retrieve, for instance, all phrases in the context of words likemaíz,siembra,subsistencia,mantenimientos,comida(i.e.maize,sowing,subsistence,sustenance,food), which would appear linked to a map showing the geographic locations where such terms appear.</p>
<p>Furthermore, by putting words in context through collocation, a historian could extract in a few seconds — as opposed to the weeks that it would take to access the information without GTA tools — interesting details about the first colonists in New Spain. Such a query, for instance, might involve running a collocate search of the word “conquistador” (<a href="#figure08">Figure 8</a>). Another type of search can be conducted using general categories, such as employing the termfoodto retrieve words likebeans,fish,orbread(<a href="#figure09">Figure 9</a>).</p>
<p>In the following subsections, we highlight several topics of historic analysis that we plan to examine through this research.</p>
<h2 id="41-historical-phenomena-changing-the-face-of-new-spain-at-the-end-of-the-sixteenth-century">4.1 Historical phenomena changing the face of New Spain at the end of the sixteenth century</h2>
<p>One area of application for the techniques detailed in this study is understanding the coexistence of competing systems of land ownership and labor in New Spain during the colonial period. In New Spain during the short time of compilation of the RGs, there was a strong debate about the system ofencomiendasand the desire to replace it with the so-calledrepartimientos. Theencomiendawas the right to exploit the labor of indigenous populations, granted by the Spanish Crown to conquistadors, who at the beginning of the colonization held this privilege in perpetuity and could, therefore, pass it to their descendants with little intervention from the royal government in Madrid. In contrast, therepartimientoonly allocated the labor force of native workers for a fixed period of time in exchange for a meager remuneration. The latter gave the royal government more control over its subjects and resources. Neither the holders ofencomiendasnorrepartimientoswere allowed to appropriate lands, as private property was reserved forhaciendas. These three systems coexisted in the 1570s despite the enactment of the so-called New Laws in 1542, which attempted to protect the rights of the indigenous populations and prevent the dispossession of their lands by abolishing theencomiendas. Throughout the texts of the RGs, therefore, it is common to find claims by conquistadors’ descendants of theirencomiendarights, and others defending the benefits ofrepartimientos. A comprehensive study of the claims and contentions found in the RG corpus would improve our understanding of the period.</p>
<h2 id="42-the-local-government-organization-of-new-spain-toward-the-third-quarter-of-the-sixteenth-century">4.2 The local government organization of New Spain toward the third quarter of the sixteenth century</h2>
<p>A second application of these methodologies has to do with disambiguating local structures of governance in New Spain. The early colonial period was a time when the functions and spheres of influence of the four branches of colonial government were not well defined, and consequently the spatial boundaries of the judicial, administrative, military and ecclesiastical jurisdictions overlapped (<a href="#figure10">Figure 10</a>). This was especially true at the municipal level. Consequently, the corpus contains terms associated with several kinds of jurisdictions whose meanings were not consistent throughout the vast territory of New Spain (e.g. <em>partidos de clérigos</em> , <em>distrito de mision</em> , <em>custodia</em> , <em>guardianía</em> , <em>vicaría, presidencia</em> , etc.). The subject has been a matter of ongoing debate among historians<a class="footnote-ref" href="#gerhard1972b"> [gerhard1972b] </a>, but we believe that applying collocation analysis for extracting the contextual use of such words would shed light on how those institutions functioned in parallel to <em>alcaldías mayores</em> and <em>corregimientos</em> and this would be an important contribution to the knowledge of this period.</p>
<h2 id="43-settlement-pattern-analysis-to-elucidate-the-territorial-organization-of-new-spain">4.3 Settlement pattern analysis to elucidate the territorial organization of New Spain</h2>
<p>A third area for future study has to do with demarcating the boundaries of territories in New Spain. By reading the RGs, we could attempt to identify the names and boundaries (linderos) of towns belonging tocorregimientos(territorial demarcations for administrative and judicial purposes) mentioned in the corpus. Circa 1570, there were 200 of such units whose frontiers have been outlined by<a href="#gerhard1972a">Gerhard (1972a)</a>. However, the smaller demarcations (towns, villages) suffered adjustments in boundaries and jurisdictions. As Gerhard points out, at the time of the RGs, “[e]arly civil and ecclesiastical divisions lost importance and were eliminated; others came into being as a result of conquest, proselytization, mining activity, and other causes” <a class="footnote-ref" href="#gerhard1972b"> [gerhard1972b] </a>. The application of a mathematical model that analyzes the maximum available territory around each settlement within a region, like the one proposed by<a href="#ducke2008">Ducke and Kroefges (2008)</a>, could provide preliminary hypotheses on such demarcations. These would then be tested against the actual historical information extracted from the corpus through geographic collocation analysis. One of the many ways that such a study could begin is by extracting references on the routes that local administrators take for their visits to towns within their jurisdiction, the distances they traversed, the geographic features and topography of the landscape, etc. (<a href="#figure10">Figure 10</a>) This, and much other information, is available throughout the corpus, but more specifically in the answers to questions 7, 8, 11, and 12 (see<a href="#appendix01">Appendix 1</a>).</p>
<h2 id="44-analysis-of-historical-diseases">4.4 Analysis of historical diseases</h2>
<p>A fourth research question has to do with our understanding of the outbreak of disease (1576-1581) that took the lives of half the population of New Spain during the early colonial period<a class="footnote-ref" href="#acuna-soto2004"> [acuna-soto2004] </a>. This was the second time thatcocoliztli(as the epidemic was called) had decimated the native population, causing the disappearance of whole communities, shortages in labor-force for theencomiendasandrepartimientos, the displacement of people over different regions, or, on the contrary, the congregation of survivors (sometimes of different ethnic communities) in new Indian towns, all of which altered dramatically the traditional settlement pattern<a class="footnote-ref" href="#gerhard1972a"> [gerhard1972a] </a>. How did this phenomenon vary over different regions? How many people died in each locality? How did this epidemic compare with others in the past? How did the new settlement change in comparison with Prehispanic times? These are all questions that GTA could help to answer by collocating words and phrases related to health (such as diseases, symptoms, and remedies) and analyzing them with spatial mathematical models of disease contagion.</p>
<h2 id="45-the-spatial-distribution-of-natural-resources-flora-fauna-minerals-etc-and-exploitation-practices-at-the-time-of-the-rgs">4.5 The spatial distribution of natural resources (flora, fauna, minerals, etc.) and exploitation practices at the time of the RGs</h2>
<p>A fifth application of our methodology has to do with the study of natural resources. GTA will allow the extraction and analysis of regional historical information on natural resources such as plants. There are already interesting archaeological, historical and ethnographic research related to plants and their use in Mesoamerica, medicinal and otherwise<a class="footnote-ref" href="#alboreszarate2015"> [alboreszarate2015] </a><a class="footnote-ref" href="#chavezmejia2020"> [chavezmejia2020] </a><a class="footnote-ref" href="#hersch1999"> [hersch1999] </a>. Some further research has been also dedicated to assessing the importance of the trees and edible plants introduced by Europeans. With the annotation of the RGs in this project and the development of GTA, it is now possible not only to extract information regarding native and European plants introduced in the different regions of New Spain, but also to contribute to further debates. It is known, for instance, that Mesoamerican cultures had an extended knowledge of plants for medicinal use and most of the research about this has been carried out using colonial primary sources. We could now create a map of all the plants mentioned in the RGs and compare this dataset with archaeological data and other primary sources that were dedicated to the recording of medicinal plants, such as the Códice Badiano or the Historia Natural de Nueva España. This would allow researchers, for instance, to assess the continuation in the use of specific plants for remedies and consumption in specific regions of New Spain. Other interesting avenues of possible research with GTA analysis are the availability of food and animals both native and introduced, the use of natural resources, the existence of cultural artefacts, the presence of priests and religious orders in particular regions, as well as types of architecture.</p>
<h2 id="46-exchange-networks-trading-practices-and-communication-routes">4.6 Exchange networks, trading practices and communication routes</h2>
<p>An additional topic is the study of exchange networks and trading practices, as well as communication routes, both terrestrial and aquatic, among the populations described in the RGs. One such study has already been conducted by<a href="#favila-vazquez2019">Favila-Vázquez (2019)</a>, who successfully reconstructed aquatic communication networks in the Rio Balsas region by extracting information from the responses available to queries 38 to 47 of the RGs (<a href="#figure11">Figure 11</a>). These contain crucial data regarding navigation by sea, including location of ports and coastal landscape. Together with data from question 19 (focused on fluvial networks), the extraction of data from the RGs corpus allowed Favila-Vázquez to reconstruct a riverine and coastal system of communication that explains the spatial connectivity of the Valley of Mexico to the Pacific coast. </p>
<h2 id="5-conclusion">5. Conclusion</h2>
<p>Geographical Text Analysis can make an important contribution to the study of massive corpora, like the RGs, by expediting the extraction and analysis of specific information that would be too slow or cumbersome to find in big datasets through traditional reading methods. It also can provide tools to uncover patterns behind the narrative of historical sources and link them to their geographic locations. Thus, GTA creates a way for historians to apply what in computational literary studies is calleddistant reading.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup></p>
<p>At the same time, the use of geographic collocations and the concept ofkeywords in contextpermit a more detailed, granular comprehension of the corpus by identifying those parts that deserve aclose reading.This flexibility has been demonstrated in previous research projects employing GTA<a class="footnote-ref" href="#donaldson2017"> [donaldson2017] </a><a class="footnote-ref" href="#murrieta-flores2017a"> [murrieta-flores2017a] </a><a class="footnote-ref" href="#taylor2017"> [taylor2017] </a>. Having a multiplicity ofplace names in contextassociated with keywords of interest opens an unprecedented range of possibilities in terms of identifying information patterns and hypothesis–testing across large corpora, which in turn allows answering historical questions in a way that would be impossible otherwise.</p>
<p>In such a context, the proposal of GTA must not be seen as an attempt to replace the careful micro study of historical sources practiced by modern historians. More exactly, GTA is a methodology for parsing and crosslinking information at a macro scale throughout a whole corpus in a relatively short period of time, so historians can use their efforts and time more efficiently to focus on the more important documents or fragments of texts.</p>
<p>One of the main contributions of our project specifically has been adapting named entity recognition, disambiguation, and classification techniques to text collections that either belong to specific historical periods or might pose a further challenge due to their multi–language nature. We have succeeded in developing a new deep-learning model to process the language of the RGs despite the orthographic variance across the corpus and the high frequency of indigenous vocabulary. Nevertheless, there is still much work to be done, especially for the indigenous languages of the Americas<a class="footnote-ref" href="#mager2018"> [mager2018] </a>.</p>
<p>Finally, we have already produced a significant number of digital datasets of value, such as the gazetteer, which includes not only sixteenth–century localities but place names from other Mexican historic periods. Hopefully, these will prove valuable resources for humanists engaged in studying the Latin American historical and archaeological past. The methods and tools being developed by the project have the advantage of being generic, and therefore, applicable to other corpora.</p>
<p>We are committed to releasing the digital products and software tools through several repositories, including GitHub and our own online platform. Our hope is that scholars from diverse fields will be able to identify the desired information, extract it, cross–link it to other document resources, and most importantly, answer significant research questions: Where do certain phenomena happen more often? Who was responsible for certain events? What was happening in specific places at certain times? Such kind of enquiry will take historical analysis a step further, contributing significantly to advancing research on the colonial period in Latin America, and humanities research more generally.</p>
<h2 id="appendix-1-the-questionnaire-of-the-relaciones-geográficas21">Appendix 1. The Questionnaire of the Relaciones Geográficas<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></h2>
<h1 id="memorandum-of-the-things-that-are-to-be-answered-and-of-that-which-shall-be-taken-into-account">Memorandum Of The Things That Are To Be Answered, And Of That Which Shall Be Taken Into Account.</h1>
<p>Firstly: For towns of Spaniards, state the name of the district or province in which it lies. What does this name mean in the native language, and why is it so called?Who was the discoverer and conqueror of this province? By whose order was it discovered? In what year was it discovered and conquered, as far as is readily known?What is the general climate and character of the province or district? Is it very cold or hot, humid or dry? Does it have much or little rain, and when, approximately, does it fall? How violently and from where does the wind blow, and at what times of the year?Is the terrain flat or rugged, clear or wooded, with many or few rivers or springs, abundant in or lacking water? Is it fertile or without pasture, abundant or lacking in fruits and sustenance?Are there many or few Indians? Were there more or fewer at other times, and what are the known causes of this? Are they presently settled in planned and permanent towns? Describe the degree and quality of their intelligence, inclinations, and way of life. Are there different languages in the province or a general language that all speak?What is the latitude, or the altitude of the Pole Star, at each Spanish town, if it has been taken and is known, or if anyone knows how to observe it? Or on which days of the year does the sun not cast a shadow at midday?What are the league distances and the direction of each Spanish city or town in the district to the city of its <em>Audiencia</em> , or to the town where the governor to whom it is subject resides?Likewise, what are the league distances and the direction of each Spanish city or town to adjacent ones? Are these leagues long or short, through flat or hilly land, over straight or winding roads, easy or difficult to travel?What are the present and former names and surnames of each city or town? Why are they so called, if known? Who gave each its name, who was its founder, by whose order was it settled? What year was it founded? How many residents did the settlement first have, and how many does it have now?Describe the sites upon which each town is established. Is each upon a height, or low-lying, or on a plain? Make a map of the layout of the town, its streets, plazas and other features, noting the monasteries, as well as can be sketched easily on paper. On it show which part of the town faces south or north.For native towns, state only how far they are from the town in whose corregimiento or jurisdiction they are, and how far they lie from their cabecera de doctrina.In addition, state how far the native towns lie from surrounding native or Spanish towns. Declare for all their direction from these other towns. Are the leagues long or short, the roads through level or hilly land, straight or winding?What does the name of this [native] town mean in the indigenous language? Why is it called this, if known? What is the name of the language spoken by the natives of this town?Who were their rulers in heathen times? What rights did their former lords have over them? What did they pay in tribute? What forms of worship, rites, and good or evil customs did they practice?How were they governed? With whom did they wage war? How did they battle? What was their battle dress and clothing like, both formerly and now? What was their former and is their present means of subsistence? Were they more or less healthy than now and what are reasons for this that you may know?For all towns, both Spanish and native, describe the sites where they are established. Are they in the mountains, in valleys, or on open flat land? Give the names of the mountains, valleys, and districts, and for each, tell what the name means in the indigenous language.Is the land or site healthy or unhealthy? If unhealthy, why (if it is known)? What illnesses commonly occur, and what cures are commonly used for them?How far or near, and in what direction does each town lie from a nearby prominent mountain or range? Supply its name.What major river or rivers flow nearby? How distant and in what direction do they lie? How great is their flow? Is there anything notable known about their sources, water, orchards and other growth along their banks? Are there or could there be irrigated lands of value?What are the significant lakes, lagoons, or springs within the town boundaries? Note anything remarkable about them.What are the volcanoes, caves, and all other notable and remarkable aspects of nature in the district worthy of being known?Which wild trees and their fruits are commonly found in the district? What are the uses of them and their woods, and to what good are they or could they be put?Which cultivated trees and fruit orchards are in the region? Which were brought from Spain and elsewhere? Do these grow well?What are the grains and seed plants, and other garden plants and vegetables that are or have been used as sustenance for the natives?Which were brought from Spain? Does the land yield wheat, barley, wine, or olive oil, and in what quantities? Is there silk or cochineal in the region, and in what quantities?What are the herbs or aromatic plants that the natives use for healing? What are their medicinal or poisonous properties?What animals and birds, both wild and domestic, are in the region? Which ones were brought from Spain, and how well have they bred and multiplied?In the region or within the town lands, are there any gold or silver mines or sources of other metals, or black or colored pigments?Are there any quarries of precious stone, jasper, marble, or other notable ones? What value might they have?Are there sources of salt in the town or nearby? If [residents] lack salt and other items necessary for their sustenance or clothing, where do they procure all these things?How are the houses built and what is their form? What building materials are found in the town, or brought from elsewhere?What are the towns&rsquo; fortifications? Are there barracks, or any fortified or impregnable places within the boundaries of the district?Through what dealings, trade, and profits do both Spaniards and Indians live and sustain themselves? What are the items involved and with what do they pay their tribute?In which diocese of the archbishopric, bishopric, or abbey does each town lie? In which district does each lie? How many leagues and in which direction does each town lie from the town of the cathedral and the cabecera of the district? Are the leagues long or short, along straight or winding roads, and through flat or hilly land?In each town, what are the cathedral and parish church or churches? What is the number of endowed church offices and allotments for clergymen&rsquo;s salaries in each? Do any have a chapel or significant endowment, and, if so, whose it is and who established it?What are the monasteries or convents of each Order? By whom and when were they founded? How many notable things do they contain? And what is the number of religious?What are the hospitals, schools, and charitable institutions in the towns? By whom and when were they founded?If the towns are on the seacoast, in addition to the above, report in your account the nature of the sea in the vicinity, whether it is calm or stormy, the nature of the storms and other dangers. What times, approximately, are they frequent?Is there beach or cliffs along the coast? What are the prominent reefs and other dangers to navigation along it?How great are the tides and tidal ranges? On which days and at which hours do they occur? In which season are they greater or lesser?What are the notable capes, points, bights, and bays in the district? Note their names and sizes, as well as can be determined.What are the ports and landings along the coast? Make a map showing their shape and layout as can be drawn on a sheet of paper, in which form and proportion can be seen.What is their size and capacity? Note their approximate width and length in leagues and paces, as well as can be determined. Also note how may ships they will accommodate.What is the depth in fathoms of each? Is the bottom clear? Are there any shallows and shoals? Indicate their locations, and whether the port is free of shipworm and other impediments.What directions do their entrances and exits face? With which winds must one enter and depart?What are their advantages or lack of them in the way of firewood, water, and provisions? What are the favorable or unfavorable considerations for entering and remaining?What are the names of the islands along the coast? Why are they so named? Make a map, if possible, of their form and shape, showing their length, width, and lay of the land. Note the soil, pastures, trees, and resources they may have, their birds and animals, and the notable rivers and springs.Where are the abandoned Spanish towns located in the region? When were they settled and abandoned? What is known about the reasons for abandonment?Describe any other of the notable aspects of nature, and any notable qualities of the soil, air, and sky in any part of the region.Having completed the account, the persons who have collaborated on it will sign it. It must be returned without delay, along with these directions, to the person from whom it was received.</p>
<h2 id="appendix-2-figures">Appendix 2. Figures</h2>




























<figure ><img loading="lazy" alt="A page from _Instrucción y Memoria_ ." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>First page of the printed <em>Instrucción y Memoria</em> sent by the Council of Indies to guide the compilation of the <em>Relaciones Geográficas</em> . Photograph courtesy of the Benson Latin American Collection. The General Libraries, The University of Texas at Austin (JGI xxiii-13).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="A page of the _Relación of Atlatlauhca_ manuscript." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Manuscript from the <em>Relación of Atlatlauhca</em> (Morelos) containing responses to the first two questions of the enquiry.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Handdrawn map of Ixtapalapa (Ciudad de Mexico)." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Map of Ixtapalapa (Ciudad de Mexico) included in the <em>Relación Geográfica de Ixtapalapa</em> (1580), belonging to the corregimientoof Mexicaltzingo. Size of the original: 43 x 31 cm. The author is Martin Cano, a native local artist, who, as Mundy (1996: 63) points out, is one of the uses pictographs to represent the town´s name, which in Nahuatl means “water near the flagstones”: “Below the church, a hexagonal flagstone is surrounded by a blue ribbon of water. Ixtapalapa´s church dominates one axis of the composition, while its twin community buildings, at left, dominate the other”. Photograph courtesy of the Benson Latin American Collection. The General Libraries, The University of Texas at Austin (JGI xxiv-8).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Handdawn map of _Relación de Amoltepec_ ." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Map of the <em>Relación de Amoltepec</em> . This is another example of the indigenous tradition to represent a geographic region. The place names of neighbor and subject towns are drawn with logographs organized in a semi-circle, surrounding the church and the ruler´s palace (Mundy, 1996: 113). Photograph courtesy of the Benson Latin American Collection. The General Libraries, The University of Texas at Austin (JGI xxiv-5).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Handdrawn map of _Relación de Tlacotalpa_ ." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Map of the <em>Relación de Tlacotalpa</em> . One of the best examples of charts in the European tradition that can be found in the RGs corpus. This was produced by Francisco Stroza Gali, a professional mariner in 1580 (Mundy, 1996: 51). A detailed study of the document reveals the extraordinary precision of the geographic measurements achieved by Gali<a class="footnote-ref" href="#morato-moreno2017"> [morato-moreno2017] </a>.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Map of Mexico and Central America with divisions depicted using different colors." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Location of the 3919 sites georeferenced so far (April 2020) through linguistic and locational disambiguation, which are added to the project´s gazetteer
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="The Tagtog software tool with words highlighted in various colors." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Annotation of the <em>Relación de Merida</em> with the Tagtog software tool. Notice the color code to distinguish different annotation categories: red is used for words referring to persons, either by name, profession or roles; green to locations (either toponyms or geographic features); light blue to dates, and so on.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="The GTA tool with words highlighted and an accompanying map." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Extracting information with GTA tools (which are still a work in progress). In this example, the keyword “conquistador” is used to recover data from the colonists mentioned in the <em>Relación de Tekal</em> . The map shows the location of this town in Yucatán. Queries like this can be apply to a single document or to the complete corpus.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="The GTA tool with words highlighted." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Another type of query that retrieves works in context belonging to the food category. In this example, the threshold for the collocation has been set 10 words before and after the key category.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Map of Mexico and Central America with divisions depicted with blue and red lines." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Map illustrating the overlapping of three types of colonial jurisdictions: political ( <em>gobiernos</em> ), ecclesiastic (dioceses), and administrative ( <em>provincias</em> ).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="Map of Mexico highlighting towns that were along the Pacific coast and Balsas river." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Map showing the location of towns that were part of the indigenous network of navigation through the Pacific coast and the Balsas river towards the third quarter of the 16th century. Photograph courtesy of<a href="#favilavazquez2019">Favila-Vázquez (2019)</a>.
        </p>
    </figcaption>
</figure>
<h2 id="annotation-schema-table">Annotation schema table</h2>
<p>Annotation schema: entities, DBpedia definitions and labels per entity.EntityOntological definitionLabelsPerson<a href="http://dbpedia.org/page/Person">http://dbpedia.org/page/Person</a>female/male, title, professionDate<a href="http://dbpedia.org/ontology/date">http://dbpedia.org/ontology/date</a>Institution<a href="http://dbpedia.org/page/Institution">http://dbpedia.org/page/Institution</a>civil, ecclesiasticalLocation<a href="http://dbpedia.org/ontology/location">http://dbpedia.org/ontology/location</a>settlement type, generic location, geographic feature type, toponym, address, imaginary, ecclesiastical jurisdiction, civil jurisdictionActivity<a href="http://dbpedia.org/ontology/activity">http://dbpedia.org/ontology/activity</a>agriculture, warfare, economy, mining, domestic, female/maleAnimal<a href="http://dbpedia.org/ontology/animal">http://dbpedia.org/ontology/animal</a>insect, mammal, reptile, bird, amphibian, aquatic, domesticatedPlant<a href="http://dbpedia.org/page/Plan">http://dbpedia.org/page/Plan</a>Food<a href="http://dbpedia.org/page/Food">http://dbpedia.org/page/Food</a>Natural Resource<a href="http://dbpedia.org/page/Natural_resource">http://dbpedia.org/page/Natural_resource</a>Cultural artefact<a href="http://dbpedia.org/page/Cultural_artifact">http://dbpedia.org/page/Cultural_artifact</a>house goods, commodities, clothing, weapon, toolArchitecture<a href="http://dbpedia.org/page/Architecture">http://dbpedia.org/page/Architecture</a>religious, civil, domesticCosmogony<a href="http://dbpedia.org/page/Cosmogony">http://dbpedia.org/page/Cosmogony</a>ritual, festivity, activity, deities, saints, objectHealth<a href="http://dbpedia.org/page/Health">http://dbpedia.org/page/Health</a>disease, remedyRoute of Transportation<a href="http://dbpedia.org/ontology/RouteOfTransportation">http://dbpedia.org/ontology/RouteOfTransportation</a>terrestrial, aquatic, route direction, distanceKinship<a href="http://dbpedia.org/page/Kinship">http://dbpedia.org/page/Kinship</a>Climate<a href="http://dbpedia.org/page/Climate">http://dbpedia.org/page/Climate</a>Ethnic Group<a href="http://dbpedia.org/page/Ethnic_group">http://dbpedia.org/page/Ethnic_group</a>Social Class<a href="http://dbpedia.org/page/Social_class">http://dbpedia.org/page/Social_class</a>Language<a href="http://dbpedia.org/page/Language">http://dbpedia.org/page/Language</a>Event<a href="http://dbpedia.org/page/Event">http://dbpedia.org/page/Event</a>historical, disastersMeasurement<a href="http://dbpedia.org/page/Measureme">http://dbpedia.org/page/Measureme</a>value, tribute, weight, population</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>We would like to thank the generous grant awarded by the 2017 T–AP initiative of the Trans–Atlantic Platform in Social Sciences and Humanities Research, as well as the support received in each country by the Economic and Social Research Council (ESRC, UK) (ES/R003890/1), the Foundation for Science and Technology (FCT, Portugal), and the Consejo Nacional de Ciencia y Tecnología (project 275015). Likewise, we would like to thank the Red Conacyt de Tecnologías Digitales para la Difusión del Patrimonio Cultural (project 294971), also supported by Conacyt.</p>
<ul>
<li id="acuna1982">Acuña, René. 1982–1988. _Relaciones Geográficas del siglo XVI_ , 10 vols. México: Universidad Nacional Autónoma de México. Instituto de Investigaciones Antropológicas.<a href="https://books.google.com/books/about/Relaciones_Geogr%C3%A1ficas_Del_Siglo_XVI.html?id=XuQ0834CgVAC">https://books.google.com/books/about/Relaciones_Geogr%C3%A1ficas_Del_Siglo_XVI.html?id=XuQ0834CgVAC</a>.
</li>
<li id="acuna-soto2004">Acuña–Soto, Rodolfo, David W. Stahle, Matthew D. Therrell, Richard D. Griffin, and Malcolm K. Cleaveland. 2004. “When half of the population died: The epidemic of hemorrhagic fevers of 1576 in Mexico” . _FEMS Microbiology Letters_ 240(1): 1–5. doi:<a href="10.1016/j.femsle.2004.09.011">10.1016/j.femsle.2004.09.011</a>.
</li>
<li id="afanadorpujol2015">Afanador Pujol, A. (2015). _The relación de Michoacán (1539-1541) and the politics of representation in colonial Mexico_ . University of Texas Press.<a href="https://doi.org/10.7560/771383">https://doi.org/10.7560/771383</a>.
</li>
<li id="alboreszarate2015">Albores Zarate, B. (Ed.). 2015. _Flor-flora: Su uso ritual en Mesoamérica_ . Toluca de Lerdo, Estado de México : Fondo Editorial Estado de México; El Colegio Mexiquense.
</li>
<li id="alpert-abrams2016">Alpert–Abrams, Hannah. 2016. “Machine reading the _Primeros Libros_ ” , _DHQ: Digital Humanities Quaterly_ 10(4).<a href="http://www.digitalhumanities.org/dhq/vol/10/4/000268/000268.html">http://www.digitalhumanities.org/dhq/vol/10/4/000268/000268.html</a>.
</li>
<li id="anayamonroy1960">Anaya Monroy, Fernando. 1960. “Presencia espiritual de la cultura náhuatl en la toponimia” . _Estudios de Cultura Náhuatl_ 2: 9–25.
</li>
<li id="ballesteros2005">Ballesteros García, Víctor Manuel. 2005. _La Pintura de la Relación de Zempoala de 1580_ . México: Universidad Autónoma del Estado de Hidalgo.
</li>
<li id="barlow1949">Barlow, Robert H. 1949. “Relación de Zempoala y su partido, 1580” . _Tlalocan. Revista de Fuentes para el Conocimiento de las Culturas Indígenas de México_ 3(1): 29-41.
</li>
<li id="bojanowski2017">Bojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. “Enriching Word Vectors with Subword Information.”  _Transactions of the Association for Computational Linguistics_ 5 (2017): 135-46.
</li>
<li id="borin2007">Borin, Lars, Dimitrios Kokkinakis, and Leif–Jöran Olsson. 2007. “Naming the past: Named entity and animacy recognition in 19th century Swedish literature” . In _Proceedings of the Workshop on Language Technology for Cultural Heritage Data (LaTeCH 2007)_ , pp. 1–8. Prague, Czech Republic: Association for Computational Linguistics.<a href="http://www.aclweb.org/anthology/W/W07/W07–0901.pdf">http://www.aclweb.org/anthology/W/W07/W07–0901.pdf</a>.
</li>
<li id="bravo-garvia2019">Bravo-García, Eva. 2019. _Las voces del contacto. Edición y estudio de Las Relaciones Geográficas de México (Siglo XVI)_ . Warsaw: University of Warsaw.
</li>
<li id="brand1960">Brand, Donald. 1960. _Coalcoman and Motines del Oro, an ex-Distrito of Michoacan, México_ . Austin: University of Texas, Institute of Latin American Studies.
</li>
<li id="brooke2015">Brooke, Julian, Adam Hammond, and Graeme Hirst. 2015. “GutenTag: An NLP–driven tool for digital humanities research in the project Gutenberg Corpus” . In _Proceedings of the North American Association for Computational Linguistics_ , pp. 1–6. Denver, Colorado.<a href="http://www.cs.toronto.edu/pub/gh/Brooke–etal–2015–CLfL.pdf">http://www.cs.toronto.edu/pub/gh/Brooke–etal–2015–CLfL.pdf</a>.
</li>
<li id="byrne2007">Byrne, Kate. 2007. “Nested named entity recognition in historical archive text” . In _International Conference on Semantic Computing (ICSC 2007)_ . Irvine, CA, USA: IEEE.<a href="https://ieeexplore.ieee.org/document/4338398">Doi:10.1109/ICSC.2007.107</a>.
</li>
<li id="cacereslorenzo2013">Cáceres Lorenzo, María Teresa. 2013. “Tipos de Relaciones Geográficas en el siglo XVI” . _Crítica Hispánica_ 35(1): 45-66.
</li>
<li id="cacereslorenzo2016">Cáceres Lorenzo, María Teresa. 2016. “Heteregeneidad léxica en las Relaciones Geográficas de Yucatán” , _Alpha. Revista de Artes, Letras y Filosofía_ , 42 (online)<a href="http://dx.doi.org/10.4067/S0718-22012016000100007">http://dx.doi.org/10.4067/S0718-22012016000100007</a>;<a href="https://scielo.conicyt.cl/scielo.php?script=sci_arttext&pid=S0718-22012016000100007">https://scielo.conicyt.cl/scielo.php?script=sci_arttext&pid=S0718-22012016000100007</a>.
</li>
<li id="chavezmejia2020">Chávez Mejía, M.C., L. White Olascoaga, S. Moctezuma Pérez, F. Herrera Tapia. 2020. “Practicas curativas y plantas medicinales: Un acercamiento a la etnomedicina de San Nicolás, México” . _Cuadernos Geográficos_ , 56(2): 26.<a href="http://search.ebscohost.com/login.aspx?direct=true&db=edb&AN=124569245&lang=es&site=eds-live">http://search.ebscohost.com/login.aspx?direct=true&db=edb&AN=124569245&lang=es&site=eds-live</a>.
</li>
<li id="cline1964">Cline, Howard F. 1964. The “Relaciones Geográficas of the Spanish Indies, 1577–1586” . _The Hispanic American Historical Review_ 44(3): 341–374.<a href="https://doi.org/10.2307/2511856">doi:10.2307/2511856</a>.
</li>
<li id="cline1972a">Cline, Howard F. 1972a. “Introductory notes on territorial divisions of Middle America” . In _Handbook of Middle American Indians, Volume 12: Guide to Ethnohistorical Sources, Part One_ , edited by Howard F. Cline, pp. 17–62. Austin: University of Texas Press.
</li>
<li id="cline1972b">Cline, Howard F. 1972b. “Ethnohistorical regions of Middle America” . In _Handbook of Middle American Indians, Volume 12: Guide to Ethnohistorical Sources, Part One_ , edited by Howard F. Cline, pp. 166–182. Austin: University of Texas Press.
</li>
<li id="cline1972c">Cline, Howard F. 1972c. “The Relaciones Geográficas of the Spanish Indies, 1577–1648” . In _Handbook of Middle American Indians, Volume 12: Guide to Ethnohistorical Sources, Part One_ , edited by Howard F. Cline, pp. 183–242. Austin: University of Texas Press.
</li>
<li id="cline1972d">Cline, Howard F. 1972d. “A census of the _Relaciones Geográficas_ of New Spain, 1579–1612” . In _Handbook of Middle American Indians, Volume 12: Guide to Ethnohistorical Sources, Part One_ , edited by Howard F. Cline, pp. 364–369. Austin: University of Texas Press.
</li>
<li id="cooper2011">Cooper, David, and Ian N Gregory. 2011. “Mapping the English Lake District: A literary GIS” . _Transactions of the Institute of British Geographers_ 36(1): 89–108.<a href="https://doi.org/10.1111/j.1475-5661.2010.00405.x">doi:10.1111/j.1475–5661.2010.00405.x</a>.
</li>
<li id="crane2006">Crane, Gregory and Alison Jones. 2006. “The challenge of Virginia Banks: An evaluation of named entity analysis in a 19th–century newspaper collection” . In _Proceedings of the 6th ACM/IEEE–CS Joint Conference on Digital Libraries (JCDL ‘06)_ , Chapel Hill, NC, USA: ACM Press.<a href="https://dl.acm.org/doi/10.1145/1141753.1141759">doi:10.1145/1141753.1141759</a>.
</li>
<li id="dahlgren1954">Dahlgren de Jordan, Barbro. 1954.La Mixteca: su cultura e historia prehispánicas. México: Universidad Nacional Autónoma de México.
</li>
<li id="delagarza1983">De la Garza, Mercedes (Ed.). 1983. _Relaciones histórico–geográficas de la gobernación de Yucatán: (Mérida, Valladolid y Tabasco)._ First edition, 2 vols. México: Universidad Nacional Autónoma de México.
</li>
<li id="delpaso1905">Del Paso y Troncoso, Francisco (Ed.). 1905. _Papeles de Nueva España_ . Segunda Serie: Geografía y Estadística, vols. 1, 3–7. Madrid: Sucesores de Rivadeneyra.
</li>
<li id="delgadolopez2010">Delgado López, Enrique. 2010. “Las Relaciones Geográficas como proyecto científico en los albores de la modernidad” . _Estudios Mesoamericanos_ 2(9): 97–106.
</li>
<li id="donaldson2015">Donaldson, Christopher, Ian N. Gregory, and Patricia Murrieta–Flores. 2015. “Mapping Wordsworthshire : A GIS study of literary tourism in Victorian Lakeland” . _Journal of Victorian Culture_ 20(3): 287–307.<a href="https://doi.org/10.1080/13555502.2015.1058089">doi:10.1080/13555502.2015.1058089</a>.
</li>
<li id="donaldson2017">Donaldson, Christopher, Ian N. Gregory, and Joanna E. Taylor. 2017. “Locating the beautiful, picturesque, sublime and majestic: Spatially analysing the application of aesthetic terminology in descriptions of the English Lake District” . _Journal of Historical Geography_ 56 (April): 43–60.<a href="https://doi.org/10.1016/j.jhg.2017.01.006">doi:10.1016/j.jhg.2017.01.006</a>.
</li>
<li id="ducke2008">Ducke, Benjamin and Peter C. Kroefges. 2008. “Layers of Perception” . _Proceedings of the 35th International Conference on Computer Applications and Quantitative Methods in Archaeology (CAA2007)_ , Berlin, Germany, April 2–6, edited by Axel Posluschny, Karsten Lambers, and Irmela Herzog, pp. 246-251. (Kolloquien zur Vor- und Frühgeschichte, Vol. 10). Bonn: Dr. Rudolf Habelt GmbH.<a href="https://proceedings.caaconference.org/paper/78_ducke_kroefges_caa2007/">https://proceedings.caaconference.org/paper/78_ducke_kroefges_caa2007/</a>.
</li>
<li id="edwards1969">Edwards, Clinton R. 1969. “Mapping by questionnaire: An early Spanish attempt to determine New World geographic positions” . _Imago Mundi_ 23: 17–28.
</li>
<li id="ehrmann2016">Ehrmann, Maud, Giovanni Colavizza, Yannick Rochat, and Frédéric Kaplan. 2016. “Diachronic evaluation of NER systems on old newspapers” . In _Proceedings of the 13th Conference on Natural Language Processing (KONVENS 2016))_ , edited by Stephanie Dipper, Friedrich Neubarth, and Heike Zinsmeister, pp. 97–107. Bochum, Germany: Bochumer Linguistische Arbeitsberichte.<a href="http://infoscience.epfl.ch/record/221391">http://infoscience.epfl.ch/record/221391</a>.
</li>
<li id="eynard2012">Eynard, Davide, Matteo Matteucci, and Fabio Marfia. 2012. “A modular framework to learn seed ontologies from text” . In _Semi-automatic ontology development processes and resources_ , edited by Maria Teresa Pazienza and Armando Stellato, pp. 22-47. Hershey, PA: IGI Publishing.
</li>
<li id="favilavazquez2019">Favila Vázquez, Mariana. 2019. “La navegación prehispánica: Un sistema de conectividad del paisaje mesoamericano. Modelo de interacción entre la costa del Pacífico y el Altiplano Central (Postclásico Tardío-Siglo XVI)” . PhD Thesis, México: Universidad Nacional Autónoma de México. Facultada de Filosofía y Letras, Instituto de Investigaciones Filológicas. Programa de Maestría y Doctorado en Estudios Mesoamericanos.
</li>
<li id="fernandez2006">Fernández Christlieb, Federico and Gustavo Garza Merodio. 2006. “La pintura de la Relación Geográfica de Metztitlán, 1579” . _Secuencia. Revista de historia y ciencias sociales_ 66: 160-186.
</li>
<li id="garciacubas1888">García Cubas, Antonio. 1888-1891. _Diccionario geográfico, histórico y biográfico de los Estados Unidos Mexicanos_ . 2 vols. México: Antigua Impr. de Murguía.<a href="https://catalog.hathitrust.org/Record/010416157">https://catalog.hathitrust.org/Record/010416157</a>.
</li>
<li id="firth1957">Firth, J.R. _A synopsis of linguistic theory Studies in linguistic analysis_ . Oxford: Blackwell (1957).
</li>
<li id="gerhard1972a">Gerhard, Peter. 1972a. _A Guide to the historical geography of New Spain_ . First edition. Cambridge, UK: Cambridge University Press.
</li>
<li id="gerhard1972b">Gerhard, Peter. 1972b. “Colonial New Spain, 1519–1786: Historical notes on the evolution of minor political jurisdictions” . In _Handbook of Middle American Indians, Volume 12: Guide to Ethnohistorical Sources, Part One_ , edited by Howard F. Cline, pp. 63–137. Austin: University of Texas Press.
</li>
<li id="gerhard1991">Gerhard, Peter. 1991. _La frontera sureste de la Nueva España_ . México: Universidad Nacional Autónoma de México.
</li>
<li id="gibson1967">Gibson, Charles. 1967. _Tlaxcala in the sixteenth century_ . California: Stanford University Press.
</li>
<li id="goldberg2017">Goldberg, Yoav. 2017. “Neural network methods for natural language processing” . _Synthesis Lectures on Human Language Technologies_ 10(1): 1-309.<a href="https://doi.org/10.2200/S00762ED1V01Y201703HLT037">doi:10.2200/S00762ED1V01Y201703HLT037</a>.
</li>
<li id="gómez2004">Gómez, Raúl. 2004. _Los Virreinatos americanos_ . Madrid: Dastin Export.
</li>
<li id="gregory2015">Gregory, Ian, Christopher E. Donaldson, Patricia Murrieta–Flores, and Paul E. Rayson. 2015. “Geoparsing, GIS, and textual analysis: Current developments in spatial humanities research” . _International Journal of Humanities and Arts Computing_ 9(1): 1–14.<a href="https://www.euppublishing.com/doi/abs/10.3366/ijhac.2015.0135">doi:10.3366/ijhac.2015.0135</a>.
</li>
<li id="gregory2018">Gregory, Ian Norman, Christopher E. Donaldson, Andrew Hardie, and Paul E. Rayson. 2018. “Modelling Space in Historical Texts” . In _The shape of data in Digital Humanities: Modeling texts and text–based resources_ , edited by Julia Flanders and Fotis Jannidis. London: Routledge.<a href="http://eprints.lancs.ac.uk/81427/">http://eprints.lancs.ac.uk/81427/</a>.
</li>
<li id="grover2008">Grover, C., S. Givon, R. Tobin, and J. Ball. 2008. “Named entity recognition for digitised historical texts” . In _Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08)_ . Paris: ELRA.
</li>
<li id="gruzinski1991">Gruzinski, Serge. 1991. _La colonización de lo imaginario. Sociedades indígenas y occidentalización en el México español. Siglos XVI-XVIII_ . México: Fondo de Cultura Económica (original in French, _La colonization de l´imaginaire, Sociètés indigènes et occidentalisation dans le Mexique espagnol XVI-XVIII e siècle_ . Paris: Editions Gallimard, 1988).
</li>
<li id="guzman1987">Guzmán Betancourt, Ignacio (Ed.). 1987. _De toponimia y topónimos. Contribuciones al estudio de los nombres de lugar provenientes de lenguas indígenas de México_ . México: Instituto Nacional de Antropología e Historia.
</li>
<li id="guzman1989">Guzmán Betancourt, Ignacio. 1989. _Toponimia mexicana. Bibliografía general_ . México: Instituto Nacional de Antropología e Historia.
</li>
<li id="guzman1998">Guzmán Betancourt, Ignacio, ed. 1998. _Los nombres de México_ . México: Secretaría de Relaciones Exteriores.
</li>
<li id="halterman2017">Halterman, Andrew. 2017. “Mordecai: Full text geoparsing and event geocoding” . _The Journal of Open Source Software,_ 2 (January): 91. doi:10.21105/joss.00091.
</li>
<li id="harvey1972">Harvey, H. R. 1972. “The Relaciones Geográficas, 1579-1586: Native Languages” . In _Handbook of Middle American Indians, Volume 12: Guide to Ethnohistorical Sources, Part One_ , edited by Howard F. Cline, pp. 279–323. Austin: University of Texas Press.
</li>
<li id="hersch1999">Hersch, Martinez, P. (1999). “De hierbas y herbolarios en el Mexico actual” . _Arqueología Mexicana_ , 39:60-65.
</li>
<li id="hill2000">Hill, Linda L. 2000. “Core elements of digital gazetteers: Placenames, categories, and footprints” . In _Research and advanced technology for digital libraries_ , pp. 280–290. Lecture Notes in Computer Science 1923. Berlin: Springer.<a href="https://link.springer.com/chapter/10.1007/3-540-45268-0_26">doi:10.1007/3–540–45268–0_26</a>.
</li>
<li id="hill1999">Hill, Linda, James Frew, and Qi Zheng. 1999. “Geographic names: The implementation of a gazetteer in a georeferenced digital library” . _D–Lib Magazine_ 5(1).<a href="https://doi.org/10.1045/january99-hill">doi:10.1045/january99–hill</a>.
</li>
<li id="lefebvre2017">Lefebvre, Karin and Carlos Paredes Martínez, eds. 2017. _La memoria de los nombres: la toponimia en la conformación histórica del territorio. De Mesoamérica a México_ . Morelia, Michoacán: Universidad Nacional Autónoma de México, Centro de Investigaciones en Geografía Ambiental.<a href="http://www.h–mexico.unam.mx/node/19835">http://www.h–mexico.unam.mx/node/19835</a>.
</li>
<li id="liceras-garrido2019">Liceras-Garrido, Raquel, Mariana Favila-Vázquez, Katherine Bellamy, Patricia Murrieta-Flores, Diego Jiménez-Badillo, et al. 2019. “Digital Approaches to Historical Archaeology: Exploring the Geographies of 16th Century New Spain” . _Open Access Journal of Archaeology & Anthropology_ 2(1). OAJAA.MS.ID.000526.<a href="http://dx.doi.org/10.33552/OAJAA.2019.02.000526">DOI: 10.33552/OAJAA.2019.02.000526</a>.
</li>
<li id="leonportilla2002">León Portilla, Miguel. 2002. “El destino de las lenguas indígenas de México” . In _El despertar de nuestras lenguas (Queman tlachixque totlahtolhuan)_ , edited by Natalio Hernández. México: Editorial Diana, Fondo Editorial de las Culturas Indígenas.
</li>
<li id="lopezdevelasco1894">López de Velasco, Juan. 1894. _Geografía y descripción universal de las Indias_ . Madrid: D. Justo Zaragoza: Establecimiento tipográfico de Fortanet.<a href="http://www.cervantesvirtual.com/obra–visor/geografa–y–descripcin–universal–de–las–indias–recopilada–por–el–cosmgrafocronista–juan–lpez–de–velasco–desde–el–ao–de–1571–al–de–1574–publicada–por–d–justo–zaragoza–0/html/">http://www.cervantesvirtual.com/obra–visor/geografa–y–descripcin–universal–de–las–indias–recopilada–por–el–cosmgrafocronista–juan–lpez–de–velasco–desde–el–ao–de–1571–al–de–1574–publicada–por–d–justo–zaragoza–0/html/</a>.
</li>
<li id="mager2018">Mager, Manuel, Ximena Gutierrez–Vasques, Gerardo Sierra, and Ivan Meza. 2018. “Challenges of language technologies for the indigenous languages of the Americas” . In _Proceedings of the 27th International Conference on Computational Linguistics (COLING 2018)._ <a href="https://arxiv.org/abs/1806.04291">https://arxiv.org/abs/1806.04291</a>.
</li>
<li id="márquez1998">Márquez, Ofelia, and Lilian Ramos Navarro Wold. 1998. _Compilation of colonial Spanish terms and document related phrases_ . Midway City, CA: SHAR Press (Society of Historical and Ancestral Research).<a href="http://www.somosprimos.com/spanishterms/spanishterms.htm">http://www.somosprimos.com/spanishterms/spanishterms.htm</a>.
</li>
<li id="martins2017">Martins, Bruno, and Patricia Murrieta–Flores. 2017. “GeoHumanities 2017 workshop report” . In _Proceedings of the 1st ACM SIGSPATIAL Workshop on Geospatial Humanities_ , Redondo Beach, California, USA.
</li>
<li id="morato-moreno2017">Morato-Moreno, Manuel. 2017. “The Map of Tlacotalpa by Francisco Gali, 1580: An early example of a local coastal chart in Spanish America” . _The Cartographic Journal_ 55(1): 3-15.
</li>
<li id="morenotoscano1968">Moreno Toscano, Alejandra. 1968. _Geografía económica de México (siglo XVI)_ . México: El Colegio de México.
</li>
<li id="mundy1996">Mundy, Barbara. 1996. _The mapping of New Spain: Indigenous cartography and the maps of the Relaciones Geograficas_ . Chicago: University of Chicago Press.
</li>
<li id="mundy2013">Mundy, Barbara E. 2013. “Mapping Babel: A 16th Century Indigenous Map from Mexico” . _The Appendix: A New Journal of Narrative & Experimental History_ . Online publication available at:<a href="http://theappendix.net/issues/2013/10/mapping-babel-a-sixteenth-century-indigenous-map-from-mexico">http://theappendix.net/issues/2013/10/mapping-babel-a-sixteenth-century-indigenous-map-from-mexico</a>.
</li>
<li id="mundy2014">Mundy, Barbara E. 2014. “Place–names in Mexico–Tenochtitlan” . _Ethnohistory_ 61 (2): 329–355.<a href="https://doi.org/10.1215/00141801-2414190">doi:10.1215/00141801–2414190</a>.
</li>
<li id="muntzel2010">Muntzel, Martha C., and María Elena Villegas Molina, (Eds.). 2010. _Itinerario toponímico de México: Ignacio Guzmán Betancourt_ . México: Instituto Nacional de Antropología e Historia.
</li>
<li id="murrieta-flores2015">Murrieta–Flores, Patricia, Alistair Baron, Ian Gregory, Andrew Hardie, and Paul Rayson. 2015. “Automatically analyzing large texts in a GIS environment: The Registrar General’s Reports and cholera in the 19th century” . _Transactions in GIS_ 19(2): 296–320.<a href="https://doi.org/10.1111/tgis.12106">doi:10.1111/tgis.12106</a>.
</li>
<li id="murrieta-flores2017a">Murrieta–Flores, Patricia, Christopher Donaldson, and Ian N Gregory. 2017. “GIS and literary history: Advancing digital humanities research through the spatial analysis of eighteenth–century travel writing” . _Digital Humanities Quarterly_ 11(1).<a href="http://www.digitalhumanities.org/dhq/vol/11/1/000283/000283.html">http://www.digitalhumanities.org/dhq/vol/11/1/000283/000283.html</a>.
</li>
<li id="murrieta-flores2017b">Murrieta–Flores, Patricia, and Ian N. Gregory. 2017. “Cruzando Fronteras en humanidades digitales: Análisis geográfico de textos de interés histórico y arqueológico con sistemas de información geográfica” . In _Arqueología computacional. Nuevos enfoques para la documentación, análisis y difusión del patrimonio cultural_ , edited by Diego Jiménez–Badillo, pp. 199–212. México: Instituto Nacional de Antropología e Historia.
</li>
<li id="nick2017">Nick, I. M., and Jan Tent. 2017. “Guest editorial on indigenous names and toponyms” . _Names, A Journal of Onomastics_ 65(4): 190–193.
</li>
<li id="nuttall1926">Nuttall, Zellia, (Ed.). 1926.Official reports on the towns of Tequizistlan, Tepechpan, Acolman, and San Juan Teotihuacan, sent by Francisco de Castañeda to His Majesty, Philip II, and the Council of the Indies, in 1580. _Papers of the Peabody Museum of Archaeology and Ethnology_ , 11(2): 45–84. Cambridge, Massachusetts: Harvard University.
</li>
<li id="pedrote2019">Pedrote Romero, Antonio and Eva Bravo-García. 2019. “La autoría de las Relaciones Geográficas mexicanas: Las voces náhuatl a través de los redactores” . _Anuario de Estudios Americanos, 76(1): 123-153._ Doi: <a href="https://doi.org/10.3989/aeamer.2019.1.06">10.3989/aeamer.2019.1.06</a>.
</li>
<li id="penafiel1897">Peñafiel, Antonio. 1897. _Nomenclatura geográfica de México, etimologías de los nombres de lugar correspondientes a los principales idiomas que se hablan en la República_ . 3 vols. México: Oficina tipográfica de la Secretaria de Fomento.<a href="http://archive.org/details/nomenclaturageog00pe">http://archive.org/details/nomenclaturageog00pe</a>.
</li>
<li id="porter2015">Porter, Catherine, Paul Atkinson, and Ian Gregory. 2015. “Geographical Text Analysis: A new approach to understanding nineteenth–century mortality” . _Health & Place,_ 36 (November): 25–34. doi:10.1016/j.healthplace.2015.08.010.
</li>
<li id="robelo1897">Robelo, Cecilio Agustín. 1897. _Nombres geográficos indígenas del estado de Morelos. Estudio crítico de varias obras de Toponomatología nahoa_ . Cuernavaca: Luis G. Miranda, impresor.<a href="http://archive.org/details/nombresgeogrfi00robeuoft">http://archive.org/details/nombresgeogrfi00robeuoft</a>.
</li>
<li id="robelo1900">Robelo, Cecilio Agustín. 1900. _Nombres Geográficos Indígenas Del Estado de México: Estudio Crítico Etimológico_ . Cuernavaca: Luis G. Miranda impresor.<a href="http://cd.dgb.uanl.mx/handle/201504211/14251">http://cd.dgb.uanl.mx//handle/201504211/14251</a>.
</li>
<li id="robelo1902a">Robelo, Cecilio Agustín. 1902a. _Nombres geográficos mexicanos del estado de Veracruz: Estudio critico etimológico_ . Cuernavaca: Luis G. Miranda impresor.
</li>
<li id="robelo1902b">Robelo, Cecilio Agustín. 1902b. _Toponimia tarasco-hispano-nahoa_ . Cuernavaca: Impr. de J. D. Rojas.<a href="http://archive.org/details/toponimiatarasc00robegoog">http://archive.org/details/toponimiatarasc00robegoog</a>.
</li>
<li id="robelo1904">Robelo, Cecilio Agustín. 1904. _Diccionario de aztequismos, ó sea, catalogo de las palabras del idioma nahuatl, azteca ó mexicano, introducidas al idioma castellano bajo diversas formas._ Cuernavaca: Printed by the author.<a href="https://catalog.hathitrust.org/Record/009024985">https://catalog.hathitrust.org/Record/009024985</a>.
</li>
<li id="robelo1905">Robelo, Cecilio Agustín. 1905. _Diccionario de mitología náhuatl_ . México: Ediciones Fuente Cultural; Librería Navarro.<a href="https://catalog.hathitrust.org/Record/001940449">https://catalog.hathitrust.org/Record/001940449</a>.
</li>
<li id="robertson1972">Robertson, Donald. 1972. “The pinturas (maps) of the _Relaciones Geográficas_ with a catalog” . In _Handbook of Middle American Indians, Volume 12: Guide to Ethnohistorical Sources, Part One_ , edited by Howard F. Cline, pp. 243–278. Austin: University of Texas Press.
</li>
<li id="sanchez-martinez2013">Sánchez–Martínez, Felipe, Isabel Martínez–Sempere, Xavier Ivars–Ribes, and Rafael C. Carrasco. 2013. “An Open diachronic corpus of historical Spanish: Annotation criteria and automatic modernisation of spelling” . _arXiv:1306.3692 [cs]_ , June.<a href="http://arxiv.org/abs/1306.3692">http://arxiv.org/abs/1306.3692</a>.
</li>
<li id="santos2015">Santos, João, Ivo Anastácio, and Bruno Martins. 2015. “Using machine learning methods for disambiguating place references in textual documents” . _GeoJournal_ 80(3): 375–392.<a href="https://www.jstor.org/stable/24432625">doi:10.1007/s10708–014–9553–y</a>.
</li>
<li id="snatos2017">Santos, Rui, Patricia Murrieta–Flores, and Bruno Martins. 2017. “Learning to combine multiple string similarity metrics for effective toponym matching” . _International Journal of Digital Earth_ .<a href="https://doi.org/10.1080/17538947.2017.1371253">doi:10.1080/17538947.2017.1371253</a>.
</li>
<li id="santos2018">Santos, Rui, Patricia Murrieta–Flores, Pável Calado, and Bruno Martins. 2018. “Toponym matching through deep neural networks” . _International Journal of Geographical Information Science_ 32(2): 324–348.<a href="https://doi.org/10.1080/13658816.2017.1390119">doi:10.1080/13658816.2017.1390119</a>.
</li>
<li id="sprugnoli2017">Sprugnoli, Rachele, Giovanni Moretti, Bruno Kessler, Sara Tonelli, and Stefano Menini. 2017. “Fifty years of European history through the lens of Computational Linguistics: The De Gasperi Project” . _Italian Journal of Computational Linguistics_ 2(2): 89–100.
</li>
<li id="starr1920">Starr, Frederick. 1920. _Aztec place-names, their meaning and mode of composition, selected from the Spanish of Agustin de la Rosa, Antonio Peñafiel and Cecilio A. Robelo_ . Chicago: Privately printed by the author.<a href="https://catalog.hathitrust.org/Record/001360976">https://catalog.hathitrust.org/Record/001360976</a>.
</li>
<li id="tanck2005">Tanck de Estrada, Dorothy. 2005. _Atlas ilustrado de los pueblos de indios_ . México: El Colegio de México, El Colegio Mexiquense, Comisión Nacional para el Desarrollo de los Pueblos Indígenas, and Fomento Cultural Banamex.
</li>
<li id="taule2008">Taulé, Mariona, M. Antònia Martí, and Marta Recasens. 2008. “AnCora: Multilevel annotated corpora for Catalan and Spanish” . _LREC 2008_ .<a href="https://aclanthology.info/papers/L08–1222/l08–1222">https://aclanthology.info/papers/L08–1222/l08–1222</a>.
</li>
<li id="taylor2017">Taylor, Joanna E., Ian N. Gregory, and Christopher E. Donaldson. 2017. “Combining close and distant reading: A multiscalar analysis of the English Lake District’s historical soundscape” . _International Journal of Humanities and Arts Computing_ , 12(2): 163-182.<a href="http://eprints.lancs.ac.uk/89167/">http://eprints.lancs.ac.uk/89167/</a>.
</li>
<li id="vanhooland2015">Van Hooland, S., M. de Wilde, R. Verborgh, T. Steiner, and R. Van de Walle. 2015. “Exploring entity recognition and disambiguation for cultural heritage collections” . _Digital Scholarship in the Humanities_ 30(2): 262–279. doi:10.1093/llc/fqt067.
</li>
<li id="won2018">Won, Miguel, Patricia Murrieta–Flores, and Bruno Martins. 2018. “Ensemble named entity recognition (NER): Evaluating NER Tools in the identification of place names in historical corpora” . _Frontiers in Digital Humanities_ 5.<a href="https://doi.org/10.3389/fdigh.2018.00002">doi:10.3389/fdigh.2018.00002</a>.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>This project operates thanks to a grant received from the 2017 “Digging into Data” initiative of the Trans–Atlantic Platform for Social Sciences and Humanities Research (T-AP). T-AP is a consortium supported by research institutions in 16 countries, among them the Economic and Social Research Council (ESRC, UK), the Foundation for Science and Technology (FCT, Portugal), and the National Council of Science and Technology (CONACyT, México). This project is conducted by three teams of historians, archaeologists, geographers, linguists and computer scientists from the following institutions: The Digital Humanities Hub and the History Department of Lancaster University, UK; The Instituto de Engenharia de Sistemas e Computadores, Investigação e Desenvolvimento em Lisboa, INESC–ID, University of Lisbon, Portugal; and the Instituto Nacional de Antropología e Historia in México. The website of the project can be accessed at:<a href="http://www.lancaster.ac.uk/digging-ecm">http://www.lancaster.ac.uk/digging-ecm</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>NLP techniques have often been applied to annotated texts written in modern English, and a few have been tried with historical documents composed in earlier forms of speech in several languages<a class="footnote-ref" href="#borin2007"> [borin2007] </a><a class="footnote-ref" href="#brooke2015"> [brooke2015] </a><a class="footnote-ref" href="#byrne2007"> [byrne2007] </a><a class="footnote-ref" href="#crane2006"> [crane2006] </a><a class="footnote-ref" href="#ehrmann2016"> [ehrmann2016] </a><a class="footnote-ref" href="#grover2008"> [grover2008] </a><a class="footnote-ref" href="#sprugnoli2017"> [sprugnoli2017] </a><a class="footnote-ref" href="#vanhooland2015"> [vanhooland2015] </a><a class="footnote-ref" href="#won2018"> [won2018] </a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>To give a complete picture of the enquiry, we reproduce the questions list in Appendix 1. The questionnaire in Spanish can also be found in<a href="#delagarza1983">De la Garza (1983: 7-12)</a>and<a href="#acuna1982">Acuña (1982-1988, vol. 1: 73-78)</a>, as well as in English publications by<a href="#nutall1926">Nutall (1926)</a>,<a href="#cline1964">Cline (1964,</a><a href="#cline1972a">1972c: 234-237)</a>,<a href="#mundy1996">Mundy (1996: 227–230)</a>, and<a href="#bravo-garcia2018">Bravo-García (2018: 417-422)</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>The census of these RGs published by<a href="#cline1964">Cline (1964</a>,<a href="#cline1972d">1972d</a>) and updated by<a href="#acuna1982">Acuña (1982–1988)</a>enumerates 34 RGs from Antequera; 17 from Michoacán; 15 from Tlaxcala; 54 from Yucatán; 2 from Guatemala; 34 from Mexico and 12 from Nueva Galicia (i.e. Guadalajara), though<a href="#cline1972d">Cline (1972d)</a>counts only 33 from Mexico. The collection is spread across four repositories: 80 documents are in the Archivo General de Indias in Seville; 46 in the Real Academia de la Historia in Madrid; 41 in the Latin American Collection of the Benson Library, University of Texas; and one in the Glasgow University Library. Two handmade transcriptions of the RGs, made by Joaquín García Icazbalceta, are now in the National Library of Mexico City<a class="footnote-ref" href="#cline1964"> [cline1964] </a><a class="footnote-ref" href="#acuna1982"> [acuna1982] </a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>The latest comprehensive analysis of these maps is by<a href="#mundy1996">Mundy (1996)</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>For instance, Antequera is now Oaxaca.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>In one example, sixteenth–century Cempoala (Hidalgo) moved from a hill to a valley to guarantee access to water, which caused severe alterations on its limits.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Tetlapayac, for instance, is the modern Santiago Teltlapayac.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Quauhyocan is also written as Quacyocan, for example.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>For example, ancient Quahnahuac is modern Cuernavaca.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Tetela, for instance, refers both to a town in modern Morelos and to a settlement in Puebla, and towns called Atlatlauhca can be found both in Morelos — origin of an RG — and Oaxaca.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p><a href="http://www.cdi.gob.mx/localidades2010-gobmx/">http://www.cdi.gob.mx/localidades2010-gobmx/</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p><a href="http://registropublico.inah.gob.mx/index.php">http://registropublico.inah.gob.mx/index.php</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p><a href="http://www.geonames.org/">http://www.geonames.org/</a>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p><a href="http://www.getty.edu/research/tools/vocabularies/tgn/index.html">http://www.getty.edu/research/tools/vocabularies/tgn/index.html</a>&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p><a href="http://www.getty.edu/research/tools/vocabularies/tgn/">http://www.getty.edu/research/tools/vocabularies/tgn/</a>&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p><a href="http://whgazetteer.org">http://whgazetteer.org</a>&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p><a href="www.tagtog.net/">www.tagtog.net</a>&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p><a href="https://www.corpusdelespanol.org">https://www.corpusdelespanol.org</a>&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>The premise of distance reading is that there are simply too many documents for anyone to read and study simultaneously and within the limits of the human brain and under the time imposed by contemporary academic schedules.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Reproduced from Mundy, Barbara. 1996. The mapping of New Spain. Indigenous cartography and the maps of the Relaciones Geográficas, Appendix B, pp. 227-230. Chicago: The University of Chicago Press.## Bibliography&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Introduction: Digital Humanities &amp; Colonial Latin American Studies</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000531/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000531/</id><author><name>Hannah Alpert-Abrams</name></author><author><name>Clayton McCarl</name></author><published>2020-12-15T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p><em>For Linda M. Rodriguez</em></p>
<p>This special issue of <em>Digital Humanities Quarterly</em> examines intersections between colonial Latin American studies (CLAS)<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> and digital humanities (DH) theory and practice. The essays collected here touch on matters that pertain to numerous fields, including anthropology, archaeology, art history, history, linguistics, and literature. By doing so in a digital context, they blur the lines between many of these fields, and point to several major themes that predominate across digital humanities scholarship today.</p>
<p>The project was motivated by the recognition of three realities. First, digital practice has become fundamental to how scholarly work is conducted in the study of the colonial world. Second, scholarship being carried out today demonstrates that digital methods have the potential to significantly enhance the field going forward. Third, in order to realize that potential, the diverse community of practitioners engaged in such work needs to better articulate how digital scholarship is conceptualized and conducted within CLAS.</p>
<p>In this introduction, we briefly provide context for understanding the two areas of inquiry at the center of this discussion. To do so, we first consider in broad strokes the central concerns of each, proposing ways we believe the two overlap in terms of objectives and methods. We then step back to examine the evolution of digital work within CLAS, arguing that such scholarship has followed a different path than in digital humanities communities based in the United States and Europe. We propose that legacies of colonialism have shaped this development by obliging scholars to confront material realities and theoretical problems that are often distinct from those that drive digital humanities practice elsewhere.</p>
<p>Working from this premise, we then suggest parameters for identifying a set of tendencies that can define the field we term <em>digital colonial Latin American studies</em> (DCLAS). To do so, we analyze trends in digital scholarship within the field, examining, in particular, how those ideas and concerns inform the articles in this special collection. We conclude by reflecting on the challenges that the broader community of scholars who work on colonial Latin America must face before being able to more fully harness digital methods to transform research and teaching about the colonial world.</p>
<h2 id="two-parallel-overlapping-fields">Two parallel, overlapping fields</h2>
<p>This project brings together two areas of study that are both broadly and capaciously defined. We offer our working definitions here with the purpose of better orienting readers towards the content of this special issue.</p>
<p>Defining DH in precise terms has long presented a challenge. Certainly, there is a sense in which we are all, as researchers and teachers who use computers, participants in DH, whether we are conducting our research through online databases and search engines, composing scholarly monographs using word processing software, or teaching with digital images or remote learning technologies.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> However, for many scholars, and for the purposes of this special issue, this work becomes “digital humanities” when the critical and theoretical apparatus surrounding research, teaching, and publication — which already encompasses disciplinary and cross-disciplinary frameworks — extends to the use of digital technologies.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
<p>Even calling DH a “field” is problematic, with many asserting that it is better understood as a collection of scholarly tendencies than as clearly defined areas of inquiry. Much work within the digital humanities consists of reflection on those tendencies, and in the sense of such scholarship, DH does exist as a category with its own boundaries. Beyond such work, however, DH is, to a large extent, something that must be done <em>within</em> other scholarly areas. Put another way, DH is a space in which other scholarly areas can be carried out.</p>
<p>One basic defining tension within DH in recent years has been a struggle for diversity and inclusion. DH as a field of study has been marked by the predominance of European and U.S.-based institutions, scholars, and languages. Uneven access to digital technologies has contributed to this outcome, but other factors are also involved, such as differing levels of institutional support and access to the financing needed to support large-scale DH endeavors. In part to counter this tendency, the global and multilingual movements within DH have worked to make the field more expansive and diverse by actively engaging with questions of access and equity, and by drawing on critical frameworks including feminist and decolonial studies<a class="footnote-ref" href="#burns2020"> [burns2020] </a><a class="footnote-ref" href="#risam2018"> [risam2018] </a>.</p>
<p>Latin America is one of the areas that traditionally has been underrepresented within DH. It is a vast and diverse region in geographical, linguistic, cultural, religious, racial and ethnic terms, as well as in other ways. Scholars of Latin America carry out their work within disciplinary areas across the humanities and social sciences, but many also identify with the broad interdisciplinary field known as Latin American studies (LAS), whose presence is most visibly marked each year by the international congress of the Latin American Studies Association.</p>
<p>CLAS can be understood, if imperfectly, as a chronologically demarcated subfield of LAS. While most scholarly activity within LAS today is concerned with the twentieth and twenty-first centuries, CLAS focuses on the lesser studied period that spans from the arrival of European settlers at various points starting in the fifteenth century to the disruption of European colonial rule in the late eighteenth and early nineteenth centuries. CLAS is also set apart by its theoretical and methodological approaches. CLAS shares certain characteristics with LAS more broadly — such as an emphasis on alterity, inequality, and the vindication of historical injustices — and scholars in the field, as in LAS more broadly, engage with interdisciplinary areas including ethnic studies, Indigenous studies, African diasporic studies, and post-colonial and decolonial studies. At the same time, CLAS does so in the context of different historical and cultural realities, working often from distinct types of evidence. Like scholars of the Early Modern period elsewhere, those who work in CLAS rely on primary sources that include notarial records, printed books, correspondence, sacred objects, works of art, artifacts, and archaeological data.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
<p>Brought together, DH and CLAS represent two areas of scholarly practice that are, in many ways, highly compatible. Both are fundamentally and self-consciously interdisciplinary, thriving on the interaction of scholars across traditional boundaries. Both embrace broad possibilities for engaging with and understanding textual and visual material, as well as historical and geographical processes. DH, like CLAS, places emphasis on rethinking dynamics of power, dismantling outdated stereotypes, and decolonizing knowledge. Important currents in both CLAS and DH have been concerned with the ownership and preservation of cultural heritage, and the accessibility of such material to both academic and general audiences. Scholars in CLAS, as in DH, recognize the need for cross-institutional initiatives and partnerships between researchers, archives, and others.</p>
<p>In what follows, we argue that DH is a particularly propitious space in which scholars of the colonial period can operate, due to the inherent compatibilities we identify here. The experimental nature of digital humanities research can free scholars of the colonial world to formulate new types of questions, and more fully realize the goals of interdisciplinarity and theoretical innovation that underlie the field. Promoting and supporting digital work within the study of the colonial world can also allow us to draw in new types of scholars who can renovate and re-energize the field in ways that we may not be able to envision.</p>
<h2 id="the-evolution-of-digital-approaches-within-colonial-latin-american-studies">The evolution of digital approaches within colonial Latin American studies</h2>
<p>The digital humanities as practiced within CLAS have followed a unique evolution. In the United States, Canada, and Europe, among other places, DH is generally understood to have emerged out of corpus linguistics, with early practitioners focused on the application of computer technology to conduct systematic analysis of textual material<a class="footnote-ref" href="#jacob2020"> [jacob2020] </a><a class="footnote-ref" href="#trettien2020"> [trettien2020] </a>.</p>
<p>In Latin America, in contrast, the origins of much of today’s digital practice can be traced to the facsimiles, scholarly editions, and recovery projects produced in the region in the nineteenth and twentieth centuries. As Mercedes Salómon Salazar references in this special issue, one consequence of colonial rule in the Americas has been the broad dispersal of the primary sources of colonial and pre-Columbian history, from Indigenous texts and works of art to notarial records and printed books. In the wake of independence from European colonial rule, gaining and sharing access to these records became a task of primary importance for scholars based in the Americas<a class="footnote-ref" href="#zamora2004"> [zamora2004] </a><a class="footnote-ref" href="#alpert2017"> [alpert2017] </a>.</p>
<p>This led to a proliferation of manual transcriptions, printed editions, photo-reproductions, plaster replicas, dictionaries, and bibliographies, many produced by and for researchers in the Americas and the Caribbean<a class="footnote-ref" href="#bueno2018"> [bueno2018] </a><a class="footnote-ref" href="#murrieta2020"> [murrieta2020] </a>. These projects were often developed, at great personal expense, with the express intent of correcting for the colonial silencing of the historical record by providing local access to cultural heritage, or in the words of Christina Bueno, as part of “el esfuerzo por fabricar una historia patria en el gran proceso de construcción de la nación” <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> <a class="footnote-ref" href="#bueno2018"> [bueno2018] </a>. They drew on new technologies, from plaster casts to photostats and printing presses, to achieve these goals<a class="footnote-ref" href="#mundy1996"> [mundy1996] </a>.</p>
<p>The spread of digital technology has accelerated these processes, with consequences for how CLAS is practiced. Projects that were made digital in the 1990s and the early 2000s, such as the <em>Vistas</em> project, the digital edition of Guaman Poma de Ayala’s <em>Nueva corónica y buen gobierno</em> (2001), and <em>Slave Voyages</em> (formerly the <em>Trans-Atlantic and Intra-American Slave Trade Database</em> ), all seek to broaden access to historical records and works of art that have been widely dispersed or historically undervalued, while building the scholarly apparatus that enables students and a general public to make meaning out of difficult texts and objects. These projects also point to new challenges introduced by the digital age, including the uneven distribution of access to digital resources across the Americas, the dominance of English and the United States in DH, the undervaluing of digital work at academic institutions, and the difficulty of sustaining digital projects for the long term.</p>
<p>Many of these early projects started on paper or began off-line. Rolena Adorno’s edition of Guaman Poma began as a hand transcription in 1977 and appeared first as a printed volume in 1987, while <em>Slave Voyages</em> originated as a series of databases designed by individual scholars in the 1960s, and <em>Vistas</em> was first made available on CDRom in 2000<a class="footnote-ref" href="#adorno2006"> [adorno2006] </a><a class="footnote-ref" href="#mundy2017"> [mundy2017] </a>. The traces of that earlier time, and those earlier technologies, are still visible in these projects: in their theoretical frameworks, their thematic organization, their encoding schemas, their use of language, and their interface design. Most visibly, among these early efforts we tend to find projects that are not designed for accessibility or for smartphone use, and that were created by scholars in Europe and the United States without the active participation of Latin American, Black, or Indigenous communities.</p>
<p>Thanks to the visionary work of historians of the African diaspora based in the U.S., Europe, Latin America, and the Caribbean, as well substantial funding from the National Endowment for the Humanities, <em>Slave Voyages</em> has been able to reinvent itself in recent years as a “digital memorial” to the Africans whose forced labor built our nations.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> This reinvention follows the lead of projects that were born digital in the last two decades, laying the groundwork for the new kind of digital colonial Latin American Studies that this special issue aims to explore.</p>
<h2 id="current-trends-within-digital-colonial-latin-american-studies">Current trends within digital colonial Latin American studies</h2>
<p>While diverse in terms of materials and methodologies, the work being carried out today within DCLAS is characterized broadly by a set of common features. Much of this work focuses on the recovery of and access to cultural heritage, seeks to uncover hidden narratives and geographies, poses questions about labor and pedagogy, and emphasizes problems of theory and praxis. While these concerns are not unique to DCLAS, the ways they across the field support the idea of a clearly identifiable area of digital practice. This convergence of theoretical and practical concerns across DCLAS is, in many ways, a result of the special circumstances of CLAS and the challenges that scholars face, and indeed, many of the dynamics we outline here are also central to non–digital work within CLAS.</p>
<h2 id="1-recovery--access-to-cultural-heritage">1. Recovery &amp; Access to Cultural Heritage</h2>
<p>Recovery projects are initiatives that aim to “locate, preserve and disseminate” historical records that have been devalued, dispersed, and destroyed through historical processes such as colonialism<a class="footnote-ref" href="#recovery2020"> [recovery2020] </a>. These projects depend on cross-organizational and multinational collaboration, and frequently decenter Europe and the United States. They provide access to widely dispersed collections of archival materials while building on new methods for crowdsourced transcription, text encoding, and descriptive metadata that better reflect the ambiguities and linguistic complexities of the colonial period. Within DCLAS, these projects have proliferated so widely that we cannot list them all here: some examples include the <em>Primeros Libros de las Américas</em> , the <em>Fundación Histórica Neogranadina</em> , <em>A Colony in Crisis</em> , <em>Escritos de Mujeres</em> , and <em>coloniaLab</em> .<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></p>
<p>Three articles in this special issue address the challenges of recovery work. In her article on the <em>Catálogo Colectivo de Marcas de Fuego</em> , an index of authorities, Mercedes Isabel Salomón Salazar examines the obstacles faced by digital projects that need to reference bibliographical materials across different institutional systems. She demonstrates the difficulties of standardizing the study of provenance and coordinating a project across organizational and national boundaries. She also illustrates how collaborative recovery projects can lead to the uncovering of histories that were erased by the boundaries of collecting institutions.</p>
<p>George Allen Broadwell et al. address the particular challenges of recovering Indigenous materials in collaboration with scholarly, student, and Indigenous communities. They reflect upon Ticha, a digital text explorer for writings in Colonial Zapotec. They explain how Ticha provides access to little-known archival materials, enabling modern-day speakers of Zapotec to connect with the history of their language and communities. The authors also examine Ticha as a model for partnering with Indigenous stakeholders in the production of knowledge and the design of digital humanities endeavors.</p>
<p>In a similar fashion, Laura Matthew and Michael Bannister consider Nahuatl/Nawat in Central America (NECA), a project focused on recovering and making accessible Nahuan-language texts written during the colonial period in Central America. They explore the reasons for prioritizing this corpus and explain the history of the project and its technical evolution. By looking in part at site analytics, they also analyze the challenges that this project has faced, and formulate a model for moving forward.</p>
<p>We would also like to note here one additional project focused on recovery that we were, in the end, unable to feature in this issue. <em>Digital Aponte</em> is a project “dedicated to the life and work of José Antonio Aponte, a free man of color, carpenter, artist, and alleged leader of a massive antislavery conspiracy and rebellion in colonial Cuba in 1811-1812.”  <em>Digital Aponte</em> is a creative reimagining of what it means to engage with archival silence; its subject is a lost volume produced by Aponte and recalled through notarial archives from the trial that would end his life<a class="footnote-ref" href="#rodriguez2019"> [rodriguez2019] </a>. Linda Rodriguez, the creator of <em>Digital Aponte</em> , passed away during the process of assembling this project and her contribution to this issue was never completed. Linda’s presence in our community ended too soon, and we dedicate this special issue to her.</p>
<h2 id="2-uncovering-hidden-narratives-and-geographies">2. Uncovering hidden narratives and geographies</h2>
<p>Thinking critically about representations of place and space has been fundamental to CLAS, which has a long history of engaging with and disrupting the interaction between Indigenous boundaries and colonial borders. These areas of study benefit from new digital methodologies, which bring together what Thomas Padilla has named “collections-as-data” with technologies for geospatial representation<a class="footnote-ref" href="#padilla2020"> [padilla2020] </a>. For example, projects like Maria José Afanador Llach’s <em>Mapping Nature in New Granada</em> and the broadly collaborative <em>Power of Attorney</em> take advantage of the affordances of digital technology to see history differently, allowing us to engage with historical categories ranging from borders and languages to legal codes and natural resources.</p>
<p>In this special issue, Patricia Murrieta-Flores et al. approach these questions by examining how computational approaches can expedite and facilitate the identification, analysis, and cross-referencing of vast amounts of historical, anthropological, and archaeological information available in sixteenth-century sources. Murrieta-Flores et al. consider the the experiences of the <em>Digging into Early Colonial Mexico</em> project, which focuses on the analysis of the Relaciones geográficas, a set of responses to a sixteenth-century questionnaire completed for the Spanish Crown by local colonial administrators. Their work demonstrates the potential of these methods to address questions relating to the economy, culture, natural history, and religious practices of New Spain.</p>
<p>Emma Slayton draws on archaeological data about Indigenous Caribbean settlements to model hypothetical canoe routes between Trinidad and the mainland coast of South America, exploring how possible avenues of travel were changed or interrupted during the early colonial period. Her work shows how data-driven analysis can complement the written record to better describe the impact of colonization on Indigenous communities.</p>
<p>By extending beyond the practice of close reading to explore cultural analytics and extratextual evidence, these projects allow us to find new ways of knowing that extend beyond the narrow perspective inscribed in the colonial text. This can allow us to locate new information left out of the historical record, as Slayton writes. It can also, in the words of Murrieta et al., “facilitate the discovery and analysis of geographies not immediately apprehended with normal reading.”</p>
<h2 id="3-labor-and-pedagogy">3. Labor and Pedagogy</h2>
<p>Questions surrounding labor and pedagogy — separate categories which are nonetheless closely intertwined — are central to DCLAS. Like the Ticha and Nahuatl/Nawatl projects described by Broadwell et al. and Matthews and Bannister in this issue, much current work in DCLAS involves envisioning new models for accomplishing scholarly work. This often entails imagining ways to achieve more equitable relationships across national boundaries, among scholarly institutions, and with groups that have been historically marginalized within academic settings, including Black and Indigenous scholars, language activists, and knowledge and heritage communities. Examples of such projects would be the digitization of the Fondo Real de Cholula, a collaboration between scholars and librarians at the University of Texas and the Benemérita Universidad Autónoma de Puebla, the digital edition of the Codex Mendoza developed by the Instituto Nacional de Arqueología e Historia (Mexico), <em>Mesolore</em> , and <em>Musical Passages</em> .</p>
<p>Current work in digital colonial Latin American Studies pushes us to think critically about what it means to teach about the colonial world in the digital age. Projects like Ticha and coloniaLab involve students as participants or primary collaborators, and include reflection on that student involvement as a central component of their work<a class="footnote-ref" href="#flores2020"> [flores2020] </a><a class="footnote-ref" href="#lillenhaugen2020"> [lillenhaugen2020] </a><a class="footnote-ref" href="#mccarl2020"> [mccarl2020] </a><a class="footnote-ref" href="#palacios2020"> [palacios2020] </a>. Other projects deploy technology to provide new learning opportunities for those who do not have access to attend in-person classes related to the colonial world. Two examples are <em>Chqeta’maj le qach’ab’al k’iche’</em> , a language-learning resource for K’iche’ Maya, and <em>Programming Historian en Español</em> , which offers free training resources in digital humanities for researchers working in multiple languages. As we write this introduction from our home-offices (or our kitchen tables) while under stay-at-home orders during the coronavirus pandemic, the importance of these resources and the critical apparatus that informs them are at the forefront of our minds.</p>
<p>In this special issue, Lauren G. Kilroy-Ewbank explores the merits and drawbacks of using digital visual materials, both scholarly and pedagogically, for understanding and analyzing colonial Latin American art. She demonstrates how instructors can use digital methods in teaching to reveal how “the digital frames or reframes our understanding of visual culture and to effectively critique it.” In one example, Kilroy-Ewbank discusses how an active role in the creation of metadata — a process often overlooked or regarded as acritical — can alter students’ understanding of the objects we study and the biases inherent in scholarly work.</p>
<h2 id="4-theory--praxis">4. Theory &amp; Praxis</h2>
<p>One commonality across projects in DCLAS, as is often the case in DH more generally, is an attention to the bringing together of theory and practice. <em>Slavery in the Machine</em> , the third issue of the <em>Archipelagos</em> journal of digital Caribbean studies, is a model for the breadth of theoretical possibility in colonial DH<a class="footnote-ref" href="#johnson2019"> [johnson2019] </a>. The work represented in that issue, much of which draws on the history of colonization and enslavement, envisions and implements a digital humanities based in a theoretical space of movement and change, a Caribbean that “won’t stand still” or anisla que se repite<a class="footnote-ref" href="#glover2019"> [glover2019] </a>. In this framework, experimentation exists alongside critique, silence alongside voicing, and mourning alongside rebirth.</p>
<p>Similarly, in their survey of digital research on visual culture in Spanish America, Barbara Mundy and Dana Leibsohn describe a field of scholarship that reconfigures ways of knowing, seeing, and working together, even as it works with and through digital tools<a class="footnote-ref" href="#mundy2017"> [mundy2017] </a>. As Maria José Afanador Llach writes, in the digital humanities “nos enfrentamos a procesos de producción de conocimiento mediados por el pensamiento computacional, el software y las interfaces digitales” <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> <a class="footnote-ref" href="#afanador2019"> [afanador2019] </a>. Even as colonial digital humanists build tools and platforms, digitize documents, enter metadata, and design websites, they work to understand the alignment between the tools we use, the things we see, and the knowledge that we make possible. This can involve not just thinking critically about digital tools and their interaction with social and cultural factors of colonial and post-colonial communities, but also investing in the construction of new technologies that better reflect scholarly values<a class="footnote-ref" href="#alpert2016"> [alpert2016] </a><a class="footnote-ref" href="#alpert2017"> [alpert2017] </a>.</p>
<p>The questions of theory and praxis that emerge from the articles in this special issue open new ways of theorizing DCLAS. These largely collaborative projects aim to produce “transformative work” by way of an iterative process conducted “through an ongoing conversation with user communities” <a class="footnote-ref" href="#matthew2020"> [matthew2020] </a>. As Matthew and Bannister write in this issue, this introduces a “paradigmatic change” in how scholars work together, with far-reaching consequences for knowledge production in and beyond the academy. They open the possibility, in the words of Broadwell et al., for a form of digital humanities that “democratize[s] access to materials and resources.” As Matthew and Bannister add, however, these projects also introduce new problems as we think through their relationship with colonial and neoliberal politics, the technology industry, and institutions of higher education in the United States and Latin America.</p>
<h2 id="looking-forward">Looking forward</h2>
<p>This collection points to various possibilities for CLAS. The articles gathered here illustrate ways that digital scholarship can provide new pathways to conducting scholarship in a collaborative fashion. They suggest innovative means for representing the heterogeneous and incomplete nature of the colonial archive. They demonstrate how the curation of colonial data sets can enable new ways of understanding Latin American history. Likewise, they show how digital pedagogy, or critical approaches to the selective use of digital tools and resources in teaching and learning, offers new ways for students to engage with colonial material and textual history.</p>
<p>This is not to say that DCLAS does not continue to face challenges, many of them made explicit by this special issue, both through its content and the circumstance surrounding its publication. Foremost among these challenges are issues related to peer review, the precarious professional circumstances of many within DCLAS, as well as the need we face, as a field, to think critically about how we engage digitally with colonial-era materials.</p>
<p>Like many scholarly projects, this special issue faced significant challenges during the process of peer review. We originally intended to publish these pieces in a more traditional humanities journal, but after careful consideration, the editors determined that review and revision of these project- and pedagogy-oriented initiatives was too far out of scope of that publication. This problem was exacerbated by the professional diversity of those involved, who include not only research/teaching faculty, but also faculty members, librarians, programmers, students, and language activists — voices not often included in many conventional humanities forums. A DH journal turned out to be a more appropriate home, but identifying reviewers who could speak to these articles as work sitting at the intersection of DH and CLAS proved to be another challenge.</p>
<p>All of these circumstances reflect the broader difficulty that digital humanists have in demonstrating the value of their work, with real consequences for hiring, tenure, and promotion, as well as for the sustainability of projects themselves. Such dynamics play out in CLAS in ways that are common across the humanities, with many of the scholars who are engaged in digital work within CLAS not emerging from, or entirely identifying with, the disciplinary routes that traditionally have fed into the field. As a consequence, such scholars do not have a clear path into a professional existence within the very area of inquiry that they are best positioned to help transform. Higher education in the United States and many other parts of the world continues to rely for administrative purposes on the notions of disciplines, and many scholars themselves, particularly in the face of financial cuts to vulnerable areas, defend such disciplinary lines. In an extremely tight job market, those who might identify first-and-foremost as practitioners of DCLAS face a difficult challenge in selling their broadly focused skills to disciplinary departments who are often searching for candidates with more traditional profiles who can teach more conventional coursework. The lines that have long separated librarianship from the labor of research/teaching faculty exacerbate the problem, as practitioners of DCLAS might naturally fit into a professional sphere that could span both areas, but at the present, that space is extremely limited.</p>
<p>On a conceptual level, practitioners of DCLAS face a need to imagine the common questions that should be asked about how we interact digitally with colonial-era objects. This is a topic that arose during a panel at DH2018 in Mexico City, and was one of the objectives of the first meeting of the Association for Digital Research in Early Latin America (ADRELA), held at the annual congress of the Latin American Studies Association in Boston the following year.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> As was discussed at both events, a shared protocol might be not only of a logistical nature, but also have ethical implications, helping us to consider the assumptions behind our tools and their conceptual models that might distort our work in ways we do not realize. Such questions might also address the ways that our own assumptions — as specific people working in specific contexts — do the same.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In gathering together the articles in this collection, we seek to advance the emerging conversation about the role of digital scholarship within CLAS and contribute to the formation of a more coherent digital humanities community in the field. We also seek to understand how articles like those collected here help CLAS connect with larger conversations about scholarship in the twenty-first century, and consider how digital methods can expand the ways we study, understand, and interact with the colonial period in Latin America. Perhaps most importantly, we hope to emphasize DH as a point of entry for a new generation of scholars in our field, which — like DH itself — is inherently interdisciplinary, and built upon an enthusiasm for innovation and collaboration.</p>
<p>Much of the work in this special issue has been touched by local and global crises, including climate change, the coronavirus pandemic, U.S. immigration policy, and the defunding of humanities programs at academic institutions in the United States. During the three years that this collection was developed, contributors were directly and indirectly impacted by multiple health crises, wildfires, travel bans, and campus closures, while one editor of this volume no longer works in academia. These events draw attention to the precarious conditions of our histories, our communities, and our industries, even as they make the values of openness, access, collaboration, and virtual connection that underlie these projects more essential than ever. Likewise, in the current moment of instability, crisis, and misinformation, the value of using digital technologies to preserve and provide access to culture has never been greater, particularly when those tools can empower us to recover stories that have been lost or erased.</p>
<h2 id="digital-projects-referenced-in-this-introduction">Digital Projects Referenced in this Introduction</h2>
<p><em>Catálogo Colectivo de Marcas de Fuego</em> . Mercedes Salomón and Adrian Mendoza Leal.<a href="http://www.marcasdefuego.buap.mx/">http://www.marcasdefuego.buap.mx</a></p>
<p><em>Chqeta’maj le qach’ab’al k’iche’</em> . Sergio Romero, Ignacio Carvajal, Mareike Sattler, Juan Manuel Tahay Tzaj, Carl Blyth, Sarah Sweeney, Pat Kyle, Nathalie Steinfeld Childre.<a href="https://tzij.coerll.utexas.edu/">https://tzij.coerll.utexas.edu</a></p>
<p><em>Codex Mendoza</em> . Frances Berdan, Baltazar Brito, Peter Stokes, Ernesto Miranda Trigueros, Noemí Cadena Corona, Verónica Lerma Hernández, and Gerardo Gutiérrez.<a href="https://codicemendoza.inah.gob.mx/index.php">https://codicemendoza.inah.gob.mx/index.php</a></p>
<p><em>Colección Digital Fondo Real de Cholula</em> . LLILAS Benson Latin American Studies and Collections.<a href="https://ladi.lib.utexas.edu/">https://ladi.lib.utexas.edu.</a></p>
<p><em>Colección Escritos de Mujeres Novohispanas</em> . Clara Ramírez and Claudia Llanos.<a href="https://publicacionesdigitalesunamiisue.wordpress.com/escritos-mujeres/">https://publicacionesdigitalesunamiisue.wordpress.com/escritos-mujeres</a></p>
<p><em>coloniaLab</em> . Clayton McCarl and collaborators.<a href="https://colonialab.org/">https://colonialab.org</a></p>
<p><em>A Colony in Crisis</em> . Abbey R. Broughton, Kelsey Corlett-Rivera, Nathan H. Dize, Brittany de Gail, Laurence Jay-Rayon Ibrahim Aibo, Pierre Malbranche, Daphney Vastey.<a href="https://colonyincrisis.lib.umd.edu/">https://colonyincrisis.lib.umd.edu</a></p>
<p><em>Digging into Early Colonial Mexico</em> . Patricia Murrieta-Flores, Ian Gregory, Bruno Martins, Diego Jiménez Baldillo and teams.<a href="https://www.lancaster.ac.uk/digging-ecm/">https://www.lancaster.ac.uk/digging-ecm</a></p>
<p><em>Fundación Histórica Neogranadina</em> . Juan Fernando Cobo Betancourt, Santiago Muñoz Arbeláez, Natalie Cobo, Adraína Soto Segura.<a href="https://neogranadina.org/">https://neogranadina.org</a></p>
<p><em>Mapping Nature in New Granada.</em> María José Afanador Llach. Forthcoming.</p>
<p><em>Mesolore</em> . Liza Bakewell and Byron Hamann.<a href="http://www.mesolore.org/">http://www.mesolore.org</a></p>
<p><em>Musical Passage: A Voyage to 1688 Jamaica</em> . Laurent Dubois, David K. Garner, Mary Caton Lingold.<a href="http://www.musicalpassage.org/">http://www.musicalpassage.org</a></p>
<p><em>Nahuatl/Nawat</em> . Laura E. Matthew, Michael Bannister, and Héctor Concohá Chet.<a href="https://nahuatl-nawat.org/">https://nahuatl-nawat.org</a></p>
<p><em>Primeros Libros de las Américas</em> . LLILAS Benson Latin American Studies and Collections, Cushing Memorial Library, Biblioteca Histórica José María Lafragua, Biblioteca Franciscana, Biblioteca Palafoxiana.<a href="http://primeroslibros.org/">http://primeroslibros.org</a></p>
<p><em>Programming Historian en Español</em> . María José Afanador-Llach, Victor Gayol, Silvia Gutierrez de la Torre, Jennifer Isasi, José Antonio Motilla, Joshua G. Ortiz Baco, Riva Quiroga, Antonio Rojas Castro.<a href="https://programminghistorian.org/es/">https://programminghistorian.org/es</a></p>
<p><em>Slave Voyages</em> . Emory Center for Digital Scholarship and collaborators.<a href="https://www.slavevoyages.org">https://www.slavevoyages.org</a></p>
<p><em>Ticha</em> . Brook Danielle Lillehaugen, George Aaron Broadwell, Michel R. Oudijk, Laurie Allen, Mike Zarafonetis, Xóchitl Flores-Marcial, Moises García Guzmán, Felipe López and team.<a href="https://ticha.haverford.edu/">https://ticha.haverford.edu</a></p>
<p><em>Power of Attorney</em> . Yanna Yannakakis and team.<a href="https://www.powerofattorneynative.com/">https://www.powerofattorneynative.com</a></p>
<ul>
<li id="adorno2006">Adorno, Rolena. “About the transcription and its critical apparatus”  _The Guaman Poma Website_ . Det Kongelige Bibliotek. 2006.<a href="http://www5.kb.dk/permalink/2006/poma/info/en/foreword.htm">http://www5.kb.dk/permalink/2006/poma/info/en/foreword.htm</a>.
</li>
<li id="adorno2009">Adorno, Rolena. “1989–2009: Revising Colonial Latin American Studies’ New Paradigm ” . Modern Language Association Conference, 27-30 December 2009, Philadelphia, Pennsylvania.
</li>
<li id="afanador2019">Afanador Llach, María José. “Tecnología al servicio de las Humanidades.”  _Telos_ . 11 Dec. 2019.<a href="https://telos.fundaciontelefonica.com/telos-112-cuaderno-central-humanidades-en-un-mundo-stem-maria-jose-afanadortecnologia-al-servicio-de-las-humanidades/">https://telos.fundaciontelefonica.com/telos-112-cuaderno-central-humanidades-en-un-mundo-stem-maria-jose-afanadortecnologia-al-servicio-de-las-humanidades/</a>.
</li>
<li id="alpert2016">Alpert-Abrams, Hannah. “Machine Reading the Primeros Libros.”  _Digital Humanities Quarterly_ 10.4 (2016).<a href="http://www.digitalhumanities.org/dhq/vol/10/4/000268/000268.html">http://www.digitalhumanities.org/dhq/vol/10/4/000268/000268.html</a>.
</li>
<li id="alpert2017">Alpert-Abrams, Hannah. _Unreadable Books: Colonial Mexican Documents in Circulation_ . 2017. University of Texas, PhD Dissertation.
</li>
<li id="alpert2018">Alpert-Abrams, Hannah. “Colonial Copying in an Imperial Age.”  _Catalyst_ 4.2 (2018).<a href="https://link.gale.com/apps/doc/A561685883/AONE?u=21246_dol&sid=AONE&xid=2c6e866b">https://link.gale.com/apps/doc/A561685883/AONE?u=21246_dol&sid=AONE&xid=2c6e866b</a>.
</li>
<li id="balkun2020">Balkun, Mary McAleer, and Marta Mestrovic Deyrup. _Transformative Digital Humanities: Challenges and Opportunities_ . Routledge, 2020.<a href="https://www.taylorfrancis.com/books/9780429399923">https://www.taylorfrancis.com/books/9780429399923</a>.
</li>
<li id="bolanos2002">Bolãnos. Alvaro F́elix, and Gustavo Verdesio, eds. “Colonialism Past and Present : Reading and Writing About Colonial Latin America Today.” Albany, NY: SUNY Press, 2002.
</li>
<li id="bueno2018">Bueno, Christina. “La Biblioteca Nacional de Antropología e Historia de México: un legado del nacionalismo porfiriano.” In Carlos Aguirre and Ricardo D. Salvatore, _Bibliotecas y cultura letrada en América Latina: siglos XIX y XX._ Lima: Pontificia Universidad Católica, Fondo Editorial, 2018. 205-225.
</li>
<li id="burns2020">Burns, Patrick and Quinn Dombrowski. “Language is not a Default Setting: Countering Digital Humanities’ English Problem.” Matthew Gold and Lauren Klein, eds. _Debates in the Digital Humanities_ 2021. University of Minnesota Press. _Forthcoming_ .
</li>
<li id="crompton2016">Crompton, Constance Louise Kathleen, Richard J. Lane, and Raymond George Siemens. 2016. _Doing Digital Humanities: Practice, Training, Research_ . Routledge, 2016.
</li>
<li id="crompton2020">Crompton, Constance, Richard J. Lane, and Raymond George Siemens. _Doing More Digital Humanities: Open Approaches to Creation, Growth, and Development_ . Routledge, 2020.
</li>
<li id="daut2019">Daut, Marlene. “Haiti @ the Digital Crossroads: Archiving Black Sovereignty.”  _Archipelagos_ 3 (2019).
</li>
<li id="diaz2014">Díaz, Mónica. “El nuevo paradigma de los estudios coloniales latinoamericanos,”  _Revista de Estudios Hispánicos_ 48:3 (2014): 519–47.
</li>
<li id="dombrowski2020">Dombrowski, Quinn. “The Stakes of Multilingual DH in the United States.”  _quinndombrowski.com_ . March 13, 2020.
</li>
<li id="emory2020a">Emory Center for Digital Scholarship and collaborators. “About the Project.” <a href="https://www.slavevoyages.org/about/about#">https://www.slavevoyages.org/about/about#</a>.
</li>
<li id="emory2020b">Emory Center for Digital Scholarship and collaborators. “History of the Project.” <a href="https://www.slavevoyages.org/about/about#history/1/en/">https://www.slavevoyages.org/about/about#history/1/en/</a>.
</li>
<li id="flores2020">Flores-Marcial, Xóchitl. “Zapotec-Language Use in Social Media Platforms as a Pedagogical Method for Undergraduate Students.” Presentation at Virtual Conference of the Latin American Studies Association, May 16, 2020.
</li>
<li id="glover2019">Glover, Kaiama and Alex Gil. “The Caribbean Won't Stand Still.”  _Archipelagos_ 3 (2019).
</li>
<li id="jacob2020">Jacob, Arun. "Punching Holes in the International Busa Machine Narrative." IDEAH 1.1 (May 30, 2020).<a href="https://assets.pubpub.org/cjsnqq1f/2701f4a8-ef0f-4b40-a86a-b6f520c35270.pdf">doi: 10.21428/f1f23564.d7d097c2</a>.
</li>
<li id="johnson2019">Johnson, Jessica Marie. “We Are Deathless (Slavery in the Machine).”  _Archipelagos_ 3 (2019).
</li>
<li id="lillenhaugen2020">Lillehaugen, Brook. “TEI Encoding and the Creation of Digital Editions of Zapotec-Language Texts in an Undergraduate Classroom.” Presentation at Virtual Conference of the Latin American Studies Association, May 16, 2020.
</li>
<li id="matthew2020">Matthew, Laura and Michael Bannister. “The Form of the Content: The Digital Archive Nahuatl/Nawat in Central America”  _Digital Humanities Quarterly_ <a href="http://digitalhumanities.org/dhq/vol/14/4/000491/000491.xml">http://digitalhumanities.org/dhq/vol/14/4/000491/000491.xml</a>
</li>
<li id="mccarl2020">McCarl, Clayton, Amarilys Sánchez and Emilia Thom. “Reevaluating the History of Africans and their Descendants in Antioquia, Colombia, through a Digital-Editing-on-Site Study Abroad Experience.” Presentation at Virtual Conference of the Latin American Studies Association, May 16, 2020.
</li>
<li id="mundy1996">Mundy, Barbara and Dana Leibsohn. “Of Copies, Casts, and Codices: Mexico on Display in 1892.”  _RES: Anthropology and Aesthetics_ , no. 29/30 (April 01, 1996): 326-43.
</li>
<li id="mundy2017">Mundy, B., & Leibsohn, D. “Digital Resources: The State of Digital Research on the Visual Culture of Spanish America.”  _Oxford Research Encyclopedia of Latin American History_ . 2017.<a href="https://doi.org/10.1093/acrefore/9780199366439.013.117">DOI: 10.1093/acrefore/9780199366439.013.117</a>.
</li>
<li id="murrieta2020">Murrieta-Flores, Patricia et al. “Developing Geographically Oriented NLP Approaches to Sixteenth–Century Historical Documents: Digging into Early Colonial Mexico.”  _Digital Humanities Quarterly_ <a href="http://digitalhumanities.org/dhq/vol/14/4/000490/000490.xml">http://digitalhumanities.org/dhq/vol/14/4/000490/000490.xml</a>
</li>
<li id="padilla2020">Padilla, Thomas. “Always Already Computational: Collections as Data.” <a href="https://collectionsasdata.github.io/">https://collectionsasdata.github.io/</a>.
</li>
<li id="palacios2020">Palacios, Albert A. “From the Colonial Page: Introducing DH through Transcription.” Virtual Conference of the Latin American Studies Association, May 16, 2020.
</li>
<li id="putnam2016">Putnam, Lara. “The Transnational and the Text-Searchable: Digitized Sources and the Shadows They Cast.”  _The American Historical Review_ , 121.2, April 2016. 377–402.<a href="https://doi.org/10.1093/ahr/121.2.377">https://doi.org/10.1093/ahr/121.2.377</a>.
</li>
<li id="recovery2020"> “Recovering the US Hispanic Literary Heritage.”  _Arte Publico Press_ 2020.<a href="https://artepublicopress.com/recovery-program/">https://artepublicopress.com/recovery-program/</a>.
</li>
<li id="rodriguez2019"> “Collaborating with Aponte: Digital Humanities, Art, and the Archive.”  _Archipelagos_ 3 (2019).
</li>
<li id="risam2018">Risam, Roopika. _New Digital Worlds._ Chicago: Northwestern University Press, 2018.
</li>
<li id="trettien2020">Trettien, Whitney. “A Hornbook for Digital Book History with Whitney Trettien.”  _Rare Book School_ . YouTube.
</li>
<li id="zamora2004">De Zamora, Rosa María Fernández. “Hacia un mundo visible del patrimonio bibliográfico mexicano: Retos y acciones que las bibliotecas deben alcanzar.”  _Encuentro Nacional de Bibliotecas con Fondos Antiguos_ (2004).
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Though the abbreviation <em>CLAS</em> is not widely used, we employ it for the sake of brevity, in parallel with the more common use of <em>DH</em> . Below we introduce another abbreviation, <em>DCLAS</em> , to designate the intersection of these two fields.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>For a discussion of general problems in working with digital sources, see Putnam 2016 and Daut 2019.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>For some recent volumes that survey the current state of DH, see Crompton et al. 2016, Balkun and Deyrup 2020, and Crompton et al. 2020.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Scholarship aimed at defining CLAS as a field is perhaps not abundant, but certainly over the last two decades, scholars have raised questions about the need to revisit or expand the critical lenses that practitioners of CLAS employ. See, for instance,<a href="#bolanos2002">Bolãnos and Verdesio 2002</a>,<a href="#adorno2009">Adorno 2009</a>,<a href="#diaz2014">Díaz 2014</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>“The effort to create a history of the homeland in the great process of constructing the nation.” Translation ours.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>For the history of the project and this reformulation, see<a href="#emory2020a">Emory Center 2020a</a>,<a href="#emory2020b">2020b</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>There are too many projects of this kind to list comprehensively here; for a more complete list of digital projects and collections relating to colonial Latin American Studies, we refer you to the crowdsourced bibliography of Latin American DH:<a href="https://docs.google.com/document/d/1JE5s77JETxUC6Qx_ZOd7aiRxfr2WBPNDweTemJGcYT8/edit#">https://docs.google.com/document/d/1JE5s77JETxUC6Qx_ZOd7aiRxfr2WBPNDweTemJGcYT8/edit#</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>“We are faced with processes of knowledge construction mediated by computational thinking, software, and digital interfaces.” Translation ours.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Those conversations — which brought together scholars from across the United States, Europe, and Latin America — inform all of the work in this introduction. For more information about both, see the “Events” page of the ADRELA website (<a href="https://adrela.net/events">https://adrela.net/events</a>).## Bibliography&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Modeling Amerindian Sea Travel in the Early Colonial Caribbean</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000482/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000482/</id><author><name>Emma Slayton</name></author><published>2020-12-15T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Considering the written record is a vital component in evaluating the effect of early colonial encounters on Amerindian life in the Caribbean. Documents that reference Amerindian practices provide insight into everything from foodstuffs to the basics of canoe use or construction (ex. Benozi 1563; Columbus 1498; Mendez 1933; Oviedo Valdes 1851). In turn, there are some detailed references to the movement of these, and the people who used them, between different islands. The specific routes by which these goods moved, and their alteration after the arrival of Europeans, are unfortunately difficult to trace through text and traditional archaeological analysis alone. Inconsistencies in the areas of coastline surveyed, the small number of objects relating to seafaring toolkits documented in the archaeological record, and the limited references concerning the specifics of canoe use by Amerindians in the historical record make these investigations challenging. Yet knowledge of the location of these pathways would help us understand specifics about Amerindian connections and social interactions not made explicit in the historical record.</p>
<p>Digital humanities approaches, or humanist theory as applied to or analyzed by computer applications, can provide a solution to this issue. Through the application of archaeological inquiry and computational analysis, the movement of materials and peoples in this region can be modeled as representations of past canoe routes between two points. These generated routes can offer insight into connections that developed long before Columbus’ arrival and continued as prime canoe pathways after European colonization. The trajectory of canoe travel corridors, or the routes people followed by South American mainland and Lesser Antillean communities were likely altered by European contact (1498–1650 AD), something that is unlikely to be represented explicitly in historical texts.</p>




























<figure ><img loading="lazy" alt="A map of the northern coast of South America." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Map of the case study region, including Guyana, Trinidad, Tobago, and the Windward Islands.
        </p>
    </figcaption>
</figure>
<p>To explore the location heavily used for voyaging by Amerindians I modeled hypothetical canoe routes between communities in contact, as referenced in the historical or archaeological record. Specifically, I used least-cost pathway analysis to determine travel corridors taking the least amount of time that may have existed. Such methods are drawn from previous landscape models (ex.<a class="footnote-ref" href="#bell2000"> [bell2000] </a><a class="footnote-ref" href="#conolly2006"> [conolly2006] </a>) and seascape<a class="footnote-ref" href="#callaghan1999"> [callaghan1999] </a><a class="footnote-ref" href="#callaghan2001"> [callaghan2001] </a>, which rely on algorithms to calculate these time costs. In many cases, these algorithms are either A* or Djekstra<a class="footnote-ref" href="#white2012"> [white2012] </a>and tabulate the cost to movement by adding the difficulty of moving between regions of topography together until the lowest value between two points on a map can be determined.</p>
<p>The area from the north coast of mainland South America to the Windward Islands provides an interesting perspective for this approach. Though contact with Europeans in the Caribbean occurred in 1498, Amerindians were still using traditional seafaring lines well into the 1700s. Contacts between Amerindian peoples from South America and Europeans as referenced in early colonial accounts and the archaeological record, were taken alongside modeled least–cost pathways that consider the areas where interaction between these communities may have taken place. The results of route modeling are used to evaluate where and to what result Amerindians’ travel corridors may have related to Europeans into the region. These efforts can help to provide a base for further analysis of Amerindian culture across the pre–Columbian and historic divide.</p>
<h2 id="routes-demonstrated-in-precolumbian-and-historical-record-in-the-caribbean">Routes Demonstrated in Pre–Columbian and Historical Record in the Caribbean</h2>
<p>Seafaring practices covered the maintenance of a complex web of social and material mobility networks that linked these communities. When the Europeans arrived in the Caribbean at the end of the 15th century, peoples from the north coast of South America to the Windward Islands formed complex groups of multi–lingual and multi–ethnic individuals<a class="footnote-ref" href="#boomert2010"> [boomert2010] </a><a class="footnote-ref" href="#hofman2010"> [hofman2010] </a><a class="footnote-ref" href="#keegan2004"> [keegan2004] </a><a class="footnote-ref" href="#watters1998"> [watters1998] </a>). These cross–island/mainland relationships were built on the sea, and the connections and materials that could be gained by traveling it. This often meant that island communities were more focused on inter–island rather than intra–island connections (see<a class="footnote-ref" href="#boomert2010"> [boomert2010] </a>). Excavated sites dating to the colonial period possess materials that suggest substantial interactions existed between peoples on different islands<a class="footnote-ref" href="#keegan2016"> [keegan2016] </a>.</p>
<p>Though the evidence used as the base for the discussion in this paper primarily comes from the archaeological record, we also see support for these connections in ethnohistoric accounts. The first written information about peoples from Trinidad and Tobago appears in the logs of Columbus’ third voyage in 1498<a class="footnote-ref" href="#columbus1498"> [columbus1498] </a>(see also<a class="footnote-ref" href="#boomert2016"> [boomert2016] </a>). Later writers reported on Spanish efforts to take over the Orinoco River area as well as the islands off what today is the Venezuelan coast (Boomert 2016). Due to their proximity to Amerindians, these early chroniclers were thus able to view the comings and goings of seafarers between specific regions and islands, accounts often document the location of prominent canoe travel corridors used by Amerindians moving from the mainland to the Windward Islands and back. One of the earliest records of such a voyage comes from Columbus on his first voyage, where he mentions abducting a man mid-voyage between two points. Others also have made note of these types of voyages. Raymond Breton wrote during his stay on Dominica (1635):</p>
<blockquote>
<p>They are descended from the people of the mainland closest to the island… The friendship they maintain with them and their commerce with them are signs of it. [Breton and la Paix 1926: 45‑46]<a class="footnote-ref" href="#davis1990"> [davis1990] </a>).</p>
</blockquote>
<p>Though these records are not from the region in question, it does set an example for Europeans meddling in Amerindian transportation routes from the time of initial contact. Breton, in addition to mentioning voyages near Dominica, recounted that South American Kaliña had branched out from their coasts to colonize the islands<a class="footnote-ref" href="#davis1990"> [davis1990] </a>. Others disagreed and considered these connections between Island Carib peoples on St. Vincent at the period in question were mere associations and not deeper ties, as suggested by de Rochefort<a class="footnote-ref" href="#davis1990"> [davis1990] </a>. Another example comes from reference to contact between peoples of Trinidad and Grenada by Dutch sailors in 1628<a class="footnote-ref" href="#boomert2002"> [boomert2002] </a><a class="footnote-ref" href="#boomert2016"> [boomert2016] </a><a class="footnote-ref" href="#laet1931"> [laet1931] </a>.</p>
<p>Historical accounts also mention canoe crews using Tobago as a waypoint on their way to raid Arawak communities on the mainland<a class="footnote-ref" href="#boomert2002"> [boomert2002] </a>. The governor of Tobago in 1654 noted that both mainland Kaliña and island Kalinago canoers used the small island as a rest area for traveling between the two regions (Mollens, in<a class="footnote-ref" href="#mattiesen1940"> [mattiesen1940] </a>). The governor of St. Kitts, in the late 1620s, suggested it was too hazardous to colonize Tobago because of the number of Carib vessels traveling by the island<a class="footnote-ref" href="#boomert2002"> [boomert2002] </a>. What is clear, even in the historic record, is that these groups were linked. Information concerning the movements of Amerindian peoples within these European sources can provide insight into past practices of Amerindian seafaring, as well as context for connections shown by least–cost pathway modeling.</p>
<p>Historical records from early contact periods can also be problematic, not only because they often ignore large portions of Amerindian culture, but also because what they do mention often paints only the vaguest of pictures. For example, while canoeing Amerindians and their watercraft were popular topics for European chroniclers, reports about specific construction techniques or navigation practices were often glossed over. Likewise, none of these documents included detailed description of Amerindian canoeing activity. Most often they simply referred to the speed, size of the vessel or crew, and rough design of the canoe (ex.<a class="footnote-ref" href="#columbus1498"> [columbus1498] </a><a class="footnote-ref" href="#benzoni1563"> [benzoni1563] </a>Bernáldez, in<a class="footnote-ref" href="#jane1988"> [jane1988] </a>), without discussing specific details about construction or navigation practices. For example, Columbus describes seeing Amerindians in a large war canoe, or pirogue, holding 25 men off the west coast of Trinidad in his 1498 dairies<a class="footnote-ref" href="#columbus1498"> [columbus1498] </a><a class="footnote-ref" href="#columbus1824"> [columbus1824] </a><a class="footnote-ref" href="#boomert2016"> [boomert2016] </a>. However, the full picture of the technology and canoeing strategies goes unmentioned. Others also go into detail about the great length of these vessels, some extending 26 paces. Depictions of canoes seem to indicate that pre–Columbian travel was conducted without the use of sails. This absence would have limited the reach of seafarers, making their voyages targeted to areas within paddle distance of coastlines. It is from these limits that we can discern a base for modeling watercraft and site locations to retrace routes referred to by European chroniclers and observed in the archaeological record. It is in the margins or sparse commentary that researchers must look to contextualize what is found in the archaeological record.</p>
<p>While colonial records provide possible insights into pre–Columbian seafaring technology, the introduction of new technologies and people into the region began to alter inter–island relationships. There were changes in technological toolkits, such as the sporadic adoption and adaption of the sail<a class="footnote-ref" href="#fitzpatrick2013"> [fitzpatrick2013] </a><a class="footnote-ref" href="#mckusick1960"> [mckusick1960] </a>. Tracking population fluctuations and movement to new settlements, and the role of European contact in these developments, can show regional changes in relationships<a class="footnote-ref" href="#keegan2016"> [keegan2016] </a>. The decline of island populations because of the impact of forced removal of the populations and the spread of disease also influenced the construction of regional mobility patterns.</p>
<p>Record of this movement was not always positive. Interaction between Amerindians and Europeans often resulted in violent encounters. The fact that Tobago remained free of colonization until midway through the eighteenth century, in part due to persistent attacks by Kaliña (mainland Amerindian communities) and Kalingao (Windward Island Amerindian communities) peoples from the Windward Islands<a class="footnote-ref" href="#boomert2010"> [boomert2010] </a><a class="footnote-ref" href="#keegan2016"> [keegan2016] </a>, speaks to its importance as a waypoint along the mobility corridors connecting mainland and island communities. That control of the eastern side of Trinidad remained difficult for Europeans<a class="footnote-ref" href="#boomert2010"> [boomert2010] </a>also points to the desire of Amerindians to keep these travel corridors clear. These waypoints, or areas where there were safe portages for canoes, needed to be preserved to maintain the connection between Kaliña and their island Kalinago counterparts (see Figure 2).</p>
<p>As time passed, it is probable that Amerindians canoeing between the islands sought to minimize contact with Europeans. These patterns of avoidance may have been based on techniques learned from previous generations, as many of the groups in this region participated in raiding of other settlements<a class="footnote-ref" href="#boomert2016"> [boomert2016] </a><a class="footnote-ref" href="#moreau1992"> [moreau1992] </a><a class="footnote-ref" href="#newson1976"> [newson1976] </a>and possibly learned evasive maneuvering. The placement of canoe corridors may have centered on whether they took paddlers near to or away from coastlines, either to take advantage of an easy rest point or to avoid contact that may lead to an unfavorable result. In the case of the early European contact record, the location of interaction around the island like Margarita for pearl fishing, could have reinforced links moving to the eastern coast of Venezuela to the islands, which was a popular travel corridor prior to European contact, as referenced in the archaeology.</p>
<p>Though the historical record provides some information on Amerindian mobility corridors, the majority of evidence for direct contact between peoples of this region comes from the archaeological record. Materials — mostly ceramics — that connect sites on different islands tie stylistically to designs developed on the mainland<a class="footnote-ref" href="#boomert2016"> [boomert2016] </a><a class="footnote-ref" href="#hofman2011"> [hofman2011] </a>.</p>
<p>The Amerindian peoples of the Windward Islands were influenced by several avenues of exchange, both from the islands in the north and the mainland in the south (see<a class="footnote-ref" href="#allaire1990"> [allaire1990] </a><a class="footnote-ref" href="#boomert2002"> [boomert2002] </a><a class="footnote-ref" href="#boomert2016"> [boomert2016] </a><a class="footnote-ref" href="#hofman2011"> [hofman2011] </a><a class="footnote-ref" href="#keegan2016"> [keegan2016] </a>. Similar styles of ceramic vessel shapes and decoration can be seen between ceramics found in the Guianas, or Koraibo ceramics, and in the Windward Islands, or Cayo ceramics, that date to periods directly before and after European contact (1250–1600 AD)<a class="footnote-ref" href="#bright2011"> [bright2011] </a><a class="footnote-ref" href="#davis1990"> [davis1990] </a><a class="footnote-ref" href="#kirby1974"> [kirby1974] </a>. Comparable shapes include Cassava brewing ceramics, for example, which can be found in both Kaliña and Kalinago assemblages<a class="footnote-ref" href="#boomert1986"> [boomert1986] </a>. Stylistic similarities include adornos, or ceramic elements adorning vessels, fashioned in anthropomorphic motifs and found on the upper sections of ceramic objects<a class="footnote-ref" href="#antczak2006"> [antczak2006] </a>. Rim decoration, common in mainland Koriabo ceramics, found on Late Ceramic Age (AD 1200–1500) and early colonial period (AD 1498 to 1600) island–produced wares from Guadeloupe to Tobago, also indicate a connection<a class="footnote-ref" href="#boomert1995"> [boomert1995] </a><a class="footnote-ref" href="#bright2011"> [bright2011] </a><a class="footnote-ref" href="#petersen2004"> [petersen2004] </a>.</p>
<p>Island–made Cayo ceramics likely resulted from local attempts to fit within macro–regional interaction networks<a class="footnote-ref" href="#bright2011"> [bright2011] </a><a class="footnote-ref" href="#hofman2013"> [hofman2013] </a><a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>. In fact, the rise of Cayo style vessels largely coincided with the inception of mainland Kaliña materials, also known as the Koriabo style<a class="footnote-ref" href="#evans1960"> [evans1960] </a><a class="footnote-ref" href="#vandenbel2015"> [vandenbel2015] </a>. Cayo ceramics have been considered a simplified version of Koriabo ware<a class="footnote-ref" href="#boomert1986"> [boomert1986] </a><a class="footnote-ref" href="#keegan2016"> [keegan2016] </a>. Currently there are roughly 20 sites that possess Cayo ceramics within the Lesser Antilles<a class="footnote-ref" href="#hofman2012"> [hofman2012] </a>, the majority of which are centered around the islands of Grenada and St. Vincent. Replicating these connections through least–cost pathways should center on modeling routes between Cayo sites on Grenada or St. Vincent and the area off the coast of Guyana, following the trajectory of both stylistic and linguistic transfer, including references to canoe–centric names or to shared words around travel or connection<a class="footnote-ref" href="#boomert2016"> [boomert2016] </a>. For example, the connection of settlements and canoe use is indicated in the termhueitinocou, meaning both villager and member of a canoe crew<a class="footnote-ref" href="#hofman2011"> [hofman2011] </a>. That these patterns are noted in the archaeological record and by Europeans throughout the early contact period points to the longevity of these travel corridors, despite possible “adversarial” encounters between Europeans and Amerindian groups.</p>
<p>These systems of interactions and mobility corridors stemmed from routes created during early micro– and macro–regional explorations that brought migrating communities from the South American mainland into the islands<a class="footnote-ref" href="#hofman2010"> [hofman2010] </a><a class="footnote-ref" href="#keegan2016"> [keegan2016] </a>. It is likely that avenues of movement developed as lifelines for Amerindian island settlers<a class="footnote-ref" href="#hofman2007"> [hofman2007] </a><a class="footnote-ref" href="#keegan2004"> [keegan2004] </a><a class="footnote-ref" href="#hofman2010"> [hofman2010] </a><a class="footnote-ref" href="#kirch1988"> [kirch1988] </a><a class="footnote-ref" href="#watters1998"> [watters1998] </a>and solidified into deeper patterns of use for the exchange or raiding practices described by Europeans after 1500. However, as pointed out by<a href="#hofman2010">Hofman and Carlin</a>[2010, 111], the maintenance of these networks was tied to the shifting priorities of Amerindian communities both in the islands and on the mainland. These shifts were based on a desire to adapt social ties, develop avenues of exchange, or to engage in conflict. Therefore, a discussion of the location of routes modeled from around the northern coast of mainland South America past Trinidad or Tobago towards the Windward Islands furthers our understanding of the location of travel corridors from long–standing exchange patterns to those encountered by early colonial visitors.</p>
<h2 id="methods">Methods</h2>
<p>The physical processes of moving through the Caribbean have traditionally been evaluated through ethnographic and historic accounts. For example, many researchers refer to the ease of movement linked with following known environmental patterns, such as the South Equatorial or Guiana Current, and the prevailing northeastern trade winds associated with movement to and from Trinidad<a class="footnote-ref" href="#agard2000"> [agard2000] </a><a class="footnote-ref" href="#boomert2009"> [boomert2009] </a>. Adding lines of evidence for movement through computer–based modeling allows us to ask new, more detailed questions about connections between Kaliña and Kalinago communities. When combined with traditional text–based and archaeological analysis, modeled movement between these areas is an important aspect of the broader analysis of social networks in the region, both pre– and post–European contact.</p>
<p>The routes analyzed here can be tied to the theory of least–cost pathway analysis, in which pathways are generated based on the cumulative effort of either the caloric or time expenditure it takes to travel from one geographic point to another<a class="footnote-ref" href="#bell2000"> [bell2000] </a><a class="footnote-ref" href="#herzog2013"> [herzog2013] </a><a class="footnote-ref" href="#llobera2000"> [llobera2000] </a><a class="footnote-ref" href="#tobler1993"> [tobler1993] </a>. Least–cost pathway analysis is a common technique used in archaeology to evaluate possible connections between sites. The method is often applied to movement through landscapes, where the cost of the journey is tied to movement with or against slopes within a terrain (e.g.,<a class="footnote-ref" href="#bell2000"> [bell2000] </a><a class="footnote-ref" href="#conolly2006"> [conolly2006] </a><a class="footnote-ref" href="#llobera2000"> [llobera2000] </a><a class="footnote-ref" href="#lock2009"> [lock2009] </a><a class="footnote-ref" href="#tobler1993"> [tobler1993] </a>;<a class="footnote-ref" href="#white2012"> [white2012] </a>). These methods are often based on Dijkstra&rsquo;s algorithm, which most commonly is used find the shortest paths from a fixed source point to all other grids within a raster surface, resulting in a shortest-path tree. These calculate the environment to assign portions of the area with a cost in time or energy, which then can be added together as a path is charted through these areas.</p>
<p>In most cases, several least–cost routes are modeled between various points that correspond to archaeological sites within a landscape. These routes are then compared against existing knowledge and theory of connection in the area to draw conclusions about social relationships between sites. In recent years, interest in modeling this type of movement on waterscapes has increased, inspiring work on regional connections from the Pacific (see<a class="footnote-ref" href="#irwin1990"> [irwin1990] </a><a class="footnote-ref" href="#levison1972"> [levison1972] </a><a class="footnote-ref" href="#montenegro2016"> [montenegro2016] </a>) to the Caribbean (see<a class="footnote-ref" href="#altes2011"> [altes2011] </a><a class="footnote-ref" href="#cooper2010"> [cooper2010] </a>). This interest is likely to grow as access to more robust and higher resolution climate data sets, both modern and reconstructed, become available.</p>
<p>Previous work in the Caribbean region has largely focused on analyzing models of large scale migration or colonization routes. Richard Callaghan<a class="footnote-ref" href="#callaghan1999"> [callaghan1999] </a><a class="footnote-ref" href="#callaghan2001"> [callaghan2001] </a>has completed extensive work in this area, describing migration and travel patterns for both drift and non-drift voyages from the coast of South America to the Greater Antilles, as well as along the South and Central American coast. Others who have followed in his footsteps have either focused on similar scales of migration<a class="footnote-ref" href="#altes2011"> [altes2011] </a>or similar areas, such as the Greater Antilles<a class="footnote-ref" href="#cooper2010"> [cooper2010] </a>. The goal of this paper is to explore maintained relationships between island and mainland communities at a finer scale and in as yet little modeled areas in the Caribbean using this underutilized digital method (see also<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>), to compare with the historic and archaeological record.</p>
<p>For this work, I applied an isochrone approach to least–cost pathway modeling to examine seafaring routes. An isochrone method simply refers to a model that evaluates movement over the generated environmental surface based on where an “agent,” or individual, can move within a particular set time (see<a class="footnote-ref" href="#hagiwara1989"> [hagiwara1989] </a><a class="footnote-ref" href="#hildenbrand2015"> [hildenbrand2015] </a><a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>). Here I use the modified isochrone method, as based on Hagiwara, where movement is calculated using a variant of Dijkstra&rsquo;s algorithm. Specifically, I focused on the distance it is possible for a modeled canoe to move from where the boat was launched within a set time period. Although many possible directions of travel are evaluated, consecutive route segments are chosen based on the direction of travel where the canoe can move the furthest during the set time period<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>derived from calculations using modified isochrone method based on a global understanding of the environment or the anticipation of all possible routes. This process is repeated until the landing point — in most cases a known settlement area — is reached. These segments are then linked together to form a continuous route that suggests where it would have been easiest for canoes to travel between two points (see for example Figure 2).</p>
<p>As such, routes can reflect traditional navigation practices, as seafarers may have reevaluated their boat’s heading several times during a journey, which is reflected in the length of time between isochrone generations in the model. Keeping with the theme of modeling hypothetical travel corridors taken by real world canoers, there was an option to set a canoe speed within the model. This speed is reflective of the paddling power of those on board. Here, the canoe speed was set at 3 knots (see also<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>) or the typical speed achieved by canoers on experimental canoeing voyages in the region (<a class="footnote-ref" href="#berard2016"> [berard2016] </a>.</p>
<p>I used modern day environmental data, such as current and wind direction and strength, as the base for the surface on which these segments were modeled (see<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>). Specifically, surfaces were based on modern environmental data captured for the Caribbean Sea; water current data was gathered from the National Oceanographic and Atmospheric (NOAA) Amseas 3D program and wind data from the NOAA Global Forecast System (GFS) (for a more detailed discussion see<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>). These two data sets have a particularly robust iteration period, i.e., the time intervals over which environmental data is captured; new current or wind is data generated which allows for the model to evaluate updated currents every three hours. Additionally, the Amseas 3D program captures information every 3 km2, while the GFS can only return information in 25 km segments. As a result, the tool includes a function that allows for these surfaces to be interpolated, or meshed, together. In this way current and wind are both reflected in the underlying surface on which the route segments are based on.</p>
<p>Though sequential modern current data was used as the base for this analysis, it is important to note that others have used randomized or past-forecasted climate data. However, due to the lack of change in bathymetry (or under water topography) in this region, combined with the relatively stable current and wind data from the periods discussed<a class="footnote-ref" href="#callaghan2001"> [callaghan2001] </a>, modern data was deemed acceptable due to the high rate of iterative data provided by NOAA. Using this type of current data is also effective due to the geographic unit and time iteration of the NOAA models, as it allows for a finer resolution within the cost surface than has been used in other examples where nautical sailing charts were used<a class="footnote-ref" href="#callaghan1999"> [callaghan1999] </a><a class="footnote-ref" href="#callaghan2001"> [callaghan2001] </a>.</p>
<p>Additionally, this iterative data allows for the capture of extreme weather (ex. hurricanes) in the return of high cost routes. In the future, more types of environmental constraints (i.e. wave height) should be considered. In keeping with the iteration period of both data sets, routes were modeled every three hours, during the months of January, April, August, and November due to the seasonal fluctuations observed in the underlying data sets (see<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>).</p>
<p>Routes modeled were connected to the Amerindian and European contact period by using launch and landing points known for their extended use leading up to and directly after the contact period. Though not to be taken as an exact representation of the past, routes modeled in this way can suggest avenues of contact between mainland and island Amerindian communities.</p>
<p>Due to limitations with the extent of the underlying data set used to model these travel corridors, I was unable to model routes directly from communities from the southern Guianas. By viewing routes modeled from an area at the farthest extent of the underlying environmental data set, however, it was possible to evaluate routes that passed by large areas of Guyana that were inhabited by Kaliña peoples who were likely in contact with island communities. Routes examined in this study were modeled from off the coast of Guyana (Figures 2 to 5). In order to ensure efficiency in comparisons for this work, routes towards only sites on only two islands, Grenada and St. Vincent, will be discussed.</p>
<p>Routes for this paper were taken from the author’s PhD research on movement to and from the coast of Guyana and the Windward Islands<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>. The evaluation of these routes centers on how they can be used to hypothesize the location of known connection points and on how peoples following these mobility routes may have reacted to European arrival. As such, examples of routes referenced here (Figures 2 to 5) were chosen for their relationship to point of contact between newly–arrived Europeans and established Amerindian travel corridors mentioned in the ethnohistorical record (ex. Mollens, in<a class="footnote-ref" href="#mattiesen1940"> [mattiesen1940] </a>). Due to limited space provided by this article, I will briefly discuss two examples of travel corridors modeled from the South American mainland to the Windward Islands using this qualitative analysis.</p>
<h2 id="modeled-routes-and-comparisons-to-the-historical-record">Modeled Routes and Comparisons to the Historical Record</h2>
<p>Examples of European style pottery within site depositions on Grenada and St . Vincent<a class="footnote-ref" href="#bright2011"> [bright2011] </a>indicate that some level of exchange was being sought by Amerindian peoples to acquire these materials, even if they indirectly acquired them through down–the–line exchange with other Amerindian groups. Amerindian–produced pottery also indicates the strength of these ties, showcasing the longevity of contact between mainland and island communities. Stylistic motifs used in Kalinago pottery are viewed as connected to those produced by mainland populations<a class="footnote-ref" href="#davis1990"> [davis1990] </a>. Modeling these corridors, established through connections recognized from archaeology and the historic record, we can begin to assess possible travel corridors which carried these peoples and materials.</p>
<p>One of the travel corridors analyzed in this paper suggests movement along the coast of Tobago, while the other looks at movement towards the northern coast of Venezuela, where Amerindian canoers were more likely to have encountered the newly arrived Spanish. As mentioned above, routes were modeled between sites from suspected Cayo sites dating to AD 1250–1600<a class="footnote-ref" href="#boomert1986"> [boomert1986] </a>, which in some cases overlapped with European arrival. This allows for a brief discussion of the differences in contact opportunities for peoples along each possible corridor.</p>




























<figure ><img loading="lazy" alt="A map of an isochrone route between Guyana and east coast of Grenada depicted with a black line." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Modeled isochrone route between the Guyana and the east coast of Grenada launched November 17 at 3 pm<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>.
        </p>
    </figcaption>
</figure>
<p>The travel corridor over the north coast of Trinidad towards the northeast coast of Venezuela was indicated by several routes modeled between the Guianas and the Windward Islands. Movement along the north coast of Trinidad was likely a crucial aspect of the mobility network around Venezuela to the Windward Islands. This is due in part to the ability for persons to see the Windward Islands from the northeast coast of Trinidad<a class="footnote-ref" href="#boomert2009"> [boomert2009] </a>. Routes that pass by the northern coast of Trinidad commonly travel past the eastern coast of the island as well. The separation of communities from the western and eastern sides of the island is evident in both the archaeological and historic record<a class="footnote-ref" href="#boomert2016"> [boomert2016] </a>. This may have played into preferences for routes that avoided the western half of the island as well, in connection with later notes on island habitation from colonial sources.</p>
<p>The acknowledgment of Tobago being used as a through–point of connection, both in the archaeological record and by European Governors of St. Kitts and Tobago, indicates that in some cases avoidance of Europeans was not possible or sought out. In addition, routes modeled from Guyana run directly past the site of Blanchisseuse, possibly highlighting the importance of finding natural rest points along routes<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>. In the case of Figure 2, the route ran directly into the area adjacent to the site. The placement of this circa AD 1200–1500 site supports the focus of peoples in this region towards inter–island connections, and the site may have acted as a waypoint for travel between Kaliña and Kalinago communities. Though use of this site was largely ended by the time Europeans arrived in this region, it does support the link between settlement use and the trajectory of routes returned by this model. The strong connection between the suggested routes and active use by Amerindians indicates that other modeled routes can stand in for past avenues of mobility. We might also ask archaeologists to question why natural stopping points used in earlier periods are not reestablished after European contact, as many sites or areas are typically part of a habitation season or cycle in the ceramic age.</p>




























<figure ><img loading="lazy" alt="A map of an isochrone route between Guyana and the west coast of Grenada depicted with a black line." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Modeled isochrone route between the Guyana and west coast of Grenada launched November 9 at 12 am, which connects with the Península de Paria<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>.
        </p>
    </figcaption>
</figure>
<p>Modeled routes following the trajectory in Figure 3 also go further to the west, keeping to the northern coast of Trinidad in its entirety and on rare occasions making contact with the Península de Paria. Peoples moving along more westerly routes could potentially have made contact with the active mobility corridors around coastal Venezuela. Pathways like these would also have brought peoples from Trinidad and the Guianas into contact with Europeans who settled within this region to gain access to pearl harvesting areas (see<a class="footnote-ref" href="#boomert2016"> [boomert2016] </a>). The intensity of use of these routes thus may have been altered due to this presence. This may explain why ceramics at sites like Blanchisseuse, inhabited or before conflict, show a change in this period. However, it may also be that increased raiding activity in the region or conflict between peoples on the west coast of Trinidad and the Venezuelan coast linked to this avoidance, as well. Re-evaluating routes within this mobility corridor, from the coast of Venezuela towards the Windward Islands needs to be done alongside considerations of materials found within the sites used as origin points needs to be done. It may help researchers to understand better if or when peoples traveled from the Guianas to the north coast of Trinidad post AD 1500.</p>
<p>Another prominent corridor indicated by modeling routes between the Windward Islands and the area off the coast of Grenada covers the east and west coast of Trinidad (Figure 4). That many of the routes modeled between St. Vincent and Guyana’s coast show movement past Tobago comports with the multiple references in the historical record that point to the island’s importance to Amerindian peoples as a waypoint for travel between the Windward Islands and the mainland. These references make note of altercations between Amerindians and Europeans, where the former was perhaps intimidating the others who were populating Tobago<a class="footnote-ref" href="#boomert2002"> [boomert2002] </a>. Efforts to keep the island clear may have been linked to its prominence as a waypoint, with the need to protect travel corridors between Windward Islands settlements and the mainland “homeland” communities. That Tobago is referred to multiple times by Europeans as an Amerindian waypoint between these two regions further highlights the island’s significance.</p>
<p>The consistent movement of peoples past the island of Tobago, which was known by both Amerindians and Europeans to be a waypoint for Amerindian travelers, shows a commitment to this travel corridor. The strong response by Amerindians to protect Tobago, and its lack of European settlement until the late eighteenth century, indicates that these corridors of movement may have been only partially disrupted by Spanish settlement on islands off the Venezuela coast. Even the east coast of Trinidad remained relatively free of European influence, protecting through lines of traffic from disruption. As such, it is likely that only towards the eighteenth century did these routes truly suffer the full impact of outside influences.</p>
<p>Routes that pass by Tobago originated in all points used for the start and end of voyages, both for the Guyana and the Grenada or St. Vincent start/end points (example Figure 4 and 5). This showcases the wide variety of peoples who may have taken advantage of stopping at this island. Unfortunately, there are still many stretches of Tobago’s coastline left to be surveyed by archaeologists and connections between specific mainland sites and those from the island are difficult to draw. In the future, areas that lie along modeled routes, areas of survey, and the specifics of European mentions of Tobago should be compared.</p>




























<figure ><img loading="lazy" alt="A map of an isochrone route between St. Vincent and Guyana depicted with a black line." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Modeled isochrone route between St. Vincent and Guyana launched November 15 from 9 pm<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="A map of an isochrone route between Guyana and the south coast of Grenada depicted with a black line." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Modeled isochrone route between the Guyana and south coast of Grenada launched November 10 at 3 am<a class="footnote-ref" href="#slayton2018"> [slayton2018] </a>.
        </p>
    </figcaption>
</figure>
<p>It is also possible to evaluate the position of these routes not in terms of how they may have been affected by the presence of outsiders but by the efforts of Amerindian peoples to preserve them. The existence of these exchange and raiding corridors has been referred to as vital to the social structures of Amerindian Islanders. The desire to protect these connections was likely high and is conceivably reflected in the response of the Amerindians who fought to keep Europeans out of this area.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This paper explores possible routes that connected the Late Ceramic Age/early European contact period Kaliña peoples of the mainland and the Kalinago peoples of the Windward Islands with the idea of connecting them to the location of canoe routes referenced within the ethnohistoric record of the early colonial period. Here, I specifically relate to the mentions of Amerindian peoples in canoes that pass the area between St. Vincent and Grenada between 1492 and 1650 AD. These references to the location of Amerindian travel corridors provide some insight into where Caribbean canoers paddled, but they only make up one brush stroke of the larger painting of these networks.</p>
<p>This paper provides an example of how computational archaeology methods can act as a context for knowing the location of routes these comments were based on, as well as where these routes passed when out of sight of Europeans. The use of computational least-cost pathway modeling — a digital approach to humanities — is a vital addition to traditional modes of analysis of Amerindian mobility during this period. This is due to the limited European knowledge of the canoe routes that traversed this area. The methods used to generate the hypothetical canoe routes discussed above reveal new layers of understanding that would be impossible without computer modeling. These avenues of inquiry highlight the importance of using digital humanities techniques to supplement traditional text–based analysis.</p>
<p>The level to which these travel corridors remained in the minds Amerindians prior to or after the arrival of Columbus is unknowable. However, studies like these can provide a unique opportunity to examine the existing historical and archaeological record. The fact that the possible location of these corridors in some cases lie close to known archaeological sites from this period support some preliminary theories as to the underlying process of movement between these groups. However, to what extent Europeans encountered Amerindian peoples, and vice versa, cannot be learned through modeling alone. These modeled routes can only be discussed as a reflection of the singular least–cost path between two areas rather than as corridors reactive to social stressors. Further examination of textual resources, archaeological sites, and additional modelled routes needs to be conducted in order to determine if shifts in Amerindian population areas around the time of European contact met with them on the travel corridors that crisscrossed the expanse between the mainland and the Windward Islands.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>I would like to thank Corinne Hofman for the guidance she provided on my PhD research, on which this article is based. I would also like to thank Jan Athenstädt and Jan Hildenbrand for their work in creating the seafaring isochrone model used in this research.</p>
<h2 id="bibliography">Bibliography</h2>
<ul>
<li id="agard2000">Agard, John BR, and Gobin, Judith F. “The Lesser Antilles, Trinidad and Tobago.” In Sheppard, C.R.C. (ed.) _Seas at the millennium: an environmental evaluation: 1._ Regional chapters: Europe, The Americas and West Africa. (2000), pp. 627–641.
</li>
<li id="allaire1990">Allaire, Louis. “Prehistoric Taino interaction with the Lesser Antilles: the view from Martinique.” 55th Annual Meeting of the Society for American Archaeology, Las Vegas, Nevada. 1990.
</li>
<li id="altes2011">Altes, Christopher. “A brief note on currents, current archaeologists, and ancient fiber–tempered pots.”  _The Florida Anthropologist_ , 64(2) (2011): 113–118.
</li>
<li id="antczak2006">Antczak, María Magdalena, and Antczak, Andrzej T.. Los ídolos de las islas prometidas: Arqueología prehispánica del Archipiélago de Los Roques. Equinoccio, (2006).
</li>
<li id="bell2000">Bell, Tyler, and Lock, Gary. “Topographic and cultural influences on walking the Ridgeway in later prehistoric times.”  _Nato ASI Series A Life Sciences_ 321 (2000): 85–100.
</li>
<li id="benzoni1563">Benzoni, Girolamo. “La Historia del Mondo Nuovo.” Venice (1563).
</li>
<li id="berard2016">Bérard, Benoît, Billard, Jean–Yves, L’Etang, Thierry, Lalubie, Guillaume, Nicolizas, Costantino, Ramstein, Bruno, and Slayton, Emma. “Technologie du fait maritime chez les Kalinago des Petites Antilles aux XVIe et XVIIe siècles.”  _Journal de la société des américanistes 102_ , no. 102–1 (2016): 129–158.
</li>
<li id="boomert1995">Boomert, A. (1995). Island Carib archaeology. In N. Whitehead (Ed.), _Wolves from the sea: Readings in the anthropology of the native Caribbean_ (pp. 23 36). Leiden: KITLV Press.
</li>
<li id="boomert1986">Boomert, Arie. “The Cayo complex of St. Vincent: Ethnohistorical and archaeological aspects of the Island Carib problem.”  _Anthropologica_ 66 (1986): 3–68.
</li>
<li id="boomert2002">Boomert, Arie. “Amerindian–European Encounters on and around Tobago (1498–ca. 1810).”  _Antropológica_ 97, no. 98 (2002): 71–207.
</li>
<li id="boomert2009">Boomert, Arie. “Between the mainland and the islands: The Amerindian cultural geography of Trinidad.”  _Bulletin of the Peabody Museum of Natural History_ 50, no. 1 (2009): 63–73.
</li>
<li id="boomert2010">Boomert, Arie. “Crossing the Galleons’ Passage: Amerindian Interaction and Cultural (Dis) Unity between Trinidad and Tobago.” , _Journal of Caribbean Archaeology_ , 3 (2010): 106–121.
</li>
<li id="boomert2016">Boomert, Arie. _The Indigenous Peoples of Trinidad and Tobago: From the First Settlers Until Today_ . Sidestone Press, Leiden (2016).
</li>
<li id="bright2011">Bright, Alistair J. _Blood is thicker than water: Amerindian intra–and inter–insular relationships and social organization in the pre–Colonial Windward Islands_ . Sidestone Press, Leiden (2011).
</li>
<li id="callaghan1999">Callaghan, Richard T. “Computer simulations of ancient voyaging.”  _Northern Mariner_ 9 (1999): 11–22.
</li>
<li id="callaghan2001">Callaghan, Richard T. “Ceramic age seafaring and interaction potential in the Antilles: a computer simulation.”  _Current Anthropology_ 42, no. 2 (2001): 308–313.
</li>
<li id="theadmiral">The admiral, Don Christopher Columbus. See C. Columbus 1930–1933, 2:112–140.
</li>
<li id="columbus1498">Columbus, C. (translated by Markham, C. R.) (1893). _The journal of Christopher Columbus (during his first voyage, 1942-93) and documents relating the voyages of Jon Cabot and Gaspar Corte Real._ London: Lincoln’s Inn Fields.
</li>
<li id="columbus1932">Columbus, Christopher. “Fourth voyage of Columbus.” Select documents illustrating the four voyages of Columbus 2 (1932).
</li>
<li id="columbus1824">Columbus, Ferdinand. “History of the discovery of America, by Christopher Columbus; written by his son Don Ferdinand Columbus In Kerr R (ed) A General History and Collection of Voyages and Travels.” (1824), pp. 1–242.
</li>
<li id="cooper2010">Cooper, Jago. “Modelling mobility and exchange in pre–Columbian Cuba: GIS led approaches to identifying pathways and reconstructing journeys from the archaeological record.”  _Journal of Caribbean Archaeology_ 3 (2010): 122–137.
</li>
<li id="conolly2006">Conolly, James, and Lake, Mark. _Geographical information systems in archaeology_ . Cambridge University Press, Cambridge 2006.
</li>
<li id="davis1990">Davis, Dave D., and Goodwin, R. Christopher. “Island Carib origins: evidence and nonevidence.”  _American Antiquity_ 55, no. 1 (1990): 37–48.
</li>
<li id="deoviedo">de Oviedo Valdes, GF “Historia general y natural de las Indias, islas y tierra firme de la mar oceano.”  _Real Academia del Historia_ , Madrid. (1851–1855).
</li>
<li id="evans1960">Evans, Clifford, and Meggers, Betty J.. “Part II, An archaeological evaluation of the method.”  _American Antiquity_ 25, no. 4 (1960): 523–537.
</li>
<li id="fitzpatrick2013">Fitzpatrick, Scott M. “Seafaring capabilities in the pre–Columbian Caribbean.”  _Journal of Maritime Archaeology_ 8, no. 1 (2013): 101–138.
</li>
<li id="hagiwara1989">Hagiwara, Hideki. “Weather routing of (sail–assisted) motor vessels.” Ph.D. Thesis, Technical University of Delft (1989).
</li>
<li id="herzog2013">Herzog, I. (2013). _Theory and practice of cost functions._ Paper presented at the _38th Annual Conference on Computer Applications and Quantitative Methods in Archaeology, Granada_ .
</li>
<li id="hildenbrand2015">Hildenbrand, Jan. “Shortest path calculation on water surfaces” M.A. thesis, University of Konstanz (2015).
</li>
<li id="hofman1993">Hofman, Corinne Lisette. _In search of the native population of pre–Columbian Saba:(400–1450 AD). Pottery styles and their interpretaions_ . Rijksuniversiteit, (1993).
</li>
<li id="hofman2013">Hofman, Corinne L. “The Post–Saladoid in the Lesser Antilles (AD 600/800–1492).” In _The Oxford Handbook of Caribbean Archaeology_ . Oxford University Press, Oxford (2013): 205–220.
</li>
<li id="hofman2010">Hofman, Corinne L., and Carlin, Eithne B. “The ever dynamic Caribbean: Exploring new approaches to unraveling social networks in the pre–colonial and early colonial periods.”  _Linguistics and archaeology in the Americas: The historization of language and society_ 2 (2010): 107.
</li>
<li id="hofman2011">Hofman, Corinne L., and Hoogland, Menno LP. “Unravelling the multi–scale networks of mobility and exchange in the pre–colonial circum–Caribbean.” In _Communities in contact: Essays in archaeology, ethnohistory and ethnography of the Amerindian Circum–Caribbean_ (2011): 14–44.
</li>
<li id="hofman2012">Hofman, Corrine L., and Hoogland, Meno LP. “Caribbean encounters: rescue excavations at the early colonial Island Carib site of Argyle, St. Vincent.”  _Analecta Praehistorica Leidensia_ 43, no. 44 (2012): 63–76.
</li>
<li id="hofman2007">Hofman, Corinne L., Bright, Alistair J., Boomert, Arie, and Knippenberg, Sebastiaan. “Island rhythms: the web of social relationships and interaction networks in the Lesser Antillean archipelago between 400 BC and AD 1492.”  _Latin American Antiquity_ 18, no. 3 (2007): 243–268.
</li>
<li id="hofmanetal2011">Hofman, Corinne L., Boomert, Arie, Bright, Alistair J., Hoogland, Menno LP, Knippenberg, Sebastiaan, and Samson, Alice VM. “Ties with the homelands: archipelagic interaction and the enduring role of the South and Central American mainlands in the pre–Columbian Lesser Antilles.” In _Islands at the crossroads: migration, seafaring, and interaction in the Caribbean_ . University of Alabama Press, Tuscaloosa (2011): 73–86.
</li>
<li id="irwin1990">Irwin, Geoffrey, Bickler, Simon, and Quirke, Philip. “Voyaging by canoe and computer: experiments in the settlement of the Pacific Ocean.”  _Antiquity_ 64, no. 242 (1990): 34–50.
</li>
<li id="jane1988">Jane C (1988) The voyage of Christopher Columbus. Argonaut Press, London.
</li>
<li id="keegan2004">Keegan, William. F. “Islands of chaos” . In A. Delpuech, & C. L. Hofman (eds.), _The Late Ceramic Age in the eastern Caribbean_ . Archaeopress, Oxford. (2004): 33–46.
</li>
<li id="keegan2016">Keegan, William F., and Hofman, Corinne L. _The Caribbean before Columbus_ . Oxford University Press, Oxford (2016).
</li>
<li id="kirby1974">Kirby, I. A. E. (1974). _The Cayo pottery of St. Vincent: A pre-Calivigny series_ . Paper presented at the _Vth International Congress for the Study of the Pre-Columbian Cultures of the Lesser Antilles, Antigua_ .
</li>
<li id="kirby2009">Kirby, Peter Wynn. “Lost in space : an anthropological approach to movement.”  _Boundless worlds: an anthropological approach to movement_ (2009): 1–28.
</li>
<li id="kirch1988">Kirch, Patrick V. “Long‐distance exchange and Island colonization: The Lapita case.”  _Norwegian Archaeological Review_ 21, no. 2 (1988): 103–117.
</li>
<li id="levison1972">Levison, Michael, R. Ward, Gerard, and Webb, John W. “The settlement of Polynesia: a report on a computer simulation.”  _Archaeology in Oceania_ 7, no. 3 (1972): 234–245.
</li>
<li id="laet1931">Laet, Johannes. Iaerlyck Verhael van de Verrichtinghen der Geoctroyeerde West– Indische Compagnie, 4 vols. Ed. by S.P.L. l’Honoré Naber. ’s– Gravenhage: Linschoten Vereeniging/Martinus Nijhoff. (1931/37) [First publ. Leyden, 1644].
</li>
<li id="llobera2000">Llobera, Marcos. “Understanding movement: a pilot model towards the sociology of movement.”  _Nato ASI Series A Life Sciences_ 321 (2000): 65–84.
</li>
<li id="lock2009">Lock, Gary, and Pouncett, John. “Walking the Ridgeway Revisited: The Methodological and Theoretical Implications of Scale Dependency for the Derivation of Slope and the Calculation of Least–Cost Pathways.” In Making History Interactive. CAA 2009–Proceedings of the 37th Conference, pp. 192–203. 2009.
</li>
<li id="mattiesen1940">Mattiesen, Otto Heinz. “Die Kolonial–und Überseepolitik der kurländischen Herzöge im 17. und 18.” Jahrhundert. Stuttgart (1940).
</li>
<li id="mckusick1960">McKusick, M. (1960a). Aboriginal canoes in the West Indies. _Yale University Publications in Anthropology_ , 70, 3-11.
</li>
<li id="mendez1933">Mendez, Diego. “An account, given by Diego Mendez, of certain things that occurred on the last voyage of the admiral, Don Christopher Columbus.” See C. Columbus (1933): 1930–1933, 2:112–140.
</li>
<li id="moreau1992">Moreau, Jean–Pierre. “Les Petites Antilles de Christophe Colomb à Richelieu: 1493–1635.” Paris: Karthala Editions, (1992).
</li>
<li id="montenegro2016">Montenegro, Álvaro, Callaghan, Richard T., and Fitzpatrick, Scott M.. “Using seafaring simulations and shortest–hop trajectories to model the prehistoric colonization of Remote Oceania.”  _Proceedings of the National Academy of Sciences_ 113, no. 45 (2016): 12685–12690.
</li>
<li id="newson1976">Newson, Linda A. “Aboriginal and Spanish Colonial Trinidad: a study in culture contact.” Academic Press New York (1976).
</li>
<li id="petersen2004">Petersen, James B., Hofman, Corinne L., and Curet, L. Antonio. “Time and culture: chronology and taxonomy in the eastern Caribbean and the Guianas.” BAR International Series (2004): 17–32.
</li>
<li id="slayton2018">Slayton, Emma. _Seascape Corridors: Modeling Routes to Connect Communities Across the Caribbean Sea_ . Leiden, Netherlands. Sidestone Press, (2018).
</li>
<li id="tobler1993">Tobler, Waldo. “Three Presentations on Geographical Analysis and Modeling: Non- Isotropic Geographic Modeling; Speculations on the Geometry of Geography; and Global Spatial Analysis (93-1).”  _UC Santa Barbara: National Center for Geographic Information and Analysis_ .
</li>
<li id="vandenbel2015">Van den Bel, M. _Archaeological Investigations between Cayenne Island and the Maroni River: A cultural sequence of western coastal French Guiana from 5000_ , PhD Dissertaion. University of Leiden. Sidestone Press (2015).
</li>
<li id="watters1998">Watters, David R. “Maritime adaptive strategies in the Caribbean archipelago.”  _Revista de arqueologia Americana_ , No. 15 (1998): 7-31.
</li>
<li id="white2012">White, Devin A., and Surface–Evans Sarah L., eds. _Least cost analysis of social landscapes: Archaeological case studies._ University of Utah Press, (2012).
</li>
</ul>
]]></content></entry><entry><title type="html">The Form of the Content: The Digital Archive Nahuatl/Nawat in Central America</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000491/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000491/</id><author><name>Laura Matthew</name></author><author><name>Michael Bannister</name></author><published>2020-12-15T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<p>Some thirty years ago, in <em>The Content of the Form</em> , Hayden White reminded his fellow historians of the extent to which history&rsquo;s content is dictated by the form of its presentation. Annals, chronicles, biographies, narrative, and discursive analyses all entail “ontological and epistemic choices with distinct ideological and even specifically political implications” <a class="footnote-ref" href="#white1987"> [white1987] </a>. Here, we adapt White&rsquo;s title to make a similar point about the digital archive <em>El Náhuatl/Náhuat en Centroamérica</em> or in English, <em>Nahuatl/Nawat in Central America</em> (NECA;<a href="http://nahuatl-nawat.org/">http://nahuatl-nawat.org</a>).<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> Whereas White focused on how content may be influenced by its form independent of the creator&rsquo;s intent, here we examine the curatorial decisions we made regarding NECA&rsquo;s form in order to intentionally impact the reception, use, and utility of its content.</p>
<p>NECA assembles a corpus of handwritten, colonial-era texts produced in Central America in variations of the related Mesoamerican languages Nahuatl and Nawat, from eight repositories in Guatemala, Mexico, Spain, and the United States. It emphasizes the fact that these oft-ignored documents exist, and encourages their collaborative study across national, scholarly, community, and disciplinary lines. Neither goal is neutral or apolitical, although the significance of studying these texts may vary depending on whether the user is an Indigenous rights activist from Mexico City or Los Angeles, a linguist of Mayan languages from Guatemala, a native speaker from Guerrero, a primary school teacher from El Salvador, or a doctoral candidate from Europe, etc.</p>
<p>In this essay we explain our rationale for creating a digital archive of Nahuatl texts from Central America in the first place, arguing that NECA&rsquo;s content should be studied not only by individuals analyzing particular texts for the purposes of geographically or disciplinarily bounded research and revitalization projects, but also collaboratively and more experimentally as a standalone corpus. We then review the ontological and epistemic as well as technical choices we made in the project&rsquo;s design to encourage this outcome. NECA&rsquo;s form attempts to prod users towards a variety of actions both within and outside the digital archive. The success or failure of the affordances we created to increase the usefulness and usability of the site, and thus to direct the user toward specific activities, can be measured in the site&rsquo;s analytics. These indicate not just where the digital environment we created is working well or can be improved, but also where it may not be the best workspace available — or at least, not yet.</p>
<h2 id="the-content-why-nahuatl-in-central-america">The Content: Why Nahuatl in Central America?</h2>
<p>Nahuatl, best known as the language of the Aztec empire, was spoken by tens of millions of people in the early sixteenth century. It is not a single language but a range of mutually intelligibleNahuanvariants ranging from northern Mexico to Nicaragua since at least the second half of the first millennium A.D. (see<a href="#figure01">Figures 1</a>and<a href="#figure02">2</a>). Many Nahuan languages have died out, especially in the last 150 years. Others persist but are threatened by continued and increasing contact with and preference for European languages such as Spanish and English. Today, there are approximately 1.5 million native speakers of Nahuatl variants in Mexico and the United States disapora, and around 200 native speakers of the related language Nawat in the Izalcos and Santo Domingo de Guzmán areas of Sonsonate and in Tacuba, Ahuachapán, both in western El Salvador (<a href="http://www.unesco.org/languages-atlas/index.php">http://www.unesco.org/languages-atlas/index.php</a>).<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Nahuan languages in Guatemala, Belize, Honduras, and Nicaragua have largely ceased to exist.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Classification of Nahuan languages
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Approximate distribution of major Mesoamerican language families at the time of Eurasian contact. Given the extent of migration, trade, and diplomacy as well as the reach of the Aztec empire, this map is an oversimplification and leaves out many other languages such as Totonacan, Xinka, and non-Nahuan languages of the Uto-Aztecan branch.
        </p>
    </figcaption>
</figure>
<p>When the Spanish arrived in 1519, central Mexico was the most urbanized, politically powerful, and densely populated part of Mesoamerica. The Spanish made the defeated Aztec capital of Tenochtitlan the bureaucratic heart of their own nascent empire, and engaged Indigenous intellectuals in a remarkable, sometimes violent merging of Mesoamerican and European writing systems<a class="footnote-ref" href="#mcdonough2014"> [mcdonough2014] </a><a class="footnote-ref" href="#townsend2016"> [townsend2016] </a>. This produced a significant amount and variety of Nahuatl written in Roman script that has been studied extensively, for centuries in Mexico and more recently in the United States and Europe.</p>
<p>This large corpus of Nahuatl documentation from central Mexico has spawned a number of digital projects with a variety of aims, such as increasing access to lesser-known texts and making databases of glyphic and linguistic information searchable online for comparative study. For instance, the <em>Compendio Enciclopédico Náhuatl</em> (<a href="http://cen.iib.unam.mx/">http://cen.iib.unam.mx/</a>) links linguistic data from approximately twenty historical and modern Nahuatl dictionaries with separate databases of information from pictorial and alphabetic texts. The <em>Nahuatl Dictionary</em> of the Wired Humanities Project at the University of Oregon (<a href="https://nahuatl.uoregon.edu/">https://nahuatl.uoregon.edu</a>) allows users to search for attestations, headwords, and themes associated with any string of letters in English, Spanish, or Nahuatl, in order to compare usages in early modern Nahuatl from central Mexico as well as contemporary Nahuatl from the Huasteca, Veracruz. Also from Oregon, the <em>Early Nahuatl Library</em> and the <em>Mapas Project</em> (<a href="https://enl.uoregon.edu/">https://enl.uoregon.edu</a>) make available images, transcriptions, and English translations of around 100 Nahuatl texts with annotations from a variety of archival and published sources. <em>Axolotl</em> (<a href="https://axolotl-corpus.mx/">https://axolotl-corpus.mx</a>) similarly depends on the published and unpublished work of established scholars to cross-reference approximately 30 colonial-era books in Spanish-Nahuatl translation.</p>
<p>Significant colonial-era Nahuan language documentation also exists from outlying regions of the former Aztec empire. Like the Aztecs, the Spanish used central Mexican Nahuatl as an imperiallingua franca<a class="footnote-ref" href="#dakin1996"> [dakin1996] </a><a class="footnote-ref" href="#herrera2003"> [herrera2003] </a><a class="footnote-ref" href="#gasco2017"> [gasco2017] </a><a class="footnote-ref" href="#herranz2001"> [herranz2001] </a>.Nahuatlatos— native and non-native speakers of Nahuatl who acted as translators and scribes — constituted a crucial link in the chain of translation from other Mesoamerican languages to Nahuatl to Spanish or Latin and vice versa, making them key actors in diplomacy, Catholic evangelization, and the application of Spanish law. Aztec outposts administered by central Mexican Nahuatl speakers at the edges of unconquered territory lay the groundwork for Nahua-Spanish invasion and colonization of independent regions such as Michoacán, Oaxaca, the Yucatán, and Central America<a class="footnote-ref" href="#carrasco1999"> [carrasco1999] </a><a class="footnote-ref" href="#navarrete1996"> [navarrete1996] </a><a class="footnote-ref" href="#voorhies2004"> [voorhies2004] </a>. In the United States in the 1990s, a historical methodology called the New Philology began to analyze records of Spanish bureaucracy written in Nahuatl not only in central Mexico, but also in regions where it acted as a second language of translation<a class="footnote-ref" href="#restall1997"> [restall1997] </a><a class="footnote-ref" href="#restall2003"> [restall2003] </a><a class="footnote-ref" href="#terraciano2001"> [terraciano2001] </a><a class="footnote-ref" href="#christensen2013"> [christensen2013] </a>.</p>
<p>In Central America, Nahuatl&rsquo;s usefulness as a tool of empire was augmented by its mutual intelligibility with Nawat and other Eastern Peripheral Nahuan languages natively spoken in what today is Chiapas (Mexico), southwestern Guatemala, and El Salvador<a class="footnote-ref" href="#arauz1960"> [arauz1960] </a><a class="footnote-ref" href="#rivas1969"> [rivas1969] </a><a class="footnote-ref" href="#campbell1985"> [campbell1985] </a><a class="footnote-ref" href="#fowler1989"> [fowler1989] </a><a class="footnote-ref" href="#reyesgarcia1961"> [reyesgarcia1961] </a><a class="footnote-ref" href="#navarrete1975"> [navarrete1975] </a><a class="footnote-ref" href="#knab1980"> [knab1980] </a><a class="footnote-ref" href="#gasco2016"> [gasco2016] </a>. Comparatively little attention, however, has been paid to Central American documents written in colonial-era Nahuan languages. This is partially due to an apparent lack of material. Such appearances, however, are deceiving. The largest repositories of colonial-era documents from Central America outside of Spain are located in Chiapas and Guatemala, both of which have significant Maya populations. Mayan language documents from these regions are therefore highly valued, highlighted in archival catalogs, and may even be removed from their original context to become standalone documents.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> By contrast, documents in Nahuan languages are fragmentary, rarely noted as such, and often remain hidden inside bundles of Spanish-language legal papers. Historians of Spanish Guatemala typically rely on scribal Spanish translations of Nahuan language text, while Maya linguists and language revitalization activists tend to view historical writing in Nahuan languages as a colonial-era imposition that has little to offer their project of fortifying Mayan languages for future generations and recovering Mayan historical and sacred texts.</p>
<p>In neighboring El Salvador, by contrast, Nawat — the only surviving natively-spoken Nahuan language in Central America — is simultaneously valorized as part of the national patrimony and discriminated against in everyday life. In 1932, Salvadoran state forces massacred tens of thousands of peasants, most of them Nawat speakers, in response to an uprising against coffee plantations. Fearful of further repression, survivors avoided speaking Nawat in public or teaching it to their children<a class="footnote-ref" href="#lindo-fuentes2007"> [lindo-fuentes2007] </a><a class="footnote-ref" href="#gould2008"> [gould2008] </a>. This generational trauma, combined with deep-seated social and economic prejudices against indigeneity and a heavy emphasis on Spanish in the education system, has brought Nawat in El Salvador to a critical point of endangerment in the twenty-first century. Research on historical Nawat has therefore taken a back seat to the urgent task of recording and teaching modern Nawat<a class="footnote-ref" href="#lemus2004"> [lemus2004] </a><a class="footnote-ref" href="#laramartinez2015"> [laramartinez2015] </a>. In Nicaragua and Honduras, where Nahuan languages are no longer spoken, Nahua heritage is also nationalistically valorized but historically hazier and thus far, not well documented<a class="footnote-ref" href="#bonta2009"> [bonta2009] </a><a class="footnote-ref" href="#laramartinez2014"> [laramartinez2014] </a><a class="footnote-ref" href="#brinton1883"> [brinton1883] </a><a class="footnote-ref" href="#mccafferty2015"> [mccafferty2015] </a>.</p>
<p>For all these diverse and contradictory reasons, few Central Americans have studied historical documents in Nahuan languages from their own region (although this is beginning to change; see<a href="#romero2017">Romero 2017</a>,<a href="#cossich2012">Cossich 2012</a>). Indeed, it has long been assumed that hardly any such documentation existed. The most basic goal of NECA is to correct this false impression. Our central claim, however, is not merely that these documents exist, but that they are worth studying.</p>
<p>Linguistically, Central American documents in Nahuan languages bring an entirely new data set to debates about the historical evolution of Nahuan languages, especially in areas beyond the imperial center. Linguists generally agree on the basic dialectal features of the two main branches of Nahuatl, Eastern and Western, and of the urban, imperial Nahuatl developed in fifteenth- and sixteenth-century Mexico-Tenochtitlan<a class="footnote-ref" href="#dakin1985"> [dakin1985] </a><a class="footnote-ref" href="#canger1988"> [canger1988] </a><a class="footnote-ref" href="#canger2011"> [canger2011] </a><a class="footnote-ref" href="#hansen2014"> [hansen2014] </a>.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> How Nahuan languages from Central America fit into these typologies is less settled.<a href="#campbell1985">Lyle Campbell (1985)</a>viewed the central Mexican characteristics of Nahuan-language colonial-era documents from Guatemala as the product of contact with the central Mexican allies of the Spanish. Karen Dakin&rsquo;s broader analysis of 20 letters in Nahuatl from sixteenth-century Santiago de Guatemala<a class="footnote-ref" href="#dakin1996"> [dakin1996] </a>and 14 other documents mostly from Chiapas<a class="footnote-ref" href="#dakin2009"> [dakin2009] </a><a class="footnote-ref" href="#dakin2010a"> [dakin2010a] </a>led her to posit anarchaicNahuan language that predated and continued to be used in Central America alongside the Aztec/Spanishkoine. Dakin considers this a unique southern Postclassiclingua francaquite distinct from the Azteckoine, linking it to pan-Mesoamerican Zuyuan ideology<a class="footnote-ref" href="#lopezaustin2000"> [lopezaustin2000] </a>and possibly earlier Nahua-Maya interactions<a class="footnote-ref" href="#dakin2010b"> [dakin2010b] </a>.<a href="#romero2014">Sergio Romero (2014)</a>sees the same texts as evidence of local, precolumbian Nahuan vernaculars. NECA makes possible significant advances in these linguistic debates, by more than doubling the number of identified sources and making high quality images of them accessible online.</p>
<p>NECA is also notable for its range of dates and genres: catechisms, wills, letters to Spanish officials, town council memos, bills of sale, community annals, tributary rolls, judicial testimony and denunciations, land titles, musical manuscripts, and confraternity books from the mid-sixteenth to the early eighteenth century. Religious texts in Indigenous languages are a foundational genre in Mesoamerican studies, and have been analyzed for the cadences of Mesoamerican ceremonial speech as well as the intense and sometimes antagonistic back-and-forth between European and Indigenous intellectuals<a class="footnote-ref" href="#burkhart2011"> [burkhart2011] </a><a class="footnote-ref" href="#sell2008"> [sell2008] </a><a class="footnote-ref" href="#sparks2017"> [sparks2017] </a><a class="footnote-ref" href="#doesburg2008"> [doesburg2008] </a>.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> Grammars, vocabularies, catechisms, and other Mesoamerican language texts produced by Catholic friars also provide valuable linguistic information, sometimes unwittingly. The clerical author of the late seventeenth-century Guatemalan sermon <em>Teotamachilizti in yiuliliz auh in ymiquiliz Tutemaquizticatzim Iesu Christo</em> now held at the John Carter Library at Brown University in the United States, for instance, noted the existence of a vehicular orvulgarNahuatl used alongside Nawat and the central Mexicankoinein Guatemala. The cleric aspired to write his sermon in thevulgardialect but frequently slipped back into the central Mexican variety with which he was more familiar<a class="footnote-ref" href="#madajczak2016"> [madajczak2016] </a><a class="footnote-ref" href="#romero2014a"> [romero2014a] </a>.</p>
<p>Bureaucratic documentation generated mostly by Indigenousnahuatlatos, conversely, tends to imitate the prestigious central Mexicankoineand to adopt Spanish legal formulae, but also employs less standardized orthography that reflects local speech patterns and the decreasing influence over time of the Catholic church on translation norms<a class="footnote-ref" href="#vonmentz2009"> [vonmentz2009] </a><a class="footnote-ref" href="#lockhart1991"> [lockhart1991] </a><a class="footnote-ref" href="#pizzigoni2007"> [pizzigoni2007] </a><a class="footnote-ref" href="#olko2013"> [olko2013] </a>. Historians have used such bureaucratic and legal documentation to track political, sociocultural and linguistic changes in Mesoamerica as a result of European colonialism, and to uncover regional and subregional variations of the language. They have done so by systematically assembling, transcribing, translating, cataloguing the characteristics of, and comparatively analyzing various corpora of Nahuatl documents. This methodology holds great promise for NECA. With transcriptions and translations — to date, an aspirational goal — we would be able to create a database of dialectal and other linguistic features, locations, genres, scribes&rsquo; names, year of creation, etc., which would surely yield new insights into the history of Nahuatl&rsquo;s diffusion, scribal and ecclesiastical networks, relationship to geography, and other avenues of future research.</p>
<p>Beyond philology, translations and transcriptions of the documents assembled by NECA would enrich the social history of the region. The vast majority of lives revealed are of non-native speakers of Nahuan languages: African urbanites, Oaxacan plantation workers, Maya choirmasters and cofradía officials, French merchants, and innumerous Indigenous political leaders: Mam, K&rsquo;iche&rsquo;, Tzeltal, Tojolabal, Jakalteko, Kaqchikel, etc. Contact points between friars, Spanish administrators, and local authorities are also plentiful in these documents. Family relations simmer underneath accusations of adultery, bigamy, and incest. Inventories and wills track the material culture of everyday life and the globalization of Mesoamerican commerce. Witchcraft, land and inheritance disputes, and the forced labor of women all make an appearance. The input of scholars and community members who may not have Nahuan language skills but who bring deep expertise in Mayan and Central American history, anthropology, archaeology, geography, and art history is crucial for contextualizing such information and incorporating it into larger narratives.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<p>To our assertion of NECA&rsquo;s potential for advancing Nahuan linguistics and Central American history, we add the possibility of supporting Nawat revitalization efforts in El Salvador. Diverse and overlapping intercultural and intergenerational campaigns have been underway in that country since the early 2000s, including a “language nest” primary school immersion program<a class="footnote-ref" href="#lemus2018"> [lemus2018] </a>, university classes in Nawat as a second language (<a href="http://www.uca.edu.sv/escuela-de-idiomas/cursos-nahuat">http://www.uca.edu.sv/escuela-de-idiomas/cursos-nahuat</a>), regional initiatives such as <em>Tushik</em> (<a href="http://tushik.org/">http://tushik.org/</a>) and the Colectivo Tzunhejekat (<a href="https://www.facebook.com/Tzunhejekat">https://www.facebook.com/Tzunhejekat</a>), and social media hubs (;<a href="https://www.facebook.com/groups/33974937500">https://www.facebook.com/groups/33974937500/</a>). Increasing native speakers&rsquo; access to historical documents written in Indigenous languages has proven valuable in other revitalization and decolonization efforts, from the workshop-and-publication model in the Polish-Mexican project <em>Revitalizing Indigenous Languages</em> <a class="footnote-ref" href="#olko2014"> [olko2014] </a>to the <em>Ticha</em> digital archive of historical Zapotec documents from Oaxaca discussed by Broadwell et al. in this special issue (<a href="https://ticha.haverford.edu/en">https://ticha.haverford.edu/en</a>).</p>
<p>Preliminary discussions with Salvadorans involved in Nawat revitalization indicate that while there may be a place for NECA in the future, for now the urgency of recording and promoting modern Nawat overshadows interest in historical documents. How NECA might contribute to Nawat revitalization is uncertain, in part, because the linguistic identification of so many of our documents remains unclear and the majority are from Guatemala, where Nawat was historically spoken but is no longer. Again, further study via transcriptions and translations is needed in order to clarify how the NECA corpus may speak to the case of Salvadoran Nawat. In the meantime, we hope that NECA&rsquo;s expression of international scholarly interest in Central American Nahuan languages, free access to downloadable, high-quality images of colonial-era documents for anyone with an internet connection, and public witness to the long history of Nawat in El Salvador stands as a one more “symbol of cultural identity and pride &hellip; [the] first step in any language revitalization process” <a class="footnote-ref" href="#lemus2008"> [lemus2008] </a>.</p>
<h2 id="the-form-going-digital">The Form: Going Digital</h2>
<p>NECA began with a list of over 40 documents compiled by Sergio Romero (University of Texas at Austin) and Laura Matthew (Marquette University), in collaboration with a dozen other colleagues, for an encyclopedia project that never materialized. As Romero and Matthew sought alternate ways to publish the list, new items continued to surface. It became clear that given the number of Nahuan language documents that go unrecorded in archive catalogs and the extent to which scholars tend to run across them unexpectedly, the list could easily grow longer and a traditional print publication would quickly become outdated. Simply posting the list online might stimulate interest, but the need to travel to physical archives represented a significant barrier to serious engagement since those with the most capacity to read early modern manuscripts in Nahuan languages tend not to live or work in Guatemala and Chiapas, where the main repositories of NECA&rsquo;s documents are located. Working with programmer Michael Bannister, and with permission from the original repositories, Matthew decided in 2015 to create a digital archive of high-quality images using Omeka, the popular open-source content management system for digital collections from the Roy Rosenzweig Center for History and New Media (CHNM) at George Mason University. For the remainder of this essay,werefers to Matthew and Bannister as the sole creators and curators of NECA.</p>
<p>Our first curatorial decision was conceptual: to restrict the archive&rsquo;s geographical range to Central America as defined by colonial-era administrative boundaries. This meant including documents from Chiapas but not from neighboring and similarly multilingual places like Oaxaca, where Nahuatl also functioned as a vehicularlingua franca<a class="footnote-ref" href="#terraciano2001"> [terraciano2001] </a><a class="footnote-ref" href="#swanton2008"> [swanton2008] </a>. Segregating Oaxaca from Central America seemed in some ways artificial and over-determined by the same national, academic, and disciplinary boundaries NECA aspires to overcome. But such boundaries are both real and significant. At a practical level, we accumulated items from Chiapas but not Oaxaca by default, because Chiapas’s colonial records were sent to the judicial Audiencia of Guatemala while Oaxaca&rsquo;s were sent to Mexico. Linguistically speaking, a Central American focus also directed attention to the contact points between Mayan and Nahuan languages. We did not want the Central American material to be prematurely absorbed into the considerably more developed academic literature on Nahuatl in Oaxaca and elsewhere in Mexico, without a proper understanding of the local contexts that produced it.</p>
<p>We also took seriously Justyna Olko&rsquo;s and John Sullivan&rsquo;s assertion that “more research on this topic [of local and regional differences and their relation to standardization] is greatly needed; especially useful would be a systematic comparison between regions as well as between higher and lower-ranking scribes/authors within a given locality” <a class="footnote-ref" href="#olko2013"> [olko2013] </a>. A distinctly Central American corpus creates the possibility of comparative study with data sets from other multilingual, borderland, and outlying regions where Nahuatl was and is spoken, such as Oaxaca, Jalisco, Veracruz, and Guerrero<a class="footnote-ref" href="#canger2017"> [canger2017] </a><a class="footnote-ref" href="#olko2014"> [olko2014] </a><a class="footnote-ref" href="#guion2010"> [guion2010] </a><a class="footnote-ref" href="#yanezrosales2017"> [yanezrosales2017] </a>. Finally, by drawing a line around Central America we hoped to direct attention towards and raise awareness of the ongoing, severely underfunded, but multi-pronged efforts to revitalize Nawat in El Salvador.</p>
<p>As we began to build the site, created and solicited feedback from an advisory board, and presented at conferences in the United States, Guatemala, and El Salvador, overlapping and mismatched interests in the NECA corpus became increasingly apparent. Historians, anthropologists, and archaeologists working in Central America were enthusiastic about sharing their archival references and interested in the information the documents contained, which they often could not read. Linguists and philologists working primarily in Mexico were interested in the dialectal features of the documents but were unfamiliar with their Central American context and history. Scholars and activists working on Nahuan languages in Central America expressed interest but lacked the financial and human resources to engage NECA without diverting valuable attention from existing projects, especially those supporting revitalization of Nawat in El Salvador.</p>
<p>We began to think about how NECA’s structure could more actively facilitate communication across these disciplinary, regional, and national borders. Unlocking the information inside the documents would be the essential first step for any kind of macro-analysis of the entire corpus, computational or otherwise, and for connecting scholars with similar interests and complementary skills. Could we help scholars find not just the documents, but each other? Could we create an online workspace that encouraged scholars to share their expertise and begin to generate data for comparative and collaborative analysis? Taking inspiration from crowdsourcing projects such as <em>Colored Conventions</em> (which has since retired this feature) (<a href="https://web.archive.org/web/20150322130256/http:/coloredconventions.org">https://web.archive.org/web/20150322130256/http://coloredconventions.org</a>) and <em>DIY History</em> (<a href="https://diyhistory.lib.uiowa.edu/">https://diyhistory.lib.uiowa.edu</a>), we added the transcription plugin Scripto, and created anAdd a Documentfeature using a Simple Contact Form plugin to encourage contributions of new documents. A separate, linked Wordpress site (<a href="https://nahuatlnawat.wordpress.com/">https://nahuatlnawat.wordpress.com</a>) became the project blog and discussion space.</p>
<p>The backbone of Omeka is the items list, supported by Dublin Core-based metadata. Most metadata elements are obvious: date, title, source, etc. Nevertheless, each element reflects a curatorial decision made by us with certain goals in mind. We added new metadata elements for the number offoliosto emphasize the variety and extent of the corpus, and for at-a-glance decisions by users about whether or not to transcribe;sample textto spark the potential transcriber&rsquo;s and/or translator&rsquo;s interest;locationwith the modern countries, states, and/or departments in addition to the colonial-era information to allow for sub-regional searches and future experiments in mapping;date of creationof the item itself to keep a record of the corpus&rsquo;s growth; and thecontributorof the document in order to acknowledge her or his research and participation.</p>
<p>Metadata omissions also reveal the synergy between form, content, and curation. A primary goal of NECA is to encourage the linguistic study of a larger corpus of Nahuan documents from Central America than usual, and eventually to gather the results in a database of linguistic features for comparative analysis. Some of our documents conform to a single, clear Nahuan variant. Most, however, present a mix of attributes, as one might expect of writing produced by non-native speakers in a context of ongoing (or decreasing) standardization, colonial power dynamics, and the adoption by Indigenous people of foreign writing technologies. This linguistic heterogeneity makes the NECA corpus an exceedingly valuable resource for exploring the history of Nahuan languages at linguistic borderlands<a class="footnote-ref" href="#madajczak2016"> [madajczak2016] </a>. We chose not to create a metadata element that prematurely assigned the documents a reductive linguistic label until we have more data through transcription and analysis. We also wanted to avoid a situation in which non-linguists might interpret such labels as more definitive than they really are.</p>
<p>Decisions about the items themselves predetermine what researchers can and cannot do with them. Most of NECA&rsquo;s items are fragments within larger documents — sometimes, much larger. On a mostly non-existent budget, we faced issues of server space, labor, and funding: photographers require payment, repositories may charge publication fees. Additionally, in this first iteration of the project we were focused on access and translation. We therefore chose to publish only the Nahuatl portions of any given document, for both practical reasons and in order to attract Nahuatl translators. This decision has consequences. For better or worse, it denies the user access to any Spanish translation that might have appeared in the original document. It also separates the fragment from its larger documentary context, digitally replicating the same de-contextualization that has been suffered by many Mayan-language documents. A fuller understanding of the document&rsquo;s creation and information can only be achieved by consulting the original document in relation to its archival context. Data sets of people, places, and other kinds of information contained in the digital archive — for instance, paying attention to geographical location or scribal networks — will also remain incomplete without access to the full original. Researchers will have to return to the physical archives in order to get the whole picture, and we run the danger that they will not<a class="footnote-ref" href="#putnam2016"> [putnam2016] </a>.</p>
<p>Finally, anticipating the user experience led to some programming alterations. Omeka&rsquo;s automatically generated citations omitted the original archive; we changed the code to cite the document&rsquo;s physical repository and archival signature first, followed by NECA and the date of access. To guide users towards specific activities, we turned Omeka&rsquo;sfeatured itemsinto asample transcriptionandfeatured collectionsintodocument teams.Omeka&rsquo;s built-in internationalization combined with the plugin Locale Switcher made the site bilingual, allowing users to choose in real time whether to view the site in Spanish or English. Because we had significantly altered the standard Omeka framework with new navigation headings, metadata categories, etc., Spanish versions had to be added to the internationalization code, as did all Spanish translations of all the text within the transcription tool Scripto. However, these changes affected only the user interface, not the items&rsquo; metadata. Assuming that most of our users would be competent in Spanish but not necessarily in English, we decided to make Spanish the primary language of the site (and in doing so, officially baptized it as NECA: in Spanish, <em>El Náhuatl/náhuat en Centroamérica</em> ). All metadata is in Spanish regardless of the interface language, and simple pages unaffected by the plugin privilege Spanish at the top with anchors to an English translation below.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Home page of NECA, a simple page with stable Spanish and anchored English translation, plus English navigation and sidebar headings that can be changed to Spanish with a click of the flag. The metadata of the items, seen here in the right-hand sidebar underSample Transcription,is always in Spanish. A video on the revitalization/language nest program “Cuna Náhuat” from El Salvador is featured at the top of the sidebar.
        </p>
    </figcaption>
</figure>
<p>At every structural opportunity we emphasized the collaborative, open nature of the project and minimized our own gatekeeping. Conversations during beta testing between anthropologist Janine Gasco and historians Julia Madajczak and Agnieszka Brylak inspired us to create mechanisms for interdisciplinary document teams to work on single items. Contributors of new citations are individually added to theAbout Uspage as well as to their items&rsquo; metadata. Transcribers and translators are encouraged to register for Scripto with their full name so they can be properly identified in the versioning of transcriptions and translations and credited in future publications, as we require under our Creative Commons Attribution-Non Commercial 3.0 U.S. license. NECA is not a crowdsourcing project, but it does invite researchers to share their documents, modernnahuatlatosto share their translations, and academics and community members to share their ideas transnationally and interdisciplinarily. Through its design, the website attempts to make the case that this is worth everyone&rsquo;s while.</p>
<h2 id="the-form-of-the-content-if-we-build-it-will-they-come">The Form of the Content: If We Build It, Will They Come?</h2>
<p>Archival research and the transcription and translation of idiosyncratic documents written in difficult handwriting, often in foreign languages, requires patience, time, resources, and above all, advanced skills that accrue over the years. Doctoral degrees, job offers, tenure, and future funding depend on demonstrating the fruits of this individual labor. There is nothing wrong with claiming the privacy to work, and what we have labeleddocument teamsin NECA can also form via email, conferences, special journal issues, and edited volumes. If NECA&rsquo;s first iteration – the digital archive – produces a flurry of new publications and dissertations created outside our platform, this will be a positive result.</p>
<p>NECA nevertheless encourages scholars to go beyond individual documents and to work beyond their comfort zones. It identifies common research interests across disciplines and national and academic communities, and presents the opportunity to share citations, translations, and knowledge in a public forum; to compare notes online; and eventually, given transcriptions and translations, to create databases, analyze the corpus as a whole, and experiment with different digital and computational tools. The NECA corpus is large and geographically varied enough to reveal not only the dialectal features of Nahuan languages in Central America, but also the documents’ production related to colonial settlement, ecclesiastical influence, social and political networks, the economy, and geography. We see great future value, especially, in thinking through NECA’s data using spatial analysis and mapping tools. Bringing linguists and translators of Nahuatl together with non-nahuatlatoscholars of Central America has the potential to advance all this research further, faster. We built NECA to nudge people in this collaborative direction. The question is, will they come?</p>
<p>So far, the answer is yes and no. NECA&rsquo;s analytics from Reclaim Hosting show that since the digital archive went online in July 2016, it has received the most intensive and consistent use (measured by bandwidth used, the ratio of pages to hits, and annual location data) from Mexico, El Salvador, and Guatemala, as well as Spain, Germany, Poland, and France in Europe — the last three being major centers of Mesoamerican and Nahuatl studies — and the United States, Brazil, and Canada in the Americas. Presentations at the University of Texas at Austin in March 2017, the Congreso de Estudios Mayas in Guatemala City in July 2017, the Asociación Centroamericana de Lingüística annual meeting in San Salvador in August 2017, the American Historical Association annual meeting in January 2018, and the Sociedad Mexicana de Historiografía Lingüística in Mexico City in October 2018, each produced temporary bumps in the number of unique visitors and/or intensity of use, which then tapered off. The Austin presentation acted as an official launch of the project with the power of social media behind it, resulting in an eighteen-fold increase in unique visitors immediately afterwards (March-April 2017). Subsequent presentations in Guatemala and El Salvador produced the most remarkable user data in the site&rsquo;s history thus far. In the two months following (July-August 2017) — and with no official social media push — the number of unique visitors to the site quadrupled. More importantly, the bandwidth and pages-to-hits ratio indicated significantly more searching through the site&rsquo;s most complex pages, such as those containing document images, than after the Austin presentation. The Central Americans&rsquo; more intensive use is visible in the contrast between their relatively low number of unique visitors (yellow) relative to pages, hits, and bandwidth (blue and green):</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Usage data for NECA, 2017.
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Top user locales for NECA, 2017.
        </p>
    </figcaption>
</figure>
<p>From 2016 through 2018, the United States and Ukraine generated most of the site’s hundreds of thousands of page views, 75% of which lasted thirty seconds or less. Presumably, a large portion of these were bots. The next largest proportions of visits, however, lasted for over one hour (around 8%), thirty minutes to an hour (around 6%), and fifteen to thirty minutes (around 4%), suggesting that a significant minority of users were seriously engaging the site. Notably, when we ceased to actively promote the site in 2019 we saw a drop in unique visitors, a consistent narrowing of the pages-to-hits ratio indicating shallower exploration of the site, and 88% of visits lasting less than thirty seconds. (For the first time, a large number of such visits in 2019 came from the Netherlands, bumping Ukraine to third place in theprobably a botcategory). Nevertheless, in 2019 the most intensive users — those spending thirty minutes to over an hour on the site at a time — still constituted our next largest user group, or 7% of the total number of visits.</p>
<p>As a digital archive, therefore, NECA is doing reasonably well even when we do not take advantage of conferences, social media, and other means to publicize and promote it. As an online platform for collaborative transcription, it has been less successful. A few people have used theAdd a Documentfeature to provide new citations and high-quality images, but most of the 19 new documents added since the site’s inception have come from our own research or direct outreach. The same is true of the Discussion area, where invited essays by Janine Gasco on Nahuan agricultural terms in the Soconusco and by Adriana Álvarez on Nahuatl instruction at the Universidad de San Carlos in Guatemala have generated a handful of comments from community members mostly from El Salvador or of Salvadoran descent in the United States, but no serious scholarly engagement, without which we cannot move forward to better understand why, how, or to whom these documents might be important.</p>
<p>The document teams and Scripto&rsquo;s transcription tool have attracted no users at all since beta testing in March 2017. This may be a design issue. This first iteration of NECA is based on a pre-designed Omeka platform and utilizes only the Scripto features made available through the plug-in. Certainly we could improve the transcription and translation tool to be more appealing and effective, including a simpler user interface, better versioning, an improved commenting feature that identifies the user and is always visible, side-by-side images and workspace, progress bars, and the ability to toggle between transcriptions, translations, and versioning on a single page. The features and functionality of the transcription tool at the <em>Codex Aubin</em> project, hosted on software developer Ben Brumfield&rsquo;s transcription platform FromThePage based on Ruby on Rails (<a href="https://fromthepage.com/">https://fromthepage.com</a>), are exemplary (<a href="https://fromthepage.ace.fordham.edu/benwbrum/codex-aubin">https://fromthepage.ace.fordham.edu/benwbrum/codex-aubin</a>), as is the transcription and search tool created for the <em>Freedom on the Move</em> project (<a href="https://freedomonthemove.org/index.html">https://freedomonthemove.org/index.html</a>). Other projects with more user-friendly transcription workspaces than NECA include the Newberry Library&rsquo;s <em>Newberry Transcribes</em> (<a href="https://publications.newberry.org/digital/mms-transcribe/index">https://publications.newberry.org/digital/mms-transcribe/index</a>) and Maynooth University&rsquo;s <em>Letters 1916-1923</em> (<a href="http://letters1916.maynoothuniversity.ie/learn">http://letters1916.maynoothuniversity.ie/learn</a>), both of which are based on Omeka and Scripto.</p>
<p>How the digital archive&rsquo;s form can encourage engagement with its content is not, however, only a design issue. The most successful transcription projects come from outward-facing institutions digitizing items from their physical archives and making them available tocitizen humanistswith the clear goal of public engagement — for instance (among many other examples), the Smithsonian Institution&rsquo;s <em>Digital Volunteers</em> initiative (<a href="https://transcription.si.edu/">https://transcription.si.edu</a>) and the Library of Virginia&rsquo;s <em>Making History</em> project (<a href="http://www.virginiamemory.com/transcribe">http://www.virginiamemory.com/transcribe</a>). Often, featured collections are chosen with audience interest and capabilities in mind. The Stanford University Archives (<a href="https://library.stanford.edu/spc/university-archives">https://library.stanford.edu/spc/university-archives</a>), for example, invites online transcription of manuscripts related to the university&rsquo;s history, in English. Broad or targeted appeal of the subject matter, readability of the documents, and language accessibility seem equally relevant to the success of the aforementioned <em>Freedom on the Move Project</em> , which crowdsources transcriptions of mostly English, printed newspaper announcements of rewards for runaway African American slaves; <em>Newberry Transcribes</em> , which presents mostly English-language diaries and letters about family life in the Midwest; and the narrower but commemorative <em>Letters 1916-1923</em> , which invites visitors to submit and transcribe their own family&rsquo;s documents for upcoming anniversaries of the Easter Rising, World War I, and the Irish War of Independence and Civil War.</p>
<p>A search through the transcription platform FromThePage&rsquo;s various collections suggests that more academic projects often involve fewer participants, especially where handwritten manuscripts from earlier time periods with idiosyncratic paleography in languages other than English are concerned. Online transcription in these circumstances seems to work best as a collaboration tool between professors and students, or between small groups of colleagues with similar skills. This is the case of the <em>Codex Aubin</em> and <em>French from Outremer</em> (<a href="https://fromthepage.ace.fordham.edu/collection/show?collection_id=1">https://fromthepage.ace.fordham.edu/collection/show?collection_id=1</a>) projects from Fordham University, which deal with medieval and early modern manscripts in Nahuatl and French requiring highly specialized transcribers. Many digital archives of similarly challenging material rely entirely on professional teams and do not make collaborative online transcription tools available, for instance the <em>BFM - Base de Français Médiéval</em> (<a href="http://txm.bfm-corpus.org/">txm.bfm-corpus.org</a>), the <em>1641 Depositions Project</em> from Trinity College, Ireland (<a href="http://1641.tcd.ie/project.php">http://1641.tcd.ie/project.php</a>), and the <em>Native Northeast Research Collaborative</em> (<a href="https://www.thenativenortheast.org/">https://www.thenativenortheast.org</a>).</p>
<p>Comparing these projects, and NECA, to the <em>Ticha</em> project described in this issue by Broadwell et al. makes clear that the challenges faced by creators of digital archives are highly contingent. As a digital archive and online transcription platform for colonial-era texts in Zapotec languages from Oaxaca, <em>Ticha</em> encountered some of the same design limitations as NECA when using software such as Scripto and the Fieldworks Language Explorer (FLEx)<a class="footnote-ref" href="#broadwell2020"> [broadwell2020] </a><a class="footnote-ref" href="#broadwell2013"> [broadwell2013] </a>. <em>Ticha</em> was aided by the fact that the interests of Zapotec speakers and scholars, ethnohistorians, and linguists converged on the same region and language, as opposed to the criss-crossing and sometimes conflicting interests faced by NECA. However, <em>Ticha</em> is also a powerful example of what sustained attention to the human side of digital projects — conferences and workshops, acceptance and accommodation of a wide range of user communities, and outreach especially to non-academic stakeholders, in this case native speakers of Indigenous and minority languages — can achieve.</p>
<p>To re-design the weakest link of NECA, its transcription tool, would require at minimum a switch from the current pre-designed website and/or outsourcing of the tool, and possibly changing from WikiMedia to a standalone database. It is not clear that, at this stage of the project, the effort would be worth it. While some have expressed interest in using the site as a teaching tool for advanced students who are simultaneously learning Nahuatl and paleography, there is no way to know whether this is happening. Likewise, if more established scholars are working with documents from NECA, they are doing outside the context of the site. At a practical level, scholars may find online transcription and translation, which requires working within the confines of the program and/or between multiple formats, less efficient than traditional methods. They may also appreciate opportunities for face-to-face discussion prior to performing their work online. Scholarship is risky and takes time. Sturdy, creative collaborations between people who have not traditionally worked together — such as the local, national, disciplinary, and academic networks that have expressed interest in NECA yet remain siloed from each other — may initially develop better in person. Rather than immediately overhauling the site or the transcription tool, a better next step for NECA may be more old-fashioned: to convene scholars and community members in different combinations and venues, with the goal of creating collaborative teams and identifying viable research questions and interests in common.</p>
<p>Digital humanities promises more than a new marriage between mathematical, qualitative, and design methodologies and tools. It also proposes a paradigmatic change in how scholars collaborate, flattening research and/or learning communities and vaunting an idealized, non-hierarchical community where people willingly share their research, promote interdisciplinarity, and work in teams of members with complementary skills sets, none of which is seen as more important than another. Despite the ways in which this mimics Silicon Valley-ese (rightly criticized for its hypocrisy), there is much to hold onto here: the potential of digital humanities to communicate with broader publics, to democratize the production of knowledge, to make the fruits of scholarship more accessible, and to make us all more flexible thinkers. As NECA argues, digital archives also have the potential to push scholarship in certain directions by calling attention to understudied texts or problematics and by making the materials for studying them available.</p>
<p>But the digital humanities’ optimistic, even utopian view of the scholarly workplace is tinged with disciplinary, financial, and intergenerational anxieties. In the United States, humanities scholars of all stripes fear the devaluation of their work in the information age. The younger generation faces an increasingly freelance economy and shrinking humanities job market from the peculiar position of being simultaneously valued for their digital savvy (writing code, understanding algorithms, managing project teams, marketing their work), expected to be innovators and jacks-of-all-trades, and suspected of not doing the kinds of specialized research that got their professorly elders tenure. Established scholars are suspected of lagging behind the digital turn, but have more freedom to experiment with digital tools — or not — with far less risk to their future careers. They are also the gatekeepers of the academy.</p>
<p>It is therefore incumbent upon senior scholars, especially, to ponder the lessons of creative failure in digital humanities projects. NECA shows the potential for digital archiving to turn a wide range of people&rsquo;s attention towards a particular corpus of historical documentation and set of questions. NECA also highlights the difficulty of attracting scholars to skills-intensive transcription and translation online in collaborative projects without prior commitments, goals, and relationships in common. While we maintain the first iteration of the NECA digital archive, our next best step for transcription and translation — the necessary building blocks of any future database — will involve human, not digital, development: recruiting and funding new team members, acquiring grant money to pay for skilled transcriptions and translations, and organizing conferences. With data in hand and new ideas on the table, we can start to contemplate smaller, more limited digital tools — what Rockwell and Sinclair [<a href="#rockwell2016">2016</a>] call “embeddable toys” — for scholars to play with, exploring what value computation might bring to the analysis of the entire NECA corpus. To move forward we must forcefully argue for the funding of <em>both</em> methods of scholarship, digital and traditional, most especially for those who will be the generators, guardians, and teachers of Nahuatl and Nawat in the future.</p>
<ul>
<li id="alvarezsanchez2014">Álvarez Sánchez, A. _Patronazgo y educación. Los proyectos y la fundación de la Real Universidad de San Carlos de Guatemala. (1619-1687)_ . FFyL-UNAM, Mexico (2014).
</li>
<li id="arroyo2014">Arroyo, B. “Mesa redonda sobre arqueología tardía de la Costa Sur: Discusión” . In _XVIII Simposio de Investigaciones Arqueológicas en Guatemala_ , eds. J. P. LaPorte, B. Arroyo, and H. E. Mejía, No. 99. Museo Nacional de Arqueología y Etnología, Guatemala (2014).
</li>
<li id="arauz1960">Aráuz, P. _El Pipil de la Región de los Itzalcos_ . Ministerio de Cultura, San Salvador (1960).
</li>
<li id="bonta2009">Bonta, M. “The dilemma of indigenous identity construction: the case of the newly recognized Nahoa of Olancho, Honduras” . In _Temas de Geografía Latinoamericana: Reunión CLAG-Morelia_ , eds. P. S. Urquijo Torres and N. Barrera-Bassols. Universidad Nacional Autónoma de México-Centro de Investigaciones en Geografía Ambiental, Morelia (2009), pp. 49-86.
</li>
<li id="borg1985">Borg, P. “The polyphonic music in the Guatemalan music manuscripts of the Lilly Library” . Ph.D. dissertation, Indiana University (1985).
</li>
<li id="brinton1883">Brinton, D. G. _The Güegüence: A comedy ballet in the Nahuatl-Spanish dialect of Nicaragua_ . D. G. Brinton, Philadelphia (1883)
</li>
<li id="broadwell2013">Broadwell, G. and B. D. Lillehaugen. “Considerations in the Creation of an Electronic Database for Colonial Valley Zapotec” . _International Journal of LASSO_ 12, 2 (2013): 77-110
</li>
<li id="broadwell2020">Broadwell, G., García, M., Lillehaugen, B., Lopez, F., Plumb, M, Zarafonetis, M. “Ticha: Collaboration with indigenous communities to build digital resources on Zapotec language and history” . _Digital Humanities Quarterly_ , 14:4 (2020),<a href="http://www.digitalhumanities.org/dhq/editorial/000529/000529.html">http://www.digitalhumanities.org/dhq/editorial/000529/000529.html</a>.
</li>
<li id="burkhart2011">Burkhart, L. _Aztecs on Stage: Religious Theater in Colonial Mexico_ . University of Oklahoma Press, Norman (2011).
</li>
<li id="campbell1985">Campbell, L. _The Pipil Language of El Salvador_ . De Gruyter, Berlin (1985).
</li>
<li id="canger2017">Canger, U. “A Nawatl Dialect with a Shallow History” . Unpublished paper,<a href="https://www.researchgate.net/publication/317887931_A_Nawatl_Dialect_with_a_Shallow_History_or_Is_the_Nawatl_dialect_area_known_as_the_Western_Periphery_a_True_Dialect_area_2017">https://www.researchgate.net/publication/317887931_A_Nawatl_Dialect_with_a_Shallow_History_or_Is_the_Nawatl_dialect_area_known_as_the_Western_Periphery_a_True_Dialect_area_2017</a>, accessed June 15, 2018.
</li>
<li id="canger2011">Canger, U. “El nauatl urbano de Tlatelolco/Tenochtitlan, resultado de convergencia entre dialectos. Con un esbozo brevísimo de la historia de los dialectos” . _Estudios de cultura náhuatl_ 42 (2011): 243-258.
</li>
<li id="canger1988">Canger, U. “Nahuatl Dialectology: A Survey and Some Suggestions” . _International Journal of American Linguistics_ 54 (1988): 28-73.
</li>
<li id="carrasco1999">Carrasco, P. _The Tenochca Empire of Ancient Mexico: The Triple Alliance of Tenochtitlan, Tetzcoco, and Tlacopan_ . University of Oklahoma Press, Norman (1999).
</li>
<li id="christensen2013">Christensen, M. _Nahua and Maya Catholicisms: Texts and Religion in Colonial Central Mexico and Yucatan_ . Stanford University Press, Stanford (2013).
</li>
<li id="cossich2012">Cossich Vielman, M. “Escritura logo-silábica en los códices del Centro de México del siglo xvi y su importancia para el desciframiento de la escritura nahua no azteca de Centroamérica” . In _Las edades del libro_ , Gravier, M. G., Russell, I. G., and Godinas, L. eds. UNAM, Mexico (2012).
</li>
<li id="dakin2009">Dakin, K. “Algunos documentos nahuas del sur de Mesoamérica” . In _Visiones del Encuentro de Dos Mundos en América: Lengua, Cultura, Traducción y Transculturación_ , Dakin, D., Montes de Oca, M., and Parodi, C., eds. Universidad Nacional Autónoma de México-Insituto de Investigaciones Filológicas/Universidad de California-Centro de Estudios Coloniales Iberoamericanos, México/Los Angeles (2009), pp. 247-270.
</li>
<li id="dakin2010a">Dakin, K. “Lenguas francas y lenguas locales en la epoca prehispánica” . In _Historia sociolingüística de México_ , Barriga Villanueva, R. and Butragueño, P. M., eds. El Colegio de México, Mexico (2010), pp. 161-183.
</li>
<li id="dakin2010b">Dakin, K. “Linguistic Evidence for Historical Contacts between Nahuas and Northern Lowland Mayan Speakers” . In _Astronomers, Scribes, and Priests: Cultural Interchange between the Northern Maya Lowlands and Highland Mexico in the Late Postclassic Period_ , Vail, G. and Hernández, C., eds. Dumbarton Oaks, Washington DC, pp. 217-40.
</li>
<li id="dakin1996">Dakin, K. and Lutz, C. _Nuestro pesar, nuestra aflicción tunetuliniliz, tucucuca: Memorias en lengua Nahuatl enviadas a Felipe II por indígenas del Valle de Guatemala hacia 1572_ . UNAM/Centro de Investigaciones Regionales de Mesoamérica, México/Guatemala (1996).
</li>
<li id="dakin1985">Dakin, K. and Canger, U. “An Inconspicuous Basic Split in Nahuatl” . _International Journal of American Linguistics_ 51,4 (Oct 1985): 358-361.
</li>
<li id="doesburg2008">Doesburg, S van. and Swanton, M. W. “La traducción de la 'Doctrina Cristiana en Lengua Mixteca de Fray Benito Hernández al chocholteco (ngiwa)” . In _Conferencias sobre lenguas otomanges y oaxaqueños_ , Vol. 2, López Cruz, A. and Swanton, M., eds. Colegio Superior para la Educación Integral Intercultural de Oaxaca/Instituto Nacional de Lenguas Indígenas/Universidad Autónoma Benito Juárez de Oaxaca/Fundación Alfredo Harp Helú Oaxaca, Oaxaca (2008), pp. 81-117.
</li>
<li id="escalanteacre2001">Escalante Arce, P. _Los Tlaxcaltecas en Centro América_ . Dirección de Publicaciones e Impresos, San Salvador (2001).
</li>
<li id="fowler1989">Fowler, W. _The Cultural Evolution of Ancient Nahua Civilizations_ . University of Oklahoma Press, Norman (1989).
</li>
<li id="gasco2017">Gasco, J. “Cacao and Commerce in Late Postclassic Xoconochco” . In _Rethinking the Aztec Economy_ , Nichols, D. and Berdan, F. F., eds. University of Arizona Press, Tucson (2017), pp. 221-247.
</li>
<li id="gasco2016">Gasco, J. “Linguistic Patterns, Material Culture, and Identity in Late Postclassic to Postcolonial Soconusco” . In _Archaeology and Identity on the Pacific Coast and Southern Highlands of Mesoamerica_ , García-DesLauriers, C. and Love, M., eds. University of Utah Press, Salt Lake City (2016), pp. 126-141.
</li>
<li id="gould2008">Gould, J. and Lauria-Santiago, A. _To Rise in Darkness: Revolution, Repression, and Memory in El Salvador, 1920-1932_ . Duke University Press, Durham (2008).
</li>
<li id="guion2010">Guion, S, Amith, J., Doty, C. and and Shport, I. “Word-level prosody in Balsas Nahuatl: The origin, development, and acoustiv correlates of tone in a stress accent language” . _Journal of Phonetics_ 38 (2010): 137-166.
</li>
<li id="hansen2016">Hansen, M. P. “How to spell Nahuatl? Nawatl? Nauatl?”  _Nahuatl Studies_ (blog), July 26, 2016<a href="http://nahuatlstudies.blogspot.com/2016/07/how-to-spell-nahuatl-nawatl-nauatl.html">http://nahuatlstudies.blogspot.com/2016/07/how-to-spell-nahuatl-nawatl-nauatl.html</a>, accessed June 15, 2018.
</li>
<li id="hansen2014"> “The East-West split in Nahuan Dialectology: Reviewing the Evidence and Consolidating the Grouping” . Friends of Uto-Aztecan Workshop, Universidad Autónoma de Nayarit. 20 June 2014.
</li>
<li id="herranz2001">Herranz, A. _Estado, sociedad, y lenguaje: La política lingüística en Honduras_ . Editorial Guaymuras, Tegucigalpa (2001).
</li>
<li id="herrera2003">Herrera, R. _Natives, Europeans, and Africans in Sixteenth-Century Santiago de Guatemala_ . University of Texas Press, Austin (2003).
</li>
<li id="knab1980">Knab, T. “Lenguas del Soconusco, pipil y náhuatl de Huehuetán” . _Estudios de cultura náhuatl_ 14 (1980): 375-378.
</li>
<li id="laramartinez2015">Lara Martínez, R. _Artes de la lengua náhuat-pipil (Estudios lingüísticos)_ . Universidad Don Bosco, San Salvador (2015).
</li>
<li id="laramartinez2014">Lara Martínez, R.l and Maccallister, R. _Glosario cultural Pipil-Nicarao, El Güegüense y Mitos en la lengua materna_ . Editorial Universidad Don Bosco, San Salvador (2014).
</li>
<li id="lemus2004">Lemus, J. “El pueblo pipil y su lengua” . _Científica_ 4,5 (Junio 2004): 7-28.
</li>
<li id="lemus2008">Lemus, J. “Un modelo de revitalización lingüística: el caso de náhuat/pipil de El Salvado” r. In _Identità delle Comunità Indigene del Centro America, Messico e Caraibi_ , Palmisano, A. L., ed. Istituto Italo-Americano, Trieste (2008), pp. 127-149.
</li>
<li id="lemus2018">Lemus, J. “Revitalizing Pipil: The Cuna Nahuat Experience” . In _The Routledge Handbook of Language Revitalization_ , eds. Hinton, L., Huss, L., and Roche, G. Routledge, New York (2018), pp. 395-405.
</li>
<li id="lindo-fuentes2007">Lindo-Fuentes, H., Ching, E., and Lara Martínez, R. _Remembering a Massacre in El Salvador: The Insurrection of 1932, Roque Dalton, and the Politics of Historical Memory_ . University of New Mexico Press, Albuquerque (2007).
</li>
<li id="lockhart1991">Lockhart, J. _The Nahuas After the Conquest: A Social and Cultural History of the Indians of Central Mexico, Sixteenth Through Eighteenth Centuries_ . Stanford University Press, Stanford (1991).
</li>
<li id="lokken2000">Lokken, P. “From Black to Ladino: People of African Descent, Mestizaje, and Racial Hierarchy in Rural Colonial Guatemala, 1600–1730” . Ph.D. thesis., University of Florida (2000).
</li>
<li id="lopezaustin2000">López Austin, A. and López Luján, L. “The Myth and Reality of Zuyuá: The Feathered Serpent and Mesoamerican Transformations from the Classic to the Postclassic” . In Carrasco, D., Jones, L. and Sessions, S., eds., _Mesoamerica’s Classic Heritage: From Teotihuacan to the Aztecs_ . University Press of Colorado, Boulder (2000), pp. 21-84.
</li>
<li id="luhanmunoz1988">Luján Muñoz, J. _Agricultura, mercado, y sociedad en el corregimiento del Valle de Guatemala, 1670–80_ . Universidad de San Carlos Cuadernos de Investigación, Guatemala (1988).
</li>
<li id="lutz1994">Lutz, C. _Santiago de Guatemala, 1541–1773: City, Caste, and the Colonial Experience_ . University of Oklahoma Press, Norman (1994).
</li>
<li id="madajczak2016">Madajczak, J. and Hansen, M. P. “Teotamachilizti: An analysis of the language in a Nahua sermon from colonial Guatemala” . _Colonial Latin American Review_ 25, 22 (2016): 220-244.
</li>
<li id="matthew2012a">Matthew, L. _Memories of Conquest: Becoming Mexicano in Colonial Guatemala_ . University of North Carolina Press, Chapel Hill (2012).
</li>
<li id="matthew2012b">Matthew, L. and Romero, S. “Nahuatl and Pipil in Colonial Guatemala: A Central American Counterpoint” . _Ethnohistory_ 59,4 (2012): 765-783.
</li>
<li id="mccafferty2015">McCafferty, G. “The Mexican Legacy in Nicaragua, or Problems when Data Behave Badly” . _Archaeological Papers of the American Anthropological Association_ , 25 (2015): 110-118.
</li>
<li id="mcdonough2014">McDonough, K. S. _The Learned Ones: Nahua Intellectuals in Postconquest Mexico_ . University of Arizona Press, Tucson (2014).
</li>
<li id="vonmentz2009">von Mentz, B. “Cambio social y cambio lingüísitico: El náhuatl cotidiano, el de doctrina, y el de escribanía en Cuauhnáhuac entre 1540 y 1671.” In _Visiones del Encuentro de Dos Mundos en América: Lengua, Cultura, Traducción y Transculturación_ , Dakin, K., Montes de Oca, M., and Parodi, C., eds.. Universidad Nacional Autónoma de México-Insituto de Investigaciones Filológicas/Universidad de California-Centro de Estudios Coloniales Iberoamericanos, México/Los Angeles (2009), pp. 111-146.
</li>
<li id="morales2015">Morales Abril, O. “A presença de música e músicos portugueses no vice-reinado da Nova Espanha e na província de Guatemala, nos séculos XVI-XVII” . _Revista Portuguesa de Musicologia_ , 2,1 (2015): 149-72.
</li>
<li id="navarrete1996">Navarrete, C. “Elementos arqueológicos de mexicanización en las tierras altas mayas” . In _Temas mesoamericanos_ , Lombardo, S. and Nalda, E., eds.. Instituto Nacional de Antropología e Historia, Mexico (1996), pp. 309-356.
</li>
<li id="navarrete1975">Navarrete, C. “Nueva información sobre la lengua náhuatl en Chiapas” . _Anales de Antropología_ 12,1 (1975): 273-283.
</li>
<li id="olko2013">Olko, J. and Sullivan, S. “Empire, Colony, and Globalization: A Brief History of the Nahuatl Language” . In _Colloquia humanistica: Minor Languages, Minor Literatures, Minor Cultures_ , Lukaszyk, E. and Chuszczewska, K., eds. Institute of Slavic Studies Polish Academy of Sciences, Warsaw (2013), pp. 181-216.
</li>
<li id="olko2014">Olko, J. and Sullivan, J. “Toward a Comprehensive Model for Nahuatl Language Research and Revitalization” . In _Proceedings of the Fortieth Annual Meeting of the Berkeley Linguistic Society_ , Leung, H. et al., eds. Berkeley Linguistic Society, Berkeley (2014), pp. 369-397.
</li>
<li id="pizzigoni2007">Pizzigoni, C. “Region and Subregion in Central Mexican Ethnohistory: The Toluca Valley, 1650–1760” . _Colonial Latin American Review_ 16,1 (2007): 71–92.
</li>
<li id="putnam2016">Putnam, L. “The Transnational and the Text-Searchable: Digitized Sources and the Shadows They Cast” . _American Historical Review_ 121, 2 (2016): 377-402.
</li>
<li id="restall2003">Restall, M. “A History of the New Philology and the New Philology in History” . _Latin American Research Review_ 38, 1 (2003): 113-134.
</li>
<li id="restall1997">Restall, M. _The Maya World: Yucatec Culture and Society, 1550-1850_ . Stanford University Press, Stanford (1997).
</li>
<li id="reyesgarcia1961">Reyes García, L. “Documentos nahoas sobre el Estado de Chiapas” , in _Los mayas del sur y sus relaciones con los nahuas meridionales, VIII Mesa Redonda de la Sociedad Mexicana de Antropología_ . Sociedad Mexicana de Antropología, Mexico (1961), pp. 67-93.
</li>
<li id="rivas1969">Rivas, P. _El Nawat de Cuscatlán: Apuntes para un gramática tentativa_ . Ministero de Educación, San Salvador (1969).
</li>
<li id="rockwell2016">Rockwell, G. and Sinclair, S. _Hermeneutica: Computer Assisted Interpretation in the Humanities_ . The MIT Press, Cambridge (2016).
</li>
<li id="romero2017">Romero, S. “Los manuscritos en náhuatl centroamericano y la historia cultural de Guatemala” . _Anales de la Academia de Geografía e Historia de Guatemala XCII_ (2017): 75-104.
</li>
<li id="romero2015">Romero, S. “Language, catechisms and Mesoamerican lords in Highland Guatemala: Addressing ‘God’ after the Spanish conquest” . _Ethnohistory_ 62, 3 (2015): 623-650.
</li>
<li id="romero2014a">Romero, S. “Grammar, dialectal variation and honorific registers in Nahuatl in 17th century Guatemala” . _Anthropological Linguistics_ 56, 1 (2014): 1-24.
</li>
<li id="romero2014b">Romero, S. and Cossich Vielman, M. “El Título de Santa María Ixhuatán: Un texto del siglo xvii en náhuatl centroamericano” . In _XXVIII Simposio de Investigaciones Arqueológicas en Guatemala_ , Arroyo, B., Méndez Salinas, L., and Paiz, L., eds. Museo Nacional de Arqueología y Etnología, Guatemala (2014), pp. 1231-1241.
</li>
<li id="sampeck2015">Sampeck, K. “Pipil Writing: An Archaeology of Prototypes and a Political Economy of Literacy” . _Ethnohistory_ 62, 3 (2015): 469-495.
</li>
<li id="sell2008">Sell, B., Burkhart, L., and Wright, E., eds. _Nahuatl Theater Vol. 3: Spanish Golden Age Drama in Mexican Translation_ . University of Oklahoma Press, Norman (2008).
</li>
<li id="stevenson1964">Stevenson, R. “European Music in Sixteenth-Century Guatemala” . _The Musical Quarterly_ 50, 3 (July 1964): 341-352.
</li>
<li id="sparks2017">Sparks, G., Sachse, F., and Romero, S. _The Americas' First Theologies: Early Sources of Post-Contact Indigenous Religion_ . Oxford University Press, New York (2017).
</li>
<li id="swanton2008">Swanton, M. “Multilingualism in the Tocuij Ñudzavui Region” . In _Mixtec Writing and Society/Escritura de Ñuu Dzaui_ , Jansen, M. and Broekhoven, L. van, eds. Koninklijke Nederlandse, Amsterdam (2008), pp. 347-380.
</li>
<li id="terraciano2001">Terraciano, K. _The Mixtecs of Colonial Oaxaca: Ñudzahui History, Sixteenth through Eighteenth Centuries_ . Stanford University Press, Stanford (2001).
</li>
<li id="townsend2016">Townsend, C. _Annals of Native America: How the Nahuas of Colonial Mexico Kept Their History Alive_ . Oxford University Press, New York (2016).
</li>
<li id="quiroa2017">Quiroa, N. “Friar Francisco Ximénez and the Popol Vuh: From Religious Treatise to a Digital Sacred Book” . _Ethnohistory_ 64, 2 (2017): 241-270.
</li>
<li id="viqueiraalban2002">Viqueira Albán, J. P. _Encrucijadas chiapanecas: Economía, religión e identidades_ . Tusquets Editores/El Colegio de México, Mexico (2002).
</li>
<li id="voorhies2004">Voorhies, B. and Gasco, J. _Postclassic Soconusco Society: The Late Prehistory of the Coast of Chiapas, Mexico_ . University at Albany-Institute for Mesoamerican Studies, Albany (2004).
</li>
<li id="white1987">White, H. The Content of the Form. Johns Hopkins University Press, Baltimore (1987).
</li>
<li id="yanezrosales2017">Yañez Rosales, R. H. “Nahuatl L2 texts from Northern Nueva Galicia: Indigenous language contact in the seventeenth century” . In _Language Contact and Change in Mesoamerica and Beyond_ , eds. Dakin, K., Parodi, C., and Operstein, N. John Benjamins Publishing Company, Amsterdam/Philadelphia (2017), pp. 237-262.
</li>
<li id="zantwijk2011">Zantwijk, R. van. “El futuro de la lengua náhuatl (náhuatlatolli)” . _Estudios de cultura náhuatl_ 42 (2011): 259-65.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The termsNáhuatlandNáhuatin Spanish,NahuatlandNawatin English, are currently the most conventional ways of referencing these related but distinct languages. As Hansen 2016 explains, the orthographic conventions of Nahuan languages are fluid and we do not intend any definitive statement by selecting these particular ones. On the politics of orthography and revitalization see also<a href="#olko2013">Olko and Sullivan 2013 esp. pp. 201-11</a>, and<a href="#vanzantwijk2011">van Zantwijk 2011</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>In the colonial period Nawat was calledPipilormexicana corruptaby the Spanish. BothNawatandPipilare common terms for the same language spoken in El Salvador today. To avoid confusion, in this article we refer only toNawat.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>For instance, documents of only a few pages each in many different Indigenous languages and genres — cofradía documents, letters, tribute records, etc., — are archived together as standalone documents, removed from their original documentary context with no paper trail, within the folder A1 legajo 6074 in the Archivo General de Centro América in Guatemala City. Similarly, see<a href="#quiroa2017">Quiroa 2017</a>on the recent decision by the Newberry Library in Chicago to physically separate thePopol Wujfrom the rest of the clerical text by Dominican Fr. Francisco Ximenez to which it once belonged, while preserving a record of its provenance and the state in which it arrived at the Newberry. The removal of texts from their place of origin by antiquarian collectors and scholars, with permission or not, represents yet another kind of decontextualization.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>But see the cautionary example provided by Madajczak and Hansen 2016, who show that even the characteristics assigned to these generally accepted linguistic labels may be combined or modified and fail to precisely identify the language of any given document.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>The literature on this process of linguistic, religious, and intellectual exchange is vast and varied, resting on the shoulders of scholars such as Angel María Garibay, Fernando Horcasitas, and Miguel León-Portilla in Mexico, and Dennis Tedlock, James Lockhart, Louise Burkhart, and Judith Maxwell in the United States.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>A short list might include<a href="#arroyo2004">Arroyo (2004)</a>(especially Popenoe de Hatch, Akkeren, and Chinchilla) on precolumbian Nahuas on the Guatemalan Pacific coast;<a href="#fowler1989">Fowler (1989)</a>,<a href="#escalantearce2001">Escalante Arce (2001)</a>, and<a href="#sampeck2015">Sampeck (2015)</a>on Nahua peoples inPipilterritory;<a href="#lujanmunoz1988">Luján-Muñoz (1988)</a>and<a href="#herrera2003">Herrera (2003)</a>on Spanish Guatemala;<a href="#stevenson1964">Stevenson (1964)</a>,<a href="#borg1985">Borg (1985)</a>, and<a href="#morales2015">Morales (2015)</a>on musical traditions;<a href="#lutz1994">Lutz (1994)</a>and<a href="#lokken2000">Lokken (2000)</a>on Afro-descendents in Guatemala; and<a href="#viqueiraalban2002">Viqueira Albán (2002)</a>on Chiapas.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>CHNS has since released a new version Omeka S with a built-in multilingual option, but as of this writing it is not compatible with Scripto. Rafael Lara Martínez generously translated all our simple pages into Spanish.## Bibliography&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Ticha: Collaboration with Indigenous communities to build digital resources on Zapotec language and history</title><link href="https://startwords.cdh.princeton.edu/vol/14/4/000529/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/vol/14/4/000529/</id><author><name>George Aaron Broadwell</name></author><author><name>Moisés García Guzmán</name></author><author><name>Brook Danielle Lillehaugen</name></author><author><name>Felipe H. Lopez</name></author><author><name>May Helena Plumb</name></author><author><name>Mike Zarafonetis</name></author><published>2020-12-15T00:00:00+00:00</published><updated>2023-08-04T13:14:15-04:00</updated><content type="html"><![CDATA[<h2 id="indigenous-voices-in-colonial-history">Indigenous voices in colonial history</h2>
<p>Around 1675, Sebastiana de Mendoza, a prominent woman in the Zapotec community of Tlacochahuaya, Oaxaca, created her last will and testament<a class="footnote-ref" href="#floresmarcial2015"> [floresmarcial2015] </a><a class="footnote-ref" href="#munro2018"> [munro2018] </a>. In this document, she tells her descendants and executors her wishes for the final disposition of her belongings. As Flores-Marcial [<a href="#floresmarcial2015">2015</a>, 52] writes, Sebastiana de Mendoza</p>
<blockquote>
<p>bequeathed to her daughters, Gerónima and Lorenza, and her granddaughter named Sebastiana, an array of belongings that included religious paraphernalia, valuable agricultural goods, and finished goods and money. She divided her property in the following manner: ten magueys, a wool skirt, a cotton huipil, and ten pesos went to her daughter Gerónima. She gave her granddaughter Sebastiana five magueys and a picture of Saint Sebastian. She did not bequeath her house to anyone specifically, but she gave her daughter Lorenza a total of thirty-five magueys and declared that, as the oldest, she should be in charge of the house and its affairs.</p>
</blockquote>
<p>Sebastiana was careful to distribute her property, but also scrupulous in noting her debts and obligations to others in the community as well as the debts and obligations owed to her. This complex system of interconnected social and fiscal responsibilities is known asguelaguetzain Zapotec. In the Zapotec inheritance system, her heirs inherited herguelaguetzaassets and liabilities. Her last will and testament states:</p>
<blockquote>
<p>chela tini pea nasaui quela queza xtenia SanJuan que / lauia li chi lucas luis chi uitopa tomin lichi Bartolo / me delos angel chi tomines lichi pedro no lasco chiui / topatomines lichi Saluador mendoza toui peso lichi / pedro mendes chiui topa tomines che la nosaui lorenso / garcia xonopeso pedro mendes no sauini xopa peso no / saui rey mundo dela cruz cayopeso nosaui quetoo / lorenso lopes chona peso — franco de agilar nosaui / ni chona peso geroni moperes no sauini chona peso / quira tomin niri que gixeni caca missa xteni qui / ropa leche lano</p>
</blockquote>
<blockquote>
<p>and I order [that] myguelaguetzais owing [i.e., there isguelaguetzaowing to me] in San Juan Guelavía: in the house of Lucas Luis, twelve tomines; in the house of Bartolomé de los Ángeles, ten tomines; in the house of Pedro Nolazco, twelve tomines; in the house of Salvador Mendoza, one peso; in the house of Pedro Méndez, twelve tomines; and Lorenzo García owes eight pesos; Pedro Méndez, he owes six pesos; Reymundo de la Cruz owes five pesos; the late Lorenzo López owes three pesos; Francisco de Aguilar, he owes three pesos; Gerónimo Pérez, he owes three pesos. All this money they should pay, [that] will be [for] masses for us two spouses.<a class="footnote-ref" href="#munro2018"> [munro2018] </a></p>
</blockquote>
<p>For an understanding of the social relationships and networks of colonial Oaxaca, there are few sources as rich as testaments like that of Sebastiana de Mendoza. Documents like these are of potential interest to many, particularly those with personal and / or academic interests in the histories, cultures, and languages of the Indigenous people of Mesoamerica. This document is of particular interest to the Zapotec people of Tlacochahuaya. Yet this remarkable text — and many others like it — are practically unknown to a large group of potential readers.</p>
<p>Why have vital manuscripts like these not been accessible to members of Indigenous communities who would like to read them? As we explain below, they have mostly been held in physical archives where they are accessible primarily to scholars with sufficient resources and privilege to use them. That these archival resources are little known to Zapotec stakeholders aligns with the analysis that “archives have functioned as mechanisms of colonialism” <a class="footnote-ref" href="#gauthereau2018"> [gauthereau2018] </a>. For example, as pointed out by Stoler [<a href="#stoler2002">2002</a>, 87], “What constitutes the archive, what form it takes, and what systems of classification and epistemology signal at specific times are (and reflect) critical features of colonial politics and state power.” Ticha seeks to use the power of digital humanities to democratize access to materials and resources which previously were almost exclusively the domain of scholars. Archiving, scholarship, and community engagement can be brought together in a powerful synthesis when community members have access to important documents from their own history.</p>
<h2 id="background-and-corpus">Background and corpus</h2>
<p>Zapotec is a language family indigenous to southern Mexico, and is the third largest Indigenous language family in Mexico. Today, there are over 50 different Zapotec languages, most endangered, spoken primarily in what is now the state of Oaxaca, Mexico, by a total of approximately 450,000 people within a much larger Zapotec ethnic community. The Zapotec language family, which belongs to the Otomanguean stock, is on par with the Romance language family in terms of time depth and diversity of member languages. The Zapotecs are one of the major civilizations of Mesoamerica, with cultural traditions going back to 500 B.C. and distinct from the better-known Nahua (Aztec) and Maya.</p>
<p>With the arrival of the Spanish in 1519, alphabetic writing was introduced and adopted by Indigenous peoples. McDonough [<a href="#mcdonough2014">2014</a>, 199] points out that, “as opposed to being passive receivers of an imposed European technology, Nahuas have appropriated and adapted alphabetic writing for their own purposes.” The same can be said of speakers of Zapotec, who quickly put this new technology to use. Zapotec has one of the longest records of alphabetic written documents for any Indigenous language of the Americas<a class="footnote-ref" href="#romero2003"> [romero2003] </a>. Over 900 documents in Zapotec language written by Zapotec scribes have been identified, the earliest from 1565<a class="footnote-ref" href="#oudijk2008"> [oudijk2008] </a>. The richest variety of colonial Zapotec documents are those composed in the kind of Zapotec spoken in and around Oaxaca City, known as Valley Zapotec. The Colonial Valley Zapotec corpus includes an extensive dictionary<a class="footnote-ref" href="#cordova1578b"> [cordova1578b] </a>, grammar<a class="footnote-ref" href="#cordova1578a"> [cordova1578a] </a>, and doctrine<a class="footnote-ref" href="#feria1567"> [feria1567] </a>, and over 200 administrative documents (mostly wills).</p>
<p>These documents hold invaluable information for a wide range of interested parties. They provide insight into the ethnic diversity, religious history, and familial, social, and economic structures of Mexico for a 500-year period. They create a bridge across multiple cultural borders: a link between modern scholars, colonial priests, and Zapotec people throughout time. The large corpus of Colonial Nahuatl language material has proven useful to scholars across many disciplines (e.g.<a class="footnote-ref" href="#lockhart1992"> [lockhart1992] </a>;<a class="footnote-ref" href="#madajczak2016"> [madajczak2016] </a>;<a class="footnote-ref" href="#matthew2020"> [matthew2020] </a>). As Colonial Zapotec is less studied and is understood by far fewer people, linguistic analysis is particularly needed to help users understand the texts and to allow them to critically evaluate any translations of the original text. Because of the difficulty in using the original manuscripts and in understanding the language, this corpus of documents written in Colonial Valley Zapotec has not been easily accessible outside of a small circle of specialists<a class="footnote-ref" href="#broadwell2013"> [broadwell2013] </a>.</p>
<h2 id="difficulties-of-access-to-colonial-materials">Difficulties of access to colonial materials</h2>
<p>Reading and translating these Colonial Valley Zapotec documents can be extremely difficult. Physical access alone can be a barrier to reading the documents, as these texts are housed in various archives not only throughout Oaxaca and other parts of Mexico, but also in archives in the United States and Europe. One must know which archive to visit and how to request a document, and sometimes that is insufficient. For example, the Archivo General del Poder Ejecutivo del Estado de Oaxaca has changed their archival numbering system, and now reference numbers like those published in Smith Stark et al. (<a href="#smithstark2008">2008</a>) are no longer accurate. Moreover, discrimination against people perceived to be Indigenous means that some employees at an archive, including guards, may discourage and intimidate some potential users from entering the archives, as we have ourselves witnessed on more than one occasion.</p>
<p>Even if one has physical access to the texts, many aspects of the documents themselves can be a barrier to access. The writing and printing conventions for colonial documents can be opaque to contemporary users. Reading handwriting from this period often requires special training, and printed texts often use extensive abbreviations and may also contain printing errors (such as reversed letters and broken type) and handwritten corrections.</p>
<p>The Zapotec language poses additional challenges in understanding the texts. Knowledge of (or fluency in) a modern Zapotec language is not enough to translate the colonial documents due to variation in orthographic choices and regular processes of language change. The orthography in the texts is highly variable and inconsistent throughout the corpus, and there is as of yet no fully adequate Zapotec-to-Spanish or Zapotec-to-English dictionary that reflects the full range of orthographic variation found in the corpus<a class="footnote-ref" href="#broadwell2013"> [broadwell2013] </a>. Beyond orthography, the Zapotec language has undergone language change over the last 500 years, including significant phonological and morphosyntactic alterations. Thus the grammar of these documents is also different from that of modern Zapotec languages. Potential users of such documents cannot read them without training, and, as a result, only a very small number of people use them — typically linguists and ethnohistorians with special interest in Zapotec language materials and a handful of other dedicated specialists. Other stakeholders, including most speakers of modern Zapotec languages, have no easy way to discover or read the texts that document the histories of their communities.</p>
<p>In addition to these more tangible obstacles, discriminatory linguistic ideologies pose systemic challenges to the access of Zapotec language materials. In Mexico, Zapotec is viewed as something less than a real language, and knowledge of Zapotec language is devalued. There are pervasive false beliefs that Zapotec has never been written, cannot be written, and perhaps even should not be written. Janet Chávez Santiago, a native Zapotec speaker and language activist, reflects (in English) on the impact of such beliefs:</p>
<blockquote>
<p>When I was in elementary school in the 90s, I remember children speaking Zapotec in many contexts: playing in the streets, at parties, and during town celebrations — but never at school. Instead, we had to “behave” ourselves by not speaking Zapotec, otherwise teachers could punish us by giving us extra homework or by not letting us eat lunch or even beating us. Teachers made us believe that speaking Zapotec was disrespectful, something to be ashamed of. They devalued our language by calling it a “dialect” . As a child, I never saw anything written in Zapotec. All my books and books that my parents bought me were in Spanish, so at some point I thought teachers were right, that Zapotec was a language with no value so nobody wanted to write books in my language. By the end of the 90s there was no need to prohibit children speaking Zapotec in the school, because in order to avoid their children being punished, parents had switched to speaking in Spanish to their children at home. These days, there are very few children who speak Zapotec in my town.<a class="footnote-ref" href="#mannix2016"> [mannix2016] </a></p>
</blockquote>
<p>These ideologies about the value of Zapotec language certainly impact access in multiple ways, but they also create a space for projects such as ours to intervene in larger questions of social justice. In the following sections we describe how Ticha addresses inequities of access in an effort to make the Colonial Valley Zapotec corpus available to the widest possible audiences. Moreover, we discuss how the creation and evolution of Ticha is done in consultation and collaboration with Zapotec-speaking community members such that both the methodology and “result” are spaces for collaboration with stake-holding community members. We consider how creating access to a corpus of historical texts in Valley Zapotec can be a form of resistance to such false ideologies, both in its form as a resource and through the collaborative methods in which we create and grow the project.</p>
<h2 id="the-ticha-project">The Ticha project</h2>
<p>Ticha (<a href="https://ticha.haverford.edu">https://ticha.haverford.edu</a>) is a large, collaborative, interdisciplinary digital resource<a class="footnote-ref" href="#lillehaugen2016"> [lillehaugen2016] </a>, with a diverse team, including linguists, ethnohistorians, digital scholarship experts, and Zapotec language and culture experts.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> The core team consists of academics and non-academics as well as Zapotec people and non-Native people. Undergraduate research assistants play a large role in the development of the project, as discussed below.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Beyond these more formalized team members, there is broader community participation through crowd-sourced transcription and commenting, some by anonymous participants and others credited on the acknowledgements page of Ticha.</p>
<p>The Ticha project seeks to provide access to the corpus and language of the Colonial Valley Zapotec corpus in a way that mitigates the systemic language devalorization described above. In regards to the corpus itself, we practice post-custodial archiving<a class="footnote-ref" href="#ham1981"> [ham1981] </a><a class="footnote-ref" href="#cook1994"> [cook1994] </a>, using existing digital images of the documents when available, and by creating our own high-resolution digital images when not. As Alpert-Abrams points out, “In the United States, we have a long history of removing historical records from the communities that created them, often in the name of preservation… The post-custodial model of archival practice uses digital technology in pursuit of a more collaborative approach to multinational archival work” [<a href="#alpertabrams2018">2018</a>, n.p.]. Post-custodial practices are usually discussed in relation to institutions that are capable of taking possession of materials — like libraries and archives. Ticha is not a library or a physical archive, nor is it an institution that seeks to assume possession of archival texts. The creation of digital surrogates and the maintenance of collaborative partnerships with stake-holding communities allow us, however, to curate a collection of texts digitally.</p>
<p>The Ticha interface, built in the Django framework, allows users to browse and search the corpus of Colonial Valley Zapotec texts, including the images and metadata. Given the sociolinguistic context around this language and these texts, we make any resources we have available as soon as possible, borrowing from the idea of progressive archiving<a class="footnote-ref" href="#nathan2013"> [nathan2013] </a>. This means that for some texts, we may just have images and metadata. For others we may have first pass transcriptions. Yet others may have polished transcriptions and translations. We invite corrections and collaboration and view the resource as a living document and a space for collaboration.</p>
<p>Ticha allows users to navigate a corpus that is otherwise physically dispersed. Figure 1 illustrates one interface for browsing the corpus, which can be searched or filtered along several fields, including date of document, town of origin, archival home, genre, and language of the text. The corpus can also be navigated through a timeline and a map, the latter of which is shown in Figure 2.</p>




























<figure ><img loading="lazy" alt="A table of available manuscipts including metadata on year, langauge, and so on." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Browsing the corpus of handwritten manuscripts, table (<a href="https://ticha.haverford.edu/en/texts/handwritten/">https://ticha.haverford.edu/en/texts/handwritten/</a>)
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="A map with over a dozen points." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Browsing the corpus of handwritten manuscripts, map (<a href="https://ticha.haverford.edu/en/texts/">https://ticha.haverford.edu/en/texts/</a>)
        </p>
    </figcaption>
</figure>
<p>In order to make Ticha more accessible to a wide range of users, we present the texts not as flat objects but as dynamic resources. Other scholars have published translations and annotations of colonial-era linguistic materials in print form; Lockhart’s translation of a Colonial Nahuatl grammar is a notable example<a class="footnote-ref" href="#carochi2001"> [carochi2001] </a>. However, print editions are generally aimed at academic audiences and often present readers with too much detail for the interested non-academic. Presenting this material as a digital resource allows readers to view or hide different levels of analysis, depending on their needs and interests.</p>
<p>Figure 3 shows a page from the <em>Arte en lengua zapoteca</em> , a colonial-era grammar of Valley Zapotec which is credited to Fray Juan de Cordova, though undoubtedly many (uncredited) Zapotec individuals were involved in its creation<a class="footnote-ref" href="#cordova1578a"> [cordova1578a] </a>. At the most basic level, visitors may view the scanned images of the original document side-by-side with a diplomatic transcription. As the colonial Spanish text contains abbreviations and spelling inconsistencies which may be difficult for some users to understand, a modernized Spanish version is also available. This was created in response to a request from Zapotec community members who noted that the Early Modern Spanish was a barrier to understanding the text. The modernized Spanish version updates spelling and word boundaries, but does not alter lexical choice or syntax. Feedback from speakers of modern Mexican Spanish has been clear that this type of modernization has been helpful in reading the text.</p>




























<figure ><img loading="lazy" alt="The original text and translation of Corova&#39;s Arte." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Transcription and morphological pop-ups in Corova’s Arte (1578a: 1v)<a href="https://ticha.haverford.edu/en/texts/cordova-arte/13/original/">https://ticha.haverford.edu/en/texts/cordova-arte/13/original/</a>
        </p>
    </figcaption>
</figure>
<p>Layers of accessible linguistic information are also used to communicate more about the Zapotec language in these texts. As the <em>Arte</em> is a meta-linguistic document, the text itself is an analysis of the Zapotec language. As is to be expected from the time period, this grammar is structured following the Latin model. For example, in the passage in Figure 2 describes the “declensions” of Zapotec nouns, a concept that only serves to obscure the grammar of Valley Zapotec, which has no grammatical case. While the framework is rather unhelpful in understanding the language, the Zapotec language examples themselves are invaluable. Ticha can facilitate accessibility to understanding the Zapotec here, by providing access to modern linguists’ understanding of the Zapotec language. As shown in Figure 2, clicking on a Zapotec word or phrase in the text brings up a pop-up containing a complete morphological analysis and translation of the Zapotec, which may or may not be consistent with the explanation in the original text. The interested reader, then, can compare the analysis in the <em>Arte</em> with that of a modern linguist.</p>
<p>As we considered what kind of access and collaboration could mitigate the type of language devalorization described above, we also wanted to be careful that a project on a historical corpus of Zapotec texts did not reinforce another harmful false ideology — that Zapotec language and people are only of the past, frozen in time. This type of thinking regarding Indigenous people, culture, and language is ubiquitous. We wanted Zapotec people and modern language to be clearly visible in the Ticha Project.</p>
<p>One way we addressed this was by bringing Zapotec voices to the site. Figure 4 shows one of the resources available on Ticha: a vocabulary of the most common words found in the corpus, along with their definitions and alternative spellings. Wherever possible, we connect these lexical entries for historical forms of words with their modern counterparts, by linking entries in Ticha’s Vocabulary with entries in online Talking Dictionaries for several Valley Zapotec language varieties (described in<a class="footnote-ref" href="#harrison2019"> [harrison2019] </a>), including those from Teotitlán del Valle<a class="footnote-ref" href="#lillehaugenchavez2019"> [lillehaugenchavez2019] </a>, San Jerónimo Tlacochahuaya<a class="footnote-ref" href="#lillehaugenguzman2019"> [lillehaugenguzman2019] </a>, and San Lucas Quiaviní<a class="footnote-ref" href="#lillehaugen2019"> [lillehaugen2019] </a>. The design came out of one of the in-person workshops in Oaxaca. As the room full of Zapotec speakers from different communities in the Valley of Oaxaca worked through understanding one of the colonial-era texts together, a pattern of practice emerged. For each word, speakers would go around the table, saying the modern cognate in their variety of Zapotec. The text was read, performed — even echoed — in a multitude of modern Zapotec languages. The Vocabulary on Ticha is our attempt to realize this in a digital format.</p>




























<figure ><img loading="lazy" alt="An alphabetical list of voacbulary beginning with the letter “A” ." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Vocabulary of Colonial Valley Zapotec connected to modern Zapotec Talking Dictionaries
        </p>
    </figcaption>
</figure>
<p>Connecting these modern lexical resources with this historical vocabulary not only allowed us to resist a reading of these materials that excludes the modern Zapotec community, but also allowed us to incorporate a Zapotec designed engagement with the texts. As described further in the section that follows, our iterative methodology includes regular trips to Oaxaca, where we not only solicit feedback and suggestions from Zapotec speakers with interest in the corpus but also spend time looking at Colonial Zapotec language texts together.</p>
<h2 id="digital-scholarship-and-community-engagement">Digital scholarship and community engagement</h2>
<p>In this section, we turn to directly examining the structure and methodology surrounding our development process, and in particular the role of stakeholding communities in our project design. Thorpe and Galassi note that long-term engagement with stakeholding communities requires libraries to challenge their traditional workflows and “establish new ways of practice that allow Indigenous people and communities to guide and control the process” [<a href="#thorpe2014">2014</a>, 91–92]. These ideas are echoed in the literature on community-based linguistic research, where scholars have recently emphasized community collaboration and sharing control of research project design<a class="footnote-ref" href="#czaykowska2009"> [czaykowska2009] </a><a class="footnote-ref" href="#rice2011"> [rice2011] </a>. Ticha prioritizes community engaged methods not only as a goal, but as a means throughout the project; as Ortega notes in her review of Ticha, “the engaging of a community of Zapotec speakers is very clearly the backbone of the project and, through recurrent workshops, has given shape to its other components” [<a href="#ticha2019">2019</a>].</p>
<p>Our project benefits from other digital scholarship projects working with Indigenous languages, corpora of manuscripts, and community engaged projects generally, especially those working with marginalized communities and languages. We are aware of one other project that also makes Zapotec language texts publicly accessible: Satnu: Repositorio Filológico Mesoamericano (<a href="https://satnu.mx/">https://satnu.mx/</a>), which as the name suggests is a repository and digital archive for texts in Mesoamerican languages, including — but not limited to — Zapotec language texts. The Early Nahuatl Library (<a href="http://enl.uoregon.edu/">http://enl.uoregon.edu/</a>), for example, gathers together 16th- through 19th-century Nahuatl-language manuscripts with transcriptions, translations, and historical context. In this issue, Matthew and Bannister describe NECA: Nahuatl/Nawat in Central America (<a href="https://nahuatl-nawat.org/">https://nahuatl-nawat.org/</a>), a digital project that makes a corpus of Nahuan-language documents produced in Spanish Central America publicly available. Olko (2019) describes a community-engaged approach in which archival work on Nahuatl language texts is fused with ethnolinguistic fieldwork in a project that seeks to “combine Western/academic and Indigenous methodologies” [<a href="#olko2019">2019</a>, 7]. Moving beyond Nahuatl, the Proyecto Oralidad Modernidad (<a href="https://oralidadmodernidad.wixsite.com/oralidad">https://oralidadmodernidad.wixsite.com/oralidad</a>) uses a community-engaged approach to language documentation that encourages Indigenous Ecuadorians to connect with their history through language as they document the knowledge of elders<a class="footnote-ref" href="#haboud2019"> [haboud2019] </a>. Far outside of Latin America, The Notebooks of William Dawes (<a href="https://www.williamdawes.org/">https://www.williamdawes.org/</a>;<a class="footnote-ref" href="#nathan2007"> [nathan2007] </a>) makes accessible threatened language documentation from the century on Darug/Dharuk, a language of Sydney, Australia, through images, transcriptions, and connections to modern speakers. Originally located at the SOAS and now a free-standing resource, the Notebooks of William Dawes brings archival texts, commentary, and modern language together online and through a companion print version<a class="footnote-ref" href="#nathan2009"> [nathan2009] </a>. Ticha combines elements of many of these projects — and especially that of the Notebook of William Dawes — connecting stakeholding communities to Zapotec history through colonial-era documents while acknowledging and engaging with the social-political power of Zapotec writing, spoken Zapotec language, and Zapotec communities.</p>
<p>Ticha extends the traditional user-centered approach to design by defining user groups as communities. Each community brings its own skill sets and experiences to the project, which shapes the technology and workflows that make up the project. The array of communities that make up Ticha include the Zapotec community members, Haverford College linguistics and computer science students, scholars in linguistics and ethnohistory, and librarians, though membership in these categories may overlap. Each community is both a user and a participant in their engagement with the project web site. Access to the materials includes traditional methods of discovery, but also engagement with and close reading of the materials through features like transcription, text encoding, and audio recording. The artifacts of this engagement become part of the Ticha workflow (e.g. manuscripts transcribed by Zapotec community members or Haverford linguistics students, recordings for the Talking Dictionary by Zapotec community members, or morphological analysis of Zapotec words by linguists), and emerge as additional points of engagement for the project’s communities. As such, the design of the project accounts for the experiences and needs of each community, is informed by feedback from its communities, and is iterative in its approach. The morphological analysis is done in Fieldworks Language Explorer (FLEx), and discussed in<a href="#broadwell2013">Broadwell and Lillehaugen, 2013</a>. This is exported as XML and processed with the TEI (Text Encoding Initiative) encoding of the text by a Python script and XSLT (Extensible Stylesheet Language Transformations) to ultimately produce HTML. This HTML creates the public-facing interface for the encoded texts.</p>
<p>Our development process has a clear institutional component, as Haverford College Libraries is an active partner in the design and development of the Ticha project site. The Digital Scholarship group, which partners with faculty and students to produce multimodal scholarship through the use of digital tools and methods, has been primarily responsible for web design, web and application development, server administration, archival and preservation workflows, and data curation practices for the project.</p>
<p>Ticha is a system of tools that fit together in ways that meet the needs of its community members. The skill sets and tools available to each community determines the choices of tools and methods for the project. While the library is responsible for technical development of the project site, digital scholarship librarians and student employees are often developing tools or features for the first time. The library exercises a strong preference for existing tools that meet community needs and standards and prefers to develop custom-made solutions only when the project exceeds the capacity of ready-built tools. The ability to export data in standard formats (e.g. JSON, CSV, XML) is essential for each tool so that future flexibility is built into the project in all areas.</p>
<p>Existing tools come with their own set of limitations, as they are not developed in the context of a specific project but instead designed to be used broadly. When the needs of a community reach beyond the limits of — or are not being effectively met by — existing tools, it is necessary to built upon existing project features. An open channel for feedback is crucial, and that feedback drives iteration on the features that require it. Feedback comes in two primary forms: workshops and web analytics. Web analytics (Ticha uses Google Analytics) provide meaningful data on site usage and user location, from which we can draw useful conclusions. For example, analytics in late 2017 suggested that users that visited the home page of the project site often moved on quickly, while those who visited specific manuscripts directly (from a link shared on social media or search results) tended to engage with other areas of the site. This data strongly suggested that a redesign of the home page was necessary to provide users with more information on what they can do in the Ticha project site, and such a redesign was implemented during the summer of 2018.</p>
<p>Some of the most meaningful feedback comes from engagement with members of the Zapotec-speaking community in Oaxaca. Transcription workshops helped the project team see the tools in action on the equipment available to its users (i.e. tablets or computers that aren’t necessarily current, running the latest software, or reliably connected to the Internet). A series of workshops with students at the Centro de Estudios Tecnológicos Industrial y de Servicios No. 124 (CETIs #124), a high school in Tlacolula de Matamoros, Oaxaca, was significantly affected by Wifi connectivity issues, highlighting the need to account for access to the manuscripts and some features of the project site when the network connection is unreliable. As a result, the project now features a PDF export option for manuscripts that include high-resolution images of the documents and associated metadata that can be saved to a storage device for offline access.</p>
<p>The transcription feature for the manuscripts on Ticha is a particularly instructive case study of this iterative approach. In 2015, members of the Zapotec-speaking community expressed a strong desire to transcribe the manuscripts through the project site. While the Haverford College Libraries could have attempted to build a custom transcription interface, the Digital Scholarship team did not have technical capacity to develop such a feature. The project was already using Omeka as a digital collections platform to serve and describe the digitized manuscripts in parallel with the Django project site. The Scripto plugin for Omeka provided a ready-built solution for a transcription feature. Implementation of that feature occurred in the spring of 2016, at which point the project group conducted two workshops with Zapotec-speaking community members in Oaxaca on document transcription. During these workshops, the affordances and limitations of the Scripto interface became apparent. Users of the web site needed to perform three or four clicks to move from the manuscript viewer to the transcription tool, and the interface itself was difficult to customize for language and format. With this feedback, the digital scholarship group developed its own transcription interface in parallel with the already-launched Scripto interface, which then replaced Scripto in the spring of 2018. The new transcriber is completely integrated within the existing manuscript viewer interface, accessible by only one click or tap from an input device.</p>
<p>An interest on the part of academics and/or community members to contribute to online transcriptions and translations should not be assumed, as demonstrated in the context of NECA (Nahuatl/Nawat in Central America) in<a href="#matthew2020">Matthew and Bannister, this issue</a>, who also express encountering similar limitations with Scripto in their project.</p>
<h2 id="impact-and-reflections">Impact and reflections</h2>
<p>As part of our commitment to community-led research, Ticha includes an advisory board of Zapotec community members. While community workshops provide feedback on the functionality of the site, members of the advisory board give ongoing advice to shape the project as a whole. In this section, Moisés García Guzmán and Dr. Felipe H. Lopez, two members of the advisory board, reflect on the impact of Ticha in their community. Their words speak best for themselves and thus are intentionally presented here as they were written by the co-authors. García Guzmán, a Zapotec educator and activist, offers the following reflection:</p>
<blockquote>
<p>Many local communities in Oaxaca were not aware of the existence of documents in Zapotec. Ticha has helped them to see how important their language was in official procedures in the past, but has also helped to create a link with revitalization efforts that are going on, by showing community members that their proposals on contemporary Zapotec can lead to a new standardized written system. García Guzmán, a Zapotec educator and activist, offers the following reflection:</p>
</blockquote>
<blockquote>
<p>As a speaker and activist in my community, Ticha is a great tool in raising awareness on all revitalization efforts. Young kids can see how our language played an important role in some activities of our towns in the past. But also I encourage them not to see the language as only a part of our past, but to also work towards restoring use of our language in many contexts where Zapotec seems to be losing ground. In the end, I hope to instill in them the idea to work towards an official recognition again. I also hope that our efforts will encourage local authorities to give us better access to archives, by showing them all the work that is done. The existence of Ticha makes archival authorities more open and cooperative with these efforts.</p>
</blockquote>
<blockquote>
<p>Overall, it has been a great experience, and as the work progresses, it helps students, speakers and communities to strengthen the sense of identity with our native language.</p>
</blockquote>
<p>Lopez has been key in starting and facilitating the workshops at the high school in Tlacolula. He offers these reflections:</p>
<blockquote>
<p>I have always believed that the youth could be very influential in their communities today and have sought ways to engage with them to promote the Zapotec languages in their pueblos. For the last three years I have had the opportunity to participate in Zapotec workshops at CETIs #124 in collaboration with Haverford College and the Ticha project. These workshops have become pivotal for engaging with students and school officials to rethink the value and importance of Zapotec. In a sense, these workshops have given this school community a different access to the language. In these three years, I have witnessed the way the students involved in these workshops have strengthened their values towards their own language at the same time their identities.</p>
</blockquote>
<blockquote>
<p>At the beginning there was some skepticism about these Zapotec workshops given that only six students participated. However, each year there has been an increase in the number of students participating, and last year there were more than 20 students who signed up for the Colonial Zapotec workshops.</p>
</blockquote>
<blockquote>
<p>This particular workshop gave students an opportunity to understand their language from a historical perspective and to work with Colonial documents. The Zapotec students tried to understand Colonial Zapotec words and to think about the equivalent modern Zapotec words. Through these documents, they understood that Zapotec is a living language which has been written for hundreds of years, dispelling the notion that Zapotec is not a written language. All the students found commonalities between Colonial Zapotec and the various Zapotec languages they spoke. Furthermore, they were pleasantly surprised to learn ways to count in Zapotec. As is the case in my own community of San Lucas Quiaviní, most students can only count up to ten or so and then use Spanish words, and so through these Colonial Zapotec documents they learned something about their own language.</p>
</blockquote>
<blockquote>
<p>The openness of the Principal Dr. Marcos Pereyra Rito and the support of the main advocate of this program, Abisai Aparicio, has given this opportunity to students, despite the absence of a clear precedent in the educational system in Mexico. In fact, historically, schools served as an instrument of assimilation and punished people who spoke their Indigenous language. However, as part of this collaboration at CETIs #124, the vice-principal, who isn’t a native speaker of Zapotec, made an effort to read a message in Zapotec to the participating students in the workshop last year. Also, one of the teachers, Dr. David Velasco, was willing to accept work written in Zapotec in his literature course. I have also witnessed how students have changed their behaviour towards using their language since these workshops have started. I see students talking Zapotec more openly on campus, whereas prior to this project, we were told that students were embarrassed to speak Zapotec on campus or even to admit they spoke it at all. So, the conditions in which these students decide to use their language is being reshaped at this institution, hopefully as well as outside. These efforts, then, are working to reshape the sociolinguistic possibilities at this institution, and potentially even beyond.</p>
</blockquote>
<h2 id="conclusions">Conclusions</h2>
<p>As Nakata and Langton say, effective community collaboration is not just “consultation” with the community, but “dialogue, conversation, education, and working through things together” [<a href="#nakata2005">2005</a>, 5]. Ticha embraces this philosophy by working through an ongoing conversation with user communities. Our iterative approach allows the technical design of the project to continually meet the needs of its communities. Furthermore, it situates the project in dialogue with other digital projects that employ similar tools or methods, and provides a model for doing truly community-engaged digital scholarship. For example, Albert-Abrams et al. describe their work as being practiced “not through a static set of methodologies, but rather an ongoing process of learning, unlearning, and restructuring in pursuit of a collective good” [<a href="#albertabrams2019">2019</a>, 1]. We recognize our own practice in this description, as well as in the framing provided by Duff et al, that “Social justice is always a process and can never be fully achieved” [<a href="#duff2013">2013</a>, 324].</p>
<p>Our engagement with the Ticha project has yielded many positive results, both for scholars and members of the Zapotec community. The Zapotec language documents in Ticha are a resource for those interested in Zapotec people, their languages, and their history. Ticha’s project design is grounded in well-established theories of cultural and linguistic reclamation and revitalization. Scholars have long discussed the importance of schools in creating positive language ideologies, particularly among youth<a class="footnote-ref" href="#lee2007"> [lee2007] </a>, as well as the complexity surrounding the roles that Indigenous educators can have within these systems, in particular in Mexico<a class="footnote-ref" href="#mcdonough2014"> [mcdonough2014] </a>. Researchers have also noted the power of Indigenous community members directly preserving their own histories<a class="footnote-ref" href="#hoobler2006"> [hoobler2006] </a>. Given this, we think it is likely that similar results might be achieved in other communities following our methods, adapted for local priorities and practices. While a handful of projects exist, as mentioned earlier, we could imagine even more projects like this not only in Oaxaca, but in Latin America more broadly, and world-wide where such historical corpora exist. All of the Ticha encoding and scripting is freely available to anyone who would like to use or adapt it for similar projects.</p>
<p>As local language ideologies in Mexico favor Spanish over Indigenous languages such as Zapotec, a project like Ticha serves as a resource for local language activists. In particular, Ticha forefronts Indigenous voices and knowledge. As Pratt says: “If one studies only what the Europeans saw and said, one reproduces the monopoly on knowledge and interpretation that the imperial enterprise sought” [<a href="#pratt2007">2007</a>, 7]. Important historical documents, like the testament of Sebastiana de Mendoza, demonstrate in a very concrete way the long literate history of Zapotec people and the importance of the Zapotec language to understanding this history.</p>
<p>We also take this project to be a clear demonstration of the power of digital humanities projects to democratize access to materials and resources which might otherwise be used primarily by scholars. We seek to practice transformational work as part of a larger interdisciplinary project that we would also classify as engaged scholarship. When community members have access to important documents from their own history, we are able to bring together archiving, scholarship, and community engagement in a powerful synthesis.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>We want to acknowledge our appreciation to the editors Hannah Alpert-Abrams and Clayton McCarl for all their work in making this issue possible, including their advice in the development of this piece. Thanks also to two anonymous reviewers for the helpful and encouraging feedback and to K. David Harrison and Peter Austin for their thoughtful suggestions. We are grateful for comments from attendees at the following conferences: the annual meeting of the Latin American Studies Association, Encuentro de Humanistas Digitales, and the Coloquio sobre Lenguas Otomangues y Vecinas. In addition, we thank Julie Gonzales and Eloise Kadlecek for their editorial support in the preparation of this manuscript. Special thanks for K. David Harrison and Jeremy Fahringer in facilitating the connection between the Zapotec Talking Dictionaries and Ticha’s Vocabulary.</p>
<p>The Ticha project is grateful to funding from the American Council of Learned Societies, the American Philosophical Society, the Center for Peace and Global Citizenship at Haverford College, the Provost Office of Haverford College, the Hurford Center for the Arts and Humanities at Haverford College, the Haverford College Libraries, the National Endowment for the Humanities, and the Tri-Co Digital Humanities. Any opinions, findings, conclusions, or recommendations expressed in this project do not necessarily represent those of the National Endowment for the Humanities.</p>
<ul>
<li id="alpertabrams2018">Alpert-Abrams, H. “Post-custodial Archiving for Our Collective Good.”  _Council on Library and Information Resources Blog_ (2018, October 25). Online:<a href="https://www.clir.org/2018/10/post-custodial-archiving/">https://www.clir.org/2018/10/post-custodial-archiving/</a>.
</li>
<li id="alpertabrams2019">Alpert-Abrams, H., Bliss, D. A., and Carbajal, I. “Post-Custodialism for the Collective Good: Examining Neoliberalism in US-Latin American Archival Partnerships.” In M. Cifor and J. A. Lee (eds.), _Evidences, Implications, and Critical Interrogations of Neoliberalism in Information Studies_ , special issue _Journal of Critical Library and Information Studies_ 2.1 (2019). doi:<a href="https://journals.litwinbooks.com/index.php/jclis/article/view/87">10.24242/jclis.v2i1.87</a>.
</li>
<li id="broadwell2013">Broadwell, G.A. and Lillehaugen, B.D. “Considerations in the creation of an electronic database for Colonial Valley Zapotec,”  _International Journal of the Linguistic Association of the Southwest_ , 32 (2013): 77–110.
</li>
<li id="carochi2001">Carochi, H., and Lockhart, J. (trans.). _Grammar of the Mexican Language: With an Explanation of Its Adverbs_ . Stanford University Press, Stanford (2001).
</li>
<li id="decerteau1988">de Certeau, M. “The Historiographic Operation (1974),” in _The Writing of History_ . Columbia University Press, New York (1988).
</li>
<li id="cook1994">Cook, T. “Electronic Records, Paper Minds: The Revolution in Information Management and Archives in the Post-Custodial and Post-Modernist Era,”  _Archives and Manuscripts_ 22 (1994): 300–328.
</li>
<li id="cordova1578a">Cordova, Fr. J. de. _Arte en lengua zapoteca_ [Grammar in the Zapotec language]. En casa de Pedro Balli, Mexico (1578).
</li>
<li id="cordova1578b">Cordova, Fr. J. de. _Vocabulario en lengua çapoteca_ [Vocabulary in the Zapotec language]. Ediciones Toledo, Mexico (1578/1987).
</li>
<li id="czaykowska2009">Czaykowska-Higgins, E. “Research Models, Community Engagement, and Linguistic Fieldwork: Reflections on Working within Canadian Indigenous Communities,”  _Language Documentation and Conservation_ , 3.1 (2009): 15–50.
</li>
<li id="duff2013">Duff, W. M., Flinn, A., Suurtamm, K. E., and Wallace, D. A. “Social justice impact of archives: a preliminary investigation.”  _Archival Science_ , 13 (2013): 317–348.
</li>
<li id="feria1567">Feria, Fr. P. de. _Doctrina cristiana en lengua castellana y çapoteca_ [Christian doctrine in the Spanish and Zapotec languages]. En casa de Pedro Ocharte, Mexico City (1567).
</li>
<li id="floresmarcial2015">Flores-Marcial, X.M. _A history of _guelaguetza_ in Zapotec communities of the Central Valleys of Oaxaca, 16th century to the present_ . Doctoral dissertation, University of California, Los Angeles, United States (2015). Retrieved from<a href="https://escholarship.org/uc/item/7tv1p1rr">https://escholarship.org/uc/item/7tv1p1rr</a>.
</li>
<li id="gauthereau2018">Gauthereau, L. (2018, August). “Post-Custodial Archives and Minority Collections,”  _Recovering the U.S. Hispanic Literary Heritage Blog_ (2018, August 7). Online:<a href="https://recoveryprojectappblog.wordpress.com/2018/08/07/post-custodial-archives-and-minority-collections/">https://recoveryprojectappblog.wordpress.com/2018/08/07/post-custodial-archives-and-minority-collections/</a>.
</li>
<li id="haboud2019">Haboud, M. “Estudios sociolingüísticos y prácticas comunitarias para la documentación activa y el reencuentro con las lenguas indígenas del Ecuador,”  _Visitas Al Patio_ 13 (2019): 37–60.
</li>
<li id="ham1981">Ham, G. “Archival Strategies for the Post-Custodial Era,”  _The American Archivist_ 44.3 (1981): 207–216.
</li>
<li id="harrison2019">Harrison, K. D., Lillehaugen, B. D., Fahringer, J., and Lopez, F. H. “Zapotec language activism and Talking Dictionaries. Electronic lexicography in the 21st century.” In I. Kosem, T. Zingano Kuhn, M. Correla, J. P. Ferreria, M. Jansen, I. Pereira, J. Kallas, M. Jakubíček, S. Krek, and C. Tiberius (eds.), _Electronic lexicography in the 21st century. Proceedings of the eLex 2019 conference_ (2019), 31–50.<a href="https://elex.link/elex2019/wp-content/uploads/2019/09/eLex_2019_3.pdf">https://elex.link/elex2019/wp-content/uploads/2019/09/eLex_2019_3.pdf</a>.
</li>
<li id="hoobler2006">Hoobler, E. “ To Take Their Heritage in Their Hands : Indigenous Self-Representation and Decolonization in the Community Museums of Oaxaca, Mexico,”  _American Indian Quarterly_ 30 (2006): 441–460.
</li>
<li id="lee2007">Lee, T. “ If They Want Navajo to Be Learned, Then They Should Require It in All Schools : Navajo Teenagers’ Experiences, Choices, and Demands Regarding Navajo Language,”  _Wicazo Sa Review_ 22 (2007): 7–33.
</li>
<li id="lillehaugen2016">Lillehaugen, B.D., Broadwell, G.A., Oudijk, M.R., Allen, L., Plumb, M.H., and Zarafonetis, M. _Ticha: a digital text explorer for Colonial Zapotec, first edition_ (2016). Online:<a href="http://ticha.haverford.edu/">http://ticha.haverford.edu/</a>.
</li>
<li id="lillehaugen2019">Lillehaugen, B.D., Lopez, F.H., and Munro, P., with Deo, S.M., Mauro, G., and Ontiveros, S. _San Lucas Quiaviní Zapotec Talking Dictionary, version 2.0._ Living Tongues Institute for Endangered Languages (2019).<a href="http://www.talkingdictionary.org/sanlucasquiavini">http://www.talkingdictionary.org/sanlucasquiavini</a>.
</li>
<li id="lillehaugenchavez2019">Lillehaugen, B.D. and Chávez Santiago, J., with Freemond, A., Kelso, N., Metzger, J., Riestenberg, K., and Harrison, K.D. _Teotitlán del Valle Zapotec Talking Dictionary, version 2.0._ Living Tongues Institute for Endangered Languages (2019).<a href="http://www.talkingdictionary.org/teotitlan">http://www.talkingdictionary.org/teotitlan</a>.
</li>
<li id="lillehaugenguzman2019">Lillehaugen, B.D., and García Guzmán, M., with Goldberg, K., Méndez Morales, M.M., Paul, B., Plumb, M.H., Reyes, C., Williamson, C.G., and Harrison, K.D. _Tlacochahuaya Zapotec Talking Dictionary, version 2.1_ . Living Tongues Institute for Endangered Languages (2019).<a href="http://www.talkingdictionary.org/tlacochahuaya">http://www.talkingdictionary.org/tlacochahuaya</a>.
</li>
<li id="lockhart1992">Lockhart, J. _The Nahuas After the Conquest: A Social and Cultural History of the Indians of Central Mexico, Sixteenth Through Eighteenth Centuries_ . Stanford University Press, Stanford (1992).
</li>
<li id="madajczak2016">Madajczak, J and Hansen, M.P. “Teotamachilizti: an analysis of the language in a Nahua sermon from colonial Guatemala,”  _Colonial Latin American Review_ 25 (2016): 220–244.
</li>
<li id="mannix2016">Mannix, A., Lillehaugen, B.D., and Chávez Santiago, J. “Technology and collaboration in language documentation and revitalization: The case of a Zapotec Talking Dictionary,”  _4th International Conference on Language Documentation and Conservation_ , Honolulu (2015, February). Online:<a href="https://scholarspace.manoa.hawaii.edu/handle/10125/25320">https://scholarspace.manoa.hawaii.edu/handle/10125/25320</a>.
</li>
<li id="matthew2020">Matthew, L. and Bannister, M. “The Form of the Content: Nahuatl/Nawat in Central America (NECA),”  _Digital Humanities Quarterly,_ this issue (2020).
</li>
<li id="mcdonough2014">McDonough, K. S. _The Learned Ones: Nahua Intellectuals in Post-conquest Mexico_ . The University of Arizona Press, Tucson (2014).
</li>
<li id="munro1999">Munro, P. and Lopez, F.H., with Mendez, O., Garcia, R., and Galant, M.R. _Di’csyonaary x:tèe’n dìi'zh sah San Lu’uc. San Lucas Quiaviní Zapotec dictionary_ . Chicano Studies Research Center, UCLA, Los Angeles (1999).
</li>
<li id="munro2018">Munro, P., Terraciano, K., Galant, M., Lillehaugen, B.D., Flores-Marcial, X., Ornelas, M., Sonnenschein, A.H., and Sousa, L. “The Zapotec language testament of Sebastiana de Mendoza, c. 1675,”  _Tlalocan_ 13 (2018): 187–211. Online:<a href="https://revistas-filologicas.unam.mx/tlalocan/index.php/tl/article/view/480/458">https://revistas-filologicas.unam.mx/tlalocan/index.php/tl/article/view/480/458</a>.
</li>
<li id="nakata2005">Nakata, M. and Langton, M. “Introduction,”  _Australian Academic and Research Libraries_ , 36.2 (2005): 3–6.
</li>
<li id="nathan2013">Nathan, D. “Progressive archiving: theoretical and practical implications for documentary linguistics,”  _3rd International Conference on Language Documentation and Conservation (ICLDC)_ , Honolulu (2013, February).
</li>
<li id="nathan2007">Nathan, D., Rayner, S., and Brown, S. “Opening Dawes: Organising Knowledge around a Linguistic Manuscript,”  _Digital Resources in the Humanities and Arts_ , Dartington (2007, September). Online:<a href="http://projects.oucs.ox.ac.uk/DRHA/2007/DRHA-07/subs/36.doc">http://projects.oucs.ox.ac.uk/DRHA/2007/DRHA-07/subs/36.doc</a>.
</li>
<li id="nathan2009">Nathan, D., Rayner, S., and Brown, S. (eds.) _William Dawes’ Notebooks on the Aboriginal language of Sydney : a facsimile version of the notebooks from 1790-1791 on the Sydney language written by William Dawes and others_ . London, SOAS and Blacktown Darug Tribal Aboriginal Corporation (2009).
</li>
<li id="olko2018">Olko, J. “Spaces for participatory research, decolonization and community empowerment: working with speakers of Nahuatl in Mexico,”  _Language Documentation and Description_ , 16 (2018): 1-34. Online:<a href="http://www.elpublishing.org/itempage/167">http://www.elpublishing.org/itempage/167</a>.
</li>
<li id="ortega2019">Ortega, É. “Review: Ticha,”  _Reviews in Digital Humanities_ , I.1 (2019). doi:<a href="https://assets.pubpub.org/ic3dgh75/262410d4-7890-4590-8233-11f2eaa916e0.pdf">10.21428/3e88f64f.2cb07375</a>.
</li>
<li id="oudijk2008">Oudijk, M.R. “El texto más antiguo en zapoteca,”  _Tlalocan_ 15 (2008): 227–40. Online:<a href="http://www.revistas.unam.mx/index.php/tlalocan/article/view/28754">http://www.revistas.unam.mx/index.php/tlalocan/article/view/28754</a>.
</li>
<li id="pratt2007">Pratt, M.L. _Imperial Eyes: Travel Writing and Transculturation_ . Routledge (2007).
</li>
<li id="rice2011">Rice, K. “Documentary Linguistics and Community Relations,”  _Language Documentation and Conservation_ 5 (2011): 187–207.
</li>
<li id="romero2003">Romero Frizzi, M de la A. _Escritura zapoteca: 2,500 años de historia_ . INAH, Mexico City (2003).
</li>
<li id="smithstark2008">Smith Stark, T.C., López Cruz, A., Montes de Oca Vega, M., Rodríguez Cano, L., Sellen, A., Torres Rodríguez, A., Marcial Cerqueda, V., and Rosas Camacho, R. “Tres documentos zapotecos coloniales de San Antonino Ocotlán.” In S. van Doesburg (ed.), _Pictografía y escritura alfabética en Oaxaca_ [Pictography and alphabetic writing in Oaxaca], Instituto Estatal de Educación Pública, Oaxaca (2008), 287–350.
</li>
<li id="stoler2002">Stoler, A.L. “Colonial Archives and the Arts of Governance,”  _Archival Science_ 2 (2002), 87–109.
</li>
<li id="thorpe2014">Thorpe, K., and Galassi, M. “Rediscovering Indigenous Languages: The Role and Impact of Libraries and Archives in Cultural Revitalisation,”  _Australian Academic and Research Libraries_ 45 (2014), 81–100.
</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The full list of current team members can be found at:<a href="https://ticha.haverford.edu/en/team/">https://ticha.haverford.edu/en/team/</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Current and recent research assistants include Felipe Acosta-Muñoz, Kimberly Aguero, Carolyn Jane Anderson, Ian Davis, Ian Fisher, Eloise Kadlecek, Collin Kawan-Hemler, Filip Kesicki, Emily Lin, Jaime Metzger, Tomas Paris, Heewon Park, May Helena Plumb, and Conor Stuart Roe.## Bibliography&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry></feed>