<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://gohugo.io/" version="0.116.0">Hugo</generator><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/" rel="alternate" type="text/html" title="html"/><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/index.xml" rel="alternate" type="application/rss+xml" title="rss"/><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/atom.xml" rel="self" type="application/atom+xml" title="Atom"/><updated>2023-08-07T14:26:47+00:00</updated><rights>This work is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License.</rights><id>https://rlskoeser.github.io/dhqwords/vol/13/4/</id><entry><title type="html">Changes in Lyrical and Hit Diversity of Popular U.S. Songs 1956-2016</title><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/000440/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/13/4/000440/</id><author><name>Peter Meindertsma</name></author><published>2019-12-14T00:00:00+00:00</published><updated>2019-12-14T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>In September 2012 the Universal Music Group completed the acquisition of EMI Music, reducing the number of worldwide music label conglomerates from four to three: Universal, Sony Music and Warner Music Group. This was another step in the concentration of media corporations that accelerated in the 1980s and 1990s <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> and gradually became a global media oligopoly, a form in which a market or industry is dominated by a small number of sellers. This oligopoly now not only controls music (e.g. 85% of the U.S. recording music industry <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>) but also broadcasting, movies, publishing and advertising markets. This concentration of media ownership frequently raises concerns about the reduction of cultural diversity communicated through major media channels. Some argue that this concentration results in a shift away from serious news to infotainment <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> and that it becomes harder for independent record companies to get airplay while large companies become more selective in the artists offered to radio stations <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. Even decades ago, Theodor Adorno warned about the eroding effects of the transition from autonomous works of art to profitable cultural products and the resulting impediment of the development of individual consciousness due to a strong cultural industry <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. Yet, despite all these concerns, the aforementioned acquisition of EMI clearly indicates that the process of media convergence has not been halted.</p>
<p>This creates an opportunity to investigate the diversity of cultural output over time to see if there is a homogenization of cultural meanings, values and tastes. To do so, I have chosen to examine the diversity of an important and omnipresent cultural product: popular music, by looking at changes in the number of hit songs (songs that appeared on a chart, ranked by sales or popularity) and lyrical variation over time.</p>
<p>Instead of stitching together lyrics of a few selected songs to represent popular music, which has been, until recently, the default method for lyric related studies, I will apply a macro analytic approach to grasp popular music as a whole. With the ever increasing capacity and speed of computers it becomes easier to create and quantitatively analyze large corpora of digitized texts and other media to study underlying phenomena. It has been applied successfully in many studies (e.g. <a href="#moretti2005">Moretti, 2005</a>; <a href="#jockers2011">Jockers, 2011</a>; <a href="#michel2011">Michel, 2011</a>; <a href="#mauch2015">Mauch, 2015</a>). Note that challenges remain, such as adequately representing popular culture. Merely creating a large collection of song lyrics is not sufficient, for one can wonder if every included song qualifies to represent popular culture. And perhaps even more important: does the absence of all other similarly qualifying songs result in bias? Many studies of lyrics of popular songs tackle this issue by using charts, usually the U.S. Billboard Hot 100, to select songs that have earned a certain level of popularity. These charts remain a  “crude but effective”  means to measure the cultural impact of a song among the record buying public <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>However studies that rely on hit song charts predominantly use subsets, e.g. top 10 songs for every tenth year, and are therefore limited in scope and detail. To contribute to the extensiveness of this study, I tried to collect lyrics of all songs that appeared on the Billboard Hot 100.</p>
<h2 id="dataset-and-methodology">Dataset and Methodology</h2>
<p>The focus of this study is on lyrics from popular songs that charted in the USA, arguably the most important market in popular culture. To overcome limitations by scale, where only a few songs represent a much larger group, a major goal is to collect and analyze as much lyrics as possible of songs that have appeared on the Billboard Hot 100. Just by reaching a position on this chart, these songs have proven their popular cultural mass appeal.</p>
<p>Despite its shortcomings, e.g. payola scandals and frequent changes in the balancing of digital and physical sales and airplay influence, the Billboard Hot 100 is still by far the leading song chart of the USA and for several decades it has been used for scientific research. By many it is regarded as the most appropriate source for songs that were most representative of general cultural preferences across time in the USA <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>In order to have ample charting songs per year to be collected and analysed, the scope is restricted to the years from 1956 up to and including 2016. Billboard changed its weekly Top 40 chart of popular singles into a Top 100 in November 1955 and was renamed the Hot 100 in 1958. The year 1955 also roughly coincides with the dawn of the rock age when Rock ‘n’ Roll got a grip on the Billboard charts and quickly turned the focus of popular music primarily towards the youth and shaped popular music for at least the next forty years <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.</p>
<p>The main source for the chart listings of songs, artists and years is Bullfrogs Pond’s Billboard database, an extensive collection of Billboard related chart data (1890-2017) maintained by an anonymous ‘avid music lover’ since 1999 (Bullfrog, 2016). Many randomly selected songs’ peak positions and years were double checked with official Billboard Chart data (at Billboard.com and Joel Whitburn’s  “Top Pop Singles 1955-2012”  (2013)) and chart data at Top40db.net to verify the reliability of this source. Based upon these sources I found that of all top 100 hits from 1956 up to and including 2016 (n=28.477), about 96% (n=27.387) of these songs have (predominantly) lyrics in English, when instrumental (3.5%, n=986) and non-English lyric songs (0.4%, n=104) are excluded.</p>
<p>The texts of these songs with lyrics in English were extracted automatically <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>  from several online archives<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> . Simultaneously, automatic and manual corrections were applied to restore song structures (e.g. replacing lines like repeat chorus with the fully transcribed chorus) and to remove mark-up, punctuation and metadata about performers or musical segments (e.g. phrases like written by, intro or guitar solo). Eventually I managed to obtain the lyrics of all but 1% (n=279) of all songs sung in English that charted on the Billboard top 100 charts from 1956 up to and including 2016. This resulted in a corpus of 7.727.622 words in 27.108 song files with an average of 444 examined songs per year, <a href="#figure01">see Figure 1</a>.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Total and collected number of Billboard Hot 100 hit song lyrics per year 1956-2016. Lyrics of instrumental (3.5%), non-English (0.4%), and unobtainable (1,0%) songs were not collected.
        </p>
    </figcaption>
</figure>
<h2 id="results">Results</h2>
<p><em>1. Changes in hit diversity</em></p>
<p>Inspired by Lee’s research on the radio industry <sup id="fnref1:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, I first examined the frequency of charting songs per year and found a sharp decrease in the annual number of songs that obtained top 100, top 40, top 10 or number 1 positions (see Figure 2a, and 2b, a detailed version of 2a).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Total top 100, 40, 10 and number 1 hits in the Billboard Hot 100 per year (1956-2016).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Total top 100, 40, 10 and number 1 hits in the Billboard Hot 100 per year (1956-2016).
        </p>
    </figcaption>
</figure>
<p>The number of annual Hot 100 hits reached its low point in 2002 when 294 songs charted, which is less than 40% of its peak in 1966 when 743 songs appeared on the chart. Note that Figure 2b clearly shows a sharp decline in the total number of yearly top 10 and number 1 hits after 1991.</p>
<p>It is very likely that these changes around the year 1991 were caused by an alteration in the way Billboard tracks sales. In that year the Billboard Hot 100 switched to Nielsen SoundScan, a digital and improved system for tracking sales, based upon data that represents over 90% of the U.S. music retail market <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. It replaced a manual, error-prone and easy to manipulate system of calling selected stores about sales figures. Additionally, Billboard then also started to remove descending songs after twenty weeks that fell below position number 50, in order to make the charts more current  <sup id="fnref1:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. In theory this could make more chart positions available for new and yet uncharted songs, but it apparently did not prevent the previously observed sharp decrease of annual charting songs, and led to an increase in the average time songs spent on the charts. Perhaps the previously used manual system caused an even greater removal of descending songs from the chart.</p>
<p><a href="#figure02">Figure 2a and 2b</a> also show that for the period prior to the introduction of SoundScan in 1991, the number of Top 100, 40 and 10 hits per year was, except for a peak in the number of Top 10 songs during the 1980s, steadily decreasing since 1966. In the latter year 743 songs charted on the Hot 100 and by 1990 this number was nearly halved to 376. Since several studies have shown a positive relation between the number of different recordings that reached the hit song charts and intensity of market competition <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>  <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>  <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>, Figure 2a and 2b therefore indicate a loss of market competition and diversity.</p>
<p><em>2. Changes in word usage</em></p>
<p>Inspired by Google’s Ngram Viewer <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>, I arranged the lyric files by year and constructed a bigram viewer (see <a href="http://www.petermeindertsma.com/lyrics/">http://www.petermeindertsma.com/lyrics/</a>) to examine changes in the popularity of word and term usage. In order to limit the influence of duplicate terms in transcribed parts of the lyrics, e.g. in repeated choruses etc., I calculated the percentage of annual songs in which these words occur, so each song can only make one contribution to the popularity of a given word or term per year. This method enabled me to visualize the popularity of these words over time in order to signal trends, <a href="#figure03">see Figure 3</a>.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Relative frequencies of song lyrics that contain selected (case insensitive) terms on the Billboard Hot 100 (1956-2016). An * indicates that all suffixes are included, e.g. darlin* includes darling and darlin’.
        </p>
    </figcaption>
</figure>
<p>For example, a word like darling (or darlin’) clearly lost its popularity (<a href="#figure03">Figure 3A</a>). In a similar way this tool can visualize the impact and duration of hypes in their times, e.g. dance crazes (disco, twist) (<a href="#figure03">Figure 3B</a>), and what was on our collective minds (e.g. war and money) (<a href="#figure03">Figure 3C</a>). This macro analytic approach demonstrates a major benefit: results become quantifiable: For example, the term twist is used in nearly twice as many songs in its peak year compared to the term disco (<a href="#figure03">Figure 3B</a>). It can also visualize trends like the rapid increase of profanity in lyrics since 1991 (<a href="#figure03">Figure 3D</a>), especially when compared to its gradual growth rate in books<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> . This seems to signify an important change in American popular (music) culture and deserves more research.</p>
<p>Although this visualization method can signal changes in the popularity of word usage, it is too limited to examine changes in the homogeneity of popular lyrics. Therefore other methods are needed, like the analysis of sentiment and lexical complexity.</p>
<ol start="3">
<li><em>Changes in sentiment</em></li>
</ol>
<p>To examine an aspect of changes in sentiment over time, I applied the Affective Norms for English Words (ANEW) list. This is a word list developed by Bradley and Lang to classify texts by valence (or  “level of pleasantness” ) <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>  <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. This list contains 1034 words in English that have a score for emotional weight on a scale from 1 to 9. For example, love has a score of 8.72, suicide has 1.25. By adding these scores together for each of these ANEW words’ occurrences, the average emotional weight for each song is calculated. The resulting analysis is consistent with Danforth and Dodds’ findings <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> that the average valence of lyrics from popular songs is decreasing over time and songs on average are less happy than ever before, <a href="#figure04">see Figure 4</a>.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Average valence scores of songs on the Billboard Hot 100 per year (1956-2016).
        </p>
    </figcaption>
</figure>
<p>Finally, I examined the variance (standard deviation) of the average valence of all songs per year, <a href="#figure05">see Figure 5</a>.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Standard deviation of average valence of Billboard Hot 100 songs per year (1956-2016).
        </p>
    </figcaption>
</figure>
<p>Beside short-term fluctuations, the overall trend is a slow decrease in variance over time, which indicates a trend towards homogeneity in lyrics of popular songs.</p>
<ol start="4">
<li>Changes in lexical complexity</li>
</ol>
<p>To examine changes in lexical complexity, I computed the average number of words per song per year (<a href="#figure06">Figure 6</a>) and used Bullfrogs Pond’s data to find the average duration (length in seconds) per song over time (<a href="#figure07">Figure 7</a>).</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Average number of words per song on the Billboard Hot 100 per year (1956-2016).
        </p>
    </figcaption>
</figure>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Average length in seconds of songs on the Billboard Hot 100 per year (1956-2016).
        </p>
    </figcaption>
</figure>
<p>Both graphs show a gradual increase over time. By 1994 the average number of words per song has nearly doubled since 1960, while the average duration of songs has increased by about 60% between 1960 and 1991.</p>
<p>With this data, I also calculated the average number of words per second, which remained fairly stable at about 1.2 words per second until around 1991 when it started to increase rapidly and reached its (preliminary) peak in 2004 with 1.87 words per second, <a href="#figure08">see Figure 8</a>.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Average words per second of songs on the Billboard Hot 100 per year (1956-2016).
        </p>
    </figcaption>
</figure>
<p>This increase of the average of number of words per second in songs hints at an increase in lyrical complexity. It also suggests, like my previous findings, that a big change has occurred in popular music around 1991.</p>
<p>To further examine this likely increase in lexical complexity, I computed the percentage of unique words per text or Type Token ratio. This is a frequently used method to provide an estimate of lexical complexity where a higher percentage indicates a higher level of complexity. However, this ratio is affected by varying lengths of texts. Since I have previously demonstrated that the average number of words per song has roughly doubled between 1960 and 1994 (<a href="#figure06">see Figure 6</a>), I have used a sampling method to compensate for the changes in average length of lyrics over time. From each song’s lyrics, 75 words (sample size) were selected randomly to calculate the song’s Type Token ratio. To reduce the influence of potential unintended effects of this random selection, I repeated this process fifty times (!) per song in order to achieve an average sampled Type Token Ratio. For different sample sizes (50, 75 and 100 words), I found an increase in this sampled Type Token ratio which indicates an increase in lyrical complexity, see Figure 9.</p>




























<figure ><img loading="lazy" alt="" src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     ><figcaption>
        <p>Average Type Token ratio of songs on the Billboard Hot 100 per year (1956-2016), based upon a sample size of 75 words per song.
        </p>
    </figcaption>
</figure>
<p>Note that the average Type Token ratio starts to increase considerably around 1990. This coincides with the rapidly increasing popularity of hip hop on the Billboard Hot 100 around that time. For example, Katznelson et al. have found a higher type token ratio for hip hop songs compared to rock and pop songs between 1989 and 2009 <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>.</p>
<p>As for changes in lexical diversity, I have also examined the variance (standard deviation) of this sampled Type Token ratio and it clearly fluctuates over time, <a href="#figure10">see Figure 10</a>.</p>




























<figure ><img loading="lazy" alt="Standard deviation of sampled Type Token Ratio of songs on the Billboard Hot 100 per year (1956-2016)." src=""
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset=" 500w,
     800w, w" 
     class="landscape"
     >
</figure>
<p>This variance roughly seems to behave like a sine wave cycle, repeating nearly every twenty years. The global trend, however, is a slowly decreasing variance, which means that lyrics become more similar and again indicates a loss of diversity.</p>
<h2 id="limitations">Limitations</h2>
<p>The results of this study support the argument that the lyrics of popular songs reveal a trend toward homogeneity over time. However, this work has several limitations and acknowledging these can provide a better understanding of the scope of these results and might improve further related research.</p>
<p>A first limitation is the restriction of using only lyrics of songs that charted in the USA. Since this country currently accounts for about 4.5% of the world’s population, these results cannot be applied internationally <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>  <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> and require further research into other cultures. Also note that this study focuses solely on the pop singles charts, which relate strongly to youth culture. Other aspects of popular culture, e.g. more adult oriented pop albums, radio station playlists, music venue owners, movie scripts, popular fiction novels or special interest magazine articles, may yield different results.</p>
<p>A second restriction is the potential imperfection of the examined lyrics. Due to the lack of access to or absence of official sources, the lyrics were collected from several Internet websites, and were, unfortunately, subject to errors. These lyrics were most likely transcribed by individuals and could potentially not always accurately reflect the official spelling of the words used. For example, lyrics by British musicians could have been transcribed by American individuals choosing the word color over colour and vice versa. Additionally, since there were basically no online lyric archives before the 1990s, it is safe to assume that most of the transcriptions of songs from previous decades were made long afterwards. Since language and peoples’ preferences gradually change over time, it seems likely that these lyrics do not necessarily reflect the preferred spelling (fashions) of its original times, e.g. words like kissing and love could have been replaced by kissin’ and luv respectively. For further analysis, stemming and lemmatization techniques are recommended to improve some of these issues.</p>
<p>A further challenge is related to the increasing average number of words used per song over time. As I have shown previously <a href="#figure06">in Figure 6</a>, the average number of words per song has doubled between 1960 and 1994. This means that, regarding my method of visualizing term usage over time (<a href="#figure03">see Figure 3</a>), songs from 1994 can, in theory, contribute to the popularity of twice as many different terms compared to that of songs from 1960. A word-weighing formula might be considered to compensate for this.</p>
<p>Finally, the used method of measuring valence has its limitations. It is based upon only 1034 words that constitute the ANEW list and this in general works better for longer texts. Also, the method of counting specific words or phrases does not necessarily overlap with intended meaning, e.g. sarcasm, hidden messages or context, like changes in time and space <sup id="fnref1:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>. For example, some words with a low valence value are from time to time used as words of approval like wicked and sick and should therefore deserve a distinct and higher value.</p>
<p>Unfortunately, this study’s focus on extensiveness comes with a price, as most of the limitations mentioned above illustrate less paid attention to detail. Ideally, for an all encompassing and thorough study, this macro analytic approach can therefore not replace the traditional method of close reading, but rather supplement it. For similar or larger sized corpora, this combination can become very labor intensive. Nevertheless, for examining underlying phenomena less focus on detail is required, as Bernoulli’s law of large numbers should prove. The methods and results of this study therefore should only be applied to improve our understanding of the big picture.</p>
<h2 id="conclusion-and-discussion">Conclusion and Discussion</h2>
<p>In this study I have devised and applied a macro analytic approach for re-evaluating our understanding of popular music’s last sixty years, especially to examine if changes occurred in its homogeneity over time. Using this method, I have analyzed the diversity of hit songs and their lyrics over time and found that the number of annual charting songs on the Billboard Hot 100 has gradually, but steadily been decreasing since the 1960s until 2005<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> . I have also demonstrated that the variances of valence (a level of pleasantness) and the variances of sampled Type Token ratio (an indicator for lexical complexity) have decreased over time.</p>
<p>These findings all indicate a loss of diversity of popular songs and will hopefully inspire further research to take the next step: examine if this observed trend toward homogenization is a symptom of the aforementioned media convergence, e.g. by analyzing differences in output diversity of large vs. independent record labels over time.</p>
<p>Additionally, this study’s findings also demonstrate remarkable changes around the year 1991. It is very likely that Billboard’s switch to SoundScan in 1991 influenced these changes, but the findings suggest other causes as well. The rapid increase in the average number of words per song (<a href="#figure06">see Figure 6</a>), words per second (<a href="#figure08">see Figure 8</a>) and sampled Type Token Ratio (<a href="#figure09">see Figure 9</a>), the further decrease in valence (<a href="#figure05">see Figure 5</a>) and the remarkable increase of profanity in song’s lyrics (<a href="#figure03">see Figure 3D</a>) indicate that popular music in the USA has changed considerably at that time. This coincides with the time when hip hop became a dominant music genre on the charts, at the expense of others, e.g. music by British musicians and especially (classic, alternative and hard-) rock music. This shift is arguably the most important event that shaped the Billboard charts in the last sixty years <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>.</p>
<p>As Figure 10 points out, I have also found that the variance of the sampled Type Token Ratio roughly behaves like a sine wave cycle over time. Further research can hopefully specify if periods of rapid increases (e.g. 1989-1994) correspond with transitional periods in popular music (e.g. increased market competition and changes of dominating genres), while the rapid decreases (e.g. 1977-1981) are years of stabilization. This method can then facilitate predictions of coming changes in the development in popular music and add to the debate whether cultural products go through cycles <sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>.</p>
<p>Finally, the remarkable increase in the number of annual charting songs that peak between position 40 and 100 since 2005 (<a href="#figure02">see Figure 2a</a>), indicates new changes in chart diversity, especially in the lower chart regions, for the number of yearly Top 40, Top 10 and Number 1 songs has not changed that much since 2005. This increase of annual charting songs is likely due to Billboard’s inclusion of digital sales from online retail stores such as iTunes for compiling the weekly Hot 100 charts since 2005 <sup id="fnref2:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. These stores are in general not depending on the physical availability and storage of singles and can offer a much larger and more diverse and quickly accessible stock compared to offline retailers. Songs are also no longer required to have a physical single release in order to chart, which is exemplified by the simultaneous charting of many album tracks when current popular artists like Taylor Swift and Eminem release much anticipated new albums. It also enables short chart runs for (in general) short-lived televised song performances, e.g. by American Idol artists (since 2002) and the cast of the TV series Glee (since 2009). This increase in annually charting songs could in theory indicate a new period of increased song diversity on the charts, although the variances of valence (<a href="#figure05">see Figure 5</a>) and Type Token ratio (<a href="#figure10">see Figure 10</a>) are still (slightly) below average.</p>
<p>It is nevertheless very likely that the composition of the Billboard Hot 100 chart will continue to change. For example, in February 2013 it started to include YouTube (Vivo) streams, making it more susceptible for songs that suddenly become a hit on the Internet (e.g.  <em>Harlem Shake</em>  by Baauer). This change could lead to a further increase in the number of annual charting songs and future research should reveal how this affects the diversity of popular songs.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>I want to thank Valerio Basile, Johan Bos, Leonie Bosveld-de Smet, Gosse Bouma, Douwe Draaisma, Dicky Gilbers, Dore van Hoorn, Carel Jansen, Matthew Jockers, Henny Klein, Daniël de Kok, Laura MacDonald, Kim Middel, Gertjan van Noord, Erik Tjong Kim Sang, Nynke van der Vliet, Tity de Vries, George Welling, Dirk Jan Wolffram and especially John Nerbonne and Kristin McGee for their time and insightful comments.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Bagdikian, B.  <em>The New Media Majority</em> , Beacon Press, Boston (2004).&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Lule, J.  <em>Understanding Media and Culture: An Introduction to Mass Communication</em>  (online book), <a href="http://catalog.flatworldknowledge.com/bookhub/reader/3833?e=lulemedia_1.0-ch06_s03"> http://catalog.flatworldknowledge.com/bookhub/reader/3833?e=lulemedia_1.0-ch06_s03</a> (accessed 1 September 2012).&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Owen, D.  “Media Consolidation, Fragmentation and Selective Exposure in the USA” . In  <em>SAGE Handbook of Political Communication</em> , SAGE Publications Ltd, London (2012): pp. 402.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Lee, S.S.  “Radio Industry Structure and Music diversity: 1989-2002” ,  <em>Poetics</em> , 32 (2004): 325-342.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Adorno, T. W. and Rabinbach, A. G.  “Culture Industry Reconsidered” ,  <em>New German Critique</em> , 6 (1975): 12-19.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Stewart, J.  “What&rsquo;s Going On: Anti-War and Pro-War Hits on the Billboard Singles Charts during the Vietnam War Era (1965–1975) and the &lsquo;War on Terror&rsquo;(2001–2010)” . In S. Gibson and S. Mollan. (eds),  <em>Representations of Peace and Conflict</em> . Palgrave Macmillan, Basingstoke (2012): pp. 67-85.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Pettijohn, T. and Sacco, D.  “The Language of Lyrics. An Analysis of Popular Billboard Songs Across Conditions of Social and Economic Threat” ,  <em>Journal of Language and Social Psychology</em>  28(3) (2009): 297-311.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Garofalo, R.  <em>Rockin’ Out: Popular Music in the U.S.A.</em> , Pearson, Boston (2008).&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>To obtain lyrics from online archives, a parser was written in Perl. It included instructions to retrieve the lyrics at random delay times to avoid bot detection (i.e. non-human behaviour) and potential blacklisting.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>The lyrics were predominantly retrieved from Lyrics.com. Additional lyrics were acquired from Top40db.net, metrolyrics.com, lyricsfreak.com and, to a lesser extent from lyrics.wikia.com, releaselyrics.com, lyricsmode.com, azlyrics.com, lyricsdomain.com, lyricstime.com, lyricsmania.com, and musicsonglyrics.com.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Billboard.com.  <em>Billboard Charts Legend</em> . <a href="http://www.billboard.com/biz/billboard-charts-legend"> http://www.billboard.com/biz/billboard-charts-legend</a> (accessed 10 September 2013).&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Peterson, R. and Berger, D.  “Cycles in Symbol Production: The Case of Popular Music” ,  <em>American Sociological Review</em> , 40(2) (1975): 158-173.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Rothenbuhler, E. and Dimmick, J.  “Popular music: concentration and diversity in the industry” ,  <em>Journal of Communication</em>  32(1) (1982): 143-149.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Burnett, R. and Weber, R. P.  “Concentration and Diversity in the Popular Music Industry 1948-1986” , Paper presented at the 84th Annual Meeting of the American Sociological Association (1989).&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Michel, J.B. et al.  “Quantitative Analysis of Culture Using Millions of Books” ,  <em>Science</em> , 331 (2011): 176-182.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>See Google Books Ngram Viewer: <a href="https://books.google.com/ngrams/graph?content=fuck,shit&amp;year_start=1956&amp;year_end=2014&amp;corpus=15&amp;smoothing=0&amp;share=&amp;direct_url=t1;,fuck;,c0;.t1;,shit;,c0"> https://books.google.com/ngrams/graph?content=fuck,shit&amp;year_start=1956&amp;year_end=2014&amp;corpus=15&amp;smoothing=0&amp;share=&amp;direct_url=t1;,fuck;,c0;.t1;,shit;,c0</a>&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Bradley, M. M. and Lang, P. J.  “Affective norms for English words (ANEW): Instruction manual and affective ratings” ,  <em>Technical Report C-1</em> , The Center for Research in Psychophysiology, University of Florida (1999).&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Osgood, C., Suci, G. and Tannenbaum, P.  <em>The Measurement of Meaning</em> . University of Illinois, Urbana (1957).&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Danforth, C. M. and Dodds, P. S.  “Measuring the Happiness of Large-Scale Written Expression: Songs, Blogs, and Presidents” ,  <em>Journal of Happiness Studies</em> , 11 (2010): 441-456.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Katznelson, N., Gelman, J., Lindblom, K., and Caput, M.  <em>American Song Lyrics. A Corpus-Based Research Project</em> , <a href="http://mariecaput.myefolio.com/Uploads/737final.doc"> http://mariecaput.myefolio.com/Uploads/737final.doc</a>. (accessed 12 May 2013).&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Arnett, J.  “The Neglected 95%: Why American Psychology Needs to Become Less American” ,  <em>American Psychologist</em> , 63 (2008): 602-614.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>DeWall, C.N., Pond Jr., R.S., Campbell, W.K., and Twenge, J.M.  “Tuning in to psychological change: Linguistic markers of psychological traits and emotions over time in popular U.S. song lyrics” ,  <em>Psychology of Aesthetics, Creativity, and the Arts</em> , 5(3) (2011): 200-207.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>The number of annual charting songs began to increase again in 2005, especially in the lower chart regions.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Mauch, M., MacCallum, R.M., Levy, M., and Armand, L.M.\  “The Evolution of popular music: USA 1960-2010” ,  <em>Royal Society Open Science</em> , 2 (2015): <a href="http://dx.doi.org/10.1098/rsos.150081">http://dx.doi.org/10.1098/rsos.150081</a>.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Cosmopolitanism, Japaneseness, and Video Game Studies: A Review of Mia Consalvo's Atari to Zelda: Japan's Videogames in Global Contexts</title><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/000433/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/13/4/000433/</id><author><name>Steven Braun</name></author><published>2019-12-14T00:00:00+00:00</published><updated>2019-12-14T00:00:00+00:00</updated><content type="html"><![CDATA[<p>As someone who has spent extensive time collectively studying, traveling to, and living in Japan, I am well-versed in the myriad ways one might engage with the study of Japan across different media, consumer spaces, academic disciplines, and beyond. Products like anime and manga have entered popular culture well outside Japan’s borders, spurring communities of scholars to research their history and influence in the consumer realm; Japanese technological industries have proven their popularity and preeminence across the globe, fostering in popular imagination a conception of Japan as a futuristic, advanced society; and the study of Japanese history, religion, language, literature, and visual culture persists as major foci of research at academic institutions around the world, areas of inquiry viewed as ways to peer into questions of where Japan as a country has evolved from and where it is going. This work is illustrated by the research of many scholars in the fields of media studies and Japanese digital humanities, including Ian Condry, Molly Des Jardin, Hoyt Long, and Jonathan Abel, to name a few. Scholarship in Japanese studies continues to be defined primarily in these domains, organized around those artifacts of culture, history, and society that seem most distinctly, recognizably Japanese. Yet at the same time, I am also aware of the many ways we encounter Japan on a daily basis in much more banal, mundane spaces, through interactions with products and cultural artifacts of Japan in the global marketplace that we may not realize are foreign in their origin. It is perhaps through such mundane encounters that there is much yet to be discovered as the study of Japan spills into new domains.</p>
<p>In  <em>Atari to Zelda: Japan’s Videogames in Global Contexts</em> , Mia Consalvo invites the reader to focus their attention on one such domain of encounters which has historically been both mundane and distinctive in its expression: video games from Japan and the Japanese game industry. Though (disappointingly) making little reference to neither the Atari gaming console nor the  <em>Legend of Zelda</em>  game series, Consalvo’s book succeeds more in the task defined by the second half of its title, positioning the practices of Japanese developers both within the Japanese game industry as well as the global marketplace. In the process, Consalvo endeavors to interrogate the evolution of Japanese games between those spaces through several lenses that assess their relationship with globalization, notions of Japaneseness, and the global game industry at large: how has globalization influenced the ways that video games from Japan enter the global market, and in turn, how have Japanese games influenced the practices of the global game industry? What makes a game distinctly Japanese, and what might this suggest about how such practices have evolved within a rapidly globalizing gaming industry that is both consumptive and agnostic of such cultural differentiation? Using strategies ranging from the organization of multinational development and production teams to the recruitment of specialized localization expertise, the book suggests Japanese producers of video games have developed practices that tug at how consumers relate to video games from Japan, the Japaneseness of those games, and ultimately, the consequences such encounters have for creating communities of players that are globally mobilized.</p>
<p>Consalvos begins by crafting the framework that is intended to weave in and out of the chapters of the book, one oriented around cosmopolitanism, monolithic Japaneseness, and its origins in japonisme and neo-techno orientalism <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Though each in turn is discussed as a theoretical buttress for the analyses that follow, these conceptual abstractions are aliases for much larger discourses that unfortunately feel more distantly removed from the structure of Consalvo’s arguments in subsequent chapters than I would have preferred. While Consalvo gives these concepts a basic theoretical treatment in the introduction, I often found myself having to actively position the discussions that appear in each chapter back within this introduced framework, building and rebuilding the recurring thread of analysis along the way. In my own background in digital humanities, the relationship between digital humanities and cosmopolitanism is not readily apparent, particularly in the field of Japan studies where digital humanities approaches are yet nascent and often tangentially attached to traditional studies of history, literature, and culture. Despite wishing for a bit more guidance from the author on this recontextualization, though, I came to understand by the end of the book that these concepts are intended not so much as fixed waypoints but rather as often-shifting concepts that scope the book’s ultimate objective – to understand the study of Japan’s video games as itself an uncertain endeavor that is fraught with ambiguity <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>Perhaps recognizing this ambiguity, Consalvo proceeds to approach the study with a strategy also fraught with its own shifts in boundaries. In the subsequent chapters, Consalvo explores a different facet of the Japanese video game industry, positioning each within a broader context of the global game industry. To begin, in chapter one, Consalvo discusses her study of a group of several non-Japanese players of Japanese video games, considering the extent to which those games spurred them towards cosmopolitan practices in varying forms <sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Their practices range in depth and breadth, from casually studying Japanese language to living and working in Japan, representing a spectrum of cosmopolitan dispositions that Consalvo argues is an expression of globalization in action <sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In the process, Consalvo interrogates the role that video games themselves have played: are such players predisposed to cosmopolitanism by other means, or did the video games these individuals played cause them to engage in cosmopolitan practices? Recognizing the many different ways cosmopolitan dispositions can be expressed – banal/mundane, consumer, pop, esthetic – Consalvo considers what it means to think of video games as a space of cosmopolitan activation, suggesting that game studies offers a new lens through which to theorize historical definitions of what cosmopolitanism truly means <sup id="fnref4:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>In reading chapter one, I found myself reflecting on my own experience playing Japanese video games. Much like the many individuals profiled in Consalvo’s research, I too was exposed to video games from Japan at an early age and captivated by them without fully understanding what it meant for those games to be from Japan. Here and in the following chapters, Consalvo discusses Koichi Iwabuchi’s notion of cultural odor – or the sense of Japanese origin that comes attached to and has been historically designed out of exports from Japan – as something that the players who were interviewed either embraced enthusiastically or paid little attention to <sup id="fnref5:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. For those players who were unaware of the games’ Japanese origin, discovery of their Japaneseness resulted in different responses, inspiring some to study the culture, language, and history of Japan in other deeper ways. As someone whose own early interest in Japan was at least partially informed by encounters with Japanese video games, I greatly appreciate Consalvo’s inclusion of these players’ perspectives for they demonstrate that in game studies, the experiences and practices of individual consumers can tell us much about the industry’s evolution.</p>
<p>After this focus on players, Consalvo then moves on to discuss the games themselves, conducting an environmental scan of the variety of games produced by Japanese developers across different consoles and genres <sup id="fnref6:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Despite Consalvo’s attempt to assert otherwise, however, I unfortunately felt as though chapter three read more like the author’s description of her personal experience of playing games or interacting with different conventions of gameplay in Japanese games, than a holistic assessment of why an analysis of those games is important in the first place. In the end, Consalvo endeavors to position discussion within a larger consideration of Japaneseness, exploring the features of games that make them seem distinctly and uniquely Japanese <sup id="fnref7:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. As the author demonstrates, games’ expressions can come in many forms – by way of language, cultural reference, gameplay feel, geography, genre, and platform – and as such, pinning down the origins of Japaneseness in such games is as slippery as defining Japaneseness in the first place.</p>
<p>It is at this point that Consalvo pivots her analysis to respond to this apparent ineffability through more indirect means. Here the discussion of Japaneseness is transitioned away from defining what it is and where it comes from and toward an analysis of those practices that are designed to minimize or erase that very Japaneseness to enhance a game’s consumption in foreign markets – game localization <sup id="fnref8:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Consalvo explores the many activities that come with localizing Japanese games for foreign audiences and the variable energy Japanese game companies invest in that process, suggesting that a key recent evolution in Japanese game developers’ practices abroad is the extent to which they work to translate the cultural and linguistic noise of Japanese games into an experience that transcends their foreign origin. It is also where Consalvo elaborates upon an important concept introduced earlier, that of the culture broker  <sup id="fnref9:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> who makes decisions about how to best transform the strongest signals of Japanese origin (in video games) into their analogous expression in other cultures <sup id="fnref10:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In describing the translation-like art of adapting Japanese video games for global markets, Consalvo writes,  “localized content is never a true picture of another country or culture but is usually more a pastiche of symbols, icons, and broad references. The job of the localizer is more akin to [Mark] Peterson’s culture broker, whose job is to create harmony from the noise or discordance of another language and another culture, complete with its accents, idioms, slang, and shortcuts”   <sup id="fnref11:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Consalvo thus suggests that localization experts do precisely this work and are culture brokers themselves; localization endeavors not to necessarily erase a sense of the foreign but rather translate the experience of the original into an analogous experience in societies and cultures outside of the one in which it was created <sup id="fnref12:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Much later in the book’s concluding pages, Consalvo rounds this discussion out with an intriguing parallel to early principles of japonisme. In the same way that art collectors of the nineteenth century influenced the products that were exported out of Japan to serve the tastes of Western consumers, so too have Japanese video games become directly influenced by and sometimes designed for the desires of foreign markets <sup id="fnref13:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Far from being something to entirely eliminate, however, a game’s perceived Japaneseness can sometimes be regarded by gamers as something desirable, which suggests that localization as a practice can occupy a useful dialogic space between developer and consumer <sup id="fnref14:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>As we approach the end of the book, Consalvo finally invites the reader to consider yet another lens of Japanese video games at a more macroscopic level, looking at the practices of entire companies and the industry itself <sup id="fnref15:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In the same way that individuals can be assessed along a spectrum of cosmopolitan dispositions, so too can video game companies. This is a lens that Consalvo had opened at an earlier point in the book when discussing Square Enix in particular, a Japanese game developer whose games have significant international acclaim. There, Consalvo notes,  “The company’s activities are cosmopolitan in many ways: its aggressive entry into multiple markets, expanding use of localization, acquisition of Western studios, and ever-expanding portfolio demonstrate its commitment to travel to multiple lands, learn about the other, take risks, and be transformed in the process”   <sup id="fnref16:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Continuing this conversation against a backdrop that considers Japanese games’ foreignness as an inextricable facet of their mobility, Consalvo posits an intriguing idea: that Japaneseness, when not regarded as something to be actively scrubbed out of Japanese video games, can sometimes be used as a defensive rhetoric by Japanese video game companies to minimize risk <sup id="fnref17:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. The idea is rooted in notions of Japanese exceptionalism, or nihonjinron, and suggests that since Japanese esthetic preferences in video games are so different from those of Western companies, Japaneseness by default could explain when and why Japanese games fail to succeed beyond Japan’s borders <sup id="fnref18:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In this way, Consalvo’s assessment of Japanese game developers is inflected by a framework that regards Japaneseness and its variable expressions in a globalized, cosmopolitan industry as an integral part of game developers’ practices. In chapter seven, Consalvo explores how such developers use multiple senses of Japaneseness to inform their design processes, noting in particular how they use one sense  “to refer to design elements that possess an almost ephemeral quality of Japaneseness. This quality holds together multiple beliefs where Japaneseness can be an invocation of the positively valued, weird, wacky, and beautiful, elements of a game as well as of the perhaps alienating, remote, or irreducibly foreign components that Western developers cannot imitate or emulate”   <sup id="fnref19:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Here again the author points out how Japaneseness, variably invoked as desirable or undesirable, measurable or ineffable, may be a key component in understanding how Japanese video games have influenced the global gaming industry at large.</p>
<p>Reaching the concluding chapter, I find myself struggling to reorient Consalvo’s wide-ranging analysis – all the way from individual game players to individual games, localization teams, development companies, and finally the industry at large – within the initial (specific) context that sought to consider the relationships between globalization, notions of Japaneseness, and the video game industry. In considering the many foci the book explores, several questions come into view: is  <em>Atari to Zelda</em>  primarily a study of Japanese video game developers, their rhetorics, and their practices? Is it a study of how those companies have affected the nature of the global video game industry? Is it a study of their games, and how they are consumed in a global context? Or is it a study of Japanese exceptionalism, expressed through a cultural product that has become undeniably globalized in its mobility? The best answer to this question is perhaps that it is all of the above. Indeed, in the penultimate chapter of the book, Consalvo summarizes what feels to me to be the most that can be stated: a recognition that  “Japanese videogames have influenced Western game developers in a multitude of ways and in doing so have contributed in key ways to a global culture”   <sup id="fnref20:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. This assertion opens up new opportunities for Japanese digital humanities, positioning the traditional study of Japan, its culture, and the globalization of its products within a reinvented digital understanding of cosmopolitanism that is made mobile by video games and related media.</p>
<p>In the same way that an attempt to reduce a study of Japaneseness down to observable characteristics would imply that Japanese video games can be characterized in singular, unidimensional terms, Consalvo contends that her research makes clear that it is no longer useful to speak of the video game industry as though it were a singular, monolithic, homogeneous entity <sup id="fnref21:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Instead, it is better to speak of many industries proliferating in parallel, and in consequence, of the impact of Japanese video games on the practices of specific subindustries of the global market. In the discussion of many Japanese game developers – Square Enix, Capcom, Level-5, Nintendo, and beyond – Consalvo describes several expressions of this differentiation, including the increased permeability and gradual erasure of distinctions between the borders of national and global marketplace, stratification between handheld versus console games, relationships between industry localization efforts and fan translators and ROM hackers, and the rapid emergence of indie game studios, each inflected with the complexity of defining Japaneseness. I found the concluding chapter to be the most useful of them all, for it answered most concretely a lingering feeling of uncertainty that emerged in chapter one. But perhaps Consalvo’s work is successful for precisely this reason, contributing to Japanese and game studies alike a plethora of new questions to explore: at the same time that it is impossible to precisely define the ways that Japanese video games have influenced the global game industry, Consalvo’s imprecision demonstrates that as the industry continues to evolve, so too will the ways in which we understand its influence.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Consalvo, Mia.  <em>Atari to Zelda: Japan’s Videogames in Global Contexts</em> . MIT Press, Cambridge, MA (2016).&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref10:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref11:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref12:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref13:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref14:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref15:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref16:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref17:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref18:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref19:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref20:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref21:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Creating a User Manual for Healthy Crowd Engagement: A Review of Mark Hedges and Stuart Dunn's Academic Crowdsourcing in the Humanities: Crowds, Communities and Co-production</title><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/000435/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/13/4/000435/</id><author><name>Samantha Blickhan</name></author><published>2019-12-14T00:00:00+00:00</published><updated>2019-12-14T00:00:00+00:00</updated><content type="html"><![CDATA[<p>In an academic context, crowdsourcing refers to the act of presenting data to members of the public, and inviting them to perform a task, or series of tasks, upon those data. It is a broad definition, but crowdsourcing is a broad methodological concept that can be applied in a number of ways, from academia to business practice. As their title suggests, Mark Hedges and Stuart Dunn narrow the scope considerably with  <em>Academic Crowdsourcing in the Humanities: Crowds, Communities and Co-production</em> , aiming to offer practical guidance, theoretical frameworks, and real-life examples from crowdsourced humanities research projects. Even within this limited scope, there is a wide range of possibility for crowdsourcing when used as a method of academic research, and the authors structure their text accordingly.</p>
<p>Such breadth of methodological usage is not new territory for authors writing about digital projects in the humanities (and it should be said that the focus within this text is overwhelmingly on digital methods, though the authors acknowledge crowdsourcing’s pre-digital roots), which can be difficult to fit within a single framework, particularly due to frequent advances in the technologies that support digital projects. The potential audience for this methodological text can include everyone from participants in digital humanities projects to practitioners — including (but not limited to) researchers, archivists, academics, librarians, institutional staff, and students.</p>
<p>The authors address this breadth of scope in content as well as audience by using existing literature from other participatory research fields (most notably the adjacent field of citizen science) as a starting point on which to build their framework. They note that, under the umbrella of citizen science, projects can either focus on data processing (delegative tasks) or on bringing in external participants to the process of research (democratizing tasks) <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Using the framework of citizen science allows the authors to present the parallel outcomes from humanities-focused projects. These include a distinction between academic knowledge and the knowledge production typically associated with academic crowdsourcing, as well as frequent outcomes for humanities crowdsourcing, such as content transformation and information synthesis. However, this discussion also allows the authors to identify where the framework of citizen science does not meet the needs of the humanities community, thereby requiring a separate system within which this work can take place <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>Creating a framework for any digital research method presents a unique challenge. The speed with which tools are released, adapted, and discontinued — in conjunction with the relatively slow development and practice of the academic research process, particularly in regard to traditional methods of publication — means that any sort of so-called standard practice can be very difficult to sustain, and research making use of digital technologies often becomes commonplace within academic fields before any type of structure can be proposed, peer-reviewed, and refined.</p>
<p>A lack of standardization in the early stages of implementing new academic research practice does not necessarily guarantee a negative outcome for the work conducted within these nascent technological environments. Such instances of trial and error can allow new practices to emerge, free from traditional boundaries, but it often means that meta-textual studies must simultaneously function as both historiography and theory for these fields: critiquing, reviewing and suggesting best practices for their continued use. Hedges and Dunn have set out to provide just such a structure with  <em>Academic Crowdsourcing in the Humanities</em> , a work that began as a  “typology of arts and humanities crowdsourcing methods”   <sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, but which ultimately functions as a sort of how-to guide for those who wish to create, evaluate, or otherwise engage with academic crowdsourcing in the humanities. Throughout the book, the authors incorporate interviews with experts, practitioners and participants in crowdsourcing projects, gathered from Hedges’ and Dunn’s 2012  <em>Crowdsourcing Scoping Study</em>  and a PARTHENOS project-supported  <em>Foresight Study</em> , which bring an appropriately co-created element to the text.</p>
<p>Though researchers in the humanities have acknowledged crowdsourcing as a method since the early 2010s, the majority of publications on the subject have been overviews of how crowdsourcing has been used within specific humanistic disciplines or sub-disciplines (examples include <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>), explorations of the effect of public engagement methods in the digital humanities <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, or research studies resulting from individual crowdsourcing projects (see for example any of the articles produced by the  <em>Transcribe Bentham</em>  team, including <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> and <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>). These early publications are thoroughly referenced in  <em>Academic Crowdsourcing in the Humanities</em> , and their existence essential to the creation of this text, but Hedges’ and Dunn’s work is filling a much-needed gap in the literature by providing a general framework that will be useful for students, research professionals, and members of the public alike.</p>
<p>The first three chapters of the book are devoted to an overview of crowdsourcing as a method, including an examination of the historical and technological developments that set the stage for a rise in modern academic crowdsourcing (including the World Wide Web, Web 2.0, and business-oriented crowd models); the scientific origins of crowdsourcing as a method, and how they have influenced subsequent humanities-based work; and — perhaps most importantly — the presentation of a typology of crowdsourcing, modeled after Short and McCarty’s methodological commons for digital research methods in the early 2000s <sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. A number of projects are used as examples to illustrate many of the practices discussed in the early chapters, and actual case studies do not appear until Chapter 4, where they are used mainly to further illustrate examples of the typology presented in Chapter 3. This structure allows Hedges and Dunn to present a useful overview of how academic crowdsourcing projects work, without veering into a prescriptive approach.</p>
<p>Once the authors have presented the history and methods, and offered a shared vocabulary for the actions being taken within digital crowdsourcing projects, they turn their attention to the social elements of crowdsourcing, both for individuals and communities alike. Topics include roles within projects (Chapter 5), motivations for and benefits of participation (Chapter 6), ethical issues like exploitation of volunteer labor and questions of data ownership (Chapter 7), and the role crowdsourcing can play in the creation of knowledge and memory in regard to cultural heritage (Chapter 7). The chapter on ethics is particularly welcome. When digital methodologies involve members of the public in academic work, as is the case with crowdsourcing, it becomes essential to create a system within which projects can be evaluated, as such systems are needed not only for the benefit of the academic research output, but to ensure the fair and ethical treatment of the communities participating. There has been a fair amount of work published on the ethics of paid crowdsourcing, in academia and other platforms like Amazon’s Mechanical Turk (see for example <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>), but this is not the case regarding publications on unpaid academic crowdsourcing.</p>
<p>The discussion of labor and exploitation within the chapter on ethical issues presents commonly-asked questions about the ethical grey area that exists around volunteer participation in academic research <sup id="fnref4:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In this section, the interview excerpts are useful for illustrating some of the questions which do not have a definitive answer, especially those which relate to the various justifications presented for why academic crowdsourcing should not be considered unethical. Hedges and Dunn do not shy away from these often difficult topics, and the way they present this information gives a unique insight into the care with which project creators must go about the work of designing, developing and running projects:  “While participants do not in general regard themselves as exploited, their willingness to volunteer and their professed enjoyment in participating does not in itself imply that humanities crowdsourcing is in ethical terms positive, or even neutral ” <sup id="fnref5:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>For all cases involving ethics and crowdsourcing, the authors note that transparency and regular communication are requisite elements for projects involving the public, as well as acknowledgment of participants and open access to project outcomes in the form of data. The suggestion of access to outcomes in the form of data is critical, but the authors miss the opportunity to discuss a delicate but important issue: that of open access to resulting publications which make use of project data. The authors come close to this topic in an earlier discussion of motivations and benefits, stating  “Most humanities crowdsourcing projects, however, do not reward their contributors in material or professional ways” , having listed publication as a material outcome for researchers in the previous sentence <sup id="fnref6:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, but fall short of calling for open access publication as a requirement for crowdsourcing project practitioners. In many ways this is part of a larger conversation about access to publication within academia and is certainly not exclusive to the field of crowdsourcing, but it is particularly relevant to a field which invites — and relies upon — public participation. Is it ethical to ask participants to volunteer their time for research, and then put a paywall between those same people and their access to the resulting publications?</p>
<p>In the final chapter,  “Crowds past, present and future” , the authors reiterate the main arguments from the first eight chapters, and present some suggestions that will benefit practitioners of and participants in digital crowdsourcing in the future. These include human-computer optimization methods, data literacy initiatives for the public, and adoption of open data frameworks (another place where a slight push into adjacent issues of open access publication would have been welcome). Hedges and Dunn note that many projects and wider initiatives already exist which make use of and promote these approaches, but they would certainly benefit from wider adoption.</p>
<p>In their conclusion, the authors note that  <em>Academic Crowdsourcing in the Humanities</em>  will not be a step-by-step guide for crowdsourcing practitioners, but is instead meant to provide a theoretical framework to ensure that there is a healthy balance between the quality of project outcomes, and the experience of participants. It is indeed a welcome addition to the growing corpus of publications related to academic crowdsourcing, and when used in conjunction with the existing literature will be a wonderful tool for participants and practitioners alike.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Hedges, M. and Dunn, S.,  <em>Academic Crowdsourcing in the Humanities: Crowds, Communities and Co-production</em> . Elsevier, Inc. (2017).&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Ferriter, M.  “Inviting Engagement, Supporting Success: How to Manage a Transcription Center” ,  <em>Collections: A Journal for Museum and Archives Professionals</em> , 12.2 (2016): 97-116. DOI: <a href="https://doi.org/10.1177%2F155019061601200204">https://doi.org/10.1177%2F155019061601200204</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Ridge, M. (ed),  <em>Crowdsourcing Our Cultural Heritage</em> . Ashgate, Surrey (2014).&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Terras, M.  “Crowdsourcing in the Digital Humanities” . In S. Schreibman, R. Siemens, and J. Unsworth (eds),  <em>A New Companion to Digital Humanities</em> , Wiley-Blackwell (2016), pp. 420-439. DOI: <a href="https://doi.org/10.1002/9781118680605.ch29">https://doi.org/10.1002/9781118680605.ch29</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Causer, T. and Wallace, V.  “Building a volunteer community: results and findings from  <em>Transcribe Bentham</em> ” ,  <em>Digital Humanities Quarterly</em> , 6.2 (2012). Available at: <a href="/dhqwords/vol/6/2/000125/">http://www.digitalhumanities.org/dhq/vol/6/2/000125/000125.html</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Causer, T. and Terras, M.  “Crowdsourcing Bentham: Beyond the Traditional Boundaries of Academic History” ,  <em>International Journal of Humanities and Arts Computing</em>  8.1 (2014): 46-64. DOI: <a href="https://doi.org/10.3366/ijhac.2014.0119">https://doi.org/10.3366/ijhac.2014.0119</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Williamson, V.  “Can crowdsourcing be ethical?” ,  <em>TechTank</em>  blog (Feb. 3, 2016), <a href="https://www.brookings.edu/blog/techtank/2016/02/03/can-crowdsourcing-be-ethical-2/">https://www.brookings.edu/blog/techtank/2016/02/03/can-crowdsourcing-be-ethical-2/</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Decoupling Quality Control and Publication: The Digital Latin Library and the Traveling Imprimatur.</title><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/000438/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/13/4/000438/</id><author><name>Samuel J. Huskey</name></author><author><name>Jeffrey C. Witt</name></author><published>2019-12-14T00:00:00+00:00</published><updated>2019-12-14T00:00:00+00:00</updated><content type="html"><![CDATA[<h1 id="decoupling-quality-control-and-publication-the-dll-and-the-traveling-imprimatur">Decoupling Quality Control and Publication: The DLL and the Traveling Imprimatur.</h1>
<h2 id="background-and-history-of-the-digital-latin-library">Background and History of the Digital Latin Library</h2>
<p>People have been publishing digital versions of Latin texts — in the sense of making them available to the public — for at least as long as there has been an internet. Until recently, however, digital Latin texts did not include any of the features of critical editions, for a variety of reasons. Copyright restrictions have prevented the digitization of anything but the main text of existing editions. The technical challenges of representing a critical apparatus in a digital format are considerable. Perhaps the most significant barrier has been the problem of defining what a digital critical edition is. Then there is the issue of publication itself. Scholars are reluctant to try a new form of publication if they are not certain that their peers will equate it with existing forms.</p>
<p>For all of these reasons, the publication of digital critical editions of Latin texts has been the primary objective of the DLL project from its beginning. It is why representatives of three major learned societies, the <a href="https://classicalstudies.org">Society for Classical Studies</a> (SCS), the <a href="https://www.medievalacademy.org">Medieval Academy of America</a> (MAA), and the <a href="https://www.renaissancesociety.org">Renaissance Society of America</a> (RSA) have always been on the project’s advisory board, since these three groups share a common interest in promoting the publication of digital critical editions of Latin texts. Publication has also been the main factor in the project’s funding, which has so far come solely from the Scholarly Communications program of the <a href="https://www.mellon.org">Andrew W. Mellon Foundation</a>.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>  In short, publication is the reason for the project’s existence.</p>
<p>But what will the DLL publish? The term digital edition can be applied to a wide variety of projects, from simple web pages with just a text and some notes to multimedia projects that include transcriptions of multiple manuscripts, digital images of manuscripts and editions, visual representations of textual data, links to other resources, special tools for reading and analysis, and other features.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  This wide range of possibilities makes it possible to create digital editions that highlight the special characteristics of individual texts or collections. But those same possibilities complicate the implementation of uniform criteria for evaluating projects and developing reliable, stable outlets for their publication. It also frustrates efforts to query, compare, and reuse information from multiple projects, since the data are stored in any number of formats.</p>
<p>The key word in that last sentence is data. Regardless of the presentational format — a printed book, a multimedia resource, a data file, a visualization — the quality of the information in a critical edition is what matters most. However aesthetically pleasing a critical edition — print or digital — might be, it is not worth much if the text and accompanying materials are based on shoddy scholarship. For that reason, we have made the decision to decouple the data of a digital critical edition from any of the presentational formats that it might take. In other words, the DLL is a publisher of critical editions not as books or web pages, but as sets of data.</p>
<p>This is not to say that the presentation of an edition’s data does not matter, or that encoded data is not itself a type of presentation.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>  Rather, the point of the decoupling that we propose here is to recognize the importance of treating presentation as a field of scholarship and practice in its own right. In other words, the work of textual editors should be editing texts. In addition to doing the work of textual criticism, editors should not be expected to master the fields of Data Visualization and Human Computer Interaction, not to mention the technologies and programming languages required to build and maintain sophisticated applications.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>  By the same argument, designers of interfaces and tools should not be expected to master the field of textual criticism. They should, however, be expected to base their work on texts that meet the highest standards of scholarship.</p>
<p>The DLL itself puts this decoupling into practice by providing its own applications for using LDLT texts. For example, its web-based DLL Viewer is an ongoing scholarly project of Hugh Cayless that presents an LDLT edition’s data in a user-friendly, feature-rich online interface based on the JavaScript library CETEIcean.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>  Chris Weaver has also built an experimental application for applying data visualization techniques to critical editions, with a view to encouraging data visualization as a form of philological scholarship<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> . The DLL also provides a service for generating PDF versions of critical editions so that they can be printed out in the format familiar to generations of readers. Since the data for the DLL&rsquo;s critical editions will be available on an open basis, others may devise other presentational formats, which leads to the point of this article.</p>
<p>Our aim is to provide a means of independently verifying that a text presented in an interface has undergone scholarly peer review. In this way, textual editors receive credit for their work when it is used in other projects, and interface designers and others can certify that their data come from the authorized, published version of a text. The DLL Review Registry Service fills that need by providing what we are calling a travelling imprimatur.</p>
<h2 id="the-dll-review-registry-service">The DLL Review Registry Service</h2>
<p>The DLL Review Registry Service is one piece of a larger ecosystem that is trying to change the way we think about publication and quality control. In traditional models, publication and the imprimatur of quality control have been tightly coupled. The publisher is responsible not only for printing and distributing a text, but also for providing an imprimatur that indicates that the text in question has reached a certain level of quality. A consequence of this approach is that the imprimatur of a text is bound to a particular presentation of the underlying data. This coupling means that if one wants to access or use the reviewed text, one must do so exclusively within the confines of the particular presentation offered by the publisher. This requirement severely limits our ability to reuse the underlying data for new and unanticipated purposes and it likewise de-incentivizes scholarly interest in creating reusable data of high quality.</p>
<p>One of the most exciting possibilities afforded to us by the digital medium is the ability to use and re-use a text for a plurality of purposes and within a plurality of presentations. With a single source document we can create books, websites, databases, and networks tailored to specific research questions.</p>
<p>Unfortunately, the dominant publication practices have not kept pace with these changes. While it is now technologically possible to separate the underlying data of a text from its presentational form, the practice of coupling an imprimatur to its publication practically demands that the reviewed text can only be used in a single presentational form, severely limiting the way a peer-reviewed text can be reused.</p>
<p>The DLL and its partners aim to offer a new kind of peer review that separates the task of review and quality control from the task of publication and distribution.</p>
<p>In our model, each of the partner organizations undertakes the tasks of reviewing the underlying data of a given text rather than any particular presentational form. The DLL Review Registry Service exists to help record these reviews and make them accessible for re-use throughout the web in any publication platform and any client viewer.</p>
<p>On this approach, reviews are tied to the reviewed text using a cryptographic hash. <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>  A cryptographic hash allows us to identify a text not by its location on a file system, but by its digital fingerprint. Every file reviewed by a given society can be reduced to a unique number. If a single character were added or subtracted from the reviewed text, its fingerprint would change, and any end user would know immediately that the file in question is not identical to the file reviewed and approved by the society.</p>
<p>The DLL Review Registry Service is built around these unique fingerprints. Every review certificate (described below) indicates the hash of the file that has been approved. It then associates this hash with a rubric or set of criteria used by the society to make their evaluation.</p>
<p>Meanwhile, any publication application, whether print or web, can use the fingerprint of the file to discover any existing reviews. Using the DLL Review Registry Service API, a client application can compute the hash of any file it has. It can then send that hash to the DLL endpoint and discover any review of that precise file. For any request, the DLL endpoint will respond with a machine actionable set of metadata about the review for this file.</p>
<p>Included in this response is a link to a society’s badge or icon that can be used in client applications to show that the text the end-user is currently seeing has been reviewed by one or more of the academic societies working in collaboration with the DLL. Additionally, the DLL Review Registry Service will return a review ID. Clients can use this ID to create a hyperlink back to the original review. In this way, end users can click on the badge and be immediately brought back to the review report to verify that the text they are viewing on a client site is the same text that has been reviewed through the DLL. Finally, clients will receive a pointer to an issued certificate, indicating the nature of the review and the document reviewed, that itself has a cryptographic hash and is digitally signed using the reviewing society’s private key. This certificate can itself be detached from the DLL Review Registry Service and accessed anywhere on the web. No matter where this signed certificate is discovered, by using the certification verification system described below, clients can offer users a way to verify the authenticity of the certification independent of the DLL Review Registry Service or domain name.</p>
<p>In this regard, the DLL Review Registry Service operates as one of possibly many indexing or discovery services. This service is therefore centralizing only in the sense that it keeps track of review certificates in a single registry. It thereby provides a convenient API for clients to discover these certificates. However, because the authority of the review certificates does not come from its association with a given domain name or API endpoint, but from the certificate&rsquo;s signature, anyone can create a similar indexing service, allowing clients access to alternative discovery APIs via other web domains.</p>
<p>In sum: Instead of confining the imprimatur to a particular book or particular website, the DLL Review Registry Service assigns an imprimatur to the underlying data. The service allows that review to be instantly accessed regardless of where or how that text is being published. In this way, the imprimatur travels with the text wherever it goes, which is why we refer to it as the traveling imprimatur.</p>
<h2 id="overview-of-technical-implementation-of-the-dll-review-registry">Overview of technical implementation of the DLL Review Registry</h2>
<p>The follow is a technical overview of the 1.0.0 DLL Review Registry Service. Given the fast pace of web development and our heavy use and modification of emerging technologies, the following description should not be viewed as documentation of the production system. For up-to-date documentation, the production system itself should be consulted (<a href="https://dll-review-registry.digitallatin.org">https://dll-review-registry.digitallatin.org</a>). Instead, we offer here a description of the basic architecture of the review system with sufficient technical detail to make that pattern clear and intelligible. While the specific details of how that pattern is executed will undoubtedly change over time, it is the larger pattern and workflow that we aim to communicate here.</p>
<p>There are three main interactions that the DLL Review Registry Service anticipates:</p>
<ul>
<li>review creation</li>
<li>review verification</li>
<li>review retrieval</li>
</ul>
<p>In order to ensure the long-term survival of these reviews and to avoid the pitfalls of a service with a single point of failure, we have attempted to enact all three aspects in the most decentralized way possible, and it will be the goal of further development of the system to continue moving in this direction as new technologies emerge and stabilize.</p>
<p>As mentioned above, this means that while for convenience the service will offer a public-facing site and a centralized index of reviews, the issued review certificates themselves are not dependent on the index for their existence or retrievability. Moreover, reviews will be created and published in such a way that the authenticity of their content is not dependent on the origin from which they are retrieved. That is, one need not infer the legitimacy of the review based on the domain name or service from which it was retrieved. Instead the certificates will carry within themselves sufficient information for new aggregation and new index services to be constructed from verified content. Thus, it will be possible for multiple indices of these reviews to exist at the same time. More importantly, this approach allows subsequent indices to easily replace the existing index service should that become necessary.</p>
<h2 id="review-creation">Review Creation</h2>
<p>When a society is ready to submit a review for an approved edition, it can submit that review in one of three ways: via a webform, via a  <code>POST</code>  request to the DLL Review Registry API, or they can construct, sign, and publish the review themselves and then submit a minimal  <code>POST</code>  to register the existence of the review. The latter option may lack the convenience of the former options, but the option exists to emphasize that the creation and verification of these reviews is based on a set of rules and protocols, not on the existence of a particular website. Registration with the DLL is then simply a way of letting particular aggregators know about the existence of the review created according to community standards and protocols described here. The aggregator then functions as a convenient discovery endpoint whereby third party clients can discover the existence of reviews of interest.</p>
<p>In its most basic form, a review is a JSON document that takes as its template the <a href="https://openbadges.org/">OpenBadges</a> specification.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>  The OpenBadges specification is primarily designed for assigning badges to people as recipients. In our case, we want to award badges or certificates not to people, but to documents: documents that can be both identified and retrieved by a unique fingerprint.</p>
<p>To do this we make use of another emerging technology called IPFS or the <a href="https://ipfs.io/">Interplanetary File System</a>. With the help of IPFS we are not only able to generate a unique fingerprint (a SHA256 hash) of the file being reviewed, but via the IPFS network we are actually able to retrieve this file by its hash or content rather than its location.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>  This gives us an immediate level of decentralization and verification. In order to retrieve a specific certificate and to be certain that one is in fact receiving the desired certificate, a user does not need to care about the location (or domain) from which the file is retrieved. Requesting the certificate by its unique hash or fingerprint guarantees that the file received is the file with this fingerprint. Change a bit in the hash and a different file will be received. Change a bit the file and the file is now a new file and will no longer be returned when the hash of the previous version is requested.</p>
<p>Our modified OpenBadges certificate uses the recipient field to identify the IPFS hash of the document or documents being reviewed, rather than a name, email, or url. In addition, the certificate itself should include the public key of the agency of institution that signed the document (see the section of verification below). This public key itself can be hashed and made addressable via the IPFS network as well being stored and addressed via the DLL Review Registry site.</p>
<p>A basic certificate can be seen here:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span> { <span style="color:#f92672">&#34;@context&#34;</span>: <span style="color:#e6db74">&#34;https://w3id.org/openbadges/v2&#34;</span>, <span style="color:#f92672">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;urn:uuid:2d817e2a-278a-40fe-9080-af73e483699b&#34;</span>, <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;Assertion&#34;</span>, <span style="color:#f92672">&#34;recipients&#34;</span>: [ { <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;hash&#34;</span>, <span style="color:#f92672">&#34;identity&#34;</span>: <span style="color:#e6db74">&#34;QmUeCAUYSNDK1gDrEGcwzRhbbJxwXAsAu7VN4D2ppzD1gQ&#34;</span>, <span style="color:#f92672">&#34;url&#34;</span>: <span style="color:#e6db74">&#34;https://gateway.digitallatin.org/ipfs/QmUeCAUYSNDK1gDrEGcwzRhbbJxwXAsAu7VN4D2ppzD1gQ&#34;</span> }, { <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;hash&#34;</span>, <span style="color:#f92672">&#34;identity&#34;</span>: <span style="color:#e6db74">&#34;QmUeCAUYSNDK1gDrEGcwzRhbbJxwXAsAu7VN4D2ppzD1gQ&#34;</span>, <span style="color:#f92672">&#34;url&#34;</span>: <span style="color:#e6db74">&#34;https://gateway.digitallatin.org/ipfs/QmUeCAUYSNDK1gDrEGcwzRhbbJxwXAsAu7VN4D2ppzD1gQ&#34;</span> } ], <span style="color:#f92672">&#34;issuedOn&#34;</span>: <span style="color:#e6db74">&#34;2018-07-30 15:47:19 +0000&#34;</span>, <span style="color:#f92672">&#34;verification&#34;</span>: { <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;signedBadge&#34;</span>, <span style="color:#f92672">&#34;publicKey&#34;</span>: <span style="color:#e6db74">&#34;QmZ5MFqMdZDunokFFQq5rKHxtURgjTg8e78cmzCypxcadG&#34;</span>, <span style="color:#f92672">&#34;publicKey-url&#34;</span>: <span style="color:#e6db74">&#34;https://gateway.digitallatin.org/ipfs/QmZ5MFqMdZDunokFFQq5rKHxtURgjTg8e78cmzCypxcadG&#34;</span> }, <span style="color:#f92672">&#34;badge&#34;</span>: { <span style="color:#f92672">&#34;image&#34;</span>: <span style="color:#e6db74">&#34;https://dll-review-registry.scta.info/maa-badge-working.svg&#34;</span>, <span style="color:#f92672">&#34;issuer&#34;</span>: { <span style="color:#f92672">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;https://www.medievalacademy.org/&#34;</span>, <span style="color:#f92672">&#34;image&#34;</span>: <span style="color:#e6db74">&#34;https://pbs.twimg.com/profile_images/1534408703/maa_symbol_small_400x400.png&#34;</span>, <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;Profile&#34;</span>, <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;Medieval Academy of America&#34;</span>, <span style="color:#f92672">&#34;email&#34;</span>: <span style="color:#e6db74">&#34;info@themedievalacademy.org&#34;</span>, <span style="color:#f92672">&#34;url&#34;</span>: <span style="color:#e6db74">&#34;https://www.medievalacademy.org/&#34;</span> }, <span style="color:#f92672">&#34;criteria&#34;</span>: {<span style="color:#f92672">&#34;narrative&#34;</span>: <span style="color:#e6db74">&#34;Meets the standards of a critical edition; judged by the MAA as equal in quality to the kinds of editions that appear in the MAA printed editions series or scholarly articles that appear in the MAA journal &#39;Speculum&#39;.&#34;</span>} } } 
</span></span></code></pre></div><p>The construction of this certificate is the main task of creating a review. The resulting document itself can be hashed and pinned to the IPFS network. But in order for this certificate to be discoverable, the hash itself needs to be given to a registry or index, such as the DLL Review Registry Service.</p>
<p>This could be done manually or through an API service. However, the more likely case is that an issuer will prefer to use an automated system for hashing the various files, publishing them to the IPFS network, as well as digitally signing the resulting certificate.</p>
<p>The DLL Review Registry Service provides this service through a webform, seen in <a href="#figure01">Figure 1</a>.</p>




























<figure ><img loading="lazy" alt="The webform for the DLL review registry service." src="/dhqwords/vol/13/4/000438/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000438/resources/images/figure01_hue16bbf82b9fde788cce06857a449b0b1_56523_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000438/resources/images/figure01_hue16bbf82b9fde788cce06857a449b0b1_56523_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000438/resources/images/figure01.png 759w" 
     class="landscape"
     >
</figure>
<p>Submission through the webform takes five basic parameters:<br>
Review Text Url  Review Society  Review Approval Code  Review Summary  Review Submitter</p>
<p>.</p>
<p>The Review Text URL is a URL from which the document or documents being reviewed can be retrieved. If the document has already been hashed and pinned to the IPFS network, then an IPFS gateway address can be used, but any other URL will work as well. This information is not embedded in the certificate, but is used to create the recipient hash embedded in the issued certificate.</p>
<p>The Review Society field is the place for authorized users to select the society issuing the certificate. A society listed here means that the DLL Review Registry Service contains and protects a copy of the society’s private key and is therefore authorized to issue certificates signed with this key (again, see below). The selection of a society will likewise determine which public key gets inserted into the review certificate.</p>
<p>The Review Approval Level is a field for reviewers or institutions to indicate the rubric used for the review. The possibility of indicating approval codes creates a way for reviews to escape the binary of an all or nothing review. A society, if it wishes, can create different kinds of reviews corresponding to different rubrics, allowing them to acknowledge quality work that meets different criteria. The code indicated here will determine which badge is issued in the resulting certificate.</p>
<p>An example of such a rubric might look like the rubric seen below in <a href="#figure02">Figure 2</a>.</p>




























<figure ><img loading="lazy" alt="An example of a rubric used in the review service." src="/dhqwords/vol/13/4/000438/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000438/resources/images/figure02_hu28862b5d65de9cccb5feb3bc229c36ba_138163_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000438/resources/images/figure02_hu28862b5d65de9cccb5feb3bc229c36ba_138163_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000438/resources/images/figure02.png 711w" 
     class="portrait"
     >
</figure>
<p>A Review Summary is a field for leaving any pertinent details about the particular review. It could be inserted into the certificate itself, but at the present it is used merely as a place for a notice about reviews issued through the DLL Review Registry Service.</p>
<p>The Review Submitter field is, again, a field used only by the DLL Review Registry Service to keep track of the individual who created the review through the service and on behalf of a particular society. At present it is not used in the creation of a certificate.</p>
<p>Upon submitting the above information review, the DLL Review Registry Service performs several actions.</p>
<p>First, using the Review Text URL(s), the service retrieves the designated file(s) and pins the file to an IPFS node. At the same time it records the IPFS hash and the plain sha256 hash. (It should be noted that an IPFS hash is also a 256-hash, plus a prefix, encoded in base58, representing the file divided into a series of blocks.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> ) Pinning the file does not just produce a file hash, it also makes the file retrievable via its content hash on the IPFS network. This content then becomes accessible via any computer running an IPFS node. It is also accessible via http on a server running an IPFS gateway. The DLL Review Registry Service itself provides such a gateway (<a href="https://gateway.digitallatin.org/ipfs/">https://gateway.digitallatin.org/ipfs/</a>) and the files remain retrievable here as well as from any other connected gateway.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></p>
<p>Second, the service constructs the review certificate using the newly minted recipient hash, the review approval code information, and the public-key of the reviewing society.</p>
<p>Third, the service then pins the newly generated certificate to the IPFS node generating an IPFS hash for the certificate. This hash is stored in the registry index alongside of the hash of the reviewed documents.</p>
<p>Fourth, the service digitally signs the generated certificate using <a href="https://www.gnupg.org/">GnuPG</a> and the institution’s private key. This process is described below. The resulting signatures are themselves hashed and pinned to the IPFS node. These hashes are finally stored in the index alongside the hash of the document and unsigned certificate.</p>
<h2 id="review-verification">Review Verification</h2>
<p>While content addressability offers assurance that the document received is the document requested, a means of verifying that a given society really did create this review certificate is still needed. After all, the public key of any reviewing institution is public and therefore anyone could embed this public key into their own certificate.</p>
<p>The simplest way of providing this verification is through hosted verification. Namely, one can have confidence that a review was issued by a given society because that review was requested from the DLL Review Registry Service’s domain. However, in a distributed system where certificates can travel and are requested not by their location but by their content, we open the possibility for a certificate to be retrieved from any IPFS node or via http through any IPFS gateway. Thus, we need a mechanism of verification independent of the document’s point of origin. GnuPG digital signatures were designed for precisely this purpose.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup></p>
<p>Using the private key of a reviewing society, we can generate a signature for a given certificate. This signature is a hash uniquely generated from the private key of the issuer and the data being signed. Importantly, the process can never be reversed. The private key can never be generated from the public key, the signature, the data, or any combination thereof. However, the fact that this signature was generated from the society’s private key can be verified against the combination of the data to be verified and the society’s public key.</p>
<p>In other words, a document (in this case, the certificate) can be verified as being issued by a society with a specific public key by putting the data and the signature together and checking it against the society’s public key. The check will confirm that this signature could only have been made by the combination of this society’s private key and the submitted certificate. Change one bit in the certificate (in this case, one would most likely be tempted to change the hash of the recipient document) or one bit in the public key and the signature will no longer pass verification.</p>
<p>At the present the DLL Review Registry Service creates two kinds of signatures allowing two methods of verification.</p>
<p>The first method is a detached signature. The detached signature is a hash stored in a separate file that is the result of the institution’s private key and the issued certificate. The DLL Review Registry Service again pins this resulting signature to the IPFS network and stores its hash as part of the indexed record.</p>
<p>Using a detached signature and previously imported public key, the certificate can then be verified as follows:  <code>$ gpg --verify [path/to/signature] [path/to/certificate]</code></p>
<p>The drawback to using a detached signature is that the signature is detached from the certificate and creates another file that needs a central indexing service to associate with the issued certificate.</p>
<p>In order to reduce this reliance on a central indexing service, the DLL Review Registry Service also produces a clear-signed version of the original certificate. This means a new version of the certificate is produced that includes both the original content of the certificate as well as a signature. With a clear signed certificate, the verification process can both verify the certificate and return the original un-signed certificate. The certificate can be validated with the following command:  <code>$ gpg --verify [path/to/clear/signed/certificate]</code> . The original unsigned certificate can be generated from the signed certificate with  <code>$ gpg -d -o original.txt [path/to/clear/signed/certificate]</code> . This resulting document original.txt can be further verified against the unsigned-certificate.txt by comparing the hashes of each file or by performing a unix  <code>diff</code>  command against both files, e.g.  <code>$ diff original.txt unsigned-certificate.txt</code> .</p>
<p>From a verified certificate one can have complete confidence that the recipient document in the certificate is the precise document reviewed by the society. This is the case because the certificate does not point to a location but to the precise hash of the reviewed document. Addressing the document by its hash rather than its location via the IPFS network provides assurance that one is retrieving the very same document that was used to make the certificate and verified via its signature. Change one bit in the hash in the request and a different document will be retrieved. Change one bit in the hash in the certificate and the certificate will not longer be verified.</p>
<p>These verifications can be done entirely separately from the DLL Review Registry Service website, but the service also offers a web form and API through which certificates can be reviewed, as seen in <a href="#figure03">Figure 3</a>.</p>




























<figure ><img loading="lazy" alt="The web form and API through which certificates can be reviewed." src="/dhqwords/vol/13/4/000438/resources/images/figure03.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000438/resources/images/figure03_hu63463c7d31c84546f0bbb2854d7b4d47_163843_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000438/resources/images/figure03_hu63463c7d31c84546f0bbb2854d7b4d47_163843_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000438/resources/images/figure03.png 826w" 
     class="portrait"
     >
</figure>
<h2 id="review-retrieval">Review Retrieval</h2>
<p>Finally, third party services may want to be able to use the DLL Review Registry Service to discover verified review certificates for documents of interest and to be able to communicate the review status of those documents and verify that status back to end users.</p>
<p>Naturally, a human user can use the DLL Review Registry Service to browse reviews, view html renderings of reviews, verify certificates, and read the rubrics used by each society. This, however, is not the primary place an end user is expected to encounter this information. Rather, the primary expected pattern is that a client application will access this information using the DLL Review Registry Service API and offer that information back to the end user within its own interface. (See examples below.)</p>
<p>The API for data retrieval in the 1.0.0 version consists of three main routes:<br>
<code>api/v1/review/:id</code>  route   <code>api/v1/reviews/:hash</code>  or  <code>?url=document_url route</code>    <code>api/v1/verify?url=clearsigned_url</code></p>
<p>.</p>
<p>The  <code>api/v1/review/:id</code>  route (1) allows a client that knows beforehand the indexed ID of a DLL Review Registry Service review to look up the review report. This is an ID that is unique to the centralized index service. The report in turn returns the information stored in the index including the document hash, certificate hash, detached signature hash, and the clear-signed certificate hash.</p>
<p>For a route like the following:  <code>https://dll-review-registry.digitallatin.org/api/v1/review/f4b8dc2f-4d41-478d-877b-843b46e21283</code>  a sample expected output would be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span> { <span style="color:#f92672">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;f4b8dc2f-4d41-478d-877b-843b46e21283&#34;</span>, <span style="color:#f92672">&#34;review-society&#34;</span>: <span style="color:#e6db74">&#34;MAA&#34;</span>, <span style="color:#f92672">&#34;date&#34;</span>: <span style="color:#e6db74">&#34;2018-07-30 11:16:57 UTC&#34;</span>, <span style="color:#f92672">&#34;badge-url&#34;</span>: <span style="color:#e6db74">&#34;https://dll-review-registry.digitallatin.org/maa-badge-working.svg&#34;</span>, <span style="color:#f92672">&#34;badge-rubric&#34;</span>: <span style="color:#e6db74">&#34;http://dll-review-registry.digitallatin.org/rubric/maa#green&#34;</span>, <span style="color:#f92672">&#34;review-summary&#34;</span>: <span style="color:#e6db74">&#34;Review Summary&#34;</span>, <span style="color:#f92672">&#34;sha-256&#34;</span>: [ <span style="color:#e6db74">&#34;45304964c8bf9fb63737fa54e701b765baea0d950ff396c8fc686dd9bfda0416&#34;</span>, <span style="color:#e6db74">&#34;bab59377f29af62f1091ed367328db4abe96193a01f3b2c0e8615ba861e63317&#34;</span> ], <span style="color:#f92672">&#34;ipfs-hash&#34;</span>: [ <span style="color:#e6db74">&#34;QmdgZhAFTepfXmUsxEGaVampJubZ7XMk4pC42uzHgBEgvy&#34;</span>, <span style="color:#e6db74">&#34;QmUxAedP9cDvC9dfwJrezwvHJWVD4w5UaJTHzLn37KEhMa&#34;</span> ], <span style="color:#f92672">&#34;submitted-url&#34;</span>: [ <span style="color:#e6db74">&#34;https://raw.githubusercontent.com/scta-texts/hiltalingencommentary/59eae077a22511531b5da383d402d031ca3b26b7/jhb-l1q10/clm26711_jhb-l1q10.xml&#34;</span>, <span style="color:#e6db74">&#34;https://raw.githubusercontent.com/scta-texts/hiltalingencommentary/59eae077a22511531b5da383d402d031ca3b26b7/jhb-l1q9/clm26711_jhb-l1q9.xml&#34;</span> ], <span style="color:#f92672">&#34;submitted-by&#34;</span>: <span style="color:#e6db74">&#34;jeffreycwitt@gmail.com&#34;</span>, <span style="color:#f92672">&#34;cert-ipfs-hash&#34;</span>: <span style="color:#e6db74">&#34;Qmbbotxgr1DBXTWXtDEkT2ZNh18ZPm73bHuAymTvNJQVim&#34;</span>, <span style="color:#f92672">&#34;clearsigned-hash&#34;</span>: <span style="color:#e6db74">&#34;QmWZDUgZe12ALftn2G5z3GW4KMoLQXM9c4Ysb7yn8cRJTh&#34;</span>, <span style="color:#f92672">&#34;detach-sig-hash&#34;</span>: <span style="color:#e6db74">&#34;QmYLprZk5uGJsaLjiKib31hiRdyyAQDuYznuZZpqgQfm7i&#34;</span> } 
</span></span></code></pre></div><p>From a decentralized perspective, the clear-signed certificate hash is the only piece of information needed. Every other piece of information can be extracted from it.</p>
<p>The clear-signed certificate contains the reference to the public key which can be used to verify the signed certificate and to generate the original certificate. The certificate itself contains the review report as well as the reference to the hash of the reviewed documents.</p>
<p>In most cases, however, it is not expected that a client will know the DLL Review Registry Service specific review ID. More likely, a client will be serving a document and it will want to be able to inform its user quickly as to whether or not this precise document has a review. This brings us to the second provided API route.</p>
<p>The  <code>api/v1/reviews/:hash</code>  or  <code>?url=document_url</code>  route (2) offers this possibility.</p>
<p>In this second, more common case, a client can supply a pre-computed sha-256 hash and receive a list of all reviews for any document with the same fingerprint or hash. Likewise, the client can supply, if it knows it, the IPFS hash and the API will return all reviews for documents having that hash. The IPFS hash and sha-256 hash will always correlate, meaning that a sha-256 hash will always return the same list as its corresponding IPFS hash and vice versa.</p>
<p>Finally, if a client does not want to pre-compute the hash of a document, it can simply supply the URL of the document it is serving using the ?url parameter. In this case, the DLL Review Registry Service will use the supplied URL to retrieve this file, compute its hash, and return a list of reviews that correspond to the text.</p>
<p>This is perhaps the most likely scenario for a consuming client, as it presumes no prior knowledge on the part of the client except for the location of the text it wants to check. By providing the DLL registry with the location of this text, it can easily check whether or not the precise version of this text has received a review and then receive pertinent metadata about that review.</p>
<p>For the following request  <code>https://dll-review-registry.digitallatin.org/api/v1/reviews/QmdgZhAFTepfXmUsxEGaVampJubZ7XMk4pC42uzHgBEgvy</code>  a sample expected response would appear as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span> [ { <span style="color:#f92672">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;52cb5b0a-7ae0-441d-9da5-12534a9a082f&#34;</span>, <span style="color:#f92672">&#34;review-society&#34;</span>: <span style="color:#e6db74">&#34;MAA&#34;</span>, <span style="color:#f92672">&#34;date&#34;</span>: <span style="color:#e6db74">&#34;2018-07-30 11:15:11 UTC&#34;</span>, <span style="color:#f92672">&#34;badge-url&#34;</span>: <span style="color:#e6db74">&#34;http://dll-review-registry.scta.info/maa-badge-working.svg&#34;</span>, <span style="color:#f92672">&#34;badge-rubric&#34;</span>: <span style="color:#e6db74">&#34;http://dll-review-registry.scta.info/rubric/maa#green&#34;</span>, <span style="color:#f92672">&#34;review-summary&#34;</span>: <span style="color:#e6db74">&#34;review summary&#34;</span>, <span style="color:#f92672">&#34;sha-256&#34;</span>: [ <span style="color:#e6db74">&#34;45304964c8bf9fb63737fa54e701b765baea0d950ff396c8fc686dd9bfda0416&#34;</span>, <span style="color:#e6db74">&#34;bab59377f29af62f1091ed367328db4abe96193a01f3b2c0e8615ba861e63317&#34;</span> ], <span style="color:#f92672">&#34;ipfs-hash&#34;</span>: [ <span style="color:#e6db74">&#34;QmdgZhAFTepfXmUsxEGaVampJubZ7XMk4pC42uzHgBEgvy&#34;</span>, <span style="color:#e6db74">&#34;QmUxAedP9cDvC9dfwJrezwvHJWVD4w5UaJTHzLn37KEhMa&#34;</span> ], <span style="color:#f92672">&#34;submitted-url&#34;</span>: [ <span style="color:#e6db74">&#34;https://raw.githubusercontent.com/scta-texts/hiltalingencommentary/59eae077a22511531b5da383d402d031ca3b26b7/jhb-l1q10/clm26711_jhb-l1q10.xml&#34;</span>, <span style="color:#e6db74">&#34;https://raw.githubusercontent.com/scta-texts/hiltalingencommentary/59eae077a22511531b5da383d402d031ca3b26b7/jhb-l1q9/clm26711_jhb-l1q9.xml&#34;</span> ], <span style="color:#f92672">&#34;submitted-by&#34;</span>: <span style="color:#e6db74">&#34;jeffreycwitt@gmail.com&#34;</span>, <span style="color:#f92672">&#34;cert-ipfs-hash&#34;</span>: <span style="color:#e6db74">&#34;QmbhSB9CoRgCA3KBh5JXyavSaS2DymBZQQMRsqTiBSEGpC&#34;</span>, <span style="color:#f92672">&#34;clearsigned-hash&#34;</span>: <span style="color:#e6db74">&#34;Qmc1165TM3QDsRVFboy56nHSrCF5w2RqkrMDqEoEvvnz3v&#34;</span>, <span style="color:#f92672">&#34;detach-sig-hash&#34;</span>: <span style="color:#e6db74">&#34;Qmc1165TM3QDsRVFboy56nHSrCF5w2RqkrMDqEoEvvnz3v&#34;</span> }, { <span style="color:#f92672">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;f4b8dc2f-4d41-478d-877b-843b46e21283&#34;</span>, <span style="color:#f92672">&#34;review-society&#34;</span>: <span style="color:#e6db74">&#34;MAA&#34;</span>, <span style="color:#f92672">&#34;date&#34;</span>: <span style="color:#e6db74">&#34;2018-07-30 11:16:57 UTC&#34;</span>, <span style="color:#f92672">&#34;badge-url&#34;</span>: <span style="color:#e6db74">&#34;http://dll-review-registry.scta.info/maa-badge-working.svg&#34;</span>, <span style="color:#f92672">&#34;badge-rubric&#34;</span>: <span style="color:#e6db74">&#34;http://dll-review-registry.scta.info/rubric/maa#green&#34;</span>, <span style="color:#f92672">&#34;review-summary&#34;</span>: <span style="color:#e6db74">&#34;review summary&#34;</span>, <span style="color:#f92672">&#34;sha-256&#34;</span>: [ <span style="color:#e6db74">&#34;45304964c8bf9fb63737fa54e701b765baea0d950ff396c8fc686dd9bfda0416&#34;</span>, <span style="color:#e6db74">&#34;bab59377f29af62f1091ed367328db4abe96193a01f3b2c0e8615ba861e63317&#34;</span> ], <span style="color:#f92672">&#34;ipfs-hash&#34;</span>: [ <span style="color:#e6db74">&#34;QmdgZhAFTepfXmUsxEGaVampJubZ7XMk4pC42uzHgBEgvy&#34;</span>, <span style="color:#e6db74">&#34;QmUxAedP9cDvC9dfwJrezwvHJWVD4w5UaJTHzLn37KEhMa&#34;</span> ], <span style="color:#f92672">&#34;submitted-url&#34;</span>: [ <span style="color:#e6db74">&#34;https://raw.githubusercontent.com/scta-texts/hiltalingencommentary/59eae077a22511531b5da383d402d031ca3b26b7/jhb-l1q10/clm26711_jhb-l1q10.xml&#34;</span>, <span style="color:#e6db74">&#34;https://raw.githubusercontent.com/scta-texts/hiltalingencommentary/59eae077a22511531b5da383d402d031ca3b26b7/jhb-l1q9/clm26711_jhb-l1q9.xml&#34;</span> ], <span style="color:#f92672">&#34;submitted-by&#34;</span>: <span style="color:#e6db74">&#34;jeffreycwitt@gmail.com&#34;</span>, <span style="color:#f92672">&#34;cert-ipfs-hash&#34;</span>: <span style="color:#e6db74">&#34;Qmbbotxgr1DBXTWXtDEkT2ZNh18ZPm73bHuAymTvNJQVim&#34;</span>, <span style="color:#f92672">&#34;clearsigned-hash&#34;</span>: <span style="color:#e6db74">&#34;QmWZDUgZe12ALftn2G5z3GW4KMoLQXM9c4Ysb7yn8cRJTh&#34;</span>, <span style="color:#f92672">&#34;detach-sig-hash&#34;</span>: <span style="color:#e6db74">&#34;QmYLprZk5uGJsaLjiKib31hiRdyyAQDuYznuZZpqgQfm7i&#34;</span> } ] 
</span></span></code></pre></div><p>In the above response one can see that two separate reviews exist for a file with identical content.</p>
<p>The API also allows easy filtering of different kinds of reviews. If a user or application only wants to see a review by the MAA (or another specific society) and exclude all other reviews, it can simply add a parameter to the request like so:  <code>http://reviews.digitallatin.org/api/v1/reviews/45304964c8bf9fb63737fa54e701b765baea0d950ff396c8fc686dd9bfda0416?society=MAA</code>  This request will return an array of only those reviews that come from the MAA.</p>
<p>Finally,  <code>api/v1/verify?url=clearsigned_url</code>  (3) allows clients to verify clear-signed signature.</p>
<p>For the route  <code>api/v1/verify?url=clearsigned_url</code> , a client can provide the URL of a clear-signed certificate and the API will return a very simple response as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span> { <span style="color:#f92672">&#34;verification-message&#34;</span>: <span style="color:#e6db74">&#34;gpg: Signature made Mon Jul 30 07:16:58 2018 EDT using RSA key ID 76160352 gpg: Good signature from \&#34;Medieval Academy of America (Keys for Medieval Academy of America)\&#34;&#34;</span> } 
</span></span></code></pre></div><p>The expected pattern is that a client could offer its users access to the review certificate for a given document by first sending the URL of the document to the Review Registry Service. In the response, the client would find the hash of the unsigned and clear-signed signature. The client can then offer these certificates to end users. If end users want to verify the authenticity of the certificate, clients can use the retrieved url of the clear-signed certificate and the DLL Review Registry  <code>/api/v1/verify</code>  route to offer end users a verification.</p>
<p>A high-level illustration of anticipated interactions between the DLL Review Registry and Client systems can be visualized below in <a href="#figure04">Figure 4</a>.</p>




























<figure ><img loading="lazy" alt="Anticipated interactions between the DLL Review Registry and client systems." src="/dhqwords/vol/13/4/000438/resources/images/figure04.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000438/resources/images/figure04_huc7197826258b675cead477d678d7c569_201528_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000438/resources/images/figure04_huc7197826258b675cead477d678d7c569_201528_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000438/resources/images/figure04_huc7197826258b675cead477d678d7c569_201528_1200x0_resize_box_3.png 1200w,/dhqwords/vol/13/4/000438/resources/images/figure04_huc7197826258b675cead477d678d7c569_201528_1500x0_resize_box_3.png 1500w,/dhqwords/vol/13/4/000438/resources/images/figure04_huc7197826258b675cead477d678d7c569_201528_1800x0_resize_box_3.png 1800w,/dhqwords/vol/13/4/000438/resources/images/figure04.png 2000w" 
     class="landscape"
     >
</figure>
<p>Below are three brief examples of third party clients using the DLL Review Registry Service.</p>
<p><a href="#figure05">Figure 5</a> shows the <a href="http://lombardpress.org/">LombardPress</a>&rsquo; <a href="http://scta.lombardpress.org/">LombardPress-Web</a> (Lbp-Web) application displaying a critical edition. Lbp-Web does not contain any text on its server, but uses the <a href="http://scta.info/">Scholastic Commentaries and Texts Archive</a> to locate data sources based on various query parameters, then it makes a further request for that data, which can be distributed anywhere on the web, and finally it displays that data to the end user. In this case, Lbp-Web has discovered a data source, an XML file for  “Lectio 1”  of Peter Plaoul’s  <em>Commentary on the Sentences</em> . After retrieving this XML file, it wants to alert the end user to whether or not the data source has been peer reviewed. To do this, it asynchronously sends the location of that same file to the DLL Review Registry Service API and learns two things. It learns the IPFS hash of the data source and is able to provide that hash to users, so that users can always cite the precise data source they are viewing and retrieve that data source from any node on the IPFS network. Second, it learns whether or not a review certificate exists for which this data source is a recipient. If so, it crawls the certificate, discovers the imprimatur granted by the MAA, and displays the corresponding insignium of that imprimatur to the end user, along with a link back to the certificate and the DLL Review Registry Service review record.</p>




























<figure ><img loading="lazy" alt="LombardPress-Web&#39;s implementation of the DLL Review Registry Service." src="/dhqwords/vol/13/4/000438/resources/images/figure05.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000438/resources/images/figure05_hue42fc5ae7124c07d9bcf764b25a84352_550354_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000438/resources/images/figure05_hue42fc5ae7124c07d9bcf764b25a84352_550354_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000438/resources/images/figure05_hue42fc5ae7124c07d9bcf764b25a84352_550354_1200x0_resize_box_3.png 1200w,/dhqwords/vol/13/4/000438/resources/images/figure05_hue42fc5ae7124c07d9bcf764b25a84352_550354_1500x0_resize_box_3.png 1500w,/dhqwords/vol/13/4/000438/resources/images/figure05_hue42fc5ae7124c07d9bcf764b25a84352_550354_1800x0_resize_box_3.png 1800w,/dhqwords/vol/13/4/000438/resources/images/figure05.png 2500w" 
     class="landscape"
     >
</figure>
<p><a href="#figure06">Figure 6</a> provides a second example of basically the same process. What is important here is the emphasis on the way the same imprimatur can travel with the data despite the highly varied use of the data in question. In the <a href="http://lombardpress.org/adfontes/">Ad Fontes</a> application — an application designed to allow users to explore individual quotations throughout the Scholastic corpus — when a user requests to see the context paragraph of a given quotation, the application knows that this paragraph has been pulled from a larger data source (a larger XML file). At the same time that the application is showing the end user the context paragraph, it can also send an asynchronous request to the DLL Review Registry Service to check if there have been any reviews for the data source from which this context paragraph has been extracted. If so, it can display the review badge and data source hash alongside the context paragraph, as seen in the bottom right corner of Figure 6.</p>




























<figure ><img loading="lazy" alt="Implementation of the DLL Review Registry Service in the Ad Fontes application." src="/dhqwords/vol/13/4/000438/resources/images/figure06.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000438/resources/images/figure06_hu47dad30b24711387f53166131a00bf93_368426_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000438/resources/images/figure06_hu47dad30b24711387f53166131a00bf93_368426_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000438/resources/images/figure06_hu47dad30b24711387f53166131a00bf93_368426_1200x0_resize_box_3.png 1200w,/dhqwords/vol/13/4/000438/resources/images/figure06.png 1277w" 
     class="landscape"
     >
</figure>
<p>Finally, <a href="#figure07">Figures 7</a>  <a href="#figure08">and 8</a> illustrate the way the travelling imprimatur can be implemented in an even wider array of applications to provide users confidence when merging content in a Linked Data world. <a href="#figure07">Figure 7</a> illustrates how <a href="https://www.w3.org/TR/ldn/">Linked Data Notifications</a> (LDN) have been used to make announcements about related but distributed content. In this case the Scholastic Commentaries and Texts Archive has published a transcription via the IIIF Open Annotation Model about a manuscript owned by the Bayerische Staatsbiliothek and made accessible via a IIIF Manifest. Through the use of this Linked Data, LDN, and the <a href="https://github.com/jeffreycwitt/mirador-ldn-plugin">Mirador-LDN-Plugin</a><sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> , this related content can be brought together at runtime. However, librarians and end users alike want to have confidence in the content they bring into their research environment. With the traveling imprimatur, the LDN notification can either report the existence of the review certificate or the Mirador-LDN-Plugin can be modified to perform the check against the DLL Review Registry Service itself. <a href="#figure07">In Figure 7</a>, one can see that a user is given the option of importing two different pieces of related content into the workspace, only the second of which shows a review badge indicating that the data comes from a reviewed data source. Here administrative gate-keeping is removed; all available content can be announced and shown to the end user. The end user can then use indicators of quality control (like the DLL traveling imprimatur) to decide which kind of content she wants to bring into her workspace.</p>




























<figure ><img loading="lazy" alt="How Linked Data Notifications are used to make announcements about related but distributed content." src="/dhqwords/vol/13/4/000438/resources/images/figure07.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000438/resources/images/figure07_hu73c5649a6e651a465ad778c79d85c8eb_804921_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000438/resources/images/figure07_hu73c5649a6e651a465ad778c79d85c8eb_804921_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000438/resources/images/figure07_hu73c5649a6e651a465ad778c79d85c8eb_804921_1200x0_resize_box_3.png 1200w,/dhqwords/vol/13/4/000438/resources/images/figure07_hu73c5649a6e651a465ad778c79d85c8eb_804921_1500x0_resize_box_3.png 1500w,/dhqwords/vol/13/4/000438/resources/images/figure07_hu73c5649a6e651a465ad778c79d85c8eb_804921_1800x0_resize_box_3.png 1800w,/dhqwords/vol/13/4/000438/resources/images/figure07.png 1919w" 
     class="landscape"
     >
</figure>
<p>Figure 8 offers a second example of this use of the traveling imprimatur. This time the additional content for the British Library Manuscript has already been imported. The visual imprimatur and accompanying IPFS hash for the data source from which this transcription was extracted are provided for the end user. The end user can click on the imprimatur to learn more about the review and the rubric used to make the review or can use the IPFS hash to access the raw data source directly.</p>




























<figure ><img loading="lazy" alt="Importing the traveling imprimatur into Mirador via a IIIF annotation list." src="/dhqwords/vol/13/4/000438/resources/images/figure08.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000438/resources/images/figure08_hu36f57b534075e924c6f38473ae15ff68_2541192_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000438/resources/images/figure08_hu36f57b534075e924c6f38473ae15ff68_2541192_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000438/resources/images/figure08_hu36f57b534075e924c6f38473ae15ff68_2541192_1200x0_resize_box_3.png 1200w,/dhqwords/vol/13/4/000438/resources/images/figure08_hu36f57b534075e924c6f38473ae15ff68_2541192_1500x0_resize_box_3.png 1500w,/dhqwords/vol/13/4/000438/resources/images/figure08_hu36f57b534075e924c6f38473ae15ff68_2541192_1800x0_resize_box_3.png 1800w,/dhqwords/vol/13/4/000438/resources/images/figure08.png 2500w" 
     class="landscape"
     >
</figure>
<h2 id="conclusion">Conclusion</h2>
<p>It is important to acknowledge that web technologies are evolving at a rapid pace. This includes the web technologies described above. New possibilities are emerging every day. Accordingly, it needs to be reiterated that the central import of the present article is to describe the actualization of an idea and the general architecture of that achievement rather than the particular details of its achievement. Above we have tried to show how we have built a system that moves the idea of the Traveling Imprimatur to a reality in production. Beyond providing a production service, this actualization is also meant to show that social rather than technical obstacles are causing delays in de-coupling the distinct and separable functions of publication and quality control.</p>
<p>Today, the need to demonstrate that this idea can be actualized is urgent because of the persistent temptation to view the construction of a digital edition as something equivalent to or on par with a printed book, where the edition itself is bound to and identified with a particular visual presentation of that data.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>  This temptation invites us to blur the distinction between data and presentation, in effect siloing and embedding our data in technology stacks that are difficult to maintain and more importantly preventing us from re-using this data for new and unanticipated purposes. Part of this temptation naturally comes from within, from our familiarity with printed books, and the understandable tendency to reproduce what is familiar within a new medium. But another part of this temptation comes from the political structures that surround our editorial work, the social apparatuses in which we live and breath. Like a fish unaware of the water that surrounds it, we frequently and uncritically adopt the pathways that are suggested by the surrounding social structures, which shape the methods of research we adopt. If, despite a great personal desire to exploit the possibilities of the new digital medium, the social structures that evaluate and reward our work continue to reinforce a paradigm that is no longer suited to the new medium, if these social structures continue to treat visual websites as editions themselves and fail to recognize the distinction between data and presentation, then the tendency of the field will be, by and large, to continue creating siloed and unconnected digital editions, despite our awareness that there is a better way.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Grant numbers 11200693, 21400643, and 21500706.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>For an overview of the protean nature of the term digital edition see <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. See also <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>, <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>, <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>, <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>, and the essays collected in <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>See the essays collected in <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> for many views on the relationship between edition and interface. As for encoded data being a presentational form, the fact that a goal for XML was that it should be human-legible and reasonably clear (<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>) demonstrates that the encoding is a way of presenting data directly to human readers. Consider also that the Text Encoding Initiative defines encoding as any means of making explicit an interpretation of a text. (<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>) Thus, XML presents data to machines and humans; additionally, TEI XML presents an interpretation of data to machines and humans.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Cf. <sup id="fnref1:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> 94: Creating an electronic edition is not a one-person operation; it requires skills rarely if ever found in any one person. Scholarly editors are first and foremost textual critics. They are also bibliographers and they know how to conduct literary and historical research. But they are usually not also librarians, typesetters, printers, publishers, book designers, programmers, web-masters, or systems analysts.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>See <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> for a description. The code for the viewer is available at <a href="https://github.com/DigitalLatin/viewer">https://github.com/DigitalLatin/viewer</a>. On CETEIcean, see <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>For more on this research, see <a href="https://digitallatin.org/library-digital-latin-texts/data-visualization">https://digitallatin.org/library-digital-latin-texts/data-visualization</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>For an introduction to cryptographic hashes see <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>See also <a href="https://www.imsglobal.org/sites/default/files/Badges/OBv2p0/index.html">https://www.imsglobal.org/sites/default/files/Badges/OBv2p0/index.html</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>See for example, <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>See <sup id="fnref1:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> for a description of the hash pattern. According to <a href="https://github.com/richardschneider/net-ipfs-core">https://github.com/richardschneider/net-ipfs-core</a> IPFS uses the multihash project <a href="https://github.com/multiformats/multihash">https://github.com/multiformats/multihash</a> for the production of IPFS hashes.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>For example, <a href="https://ipfs.github.io/public-gateway-checker/">https://ipfs.github.io/public-gateway-checker/</a> is a list of known IPFS gateways.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>We’re also looking into the use of <a href="https://en.wikipedia.org/wiki/JSON_Web_Signature">JSON Web Signatures</a> (JWSs) as recommended by the OpenBadges specification. At present the use of JSON Web Signatures does not appear nearly as stable or well documented as the GnuPG standard which was introduced in 1997 and has a strong history of use and documentation. In the future, it would not be difficult to issue certificates signed with JSON Web Signatures alongside certificates signed with GnuPG.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>For more on the use of Linked Data Notifications and IIIF and the RERUM LDN Inbox, see <a href="https://centerfordigitalhumanities.github.io/inbox-docs/#!/">https://centerfordigitalhumanities.github.io/inbox-docs/#!/</a> and <a href="https://centerfordigitalhumanities.github.io/inbox-docs/#!/specifications">https://centerfordigitalhumanities.github.io/inbox-docs/#!/specifications</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>For a good description of this complaint among many, namely the temptation and tendency of digital editions to repeat the paradigm of the printed book in digital form, see <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> and <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Sahle, Patrick.  “What is a Scholarly Digital Edition?”  In Matthew James Driscoll and Elena Pierazzo (eds.),  <em>Digital Scholarly Editing: Theories and Practices</em> , pp. 19-40. Cambridge: OpenBook Publishers (2016).&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Robinson, Peter.  “What is a Critical Digital Edition?”    <em>Variants: The Journal of the European Society for Textual Scholarship</em>  1 (2002): 43–62.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Ducourtieux, Christine.  “L’èdition électronique en quête de définitions(s).”    <em>Le médiéviste et l’ordinateur, Histoire médiévale, informatique et nouvelles technologies</em>  43 (2004). <a href="http://lemo.irht.cnrs.fr/43/43-02.htm">http://lemo.irht.cnrs.fr/43/43-02.htm</a>.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Shillingsburg, Peter L.  <em>From Gutenberg to Google: Electronic Representations of Literary Texts.</em>  Cambridge : Cambridge University Press (2006).&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Gabler, Hans Walter.  “Theorizing the Digital Scholarly Edition.”    <em>Literature Compass</em>  7.2 (2010): 43–56.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Driscoll, Matthew James and Elena Pierazzo, eds.  <em>Digital Scholarly Editing: Theories and Practices</em> . Cambridge: OpenBook Publishers (2016). <a href="https://www.openbookpublishers.com/product/483/digital-scholarly-editing--theories-and-practices">https://www.openbookpublishers.com/product/483/digital-scholarly-editing&ndash;theories-and-practices</a>.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Bleier, Roman, Martina Bürgermeister, Helmust W. Klug, Frederike Neuber, and Gerlinde Scheider.  <em>Digital Scholarly Editions as Interfaces.</em>    <em>Schriften des Instituts für Dokumentologie und Editorik</em>  12 (2018).&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Bray, Tim and Jean Paoli, C. M. Sperberg-McQueen, Eve Maler, François Yergeau.  <em>Extensible Markup Language (XML) 1.0 (Fifth Edition).</em>  W3C Recommendation 26 November 2008. <a href="https://www.w3.org/TR/REC-xml/">https://www.w3.org/TR/REC-xml/</a>.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>TEI Consortium, eds.  “v. A Gentle Introduction to XML.”    <em>TEI P5: Guidelines for Electronic Text Encoding and Interchange.</em>  Version 3.6.0. July 2019. <a href="https://www.tei-c.org/release/doc/tei-p5-doc/en/html/SG.html">https://www.tei-c.org/release/doc/tei-p5-doc/en/html/SG.html</a> (date of access: 2019-09-18).&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Cayless, Hugh.  “Critical Edition and the Data Model as Interface.”  In Roman Bleier, Martina Bürgermeister, Helmust W. Klug, Frederike Neuber, and Gerlinde Scheider (eds.),  <em>Digital Scholarly Editions as Interfaces.</em>    <em>Schriften des Instituts für Dokumentologie und Editorik</em> , pp. 249-263.  <em>Schriften des Instituts für Dokumentologie und Editorik</em>  12 (2018).&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Cayless, Hugh, and Raffaele Viglianti.  “CETEIcean: TEI in the Browser.”  In  <em>Proceedings of Balisage: The Markup Conference 2018.</em>  Balisage Series on Markup Technologies, vol. 21 (2018). <a href="https://doi.org/10.4242/BalisageVol21.Cayless01">https://doi.org/10.4242/BalisageVol21.Cayless01</a>.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Paar, Christof and Jan Pelzl.  <em>Understanding Cryptography: A Textbook for Students and Practitioners.</em>  Springer (2009).&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Benet, Juan.  “IPFS — Content Addressed, Versioned, P2P File System”  (2014) <a href="https://arxiv.org/pdf/1407.3561.pdf">https://arxiv.org/pdf/1407.3561.pdf</a>.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Zundert, Joris van.  “Barely Beyond the Book?”  In Matthew James Driscoll and Elena Pierazzo (eds.),  <em>Digital Scholarly Editing: Theories and Practices</em> , pp. 83-106. Cambridge: OpenBook Publishers (2016).&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Sahle, Patrick.  “Zwischen Mediengebundenheit Und Transmedialisierung” .  <em>Issues</em>  30 (2016). <a href="https://doi.org/10.1515/9783110223163.0.23">https://doi.org/10.1515/9783110223163.0.23</a>.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Digital Collaborations: A Survey Analysis of Digital Humanities Partnerships Between Librarians and Other Academics</title><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/000441/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/13/4/000441/</id><author><name>Jessica Wagner Webster</name></author><published>2019-12-14T00:00:00+00:00</published><updated>2019-12-14T00:00:00+00:00</updated><content type="html"><![CDATA[<p>As technological tools have developed over the last several decades, humanities scholars have explored the opportunities computing technology makes available for conducting and enhancing their research. Scholars have developed techniques such as using software to mine texts and creating data visualizations such as maps, charts, and graphics. Further, they have developed new software products to aid in their research. These techniques allow scholars to grapple new kinds of qualitative and quantitative research questions, as well as to work with data and text at scale. Similarly, archivists and librarians have developed an extensive literature and tool set to collect, accession, make accessible, and preserve a wide variety of digital content for their collections. Many of these skills and techniques overlap with those of DH practitioners; for example, digitizing a text document and performing optical character recognition to generate a searchable transcript could be a key step in both a DH scholar&rsquo;s research and an archivist&rsquo;s making a historic pamphlet accessible for researchers. Furthermore, texts and DH projects generated by the work of DH scholars might be worth accessioning and preserving as part of their collections; steps in the archival workflow might have to be adjusted to accommodate data sets, websites, applications, visualizations, and other products that result from DH scholars&rsquo; work.</p>
<p>The present study will investigate the perceptions of information professionals (IPs) about their role in the work of DH scholars, as well as the perceptions of DH scholars on the role of IPs in their research. While other scholarly literature has considered collaborations between these groups via surveys or interviews with small project teams (e.g., <a href="#keener2015">Keener 2015</a>, <a href="#poremski2017">Poremski 2017</a>), the present study will provide a large-scale analysis of collaborations using survey responses from more than 500 scholars, librarians, and archivists. The survey questions were based upon findings in a literature review focusing on DH labor, best practices, and case studies, and were designed to identify trends across both groups. I wanted to determine the extent to which these groups collaborate with one another on project teams. Questions sought to ascertain how these collaborations unfold and who initiates them; whether IPs have begun to adjust and adapt their work to support specific DH projects, or to make their content more appealing and easy for potential future DH projects; and what administrative hurdles are faced during the collaboration. After working together, how do IPs and DH scholars view the success of the collaboration, and do they intend to collaborate in future? What do these responses tell us about how best to support all members of these collaborations?</p>
<h2 id="literature-review">Literature Review</h2>
<p>Digital humanities collaborations between information professionals and subject faculty/researchers/alt-academics have been written about extensively, primarily by information professionals; indeed, I was unable to find any studies on these collaborations authored by subject faculty. First, of course, collaborations between information professionals and subject specialists have been common occurrences since the advent of this kind of work. Further, sometimes a researcher inhabits both roles: an information professional may also pursue subject research and perform digital humanities work, and vice versa <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. To place the present study into context, I will focus on scholarship that focuses on the labor that goes into digital humanities work, as well as scholarship that describes different types of collaborations in the digital humanities.</p>
<h2 id="labor">Labor</h2>
<p>Some scholars writing about library labor in the digital humanities have focused on the question of whether information professionals should be seen as acting in service to subject scholars, or whether they inhabit the role of a professional peer.</p>
<p>Two prominent research organizations sought to frame the discussion around ways librarians can support digital humanities scholars in their work, and discussed difficulties encountered in developing and supporting these collaborations. In 2011, the Association of Research Libraries released  <em>SPEC Kit 326: Digital Humanities</em> , a report based on a survey of membership about their experiences providing digital humanities project support. Responses indicate that while most libraries provide digital services, often this is done in an ad-hoc way, with chronic understaffing and underfunding <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Similarly, for their OCLC report  “Does Every Research Library Need a Digital Humanities Center?” , Jennifer Schaffner and Ricky Erway consulted DH scholars and attended digital humanities conferences to identify scholars’ research needs. Their final report provided library administrators with recommendations for aiding digital humanities scholars with their projects <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<p>However, several scholars have provided critiques of this service approach, focusing on power imbalances inherent in the academy between librarians and scholars. Trevor Muñoz problematizes the idea that librarians should be seen in a service role for scholars doing digital humanities research. He argues that library administrators often defend library investment in DH projects as a way to show the library’s value, justify its existence, and expand funding for other essential library functions. However, he argues that  “digital humanities research [is] core to the theory and practice of librarianship in its own intellectual terms rather than as a useful lever in some temporary tactical maneuver”  and should instead be a  “source of ideas”  for librarians on its own <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. Dot Porter points out that librarians themselves may be doing digital humanities work, and that setting up digital humanities scholars in contrast to librarians may not be accurate or fruitful <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Bethany Nowviskie discusses the  “strong service ethic”  that remains a key part of library culture, but describes how it can place librarian-practitioners and library resource allocation at a significant disadvantage <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. If a librarian’s goal is to provide  “self-effacing service”  while  “not distracting the researcher for his or her work,”  this can ultimately lead to a misleading  “smooth, professional veneer over increasingly decrepit and under-funded infrastructure – effectively…hiding the messy innards of an organization from one’s faculty,”  who might otherwise be  “a library’s strongest allies”   <sup id="fnref1:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</p>
<p>Miriam Posner agrees, outlining key ways library collaborations in the digital humanities are undermined by the structure of academic libraries and the frequent lack of resources and institutional support from library and university administration. Posner argues that  “it can be very challenging for a librarian charged with  supporting  a project to dissuade a faculty member from barreling ahead with a half-baked idea,”  in part because of power differentials built into academia between librarians and scholars <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. A recent study of librarians active in DH by Molly Dahl Poremski shows that these issues continue to exist:  “The current landscape of DH librarianship shows a profession that is not entirely prepared to meet the needs of its users. [&hellip;] Given the nature of our profession, we rise to meet this challenge with enthusiasm, even if our levels of funding and support may not be as high as our hopes. DH librarians appear to be making do with what they have available to them but require additional aid, both institutionally and professionally”   <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>Another key line of criticism has focused on library work in the digital humanities sphere as emotional labor or feminized labor, in which the structures and hierarchies in place that mark library work as service work disincline other scholars from seeing librarians as peer collaborators <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. Building on this, Logsdon, Mars, &amp; Tompkins explore ways that librarians, as intermediaries between expert and novice researchers, and as people who have a wide breadth of knowledge in research skills, tools, and disciplines, can be a huge asset in DH collaborations. However, in spite of this occupation of liminal space, and in fact because of it, librarians often must provide emotional labor in the context of collaborating with digital humanities researchers, by, for example,  “appearing enthusiastic about projects that you suspect will be too unwieldy to succeed given the time and human resources available and knowing how to manage the proposer’s expectations without damaging their enthusiasm for the digital project,”  or  “maintaining a professional demeanor even when your expertise is marginalized in a given project”   <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.</p>
<p>Though these studies and analyses problematize the “service model” of librarianship, they do not attempt to assess how digital humanities scholars or information professionals interpret or navigate these power dynamics within the context of their specific projects or institutions.</p>
<h2 id="best-practices-case-studies-and-surveys">Best Practices, Case Studies, and Surveys</h2>
<p>The bulk of literature around digital humanities collaborations focuses on case studies and the development of best practice guidelines. For example, scholars have described collaborations in pedagogy, instructing students on the use of TEI <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>; in the development of scholarly digital editions <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>; or in managing a large-scale digitization project <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. Many of these also share best practices or lessons learned, while sharing any specific roadblocks or difficulties noticed during the project <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>  <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>. <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup></p>
<p>Another prevalent theme in the literature pertains to the role of digital humanities centers in fostering collaborations between librarians and subject faculty. For example, Rosenblum and Dwyer outline their experiences as a faculty member and librarian co-leading a digital humanities center at the University of Kansas, and offer best practices for maximizing the effectiveness of collaborating across disciplines in this way. Interestingly, the university-wide task force that initially suggested a dual-leadership model in this case had envisioned a very clear breakdown of responsibilities: the leader drawn from humanities faculty would be responsible for  “the scholarly contribution of research projects and educational programs,”  while the librarian would  “focus on the digital realization of scholarship and the access, organization, and preservation of sustainable digital research content working with various campus partners”   <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. As the authors assumed their leadership roles, however, they did find that the division of labor was much less clear and explicit as initially expected, and they collaborated on many, if not all, tasks <sup id="fnref1:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. This may be an example, then, of a situation in which library and faculty collaborators act more as peers.</p>
<p>Several researchers have conducted surveys or interviews with collaboration partners to get a sense of the nature of collaborations and touch on key issues that arose. Poole and Garwood interview participants in several international-scale, grant-funded collaborative digital humanities projects. They determin that while very few information professionals were explicitly listed as members on project teams, in almost every case information professionals performed essential functions on the project. They conclude, among other things, that  “librarians [and] archivists&rsquo; work remains largely invisible in these projects. It must be made visible to exploit existing and to provide evidence for additional resources”  and  “infrastructure must be leveraged and policy developed or clarified for optimal collaboration between librarians and DH”   <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>.</p>
<p>In a similar vein, Alix Keener interviewed pairs of subject faculty and information professionals from several institutions from the Center for Institutional Cooperation (CIC) collaborative. In this survey, faculty and librarians were asked a series of questions to elicit their notion of the role of librarians in digital humanities work. Key findings include the fact that many faculty feel that support for digital humanities work is much more mature and institutionalized in the library than in their home academic departments; meanwhile, the librarians interviewed did not feel that digital humanities were nearly as universally supported in their own library departments. Keener speaks to the question of librarian-as-service-provider versus librarian-as-peer, stating that librarians are perceived as peers and colleagues by their faculty colleagues and report feeling like peers to those colleagues themselves, though participants were generally aware of tensions about the inclusion of librarians in DH work <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. Interestingly, several respondents pointed out that collaboration generally is viewed with skepticism in the humanities, whether with librarians or other scholars; tensions felt may be less a function of the fact that librarians are not subject faculty, but instead the fact that collaborations are viewed with some disdain in the humanities world, while they tend to be more supported generally within the digital humanities community.</p>
<p>After consulting the literature, I determined that while collaborations between digital humanities scholars and information professionals had been studied within limited parameters (e.g., project teams at large institutions with digital humanities infrastructure, as in Keener, or internationally, as in Poole and Garwood), collaborations occurring within and across a wider spectrum of institutions, particularly smaller institutions with limited resources, required further study. In addition, the literature describing perspectives on collaboration from digital humanities scholars is limited, though some scholars have theorized about labor imbalances across the academic institutions and about challenges stemming from administrative support (e.g., <a href="#posner2013">Posner 2013</a> and <a href="#nowviskie2014">Nowviskie 2014</a>). My research was informed by my own positioning and background as a digital archivist in a small but developing university digital library program. In my own career, I have found that resources and institutional support often play a significant role in the ability of librarians and archivists to initiate and participate in digital humanities projects of any kind, and have primarily seen information professionals function in an advisory or collaborative capacity when asked to support projects initiated by research or subject faculty. My personal experience, therefore, supports findings by Posner and Nowviskie as outlined above, but I desired to test whether information professionals in a variety of institutional settings had had similar experiences, and to determine what circumstances breed successful collaborations. I therefore designed a large-scale study to investigate how IPs and scholars perceive, develop, and assess their DH collaborations and the degree to which the collaborations are considered successful.</p>
<h2 id="survey-methodology">Survey Methodology</h2>
<p>To investigate digital humanities collaborations among a variety of practitioners, a survey was developed with a total of 33 questions. The full survey can be viewed in Appendix I. The survey contained some questions that were presented to all respondents, as well as questions directed only to those who identified as library/archives professionals or faculty/graduate students/alt-academics in subject areas. Other respondents (such as administrators and IT professionals) were presented with a subset of these questions as well. The survey was distributed via online lists such as the Society of American Archivists listserv, Code4Lib, the UVictoria&rsquo;s DHSI list, and HASTAC, in order to achieve a wide array of participants in both the library-affiliated and subject faculty worlds. The online survey methodology was selected because of its ease of implementation and its ability to reach a very wide cohort of practitioners <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>. The survey was available between August 24 and October 5, 2016, and 508 responses were collected during that time. Of these, 242 surveys, or 47.64%, were completed in full. As respondents were permitted to skip questions in the survey, I accepted all submitted surveys, and analyzed each question based on the total number of valid responses submitted for that question. I used Microsoft Excel to view and analyze the data.</p>
<p>Many of the survey questions were free-text; respondents could write in as much or as little information as they wanted, rather than choose from a list of responses. For these questions, I looked for recurring themes in the answers and calculated how many respondents mentioned the most frequent themes in their statements.</p>
<p>During my analysis of the results, several errors were discovered in the structure and internal logic of the survey. In some cases, respondents were given the opportunity to answer questions for which they were not the intended audience. For example, in one case, I intended to ask archives and library professionals about their plans for long-term preservation of digital projects, but the question was presented to all respondents. In these circumstances, I separated out the answers provided by the intended audience and analyzed those; if the answers provided by the erroneous recipients proved to be useful, I analyzed them separately and reported it as such. Also, a number of respondents (60) answered that they did not collaborate on the project they were describing; I chose to remove those responses from my overall survey analysis, as the focus of this project is on collaborative projects specifically.</p>
<h2 id="survey-results">Survey Results</h2>
<h2 id="participants">Participants</h2>
<p>Of the 508 survey responses, nearly 48% identified themselves as an archivist, librarian, or a graduate student in either of these areas. Nearly 34% identified themselves as a faculty member (20.35%) or graduate student (13.31%) in a subject area outside of library or archives. Of the remaining respondents, approximately 10% self-identified academic researchers, administrators, or IT professionals. For the purposes of this article, I will distinguish between two groups: information professionals (IPs), which consist of librarians, archivists, and graduate students in those two disciplines (48% of the total); and other digital humanities scholars (DHs), which consist of subject faculty, students in subject disciplines, alt-academic scholars, administrators, and others (52%).</p>
<p>Studying and comparing the responses of information professionals to those of other types of digital humanities scholars does highlight, and perhaps reify, a binary between those two groups. As the above literature review demonstrates, information professionals conduct digital humanities research alone and in collaboration with other scholars, and casting them as distinct from other scholars poses the risk of painting them as less qualified researchers, or erasing their work from discussions of digital humanities as a field. However, as Posner argues and as the survey results will show, information professionals face different workloads than other DH scholars often do, especially those scholars for whom teaching and research is a primary responsibility <sup id="fnref1:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Further, administrative structures and funding requirements, as well as expectations of a service orientation, work differently in library and archives departments than in academic departments (or, indeed, in information technology departments or digital humanities centers). Grouping and comparing responses as I do below allows me to explore how these realities affect the experiences of the collaborative partners.</p>
<p>I also inquired about the subject specialties of the faculty and graduate students responding to the survey. 43.25% of respondents said that English, literature, foreign language literature, writing, or affiliated disciplines were their area of expertise. 17.85% indicated history, while an additional 3.78% specified Medieval history or studies. Remaining respondents mentioned a variety of other disciplines, including anthropology, art and art history, media studies, and, indeed, digital humanities. The majority of respondents (77.24%) reported working in a college or university setting, with the next largest group employed at museum or arts organizations (7.09%). 24.66% of the graduate student respondents reported that they were enrolled in a digital humanities track or major. In this survey, I did not ask respondents whether their institution had a standalone Digital Humanities Center; this would be an interesting avenue for further research.</p>
<p>The vast majority of respondents worked on at least one digital humanities project: 18.45% had worked on one project, and 73.02% had worked on more than one. I instructed respondents who had worked on multiple projects to consider their most recent project when answering the survey questions.</p>
<p>One line of inquiry not included in this survey pertains to the employment status of respondents: or whether they held a faculty, administrative or staff role; if they were faculty, whether they were full-time or adjunct; whether they were tenure-track or tenured; or if librarians or archivists, whether they held faculty status or staff status. Further research on how employment status affects collaborations, funding, and administrative support could be very fruitful.</p>
<h2 id="nature-of-digital-humanities-deliverables">Nature of Digital Humanities Deliverables</h2>
<p>I asked all respondents to describe the DH projects they had worked on, asking them to mention deliverables and which members of the team contributed to which aspects of the project. I chose not to provide a definition for &ldquo;digital humanities project&rdquo; in order to allow respondents to include anything that met with their own definition of the idea. Indeed, one respondent wrote that they were not sure whether to include their project because  “[a]rguably, this isn&rsquo;t digital humanities, but the phrase has been stretched so far that some people would include it in their definition – [I]&rsquo;m not sure what yours is.”</p>
<p>Many respondents described multiple projects in their response to this free-text question, or included a number of digital humanities workflows or outputs that dealt with a particular collection or theme. I collected 201 responses to this question. I analyzed the responses and flagged recurring features that were listed, such as websites, digitization projects, and application development; this analysis generated 546 features (for the purposes of this article, I will refer to these features as data points). For this particular question, I calculated percentages based on the number of responses; because most responses mentioned projects with several features, and some responses even mentioned multiple projects, I wanted to show how many individual practitioners mentioned particular features in their answers. The results of this question can be seen in <a href="#">Figure 1</a>.</p>




























<figure ><img loading="lazy" alt="Participant descriptions of DH Projects" src="/dhqwords/vol/13/4/000441/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000441/resources/images/figure01_hu48215858c4d834d1db1bec832d7a5190_104467_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000441/resources/images/figure01_hu48215858c4d834d1db1bec832d7a5190_104467_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000441/resources/images/figure01.png 631w" 
     class="landscape"
     >
</figure>
<p>For these respondents, then, a web component is key, either for delivering the results of their analysis or as the deliverable itself. Approximately 60% of respondents mentioned a website, Omeka gallery, or web exhibit as an outcome of their projects. Approximately 32% mentioned digitization of print or analog materials. Approximately 28% mentioned programming, creation of applications, use of Scalar, or other technical work. Approximately 25% mentioned creation of a database, catalog, or searchable archive, and approximately 24% of respondents mentioned metadata work. Interestingly, some hallmarks of digital humanities projects, including maps, data visualizations, and textual analysis, were mentioned by fewer than 15% of respondents each.</p>
<p>Indeed, because the framing of the question focused primarily on deliverables, few respondents went into depth discussing their research methodology, subject selection, or critical approach. This is a blind spot in the research design: perhaps because of my information-professional approach, I focused on the research products rather than the lines of scholarly inquiry advanced by these collaborations. In part, this serves to hide the intellectual contributions of all respondents, particularly information professionals, who may have fewer fora to showcase their research output <sup id="fnref2:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. Future research might inquire and analyze the scholarly dialogue between collaborators in IP and DH partnerships.</p>
<h2 id="initiating-the-project-beginning-the-collaboration">Initiating the project: Beginning the Collaboration</h2>
<p>Next, I wanted to identify who initiated collaborative projects: did subject specialists reach out to information professionals, or vice versa? How did these collaborations begin? When I asked information professionals about their collaborations with academic colleagues, 61.93% of the total responses (197) mentioned collaboration with faculty or professional colleagues from their own institution; 11.17% of responses mentioned that they worked with graduate students from their own institution; 16.24% reported working with faculty from other institutions; and 1.52% described working with graduate students from another institution. 9.14% of respondents mentioned that they worked on their project(s) alone.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>  Again, these respondents were removed from the remainder of the survey at this juncture.<br>
Table 1. IP Collaborations    Information professionals collaborated with…  Percentage of Respondents  n=      Faculty/ Professional colleagues, same institution  66.03%  103      Faculty/ Professional colleagues from another institution  12.82%  20      Students from my institution  10.90%  17      Alone  9.62%  15      Students from another institution  0.64%  1      Total  100.00%  156   <br>
When I asked academic colleagues about their work on projects with library and archives professionals, their responses were as follows. Out of 231 respondents, 37.23% said they worked with both archivists and librarians. 20.35% reported that they worked with librarians; 11.26% reported that they worked with archivists; and 7.36% said they worked with information professionals but were not sure whether they were librarians or archivists. 23.81% reported that they worked on their projects alone. Of course, as this survey was clearly described as being designed to study collaborative projects, it is no surprise that those who took the survey had collaboration experience. (Again, at this juncture of the survey I removed any additional respondents who reported working alone on their projects.)<br>
Table 2. DH Collaboations    DH Scholars collaborated with…  Percentage of respondents  n=      Colleagues in both areas  37.23%  86      Librarians  20.35%  47      Alone  23.81%  55      Archivists  11.26%  26      Yes, but not sure which  7.36%  17      Total  100.01%  231   <br>
Next, I asked the DH scholars and the information professionals whether they initiated the project themselves, or were invited to join by a colleague. The standout finding here is that almost 78% of the time, faculty respondents said that the project was their idea, and they reached out to their information professional colleagues to join them. For the archivists and librarians who responded, over 50% of the responses indicated that faculty colleagues initiated the project (51.56% of responses for archivists and 53.70% for librarians). For the archivists and librarians, responses ranged between 19 and 25% for initiating the project on their own or for coming up with the project in tandem with their colleague. This finding shows that for these respondents, academic researchers are frequently initiating collaborations with information professionals for some portion of their project. </p>
<p>This response is underscored by the next set of questions, displayed <a href="#table03">in Table 3</a>. I asked anyone who responded that the project had been initiated by a colleague how they came to be involved. First, approximately 72% of the respondents to this question were information professionals, which confirms the findings in the previous question. I broke the responses down: for information professionals, approximately 27% were simply asked to join by colleagues; approximately 18% had a skill necessary to complete the project; approximately 18% have jobs that explicitly include DH projects in their scope; approximately 9% were part of a staff or team that were assigned the project; approximately 9% applied to a job opening that included work on that project; and approximately 7% invited themselves onto the team/volunteered to participate. 13% had another response.<br>
Table 3. Ways Collaborators Joined Projects They Did Not Initiate    Method  Information Professionals (n=44)  DH Scholars (n=17)      Part of staff/team that was assigned specific project  8.9% (n=4)  15.8% (n=3)      Had Necessary Skills/In a role that is required to be looped in  17.8% (n=8)  21.1% (n=4)      Other  13.3% (n=6)  10.5% (n=2)      Invited Myself  6.7% (n=3)  21.1% (n=4)      Was Asked  26.7% (n=12)  15.8% (n=3)      Applied for Job Opening/Internship  8.9% (n=4)  10.5% (n=2)      Job Explicitly Includes DH  17.8% (n=8)  5.3% (n-=1)             <br>
In contrast, when I broke down the responses for academic and professional colleagues, the responses were as follows: approximately 16% were simply asked to join by colleagues; approximately 21% had a skill necessary to complete the project; approximately 5% have jobs that explicitly include DH projects in their scope; approximately 16% were part of a staff or team that were assigned the project; approximately 11% applied to a job opening that included work on that project; and approximately 21% invited themselves onto the team/volunteered to participate. 11% had another response.</p>
<p>Information professionals are still much more likely to be asked to join a project than subject faculty and other academic colleagues. Academic colleagues were much more likely to invite themselves to join a project of interest to them. Both IPs and scholars were roughly equally likely to be asked to join because of a skill they possessed. IPs were much more likely to have a job that explicitly includes DH work, but academic colleagues were much more likely to be part of a team assigned to a DH project. These responses demonstrate that scholarly researchers outside of the library have more opportunities and flexibility to take on DH projects if they are interested in doing so. Information professionals may be more likely to be constrained by their role, or limited by time and resources, as we will see later in this study; this may prevent them from being the primary motivator in establishing DH projects. However, another factor to consider is cultural; the longstanding perception of librarians and archivists as service-providers may be entrenched enough that scholars are more likely to draw on IP’s expertise than the other way around. Further research could examine constraints on when information professionals initiate projects.</p>
<h2 id="successes-and-failures">Successes and failures</h2>
<p>Both DH scholars and information professionals were asked to reflect upon their interactions with colleagues, and asked to suggest what could be done to improve similar (or future) collaborations. 57.89% of the DH scholars responded that the collaboration was successful, with another 31.58% responding that they had mixed results. Only 3 responses (2.63%) were a clear no (the remainder were coded as N/A, other, or that the project was still ongoing). Those scholars who felt they had a mixed experience most commonly mentioned that they wished the library/archives staff had more time or resources to share. Several also mentioned that they would have liked more clarity about project planning and timelines; more training so they could do more of the work on their own; or more of a mutual understanding around key project terms like metadata, preservation, and sustainability.</p>
<p>The information professionals’ assessment was a bit more complex. 82 information professionals answered this question. Of these, 28.05% said it was a successful collaboration; 8.7% said it was not; 58.54% said it was a mix; and 3.66% said N/A or other. I then broke the mixed responses into categories, to further analyze their explanations; these responses were parsed into 68 data points. 16.18% of the data points mentioned issues around communication, responsiveness, and expectation-setting with their faculty counterparts. 10.29% mentioned that the project would be more successful with increased funding. 8.82% mentioned issues around leadership, coordination, and decisionmaking; 8.82% mentioned the lack of familiarity on the part of faculty with IT or librarianship/archival work and what would be possible to accomplish; and another 8.82% mentioned the need for improved institutional support (aside from funding). For example, one librarian wrote,  “Collaboration with my immediate colleagues was/is successful, but the way our projects fit into the overall library structure is still very tricky. [Our digital project has an] unfunded mandate and this model is not sustainable, in terms of staff time required. So, it&rsquo;s not that collaboration could be better but the infrastructure around the collaboration needs to be better.”  Another librarian wrote,  “Collaboration with faculty was good. Getting buy in from library admin is harder.”</p>




























<figure ><img loading="lazy" alt="Participant responses to survey question" src="/dhqwords/vol/13/4/000441/resources/images/figure02.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000441/resources/images/figure02_hu69f000fa5abfdfa200e494722239310c_108384_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000441/resources/images/figure02_hu69f000fa5abfdfa200e494722239310c_108384_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000441/resources/images/figure02.png 637w" 
     class="landscape"
     >
</figure>
<p>From these responses, information professionals seem to be frequently turned to for support and labor, and they would like to be able to do these digital humanities projects. However, they may not have the time, resources, or support to do so. Further, many respondents mentioned that faculty colleagues had different expectations than they did around what was possible via their collaboration: how much time it would take, how responsive each party would need to be, and what kind of IT or library work was feasible and what was not. Further research could highlight the hurdles, especially administratively, that prevent information professionals from working on digital humanities projects.</p>
<p>Interestingly, 5.88% also mentioned that they felt some snobbery or dismissiveness on the part of faculty against their information professional counterparts. One archivist said,  “It was hard for academic colleagues to acknowledge the fact that I am myself also faculty and also have research interests to pursue…. They didn&rsquo;t understand why I was driving the project, and thought it needed to come out of a pet question or topic under study by a  serious  scholar. I was studying user response to data visualizations. And I got an awesome digital humanities project out of it.”  It is important to note, however, how few responses mentioned this kind of tension.</p>
<p>I also asked several questions pertaining to issues around resource allocation, which provide a preliminary snapshot into the funding associated with these respondents’ DH projects. First, all respondents were asked, in a free-text question,  “How was the project funded?”  Each respondent could list as many responses as they desired; phrases were coded and collected to yield 272 data points. Of these, 36.76% of responses mentioned receiving no additional funding at all to complete the project; the project was funded only out of regular salary or department funds. A similar percentage, 37.78%, of responses included a mention of funding by external or governmental grants (respondents who identified as DHers were more likely to mention that they had external funding: 41.28% of DHers mentioned external or governmental grants in their responses, whereas only 32% of IPs did). Additional funding for these projects came in the form of internal (departmental or institutional) grants. Responses across these categories were consistent between DH and IP respondents, aside from the difference in those reporting external grant funding.</p>
<p>Next, I asked all respondents,  “What extra resources (eg staff, time, equipment), if any, did completion of the project require?”  This, too, was a free-text question, and answers were parsed and coded. Out of a total of 356 responses, the most frequent responses were staff time (specifically existing staff time reallocated from other projects and responsibilities) at 35.92%; acquisition of equipment or software at 24.14%; and additional staff, volunteer or students hired, at 18.10%. Response rates for each of these categories were similar between DH and IP respondents.</p>
<p>Lastly, due to my interest in institutional support for information professionals participating in DH work, I asked only the IP respondents to  “Please describe any support, interest, or roadblocks you faced from supervisors while taking on this project.”  Out of 76 respondents, 57.89% reported that they received support from their supervisor. Respondents were also permitted to add a free-text explanation to this answer; the most popular issues they reported supervisors mentioning were concerns around the time it would take to complete the project (15.79%); IT support (9.21%); issues around funding (9.21%); and issues around copyright (3.95%).</p>
<p>These results provide some preliminary context for the key issues collaborative partners face in their work in DH. Many projects were supported by external grant funding. A lot of the projects were completed using existing staff and staff time, rather than via an injection of additional resources or staff. Many projects were not awarded any additional funding at all. A slim majority of information professionals reported support from supervisors, but supervisors mentioned concerns about the investment of time and resources required to participate in these DH projects. As a practicing information professional, these results suggest to me that while there is a lot of interest in this work among scholars, information professionals, and supervisors, resources may be limited to complete it, and for information professionals in particular, projects of this type that may be added to more established workloads represent a resource crunch rather than an inducement to build capacity. Further research is necessary to understand the varied experiences of library scholars and other researchers, as well as the responses and support provided by their administrative and institutional contexts.</p>
<h2 id="the-role-of-ips-according-to-dhers">The role of IPs, according to DHers</h2>
<p>Next, I wanted to explore the ways digital humanities scholars outside the library perceived the role of information professionals in contributing to their shared projects, and how that might have changed as a result of working with an information professional. I targeted a series of questions to the digital humanities scholars about their perceptions.</p>
<p>First, I asked,  “Has your understanding of the work of your archives/library colleagues changed in any way? Please explain.”  There are 69 free text answers to this question. Most people responded that they learned something new (60.87%), and the majority of these new things can be characterized as positive. Examples include:  “I have more respect for their skills and knowledge” ;  “I have a better understanding of the different roles of librarians/archivists” ; and  “I have more ideas about collaborating with them in the future.”  Nearly 57% of the answers in the lessons learned category pertain to the subject researchres learning more about what goes into library work. For example, one respondent wrote:  “I wasn&rsquo;t aware before of the  mismatches  between archival metadata (like EAD) versus the kinds of metadata other academic researchers need for searching and retrieval.”  However, not all the lessons learned were positive: some people (nearly 16%) learned lessons they described in negative terms, such as that information professionals  “don&rsquo;t have good technical skills”  or that they were not aware of how understaffed the libraries were. In addition, some responded that they were already well aware of what information professionals do from having worked with them extensively in the past.</p>
<p>Next, I asked DH scholars to explain whether they felt it was the role of archivists and librarians to prepare analog materials for use in digital humanities projects, such as by digitizing text or adding geodata to maps. Many archivists and archival repositories are seeking ways to make their collections more visible and usable by seeking to participate in such digital projects; I was curious to see whether DH scholars expected this work from IPs. The answers to this question were, again, a mix. 37.35% of respondents said yes; 10.84% said no; and 38.12% said they were unsure, or that it wasn’t necessarily in the purview of archivists and librarians.</p>
<p>Some respondents added comments or explanations to their response; I parsed these into 136 data points for analysis. 8.82% of the responses mentioned that this work should be done as a collaboration between information professionals and scholars; and 4.41% mentioned that IPs, on their own, would not know what should be digitized or prepared for DH projects, and should rely on scholar-driven research to develop their projects. This kind of answer points to some interesting contrasts in training and expectations among IPs and DH scholars. Many information professionals are experienced with selecting materials to highlight, and many are subject specialists themselves. Further, library and archival training can help teach IPs to identify materials that would be of interest to scholars. In fact, within the last fifteen years, the archival community has focused resources on processing and showcasing hidden collections, those materials that might not have been yet made visible to users due to resource or time constraints. From the perspective of IP training, digitizing collections and making them accessible can be a way to draw the attention of scholars and develop new projects around their holdings. However, resource constraints often limit IPs’ ability to do this kind of work.</p>
<p>DH scholars, on the other hand, might have an area of particular interest to their own scholarship. Their work is project-based and tied to specific corpora that would support their own research. As one respondent put it, IPs shouldn’t preemptively digitize materials because  “often they don&rsquo;t know what might be of interest to scholars.”  As another put it,  “I don&rsquo;t know how [to] help librarians know which materials to prioritize, and it would be a shame to invest an enormous effort into digitizing, collecting, or correlating data that then never gets used.”  However, it is an expected part of an information professional’s purview to perform research and investigate what content is most suitable for digitization, if resources permit.</p>
<p>Next, I asked scholars whether they felt that it was the role of information professionals to  “preserve and make accessible in the long term digital humanities projects created by scholars like yourself?”  I had 80 responses to this question; 61.25% said yes, this is within the purview of IPs, 7.5% said no, and 31.25% said not sure or not necessarily. A number of these respondents provided more detail in their explanation; I parsed these into 28 data points, and the most popular answers were as follows. 21.43% of the answers mentioned that IPs should continue providing access to digital humanities projects like they have always done with other resources, like books. 21.43% mentioned that information professionals doing this sort of preservation work preserves the relationship between a scholar, their work, and their institution; and 14.29% mentioned the idea that libraries have the resources or infrastructure necessary to do this sort of preservation. 14.29% argued that information professionals and digital humanities scholars should be having conversations and what sorts of work should be preserved and why. Overall, most scholars reported support for the notion that information professionals should be involved in this work.</p>
<p>To conclude this section, I asked DH scholars,  “How can archivists or librarians help your work in future digital humanities projects?”  Responses varied widely. I parsed the responses into 109 data points, and they break down as follows. Most respondents (24%) requested help with technical and library skills. 13.76% mentioned an interest in initiating or improving more collaborations. A number of respondents asked IPs to  “share,”    “collaborate,”    “connect,”  and  “contribute”  (12.84%) to overall projects. 4.59% of the answers highlighted help with metadata specifically. 4.59% mentioned that time and funding hurdles can prevent DHers from capitalizing effectively on IPs&rsquo; expertise. Other noteworthy themes: some DH scholars noted that IPs are key for providing access and acting as gatekeepers to particular materials (2.75%), with another 5.5% asking IPs not to be  “obstructive”  and to have a better attitude about sharing resources and listening to the needs of DHers. 2.75% said that IPs need to improve their own technical skills before they can be helpful. And 12.84% simply said wanted archivists and librarians to keep positively supporting their work: IPs should  “keep being awesome;”  they should  “keep doing exactly what they have been doing, which is being well-trained, interested colleagues open to new form[s of] digital scholarship;”  and noting that  “librarians and archivists are historians&rsquo; best friends :-)”</p>
<h2 id="the-role-of-ips-according-to-ips">The role of IPs, according to IPs</h2>
<p>Turning now to the perspective of information professionals on their role in digital humanities projects, I asked them a series of questions about their experiences. First, I asked archives and library respondents whether they felt digital humanities projects were part of their role. The results were overwhelmingly positive: 55.84% said yes, that these projects were explicitly part of their role; another 24.68% said they were somewhat or tangentially related to their role; and another 3.90% said they built digital humanities projects into their role. Only 14.29% said DH projects fell outside the scope of their work. These answer demonstrate that information professionals now expect to do this work as part of the course of their librarianship.</p>
<p>I then asked information professionals about the ways they might have altered their workflows to accommodate the needs of DH projects. First, I asked,  “Did your work on the project contribute to any of the traditional archival life cycle steps, such as Arrangement, Description, Preservation, or Providing Access? Please explain. (Examples include digitizing analog text for the project that could provide increased access, or taking steps to ensure digital preservation of a website created as part of a DH project.)”  I parsed the results to yield 122 answers. Most respondents highlight ways they provided all or most of these. Some used the word  “digitization”  in general, but it&rsquo;s not clear whether they felt this was associated with access, preservation, or another step that I highlighted; I classified those responses as other. 34.43% of the responses mention access; 18.85% mention preservation; 24.59% mention arrangement/description; 12.30% were classified as other; and the remainder (9.84%) said No or N/A.</p>
<p>For the next question, I asked information professionals,  “Did you change any of your standard archival workflows to accommodate this project, or in anticipation of future similar projects? (For example, did you switch to higher quality OCR software to support text mining? Did you embed geographical metadata into a digitized map to allow for geodata visualizations?)”  First, I broke the 69 responses from information professionals down into yes (44.93%), no (36.23%), N/A (8.7%), and other (5.8%). A number of the respondents explained their answers; I parsed these answers into 108 responses, the most popular answers of which broke down as follows. 9.82% made changes in the realm of metadata; 7.14% made changes in their work with mapping and geodata; 4.46% made changes to their digitization workflows; 2.68% changed their staffing to accommodate the new projects; 1.79% made changes with OCR; 1.79% changed their data visualization procedures; and 1.79% reported that they didn’t have standard workflows in place before this project, but the project helped to implement them.</p>
<p>Finally, I asked information professionals whether they planned to provide long-term access or preservation for this project. There were 69 respondents. The vast majority (64.38%) said Yes, they plan to ensure ongoing access or preservation in some form or fashion, with another 12.32% percent saying that they are still working it out. 15.07% percent said no, though several of these said it&rsquo;s because their projects were pedagogical in nature or proofs of concept, so they were not designed to be kept for the future. 5.48% responded in some other way.</p>
<h2 id="conclusions">Conclusions</h2>
<p>The survey results and analysis provide a number of conclusions and suggestions for further research. First, it seems clear that collaborations between subject researchers and information professionals are happening, and happening frequently. Secondly, while information professionals generally see digital humanities projects as within their purview, they are not initiating these collaborations nearly as frequently as their digital humanities scholar colleagues. Why are the information professionals not initiating as often? This is an area for further research, but responses in this survey suggest that information professionals are often so limited in their available staff time and resources that they will work with a colleague when approached but are not able to prioritize these projects from within their own departments.</p>
<p>Next, this survey lends support to Rosenblum and Dwyer’s (2016) argument that in collaborations between subject researchers and information professionals, tasks do not necessarily break down into expected categories in which the subject expert is in charge of the academic research questions and interpretation, and the information professional is in charge of tools, implementation, and support. Based on my analysis of the projects described here, information professionals and subject specialists shared many tasks, and sometimes did tasks outside of what would traditionally have been their expected purview. For example, one academic researcher wrote,  “My archivist colleague participated in the design of metadata fields, tutorials for appraisal, finding additional sources of funding. I was responsible for the design and development of the digital archive, outreach, funding and securing a home for it.”  In many projects, however, archivists and librarians are serving in a more support role, doing project management, digitizing materials, working on metadata, and learning and teaching new tools or software products.</p>
<p>This survey revealed intriguing responses regarding the impressions information professionals and digital humanist researchers had of working with each other. While, generally speaking, the researchers felt that their projects were successful and the information professionals were supportive colleagues with whom they enjoyed working and whose expertise they valued, responses from the information professionals were more mixed. Many felt that they had difficulty working collaboratively with researchers, had trouble setting appropriate expectations and communicating clearly. This may support Schaffner and Erway’s contention that collaborations might be difficult because many humanities scholars are very used to working on their own, and may not have much practice successfully negotiating a collaborative research project <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. On the other hand, many information professionals responded that they felt their collaborative work was very successful, but it would have been improved with more administrative buy-in or support in the form of staff time, funding, or other resources.</p>
<p>The survey results indicate that these collaborations, on average, tend to be viewed as successful and mutually beneficial by both parties, especially when institutional support is available. However, information professionals do report more difficulties with the collaboration, with resources, and with administrative buy-in. Institutional conditions must adapt to support more of these projects, and in particular funnel resources toward archivists and librarians to do this work and support long-term sustainability of these projects.</p>
<h2 id="full-survey">Full Survey</h2>
<p>{{/<em>&lt; figure src=&ldquo;resources/images/survey.pdf&rdquo; caption=&quot;&quot; alt=&ldquo;Image file of Qualtrics survey used in study&rdquo;  &gt;</em>/}}</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Porter, D.  “What If We Do, In Fact, Know Best?: A Response to the OCLC Report on DH and Research Libraries”  [Blog Post]. 12 February 2014. Retrieved from <a href="https://acrl.ala.org/dh/2014/02/12/what-if-we-do-in-fact-know-best-a-response-to-the-oclc-report-on-dh-and-research-libraries/">https://acrl.ala.org/dh/2014/02/12/what-if-we-do-in-fact-know-best-a-response-to-the-oclc-report-on-dh-and-research-libraries/</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Association of Research Libraries.   <em>SPEC Kit 326: Digital Humanities</em> . Tim Bryson, Miriam Posner, Alain St. Pierre, and Stewart Varner (2011).&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Schaffner, J., &amp; Erway, R.   “Does Every Research Library Need a Digital Humanities Center?”   Dublin, Ohio: OCLC Research (2014). Retrieved from <a href="http://www.oclc.org/content/dam/research/publications/library/2014/oclcresearch-digital-humanities-center-2014.pdf">http://www.oclc.org/content/dam/research/publications/library/2014/oclcresearch-digital-humanities-center-2014.pdf</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Muñoz, T.  “Recovering a Humanist Librarianship through Digital Humanities” . In White J. &amp; Gilbert H. (Eds.),   <em>Laying the Foundation: Digital Humanities in Academic Libraries</em>   (pp. 3-14). West Lafayette, Indiana: Purdue University Press (2016).&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Nowviskie, B.  “Skunks in the Library: A Path to Production for Scholarly R&amp;D.”    <em>Journal of Library Administration</em>  53 (2013): 53–66.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Posner, M.  “No Half Measures: Overcoming Common Challenges to Doing Digital Humanities in the Library” .   <em>Journal of Library Administration</em>  53.1 (2013): 43-52.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Poremski, M.D.  “Evaluating the landscape of digital humanities librarianship” .  <em>College &amp; Undergraduate Libraries</em> , 24.2-4 (2017): 140-154.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Shirazi, R.  “Reproducing the Academy: Librarians and the Question of Service in the Digital Humanities”  [Blog Post]. 15 July 2014. Retrieved from <a href="http://roxanneshirazi.com/2014/07/15/reproducing-the-academy-librarians-and-the-question-of-service-in-the-digital-humanities">http://roxanneshirazi.com/2014/07/15/reproducing-the-academy-librarians-and-the-question-of-service-in-the-digital-humanities</a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Logsdon, A., Mars, A., &amp; Tompkins, H.  “Claiming Expertise from Betwixt and Between: Digital Humanities Librarians, Emotional Labor, and Genre Theory” .  <em>College &amp; Undergraduate Libraries</em> , 24.2-4 (2017): 155-170.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Green, H.  “Fostering Assessment Strategies for Digital Pedagogy through Faculty–Librarian Collaborations: An Analysis of Student-Generated Multimodal Digital Scholarship” . In White J. &amp; Gilbert H. (Eds.),   <em>Laying the Foundation: Digital Humanities in Academic Libraries</em>   (pp. 179-204). West Lafayette, Indiana: Purdue University Press (2016).&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Clement, T., Hagenmaier, W., &amp; Levine Knies, J.  “Toward a Notion of the Archive of the Future: Impressions of Practice by Librarians, Archivists, and Digital Humanities Scholars” .  <em>The Library Quarterly: Information, Community, Policy</em> , 83.2 (2013): 112-130.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Braunstein, L.R., Carini, P., &amp; Dumpert, H.D.  ““And There Was a Large Number of People”: The Occom Circle Project at the Dartmouth College Library” . In Arianne Hartsell-Gundy, A., Braunstein, L., and Golomb, L.,  <em>Digital Humanities in the Library: Challenges and Opportunities for Subject Specialists</em>  (pp. 225-240). [Chicago]: Association of College and Research Libraries, a division of the American Library Association (2015).&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Lorang, E., &amp; Johnson, K.A.  “A Checklist for Digital Humanities Scholarship” . In Arianne Hartsell-Gundy, A., Braunstein, L., and Golomb, L.,  <em>Digital Humanities in the Library: Challenges and Opportunities for Subject Specialists</em>  (pp. 83-102). [Chicago]: Association of College and Research Libraries, a division of the American Library Association (2015).&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Vinopal, J., &amp; McCormick, M.  “Supporting digital scholarship in research libraries: Scalability and sustainability” .   <em>Journal of Library Administration</em>   53.1 (2013): 27-42.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Several of these articles mention  “digital curation”  as a key role for information professionals to play in these collaborations; Poole and Garwood describe this role as being responsible for  “the active and ongoing management of data [&hellip;] over its entire lifecycle to make it as highly-functional as possible, especially for sharing and reuse.”   <sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Rosenblum, B., &amp; Dwyer, A.  “Copiloting a Digital Humanities Center: A Critical Reflection on a Libraries–Academic Partnership” . In White J. &amp; Gilbert H. (Eds.),   <em>Laying the Foundation: Digital Humanities in Academic Libraries</em>   (pp. 111-126). West Lafayette, Indiana: Purdue University Press (2016).&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Poole, A.H., &amp; Garwood, D.A.  “‘Natural Allies’: Librarians, Archivists, and Big Data in International Digital Humanities Project Work” .  <em>Journal of Documentation</em> , 74.4 (2018): 804-826.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Keener, A.  “The Arrival Fallacy: Collaborative Research Relationships in the Digital Humanities” .  <em>Digital Humanities Quarterly</em> , 9:2 (2015).&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Vehovar, V. &amp; Manfreda, K.  “Overview: online surveys” . In Fielding, N., Lee, R., &amp; Blank, G.  <em>The SAGE Handbook of online research methods</em>  (pp. 143-161). 55 City Road, London: SAGE Publications Ltd. (2017). DOI: <a href="https://dx.doi.org/10.4135/9781473957992.n9">10.4135/9781473957992</a>&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>I asked respondents throughout the survey to answer questions based on their most recent collaboration or project, but many respondents wrote about experiences with multiple projects nonetheless. In those circumstances, I parsed the response and tallied each part individually. For example, if a respondent wrote that they worked with a subject faculty member on one project and with a graduate student on another project, I logged one response for a faculty collaboration and another response for a graduate student collaboration. Totals and percentages reflect this approach throughout the article.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Finding and Interpreting Arguments: An Important Challenge for Humanities Computing and Scholarly Practice</title><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/000436/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/13/4/000436/</id><author><name>Andrew Ravenscroft</name></author><author><name>Colin Allen</name></author><published>2019-12-14T00:00:00+00:00</published><updated>2019-12-14T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="prologue-from-distant-reading-to-close-reading">Prologue: From Distant Reading to Close Reading</h2>
<p>“We speak, for example, of an  angry  wasp.”  This sentence appears in the first edition of Margaret Floy Washburn’s textbook  <em>The Animal Mind: An Introduction to Comparative Psychology</em> , published in 1908. It occurs as part of an argument she presents against the anthropomorphic idea that we humans can use our introspection of anger to understand the emotions of organisms so physiologically and anatomically different from us. One suspects that Washburn, whose story deserves more space than we can give it here, was intimately familiar with anger. She was the first woman to earn a PhD in psychology in the United States — albeit not from Columbia University, where she wanted to study. Columbia were unwilling to set the precedent of admitting a woman for doctoral studies. Instead she received her degree from Cornell University, where she was accepted to the Sage School of Philosophy under the mentorship of Edward B. Titchener, the pioneering psychologist who pursued a combined introspective and experimental approach to the human mind. Washburn’s textbook would go through four editions, spaced roughly a decade apart, spanning one of the most consequential periods for psychology in its protracted separation from philosophy as a new experimental discipline. After World War II, Washburn’s book faded from view. We discovered it in the digital haystack of the Hathi Trust with the assistance of computational methods we deployed to help us locate argumentative needles such as the sentence leading this paragraph, the kind of process one of the present authors describes elsewhere as  “guided serendipity”   <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>Our goal in this essay is to urge more attention in the digital and computational humanities to the important scholarly practice of interpreting arguments. We describe what we learned from our attempt to take an argument–centered approach to humanistic enquiry in a big digital repository. We acknowledge that the methods and approach we adopted represents an initial attempt to explore a complex digital humanities problem, and can be improved upon, as one of our main aims is to draw attention to this problem and spur further work in this area. We believe we have provided a road map to guide future work — or, at least, an analogue to one of those early maps of the world drawn by explorers, no doubt distorting the major land masses, but better than nothing. If not dragons, wasps lie here, and although much of the work described here involved good old-fashioned human interpretation, our discovery of Washburn’s textbook and the angry wasps therein can be credited to the power of the computational methods we used to locate arguments about the anthropomorphic attribution of mental qualities such as anger to nonhuman animals.</p>
<p>Some of our work has been previously outlined in other publications that focused on our multi-level computational approach <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> and a technical investigation of the challenges of automated argument extraction <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Here, for the first time, we provide more detail about the human component of argument identification, extraction and representation scaffolded by the use of topic models to find relevant content. Through a two-stage, topic-modeling process, we drilled down from a book-level model of a large corpus (too large to read in a decade) a page-level model of a smaller subcorpus (still representing at least a year’s reading). This allowed us to select a few dozen pages from six books containing arguments that were mapped in detail within a few weeks by a team member with no prior expertise in psychology or the history &amp; philosophy of science. The argument maps produced by this step of human interpretation allowed us to identify statements that could be fed back into a third level of topic modeling, drilling down to the level of sentences in a single book. In this way we were able to discover other relevant arguments within the same text, including the one about angry wasps and another about the cognitive powers of spiders.</p>
<p>Automated argument extraction, also known as argument mining, has significant challenges and remains a holy grail of artificial intelligence research (e.g., see <a href="#mochales2011">Mochales and Moens, 2011</a>; <a href="#acl2018">ACL, 2018</a>). Our approach contributes only minimally to solving that problem <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> and, in fact, we doubt it is truly solvable with existing methods. Nevertheless, we propose that the digital humanities should invest more effort in developing argument-centered approaches to computational text analysis. We could be provocative and say that stylometrics and bibliometrics are the low-hanging fruit of digital humanities, and it is time for the digital humanities to take up challenges that may be harder, but which have more real-world impact. The skill of interpreting arguments is a cornerstone of education, scholarship, and civic life. Arguments are fundamental to human meaning making and to the maintenance, and reform of social norms. Even if the field of artificial intelligence is a long way from being able to properly interpret arguments in context, humanities scholars can use tools that are not so far out of reach to assist in their analysis and interpretation of the arguments that structure discourse in both academic and public domains. Interpreting arguments as they appear in historical documents brings them alive, allowing scholars, students, and citizens to understand their relevance for current issues. But before the arguments can be interpreted, they must first be found. As we demonstrate in this paper, available computational methods can strongly assist with that.</p>
<h2 id="exploring-arguments-in-the-digital-sphere-animal-minds-as-a-proxy-domain">Exploring Arguments in the Digital Sphere: Animal Minds as a Proxy Domain</h2>
<p>We focused on the early 20th Century debate about animal minds because, in the aftermath of Darwin’s revolutionary effect on biology, it was a particularly fertile arena for historically important arguments that were still poised between scientific and literary styles of writing, and also for the pragmatic reason that it fitted our prior expertise in psychology, ethology, and philosophy of cognitive science. The debate remains lively in academic circles more than a century since Washburn published her book, and it is, of course, important to the ongoing public debates about animal welfare and animal rights. A close reading of Washburn’s text reveals to a modern reader a mixture of familiar and unfamiliar arguments, many of which deserve revisiting today. Our work also led us to five other texts (described below), which present a similar mixture of the familiar and the unfamiliar. Anyone who engages closely with the arguments in these books learns much about the trajectory that psychology in the English-speaking world was on, and also comes to understand how current debates about animal minds are dependent on the paths laid down these earlier authors.</p>
<p>The late 19th century and early 20th century was a period of significant development for psychology that was characterised by important and competing arguments. Experimental methods were on the rise, and psychologists, who had often been housed in the same university department as the philosophers, were professionalising, forming their own associations and journals, and their own departments. Philosophy could be seen as retreating from the arguments based on experimental evidence increasingly favored by psychologists, while psychologists were wondering which of their received concepts and theories should be jettisoned, and which could form the basis of further empirical investigation. Such questions were particularly acute in animal comparative psychology. On the one hand, Darwin’s theory of evolution exerted a strong pull towards the idea of mental continuity between humans and animals. On the other hand, many Darwinians were seemingly content with anecdotal evidence of animal intelligence to make their case on analogical grounds to human behaviour, leading experimentally inclined psychologists to reject such anecdotes and analogies as anthropomorphic. Even as the disciplines of psychology and philosophy were formally disassociating themselves, philosophical arguments about the proper way to study animal psychology were becoming even more prominent among the psychologists themselves.</p>
<p>While comparative psychology in the immediate post-Darwin era was a particularly fertile era for the interplay between philosophy and science, the domain we selected is not special. It serves as a proxy for any domain where interpretation remains open and debate inevitably ensues. The lessons learned from our attempt to find and interpret text about anthropomorphism in comparative psychology generalise to other domains. There is no substitute for reading the relevant texts closely, but there is similarly no substitute for computational distant reading of such a massive repository as the Hathi Trust in order to select which texts are the best candidates for close reading and extraction of their arguments.</p>
<p>The skills involved in interpreting arguments are essential in supporting and developing critical thinking and writing skills – even, and especially, where digital media predominate (e.g., <a href="#wegerif2007">Wegerif, 2007</a>; <a href="#ravenscroft2008">Ravenscroft and McAlister, 2008</a>; <a href="#ravenscroft2010">Ravenscroft 2010</a>; <a href="#pilkington2016">Pilkington 2016</a>). The volume and variety of this digital sphere provides opportunities for thinking, learning and writing within and across educational, professional and civic contexts. Across these contexts the need to identify, understand, and critically compare arguments is particularly important today to counteract a discourse in which accusations of ‘fake news’ and appeals to emotion are used to promote simplistic, insufficiently contextualised arguments and propositions, often overriding well evidenced and supported positions on a subject. There is a pressing need to support and promote scholarly practices focused on identifying, understanding and comparing written arguments that can occur within texts in massive data or document repositories.</p>
<p>The availability of massive document collections transforms the scale and complexity of the tasks of searching for and interpreting arguments, but these collections hold out great potential for understanding the academic and broader cultural contexts in which these arguments were historically and are presently situated. A key inspiration for our approach was to help inexperienced scholars simulate the way an experienced or expert scholar moves from macro-level views of document collections to micro-level close reading and interpretation of the key arguments in particular texts.</p>
<p>Of course, there will always be ethical issues, linked to any sociological and political framing around decisions about which digital collections to focus on. For example, the extent to which these may or may not be not-for-profit and available to the public. In our case, we worked with the HathiTrust collection, because it is a consortium of mostly public state universities – spearheaded by Michigan, Illinois, and Indiana – who retain ownership of the scanned content, up to the limits of the applicable copyright laws, although Google supported work to accelerate the scanning of these materials. The original proof-of-concept tool-set that we are proposing and discussing in this article is aimed at gaining insights, both conceptual and technological, about finding and interpreting arguments in digital repositories of any kind in principle. Therefore this work is aiming to be relatively generic in its positioning around what repository to focus on, although for pragmatic reasons also, the HathiTrust was particularly suitable because project members, and one co-author (Allen), were working at Indiana University at the time of this project, which facilitated the cooperation with the HathiTrust Research Center.</p>
<h2 id="investigation-by-design">Investigation by Design</h2>
<p>Our approach was also inspired by prior work on the methodology of  “Investigation by Design”  by one of the present authors <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. This work was originally developed to model and simulate collaborative argumentation practices <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>  <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> leading to learning and conceptual development <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>  <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. A key idea behind this approach is that technology which effectively enhances scholarship and learning practices should balance existing practices with the technological possibilities for enhancing that practice. In other words, we should not try to fundamentally disrupt the way that people approach texts, but seek to amplify and enhance their processes and practices so as to support more powerful learning and scholarly interpretation across a wider variety of contexts. In our application the existing practice consists of skimming texts for arguments followed by close critical reading of them, and the technological enhancements are (1) topic modelling to improve the searching and (2) argument mapping to improve the identification, analysis and interpretation of the arguments. The semi-formal nature of the mapping tool used in the second component forced us to reflect on what is required of close critical reading during the analysis, construction and representation processes. Furthermore, we believe the level at which we have designed our approach satisfies what Edwards et al. (2007) refer to as  “below the level of the work” , i.e., a level where  “Neither the exact implementation of standards, nor their integration into local communities of practice, can ever be wholly anticipated”   <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> (<a href="#edwards2018">see also Edmond 2018</a>).</p>
<p>Consider the challenge facing learners and researchers confronted with massive, digitised document collections that are not readily browsable in the way that shelves of library books once were. For one thing, many of the books of interest have been physically shifted to deep storage facilities and must be called up one-by-one rather than whole shelves at a time. (<a href="#edmond2018">In a recent article, Jennifer Edmond (2018) laments the loss of serendipity this entails.</a>) For another, the digitised collection represented by the HathiTrust Digital Library is an order of magnitude larger than any single library collection, so what was one shelf may have become the digital equivalent of ten. When browsing shelves of physical books, readers might pull a book off the shelf, sample a few pages from the book, and decide whether to put it back or to check it out of the library for closer reading. In the digital library, that decision takes on a different character: on the one hand there is a sense in which we don’t have to put anything back as we can carry out macroscopic analyses of very large numbers of texts; on the other hand we must still make selections for the closer readings that provide valuable insights that are currently beyond the reach of algorithms.</p>
<p>It is our view that a tool that links searching of massive document collections to close critical reading of key arguments therein would have significant value across educational contexts. It could make the practices of experienced scholars more systematic, efficient and powerful. Perhaps more importantly, it could empower and support less experienced learners to engage in systematic critical thinking and reasoning linked to identifying and understanding arguments, which is a well-attested challenge throughout education (e.g., see <a href="#ravenscroft2007b">Ravenscroft et al., 2007</a>; <a href="#andrews2009">Andrews, 2009</a>; <a href="#ravenscroft2010">Ravenscroft 2010</a>). Although previous research has shown the value of argument mapping to support greater  “sense making”  and learning in general, this work has involved  “standalone”  mapping tools <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> that do not link the maps to the larger textual and intellectual context in which they arise.</p>
<p>At the time we conducted the work upon which we base our discussion here, public access to the HathiTrust Digital Library was restricted to the approximately 300,000 volumes outside copyright and in the public domain in the United States. The HathiTrust now provides non-consumptive access to over 17 million volumes (as of November 2019), increasing the challenge of identifying key texts from unreadable quantities of text for the purpose of close reading and argument extraction, making it even more important to develop techniques and tools such as those we discuss here. A primary challenge at this scale concerns how to identify and compare argumentation and arguments within and across texts, in a way that is analogous to the way a scholar works, moving from a macro-level view of texts to the close critical reading of particular arguments within and across texts. This work (whose technical details are reported by <a href="#mcalister2014">McAlister et al. 2014</a> and <a href="#murdock2017">Murdock et al. 2017</a>) represented the first time that topic modeling and argument mapping had been combined in a process that allowed a scholar to identify pages within texts that should be fed into the argument mapping task, both necessitating and supporting a close critical reading of those texts by the individual engaged in the process. This work, through ostensibly technical research combining Big Data searching and AI techniques, included a broader exploration of the possibilities for integrating science mapping and visualization, along with an initial attempt at argument extraction <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. In this paper we provide a detailed critical examination of the nature and form of arguments that were identified in the texts, and we consider the centrality of the interpreter and the interpretative processes in extracting these arguments given their historical and cultural contexts. This critical examination supports our wider reflections on the role of such technical methods in supporting the identification, interpretation and comparison of important historical arguments. These reflections provide the basis for our ‘bigger vision’ concerning the important challenge of understanding arguments via the digital humanities, and the broader implications for any field where identifying and interpreting digital arguments is important, or vital.</p>
<h2 id="searching-and-interpreting-as-a-pedagogical-practice-the-challenge-of-identifying-analysing-and-understanding-arguments-in-texts">Searching and interpreting as a pedagogical practice: The challenge of identifying, analysing and understanding arguments in texts</h2>
<p>Texts do not give up their meanings easily, and different branches of the humanities bring different interpretative strategies to bear on the very same texts. For instance, philosophy students and scholars seek to understand conceptual frameworks and arguments that are typically not fully explicit in the texts they study. History students and scholars studying the very same texts may seek different kinds of clues to assist in their interpretations, such as facts about the social and cultural milieu in which they were written, or the specific contacts and experiences that led to particular acts of authorship. Literature students and scholars may focus on narrative structure in those texts, and the extent to which a given piece of work follows or flaunts literary conventions.</p>
<p>When the goal is also to exploit large datasets in support of traditional humanities research and learning, it is necessary to answer the question of how computational methods might help these kinds of students and scholars alike. For instance, consider the history scholar or student who already knows the biographical details of a 19th Century author, but wants to understand the narrative or argumentative structure of specific passages in that author&rsquo;s work. Scientometric methods such as the analysis of co-author and citation networks <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>, and text mining methods such as named entity recognition <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> may provide hints about influences on a given author, but unless these are linked to more powerful tools for textual analysis and critical work, the role of these methods is limited to very early stages of investigation for scholars pursuing disciplinary research within the humanities. Likewise, while search engines may be useful for discovering and retrieving individual documents and even key passages, they do not help with the interpretative task of distinguishing between passages where an author is accepting a particular concept, making a particular argument, or following a particular convention, and passages where those concepts, arguments, and conventions are being attacked or rejected.</p>
<p>To serve scholars and their students well, it is necessary to develop techniques for deeper analysis of the texts they care about. Sophisticated quantitative analysis of the full contents of texts will be needed. But computational methods alone will not suffice. Progress towards more effective use of massive text repositories will require a combination of computational techniques, digital curation by experts, and a better understanding of the way texts are critically understood and used in scholarly practices. No single method alone holds the key. Researchers and students need to be able to engage with the texts and discuss them with peers. Students and interested amateurs can in turn benefit from the discussions among experts if those can be adequately summarised and represented. People participating in debates may benefit from being able quickly to locate sources, both ancient and modern, that support or controvert their positions. There are many open research questions here about the design of effective systems that can serve scholars, and facilitate the representation of their knowledge in ways that others, experts and non-experts alike, can make use of in their critical engagement with the texts.</p>
<h2 id="from-massive-document-repositories-to-argument-identification">From Massive Document Repositories to Argument Identification</h2>
<p>It is somewhat self-evident that massive document repositories offer access to an unparalleled number of texts across historical and disciplinary dimensions, opening up new possibilities for learning and scholarly activity. But, in practice, with so much choice about what to read, how do we decide which texts and parts of texts to focus on? And similarly, how can we focus on the key arguments within these texts to support the close reading and understanding of them? This is not just valuable in itself, it also counters the practice of reading texts in a fast, superficial and uncritical way, which is the temptation when we have access to such a massive quantity of text and information.</p>
<h2 id="why-topic-modelling-to-locate-arguments">Why topic modelling to locate arguments?</h2>
<p>Previous attempts at automated argument identification (e.g., <a href="#moens2007">Moens et al. 2007</a>) have focused on key words and phrases which may indicate the introduction of premises (for this reason, in virtue of, etc.) or conclusions (hence, therefore, etc.). However, given a) the enormous variety of such markers, b) the historically shifting patterns of usage, and c) how many arguments are presented without such markers, such approaches can have significant limitations. Even when enhanced to use grammatical structure <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> they face the additional weakness that that they do not capture the semantic content of arguments.</p>
<p>The set of documents accessible via the HathiTrust provide a robust test of our approach, as particular difficulties of understanding arguments from this historical era are: a) not all the content is congruent with the style of scientific thought and writing that we have come to expect in the modern era (e.g., the heavier reliance on anecdotal evidence in earlier times); b) the language used even in scientific publications is indirect, and verbose compared with its modern-day equivalent (e.g., there may be long digressions), and c) what passes for acceptable argument may well have been different in that era (e.g., the variety of rhetorical strategies). This problematisation contrasts significantly with other formal approaches to argument modeling, that have focused on articles with a modern, formulaic structure, e.g., in legal contexts <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> or in the context of modern scientific articles <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>  <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> where  “Introduction” ,  “Results” ,  “Conclusions”  etc., are explicitly identified. The type of texts we were interested in were historically and scientifically important, but written in a common and more natural style, so we were deliberately giving ourselves a hard problem, but one with high authenticity and relevance. The task of understanding, identifying and mapping arguments in these more free running social science or philosophical (and historical) texts could be considered an order of magnitude more challenging than previous work into argument mapping (e.g., <a href="#lawrence2012">Lawrence et al., 2012</a>; <a href="#kirschner2012">Kirschner et al., 2012</a>).</p>
<p>Most scholars are interested in arguments not simply for arguments’ sake, but because of the underlying topics and issues that are addressed in those arguments. Computational methods offer a variety of ways for capturing semantic relations in text. Some, such as Latent Semantic Analysis (LSA) <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> are good at capturing word-document relations, others are good at capturing word-word relationships (e.g., <a href="https://code.google.com/archive/p/word2vec/">Word2Vec</a>). For argument analysis, however, the right “chunks” for analysis are somewhere between words and whole documents. We chose to explore LDA (Latent Dirichlet Allocation) topic modelling <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> as a means to find appropriately-sized, content-rich sections of text within books, which could then be subjected to further scrutiny for argument analysis and mapping.  <em>So, our assumption was that the parts of texts that were rich in a particular topic would also be rich in the arguments that included that topic, and that assumption would be tested through our design and its application in the target domain.</em></p>
<p>LDA topic modelling (LDA-TM) is by now a familiar technique in the digital humanities. It uses machine learning to represent documents as mixtures of “topics” and these are represented as probability distributions of the words in the corpus on which the model is trained. The training process automatically assigns probabilities to the topic-document and word-topic distributions in such a way that a relatively small set of topics (set by the modeler via a hyperparameter K) can account for the word distributions found in a relatively much larger set of documents comprising the corpus. As such, then, topic models accomplish a form of data compression, enabling common themes to be identified within a large corpus. Appropriate selection of the hyperparameter K for the number of topics depends on various factors including the size of the corpus and the pragmatic goals of the scholars using the model. As described in more detail below, we explored several different values of K, and settled on a number of topics that served our goal of identifying passages of interest for our argumentative analysis and interpretation. Also described in more detail below is the process we followed to select among and within the books. We made a number of design choices which reflected our pragmatic aim of designing a prototype toolkit that could demonstrate proof of concept, rather than pursuing a systematic investigation of the space of all possible measures and methods.</p>
<p>Going beyond <a href="#murdock2017">the previous overview of our work by Murdock et al. (2017)</a>, here we focus in more detail on the pedagogical practice, through the link between the original drill-down topic modelling work and the nature, form and structure of the many arguments contained in these texts from the digital library. The detailed interpretation of the texts leading to semi-formal representation of the found arguments allow us, in this paper, to assess the importance and relevance of the discovered arguments, and to problematise the design space.</p>
<h2 id="topic-modeling-and-selection-of-texts">Topic Modeling and Selection of Texts</h2>
<p>Automated selection from large volume sets is necessary because one cannot hope to inspect by eye the whole collection. For example, although a standard keyword search in the HathiTrust collection, using Darwin,  comparative psychology, anthropomorphism, and parsimony, reduced over 300,000 public domain works to a list of 1,315 volumes, this many books is on the order of Charles Darwin’s entire personal library, accumulated and read over several decades. To help us to decide what to read? we chose to adapt topic modeling to our purposes. This technique is useful for information retrieval because it allows a higher level of semantic abstraction than keyword searching.</p>
<p>LDA topic modelling (LDA-TM) was first introduced by <a href="#blei2003">Blei et al., (2003)</a>, and it has been subsequently deployed in a variety of applications <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>  <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>  <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>, including applications in the humanities <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. A key innovation of our approach is that we adopted a multilevel approach to a scholarly workflow <sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. We first applied LDA-TM to these 1,315 volumes treating each book as a document. <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>  The resulting topic model was scanned by a person who selected thresholds on the topics<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>  to extract 86 volumes from the original 1,315, as those most closely related to our focus on anthropomorphism and animal minds. Amongst other advantages, the topic models allowed us to disambiguate discussions of anthropomorphism in the animal context from uses of the term in the context of comparative religion, allowing us to drill down efficiently to the most relevant materials. We then re-applied LDA-TM to these 86 volumes treating every page as a document. A further step of topic-model assisted selection rated books according to the number of pages containing a high density<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>  of the topics we were interested in. This yielded six books of central interest for our argument analysis. It was notable that none of these texts appeared in the first ten results of libraries standard keyword searching.</p>
<p>The six volumes selected by the methods described above each discuss our chosen topic of Animal Psychology:</p>
<p><em>The Animal Mind: A Text-Book of Comparative Psychology</em>  by Margaret Floy Washburn, 1908   <em>Comparative Studies: Psychology of Ants and of Higher Animals</em>  by Eric Wasmann, 1905   <em>The Principles of Heredity</em>  by G. Archdall Reid, 1906   <em>General Biology</em>  by James G. Needham, 1910   <em>The Nature &amp; Development of Animal Intelligence</em>  by Wesley Mills, 1898   <em>Progress of Science in the Century</em>  by J. Arthur Thomson, 1908</p>
<h2 id="selection-of-rated-pages-and-argument-maps">Selection of rated pages and argument maps</h2>
<p>We decided to adopt the visual argument mapping approach for a number of related reasons. Previous research has strongly supported the value of argument mapping for: greater  “sense-making”  of argumentative texts <sup id="fnref1:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>; providing standardized and comparable semi-formal and visual representations to support the investigation and analysis of arguments generally <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>; and, providing visual representations that could be rendered into a generic computational format, the Argument Interchange Format (AIF), <a href="#chesnevar2006">see Chesnevar et al. (2006)</a>, that can be re-used and shared between applications. In our case, this meant that the argument mapping approach that we adopted (see below) supported the close critical reading of the text selections through an argument lens and provided a standard representational scheme that could be applied across the different texts, showing the found arguments in each. Once mapped, these representations can be potentially re-used and shared in further argument inquiry or tool development. Further details of the mapping tool and process, and how it was used to interpret the texts and arguments that are specific to our study are provided below.</p>
<p>The rating of pages according to their loading on topics of interest was taken as an indicator of material worthy or argument analysis and mapping, but these were not used to limit arguments that started before or ended after the rated pages. Thus, each argument selected by the person doing the mapping spanned rated pages, but may also have spanned unrated bordering pages occasionally. Also, not all rated pages that dealt with the chosen topic contained argument. <a href="#table01">Table 1 (below)</a> shows the  <em>Pages</em>  that were selected from each  <em>Volume</em> , following our topic modelling approach, and also the number of  <em>Maps</em>  for each  <em>Volume</em> . This shows that the first three of the listed volumes, according to our topic modelling returns were potentially argument rich, with their arguments therein creating 15, 10 and 8 maps respectively. For  <em>The Animal Mind,</em>  which contained many more rated pages than listed in the table, we chose to limit our analysis to 40 pages constituting the largest blocks of contiguous pages containing pages with greater than 90% loading on the topics of interest.</p>
<p>The latter three in the list were potentially less rich in argument, creating 2, 5 and 3 maps respectively. This difference indicates the variability in writing style during this historical period, with some texts showing clearer lines of argument than others.  <em>General Biology</em>  is a textbook that follows a more didactic, less argumentative style, and differs from Washburn’s psychology textbook, in that the there is a less controversial set of accepted facts to present. The fifth text is based on predominantly personal observation, so, it is a piece of anecdotal comparative psychology, and not concerned with the methodological questions that lead to the argumentative structure of Washburn’s book. The final text has fewer arguments because it is a pop-science book and is more engaged in telling a triumphal narrative of scientific progress, rather than dealing with controversies in the field. It does have a section on animals that emphasises the discoveries that seem to show how intelligent they are, so it does not aim for the sort of complex analysis that is provided by Washburn. So, considering these findings lends support to our assumption that the topic rich texts according to our topic modeling method also approximate the degree to which the content is argument rich.<br>
Page lists of analysed pages from selected volumes    Volume  Maps  Pages       <em>The Animal Mind</em>   15  13-16, 16-21, 24-27, 28-31, 31-34, 58-64, 204-207, 288-294, total = 40 pages (original page numbering)       <em>The Psychology of Ants</em>   10  Preface, 15-19, 31-34, 48-53, 99-103, 108-112, 206-209, 209-214, total = 37 pages (renumbered; Original page numbering masked by a bug.)       <em>The Principles of Heredity</em>   8  374, 381, 382, 385, 386, 390, 394, 395, total 10 pages (renumbered)       <em>General Biology</em>   2  434-435, 436 total = 3 pages (original page numbering)       <em>The Nature &amp; Development of Animal Intelligence</em>   5  16-18, 21-26, 30-32 total = 12 pages (renumbered)       <em>Progress of Science</em>   3  479-484, total = 6 pages (renumbered)   <br>
The argument content was mapped using OVA+ <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> an application which links blocks of text using argument nodes. OVA+ (<a href="ova.arg-tech.org/">ova.arg-tech.org</a>) provides a drag-and-drop interface for analysing textual arguments that it is designed to work in an online environment, running as a HTML5 canvas application in a browser. This particular tool was chosen because it builds on the established work in argument diagraming and mapping referred to above <sup id="fnref1:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> and because it is also a widely used argument mapping tool that also incorporates and generates the standardised Argument Interchange Format (AIF) that has been used by many other projects in computational argumentation <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>. Using this tool each argument is divided into propositions and marked up as a set of text blocks. These text blocks containing propositions were linked to propositions that they support, or undercut, to create an argument map, such as the one below <a href="#figure01">(e.g., Figure 1)</a>.</p>




























<figure ><img loading="lazy" alt="" src="/dhqwords/vol/13/4/000436/resources/images/figure01.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/dhqwords/vol/13/4/000436/resources/images/figure01_hu0a0796abfccac4f2de4d802691a8f172_922368_500x0_resize_box_3.png 500w,
    /dhqwords/vol/13/4/000436/resources/images/figure01_hu0a0796abfccac4f2de4d802691a8f172_922368_800x0_resize_box_3.png 800w,/dhqwords/vol/13/4/000436/resources/images/figure01_hu0a0796abfccac4f2de4d802691a8f172_922368_1200x0_resize_box_3.png 1200w,/dhqwords/vol/13/4/000436/resources/images/figure01_hu0a0796abfccac4f2de4d802691a8f172_922368_1500x0_resize_box_3.png 1500w,/dhqwords/vol/13/4/000436/resources/images/figure01_hu0a0796abfccac4f2de4d802691a8f172_922368_1800x0_resize_box_3.png 1800w,/dhqwords/vol/13/4/000436/resources/images/figure01.png 2266w" 
     class="landscape"
     ><figcaption>
        <p>Argument Map of Argument 3 (Arg3) of <em>The Animal Mind</em> by Washburn (1908)
        </p>
    </figcaption>
</figure>
<h2 id="argument-interpretation-identification-analysis-and-mapping">Argument Interpretation: Identification, Analysis, and Mapping</h2>
<p>To identify the form and structure of the arguments contained in the selected texts we adapted a generic approach for manual argument analysis <a href="#lawrence2014">described by Lawrence et al. (2014)</a>. Through considering this work we developed a bespoke rubric that standardised and described the interpretative process that linked the analysis of our historical texts to the argument format of the mapping tool. This was informed by the members of the team with expertise in the humanities, who were familiar with the styles of writing about this topic for this historical period, and the researcher who was performing the mapping process. This was important in our case because, as mentioned earlier, the natural arguments contained in these texts, demanded more sophisticated interpretation compared with other applications where the arguments were more clearly defined. The full detail of this interpretative rubric can be accessed online <a href="https://bit.ly/35CshTD">https://bit.ly/35CshTD</a>. To summarise it for the purposes of this paper:</p>
<p><strong>Initial Reading:</strong>  Read through the selected text to get a broad-brush overview of the nature and meaning of the arguments in play   <strong>Argument Identification:</strong>  Mark beginnings and ends of major argumentative chunks (could span multiple pages) from where topic/conclusion is introduced to where it is concluded. This may be informed by linguistic identifiers (e.g., because, therefore, suggesting that etc.) where these are present   <strong>Argument Segmenting:</strong>  For each paragraph, select zero or more sentences or whole-clauses that best summarise the arguments in this text. Unless they also contribute to arguments made by the author of the text, do not select sentences or clauses from reports of arguments or other non-argumentative materials, e.g., background information. (Mark zero if the paragraph is entirely non-argumentative, e.g., descriptive or providing background context.)   <strong>Structuring:</strong>  Link the elements together with relations that show the direction of reasoning, from premise to conclusion, and whether premises are supporting or counter-argument (attack) relations   <strong>Mapping:</strong>  Transfer the highlighted sentences, text and their relations to OVA+ and review and interpret for accuracy and representativeness</p>
<p>Through interpreting and mapping the identified arguments in these texts the researcher produced the 47 OVA+ maps covering the selections from the six volumes, which can be viewed online<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> , with the maps sequentially numbered and linked to each volume. An example is included in <a href="#figure01">Figure 1.</a> It shows an argument from the first text, Argument 3 (Arg 3) from  <em>The Animal Mind</em> . The links drawn on the maps between propositions are of two types – supporting and counter-supporting (links labeled RA and CA respectively). Although OVA+ supports more link-types these were not used in this study. Instead we paid particular attention to interpreting the meaning and representing the sub-components of the argumentative text. Conclusions must be supported by at least one premise. Often the maps have sub-conclusions leading to main conclusions. Propositions that expand or explain other propositions are seen as lending support to them. A link connecting two propositions always links from one to another, with an arrow showing direction, where a supporting premise links to (points to) a conclusion or sub-conclusion.</p>
<p>The argument map (Arg 3) above contains text taken from  <em>The Animal Mind</em>  by Washburn (1908). The argument consists of 3 propositions (in the large boxes on the left) that support two related conclusions (in the large boxes on the right). The  “RA”  boxes contained in the directional arrows demonstrates that the propositions on the left (P1, P2, P3) support the conclusions on the right (P5, P6), where the latter are also interconnected, as indicated through pointing to a shared relation (an RA). In this example P2 and P3 combine to support the conclusion P4. The close reading of the content of this argument would emphasise Washburn’s sensitivity to the contrast between Descartes’ view and that of his predecessor Montaigne, and her emphasis on his use of the exquisite functioning of the behaviour of diverse species of animal as evidence for a sophisticated view of the relationship between consciousness and thought (one that is often obscured in current presentations of Descartes’ views on animal minds) along with her sensitivity to the shifting meanings of these terms over the centuries. How this particular argument fits into the more extensive close reading of the arguments is covered in the next section.</p>
<p>This approach was particularly appropriate for the volumes that we analysed, where, in some cases, the same topic is pursued for a complete chapter and so there are opportunities to map the extended argument. Given the way the arguments were differentially expressed, with some text being more easily mapped compared to others, the mapping process was quite sophisticated, yet followed the standardised rubric to maintain consistency of interpretation.</p>
<h2 id="interpreting-identified-arguments-to-support-better-understanding-and-learning">Interpreting identified arguments to support better understanding and learning</h2>
<p>This deep identification, representation and interpretation process linked to the subsequent argument maps, including careful reading of the identified texts provided a double lens onto the arguments that provided a stronger interpretative platform than if these methods had not been applied. The identification, representation and mapping process was performed by a researcher who was familiar with the basics of argument mapping, who was neither a domain expert in comparative psychology nor experienced with extracting arguments from this kind of textual material.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>  Below we describe his interpretations. In the descriptions below, for accuracy and evidence, we refer to the argument maps that the descriptions refer to that are accessible online (see footnote 4), as there isn’t the space to display them in this article. The importance and level of scholarly merit and detail of these argument interpretations is the test of our approach. In particular, we were interested in whether a researcher who knew nothing about the domain could be supported through sophisticated and deep reading of the arguments when guided by the topic models and the argument mapping process. A sample and summary of the subsequent close readings and argument descriptions of the first two volumes, which generated the most maps (15 and 10 respectively), are given below for the purposes of this paper. And these descriptions are then followed by a summary of the interpretations across the texts to demonstrate how the arguments in the individual texts could be considered collectively to improve the understanding of the topic (of Animal Psychology) in general. The full close readings of the 47 Maps linked to the six volumes is given in <a href="#mcalister2014">McAlister et al. (2014)</a>.The descriptions below have been paraphrased and condensed from the original, with material enclosed by square brackets representing additional qualifying comments introduced by the present authors.</p>
<h2 id="volume-1-analysis---_the-animal-mind_--1908">Volume 1 analysis –  <em>The Animal Mind</em> , 1908</h2>
<p>[In this first edition of her textbook, destined for four editions] Washburn sets the context for the debate on animal consciousness. She meets the charge that animal psychology is necessarily anthropomorphic straight away, and admits there is a problem (Arg1). She introduces Montaigne’s arguments for animal intelligence based upon the similarity of human and animal behaviours (Arg2) and follows with Descartes’s opposing argument, that animals are clock-like machines, with no capacity for thought (Arg3). Washburn next presents Darwin as arguing on the basis of analogical claims, such as that animals reason because they are  “seen to pause, deliberate and resolve” . She asserts that Darwin&rsquo;s aim of defending his theory of evolution in face of ongoing controversy about the mental and moral gulf between man and animals, means that his claims cannot be taken at face value (Arg4). In contrast many physiologists argue that psychic interpretations are less preferable than biological explanations of animal behaviour in terms such as tropism [unconscious reaction to stimulation] (Arg5).</p>
<p>Washburn next summarises three main anti-mentalist camps or positions in the field (Arg6). She criticises the physiologists, the first camp, for ignoring or simplifying phenomena to fit a predetermined theory, and she argues that their approach yields a reductio ad absurdum when applied to human behaviour (Arg7). Washburn outlines the arguments of ant expert Erich Wasmann [see next section], representing the second camp. Wasmann’s definition of intelligence explicitly excludes animals on the grounds that they act only on instinct. He readily generalises from ants to all animals, stating that ants are superior to other animals (Arg8). The third camp is represented by Bethe [who belongs to an ultra-Cartesian group], holding that animals lack even sensation. Washburn identifies an inconsistency between his acknowledging that modifiability of behaviour is an indicator of consciousness, while considering this improper if applied to animals. He condemns all psychology as subjective and unknowable, and asserts that only chemical and physiological processes should be the object of scientific investigation (Arg9 and Arg10).</p>
<p>Washburn argues for a cautious approach to animal psychology, acknowledging pitfalls and problems but seeking scientific methods to overcome them (Arg11). She introduces Lloyd Morgan’s [famous] Canon whereby the simplest level of psychic faculty for an animal should be assumed that can fully explain the facts of a case. She argues that the choice may not always be the right one, but at least it reduces anthropomorphism by compensating for a known bias (Arg12). Washburn next argues against Loeb’s suggestion that  “learning by experience”  is a conclusive criterion for mind, but cautions that absence of proof does not amount to disproof. She maintains that rapid learning practically assures mind, but holds that great uncertainty remains about consciousness in lower animals (Arg13 and Arg14). Morphology and similarity of animals’ physiology to humans’ must be taken into account in deciding if an animal is conscious or not, and degrees of similarity indicate a gradation of consciousness, from lower to higher animals, with no possibility of drawing a sharp line between animals with and without consciousness (Arg15) <sup id="fnref1:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>.</p>
<h2 id="volume-2-analysis---psychology-of-ants-1905">Volume 2 analysis - Psychology of Ants, 1905</h2>
<p>[Eric Wasmann was a Jesuit priest and naturalist, publicly renowned for his books about the variety of amazing ant behaviours.] Wasmann’s concept that “intelligence is a spiritual power” leads him to the claim that if animals had this spiritual power “they would necessarily be capable of language”. Animals don’t speak, so animals don’t have intelligence (Arg1). He supports his views of ants by reference to observations made by Aristotle, Stagirite, St Augustine, [and Wasmann’s contemporary naturalist] Dubois-Reymond (Arg3). Wasmann denigrates suggestions by ‘modern sociologists’ that ant “states” and human republics can be equated, explaining that class differences arise from ‘conditions of life’ or ‘intelligent’ free choice in Man, but ant castes arise from organic laws of polymorphism [multiple body forms] (Arg4). Wasmann asserts animal intelligence is really sensile cognition and sensuous experience, but if higher animals are credited with intelligence, it would be inconsistent to deny ants the same (Arg5). He argues that ants achieve a more perfect level of social cooperation than even the higher vertebrates, such as apes (Arg7).</p>
<p>Wasmann criticises Darwin for his anthropomorphic stance towards the ‘silence and obedience’ of a group of baboons, which Wasmann reinterprets as ‘fidelity and obedience’, and takes to imply ‘reasonable, voluntary subjection to the demands of duty and authority’. He argues that the more likely explanation is “the instinctive association of certain sensile perceptions with certain sensile impulses” (Arg6). This association removes the need to allow animals thought; instead, instinct is a sufficient explanation (Arg10). The author explains that instinct has two elements, ‘automatism’ of behaviour (generally found in lower orders of animals) and ‘plasticity’ of behaviour (generally found in higher orders). Because the architecture of ants’ nests varies from species to species even when the physical attributes of the ants are highly similar, he argues that a simple explanation of the variety of architecture linked to physical attributes will not do; rather the decisive factor is the psychic disposition of the ant species (Arg8). Wasmann maintains that while ants ‘verge on heroic unselfishness’ towards their young, only ‘Man’ is conscious of duty and the morals of parental love. Although he admits that some aspects of motherly love in humans are instinctual, motherly love cannot be attributed to animals because it is ‘spiritual’, based on awareness of duty that is unique to humans (Arg9). <sup id="fnref2:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></p>
<h2 id="summary-of-interpretation-of-arguments-across-six-volumes">Summary of interpretation of arguments across six volumes</h2>
<p>The section above demonstrates a sophisticated close reading of a sample of the arguments in the two selected texts, through incorporating the mapping approach into the interpretation process. For example, the comparison and contrast afforded by Washburn’s survey of the arguments in the literature and her attempt to articulate a good scientific methodology for comparative psychology. This contrasts with Wasmann’s more polemical and theological approach to the perfection of behaviour through instinct, which reveals that despite Darwin’s work, published nearly 50 years earlier, much of the controversy revolves around whether humans have a special, perhaps God-given position, separate from the animal world.</p>
<p>A number of historically important themes emerged from <a href="#mcalister2014">the interpretation of the arguments in the six volumes that are given in full in McAlister et al., (2014)</a>. These demonstrated the ability of our selection and argument mapping methods to allow a reader, who was previously unfamiliar with the scholarship in this area, to zero in on the relevant passages and then acquire an understanding of the key themes, which is a measure of the success of those methods. Although it was not a primary goal of our project to produce new insights into the domain-specific content, these would somewhat hopefully and inevitably emerge from the close critical reading of the key arguments. So it is worth making some concise, content-specific remarks here about two of the themes that emerged from the six volumes, to demonstrate the potential value of the proposed approach.</p>
<p>(i)  <em>Animal Flexibility</em> . All the authors, evolutionists and non-evolutionists alike, were willing to recognise hitherto unacknowledged flexibility and variability in behaviour of individual animals. They all identify the same extremes – excessive anthropomorphism on the one hand, and the conception of animals as automatic reflex machines on the other – but each claims the middle ground for their quite different positions! Even Wasmann, the lone anti-evolutionist in our sample, denies that individual ants are reflex machines, claiming that the flexibility of individual ants is of a  “psychic variety”  not  “mechanical automatism” , although he attributes this flexibility to  “instinct”  not reason.</p>
<p>(ii)  <em>Developmental Approaches</em> . Three of the authors, <a href="#mills1888">Mills (1888)</a>, <a href="#reid1906">Reid (1906)</a>, and <a href="#needham1910">Needham (1910)</a>, explicitly advocate a developmental approach to the study of animal mind, operating within the framework of a strong nature-environment distinction (corresponding to today’s  “nature-nurture”  distinction). They make the case for comparative developmental studies, particularly experimentally rearing animals in isolation.</p>
<p>Although the accounts (above) of the interpretation of the arguments are relatively concise, they demonstrate a successful close reading of the arguments located within the selected texts. And while the themes discovered should be compared with scholarly treatments of the same <a href="#richards1987">(e.g., Richards, 1987)</a>, nevertheless we believe that despite the variations in language (vocabulary and style), the crisscrossing overlap among the arguments discovered in these books indicates that our methods identified pages that were thematically relevant to tracking the scientific and philosophical debates about anthropomorphic attributions to animals in the late 19th and early 20th centuries. This provides confidence in our claim that the big-data analytic technique of topic modeling, linked to argument mapping, can support close reading of texts in a content-relevant, argument-guided way.</p>
<h2 id="discussion">Discussion</h2>
<p>The approach described in this article offers an initial prototype of a design for scholarly interaction with technology that begins with topic model-assisted search of massive document repositories and leads to close critical reading of the arguments in the texts therein. It has also produced important insights about the way these arguments are rendered and interpreted by a person new to such historical texts and work in the humanities. The automated content selection and categorization work described in this article demonstrated the feasibility and reliability of large-scale, fined-grained topic-based categorization across a range of topics in science and philosophy using documents defined at a variety of scales (whole books, book pages, and individual sentences in books). Categorization and selection are essential first-steps in the scholarly process of identifying further structures, such as arguments, in large data sets. Although it might have been possible to construct more sophisticated keyword searches using Boolean operators to identify the same pages of interest for our analysis, this would have required painstaking trial and error, whereas the topic modeling provided a relatively straightforward semi-automatic approach to narrowing down. A number of insights emerged from performing the human interpretation of texts that were delivered by our topic modeling techniques and then mapped in argumentative terms through the argument-mapping tool OVA+.</p>
<p>Topic modeling was clearly successful in identifying the texts (chapters and pages) that contained the ‘stuff’ of arguments linked to the keywords and topics that were searched for, strongly supporting our assumption that we could approximate topic rich texts as also being argument rich. These could be sorted through rankings that allowed just the topic rich texts to be the focus of further analysis. This is very valuable in itself, as it allowed us to identify and extract 6 argument rich texts from a big data text repository ( <em>HathiTrust</em> ). Secondly the (human) argument identification and analysis produced 47 argument maps (in OVA+), that provided interpretations from six volumes, that also showed how the type and degree of argument in historical texts can be quite different, with the different texts producing different amounts of argument maps (ranging from fifteen to two). So, the quantitative and qualitative methodologies that we developed also enabled us to represent and distinguish different levels of argument within texts in a broad-brush way. The outcome is a set of powerful descriptive and comparative interpretations of arguments within and across texts, and linked to particular authors <a href="#mcalister2014">(see McAlister et al., 2014 for a full account)</a>.</p>
<p>Furthermore, we were able to leverage the human-constructed argument maps against a micro-level topic model trained on a single book with each sentence treated as a document. Such an approach to Washburn’s  _The Animal Mind _  led us from sentences represented in the maps to sentences in other parts of the book that were judged similar within the model and despite being wholly disjoint in vocabulary, including the  “angry”  wasp. Close reading was essential to determine why certain sentences were selected by this method. For example, the relevance to anthropomorphism of the sentence,  “This, of course, does not refer to the power to judge distance,”  was not immediately evident. The context of this sentence in Washburn’s footnote on p.238 is as follows:</p>
<blockquote>
<p>Porter observed that the distance at which spiders of the genera Argiope and Epeira could apparently see objects was increased six or eight times if the spider was previously disturbed by shaking her web. This, of course, does not refer to the power to  <em>judge</em>  distance.<br>
<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> [Italics in original.] Here, then, we see Washburn cautioning the reader not to jump to a high-level interpretation of the spider behaviour. The spiders may perceive objects at various distances but they don’t judge it, where judgement is understood to be a high-level cognitive capacity. This belongs to a more elaborate argument against anthropomorphically over-interpreting the behavior of species remote from humans.</p>
</blockquote>
<p>To summarise, here are five key points from this study:</p>
<p>We have demonstrated that topic modelling finds topic-rich text that is also potentially argument rich and worthy of careful argumentative analysis.  Mapping these topic-rich regions of historical texts using a computerised mapping tool (OVA+) and a suitable rubric supports, and necessitates, close critical reading of the arguments and the texts.  The argument mapping was often a complex process, needing interpretation and sometimes gap filling by the mapper, but this was cognitively valuable in supporting argument identification, representation and understanding linked to close critical reading. Some types of argument, e.g., historical arguments, are not simply latent and waiting for identification and representation. Rather, the arguments come alive through interpretation and the processes of mapping and then writing about them.  The exercise of mapping the arguments required critical reading by the non-expert. It manifestly contributed to his deeper understanding of the arguments and their scientific and philosophical contexts than simply reading the books alone without the scaffolding we provided. This is evidenced by his accounts covering all the found arguments and the summary and comparison of all of these <a href="#mcalister2014">(see also McAlister et al., 2014)</a>.  Further development of this approach should accept points 1-4 above, and emphasise support for the process of understanding, representing and refining argument representations and related conceptualizations. This means those who design such tools should focus more on the cognitive processes of actively reconstructing arguments from complex texts, rather than assuming that arguments might simply be identified and extracted from a frame provided by grammatical and terminological markers of arguments.</p>
<h2 id="critique-and-further-work">Critique and Further Work</h2>
<p>Our emphasis on investigating and testing the feasibility of our computational tools to support existing scholarly practices of identifying and understanding arguments in digitised texts has meant that thus far we have deliberately prioritised validating technical possibilities over systematic empirical testing with different texts and/or different scholars. This suggests the need for further research that would incorporate technical and empirical strands into the development of the human-computer interaction.</p>
<p>The technical implications are that the next tool-set, should more closely connect the topic modelling to the argument mapping. Robust tools for topic modeling already exist in the form of  <em>MALLET</em>   <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> and the  <em>InPhO Topic Explorer</em>   <sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>. The latter is also well integrated with the  <em>HathiTrust Digital Library</em>  so that now even copyrighted materials may be modeled (<a href="http://inpho.github.io/topic-explorer/htrc.html">http://inpho.github.io/topic-explorer/htrc.html</a>). However, these tools need to be better integrated with tools for visually structuring argument maps such as OVA+ so that the scholarly work potentially enhanced by these tools becomes more seamless. The system should scaffold the interpretation process from identified texts to argument mapping, as this reasoning and re-representation process is cognitively valuable in achieving better understanding of arguments. Similarly, once the text is identified and the related maps are produced, other scaffolding or visualization techniques could assist coordinating between these two related representations of argument, and among the different representations produced by learners having diverse interests and goals. In this respect, further work could draw upon the large body of work into the use of external representations for learning <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>.</p>
<p>Once a more integrated and user-friendly version of the toolkit is developed, it would support more systematic empirical investigation of the interaction between user and machine. Our hypotheses are that compared to unassisted argument identification and understanding, this approach would: find the argumentative parts of relevant texts much faster and with greater accuracy; scaffold deeper understanding; and, provide flexible and permanent representations that could be reflected upon, extended and re-used. Further and more generally, future work will accept the need to move towards an environment for constructing and developing representations of argument rather than simply mapping them.</p>
<p>The above appears a sensible conceptualization for future work, because through implementing our methods it became apparent that arguments were rarely neatly and clearly structured and defined explicitly in the texts. The historical distance to these texts, and the shift in academic writing styles over the past century served to make the task of extracting the arguments even more challenging. Indeed, rather than being set structures transmitted through the texts, instead these arguments came alive through the practice of interpreting, understanding and (re)constructing them. This raises the questions, Do arguments actually exist in clearly defined forms within (certain) texts? Or, do arguments only take form when readers focus on understanding them? When today’s reader encounters the seemingly verbose yet strangely enthymematic nature of yesterday’s arguments, what can we learn about the interaction between readers and texts, and about the minds of the authors and their original readers?</p>
<p>While these questions are too big to be answered by our original study, their potential validity as important questions are, we argue, supported. The notion that textual arguments are constructed through human interpretation is also supported by the observation that argument structure is notoriously difficult for people, even after training, to determine (see <a href="#oppenheimer2011">Oppenheimer &amp; Zalta 2011</a>, <a href="#oppenheimer2017">2017</a> and <a href="#garbacz2012">Garbacz 2012</a> for an interesting example of disagreement among experts about how to formalise Anselm’s famous ontological argument in way that is adequate for computational validation). Of course, this should come as no surprise when even textbooks of argument analysis disagree with one another on the simplest of real-world examples. Yet the goal of using texts to construct arguments that satisfy disciplinary canons of interpretation of those texts defines an important scholarly activity. The abstraction provided by such efforts provides a regulative ideal that aids comprehension of difficult texts, and the representation of these abstractions in artifacts such as argument maps provides concrete targets for collaborative meaning making and deeper discussions about alternative interpretations of complex texts. The skill of generating such maps and interrogating their meanings is a legitimate aspect of mental agility and perspective taking, supporting a more sophisticated view of knowledge. The development of these skills, and the tools that support them, is essential for informed citizenship, particularly in our contemporary social media milieu.</p>
<p>Design investigations such as the one we have described here must remain mindful of the reconstructive nature of argument extraction.<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>  Despite the claims of some A.I. proponents, computer scientists seem a long way from being able to design algorithms that match the interpretive skills and subtlety of human readers. Nevertheless, we believe we have supplied one proof of the concept that machine learning applied to big data sets can support this essential aspect of human scholarship by supplying tools for both discovery and representation of specific arguments in a specific content domain. And if we now return to the broad context of critical reading and writing in which our research is placed, we argue that we have made significant technical and conceptual steps in moving towards tools that could enhance and empower this process for learners and scholars alike. This is particularly important in our contemporary digital landscape, where there is arguably an increasing need within the academy and without, to identify and understand reasoned and evidenced argument, to combat, for example, just simply agreeing or disagreeing, or liking, or not, simple emotive propositions and arguments.</p>
<p>In the application of digital tools to the humanities, we must also be mindful that high-sounding rhetoric about civic engagement, the democratization of scholarship, etc., can be undermined by the facts surrounding the choice of sources and limitations of access to the materials analysed. In our case, because of the association between HathiTrust and Google Books, some may worry (incorrectly in our estimation) that, despite its origins and continuation in publicly-funded universities, the HathiTrust nevertheless represents the sort of corporatisation of higher education that some find undesirable. Whereas we accept that there will always be challenging issues concerning which repositories to focus on, from a scholarly practice perspective our position is clear. We want to improve and democratize the scholarly practice of finding and interpreting arguments, so that argumentative and critical meaning making is potentially more inclusive, in addition to supporting deeper inquiry for those who are already engaging in such practice.</p>
<h2 id="conclusions">Conclusions</h2>
<p>The research described in this article tackled a complex problem of how to investigate and design a technological platform that empowers and supports, or scaffolds, humanistic practices guiding a non-expert to perform the kind of search, argument identification, and interpretation of an experienced or expert scholar. We investigated this within our approach through using ‘drill-down’ topic modelling to move from macro-level views of a big data document repository, through identifying the main areas of interest in specific texts, then subjecting these areas to close critical reading through semi-formal argument identification, analysis and interpretation. We were also able to show how, with the argument analyses in hand, a further drill down to topic models at the sentence level of individual books could help identify content that had not been originally selected. This investigation has also provided insights into the nature, form and structure of arguments in historical texts, and how these features can be difficult to neatly isolate and also be variable, and require the human to fit the pieces together. This work provides an important problematisation of the design space for future tool development that should arguably focus, not on automatically extracting arguments, but instead focus on how to better interrogate, manipulate and understand them: a practice that has increasing importance and relevance within and without the academy.</p>
<p>Edmond notes that the digital tools currently available to humanists, focused as they are on text, do not fully reflect the much broader information gathering practices of humanists, which, in her phrase, remain  “stubbornly multimodal”   <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>. She argues that a certain kind of productive distraction, following leads where they may, is essential to scholarly creativity in the humanities. With respect to staying ensconced in the world of (digitised) text we are guilty as charged, unfortunately unimodal. The digital library is our easily-accessed tree, even if we would push digital humanist towards higher-hanging fruit. But we would argue that the approach we have outlined addresses some of the problems she outlines that arise from changes in the way libraries are organised in this era of digitised texts and catalogues. While we agree that  “remote storage and electronic catalogues diminish the likelihood for serendipity”  for reasons we already mention, we believe we have outlined a digital research environment for argument-based analysis in which serendipity arises. Following the traces provided by topic models led to sampling a few books in more detail, and then to the wasps, spiders, and amoebae that occupied the thoughts of comparative psychologists a century ago: creatures that have all re-emerged in the 21st century in discussions of non-human forms of cognition. The selections were assisted but not forced, allowing the individual scholar to follow whatever leads looked promising in light of whatever background information the scholar has gleaned from other sources. Guided serendipity resulted, and thus the  “angry”  wasp was found.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>The research reported in this article derives from a project that was funded by the 2011 International Digging into Data Challenge. The project, entitled  “Digging by Debating: Linking Massive Data Sets to Specific Arguments” , was co-funded in the UK by Jisc, the Economic and Social Research Council (ESRC), and the Arts and Humanities Research Council (AHRC), and in the US by the National Endowment for Humanities (NEH); the project title serves as the UK grant ID and the NEH grant ID is HJ-50092-12. The authors would like to acknowledge the work and intellectual contributions of the other co-PIs to this project, the Digging by Debating team — Katy Börner, David Bourget, and Chris Reed — and the various contributions of the staff and students who worked on the project: John Lawrence, Robert Light, Simon McAlister, Jaimie Murdock, Jun Otsuka, Robert Rose, and Doori Rose (listed alphabetically). David Bourget and Colin Allen jointly developed the text-to-OVA+ argument mapping rubric with feedback from Simon McAlister. We are particularly grateful to Simon for his work on carrying out the argument mapping process itself. We are grateful, too, for the comments by an anonymous referee, who encouraged us to think more broadly about the political and ethical contexts of our work.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Allen, Colin, Hongliang Luo, Jaimie Murdock, Jianghuai Pu, Xioahong Wang, Yanjie Zhai, Kun Zhao.  “Topic Modeling the Hàn diăn Ancient Classics” .  <em>Cultural Analytics</em>  (October 2017). DOI: <a href="http://culturalanalytics.org/2017/10/topic-modeling-the-han-dian-ancient-classics-%E6%B1%89%E5%85%B8%E5%8F%A4%E7%B1%8D/"> 10.22148/16.016</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Murdock, Jaimie, Colin Allen, Katy Börner, Robert Light, Simon McAlister, Andrew Ravenscroft, Robert Rose, Doori Rose, Jun Otsuka, David Bourget, John Lawrence, and Christopher Reed.  “Multi-level computational methods for interdisciplinary research in the HathiTrust Digital Library” .  <em>PLoS ONE</em>  12.9 (2017): e0184188. Accessible at: <a href="https://doi.org/10.1371/journal.pone.0184188">https://doi.org/10.1371/journal.pone.0184188</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Lawrence, John, Christopher Reed, Colin Allen, Simon McAlister, Andrew Ravenscroft.  “Mining Arguments From 19th Century Philosophical Texts Using Topic Based Modelling” .  <em>Proceedings of the First Workshop on Argumentation Mining</em> . Baltimore, Maryland: Association for Computational Linguistics (2014): 79–87.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Ravenscroft, A. and R.M. Pilkington.  “Investigation by Design: Developing Dialogue Models to Support Reasoning and Conceptual Change” .  <em>International Journal of Artificial Intelligence in Education</em> , Special Issue on Analysing Educational Dialogue Interaction: From Analysis to Models that Support Learning. 11.1 (2000): 273-298.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>McAlister, S., A. Ravenscroft, and E. Scanlon.  “Combining interaction and context design to support collaborative argumentation using a tool for synchronous CMC” .  <em>Journal of Computer Assisted Learning</em> , Special Issue: Developing dialogue for learning 20.3 (2004): 194-204.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Ravenscroft, A.  “Promoting Thinking and Conceptual Change with Digital Dialogue Games” .  <em>Journal of Computer Assisted Learning</em>  23.6 (2007): 453-465.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Ravenscroft, A. and J.R. Hartley. (1999).  “Learning as Knowledge Refinement: Designing a Dialectical Pedagogy for Conceptual Change” .  <em>Frontiers in Artificial Intelligence and Applications Volume 50, Artificial Intelligence in Education. Open Learning Environments: New Computational Technologies to Support Learning, Exploration and Collaboration</em> , Lajoie, S. &amp; Vivet, M. (eds.), IOS Press (1999): 155-162.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Ravenscroft A.  “Designing Argumentation for Conceptual Development” .  <em>Computers &amp; Education</em> , 34 (2000): 241-255.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Edwards, Paul N., Cory P. Knobel, Steven J. Jackson, and Geoffrey C. Bowker.  “Understanding Infrastructure: Dynamics, Tensions, and Design”  (2007). Accessible at: <a href="http://hdl.handle.net/2027.42/49353">http://hdl.handle.net/2027.42/49353</a>. Accessed December 27, 2018.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Kirschner, P.A, S.J. Buckingham-Shum, and C.A. Carr.  <em>Visualising argumentation: Software tools for collaborative and educational sense-making</em> . Springer (2012).&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>McAlister, Simon, Colin Allen, Andrew Ravenscroft, Christopher Reed, David Bourget, John Lawrence, Katy Börner, Robert Light.  “From Big Data to Argument Analysis and Automated Extraction” . Final Report and Research White paper. Digging into Data Phase 2 (2014). [Programme/Project deposit], <a href="http://repository.jisc.ac.uk/5607/">http://repository.jisc.ac.uk/5607/</a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Shiffrin, R.M. and K. Börner. (2004)  “Mapping knowledge domains” .  <em>Proceedings of the National Academy of Science</em> s, 101 (suppl. 1): 5183-5185 (2004).&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Nadeau, D. and Satoshi Sekine.  “A survey of named entity recognition and classification” .  <em>Lingvisticæ Investigationes</em>  30 (2007): 3-26.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>Palau, R.M. and M.F. Moens.  “Argumentation Mining: The Detection, Classification and Structure of Arguments in Text” .  <em>Proceedings of the 12th International Conference on Artificial Intelligence and Law (ICAIL 2009)</em> , Barcelona, Spain (June 2009): 98-107.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Moens, M.F., E. Boiy, R. Palau, and Christopher Reed.  “Automatic Detection of Arguments in Legal Texts” .  <em>Proceedings of the 11th International Conference on Artificial Intelligence and Law</em> , ACM (2007): 225-230.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>Teufel, Simone and Min-Yen Kan.  “Robust Argumentative Zoning for Sensemaking in Scholarly Documents” .  <em>Advanced Technologies for Digital Libraries</em> . Springer (2009): 154-170.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Merity, S., T. Murphy, and J. R. Curran.  “Accurate Argumentative Zoning with Maximum Entropy models” .  <em>Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries</em> , ACL-IJCNLP (2009): 19-26.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Landauer, T.K. and Susan T. Dumais. A Solution to Plato&rsquo;s Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.  <em>Psychological Review</em>  104 (1997): 211-240.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p>Blei, David, Andrew Ng, and Michael Jordan.  “Latent Dirichlet Allocation” .   <em>Journal of Machine Learning Research</em>  3 (January 2003): 993–1022.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Wei, Xing and W. Croft.  “LDA-based document models for ad-hoc retrieval” .  <em>Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &lsquo;06)</em> . ACM (2006): 178-185. DOI: <a href="http://dx.doi.org/10.1145/1148170">http://dx.doi.org/10.1145/1148170</a>.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Heinrich, G.  “A generic approach to topic models” ,  <em>Proceedings ECML/PKDD</em>  (September 2009). Accessible at: <a href="http://www.arbylon.net/publications/mixnet-gibbs.pdf"> http://www.arbylon.net/publications/mixnet-gibbs.pdf</a>.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Medlar, A. and D. Glowacka.  “Using Topic Models to Assess Document Relevance in Exploratory Search, User Studies” .  <em>Proceedings of Conference on Human Information Interaction and Retrieval (CHIIR)</em>  New York, USA (2017).&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Tangherlini, T. R. and P. Leonard.  “Trawling in the Sea of the Great Unread: Sub-corpus topic modelling and Humanities research” .  <em>Poetics</em>  41.6 (2013): 725-749.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>The results of this step of the topic modeling can be explored at <a href="https://www.hypershelf.org/htrc1315/">https://www.hypershelf.org/htrc1315/</a>. All models were built using the InPhO project’s Topic Explorer open source package <sup id="fnref1:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> available for download at <a href="https://github.com/inpho/topic-explorer/README.md">https://github.com/inpho/topic-explorer/README.md</a>.&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>We took a naïve approach to this, simply using the proportions of the documents assigned by the model to the topics of interest, and then choosing a threshold on the proportions that seemed to the person making the choice to be sufficient to capture the books relevant to comparative psychology (along with many irrelevant ones; i.e., we preferred recall over precision at this stage). <a href="#murdock2017">See Murdock et al., (2017) for details.</a>&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>At this stage we preferred precision over recall. We again used a naïve approach, taking the mathematically expedient approach of summing the proportions across all pages and choosing an arbitrary threshold on the sums. Future work should explore more sophisticated information theoretic measures of relevance.&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>Reed, C., D. Walton, and F. Macagno.  “Argument diagramming in logic, law and artificial intelligence” .  <em>The Knowledge Engineering Review</em> , 22.1 (2007): 87–10.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Janier, M., John Lawrence, and Christopher Reed.  “OVA+: an Argument Analysis Interface” .  <em>Proceedings of 6th International Conference on Computational Models of Argument (COMMA 2014)</em> , IOS Press (2014): 463-466.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>Lawrence, John, F. Bex, Christopher Reed, and M. Snaith.  “AIFdb: Infrastructure for the Argument Web” .  “Proceedings of the 4th International Conference on Computational Models of Argument (COMMA 2012)” , IOS Press (2012): 515-6.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Online link (<a href="http://bit.ly/1bwJwF9">http://bit.ly/1bwJwF9</a>) to volumeData on Google Drive (view only). Open volume folder, open the pass subfolder, select a PNG image and see a Preview pane – click the blue OPEN button. A new tab will open – click button 100% to zoom. Move around by dragging the diagram.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>The depth of analysis we were seeking in this study would not have been feasible with a multi-user study, hence we focused on the pathway of one individual towards the process of extracting arguments as scaffolded by the available technologies.&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Washburn, Margaret Floy.  <em>The Animal Mind: A Textbook of Comparative Psychology</em> . The Macmillan company (1908).&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>McCallum, A.K.  <em>MALLET: A Machine Learning for Language Toolkit</em>  (2002). Accessible at: <a href="http://mallet.cs.umass.edu">http://mallet.cs.umass.edu</a>.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>Murdock, Jaimie and Colin Allen.  “Visualization Techniques for Topic Model Checking” .   <em>Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI-15)</em> . Austin, Texas (January 2015).&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Ainsworth, S.  “DeFT: A conceptual framework for considering learning with multiple representations” .  <em>Learning and Instruction</em>  16.3 (2006): 183-198.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Although we have argued that ‘extraction’ is the wrong metaphor, we recognise that the term ‘argument extraction’ is likely to continue to be used for the actual constructive, interpretative process involved. Similarly, we continue to talk of the sun coming up even though we know it is really just coming into view with the Earth’s rotation.&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Edmond, Jennifer.  “How scholars read now: When the signal  <em>is</em>  the noise” .  <em>Digital Humanities Quarterly</em>  (2018). Accessible at: <a href="/dhqwords/vol/12/2/000388/"> http://www.digitalhumanities.org/dhq/vol/12/2/000388/000388.html</a>.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Persuasive Physical Computing: A Review of David M. Rieder’s Suasive Iterations: Rhetoric, Writing, &amp; Physical Computing</title><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/000439/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/13/4/000439/</id><author><name>Nathan Sullivan</name></author><published>2019-12-14T00:00:00+00:00</published><updated>2019-12-14T00:00:00+00:00</updated><content type="html"><![CDATA[<p>In a digital age of virtual reality, augmented reality, and pervasive computing technologies, the lines between the virtual and the real have been blurred, resulting in typified virtual reality experiences — that is, users know what to expect when using these media. For David M. Rieder, that marks a point in society where digital rhetors and authors should seek to  “evert reality”  and  “creatively bend the conventional experience of reality toward some suasive end”   <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In  <em>Suasive Iterations: Rhetoric, Writing, and Physical Computing</em> , Rieder argues that for digital rhetors and authors to persuade and move audiences they should not be seeking to fashion virtuality as reality; rather, they should be seeking to combine the two in novel ways, into what he calls an eversion of reality, a transductive process where the line between the  “virtual and the real are folded together” , and the analog is blurred as a means of altering an audience’s reality <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Thus, Rieder aims to deliver succinct methodologies for designing iterations of suasive physical computing projects.</p>
<p><em>Suasive Iterations</em>  serves as a succinct reader and springboard for how digital humanists should begin research in the fields of physical computing and rhetoric and composition. Rieder’s text serves as a grand contribution to the digital humanities in that it moves and challenges the field towards considering the potential for physical computing research and empirical projects. Each chapter consists of a theoretical framework within which Rieder seeks to explore how rhetorical theory and physical computing can cooperate towards a means of persuasion in a post-PC era. Following each chapter is sub-chapter dedicated to a physical computing project which demonstrates the theoretical framework explored in the previous chapter. Organizing the book in this manner bolsters its argument, as each sub-chapter immediately puts theory into practice, providing a concrete application for the theories discussed.</p>
<p>In addition to the efficient chapter design, a visual aid is present by way of images. Rieder includes images of devices such as circuit boards and wiring, which help to inform readers who may be unfamiliar with the technology. These images are invaluable when Rieder begins to discuss the features of a particular piece of machinery as they make the text and the concepts therein feel accessible and the technology less foreign. As such,  <em>Suasive Iterations</em>  serves as an excellent text for new media courses at the upper-undergraduate level as well as all levels of graduate courses — including MA and Ph.D. classes. Classes seeking to expose students to digital rhetoric, computers and composition, or physical computing and writing will find this text useful, particularly because of the research ideas and projects included in the sub-chapters which provide students with applications to the theory discussed, processes for designing research projects, and ideas for further research.</p>
<p>The first chapter,  “For/Get the Digital and (Ditch the Umbrella)” , opens with Rieder’s appraisal of the art project  “Rain Room”  as it exemplifies the hybrid realities he argues for. Rieder introduces technologies such as passive infrared motion sensors, actuators, and slide potentiometers, believing that these technologies can be employed for rhetorical purposes in physical computing projects. Rieder believes technology contains the power to blur virtual and reality, leading to a change in one’s view of reality. The crux of this chapter lies in his presentation of Dan O’Sullivan and Tom Igoe’s term transduction:  “the process by which action or change is produced, and a reality-altering, everted experience is its outcome”   <sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Rieder uses this term in conjunction with an extension of Lloyd Bitzer’s theory of the rhetorical situation — through Kenneth Burke’s concept of casuistic stretching — to include physical computing environments and adopts Lawrence C. Rosenfield’s understanding of epideictic rhetoric as more than mere ceremonial appraisal but a celebration or appreciation of being. Rieder explains that folding (everting) the virtual into the real is  “an act of persuasion associated with epideictic”  because it is an  “event that illuminates or conceals some truth for its audience”   <sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>In Chapter Two,  “Transduction and Allegorized Style” , Rieder uses Richard Lanham’s analysis of prose to discuss how digital rhetors can allegorize data towards a suasive end. A suasive end, in this respect, refers to a reality-altering incident which utilizes  “some of the affordances of the virtual”   <sup id="fnref4:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Rieder adopts Lanham’s understanding of allegorized style to mean when content rises above its associated purpose or the argument it was intended for. Rieder provides examples of digital projects such as Laurence Sterne’s use of grammatical symbols and typographical experiments. Concepts of stylistic invention, magical and scientific logic, and computational thought are brought in to construct a theoretical foundation for what he calls  “A Multi-Stage, Recursive Process of Invention” , which is a seven-step process for designing a project with which data can be collected and allegorized towards a suasive end.</p>
<p>Chapter Three,  “Onto-Allegories for the  Great Outdoors ” , shows Rieder arguing against scholars such as John Wieser, Samuel Taylor Coleridge, and Adams Sherman Hill, the latter of whom calls for an era of ubiquitous computing — technologies that are invisible and less attention-grabbing. Rieder believes that these ideas are inherently anti-rhetorical and shows how rhetors should be seeking to grab the attention of audiences through rhetorical means. In an age of information, Rieder acknowledges that attention has become the new scarce commodity. In response, he argues that to compete with the values of calm computing digital rhetors should aim to compose projects that take on what he calls an  “onto-allegorical approach” , a combination of Lanham and Ian Bogost’s perspectives on attention and reality <sup id="fnref5:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>In Chapter Four,  “Plumbing the Paradoxical Depths” , Rieder argues for a revival of the canon of delivery and a return to embodied expressions such as gesture, posture, and corporeal experiences. Using scholars such as Adam Kendon, Ben McCorkle, and José Gil, Rieder supplants the understanding of gesture and the nature of the body in rhetoric. Rieder privileges the Xbox Kinect’s open platform system as an invaluable tool for such revival and goes into detail as to how this machine makes real-time transduction possible. Applying Deleuzian notions of the space-time of bodies, Rieder uplifts the Natural User Interface that the Kinect establishes as a means of capturing and delivering an everted bodily experience to audiences in a transductive manner. The Kinect provides an opportunity to capture paradoxically flat, raw data, and Rieder elaborates on how it can be transduced to deliver a new, everted reality to participants.</p>
<p>In what might be his most compelling chapter,  “A Call for Distant (Transductive) Writing” , Rieder argues for an approach to writing that removes the obligation to use alphabetical symbols as a means of conveying meaning and instead relies on generated surface-lines to express transduced allegorized meaning. He calls this  “distant writing” , an extension of Franco Moretti’s term distant reading  <sup id="fnref6:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. For Rieder, distant writing represents a mode of writing which removes the restraint of speech and phonetic thought as the sole method of conveyance and argument. Postulating the idea of line-making practices such as tracing, drawing, and etching as methods of distant writing, Rieder supplants the idea that writing represents speech using linguists such as Roy Harris and Tim Ingold, emphasizing the transductive potential for line-making as rhetorical practice.</p>
<p>In the final chapter,  “After the Bookish Era of the PC” , Rieder leaves readers with his hope for the future, of digital rhetors and distant writers allegorizing data for transductive purposes. Rieder reflects on the technological relationship in Spike Jonze’s film  <em>Her</em>  and how it relates to the  “new post-PC era”  and  “the post-human-reality”  we are headed towards <sup id="fnref7:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. He encourages scholars in the field to take a chance at creating a physical computing project, expressing hope that a day may come when such projects can be recognized as stand-alone scholarship and that more digital rhetors and authors would seek to explore the available means of persuasion in physical computing.</p>
<p>Perhaps the greatest strength of Rieder’s text is its insistence on exploration and experimentation. His seven-step recursive process of invention presents an invaluable heuristic of sorts with which digital rhetors can explore the limitations and potential of their physical computing projects. Another major strength is its accessibility and descriptive writing style. Rieder’s concision and clarity strengthen his argument as readers will find little trouble grasping his concepts. There is, however, an apparent limitation to his text. While not entirely unheard of, his stacked abstractions make for a very broad and open-ended scope. Because the scope is so broad and designed from the theorists he has chosen, readers may find themselves feeling limited by his abstractions to then apply his research methods.</p>
<p><em>Suasive Iterations</em>  is a strong text in that it urges digital humanists to consider the potentialities of physical computing as a means of suasive, rhetorical persuasion. To that end, Rieder negotiates the limits of writing and rhetoric and pushes them into the field of physical computing, urging interdisciplinary research and projects. The organization of the text makes for an accessible read for new scholars looking to find a conversation to join and the means with which to turn their inventive ideas into research endeavors and projects. As such, this text marks a pivotal turn for the digital humanities, documenting prospective change in a field — rhetoric and composition — which urges readers to explore and desire to capitalize on the innovative nature of technology through data-driven, empirical research.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Rieder, D.  <em>Suasive Iterations: Rhetoric, Writing, &amp; Physical Computing</em> . South Carolina: Parlor Press (2017).&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry><entry><title type="html">Reading the Quan Tang shi: Literary History, Topic Modeling, Divergence Measures</title><link href="https://rlskoeser.github.io/dhqwords/vol/13/4/000434/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://rlskoeser.github.io/dhqwords/vol/13/4/000434/</id><author><name>Peter Broadwell</name></author><author><name>Jack W. Chen</name></author><author><name>David Shepard</name></author><published>2019-12-14T00:00:00+00:00</published><updated>2019-12-14T00:00:00+00:00</updated><content type="html"><![CDATA[<h2 id="heading"></h2>
<p>The writing of literary history is perhaps an impossible endeavor. Even beyond the broader problem of justifying what counts as literature, we are faced with the question of how a historical narrative framework can effectively and comprehensively represent a given literary tradition. In many ways, this is a data modeling problem, one that turns on the question of reducing the vast arrays of literary data into a comprehensible narrative. <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>  That is, even if one lowers one’s sights to consider only a particular genre within a specific literary tradition — say, poetry written during the Tang dynasty (618–907) — there is still too much writing to account for and to fit into a coherent narrative. The problem is further complicated by the lack of a clear standard for what should be selected and what omitted, and how the selected portion could justifiably represent the whole of the data. As a result, literary histories tend to recycle the same small sample of super-canonical works and authors, unless the literary history is specifically aimed at broadening the canon or focused on a previously marginalized tradition.</p>
<p>The present paper addresses the problem of literary history precisely as a problem of data comprehensiveness and selection, seeking not to solve the impossibility of literary historical narrative, but to reframe it through a computational perspective. We take as our critical object the  <em>Quan Tang shi</em>  全唐詩 (Complete Tang poetry; hereafter  <em>QTS</em> ), the massive comprehensive anthology of Tang poetry that was commissioned by imperial decree in 1705, at the height of the Qing dynasty (1644–1912). Because the poetry of the Tang had become the standard for poetic composition over the intervening dynasties, the compilation of the  <em>QTS</em>  thus may be said to represent the culmination of some 800 years of literary canonization. This work is  <em>the</em>  major source for extant Tang poetry, and moreover, constitutes a literary historical perspective on the development of Tang poetry in its complex and multidimensional classificatory scheme (more on this below). However, the sheer quantity of Tang poetry that is preserved in the  <em>QTS</em>  — over 50,000 poems and poem fragments — simply exceeds the human-scale perspectives of close reading. Yet without reading the entirety of the  <em>QTS</em> , there can be no comprehensive understanding of what Tang poetry is, let alone a literary historical account of Tang poetry that can make use of the entire range of evidence and itself remain intelligible. To this end, what is required is access to a different scale of reading, one that has been characterized as  “distant reading”   <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup><sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, but might be more accurately thought of as machinic reading or as computational criticism.</p>
<p>Two points should be noted. First, on the question of distant reading versus close reading, we are mindful of Andrew Piper’s caution against the oft-brandished either/or dichotomy between the two scalar approaches. He writes,</p>
<blockquote>
<p>I want us to see how impossible it is not to move between these poles when trying to construct literary arguments that operate at a certain level of scale (although when this shift occurs remains unclear). In particular, I want us to see the necessary integration of qualitative and quantitative reasoning, which, as I will try to show, has a fundamentally circular and therefore hermeneutic nature.<br>
<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
</blockquote>
<p>We fully agree with the necessity of a both/and approach that allows for recursively circular processes of insights between scales of reading, though the question remains of what it means to mediate between machinic and human understandings of text and the equally important question of how a machinic vision of reading might transform how we as humans understand hermeneutics. Second, there has been relatively little work on distant reading methodologies with regard to East Asian corpora, not only because of technical issues such as character encoding and tokenization, but also because of the higher degree of linguistic difficulty in mastering East Asian languages and textual traditions. This said, in recent years there has been work on topic modeling and classical Chinese text corpora <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, focusing on particular issues in early thought. Mention should also be made of an endeavor to apply topic modeling to a very large classical Chinese corpus, though its results are more general and preliminary, and there are some basic issues with document selection and preparation <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. There have also been some studies of East Asian literary history using computational methods that take up questions of genre and style as related to problems of scalar reading <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup><sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>, and along similar lines more specifically for Tang poetry <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.</p>
<p>This essay begins with a discussion of literary history and how it has framed problems of data selection and completeness, before turning to an overview of the  <em>QTS</em> . To make sense of the corpus as a whole, we will then show how two related forms of distant reading — topic modeling and divergence measures — allow us both to reframe and rethink these literary historical questions and to access a new perspective on the practice of literary history.</p>
<h2 id="i-what-do-we-do-when-we-write-literary-history">I. What Do We Do When We Write Literary History?</h2>
<p>Literary history, as a subfield within literary scholarship, has occupied an ambivalent place, one that has seen a decline in terms of institutional or disciplinary training, even while new literary histories are still being written. The purpose of literary history can be defined in various ways, including the emergence and development of a genre or genres, the rise of a national literature, or the situation of literary writing within particular historical and cultural contexts. Yet, however literary history is defined, it is complicated by a number of factors, among which are the restrictions that both the individual critic and the narrative form impose on what authors and texts can be included, and what it means to include certain authors or texts and not others, not to mention the broader problems of working with historical context. David Perkins, in his now–seminal study,  <em>Is Literary History Possible?</em> , writes:</p>
<blockquote>
<p>Whatever else they have also hoped to accomplish, all literary historians have sought to represent the past and to explain it. To represent it is to tell how it was and to explain it is to state why — why literary works acquired the character they have and why the literary series evolved as it did. … Of course representation and explanation can never be complete, as literary historians and theorists have always recognized. Even if a historian knew all the relevant facts and answers, he could not crowd them into a book. The only complete literary history would be the past itself, but this would not be a history, because it would not be interpretive and explanatory.<br>
Perkins goes on to ask  “how much incompleteness is acceptable”  and to note how the fact that  “a literary history must be written from a point of view”  — the limited perspective of the critic — inflects the explanatory argument of the narrative <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>. These are problems that underlie all narrative historiography, since the nature of narrative historical argument involves simplification by means of representationality. That is, certain data are selected to serve as representative of the whole, and such choices are always informed by value judgments and critical interventions.</p>
</blockquote>
<p>To speak of data selection entails a need for evidentiary standards by which the selection is made, but how standards are determined is not always clear in literary historical writing. Data are not agnostic, because what gets chosen as data always already implies value judgments <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>  <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. Decades earlier, René Wellek and Austin Warren had already noted this exact point:</p>
<blockquote>
<p>There are simply no data in literary history which are completely neutral facts. Value judgements are implied in the very choice of materials: in the simple preliminary distinction between books and literature, in the mere allocation of space to this or that author. Even if we grant that there are facts comparatively neutral, facts such as dates, titles, biographical events, we merely grant the possibility of compiling the annals of literature. But any question a little more advanced, even a question of textual criticism or of sources and influences, requires constant acts of judgement.<br>
<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> Neither Wellek and Warren nor Perkins are arguing against historiographic simplification, since literary histories, much like maps, provide us with signposts by which to navigate the practically boundless territories of literary data. Indeed, one might go even further: We rely on literary history to tell us what to read, to tell us what counts as literature — in short, to demarcate the very boundaries of the vast and otherwise amorphous realm of textuality. The map is not and should not be the territory if the map is to be of any use. That said, there is still a problem of  <em>how</em>  one makes the initial selections. To allocate space in the historical narrative to a particular author means that other authors must be neglected, or simply reduced to passing mention; at some point the linearity of the narrative will require that data be excluded or discussed in aggregate; and this refracts the data in ways that can be obscured through the graceful telling of literary history. <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup></p>
</blockquote>
<p>While one reduction of data takes place at the point of the historical narrative’s composition, another reduction takes place over the history of readership. Margaret Cohen speaks of the  “Great Unread” , the unquantified mass of writings that have been lost through readerly neglect <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>. This same idea is expressed rather more colorfully by Franco Moretti, who speaks of the  “slaughter of literature”  and  “the butchers–readers: who read novel A (but not B, C, D, E, F, G, H…) and so keep A  alive  into the following one, and so on until eventually A becomes canonized”   <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. Moretti’s model has its flaws, both because it assumes  “the shape of the past from that of the present” , effectively rediscovering the canon it claims to question <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>, and because it treats each hypothetical novel as a stable and discrete entity. The fact that Novels B, C, or D are not chosen does not necessarily mean that their traits go untransmitted to later generations. Novel A, whose traits are passed on, may also have traits similar to Novels B, C, and D, etc., and indeed, most novels within a particular genre that are produced around the same time are likely to be more similar to one another than not. If Moretti’s model does not quite hold, we may at least say that readership plays some kind of role in the selection process of literary history, a process that is largely unsupervised and distributed, in the sense that there is no single intelligence that dictates which literary works will be canonized and which will not.</p>
<p>Yet, although Moretti views the composition of literary history as largely an afterthought, a rubber stamp of approval as he says, with the real work done by the decentered agency of readership, the writing of literary history is never simply reflective of reading histories, just as literary historiography is never the sole constitutive authority of what is read. The literary historian stands at the end of a lengthy process of selection, charged with representing the history of the successfully transmitted genetic material of literary data, but she also provides a critical intervention into the history of readership, one that potentially renegotiates the terms of readerly histories. That is to say, literary historiography both articulates unarticulated processes of canonization and consciously makes further selections of material both from within the readerly canon and from without.</p>
<p>However the immense accumulations of literary data are pruned and managed before they reach us, we might consider such reductions of data to be blessings, since to paraphrase Ann Blair, there is simply too much to read <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>. Nevertheless, with the advent of massive text digitization projects and the development of quantitative, rather than qualitative, reading methodologies, we might begin to explore what a literary history of a whole corpus (defined in terms of genre, period, author, or even on greater scales, such as tradition) would look like. We are mindful that qualitative perspectives will not be supplanted by quantitative methods, and that quantitative perspectives will not simply serve to confirm (or disprove) qualitative judgments. At the same time, the impact of computational methodologies has not yet been fully assessed; how one reads across multiple scales is not yet integrated into literary and cultural studies. This essay is a first step toward articulating a set of epistemological methodologies for a computational understanding of literary history.</p>
<h2 id="ii-what-is-the--_qts_-">II. What Is the  <em>QTS</em> ?</h2>
<p>To explore this problem of literary history, we will take as our object of analysis the  <em>Quan Tang shi</em> , a comprehensive anthology of (almost) all Tang dynasty (618–907) poetry <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> that was compiled between 1705 and 1707 under the nominal editorship of the prominent official and imperial confidant Cao Yin 曹寅 (1658–1712) and a team of scholars led by Peng Dingqiu 彭定求 (1645–1719) <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>. <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>  Despite oft-voiced complaints about textual errors, misattributions, and duplicate or omitted poems, this is an extraordinary work of scholarship that has preserved almost all poetry composed between the seventh and tenth centuries that might otherwise have been lost. And because the  <em>QTS</em>  corpus is a historically defined and comprehensive collection of extant Tang verse, the flaws inherent to Matthew L. Jockers’s macroanalytic approach to English literature, namely that his corpus is, despite his grander claims, “incomplete, interrupted, haphazard,” are not relevant here <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>  <sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>.</p>
<p>The structure of the  <em>QTS</em>  is itself remarkable, representing an ingenious attempt during its time to manage a vast array of literary data and allow for efficient retrieval of documents within a complex system. It consists of nine hundred chapters (juan 卷), with 49,403 poems (shou 首), as well as 1,055 poem fragments and couplets (ju 句) <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. This work was based on two earlier anthologies of Tang poetry: first, the  <em>Tangyin tongqian</em>  唐音統籤 (Assembled documents of Tang tones), which was compiled by the Ming scholar Hu Zhenheng 胡震亨 (1569–ca. 1644) <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>; and an earlier project, also entitled  <em>Quan Tang shi</em> , that was begun by the Ming-Qing transition poet Qian Qianyi 錢謙益 (1582–1664) and continued by Ji Zhenyi 季振宜 (b. 1630), now referred to as the  <em>Quan Tang shi gaoben</em>  全唐詩稿本 (Draft version of the complete Tang poems) <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>. The  <em>QTS</em>  is organized for the most part in a chronological fashion with certain significant exceptions. The contents of the work are identified as follows:<br>
Chapters  Contents      1–9  Poems by emperors, empresses and imperial members      10–16  Poems relating to rituals and sacrifices      17–29  Music Bureau poetry      30–731  Poems by individual poets of the Tang dynasty      732–733  Poems by dynastic villains and rebels      734–766  Poems by individual poets of the Five Dynasties Period      767–784  Poems by poets with partial biographical information      785–787  Poems without authorial attribution      788–794  Linked verse poems (lianju 聯句)      795  Incomplete poems and lines by poets not listed above      796  Incomplete poems and lines without authorial attribution      797–805  Poems by women       806–851  Poems by Buddhist figures      852–859  Poems by Daoist figures      860–862  Poems by (male) immortals (xian 仙)      863  Poems by female immortals (nüxian 女仙)      864  Poems by spirits (shen 神)      865–866  Poems by ghosts (gui 鬼)      867  Poems by anomalies (guai 怪)      868  Poems sent in dreams (meng 夢)       869–872  Jest and insult poems (xienüe 諧謔)       873  Poems inscribed on walls (tiyu 提語) and judgments (pan 判)      874  Songs (ge 歌) sung by groups or local communities      875  Prophetic verse (chenji 讖記)      876  Sayings in verse form (yu 語)      877  Proverbs and enigmatic verse (yanmi 諺謎)      878  Prescient popular ditties (yao 謠)      879  Drinking songs (jiuling 酒令)      880  Divination songs (zhanci 占辭)      881  The Mengqiu 蒙求 primer by Li Han 李瀚      882–888  Poems left out of previous sections (buyi 補遺)      889–900  Song-lyrics (ci 詞)    <br>
The first nine chapters are devoted to poems by members of the Tang imperial household, while chapters 10 to 29 cover ritual-related poetic texts and yuefu 樂府 poetry (poetry that relates to the Han dynasty Music Bureau or were composed under titles related to this office) <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>  <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>. However, the bulk of the anthology’s contents (chs. 30–731) follow an approximate chronological order of the lives of the individual poets included within. The anthology breaks from historical chronology to include poems by dynastic villains such as the eunuch Gao Lishi 高力士 (684–762) and the rebel Huang Chao 黃巢 (d. 884) (chs. 732–33) before the historical chronology resumes with poets of the Five Dynasties (chs. 734–66). However, following this, one finds poets with increasingly less biographical information, beginning with poets for whom full names and rank or geographic association are known, but who have no verified dates, then taking up poets who lack names but have some kind of other association that can be used to refer to them (i.e.,  “Traveler at Mount Li”  麗山遊人), and ending with poems that no longer have attributed authors (chs. 767–87). This is followed by linked verse (poems composed collaboratively, with each poet contributing alternating lines or couplets), incomplete poems (lines, couplets, stanzas) by poets without otherwise extant complete poems, and incomplete poems without any attribution (chs. 788–96).</p>
<p>Excepting the sections for poems written by imperial household members and dynastic villains, the anthology is, up to this point, organized according to a literary historical logic, one that seeks to order the poems by chronological precedence according to the authors’ biographical information, and then places those poems that lack such information afterwards in descending order of how much information is available. Pauline Yu, writing on Tang poetic anthologies, has called attention to the essential relationship between anthologies and literary history. She points out how poems in traditional Chinese anthologies  “were generally arranged in chronological order, if known, within an individual poet’s corpus, and then from author to author as well.”  As Yu goes on to note, this practice was distinct from Japanese anthologies,  “whose topical, associative, or thematically sequential organizational schemes suggest principles that are distinctly non-historical”   <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> (also see <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>). This latter form of anthology is based on the leishu 類書 (categorized writings), which were most commonly organized by a hierarchical system of topics, from the cosmic (heaven and earth) to the miniscule (insects) <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. Leishu are comparable to encyclopedias insofar as they were intended as comprehensive repositories of textual information, though there are significant differences from the Western concept of the encyclopedia <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>.</p>
<p>We see a different organizational logic beginning with chapter 797, where the  <em>QTS</em>  departs from a literary historical mode and follows something that is much closer to the topical categories associated with Japanese-style anthologies. This next section (chs. 797–805) is concerned with female poets, from  “famous beauties”  (mingyuan 名媛) and professional female performers (jinü 妓女) to well-known named authors such as Xue Tao 薛濤 (d. 832), Yu Xuanji 魚玄機 (ca. 844–68), and Li Ye 李冶 (d. 784). Following this are sections on Buddhist and Daoist poets (chs. 806–59), and then sections on immortals (xian 仙), spirits (shen 神), ghosts (gui 鬼), and anomalies (guai 怪) (chs. 860–66). The last chapters of the anthology are truly miscellaneous, including examples of divination verse (zhanci 占辭), proverbs and enigmatic verse (yanmi 諺謎), prescient popular ditties (yao 謠), poems from dreams (meng 夢), and poems inscribed on walls (tiyu 提語). Wherever possible, these chapters begin with figures related to the imperial house (emperors, palace women) and then proceed in chronological order.</p>
<p>The organizational logic of the  <em>QTS</em>  is worth a brief comment as it combines two earlier organizational schemes for literary anthologies: the categorical scheme associated with the encyclopedic leishu and the comprehensive chronological scheme that became prominent with Ming dynasty literary anthologies. Both forms of organization express a critical intelligence that orders documents in a way that makes theoretically possible the search and retrieval of particular documents. Yet because the  <em>QTS</em>  is constructed on a larger scale than what an individual reader can productively manage, the anthology functions in many ways more like an archive or a database than a work intended for personal perusal.</p>
<p>One might contrast the  <em>QTS</em>  to other smaller Tang poetic anthologies that were clearly meant for individual readers, such as the slightly later Qing anthology,  <em>Tang shi sanbaishou</em>  唐詩三百首 (The three hundred poems of the Tang). Compiled by Sun Zhu 孫誅 (1722–78), this extremely popular selection of approximately three hundred poems has served as an elementary poetry primer for generations through to the present day <sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>. To frame this within broader issues of literary history, while the  <em>QTS</em>  has served as the imperially sanctioned and culturally canonical edition of Tang poetry since its compilation, it was the  <em>Tang shi sanbaishou</em>  (and similar anthologies) that provided convenient and familiar access and thus actually shaped the idea of Tang poetry for most readers. In this way, the  <em>Tang shi sanbaishou</em>  served as a primary training dataset for literary historical knowledge, curating the popular experience of Tang poetry throughout society, and thus constructing standards of taste and readerly expectation for what a Tang poem should be.</p>
<p>While literary histories of the Tang are not usually based on elementary anthologies like the  <em>Tang shi sanbaishou</em> , they are nevertheless shaped by other cultural datasets, whether these are more scholarly anthologies, critical studies, or university curricula. If this is the case, then what might a history of Tang poetry look like if the dataset were comprehensive, or at least more robust? That is to say, how might  <em>reading</em>  the  <em>QTS</em>  alter our view of Tang poetic history? To be sure, both the act of reading the  <em>QTS</em>  and any critical representation of this knowledge would certainly depart from the usual narrative forms associated with conventional literary history. Indeed, while the  <em>QTS</em>  has often been mined as a resource for histories of Tang poetry (in English, see <a href="#owen1977">Owen 1977</a>, <a href="#owen1981">Owen 1981</a>, <a href="#owen2006a">Owen 2006a</a>; in Chinese, see <a href="#xu1994">Xu 1994</a>, <a href="#yang1996">Yang 1996</a>), it is rarely considered in its own right. After all, how many poets and poems, representing the literary accumulation of nearly three hundred years, can be fruitfully discussed within a single narrative framework? And even if such a narrative framework were possible, what examples of poetry should be selected and what omitted? How should the oeuvre of an individual poet be represented? How does the unit of analysis, whether it be the individual poet, a poetic style, or a literary theme, shape and inflect the literary historical account? If we are to understand Tang poetry not in terms of the limited dataset of authors and texts, but in terms of the whole of transmitted literary data, then we will need to take a macroscopic perspective, one that initially forgoes the granularity of close reading for something that takes place at a more stratospheric level.</p>
<h2 id="iii-on-topic-modeling-as-literary-methodology">III. On Topic Modeling as Literary Methodology</h2>
<p>In an age in which massive text digitization projects have been carried out by research centers, universities, government agencies, and individuals, literary historical claims need not rely solely upon microscale reading. The problem of close reading is that it is only possible at the scale of the individual text, which then necessitates an exemplary approach to the selection and analysis of the critic’s dataset <sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup><sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup>. To avail oneself of distant reading methods, however, is to adopt a somewhat different understanding of what it is to read a text, one that does not rely upon the anecdotal, limited nature of individual data-gathering. Here it is the machine that transforms the interpretative process, providing the scalar shift and quantitative capacity that makes reading large corpora possible. Computational analysis is not necessary for the individual poem, but when confronted by thousands of poems (or more), then the computer makes it possible to extract meaningful information on a macroscopic level from the aggregated texts. N. Katherine Hayles has written on this point, noting that we are entering an age of  “machine reading” , which is to say,  “computer algorithms used to analyze patterns in large textual corpora where size makes human reading of the entirety impossible”   <sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup>. And Stephen Ramsay writes:</p>
<blockquote>
<p>It is one thing to notice patterns of vocabulary, variations in line length, or images of darkness and light; it is another thing to employ a machine that can unerringly discover every instance of such features across a massive corpus of literary texts and then present those features in a visual format entirely foreign to the original organization in which these features appear. Or rather, it is the same thing at a different scale and with expanded powers of observation. It is in such results that the critic seeks not facts, but patterns. And from pattern the critic may move to the grander rhetorical formations that constitute critical reading.<br>
<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup> It is important to note that Ramsay also argues (elsewhere in his work) that computer-aided reading, which he calls  “algorithmic criticism” , is not a radical break from traditional modes of literary reading, since the human critic’s acts of interpretation can also be said to depend on rule-based processes — which is to say, upon algorithms — even though the critic’s manipulations and deformations of text may not be as explicit or programmatic as those of the computer. And to return to Hayles’ point, the major difference that can be realized through the computer’s algorithmic reading is simply that of the object of study, which is no longer confined to the single text or a succession of single texts, but a macroscalar aggregation of texts.</p>
</blockquote>
<p>More recent work such as Andrew Piper’s  <em>Enumerations</em>  follows essentially the same guiding principles: Piper uses statistical methods to approximate the judgements of a human reader at a macroscopic scale. Piper arrives at some impressive conclusions, including that characters within novels are more different from each other than they are from characters in other novels, and that heroes in twentieth-century science fiction are just as introspective as the heroines of nineteenth-century women’s fiction. While critics’ chosen statistical methods have become more sophisticated, the basic approach of using statistics to approximate the human reader’s critical judgments at scale persists.</p>
<p>Topic modeling, as a form of text mining, is one method of reading a large corpus, and while it is becoming increasingly familiar to practitioners of literary analysis, we will provide a quick summary here, one that is intended to set the terms for the following section. There are various introductions and overviews for those seeking more detailed summaries <sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>; <sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>; <sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>). In brief, topic modeling deploys a set of probabilistic algorithms to identify latent semantic patterns within a set of documents. This is how David Blei, co-author of the most widely used probabilistic model — latent Dirichlet allocation or LDA <a href="#blei2003">(see Blei, Ng, and Jordan 2003)</a> — describes it:</p>
<blockquote>
<p>…the goal of topic modeling is to automatically discover the topics from a collection of documents. The documents themselves are observed, while the topic structure — the topics, per-document topic distributions, and the per-document per-word topic assignments — is hidden structure. The central computational problem for topic modeling is to use the observed documents to infer the hidden topic structure. This can be thought of as reversing the generative process — what is the hidden structure that likely generated the observed collection?<br>
<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup></p>
</blockquote>
<p>There are a number of terms and concepts that need to be explained. First of all, there is the issue of latency, which Blei refers to as the  “hidden structure”  of the corpus. Topic modeling posits that there is a latent semantic structure beneath the observable corpus, and that there is a difference between what we can read in the everyday sense of the word and what only the computer can discern. This hidden structure is what topic modeling seeks to recover as the corpus’s generative model, or the matrix of thematically significant word clusters that make up the corpus as it presently exists. These thematic word clusters are the topics that the algorithm seeks to model, composed of words that have a high rate of co-occurrence within documents (understood here as any significant unit of text). The topics are probabilistically significant distributions of words that comprise the corpus’s documents, and each of the documents is understood as a mixture of topics. Document word order is not important, as the topic model treats the corpus simply as a bag of words, drawing out each word and assigning it to a topic based on the frequency of its co-occurrence with other frequently co-occurring words.</p>
<p>How can this model claim to reflect the process of composing literature, let alone literary history? The answer is that it does not, but it approximates it. As readers, we may assume the poetic process for a poet — or a group of poets — as something like: first, a poet sets out to express an idea, which is composed of one or more themes, like love and beauty. Next, the poet chooses concrete images to express these themes and ideas, such as love and roses. From this, the poet puts the ideas into words, e.g., My love is like a red, red rose. A human reader, reading the poem, works in reverse: she encounters the poet’s actual words and transforms them into a set of images and thoughts, ultimately seeking to get a sense of what the poet is actually writing about — in other words, the themes he is trying to express. The specific layers described above perhaps do not matter so much: there may be more to the processes of composition or reading. Our point is that what we experience as the richness of human reading are the different levels of experience that a poem inspires in a reader: visualized images, emotional experiences, resonances with other words, historical context, and the like. The processes of producing or consuming literature is a process of either expressing or discovering these layers.</p>
<p>LDA follows a similar process: it starts from the poet’s word choice and assumes that some latent variables (images or themes) drive the poet’s word choices (the observed variables). It models the latent variables from the observed variables. While LDA is an approximate model, with far less sophistication than a human reader, it scales better. LDA approximates what a human being does with less sophistication: it has only two layers of meaning (observed and latent variables) versus the reader’s potentially many interpretive layers. However, it can work at a much larger scale, and with much greater accuracy because it is not subject to the failures of human memory. A human critic using LDA works off of this approximation: she assumes that the latent variables match some of the things that a human reader will discover using their own interpretive apparatus, and interprets LDA’s topics as patterns of imagery, themes, or ideas. She must negotiate between the rich meanings that a reader can extract from the few texts that a human reader can read, and the far less rich latent patterns that the LDA model can discover.</p>
<p>From this negotiation, we are able to derive a different model for doing literary history, one that scales to a larger set of texts. If one conceives of literary history as an epistemological process of discovery, one that seeks to understand the parameters for how the literary past is constructed, then this perspective has the potential to reconceptualize our received evidentiary standards. What follows may not resemble literary historical work, and indeed, may read more like laboratory reports than critical analysis, but this is necessary: we are proposing that a macroanalytic literary history will require different methodologies, ones that negotiate between human and machine visions of textuality. To highlight the applications of such a computationally enhanced methodology to poetic studies and perhaps more broadly, we illustrate how judicious examination of a topic model of the  <em>QTS</em>  calls out poems whose authors and genres have not received the blessing of concerted attention from scholars, yet upon close inspection present exemplary literary and historical insights. Moreover, the identification of these poems and their revelatory topical similarities (and divergences) follows from what is arguably the key analytical contribution of LDA topic modeling: its ability to infer semantically alloyed relationships between sets of words that may appear together in the same document infrequently or even not at all, and to do this at a corpus-wide scale that is inaccessible to the minds of even the most well-read scholars. The discussion also emphasizes the importance of keeping the human in the loop throughout such computer-aided analyses, as computational measures of significance do not always correspond to humanistic notions of meaning.</p>
<h2 id="iv-the--_qts_--and-topic-modeling">IV. The  <em>QTS</em>  and Topic Modeling</h2>
<p>On the most basic level: the topic modeling program that we used is  <em>MALLET (MAchine Learning for LanguagE Toolkit)</em>   <sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>. For the  <em>QTS</em>  corpus, we excluded all poetic fragments (generally orphan couplets and lines) from the topic model, as the shortness of these documents statistically skews the output, though we retained sections of significant length, such as Chapter 881, which is comprised solely of the poetic primer Mengqiu, as it was feasible to divide these into poem-length subsections. We did not use a stop-word list, as many classical Chinese grammatical particles have other, non-particle meanings depending on the context. We specified that  <em>MALLET</em>  should generate 150 topics, which was the number of topics (following an iterative trial-and-error process) that provided the most informational complexity while minimizing interpretive perplexity.<sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup>  From this, we received three reports: a topic-keys report (TKR), a topic-phrase report (TPR), and a document-topics report (DTR) — all of which will be discussed in turn. While these reports may be familiar to those who have experience with topic modeling, discussing these reports in detail is important for our argument, as we will demonstrate.</p>
<p>The first output file, the topic-keys report, is a non-ranked list of topics that shows the twenty strongest correlated words in each topic in ranked order (note that these are only the top twenty correlated words for a given topic, as this is the default number in  <em>MALLET</em> ). Here are the first eleven topics from the TKR:<br>
馬 車 騎 行 塵 出 長 鞭 門 走 白 嘶 金 蹄 道 鞍 青 黃 馳 驅  酒 醉 杯 飲 一 客 酌 醒 勸 滿 尊 傾 對 笑 壺 歡 酣 送 倒 且  不 人 能 知 誰 生 自 有 無 來 豈 得 在 與 作 但 令 可 古 解  相 年 家 見 弟 同 兄 來 逢 長 少 還 自 許 多 喜 說 親 作 時  江 海 迢 潮 帆 吳 越 楚 孤 滄 客 去 洲 波 歸 遠 湖 浪 遞 南  寂 遙 寥 空 落 寞 朝 風 獨 見 中 思 林 月 清 在 寒 逍 想 招  夜 月 明 燈 曉 殘 漏 星 聲 更 照 暗 寒 宿 燭 火 半 光 露 鐘  我 不 為 此 言 爾 者 何 有 亦 如 生 人 與 得 苦 無 所 願 令  水 東 流 西 山 日 去 雲 空 落 歸 中 路 陵 白 復 見 長 暮 盡  金 玉 珠 銀 紫 錦 重 寶 黃 光 刀 環 裁 佩 衣 雙 盤 珊 龍 垂  蕭 風 雨 秋 暮 條 寒 雲 吹 起 獨 颯 晚 上 日 樹 葉 空 向 索</p>
<p>The first column is the topic ID number, assigned by  <em>MALLET</em>  without rank significance. The second is the set of the words assigned to the topics in ranked order of correlation strength.</p>
<p>As the topics simply consist of ranked lists of words, to understand what the topics signify requires that labels be added to the topic-keys report. These labels are necessarily acts of interpretation, though useful ones for translating the machine perspective on the corpus into human terms. Here again are the first eleven topics, now with our provisional labels:</p>
<p>馬 車 騎 行 塵 出 長 鞭 門 走 白 嘶 金 蹄 道 鞍 青 黃 馳 驅 horses, traveling   酒 醉 杯 飲 一 客 酌 醒 勸 滿 尊 傾 對 笑 壺 歡 酣 送 倒 且 drinking ale   不 人 能 知 誰 生 自 有 無 來 豈 得 在 與 作 但 令 可 古 解 particles, common verbs   相 年 家 見 弟 同 兄 來 逢 長 少 還 自 許 多 喜 說 親 作 時 families, home   江 海 迢 潮 帆 吳 越 楚 孤 滄 客 去 洲 波 歸 遠 湖 浪 遞 南 southern waterscapes   寂 遙 寥 空 落 寞 朝 風 獨 見 中 思 林 月 清 在 寒 逍 想 招 remoteness and longing   夜 月 明 燈 曉 殘 漏 星 聲 更 照 暗 寒 宿 燭 火 半 光 露 鐘 night: moon and lamp   我 不 為 此 言 爾 者 何 有 亦 如 生 人 與 得 苦 無 所 願 令 particles, pronouns   水 東 流 西 山 日 去 雲 空 落 歸 中 路 陵 白 復 見 長 暮 盡 landscape: traveler   金 玉 珠 銀 紫 錦 重 寶 黃 光 刀 環 裁 佩 衣 雙 盤 珊 龍 垂 precious materials   蕭 風 雨 秋 暮 條 寒 雲 吹 起 獨 颯 晚 上 日 樹 葉 空 向 索 autumn evening scene</p>
<p>Taking a closer look at Topic 1, to which we have attached the label traveling with horses, we may further gloss the listed terms as follows: 馬 (horse), 車 (carriage or wagon), 騎 (rider or to ride), 行 (to travel), 塵 (dust), 出 (to depart, set forth), 長 (long), 鞭 (whip), 門 (gate), 走 (to run), 白 (white), 嘶 (to neigh), 金 (gold, metal), 蹄 (hoof), 道 (road), 鞍 (saddle), 青 (green-blue), 黃 (yellow, brown), 馳 (to gallop, to rush), and 驅 (to drive forward, to urge forth). All of these words are either thematically related to horses and traveling or illustrate what the linguist Shuanfan Huang calls syntactic contiguity, such as the three color terms <sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>.</p>
<p>More difficult to label is a result such as Topic 4, which consists of many commonly used words, including the particle 相 (mutually, or an adverbial particle replacing a direct object), 年 (year), 家 (family, home), 見 (to see, to meet), 弟 (younger brother), etc., which might relate to a number of poetic themes involving home and family or perhaps something broader. There are a number of such topics, where the meanings of the terms are clear but how they relate semantically remains more or less ambiguous, inviting the human interpreter to fill in the gaps and to imagine possible poems that might be constructed with these terms. Here, the problem becomes one of projecting meaning where meaning is indeterminate, or perhaps, not determined in ways that accord with our (human) cultural categories.</p>
<p>Turning back to the  <em>MALLET</em>  output files, the same results are available in a more detailed list with weights for each word and for frequently occurring phrases. This is provided in the second output file, the topic-phrase report. This report first begins with a listing of frequently occurring phrases (combinations of tokens) in the topic and then provides a ranked list of the first nineteen words in the topic, followed by a ranked list of the 21 most common phrases. As the TPR is an even lengthier report than the TKR, here is the section just for Topic 0, reformatted as two separate tables. The first table lists each word in ranked order with word weights and token counts:<br>
Word  Word Weight  Count      馬  0.16849291492169124  2937      車  0.049968447019677585  871      騎  0.03568355229189375  622      行  0.031897194653204064  556      塵  0.03172508748780908  553      出  0.030577706385175835  533      長  0.027594515518329414  481      鞭  0.02702082496701279  471      門  0.025299753313062934  441      走  0.020595490792266653  359      白  0.018358097642131834  320      嘶  0.016694395043313638  291      金  0.016120704491997016  281      蹄  0.014973323389363778  261      道  0.014629109058573805  255      鞍  0.01359646606620389  237      青  0.013424358900808904  234      黃  0.012047501577649016  210      馳  0.011990132522517355  209      驅  0.01187539441225403  207   <br>
The second table lists frequently occurring phrases, with phrase weights and counts:<br>
Phrase  Phrase Weight  Count      車 馬  0.0615748963883955  104      馬 蹄  0.04262877442273535  72      走 馬  0.04085257548845471  69      馬 嘶  0.04026050917702783  68      驄 馬  0.03197158081705151  54      騎 馬  0.028419182948490232  48      鞍 馬  0.02427471876850207  41      駟 馬  0.020130254588513915  34      匹 馬  0.018354055654233273  31      駿 馬  0.017761989342806393  30      駑 駘  0.017169923031379514  29      躞 蹀  0.013025458851391355  22      匆 匆  0.012433392539964476  21      驅 馬  0.011841326228537596  20      騏 驥  0.010657193605683837  18      羸 馬  0.010065127294256957  17      車 騎  0.009473060982830076  16      馬 鞭  0.0076968620485494375  13      騏 驎  0.0076968620485494375  13      白 馬  0.0076968620485494375  13      嘶 馬  0.007104795737122558  12   <br>
As can be seen, the TPR provides a clearer breakdown of the strength of each word’s correlation to the topic. Each word is assigned a value that denotes its topic weight, or the number of times that the word appears within documents identified with this particular topic. For example, the first–ranked character for Topic 0 is 馬 (horse), which is represented in the TPR as having a weighting of 0.1685 (rounded up) and a count of 2937, which means that it represents 16.85% of the 17,431 word occurrences assigned to topic 0 in the corpus (this count is also provided in the TPR). In other words, in the entire corpus, 馬 appears more than 2937 times, but for 2937 of the instances in which it occurs, it is assigned to topic 0. Most words will have a weighting value of &lt;0.001 in the TPR for a specific topic, reflecting the default prior probability that any word in the corpus vocabulary will appear in a topic at some infinitesimal level. Words with this value in the topic–phrase report are considered to have negligible weight within the modeled topic but are nevertheless still represented. For some topics there may be a more even distribution of strongly correlated words, while for others there may be a marked differential between the first word and the next–strongest words.</p>
<p>The final  <em>MALLET</em>  output file is the document–topics report, which shows the strength of each topic within every document. This is an extremely long report, consisting of the percentage breakdowns of each of the 150 topics for every poem in the  <em>QTS</em> . Rather than present the entire report, we have excerpted part of the report for Poem 30_1 in the corpus, which is to say, the first poem from Chapter 30, titled  “On Han Gaozu”  詠漢高祖. This is not an arbitrary selection, as this is the point in the anthology where it begins to be organized by individual poets in roughly chronological order, taking on a literary historical logic. Moreover, this poem was composed by the late Sui-early Tang figure Wang Gui 王珪 (570–639), who served under Tang Emperor Taizong 唐太宗 (r. 626–49) and is not particularly remembered for his poetic ability. As such, this poem represents an example of the  “Great Unread” , a literary work that should have been forgotten except for its inclusion in the  <em>QTS</em> .</p>
<p>Before turning to the report, it might be useful to be able to read the text of the poem, which we have translated in full as follows:<br>
漢祖起豐沛， Han Gaozu arose from Feng Town in Pei County,<sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>   乘運以躍鱗。 Riding fortune’s course with high-leaping scales.<sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>   手奮三尺劍， In his hand he brandished a three-foot sword,  西滅無道秦。 And to the west he destroyed the lawless Qin.  十月五星聚， In the tenth month, the five planets clustered,<sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>   七年四海賓。 In seven years, all in the four seas were his guests.<sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>   高抗威宇宙， Lofty and unyielding, he awed the universe,  貴有天下人。 Exalted, he took charge of all the world’s people.  憶昔與項王， I think back on how he accompanied Xiang Yu,<sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>   契闊時未伸。 Now long separated, that age cannot be reached.  鴻門既薄蝕， Both at the Hongmen Feast he was treated poorly,  滎陽亦蒙塵。 And at Xingyang, where he fled, covered in dust. <sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>   蟣虱生介胄， Lice are born in armor and helmets,  將卒多苦辛。 Generals and soldiers endure much suffering.  爪牙驅信越， As his claws and teeth: Han Xin and Peng Yue forged ahead,  腹心謀張陳。 As his belly and heart: Zhang Liang and Chen Ping laid plots.<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>   赫赫西楚國， How glorious was Western Chu’s kingdom,  化爲丘與榛。 Transformed now into mounds and underbrush.<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>  <br>
This is a fairly standard example of a poem on history (yongshi shi 詠史詩), one that focuses on the founding emperor of the Han dynasty. One might trace out the progression of the poem from its broad-stroke portrait of the ruler’s rise to power to its focus on his war with his great rival Xiang Yu and the eventual ruin of Xiang Yu’s Western Chu. The poem evokes a lost age of heroes, of glorious victories, fabled escapes, and tragic falls, bookending the triumphant founding of the Han dynasty with the barren fate of the Western Chu.</p>
<p>However, a different approach to analyzing this poem can be found in  <em>MALLET</em> ’s document-topics report. We have quoted only a portion of the lengthy report, stopping at the point where the percentage falls below 1%:</p>
<p>“1969 30_1, 30 0.10952380952380952 16 0.05952380952380953 139 0.05238095238095238 7 0.03809523809523809 135 0.03095238095238095 110 0.03095238095238095 32 0.03095238095238095 15 0.03095238095238095 49 0.02380952380952381 42 0.02380952380952381 125 0.016666666666666666 124 0.016666666666666666 122 0.016666666666666666 115 0.016666666666666666 109 0.016666666666666666 98 0.016666666666666666 92 0.016666666666666666 87 0.016666666666666666 83 0.016666666666666666 66 0.016666666666666666 36 0.016666666666666666 ”</p>
<p>Following the two poem IDs (1969, meaning the 1969th poem of the corpus; and 30_1, referring to the document’s chapter number and its poem number within the chapter),  <em>MALLET</em>  provides two pieces of information: the topic ID number and the percentage of that topic within the poem. Included in the whole of the report are all 150 topics in descending order of strength (again,  <em>MALLET</em>  assumes that all topics are represented in each document, even if in statistically insignificant percentages). We can see that, for this document, it is Topic 30 that ranks most highly, constituting approximately 10.95% of the poem. Only the top twenty-one topics (topics with values &gt;1%) are actually meaningful in this case, as most topics belong to the long tail of statistical insignificance. Here are the top topics (values are rounded up) in descending order of significance and with our preliminary labels for the topics:<br>
TopicID   Percentage  Topic (first 20 terms in rank order)  Topic Label      30  10.952%  天 大 皇 四 帝 海 萬 太 功 夷 方 王 三 命 元 聖 乾 業 宗 武   empire and sovereign power      16  5.952%  不 如 食 生 足 骨 口 死 飢 肉 眼 齒 腹 為 土 耳 力 飲 可 破   mortality, eating and drinking      139  5.238%  塵 人 春 新 身 親 勤 鄰 殷 頻 津 為 巾 輪 濱 四 辰 辛 貧 巡   tsyen 真 rhyme category      7  3.81%  我 不 為 此 言 爾 者 何 有 亦 如 生 人 與 得 苦 無 所 願 令   pronouns and particles      135  3.095%  將 軍 兵 戰 旗 馬 旌 功 劍 弓 戎 營 騎 鼓 戈 羽 角 虜 射 箭   military, armies      110  3.095%  未 自 慚 知 豈 雖 薄 終 非 已 顧 愧 負 辭 寧 猶 難 甘 心 敢   shame, regret      32  3.095%  十 三 年 二 五 四 六 七 一 八 百 千 九 月 今 歲 前 載 老 第   numbers, calendrical time      15  3.095%  王 漢 秦 國 宮 吳 陵 帝 楚 武 臺 陽 長 子 安 亡 苑 作 蘇 梁   Han and pre-Han kingdoms      49  2.381%  南 北 東 西 山 風 望 國 城 日 向 斗 河 闕 起 海 長 直 復 從   territorial space, cardinal directions      42  2.381%  庭 中 滿 洞 月 山 風 樹 裏 長 高 入 空 雲 水 煙 起 日 上 陽   courtyard / landscape scene?      125  1.667%  門 深 開 日 閉 高 戶 滿 入 客 出 堂 朱 外 巷 院 掩 牆 庭 靜   gates, halls, and built spaces      124  1.667%  所 言 子 豈 道 志 異 為 良 非 懷 自 徒 昔 貞 乃 可 賢 常 義   particles / will and righteousness?      122  1.667%  魚 水 釣 下 垂 鳥 池 上 時 小 鱗 竿 驚 得 網 有 無 欲 避 坐   fisherman, fishing      115  1.667%  劍 士 氣 生 平 感 侯 壯 橫 長 縱 交 雄 將 子 英 安 報 燕 節   heroes, men of valor      109  1.667%  江 湘 南 楚 水 客 舟 遠 雲 孤 秋 山 瀟 雁 陽 浦 湖 去 渚 夢   southern (Chu) riverscapes      98  1.667%  神 禮 德 惟 肅 樂 靈 降 薦 既 誠 載 以 明 昭 永 斯 福 陳 備   ritual and ceremony      92  1.667%  龍 雷 騰 神 虎 如 驚 蛟 若 蛇 電 橫 當 鼓 倒 大 氣 怪 勢 天   dragons, tigers, images of divine power      87  1.667%  然 化 物 無 浩 天 心 異 造 有 形 方 道 可 忽 中 變 至 窮 言   divine creation and transformation      83  1.667%  古 草 荒 人 空 在 野 木 平 跡 遺 地 舊 原 猶 城 餘 有 無 蕪   desolate wilderness      66  1.667%  遊 留 休 頭 秋 侯 州 收 憂 求 愁 不 丘 浮 酬 裘 子 諸 牛 羞   ghou 尤 rhyme category      36  1.667%  天 下 太 地 子 中 一 上 海 出 道 入 平 黃 九 四 守 白 大 成   empire and territory   <br>
From this, we might say that  “On Han Gaozu”  is a document constructed out of assorted topics that might be labeled empire and sovereign power, mortality, eating and drinking, tsyen 真 rhyme category,<sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>   pronouns and particles, military, armies, shame, regret, numbers, calendrical time, Han and pre-Han kingdoms, territorial space, cardinal directions, and the ambiguous courtyard / landscape scene. Some of these are topics with a strong semantic identity (for example, both empire topics), though some are topics that represent syntactic and grammatical functions (pronouns and particles) and formal characteristics of the poem (tsyen 真 rhyme category). We also find the presence of topics that are not easy to label, such as the unclear Topic 42 (courtyard / landscape scene?), and topics that are inexplicably present, such as Topic 66 (ghou 尤 rhyme category), which is a second rhyme category topic not otherwise evidenced in the poem. It is important to keep in mind that our interpretive perplexity is the result of differences between how humans and how  <em>MALLET</em>  reads the corpus, and that  <em>MALLET</em> ’s identification of topics for documents are not based on semantic reasoning but on the distribution of vocabularies. At times human and machine readings might converge, leading to deeper insight into the corpus, but at other times, we are reminded of our methodological — and ontological — differences.</p>
<h2 id="v-using-topics-to-think-through-literary-history">V. Using Topics to Think through Literary History</h2>
<p>Up until his point, the application of topic modeling to the  <em>QTS</em>  has largely been to reframe the question of representing and accessing the poetic corpus, and where we have provided an analytical perspective, it has focused on understanding what a topic model represents in relation to the poetic documents. Here, we propose that topic modeling may help us to think through the problem of selection criteria in constructing a literary historical account, enabling one to navigate the vast unread of Tang poetry, selecting poems that do not reflect the individual critic’s own biases and preferences, or those preferences predetermined by anthological training sets and other unknowable selection processes over the course of history. The resulting literary historical narrative would be semi-supervised, more strongly dependent upon human reading and interpretation at certain points in the process, and more strongly dependent upon machine reading at others. This would not be the utopian fantasy of posthuman reading, where machine objectivity replaces human subjectivity, but a shifting balance between a machine-assisted perspective and a traditional analog perspective. Part of this approach, however, is a serious attempt to engage the machine’s perspective, to try to understand how the machine sees the collection of documents, and to translate this into human terms. To this end, we rely on the Jensen-Shannon divergence measure <sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>, which quantifies the difference between any (finite) number of probability distributions.<sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>  In our case, these distributions are the probabilities of topics constituting documents, as in  <em>MALLET</em> ’s document-topics report described above. Although this measure is formulated in terms of divergence, it allows us to explore document similarity, much like vector similarity measures, and to perform unsupervised information retrieval within a large textual corpus.<sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup></p>
<p>Although the supervised selection of  “On Han Gaozu”  (Poem 30_1) as a starting point may have been somewhat arbitrary, chosen because of its position as the first poem in the main section of the  <em>QTS</em>  (the chronological-by-author section that runs from Chapter 30 to 731), its literary obscurity makes it a useful example of Tang poetry’s Great Unread. We could imagine, however, that we have arrived at this poem after navigating a topic-based index of the corpus and now seek to find topically similar poems. Using  “On Han Gaozu”  as our target document, the top five most similar documents according to the Jensen-Shannon divergences of their topic distributions are identified as follows:<br>
Document ID  Poem Title and Author  English Translation  Similarity Score      1969 (30_1)  《詠漢高祖》王珪   “On Han Gaozu”  by Wang Gui  1.0      573 (13_68)  《享太廟樂章。象德舞》 段文昌    “Hymns for the Offering to the Ancestral Temple: Dance for Manifesting Virtue”  by Duan Wenchang   0.8822478125653975      38884 (767_29)  《苻堅投棰》 孫元晏    “Fu Jian Casts His Whip”  by Sun Yuan’an  0.8787439416072281      2751 (52_30)  《過函谷關》 宋之問    “Visiting Hangu Pass”  by Song Zhiwen  0.877820744700559      37314 (729_66)  《二廢帝》 周曇    “On the Two Deposed Emperors”  by Zhou Tan  0.8722429641594189      2009 (31_26)  《梁郊祀樂章。慶休》 ?   “Hymns for the Liang Suburban Sacrifice: Jubilation”  by unknown author  0.872006203906182   <br>
The table is mostly self-explanatory, but it is worth quickly pointing out that because  “On Han Gaozu”  is the benchmark for the similarity measure scores, it has a score of 1.0, meaning that it is identical with itself, and that the more similar a document is to  “On Han Gaozu” , the higher its fractional similarity score.</p>
<p>One striking aspect of the divergence measure is how  “On Han Gaozu” , traditionally understood as a poem on history, correlates strongly to poems originating from ritual and sacrificial occasions. The top document retrieved in this manner is Poem 13_68,  “Hymns for the Offering to the Ancestral Temple: Dance for Manifesting Virtue”  享太廟樂章：象德舞, by the mid-/late Tang poet and official Duan Wenchang 段文昌 (773–835):</p>
<blockquote>
<pre><code>肅肅清廟 How magnificent and solemn, the ancestral temple,  登顯至德 Radiating forth its perfected virtue!  澤周八荒 Your grace covered the eight expanses,  兵定四極 Your armies settled the four directions.  生物咸遂 Living creatures all followed suit,  群盜滅息 All thieving ceased and came to an end.  明聖欽承 The Enlightened Sage reverently has inherited this,  子孫千億 Transmitting it to descendants for countless generations.  
</code></pre>
</blockquote>
<p><sup id="fnref1:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup><br>
This hymn belongs to the family of ritual songs categorized as  “Lyrics for the Suburban Altars and Ancestral Temple”  郊廟歌辭, and according to the  <em>Jiu Tang shu</em>  舊唐書 (Old history of the Tang dynasty), it was performed at the tomb of Tang Emperor Xianzong 唐憲宗 (r. 805–20) <sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup> (for background on this form, see <a href="#jensen2012">Kevin Jensen 2012</a>). The hymn uses the archaizing tetrasyllabic form, rather than the pentasyllabic (or heptasyllabic) form used throughout most Tang verse; this is common in other poems composed for ritual or formal court occasions.<sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>  The lyrics themselves are fairly straightforward and do not contain much of aesthetic interest, mainly serving to translate the ritual moment into linguistic expression.</p>
<p>On the face of it, Duan Wenchang’s poem would seem to share little in common with Wang Gui’s poem, given the differences in poetic subgenre and occasion. However, the DTR (document-topics report) for  “Hymns for the Offering to the Ancestral Temple: Dance for Manifesting Virtue”  reveals a similar topical mixture:<br>
TopicID  Percentage  Topic (first 20 terms in rank order)  Topic Label      30  10.163%  天 大 皇 四 帝 海 萬 太 功 夷 方 王 三 命 元 聖 乾 業 宗 武   empire and sovereign power      87  5.285%  然 化 物 無 浩 天 心 異 造 有 形 方 道 可 忽 中 變 至 窮 言   divine creation and transformation      98  4.065%  神 禮 德 惟 肅 樂 靈 降 薦 既 誠 載 以 明 昭 永 斯 福 陳 備   ritual and ceremony      32  2.846%  十 三 年 二 五 四 六 七 一 八 百 千 九 月 今 歲 前 載 老 第   numbers, calendrical time      149  1.626%  忘 隱 清 心 閒 興 林 靜 勝 自 外 幽 景 愛 機 塵 坐 情 對 境   reclusion      131  1.626%  朝 恩 主 重 詔 拜 承 明 從 臣 榮 紫 賜 門 闕 寵 官 命 列 禁   imperial court      126  1.626%  多 過 更 深 遠 近 宜 入 偏 地 好 和 處 隨 經 移 數 重 客 高   visiting someone      113  1.626%  惡 死 禍 者 敢 罪 危 狼 殺 受 非 防 虎 力 反 利 失 亂 命 傷   disaster      111  1.626%  應 出 隨 朝 從 還 臨 先 行 分 迎 暫 逐 近 節 遠 待 將 旌 方   welcoming / serving?      109  1.626%  江 湘 南 楚 水 客 舟 遠 雲 孤 秋 山 瀟 雁 陽 浦 湖 去 渚 夢   southern (Chu) riverscapes      108  1.626%  復 念 歲 已 懷 所 窮 忽 歎 何 良 憂 未 當 豈 夕 役 終 思 歡   remembering, mourning      83  1.626%  古 草 荒 人 空 在 野 木 平 跡 遺 地 舊 原 猶 城 餘 有 無 蕪   desolate wilderness      72  1.626%  山 石 松 巖 溪 泉 林 幽 雲 鳥 谷 蘿 深 澗 隱 青 徑 野 下 竹   mountain scene      40  1.626%  天 人 地 上 不 生 下 此 長 一 道 得 日 為 間 何 高 意 擾 白   Heaven and Earth      36  1.626%  天 下 太 地 子 中 一 上 海 出 道 入 平 黃 九 四 守 白 大 成   empire and territory      15  1.626%  王 漢 秦 國 宮 吳 陵 帝 楚 武 臺 陽 長 子 安 亡 苑 作 蘇 梁   Han and pre-Han kingdoms   <br>
The fact that  “On Han Gaozu”  and  “Hymns for the Offering to the Ancestral Temple: Dance for Manifesting Virtue”  share Topic 30 (empire and sovereign power) as their highest ranking topic is a large factor in the high similarity score between the two documents. However, equally important is how the two documents rank Topics 32 (numbers, calendrical time), 98 (ritual and ceremony), 87 (divine creation and transformation), 109 (southern [Chu] riverscapes), 15 (Han and pre-Han kingdoms), 83 (desolate wilderness), and 36 (empire and territory). There are clear thematic similarities here, given that both poems treat the foundings of empire, though no traditional literary history would correlate these two poems, as they would be classified differently based on their metrical forms and subgenres: one a pentasyllabic poem on history and the other a tetrasyllabic ritual poem.</p>
<p>Moreover, we can see how a comparison of document topic rankings may help us to understand what similarity and divergence means on a cultural and semantic level. If  “On Han Gaozu”  and  “Hymns for the Offering to the Ancestral Temple”  both rank Topic 30 (empire and sovereign power) first in terms of topic percentage, they diverge in their second highest ranked topic, which is Topic 16 (mortality, eating and drinking) for  “On Han Gaozu”  and Topic 87 (divine creation and transformation) for  “Hymns for the Offering to the Ancestral Temple” . This suggests that where a poem on history diverges from a ritual poem that also treats historical events is in the combination of secondary vocabularies. The topic we have labeled mortality, eating and drinking evokes subjective experience in a way that connects the lament on historical memory to the individual poet, and this would not be fitting for a ritual poem that is articulated at the higher register of divine creation and transformation.</p>
<p>Finally, related to this, we can also address the problem of topics that  <em>MALLET</em>  identifies in a particular document but that are not clearly evident to the human reader. For example, consider Topic 122 (fishermen, fishing), which ranks highly in  “On Han Gaozu”  and the presence of Topic 149 (reclusion), which ranks highly in  “Hymns for the Offering to the Ancestral Temple” . The two documents diverge on these topics (among others, of course), but what is interesting is that neither topic is particularly evident in the documents in which they are highly ranked. The question becomes, why does  <em>MALLET</em>  consider these ghost topics important for their respective documents when their vocabularies are not clearly invoked by their documents? We hypothesize that ghost topics are identified by the machine reader because they are contiguous to topics that are clearly evidenced in the documents, and that such identifications speak to latent semantic networks to which these documents can be connected.<sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup>  That is to say, if  “On Han Gaozu”  says nothing about fishermen or fishing (a common trope for the wisdom of humble folk), it nevertheless is comprised of a number of vocabulary sets that are adjacent to the topic of fishermen in some way, from the southern (Chu) riverscapes of Topic 122 to the heroes, men of valor of Topic 115, implying that fishermen, fishing should be located within the semantic networks of these probabilistic distributions. Likewise, there is nothing about reclusion in  “Hymns for the Offering to the Ancestral Temple” , though the highly ranked cluster of topics that emphasize imperial court ritual, such as Topic 87 (divine creation and transformation), Topic 98 (ritual and ceremony), and Topic 131 (imperial court), create a space for the recluse, who is often figured in diametric opposition to the courtier, as the obverse face of the same sociopolitical coin.</p>
<p>To conclude: if we think about poetry not in terms of subgenres or standard metrical forms, but rather in terms of constitutive vocabularies, it becomes clear that there is a shared set of terms that crosses different poetic modes, creating hidden textual communities that would not usually be noticed when reading along traditional throughlines. The detection of hidden or unremarked communities of poems is not in itself literary history, but it lays a new evidentiary foundation for how literary history might be imagined. Instead of narrating the development of poetic style or genre based upon the chronological progression of authors, one might take a radically agnostic thematic approach, one that treats literary compositions as bags of words and seeks out the commonalities of vocabulary across these bags, using topics to dictate the selection of documents for argument and analysis. Such an approach might not answer the impossible question of map and territory — of data completeness and selectivity — that haunts narrative historical representation, but it would allow pathways into the true unconscious of literary history, the Great Unread that contemporary databases of digitized corpora are beginning to resurrect and make legible.</p>
<p>Here, we reaffirm that human reading on its own cannot make sense of this quantity of data, and machinic reading lacks the capacity to translate patterns into meaningful arguments. It is only a conjoining and interweaving of machinic and human perspectives that make it possible to read a collection on the scale of the  <em>QTS</em> ; it is only through reading the collection as a whole that one may arrive at a comprehensive model of its contents; and it is by engaging with a comprehensive model that literary history may find its standards for the necessary reductions of data that make its narratives possible.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>We would like to thank Timothy R. Tangherlini for his advice throughout, as well as Evan Nicoll-Johnson, Yunshuang Zhang, and Ruichuan Wu for their support during the data preparation phase of the project. We are also grateful to the former UCLA Center for Digital Humanities (now HumTech) for providing a meeting space and resources.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="#rosenthal2017">See Rosenthal 2017</a> for a discussion of the relationship between narrative and data, though the problem of how the narrative form impacts the data model is not raised. On the topic of data modeling, <a href="#flanders2016">see Flanders and Jannidis 2016</a>, though, conversely, there is no consideration of narrative as a data model.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Moretti, Franco.  “Conjectures on World Literature” .  <em>New Left Review</em>  1 (2000a): 54–68.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>— .  “A Genealogy of Distant Reading” .  <em>DHQ: Digital Humanities Quarterly</em>  11.2 (2017). Available at: <a href="/dhqwords/vol/11/2/000317/">http://www.digitalhumanities.org/dhq/vol/11/2/000317/000317.html</a>. Accessed September 11, 2019.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Piper, Andrew.  “Novel Devotions: Conversional Reading, Computational Modeling, and the Modern Novel” .  <em>New Literary History</em>  46 (2015): 63–98.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Nichols, Ryan, Edward Slingerland, Kristoffer Nielbo, and Uffe Bergeton.  “Modeling the Contested Relationship between Analects, Mencius, and Xunzi: Preliminary Evidence from a Machine-Learning Approach” .  <em>The Journal of Asian Studies</em>  77.1 (2018): 19–57. Available at: <a href="https://doi.org/10.1017/S0021911817000973">https://doi.org/10.1017/S0021911817000973</a>. Accessed September 5, 2019.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>Allen, Colin, Hongliang Luo, Jaimie Murdock, Jianghuai Pu, Xiaohong Wang, Yanjie Zhai, and Kun Zhao. 2017.  “Topic Modeling the Hàn diǎn Ancient Classics” .  <em>Journal of Cultural Analytics</em>  (2017). <a href="http://culturalanalytics.org/2017/10/topic-modeling-the-han-dian-ancient-classics-%E6%B1%89%E5%85%B8%E5%8F%A4%E7%B1%8D/">http://doi.org/10.22148/16.016</a>. Accessed September 5, 2019.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>Vierthaler, Paul.  “Fiction and History: Polarity and Stylistic Gradience in Late Imperial Chinese Literature” .  <em>Journal of Cultural Analytics</em>  (2016). DOI: <a href="https://doi.org/10.31235/osf.io/t9b7v">10.31235/osf.io/t9b7v</a>. Accessed August 20, 2019.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>Long, Hoyt and Richard Jean So.  “Literary Pattern Recognition: Modernism between Close Reading and Machine Learning” .  <em>Critical Inquiry</em>  42 (2016): 235–67.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>Liu, Chao-Lin, Thomas J. Mazanec, and Jeffrey R. Tharsen..  “Exploring Chinese Poetry with Digital Assistance: Examples from Linguistic, Literary, and Historical Viewpoints” .  <em>Journal of Chinese Literature and Culture</em>  5.2 (2018): 276–321.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>Perkins, David.  <em>Is Literary History Possible?</em>  Baltimore: The Johns Hopkins University Press (1992).&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>Drucker, Johanna.  “Humanities Approaches to Graphical Display” .  <em>DHQ: Digital Humanities Quarterly</em>  5.1 (2011). <a href="/dhqwords/vol/5/1/000091/">http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html</a>. Accessed September 10, 2019.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p>Rosenberg, Daniel.  “Data before the Fact” . In  <em>“Raw Data” Is an Oxymoron</em> , edited by Lisa Gitelman, 15–40. Cambridge: MIT Press (2013).&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p>Wellek, René and Austin Warren.  <em>Theory of Literature</em> . 3rd ed. New York: Harcourt, Brace &amp; World (1956).&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p>It is worth noting that Wellek and Warren’s first edition of  <em>Theory of Literature</em>  was published in 1948, the same year that Claude Shannon published his  “A Mathematical Theory of Information” , the essay that is often cited as ushering in the Information Age. Wellek and Warren, of course, do not make reference to the kinds of engineering problems with which Shannon was concerned, but they are conscious of how the vast possible quantities of literary facts impact the writing of literary history. Some work has been done on intersection between the history of information science and the history of literary studies, though there is more that can be done <sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>  <sup id="fnref:60"><a href="#fn:60" class="footnote-ref" role="doc-noteref">60</a></sup>.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p>Cohen, Margaret.  <em>The Sentimental Education of the Novel</em> . Princeton: Princeton University Press (1999).&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p>— .  “The Slaughterhouse of Literature” .  <em>MLQ: Modern Language Quarterly</em>  61, no. 1 (2000b): 207–27.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p>Bode, Katherine.  “The Equivalence of  Close  and  Distant  Reading, or, Toward a New Object for Data-Rich Literary History” .  <em>Modern Language Notes</em>  78.1 (2017): 77–106.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p>Blair, Ann.  <em>Too Much to Know: Managing Scholarly Information before the Modern Age</em> . New Haven: Yale University Press (2011).&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p><em>Quan Tang shi</em>  全唐詩 (Complete Tang poems). 25 vols. Beijing: Zhonghua shuju (1960).&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p>Spence, Jonathan D.  <em>Ts’ao Yin and the K’ang-hsi Emperor</em> . New Haven: Yale University Press (1966).&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p>Unsurprisingly, not all Tang poems are collected in the  <em>QTS</em> . For an anthology of uncollected Tang poems, see Chen 1992. Poetry recovered from Dunhuang would not have been included in the  <em>QTS</em>  because the Dunhuang Library Cave was not discovered until 1900 <sup id="fnref:61"><a href="#fn:61" class="footnote-ref" role="doc-noteref">61</a></sup>.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p>Jockers, Matthew L.  <em>Macroanalysis: Digital Methods &amp; Literary History</em> . Urbana: University of Illinois Press (2013).&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p>Tong Peiji 佟培基.  “Jin sanbai nian  <em>Quan Tang shi</em>  de zhengli yu yanjiu”  近三百年《全唐詩》的整理與研究 (Corrections and research on the  <em>Complete Tang poems</em>  over the last three hundred years),  <em>Wenxian</em>  文獻 (Textual evidence) 59.3 (1998): 17–28.&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p>Hu, Zhenheng 胡震亨 (1569–ca. 1644),  <em>Tangyin tongqian</em>  唐音統籤 (Assembled documents of Tang tones). 9 vols. Shanghai: Shanghai guji chubanshe (2003).&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p>Qian, Qianyi 錢謙益 (1582–1664) and Ji Zhenyi 季振宜 (b. 1630), comps.  <em>Quan Tang shi gaoben</em>  全唐詩稿本 (Draft edition of the complete Tang poems). Edited by Qu Wanli 屈萬里 and Liu Zhaoyou 劉兆祐. 71 vols. Taipei: Lianjing chuban shiye gongsi (1979).&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p>Allen, Joseph R.  <em>In the Voice of Others: Chinese Music Bureau Poetry</em> . Ann Arbor: Center for Chinese Studies, The University of Michigan (1992).&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p>— .  <em>The Making of Early Chinese Classical Poetry</em> . Cambridge: Harvard University Asia Center (2006b).&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p>Yu, Pauline.  “Poems in Their Place: Collections and Canons in Early Chinese Literature” .  <em>Harvard Journal of Asiatic Studies</em>  50.1 (1990): 163–96.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p>— .  “The Chinese Poetic Canon and Its Boundaries” . In  <em>Boundaries in China</em> , edited by John Hay, 105–23. London: Reaktion Books (1994).&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p>Drège, Jean-Pierre.  “Des ouvrages classés par catégories: les encyclopédies chinoises” . In  <em>Qu’était-ce qu’écrire une encyclopédie en Chine? / What Did It Mean to Write an Encyclopedia in China?</em> , edited by Florence Establet-Bretelle and Karine Chemla, 19–38.  <em>Extrême-Orient, Extrême-Occident</em> , hors série (2007).&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p>Tian, Xiaofei.  “Literary Learning: Encyclopedias and Epitomes” . In  <em>Oxford Handbook of Classical Chinese Literature (1000 BCE–900 CE)</em> , edited by Wiebke Denecke, Wai-Yee Li, and Xiaofei Tian, 132–46. New York: Oxford University Press (2017).&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32">
<p>Qian, Zhonglian 錢仲聯, gen. ed., et al.  <em>Zhongguo wenxue dacidian</em>  中國文學大辭典 (Great dictionary of Chinese literature). 2 vols. Shanghai: Shanghai guji chubanshe (2000).&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33">
<p>Hickman, Miranda B. and John D. McIntyre, eds.  <em>Rereading the New Criticism</em> . Columbus: Ohio University Press (2012).&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34">
<p>North, Joseph.  “What’s  New Critical  about  Close Reading ? I.A. Richards and His New Critical Reception” .  <em>New Literary History</em>  44, no. 1 (2013): 141–57.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35">
<p>Hayles, N. Katherine.  “How We Read: Close, Hyper, Machine” .  <em>ADE Bulletin</em>  150 (2010): 62–79.&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36">
<p>Ramsay, Stephen.  <em>Reading Machines: Toward an Algorithmic Criticism</em> . Urbana: University of Illinois Press (2011).&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37">
<p>Meeks, Elijah and Scott B. Weingart, eds. Special issue,  “The Digital Humanities Contribution to Topic Modeling” ,  <em>Journal of Digital Humanities</em>  2.1 (2012). Available at: <a href="http://journalofdigitalhumanities.org/2-1/dh-contribution-to-topic-modeling/">http://journalofdigitalhumanities.org/2-1/dh-contribution-to-topic-modeling/</a>. Accessed January 9, 2018.&#160;<a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38">
<p>Underwood, Ted.  “What Kind of  Topics  Does Topic Modeling Actually Produce?”  April 1, 2012. Available at: <a href="https://tedunderwood.com/2012/04/01/what-kinds-of-topics-does-topic-modeling-actually-produce/">https://tedunderwood.com/2012/04/01/what-kinds-of-topics-does-topic-modeling-actually-produce/</a>. Accessed January 9, 2018.&#160;<a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39">
<p>Riddell, Allen B.  “A Simple Topic Model (Mixture of Unigrams)” . July 22, 2012. Available at: <a href="https://www.ariddell.org/simple-topic-model.html">https://www.ariddell.org/simple-topic-model.html</a>. Accessed January 9, 2018.&#160;<a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40">
<p>Blei, David.  “Probabilistic Topic Models” .  <em>Communications of the ACM</em>  55.4 (2012): 77–84.&#160;<a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41">
<p>McCallum, Andrew Kachites.  _ <em>MALLET</em> : A Machine Learning for Language Toolkit_ . 2002. Available at: <a href="http://mallet.cs.umass.edu/index.php">http://mallet.cs.umass.edu/index.php</a>.&#160;<a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42">
<p>Note that the problem of optimizing the ideal number of topics for LDA is still unresolved. This is discussed, with relevant technical sources, in <a href="#tangherlini2013">Tangherlini and Leonard 2013, 731</a>.&#160;<a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43">
<p>Huang, Shuanfan Huang.  <em>Chinese Grammar at Work</em> . Amsterdam: John Benjamins Publishing Company (2013).&#160;<a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44">
<p>Han Gaozu 漢高祖 (r. 202–195 BCE), born Liu Bang 劉邦 (256–195 BCE), was the founding emperor of the Han dynasty (202 BCE–220 CE).&#160;<a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45">
<p>This same image is used in the first poem in the  “Gufeng”  古風 ( “Ancient Airs” ) series by Li Bo 李白:  “The gathered talents entrust themselves to [the Sage’s] peerless brilliance, / Riding fortune’s course, all are leaping scales”  群才屬休明，乘運共躍鱗. See <a href="#qu1980">Qu and Zhu 1980, 2.91</a>; and <a href="#qts1960"> <em>QTS</em>  1960, 161.1670</a>.&#160;<a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46">
<p>This is an auspicious celestial event, the appearance of the first five planets, each identified with one of the Five Phase elements (water, metal, earth, fire, and wood), all in one region of the sky.&#160;<a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47">
<p>That is to say, the people of the world all become Han Gaozu’s subjects.&#160;<a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48">
<p>Xiang Yu 項羽 (232–202 BCE) was a nobleman of Chu who led the rebellion against the Qin dynasty (221–206 BCE) and triumphed, in 207 BCE, with the support of Liu Bang. Xiang Yu then founded the Western Chu, declaring himself king, and warred with Liu Bang over the empire. Liu Bang would eventually triumph in the battle at Gaixia, after which Xiang Yu committe suicide.&#160;<a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49">
<p>This couplet refers to Xiang Yu’s plot to kill Liu Bang, the future Han Gaozu, at a feast at Hongmen and later at Xingyang. At Hongmen, Xiang Yu’s cousin Xiang Zhuang 項莊 was to perform a sword dance and stab Gaozu, but Gaozu was protected by Xiang Chan 項纏, uncle of Xiang Yu and Xiang Zhuang, who joined the dance and blocked each attack. Afterwards, Gaozu’s forces were surrounded at Xingyang (in modern-day Henan), and so he dressed up women in armor, sending them out to surrender, while he himself fled with a handful of men <sup id="fnref:62"><a href="#fn:62" class="footnote-ref" role="doc-noteref">62</a></sup>.&#160;<a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50">
<p>Han Xin 韓信 (d. 196) and Peng Yue 彭越 (d. 196 BCE) were both military commanders under Liu Bang. Zhang Liang 張良 (d. 186 BCE) and Chen Ping 陳平 (d. 178) were strategists who served under Liu Bang.&#160;<a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51">
<p>Western Chu (206–202 BCE) was the name of the kingdom founded by Xiang Yu after the conquest of Qin.&#160;<a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52">
<p>Classical Chinese rhymes were codified as rhyme-books (sometimes spelled as rimebooks) in the medieval period, with rhyming words categorized under header-words that represented the entire rhyme category. We have used David Prager Branner’s reconstructed medieval Chinese transcription in representing the rhyme category header-words <sup id="fnref:63"><a href="#fn:63" class="footnote-ref" role="doc-noteref">63</a></sup> and made use of his online rhyme database Yintong 音通, which can be accessed here: <a href="http://yintong.info/yintong/public/index.php">http://yintong.info/yintong/public/index.php</a>.&#160;<a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53">
<p>Lin, Jianhua.  “Divergence Measures Based on the Shannon Entropy” .  <em>IEEE Transactions on Information Theory</em>  37.1 (1991): 145–51.&#160;<a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54">
<p>This measure takes its name from Jensen’s inequality (devised by Johan L. W. V. Jensen; <a href="#jensen1906">see Jensen 1906</a>, and <a href="#needham1993">Needham 1993</a>) and the Shannon entropy (formulated by Claude E Shannon; <a href="#shannon1948">see Shannon 1948</a>, and <a href="#shannon1949">Shannon and Weaver 1949</a>).&#160;<a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55">
<p>There are other ways to calculate document similarity, including vector similarity measures such as cosine similarity <a href="#salton1983">(cf. Salton and McGill 1983, 201–4)</a>.&#160;<a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56">
<p>Liu, Xu 劉煦 (887–947),  <em>Jiu Tang shu</em>  舊唐書 (Old history of the Tang). 16 vols. Beijing: Zhonghua shuju (1986).&#160;<a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57">
<p>Tetrasyllabic verse is generally associated with the  <em>Classic of Poetry</em>  ( <em>Shijing</em>  詩經), the oldest extant collection of poetry in China and one of the Confucian Classics. Although poets continued to compose in tetrasyllabic form throughout the Han dynasty and the Period of Division (220–589 CE), by the Tang dynasty, most poets would compose in pentasyllabic or heptasyllabic meter, reserving the tetrasyllabic form mainly for ritual genres, archaizing modes, and certain formal occasions <sup id="fnref:64"><a href="#fn:64" class="footnote-ref" role="doc-noteref">64</a></sup>.&#160;<a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58">
<p>This also provides a justification for overshooting the value of n in the initial assignment of the number of topics for  <em>MALLET</em> . If one sets the number of topics so high that  <em>MALLET</em>  begins finding topics that are not noticeably present in specific documents, these extra topics may still be meaningful as semantic ghosts of the topics that are more evident in the corpus. Lowering the value of n most likely would eventually banish these ghosts.&#160;<a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59">
<p>Geoghegan, Bernard Dionysius.  “From Information Theory to French Theory: Jakobson, Lévi-Strauss, and the Cybernetic Apparatus” .  <em>Critical Inquiry</em>  38 (2011): 96–126.&#160;<a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:60">
<p>Liu, Lydia.  <em>The Freudian Robot: Digital Media and the Future of the Unconscious</em> . Chicago: University of Chicago Press (2010).&#160;<a href="#fnref:60" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:61">
<p>Ren, Zhongmin 任中敏, ed.  <em>Dunhuang geci zongpian</em>  敦煌歌辭總編 (Complete edition of Dunhuang songs and lyrics). 3 vols. Nanjing: Fenghuang chubanshe (2014).&#160;<a href="#fnref:61" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:62">
<p>Sima Qian.  <em>Records of the Grand Historian: Han Dynasty I</em> . Trans. Burton Watson. Rev. ed. Hong Kong and New York: The Research Centre for Translation, Chinese University of Hong Kong and Columbia University Press (1993).&#160;<a href="#fnref:62" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:63">
<p>Branner, David Prager.  “A Neutral Transcription System for Teaching Medieval Chinese” .  <em>T’ang Studies</em>  17 (1999): 1–169.&#160;<a href="#fnref:63" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:64">
<p>Raft, Zebulon David.  “Four-syllable Verse in Medieval China” . Ph.D. diss., Harvard University (2007).&#160;<a href="#fnref:64" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content></entry></feed>